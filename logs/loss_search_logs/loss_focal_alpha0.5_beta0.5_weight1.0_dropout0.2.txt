=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 1.0 --dropout 0.2 --name loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.2 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.2
text_dim: 128
image_dim: 256
dropout: 0.2
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6984, log_difficulty=0.5297, weight=3.6484
neutral: count=7.0, difficulty=0.6928, log_difficulty=0.5264, weight=3.6318
negative: count=13.0, difficulty=0.6563, log_difficulty=0.5046, weight=3.5229

当前batch的pt分布：
positive: min=0.1811, max=0.4858, mean=0.3016
neutral: min=0.1736, max=0.4646, mean=0.3072
negative: min=0.1732, max=0.7227, mean=0.3437

当前batch准确率：
整体准确率: 0.2500
positive 准确率: 0.1667
neutral 准确率: 0.2857
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1914
焦点损失: 0.4347
边界损失: 0.7606
总损失: 1.1624
Epoch 1 [1/172] - loss: 1.1624, acc: 0.2500
Epoch 1 [2/172] - loss: 1.0721
Epoch 1 [3/172] - loss: 0.9923
Epoch 1 [4/172] - loss: 1.1618
Epoch 1 [5/172] - loss: 1.0745
Epoch 1 [6/172] - loss: 1.1488
Epoch 1 [7/172] - loss: 1.2324
Epoch 1 [8/172] - loss: 1.0904
Epoch 1 [9/172] - loss: 1.0364
Epoch 1 [10/172] - loss: 1.0987, acc: 0.3750
Epoch 1 [11/172] - loss: 1.0667
Epoch 1 [12/172] - loss: 0.9763
Epoch 1 [13/172] - loss: 1.0014
Epoch 1 [14/172] - loss: 0.9220
Epoch 1 [15/172] - loss: 1.0409
Epoch 1 [16/172] - loss: 0.8426
Epoch 1 [17/172] - loss: 1.1972
Epoch 1 [18/172] - loss: 1.2127
Epoch 1 [19/172] - loss: 0.8768
Epoch 1 [20/172] - loss: 1.0726, acc: 0.3438
Epoch 1 [21/172] - loss: 1.0771
Epoch 1 [22/172] - loss: 1.1246
Epoch 1 [23/172] - loss: 0.9808
Epoch 1 [24/172] - loss: 0.8905
Epoch 1 [25/172] - loss: 0.8815
Epoch 1 [26/172] - loss: 0.8716
Epoch 1 [27/172] - loss: 1.0323
Epoch 1 [28/172] - loss: 1.1595
Epoch 1 [29/172] - loss: 0.9833
Epoch 1 [30/172] - loss: 0.9267, acc: 0.4375
Epoch 1 [31/172] - loss: 0.9418
Epoch 1 [32/172] - loss: 0.8478
Epoch 1 [33/172] - loss: 0.9033
Epoch 1 [34/172] - loss: 0.9379
Epoch 1 [35/172] - loss: 0.8320
Epoch 1 [36/172] - loss: 0.7303
Epoch 1 [37/172] - loss: 0.8547
Epoch 1 [38/172] - loss: 0.8993
Epoch 1 [39/172] - loss: 0.8464
Epoch 1 [40/172] - loss: 0.7888, acc: 0.5938
Epoch 1 [41/172] - loss: 0.7278
Epoch 1 [42/172] - loss: 0.6931
Epoch 1 [43/172] - loss: 0.8213
Epoch 1 [44/172] - loss: 0.8891
Epoch 1 [45/172] - loss: 0.7713
Epoch 1 [46/172] - loss: 0.6316
Epoch 1 [47/172] - loss: 0.7607
Epoch 1 [48/172] - loss: 0.7935
Epoch 1 [49/172] - loss: 0.7780
Epoch 1 [50/172] - loss: 0.6922, acc: 0.6250
Epoch 1 [51/172] - loss: 0.8058
Epoch 1 [52/172] - loss: 0.8395
Epoch 1 [53/172] - loss: 0.7205
Epoch 1 [54/172] - loss: 0.8679
Epoch 1 [55/172] - loss: 0.5651
Epoch 1 [56/172] - loss: 0.5450
Epoch 1 [57/172] - loss: 0.7511
Epoch 1 [58/172] - loss: 0.4968
Epoch 1 [59/172] - loss: 0.8008
Epoch 1 [60/172] - loss: 0.6258, acc: 0.7500
Epoch 1 [61/172] - loss: 0.8303
Epoch 1 [62/172] - loss: 0.8738
Epoch 1 [63/172] - loss: 0.9098
Epoch 1 [64/172] - loss: 0.6286
Epoch 1 [65/172] - loss: 0.7310
Epoch 1 [66/172] - loss: 0.8238
Epoch 1 [67/172] - loss: 0.7316
Epoch 1 [68/172] - loss: 0.7090
Epoch 1 [69/172] - loss: 0.8831
Epoch 1 [70/172] - loss: 0.6795, acc: 0.6562
Epoch 1 [71/172] - loss: 0.4424
Epoch 1 [72/172] - loss: 0.6386
Epoch 1 [73/172] - loss: 0.6228
Epoch 1 [74/172] - loss: 0.6757
Epoch 1 [75/172] - loss: 0.3914
Epoch 1 [76/172] - loss: 0.6685
Epoch 1 [77/172] - loss: 0.6018
Epoch 1 [78/172] - loss: 0.5800
Epoch 1 [79/172] - loss: 0.8413
Epoch 1 [80/172] - loss: 0.4204, acc: 0.8125
Epoch 1 [81/172] - loss: 0.4836
Epoch 1 [82/172] - loss: 0.7916
Epoch 1 [83/172] - loss: 0.4891
Epoch 1 [84/172] - loss: 0.7147
Epoch 1 [85/172] - loss: 0.5669
Epoch 1 [86/172] - loss: 0.8146
Epoch 1 [87/172] - loss: 0.4973
Epoch 1 [88/172] - loss: 0.6971
Epoch 1 [89/172] - loss: 0.7160
Epoch 1 [90/172] - loss: 0.6095, acc: 0.7188
Epoch 1 [91/172] - loss: 0.6830
Epoch 1 [92/172] - loss: 0.5137
Epoch 1 [93/172] - loss: 0.5642
Epoch 1 [94/172] - loss: 0.5264
Epoch 1 [95/172] - loss: 0.5746
Epoch 1 [96/172] - loss: 0.5511
Epoch 1 [97/172] - loss: 0.5423
Epoch 1 [98/172] - loss: 0.4828
Epoch 1 [99/172] - loss: 0.7278
Epoch 1 [100/172] - loss: 0.8039, acc: 0.6250

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5599, log_difficulty=0.4447, weight=3.2233
neutral: count=983.0, difficulty=0.5344, log_difficulty=0.4282, weight=3.1409
negative: count=1119.0, difficulty=0.5417, log_difficulty=0.4329, weight=3.1644

当前batch的pt分布：
positive: min=0.0310, max=0.9329, mean=0.5275
neutral: min=0.7131, max=0.9352, mean=0.8012
negative: min=0.0708, max=0.8303, mean=0.3823

当前batch准确率：
整体准确率: 0.6562
positive 准确率: 0.7500
neutral 准确率: 1.0000
negative 准确率: 0.5000

损失分量：
基础交叉熵: 0.9453
焦点损失: 0.4495
边界损失: 0.4516
总损失: 0.9416
Epoch 1 [101/172] - loss: 0.9416
Epoch 1 [102/172] - loss: 0.6826
Epoch 1 [103/172] - loss: 0.5287
Epoch 1 [104/172] - loss: 0.4111
Epoch 1 [105/172] - loss: 0.7176
Epoch 1 [106/172] - loss: 0.9210
Epoch 1 [107/172] - loss: 0.5254
Epoch 1 [108/172] - loss: 0.8312
Epoch 1 [109/172] - loss: 0.5572
Epoch 1 [110/172] - loss: 0.6551, acc: 0.6562
Epoch 1 [111/172] - loss: 0.6020
Epoch 1 [112/172] - loss: 0.5850
Epoch 1 [113/172] - loss: 0.3347
Epoch 1 [114/172] - loss: 0.4825
Epoch 1 [115/172] - loss: 0.4604
Epoch 1 [116/172] - loss: 0.5687
Epoch 1 [117/172] - loss: 0.5021
Epoch 1 [118/172] - loss: 0.3955
Epoch 1 [119/172] - loss: 0.5365
Epoch 1 [120/172] - loss: 0.3591, acc: 0.7812
Epoch 1 [121/172] - loss: 0.3027
Epoch 1 [122/172] - loss: 0.6508
Epoch 1 [123/172] - loss: 0.3936
Epoch 1 [124/172] - loss: 0.5236
Epoch 1 [125/172] - loss: 0.3572
Epoch 1 [126/172] - loss: 0.6297
Epoch 1 [127/172] - loss: 0.4018
Epoch 1 [128/172] - loss: 0.4231
Epoch 1 [129/172] - loss: 0.6716
Epoch 1 [130/172] - loss: 0.4015, acc: 0.7500
Epoch 1 [131/172] - loss: 0.2210
Epoch 1 [132/172] - loss: 0.5331
Epoch 1 [133/172] - loss: 0.5301
Epoch 1 [134/172] - loss: 0.5047
Epoch 1 [135/172] - loss: 0.3588
Epoch 1 [136/172] - loss: 0.5273
Epoch 1 [137/172] - loss: 0.6005
Epoch 1 [138/172] - loss: 0.3925
Epoch 1 [139/172] - loss: 0.3546
Epoch 1 [140/172] - loss: 0.3413, acc: 0.8125
Epoch 1 [141/172] - loss: 0.3880
Epoch 1 [142/172] - loss: 0.4479
Epoch 1 [143/172] - loss: 0.5908
Epoch 1 [144/172] - loss: 0.2962
Epoch 1 [145/172] - loss: 0.4995
Epoch 1 [146/172] - loss: 0.6502
Epoch 1 [147/172] - loss: 0.5527
Epoch 1 [148/172] - loss: 0.3453
Epoch 1 [149/172] - loss: 0.2745
Epoch 1 [150/172] - loss: 0.4134, acc: 0.7812
Epoch 1 [151/172] - loss: 0.5440
Epoch 1 [152/172] - loss: 0.4148
Epoch 1 [153/172] - loss: 0.3928
Epoch 1 [154/172] - loss: 0.4668
Epoch 1 [155/172] - loss: 0.4346
Epoch 1 [156/172] - loss: 0.7692
Epoch 1 [157/172] - loss: 0.5666
Epoch 1 [158/172] - loss: 0.4456
Epoch 1 [159/172] - loss: 0.7158
Epoch 1 [160/172] - loss: 0.4118, acc: 0.7500
Epoch 1 [161/172] - loss: 0.3756
Epoch 1 [162/172] - loss: 0.5287
Epoch 1 [163/172] - loss: 0.4270
Epoch 1 [164/172] - loss: 0.5247
Epoch 1 [165/172] - loss: 0.3828
Epoch 1 [166/172] - loss: 0.3841
Epoch 1 [167/172] - loss: 0.3856
Epoch 1 [168/172] - loss: 0.4830
Epoch 1 [169/172] - loss: 0.5078
Epoch 1 [170/172] - loss: 0.5046, acc: 0.7500
Epoch 1 [171/172] - loss: 0.3540
Epoch 1 [172/172] - loss: 0.4958

类别准确率:
positive: 0.5931 (277/467)
neutral: 0.8193 (68/83)
negative: 0.3360 (84/250)

Epoch 1/10
Train Loss: 0.4683, Train Acc: 0.7758
Val Loss: 0.9733, Val Acc: 0.5363
Epoch 2 [1/172] - loss: 0.3327, acc: 0.8125
Epoch 2 [2/172] - loss: 0.3154
Epoch 2 [3/172] - loss: 0.2846
Epoch 2 [4/172] - loss: 0.3706
Epoch 2 [5/172] - loss: 0.5057
Epoch 2 [6/172] - loss: 0.4184
Epoch 2 [7/172] - loss: 0.2707
Epoch 2 [8/172] - loss: 0.3213
Epoch 2 [9/172] - loss: 0.3626
Epoch 2 [10/172] - loss: 0.3622, acc: 0.9062
Epoch 2 [11/172] - loss: 0.2316
Epoch 2 [12/172] - loss: 0.2127
Epoch 2 [13/172] - loss: 0.3803
Epoch 2 [14/172] - loss: 0.2924
Epoch 2 [15/172] - loss: 0.3693
Epoch 2 [16/172] - loss: 0.3659
Epoch 2 [17/172] - loss: 0.4031
Epoch 2 [18/172] - loss: 0.3743
Epoch 2 [19/172] - loss: 0.3263
Epoch 2 [20/172] - loss: 0.3395, acc: 0.8750
Epoch 2 [21/172] - loss: 0.2899
Epoch 2 [22/172] - loss: 0.2768
Epoch 2 [23/172] - loss: 0.1993
Epoch 2 [24/172] - loss: 0.4958
Epoch 2 [25/172] - loss: 0.5542
Epoch 2 [26/172] - loss: 0.1829
Epoch 2 [27/172] - loss: 0.2722
Epoch 2 [28/172] - loss: 0.2326

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4835, log_difficulty=0.3944, weight=2.9720
neutral: count=1952.0, difficulty=0.4106, log_difficulty=0.3440, weight=2.7201
negative: count=2216.0, difficulty=0.4629, log_difficulty=0.3804, weight=2.9021

当前batch的pt分布：
positive: min=0.4717, max=0.9790, mean=0.7592
neutral: min=0.7100, max=0.9550, mean=0.8662
negative: min=0.0206, max=0.9218, mean=0.6110

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.6667

损失分量：
基础交叉熵: 0.4504
焦点损失: 0.2046
边界损失: 0.2554
总损失: 0.4247
Epoch 2 [29/172] - loss: 0.4247
Epoch 2 [30/172] - loss: 0.2751, acc: 0.8750
Epoch 2 [31/172] - loss: 0.4273
Epoch 2 [32/172] - loss: 0.2239
Epoch 2 [33/172] - loss: 0.2617
Epoch 2 [34/172] - loss: 0.3787
Epoch 2 [35/172] - loss: 0.2201
Epoch 2 [36/172] - loss: 0.5911
Epoch 2 [37/172] - loss: 0.2535
Epoch 2 [38/172] - loss: 0.2875
Epoch 2 [39/172] - loss: 0.4531
Epoch 2 [40/172] - loss: 0.3254, acc: 0.8125
Epoch 2 [41/172] - loss: 0.2745
Epoch 2 [42/172] - loss: 0.2164
Epoch 2 [43/172] - loss: 0.2396
Epoch 2 [44/172] - loss: 0.5920
Epoch 2 [45/172] - loss: 0.1956
Epoch 2 [46/172] - loss: 0.2925
Epoch 2 [47/172] - loss: 0.4380
Epoch 2 [48/172] - loss: 0.2583
Epoch 2 [49/172] - loss: 0.3351
Epoch 2 [50/172] - loss: 0.3388, acc: 0.8438
Epoch 2 [51/172] - loss: 0.3097
Epoch 2 [52/172] - loss: 0.3242
Epoch 2 [53/172] - loss: 0.2450
Epoch 2 [54/172] - loss: 0.1622
Epoch 2 [55/172] - loss: 0.2141
Epoch 2 [56/172] - loss: 0.2490
Epoch 2 [57/172] - loss: 0.1651
Epoch 2 [58/172] - loss: 0.2211
Epoch 2 [59/172] - loss: 0.3978
Epoch 2 [60/172] - loss: 0.2395, acc: 0.9062
Epoch 2 [61/172] - loss: 0.1837
Epoch 2 [62/172] - loss: 0.3231
Epoch 2 [63/172] - loss: 0.3233
Epoch 2 [64/172] - loss: 0.1983
Epoch 2 [65/172] - loss: 0.2523
Epoch 2 [66/172] - loss: 0.1958
Epoch 2 [67/172] - loss: 0.1725
Epoch 2 [68/172] - loss: 0.2962
Epoch 2 [69/172] - loss: 0.1738
Epoch 2 [70/172] - loss: 0.3173, acc: 0.9062
Epoch 2 [71/172] - loss: 0.3915
Epoch 2 [72/172] - loss: 0.3484
Epoch 2 [73/172] - loss: 0.2106
Epoch 2 [74/172] - loss: 0.2777
Epoch 2 [75/172] - loss: 0.2264
Epoch 2 [76/172] - loss: 0.2924
Epoch 2 [77/172] - loss: 0.2704
Epoch 2 [78/172] - loss: 0.3053
Epoch 2 [79/172] - loss: 0.2811
Epoch 2 [80/172] - loss: 0.1502, acc: 0.9688
Epoch 2 [81/172] - loss: 0.1849
Epoch 2 [82/172] - loss: 0.1599
Epoch 2 [83/172] - loss: 0.2249
Epoch 2 [84/172] - loss: 0.2725
Epoch 2 [85/172] - loss: 0.2181
Epoch 2 [86/172] - loss: 0.2365
Epoch 2 [87/172] - loss: 0.5670
Epoch 2 [88/172] - loss: 0.1973
Epoch 2 [89/172] - loss: 0.1814
Epoch 2 [90/172] - loss: 0.2910, acc: 0.8438
Epoch 2 [91/172] - loss: 0.1457
Epoch 2 [92/172] - loss: 0.2828
Epoch 2 [93/172] - loss: 0.1764
Epoch 2 [94/172] - loss: 0.2816
Epoch 2 [95/172] - loss: 0.3062
Epoch 2 [96/172] - loss: 0.1771
Epoch 2 [97/172] - loss: 0.2236
Epoch 2 [98/172] - loss: 0.1589
Epoch 2 [99/172] - loss: 0.1402
Epoch 2 [100/172] - loss: 0.1908, acc: 0.9062
Epoch 2 [101/172] - loss: 0.1804
Epoch 2 [102/172] - loss: 0.1082
Epoch 2 [103/172] - loss: 0.3832
Epoch 2 [104/172] - loss: 0.1842
Epoch 2 [105/172] - loss: 0.1708
Epoch 2 [106/172] - loss: 0.1597
Epoch 2 [107/172] - loss: 0.1617
Epoch 2 [108/172] - loss: 0.4108
Epoch 2 [109/172] - loss: 0.1406
Epoch 2 [110/172] - loss: 0.2601, acc: 0.8438
Epoch 2 [111/172] - loss: 0.1260
Epoch 2 [112/172] - loss: 0.1861
Epoch 2 [113/172] - loss: 0.1768
Epoch 2 [114/172] - loss: 0.1295
Epoch 2 [115/172] - loss: 0.1576
Epoch 2 [116/172] - loss: 0.2856
Epoch 2 [117/172] - loss: 0.3154
Epoch 2 [118/172] - loss: 0.3064
Epoch 2 [119/172] - loss: 0.1849
Epoch 2 [120/172] - loss: 0.1570, acc: 0.9062
Epoch 2 [121/172] - loss: 0.2173
Epoch 2 [122/172] - loss: 0.4649
Epoch 2 [123/172] - loss: 0.2355
Epoch 2 [124/172] - loss: 0.2933
Epoch 2 [125/172] - loss: 0.1381
Epoch 2 [126/172] - loss: 0.1381
Epoch 2 [127/172] - loss: 0.1836
Epoch 2 [128/172] - loss: 0.3014

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4127, log_difficulty=0.3455, weight=2.7274
neutral: count=2949.0, difficulty=0.3206, log_difficulty=0.2781, weight=2.3905
negative: count=3294.0, difficulty=0.3953, log_difficulty=0.3331, weight=2.6655

当前batch的pt分布：
positive: min=0.2694, max=0.9841, mean=0.7489
neutral: min=0.7369, max=0.9925, mean=0.8930
negative: min=0.1077, max=0.9574, mean=0.7965

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8000
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.2701
焦点损失: 0.0832
边界损失: 0.2291
总损失: 0.2262
Epoch 2 [129/172] - loss: 0.2262
Epoch 2 [130/172] - loss: 0.2197, acc: 0.9062
Epoch 2 [131/172] - loss: 0.2724
Epoch 2 [132/172] - loss: 0.2747
Epoch 2 [133/172] - loss: 0.2731
Epoch 2 [134/172] - loss: 0.1649
Epoch 2 [135/172] - loss: 0.3863
Epoch 2 [136/172] - loss: 0.1884
Epoch 2 [137/172] - loss: 0.1443
Epoch 2 [138/172] - loss: 0.2655
Epoch 2 [139/172] - loss: 0.2251
Epoch 2 [140/172] - loss: 0.2488, acc: 0.9062
Epoch 2 [141/172] - loss: 0.2460
Epoch 2 [142/172] - loss: 0.2067
Epoch 2 [143/172] - loss: 0.1863
Epoch 2 [144/172] - loss: 0.2559
Epoch 2 [145/172] - loss: 0.5384
Epoch 2 [146/172] - loss: 0.1798
Epoch 2 [147/172] - loss: 0.2596
Epoch 2 [148/172] - loss: 0.2097
Epoch 2 [149/172] - loss: 0.2247
Epoch 2 [150/172] - loss: 0.2283, acc: 0.8750
Epoch 2 [151/172] - loss: 0.3918
Epoch 2 [152/172] - loss: 0.2208
Epoch 2 [153/172] - loss: 0.2292
Epoch 2 [154/172] - loss: 0.2135
Epoch 2 [155/172] - loss: 0.2765
Epoch 2 [156/172] - loss: 0.2126
Epoch 2 [157/172] - loss: 0.1285
Epoch 2 [158/172] - loss: 0.1842
Epoch 2 [159/172] - loss: 0.2292
Epoch 2 [160/172] - loss: 0.1566, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1708
Epoch 2 [162/172] - loss: 0.1586
Epoch 2 [163/172] - loss: 0.3619
Epoch 2 [164/172] - loss: 0.2538
Epoch 2 [165/172] - loss: 0.2712
Epoch 2 [166/172] - loss: 0.2087
Epoch 2 [167/172] - loss: 0.1619
Epoch 2 [168/172] - loss: 0.1541
Epoch 2 [169/172] - loss: 0.1536
Epoch 2 [170/172] - loss: 0.2272, acc: 0.8750
Epoch 2 [171/172] - loss: 0.3155
Epoch 2 [172/172] - loss: 0.6507

类别准确率:
positive: 0.8737 (408/467)
neutral: 0.3253 (27/83)
negative: 0.6160 (154/250)

Epoch 2/10
Train Loss: 0.2366, Train Acc: 0.9253
Val Loss: 0.6854, Val Acc: 0.7362
Epoch 3 [1/172] - loss: 0.1219, acc: 1.0000
Epoch 3 [2/172] - loss: 0.1756
Epoch 3 [3/172] - loss: 0.0975
Epoch 3 [4/172] - loss: 0.1099
Epoch 3 [5/172] - loss: 0.1444
Epoch 3 [6/172] - loss: 0.1064
Epoch 3 [7/172] - loss: 0.1231
Epoch 3 [8/172] - loss: 0.1425
Epoch 3 [9/172] - loss: 0.2689
Epoch 3 [10/172] - loss: 0.1268, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1145
Epoch 3 [12/172] - loss: 0.1015
Epoch 3 [13/172] - loss: 0.1406
Epoch 3 [14/172] - loss: 0.1087
Epoch 3 [15/172] - loss: 0.1101
Epoch 3 [16/172] - loss: 0.3259
Epoch 3 [17/172] - loss: 0.1322
Epoch 3 [18/172] - loss: 0.2352
Epoch 3 [19/172] - loss: 0.0979
Epoch 3 [20/172] - loss: 0.1140, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1294
Epoch 3 [22/172] - loss: 0.2799
Epoch 3 [23/172] - loss: 0.1159
Epoch 3 [24/172] - loss: 0.1172
Epoch 3 [25/172] - loss: 0.1224
Epoch 3 [26/172] - loss: 0.1687
Epoch 3 [27/172] - loss: 0.1108
Epoch 3 [28/172] - loss: 0.1310
Epoch 3 [29/172] - loss: 0.1513
Epoch 3 [30/172] - loss: 0.1571, acc: 0.9688
Epoch 3 [31/172] - loss: 0.1180
Epoch 3 [32/172] - loss: 0.1197
Epoch 3 [33/172] - loss: 0.1084
Epoch 3 [34/172] - loss: 0.1867
Epoch 3 [35/172] - loss: 0.2263
Epoch 3 [36/172] - loss: 0.1133
Epoch 3 [37/172] - loss: 0.1430
Epoch 3 [38/172] - loss: 0.2007
Epoch 3 [39/172] - loss: 0.1018
Epoch 3 [40/172] - loss: 0.1279, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1466
Epoch 3 [42/172] - loss: 0.1425
Epoch 3 [43/172] - loss: 0.1026
Epoch 3 [44/172] - loss: 0.1200
Epoch 3 [45/172] - loss: 0.1661
Epoch 3 [46/172] - loss: 0.1524
Epoch 3 [47/172] - loss: 0.0972
Epoch 3 [48/172] - loss: 0.1179
Epoch 3 [49/172] - loss: 0.1151
Epoch 3 [50/172] - loss: 0.1541, acc: 0.9688
Epoch 3 [51/172] - loss: 0.1362
Epoch 3 [52/172] - loss: 0.1424
Epoch 3 [53/172] - loss: 0.1412
Epoch 3 [54/172] - loss: 0.1455
Epoch 3 [55/172] - loss: 0.1089
Epoch 3 [56/172] - loss: 0.1152

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3558, log_difficulty=0.3044, weight=2.5221
neutral: count=3923.0, difficulty=0.2704, log_difficulty=0.2393, weight=2.1965
negative: count=4382.0, difficulty=0.3423, log_difficulty=0.2944, weight=2.4720

当前batch的pt分布：
positive: min=0.2589, max=0.9742, mean=0.7938
neutral: min=0.0054, max=0.9470, mean=0.8080
negative: min=0.9811, max=0.9944, mean=0.9854

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8182
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3459
焦点损失: 0.1997
边界损失: 0.2033
总损失: 0.3268
Epoch 3 [57/172] - loss: 0.3268
Epoch 3 [58/172] - loss: 0.0963
Epoch 3 [59/172] - loss: 0.1162
Epoch 3 [60/172] - loss: 0.1470, acc: 0.9375
Epoch 3 [61/172] - loss: 0.1137
Epoch 3 [62/172] - loss: 0.1037
Epoch 3 [63/172] - loss: 0.1319
Epoch 3 [64/172] - loss: 0.1678
Epoch 3 [65/172] - loss: 0.0982
Epoch 3 [66/172] - loss: 0.1588
Epoch 3 [67/172] - loss: 0.1178
Epoch 3 [68/172] - loss: 0.0993
Epoch 3 [69/172] - loss: 0.1869
Epoch 3 [70/172] - loss: 0.0891, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1141
Epoch 3 [72/172] - loss: 0.1136
Epoch 3 [73/172] - loss: 0.0963
Epoch 3 [74/172] - loss: 0.1532
Epoch 3 [75/172] - loss: 0.1372
Epoch 3 [76/172] - loss: 0.1711
Epoch 3 [77/172] - loss: 0.1183
Epoch 3 [78/172] - loss: 0.2300
Epoch 3 [79/172] - loss: 0.1047
Epoch 3 [80/172] - loss: 0.1163, acc: 0.9688
Epoch 3 [81/172] - loss: 0.0954
Epoch 3 [82/172] - loss: 0.1071
Epoch 3 [83/172] - loss: 0.0891
Epoch 3 [84/172] - loss: 0.0875
Epoch 3 [85/172] - loss: 0.1009
Epoch 3 [86/172] - loss: 0.1021
Epoch 3 [87/172] - loss: 0.1452
Epoch 3 [88/172] - loss: 0.1086
Epoch 3 [89/172] - loss: 0.1439
Epoch 3 [90/172] - loss: 0.0862, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1321
Epoch 3 [92/172] - loss: 0.1063
Epoch 3 [93/172] - loss: 0.2372
Epoch 3 [94/172] - loss: 0.1522
Epoch 3 [95/172] - loss: 0.0884
Epoch 3 [96/172] - loss: 0.2453
Epoch 3 [97/172] - loss: 0.0994
Epoch 3 [98/172] - loss: 0.0917
Epoch 3 [99/172] - loss: 0.0992
Epoch 3 [100/172] - loss: 0.2401, acc: 0.9688
Epoch 3 [101/172] - loss: 0.2931
Epoch 3 [102/172] - loss: 0.0919
Epoch 3 [103/172] - loss: 0.1565
Epoch 3 [104/172] - loss: 0.1032
Epoch 3 [105/172] - loss: 0.1244
Epoch 3 [106/172] - loss: 0.1402
Epoch 3 [107/172] - loss: 0.1608
Epoch 3 [108/172] - loss: 0.1172
Epoch 3 [109/172] - loss: 0.1153
Epoch 3 [110/172] - loss: 0.1627, acc: 0.9062
Epoch 3 [111/172] - loss: 0.1925
Epoch 3 [112/172] - loss: 0.0938
Epoch 3 [113/172] - loss: 0.0983
Epoch 3 [114/172] - loss: 0.1161
Epoch 3 [115/172] - loss: 0.0945
Epoch 3 [116/172] - loss: 0.0937
Epoch 3 [117/172] - loss: 0.1137
Epoch 3 [118/172] - loss: 0.1352
Epoch 3 [119/172] - loss: 0.1341
Epoch 3 [120/172] - loss: 0.1918, acc: 0.9688
Epoch 3 [121/172] - loss: 0.2865
Epoch 3 [122/172] - loss: 0.1110
Epoch 3 [123/172] - loss: 0.1729
Epoch 3 [124/172] - loss: 0.1132
Epoch 3 [125/172] - loss: 0.1301
Epoch 3 [126/172] - loss: 0.2784
Epoch 3 [127/172] - loss: 0.1923
Epoch 3 [128/172] - loss: 0.1198
Epoch 3 [129/172] - loss: 0.1113
Epoch 3 [130/172] - loss: 0.1685, acc: 0.9062
Epoch 3 [131/172] - loss: 0.1228
Epoch 3 [132/172] - loss: 0.0868
Epoch 3 [133/172] - loss: 0.1698
Epoch 3 [134/172] - loss: 0.1310
Epoch 3 [135/172] - loss: 0.0986
Epoch 3 [136/172] - loss: 0.1277
Epoch 3 [137/172] - loss: 0.0980
Epoch 3 [138/172] - loss: 0.0968
Epoch 3 [139/172] - loss: 0.1058
Epoch 3 [140/172] - loss: 0.1339, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1405
Epoch 3 [142/172] - loss: 0.1502
Epoch 3 [143/172] - loss: 0.1052
Epoch 3 [144/172] - loss: 0.1563
Epoch 3 [145/172] - loss: 0.1131
Epoch 3 [146/172] - loss: 0.1187
Epoch 3 [147/172] - loss: 0.1780
Epoch 3 [148/172] - loss: 0.1093
Epoch 3 [149/172] - loss: 0.0980
Epoch 3 [150/172] - loss: 0.1241, acc: 0.9688
Epoch 3 [151/172] - loss: 0.2345
Epoch 3 [152/172] - loss: 0.1390
Epoch 3 [153/172] - loss: 0.0928
Epoch 3 [154/172] - loss: 0.3144
Epoch 3 [155/172] - loss: 0.0944
Epoch 3 [156/172] - loss: 0.1478

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3095, log_difficulty=0.2696, weight=2.3482
neutral: count=4903.0, difficulty=0.2329, log_difficulty=0.2094, weight=2.0468
negative: count=5500.0, difficulty=0.3000, log_difficulty=0.2624, weight=2.3118

当前batch的pt分布：
positive: min=0.4907, max=0.9891, mean=0.8980
neutral: min=0.6572, max=0.9917, mean=0.9288
negative: min=0.2959, max=0.9978, mean=0.8701

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1283
焦点损失: 0.0238
边界损失: 0.1863
总损失: 0.1205
Epoch 3 [157/172] - loss: 0.1205
Epoch 3 [158/172] - loss: 0.2569
Epoch 3 [159/172] - loss: 0.0867
Epoch 3 [160/172] - loss: 0.1424, acc: 0.9688
Epoch 3 [161/172] - loss: 0.1355
Epoch 3 [162/172] - loss: 0.1213
Epoch 3 [163/172] - loss: 0.1250
Epoch 3 [164/172] - loss: 0.0800
Epoch 3 [165/172] - loss: 0.1060
Epoch 3 [166/172] - loss: 0.1152
Epoch 3 [167/172] - loss: 0.0939
Epoch 3 [168/172] - loss: 0.1004
Epoch 3 [169/172] - loss: 0.0936
Epoch 3 [170/172] - loss: 0.1297, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1417
Epoch 3 [172/172] - loss: 0.0849

类别准确率:
positive: 0.8180 (382/467)
neutral: 0.3494 (29/83)
negative: 0.6560 (164/250)

Epoch 3/10
Train Loss: 0.1209, Train Acc: 0.9737
Val Loss: 0.7708, Val Acc: 0.7188
Epoch 4 [1/172] - loss: 0.0976, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1053
Epoch 4 [3/172] - loss: 0.1031
Epoch 4 [4/172] - loss: 0.0980
Epoch 4 [5/172] - loss: 0.1551
Epoch 4 [6/172] - loss: 0.0812
Epoch 4 [7/172] - loss: 0.1178
Epoch 4 [8/172] - loss: 0.0905
Epoch 4 [9/172] - loss: 0.1683
Epoch 4 [10/172] - loss: 0.0857, acc: 1.0000
Epoch 4 [11/172] - loss: 0.0822
Epoch 4 [12/172] - loss: 0.1430
Epoch 4 [13/172] - loss: 0.1583
Epoch 4 [14/172] - loss: 0.0972
Epoch 4 [15/172] - loss: 0.0806
Epoch 4 [16/172] - loss: 0.0833
Epoch 4 [17/172] - loss: 0.0858
Epoch 4 [18/172] - loss: 0.0918
Epoch 4 [19/172] - loss: 0.0792
Epoch 4 [20/172] - loss: 0.0840, acc: 1.0000
Epoch 4 [21/172] - loss: 0.0956
Epoch 4 [22/172] - loss: 0.1290
Epoch 4 [23/172] - loss: 0.1056
Epoch 4 [24/172] - loss: 0.0837
Epoch 4 [25/172] - loss: 0.1067
Epoch 4 [26/172] - loss: 0.3528
Epoch 4 [27/172] - loss: 0.1592
Epoch 4 [28/172] - loss: 0.1008
Epoch 4 [29/172] - loss: 0.0779
Epoch 4 [30/172] - loss: 0.1039, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1109
Epoch 4 [32/172] - loss: 0.0854
Epoch 4 [33/172] - loss: 0.0837
Epoch 4 [34/172] - loss: 0.0802
Epoch 4 [35/172] - loss: 0.0826
Epoch 4 [36/172] - loss: 0.1273
Epoch 4 [37/172] - loss: 0.0854
Epoch 4 [38/172] - loss: 0.0790
Epoch 4 [39/172] - loss: 0.1078
Epoch 4 [40/172] - loss: 0.1292, acc: 0.9375
Epoch 4 [41/172] - loss: 0.0828
Epoch 4 [42/172] - loss: 0.0985
Epoch 4 [43/172] - loss: 0.2382
Epoch 4 [44/172] - loss: 0.0845
Epoch 4 [45/172] - loss: 0.0812
Epoch 4 [46/172] - loss: 0.0898
Epoch 4 [47/172] - loss: 0.1305
Epoch 4 [48/172] - loss: 0.0986
Epoch 4 [49/172] - loss: 0.1101
Epoch 4 [50/172] - loss: 0.1129, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0907
Epoch 4 [52/172] - loss: 0.2138
Epoch 4 [53/172] - loss: 0.0918
Epoch 4 [54/172] - loss: 0.1128
Epoch 4 [55/172] - loss: 0.2208
Epoch 4 [56/172] - loss: 0.0874
Epoch 4 [57/172] - loss: 0.0800
Epoch 4 [58/172] - loss: 0.0900
Epoch 4 [59/172] - loss: 0.0880
Epoch 4 [60/172] - loss: 0.0817, acc: 1.0000
Epoch 4 [61/172] - loss: 0.0913
Epoch 4 [62/172] - loss: 0.1610
Epoch 4 [63/172] - loss: 0.0956
Epoch 4 [64/172] - loss: 0.0825
Epoch 4 [65/172] - loss: 0.1028
Epoch 4 [66/172] - loss: 0.0790
Epoch 4 [67/172] - loss: 0.0885
Epoch 4 [68/172] - loss: 0.1170
Epoch 4 [69/172] - loss: 0.1267
Epoch 4 [70/172] - loss: 0.0904, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0831
Epoch 4 [72/172] - loss: 0.0833
Epoch 4 [73/172] - loss: 0.0818
Epoch 4 [74/172] - loss: 0.2000
Epoch 4 [75/172] - loss: 0.0813
Epoch 4 [76/172] - loss: 0.0848
Epoch 4 [77/172] - loss: 0.1353
Epoch 4 [78/172] - loss: 0.0809
Epoch 4 [79/172] - loss: 0.0786
Epoch 4 [80/172] - loss: 0.1146, acc: 0.9688
Epoch 4 [81/172] - loss: 0.1324
Epoch 4 [82/172] - loss: 0.0975
Epoch 4 [83/172] - loss: 0.0805
Epoch 4 [84/172] - loss: 0.0843

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2729, log_difficulty=0.2413, weight=2.2067
neutral: count=5865.0, difficulty=0.2042, log_difficulty=0.1858, weight=1.9292
negative: count=6629.0, difficulty=0.2637, log_difficulty=0.2340, weight=2.1701

当前batch的pt分布：
positive: min=0.4653, max=0.9843, mean=0.8509
neutral: min=0.9664, max=0.9972, mean=0.9865
negative: min=0.5442, max=0.9990, mean=0.8981

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1270
焦点损失: 0.0127
边界损失: 0.1957
总损失: 0.1118
Epoch 4 [85/172] - loss: 0.1118
Epoch 4 [86/172] - loss: 0.1932
Epoch 4 [87/172] - loss: 0.0935
Epoch 4 [88/172] - loss: 0.0810
Epoch 4 [89/172] - loss: 0.0824
Epoch 4 [90/172] - loss: 0.0855, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1532
Epoch 4 [92/172] - loss: 0.1876
Epoch 4 [93/172] - loss: 0.0859
Epoch 4 [94/172] - loss: 0.0802
Epoch 4 [95/172] - loss: 0.0835
Epoch 4 [96/172] - loss: 0.0936
Epoch 4 [97/172] - loss: 0.1050
Epoch 4 [98/172] - loss: 0.1592
Epoch 4 [99/172] - loss: 0.0887
Epoch 4 [100/172] - loss: 0.0795, acc: 1.0000
Epoch 4 [101/172] - loss: 0.0942
Epoch 4 [102/172] - loss: 0.1160
Epoch 4 [103/172] - loss: 0.1506
Epoch 4 [104/172] - loss: 0.2537
Epoch 4 [105/172] - loss: 0.2494
Epoch 4 [106/172] - loss: 0.1276
Epoch 4 [107/172] - loss: 0.1376
Epoch 4 [108/172] - loss: 0.1390
Epoch 4 [109/172] - loss: 0.1374
Epoch 4 [110/172] - loss: 0.1746, acc: 0.9062
Epoch 4 [111/172] - loss: 0.0847
Epoch 4 [112/172] - loss: 0.0813
Epoch 4 [113/172] - loss: 0.0944
Epoch 4 [114/172] - loss: 0.0940
Epoch 4 [115/172] - loss: 0.1450
Epoch 4 [116/172] - loss: 0.1162
Epoch 4 [117/172] - loss: 0.0879
Epoch 4 [118/172] - loss: 0.1985
Epoch 4 [119/172] - loss: 0.0953
Epoch 4 [120/172] - loss: 0.1541, acc: 0.9688
Epoch 4 [121/172] - loss: 0.1037
Epoch 4 [122/172] - loss: 0.2050
Epoch 4 [123/172] - loss: 0.0924
Epoch 4 [124/172] - loss: 0.0841
Epoch 4 [125/172] - loss: 0.1156
Epoch 4 [126/172] - loss: 0.1898
Epoch 4 [127/172] - loss: 0.0962
Epoch 4 [128/172] - loss: 0.1038
Epoch 4 [129/172] - loss: 0.0913
Epoch 4 [130/172] - loss: 0.0820, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0857
Epoch 4 [132/172] - loss: 0.1113
Epoch 4 [133/172] - loss: 0.0917
Epoch 4 [134/172] - loss: 0.1043
Epoch 4 [135/172] - loss: 0.0959
Epoch 4 [136/172] - loss: 0.1149
Epoch 4 [137/172] - loss: 0.0967
Epoch 4 [138/172] - loss: 0.0797
Epoch 4 [139/172] - loss: 0.0890
Epoch 4 [140/172] - loss: 0.1097, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1995
Epoch 4 [142/172] - loss: 0.1130
Epoch 4 [143/172] - loss: 0.0819
Epoch 4 [144/172] - loss: 0.1383
Epoch 4 [145/172] - loss: 0.1496
Epoch 4 [146/172] - loss: 0.1542
Epoch 4 [147/172] - loss: 0.1767
Epoch 4 [148/172] - loss: 0.1023
Epoch 4 [149/172] - loss: 0.1354
Epoch 4 [150/172] - loss: 0.1249, acc: 0.9375
Epoch 4 [151/172] - loss: 0.3066
Epoch 4 [152/172] - loss: 0.0919
Epoch 4 [153/172] - loss: 0.1389
Epoch 4 [154/172] - loss: 0.1120
Epoch 4 [155/172] - loss: 0.0972
Epoch 4 [156/172] - loss: 0.1168
Epoch 4 [157/172] - loss: 0.2828
Epoch 4 [158/172] - loss: 0.1167
Epoch 4 [159/172] - loss: 0.0957
Epoch 4 [160/172] - loss: 0.1077, acc: 0.9688
Epoch 4 [161/172] - loss: 0.1136
Epoch 4 [162/172] - loss: 0.1031
Epoch 4 [163/172] - loss: 0.1210
Epoch 4 [164/172] - loss: 0.0879
Epoch 4 [165/172] - loss: 0.1482
Epoch 4 [166/172] - loss: 0.0956
Epoch 4 [167/172] - loss: 0.1197
Epoch 4 [168/172] - loss: 0.0916
Epoch 4 [169/172] - loss: 0.2052
Epoch 4 [170/172] - loss: 0.2080, acc: 0.9375
Epoch 4 [171/172] - loss: 0.0956
Epoch 4 [172/172] - loss: 0.0934

类别准确率:
positive: 0.8415 (393/467)
neutral: 0.3012 (25/83)
negative: 0.6240 (156/250)

Epoch 4/10
Train Loss: 0.1304, Train Acc: 0.9657
Val Loss: 0.7554, Val Acc: 0.7175
Epoch 5 [1/172] - loss: 0.0818, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1250
Epoch 5 [3/172] - loss: 0.0871
Epoch 5 [4/172] - loss: 0.0983
Epoch 5 [5/172] - loss: 0.0774
Epoch 5 [6/172] - loss: 0.0893
Epoch 5 [7/172] - loss: 0.0910
Epoch 5 [8/172] - loss: 0.1051
Epoch 5 [9/172] - loss: 0.1350
Epoch 5 [10/172] - loss: 0.0892, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1346
Epoch 5 [12/172] - loss: 0.0783

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2479, log_difficulty=0.2215, weight=2.1074
neutral: count=6845.0, difficulty=0.1833, log_difficulty=0.1683, weight=1.8415
negative: count=7694.0, difficulty=0.2414, log_difficulty=0.2162, weight=2.0812

当前batch的pt分布：
positive: min=0.2564, max=0.9921, mean=0.8774
neutral: min=0.9795, max=0.9991, mean=0.9927
negative: min=0.5689, max=0.9982, mean=0.8761

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1288
焦点损失: 0.0291
边界损失: 0.1833
总损失: 0.1222
Epoch 5 [13/172] - loss: 0.1222
Epoch 5 [14/172] - loss: 0.1056
Epoch 5 [15/172] - loss: 0.0783
Epoch 5 [16/172] - loss: 0.1001
Epoch 5 [17/172] - loss: 0.0941
Epoch 5 [18/172] - loss: 0.0809
Epoch 5 [19/172] - loss: 0.1337
Epoch 5 [20/172] - loss: 0.1179, acc: 0.9375
Epoch 5 [21/172] - loss: 0.1013
Epoch 5 [22/172] - loss: 0.1233
Epoch 5 [23/172] - loss: 0.1017
Epoch 5 [24/172] - loss: 0.0830
Epoch 5 [25/172] - loss: 0.0812
Epoch 5 [26/172] - loss: 0.1134
Epoch 5 [27/172] - loss: 0.0889
Epoch 5 [28/172] - loss: 0.0787
Epoch 5 [29/172] - loss: 0.0788
Epoch 5 [30/172] - loss: 0.0830, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0844
Epoch 5 [32/172] - loss: 0.0749
Epoch 5 [33/172] - loss: 0.0942
Epoch 5 [34/172] - loss: 0.0912
Epoch 5 [35/172] - loss: 0.0774
Epoch 5 [36/172] - loss: 0.0841
Epoch 5 [37/172] - loss: 0.0830
Epoch 5 [38/172] - loss: 0.0759
Epoch 5 [39/172] - loss: 0.1053
Epoch 5 [40/172] - loss: 0.1122, acc: 0.9688
Epoch 5 [41/172] - loss: 0.0839
Epoch 5 [42/172] - loss: 0.0814
Epoch 5 [43/172] - loss: 0.1814
Epoch 5 [44/172] - loss: 0.0856
Epoch 5 [45/172] - loss: 0.0747
Epoch 5 [46/172] - loss: 0.0838
Epoch 5 [47/172] - loss: 0.0799
Epoch 5 [48/172] - loss: 0.0858
Epoch 5 [49/172] - loss: 0.0812
Epoch 5 [50/172] - loss: 0.0855, acc: 1.0000
Epoch 5 [51/172] - loss: 0.0960
Epoch 5 [52/172] - loss: 0.0777
Epoch 5 [53/172] - loss: 0.1008
Epoch 5 [54/172] - loss: 0.0842
Epoch 5 [55/172] - loss: 0.0924
Epoch 5 [56/172] - loss: 0.0806
Epoch 5 [57/172] - loss: 0.0768
Epoch 5 [58/172] - loss: 0.1511
Epoch 5 [59/172] - loss: 0.1142
Epoch 5 [60/172] - loss: 0.0745, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0838
Epoch 5 [62/172] - loss: 0.0822
Epoch 5 [63/172] - loss: 0.1413
Epoch 5 [64/172] - loss: 0.1068
Epoch 5 [65/172] - loss: 0.0990
Epoch 5 [66/172] - loss: 0.0779
Epoch 5 [67/172] - loss: 0.0769
Epoch 5 [68/172] - loss: 0.0861
Epoch 5 [69/172] - loss: 0.0858
Epoch 5 [70/172] - loss: 0.0799, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0844
Epoch 5 [72/172] - loss: 0.0761
Epoch 5 [73/172] - loss: 0.0897
Epoch 5 [74/172] - loss: 0.0886
Epoch 5 [75/172] - loss: 0.0753
Epoch 5 [76/172] - loss: 0.0751
Epoch 5 [77/172] - loss: 0.0809
Epoch 5 [78/172] - loss: 0.0918
Epoch 5 [79/172] - loss: 0.0786
Epoch 5 [80/172] - loss: 0.0795, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1235
Epoch 5 [82/172] - loss: 0.1084
Epoch 5 [83/172] - loss: 0.0778
Epoch 5 [84/172] - loss: 0.0821
Epoch 5 [85/172] - loss: 0.1037
Epoch 5 [86/172] - loss: 0.0808
Epoch 5 [87/172] - loss: 0.0866
Epoch 5 [88/172] - loss: 0.0947
Epoch 5 [89/172] - loss: 0.0763
Epoch 5 [90/172] - loss: 0.0918, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0935
Epoch 5 [92/172] - loss: 0.0747
Epoch 5 [93/172] - loss: 0.0773
Epoch 5 [94/172] - loss: 0.0790
Epoch 5 [95/172] - loss: 0.0848
Epoch 5 [96/172] - loss: 0.0796
Epoch 5 [97/172] - loss: 0.1023
Epoch 5 [98/172] - loss: 0.0773
Epoch 5 [99/172] - loss: 0.2243
Epoch 5 [100/172] - loss: 0.0818, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0944
Epoch 5 [102/172] - loss: 0.0869
Epoch 5 [103/172] - loss: 0.0796
Epoch 5 [104/172] - loss: 0.1619
Epoch 5 [105/172] - loss: 0.1411
Epoch 5 [106/172] - loss: 0.0816
Epoch 5 [107/172] - loss: 0.0803
Epoch 5 [108/172] - loss: 0.1425
Epoch 5 [109/172] - loss: 0.0749
Epoch 5 [110/172] - loss: 0.0806, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0868
Epoch 5 [112/172] - loss: 0.0756

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2241, log_difficulty=0.2022, weight=2.0110
neutral: count=7825.0, difficulty=0.1655, log_difficulty=0.1532, weight=1.7658
negative: count=8780.0, difficulty=0.2200, log_difficulty=0.1988, weight=1.9941

当前batch的pt分布：
positive: min=0.1670, max=0.9930, mean=0.8765
neutral: min=0.9405, max=0.9936, mean=0.9673
negative: min=0.9919, max=0.9989, mean=0.9967

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1057
焦点损失: 0.0385
边界损失: 0.1638
总损失: 0.1206
Epoch 5 [113/172] - loss: 0.1206
Epoch 5 [114/172] - loss: 0.0941
Epoch 5 [115/172] - loss: 0.0799
Epoch 5 [116/172] - loss: 0.0757
Epoch 5 [117/172] - loss: 0.1110
Epoch 5 [118/172] - loss: 0.0780
Epoch 5 [119/172] - loss: 0.0795
Epoch 5 [120/172] - loss: 0.1285, acc: 0.9688
Epoch 5 [121/172] - loss: 0.0797
Epoch 5 [122/172] - loss: 0.0782
Epoch 5 [123/172] - loss: 0.0848
Epoch 5 [124/172] - loss: 0.0776
Epoch 5 [125/172] - loss: 0.0755
Epoch 5 [126/172] - loss: 0.0760
Epoch 5 [127/172] - loss: 0.0797
Epoch 5 [128/172] - loss: 0.0794
Epoch 5 [129/172] - loss: 0.1161
Epoch 5 [130/172] - loss: 0.0766, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0913
Epoch 5 [132/172] - loss: 0.1078
Epoch 5 [133/172] - loss: 0.1174
Epoch 5 [134/172] - loss: 0.1420
Epoch 5 [135/172] - loss: 0.0763
Epoch 5 [136/172] - loss: 0.0760
Epoch 5 [137/172] - loss: 0.0836
Epoch 5 [138/172] - loss: 0.1090
Epoch 5 [139/172] - loss: 0.2235
Epoch 5 [140/172] - loss: 0.0841, acc: 1.0000
Epoch 5 [141/172] - loss: 0.0814
Epoch 5 [142/172] - loss: 0.0787
Epoch 5 [143/172] - loss: 0.0880
Epoch 5 [144/172] - loss: 0.0764
Epoch 5 [145/172] - loss: 0.1112
Epoch 5 [146/172] - loss: 0.0854
Epoch 5 [147/172] - loss: 0.0949
Epoch 5 [148/172] - loss: 0.0758
Epoch 5 [149/172] - loss: 0.0760
Epoch 5 [150/172] - loss: 0.1588, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0796
Epoch 5 [152/172] - loss: 0.0759
Epoch 5 [153/172] - loss: 0.0752
Epoch 5 [154/172] - loss: 0.0792
Epoch 5 [155/172] - loss: 0.1201
Epoch 5 [156/172] - loss: 0.1007
Epoch 5 [157/172] - loss: 0.0823
Epoch 5 [158/172] - loss: 0.0754
Epoch 5 [159/172] - loss: 0.0730
Epoch 5 [160/172] - loss: 0.0746, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0777
Epoch 5 [162/172] - loss: 0.0836
Epoch 5 [163/172] - loss: 0.1058
Epoch 5 [164/172] - loss: 0.0740
Epoch 5 [165/172] - loss: 0.1281
Epoch 5 [166/172] - loss: 0.0851
Epoch 5 [167/172] - loss: 0.0819
Epoch 5 [168/172] - loss: 0.0776
Epoch 5 [169/172] - loss: 0.0780
Epoch 5 [170/172] - loss: 0.0873, acc: 0.9688
Epoch 5 [171/172] - loss: 0.0946
Epoch 5 [172/172] - loss: 0.0885

类别准确率:
positive: 0.8715 (407/467)
neutral: 0.3253 (27/83)
negative: 0.5760 (144/250)

Epoch 5/10
Train Loss: 0.0855, Train Acc: 0.9939
Val Loss: 0.7811, Val Acc: 0.7225
Early stopping triggered!
Best validation accuracy: 0.7362

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_081604-nud5giho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.2_Multimodal_iterations_20250118_081603
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/nud5giho
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  train_acc ▁▄▄▆▅▆▆▅▆▇▇▇█▇▇▇██▇▇▇█▇█████████▇███████
wandb: train_loss █▇▆▆▅▃▄▆▅▃▃▃▃▃▁▂▂▂▁▁▁▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂
wandb: 
wandb: Run summary:
wandb:  iteration 858
wandb:  train_acc 0.96875
wandb: train_loss 0.08731
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.2_Multimodal_iterations_20250118_081603 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/nud5giho
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_081604-nud5giho/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_082328-esu99r75
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.2_Multimodal_epochs_20250118_082328
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/esu99r75
wandb: uploading history steps 0-0, summary; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▃▅▆█
wandb:  train_acc ▁▆▇▇█
wandb: train_loss █▄▂▂▁
wandb:    val_acc ▁█▇▇█
wandb:   val_loss █▁▃▃▃
wandb: 
wandb: Run summary:
wandb:      epoch 5
wandb:  train_acc 0.99394
wandb: train_loss 0.08546
wandb:    val_acc 0.7225
wandb:   val_loss 0.78112
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.2_Multimodal_epochs_20250118_082328 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/esu99r75
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_082328-esu99r75/logs

