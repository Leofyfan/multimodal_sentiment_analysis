=== 命令 ===
python main.py --loss_type focal --alpha 0.75 --beta 0.25 --neural_init_weight 0.5 --dropout 0.3 --name loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.3 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.3
text_dim: 128
image_dim: 256
dropout: 0.3
loss_type: focal
alpha: 0.75
beta: 0.25
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6858, log_difficulty=0.5223, weight=3.6113
neutral: count=7.0, difficulty=0.6633, log_difficulty=0.5088, weight=3.5439
negative: count=13.0, difficulty=0.6655, log_difficulty=0.5101, weight=3.5506

当前batch的pt分布：
positive: min=0.1684, max=0.4073, mean=0.3142
neutral: min=0.1922, max=0.4599, mean=0.3367
negative: min=0.1766, max=0.4501, mean=0.3345

当前batch准确率：
整体准确率: 0.4062
positive 准确率: 0.2500
neutral 准确率: 0.5714
negative 准确率: 0.4615

损失分量：
基础交叉熵: 1.1498
焦点损失: 0.3891
边界损失: 0.8081
总损失: 1.2446
Epoch 1 [1/172] - loss: 1.2446, acc: 0.4062
Epoch 1 [2/172] - loss: 1.3523
Epoch 1 [3/172] - loss: 1.3964
Epoch 1 [4/172] - loss: 1.2068
Epoch 1 [5/172] - loss: 1.0341
Epoch 1 [6/172] - loss: 1.3979
Epoch 1 [7/172] - loss: 1.2504
Epoch 1 [8/172] - loss: 1.5613
Epoch 1 [9/172] - loss: 1.1610
Epoch 1 [10/172] - loss: 1.2701, acc: 0.3750
Epoch 1 [11/172] - loss: 0.9480
Epoch 1 [12/172] - loss: 0.9940
Epoch 1 [13/172] - loss: 0.9961
Epoch 1 [14/172] - loss: 1.4094
Epoch 1 [15/172] - loss: 1.2087
Epoch 1 [16/172] - loss: 0.9760
Epoch 1 [17/172] - loss: 1.1631
Epoch 1 [18/172] - loss: 1.2087
Epoch 1 [19/172] - loss: 0.8255
Epoch 1 [20/172] - loss: 0.9935, acc: 0.5000
Epoch 1 [21/172] - loss: 1.0055
Epoch 1 [22/172] - loss: 1.1480
Epoch 1 [23/172] - loss: 1.3670
Epoch 1 [24/172] - loss: 1.0412
Epoch 1 [25/172] - loss: 1.0518
Epoch 1 [26/172] - loss: 0.9624
Epoch 1 [27/172] - loss: 1.0987
Epoch 1 [28/172] - loss: 0.8065
Epoch 1 [29/172] - loss: 1.0420
Epoch 1 [30/172] - loss: 1.0982, acc: 0.5000
Epoch 1 [31/172] - loss: 1.7317
Epoch 1 [32/172] - loss: 0.7919
Epoch 1 [33/172] - loss: 1.0417
Epoch 1 [34/172] - loss: 0.8807
Epoch 1 [35/172] - loss: 1.3813
Epoch 1 [36/172] - loss: 0.8076
Epoch 1 [37/172] - loss: 1.1028
Epoch 1 [38/172] - loss: 0.9599
Epoch 1 [39/172] - loss: 0.9777
Epoch 1 [40/172] - loss: 1.1470, acc: 0.3750
Epoch 1 [41/172] - loss: 0.9932
Epoch 1 [42/172] - loss: 0.9454
Epoch 1 [43/172] - loss: 0.8575
Epoch 1 [44/172] - loss: 1.1274
Epoch 1 [45/172] - loss: 1.1504
Epoch 1 [46/172] - loss: 0.9966
Epoch 1 [47/172] - loss: 0.8630
Epoch 1 [48/172] - loss: 1.0019
Epoch 1 [49/172] - loss: 1.2564
Epoch 1 [50/172] - loss: 0.9343, acc: 0.4062
Epoch 1 [51/172] - loss: 0.7947
Epoch 1 [52/172] - loss: 1.0113
Epoch 1 [53/172] - loss: 1.0087
Epoch 1 [54/172] - loss: 0.9158
Epoch 1 [55/172] - loss: 0.6784
Epoch 1 [56/172] - loss: 0.7648
Epoch 1 [57/172] - loss: 0.9320
Epoch 1 [58/172] - loss: 0.6135
Epoch 1 [59/172] - loss: 0.9948
Epoch 1 [60/172] - loss: 0.8862, acc: 0.5625
Epoch 1 [61/172] - loss: 0.9509
Epoch 1 [62/172] - loss: 0.9482
Epoch 1 [63/172] - loss: 0.7457
Epoch 1 [64/172] - loss: 0.7232
Epoch 1 [65/172] - loss: 1.0297
Epoch 1 [66/172] - loss: 1.0450
Epoch 1 [67/172] - loss: 0.7763
Epoch 1 [68/172] - loss: 1.1812
Epoch 1 [69/172] - loss: 0.9229
Epoch 1 [70/172] - loss: 0.7883, acc: 0.5938
Epoch 1 [71/172] - loss: 0.8321
Epoch 1 [72/172] - loss: 0.9015
Epoch 1 [73/172] - loss: 0.5739
Epoch 1 [74/172] - loss: 0.6671
Epoch 1 [75/172] - loss: 0.5780
Epoch 1 [76/172] - loss: 0.9930
Epoch 1 [77/172] - loss: 0.7545
Epoch 1 [78/172] - loss: 0.9699
Epoch 1 [79/172] - loss: 0.8303
Epoch 1 [80/172] - loss: 0.5173, acc: 0.7188
Epoch 1 [81/172] - loss: 0.7875
Epoch 1 [82/172] - loss: 0.9280
Epoch 1 [83/172] - loss: 0.8231
Epoch 1 [84/172] - loss: 0.6497
Epoch 1 [85/172] - loss: 0.8900
Epoch 1 [86/172] - loss: 0.6222
Epoch 1 [87/172] - loss: 0.9509
Epoch 1 [88/172] - loss: 0.9425
Epoch 1 [89/172] - loss: 0.9583
Epoch 1 [90/172] - loss: 1.1338, acc: 0.5625
Epoch 1 [91/172] - loss: 0.6454
Epoch 1 [92/172] - loss: 0.8290
Epoch 1 [93/172] - loss: 0.8650
Epoch 1 [94/172] - loss: 0.5310
Epoch 1 [95/172] - loss: 0.7537
Epoch 1 [96/172] - loss: 0.6637
Epoch 1 [97/172] - loss: 0.8370
Epoch 1 [98/172] - loss: 0.6741
Epoch 1 [99/172] - loss: 0.8087
Epoch 1 [100/172] - loss: 0.8219, acc: 0.5625

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5978, log_difficulty=0.4686, weight=3.3432
neutral: count=983.0, difficulty=0.5760, log_difficulty=0.4549, weight=3.2743
negative: count=1119.0, difficulty=0.5738, log_difficulty=0.4535, weight=3.2675

当前batch的pt分布：
positive: min=0.1877, max=0.7632, mean=0.4661
neutral: min=0.4491, max=0.8924, mean=0.6368
negative: min=0.1551, max=0.8225, mean=0.4192

当前batch准确率：
整体准确率: 0.5938
positive 准确率: 0.6667
neutral 准确率: 1.0000
negative 准确率: 0.4375

损失分量：
基础交叉熵: 0.8557
焦点损失: 0.2582
边界损失: 0.5922
总损失: 0.7856
Epoch 1 [101/172] - loss: 0.7856
Epoch 1 [102/172] - loss: 0.6966
Epoch 1 [103/172] - loss: 0.6240
Epoch 1 [104/172] - loss: 0.4252
Epoch 1 [105/172] - loss: 1.1393
Epoch 1 [106/172] - loss: 1.0434
Epoch 1 [107/172] - loss: 0.7282
Epoch 1 [108/172] - loss: 0.7652
Epoch 1 [109/172] - loss: 0.7990
Epoch 1 [110/172] - loss: 1.0671, acc: 0.5938
Epoch 1 [111/172] - loss: 0.8325
Epoch 1 [112/172] - loss: 0.5496
Epoch 1 [113/172] - loss: 0.4358
Epoch 1 [114/172] - loss: 0.6353
Epoch 1 [115/172] - loss: 0.6337
Epoch 1 [116/172] - loss: 0.7964
Epoch 1 [117/172] - loss: 0.6611
Epoch 1 [118/172] - loss: 0.5994
Epoch 1 [119/172] - loss: 0.6641
Epoch 1 [120/172] - loss: 0.5864, acc: 0.7188
Epoch 1 [121/172] - loss: 0.4542
Epoch 1 [122/172] - loss: 0.9074
Epoch 1 [123/172] - loss: 0.4636
Epoch 1 [124/172] - loss: 0.5269
Epoch 1 [125/172] - loss: 0.6186
Epoch 1 [126/172] - loss: 0.8792
Epoch 1 [127/172] - loss: 0.6948
Epoch 1 [128/172] - loss: 0.6938
Epoch 1 [129/172] - loss: 0.7611
Epoch 1 [130/172] - loss: 0.5782, acc: 0.7500
Epoch 1 [131/172] - loss: 0.4057
Epoch 1 [132/172] - loss: 0.6343
Epoch 1 [133/172] - loss: 0.5370
Epoch 1 [134/172] - loss: 0.6613
Epoch 1 [135/172] - loss: 0.6310
Epoch 1 [136/172] - loss: 0.5610
Epoch 1 [137/172] - loss: 0.7275
Epoch 1 [138/172] - loss: 0.6409
Epoch 1 [139/172] - loss: 0.4204
Epoch 1 [140/172] - loss: 0.5403, acc: 0.7500
Epoch 1 [141/172] - loss: 0.5326
Epoch 1 [142/172] - loss: 0.6786
Epoch 1 [143/172] - loss: 0.5945
Epoch 1 [144/172] - loss: 0.4281
Epoch 1 [145/172] - loss: 0.6143
Epoch 1 [146/172] - loss: 0.8025
Epoch 1 [147/172] - loss: 0.9508
Epoch 1 [148/172] - loss: 0.7488
Epoch 1 [149/172] - loss: 0.5151
Epoch 1 [150/172] - loss: 0.8468, acc: 0.5938
Epoch 1 [151/172] - loss: 0.8139
Epoch 1 [152/172] - loss: 0.6382
Epoch 1 [153/172] - loss: 0.6213
Epoch 1 [154/172] - loss: 0.5607
Epoch 1 [155/172] - loss: 0.5469
Epoch 1 [156/172] - loss: 0.9356
Epoch 1 [157/172] - loss: 0.5122
Epoch 1 [158/172] - loss: 0.4935
Epoch 1 [159/172] - loss: 0.7982
Epoch 1 [160/172] - loss: 0.5063, acc: 0.8438
Epoch 1 [161/172] - loss: 0.5923
Epoch 1 [162/172] - loss: 0.5655
Epoch 1 [163/172] - loss: 0.4992
Epoch 1 [164/172] - loss: 0.5654
Epoch 1 [165/172] - loss: 0.4824
Epoch 1 [166/172] - loss: 0.4761
Epoch 1 [167/172] - loss: 0.3757
Epoch 1 [168/172] - loss: 0.6219
Epoch 1 [169/172] - loss: 0.3044
Epoch 1 [170/172] - loss: 0.5363, acc: 0.7188
Epoch 1 [171/172] - loss: 0.4281
Epoch 1 [172/172] - loss: 0.3916

类别准确率:
positive: 0.7045 (329/467)
neutral: 0.4578 (38/83)
negative: 0.6680 (167/250)

Epoch 1/10
Train Loss: 0.5093, Train Acc: 0.7576
Val Loss: 0.7358, Val Acc: 0.6675
Epoch 2 [1/172] - loss: 0.4472, acc: 0.8438
Epoch 2 [2/172] - loss: 0.3340
Epoch 2 [3/172] - loss: 0.3203
Epoch 2 [4/172] - loss: 0.5187
Epoch 2 [5/172] - loss: 0.6729
Epoch 2 [6/172] - loss: 0.3459
Epoch 2 [7/172] - loss: 0.3411
Epoch 2 [8/172] - loss: 0.4100
Epoch 2 [9/172] - loss: 0.3649
Epoch 2 [10/172] - loss: 0.2895, acc: 0.8438
Epoch 2 [11/172] - loss: 0.3140
Epoch 2 [12/172] - loss: 0.3010
Epoch 2 [13/172] - loss: 0.4284
Epoch 2 [14/172] - loss: 0.4181
Epoch 2 [15/172] - loss: 0.3961
Epoch 2 [16/172] - loss: 0.4546
Epoch 2 [17/172] - loss: 0.4401
Epoch 2 [18/172] - loss: 0.6150
Epoch 2 [19/172] - loss: 0.3224
Epoch 2 [20/172] - loss: 0.4672, acc: 0.8438
Epoch 2 [21/172] - loss: 0.4187
Epoch 2 [22/172] - loss: 0.3401
Epoch 2 [23/172] - loss: 0.2572
Epoch 2 [24/172] - loss: 0.8495
Epoch 2 [25/172] - loss: 0.4227
Epoch 2 [26/172] - loss: 0.2309
Epoch 2 [27/172] - loss: 0.3099
Epoch 2 [28/172] - loss: 0.3048

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5312, log_difficulty=0.4261, weight=3.1303
neutral: count=1952.0, difficulty=0.4811, log_difficulty=0.3928, weight=2.9641
negative: count=2216.0, difficulty=0.5164, log_difficulty=0.4164, weight=3.0818

当前batch的pt分布：
positive: min=0.3605, max=0.9514, mean=0.6567
neutral: min=0.2739, max=0.9853, mean=0.7000
negative: min=0.1744, max=0.9065, mean=0.5631

当前batch准确率：
整体准确率: 0.7812
positive 准确率: 0.8889
neutral 准确率: 0.8182
negative 准确率: 0.6667

损失分量：
基础交叉熵: 0.5310
焦点损失: 0.1274
边界损失: 0.3959
总损失: 0.3906
Epoch 2 [29/172] - loss: 0.3906
Epoch 2 [30/172] - loss: 0.3015, acc: 0.9375
Epoch 2 [31/172] - loss: 0.4650
Epoch 2 [32/172] - loss: 0.3435
Epoch 2 [33/172] - loss: 0.3484
Epoch 2 [34/172] - loss: 0.4427
Epoch 2 [35/172] - loss: 0.2698
Epoch 2 [36/172] - loss: 0.5313
Epoch 2 [37/172] - loss: 0.2881
Epoch 2 [38/172] - loss: 0.3939
Epoch 2 [39/172] - loss: 0.6024
Epoch 2 [40/172] - loss: 0.5637, acc: 0.6562
Epoch 2 [41/172] - loss: 0.3698
Epoch 2 [42/172] - loss: 0.2523
Epoch 2 [43/172] - loss: 0.3199
Epoch 2 [44/172] - loss: 0.6383
Epoch 2 [45/172] - loss: 0.3334
Epoch 2 [46/172] - loss: 0.2811
Epoch 2 [47/172] - loss: 0.3515
Epoch 2 [48/172] - loss: 0.4740
Epoch 2 [49/172] - loss: 0.3285
Epoch 2 [50/172] - loss: 0.3588, acc: 0.8125
Epoch 2 [51/172] - loss: 0.5043
Epoch 2 [52/172] - loss: 0.2996
Epoch 2 [53/172] - loss: 0.3173
Epoch 2 [54/172] - loss: 0.3307
Epoch 2 [55/172] - loss: 0.3512
Epoch 2 [56/172] - loss: 0.2348
Epoch 2 [57/172] - loss: 0.2985
Epoch 2 [58/172] - loss: 0.4013
Epoch 2 [59/172] - loss: 0.3763
Epoch 2 [60/172] - loss: 0.3176, acc: 0.9062
Epoch 2 [61/172] - loss: 0.2551
Epoch 2 [62/172] - loss: 0.2720
Epoch 2 [63/172] - loss: 0.3722
Epoch 2 [64/172] - loss: 0.6040
Epoch 2 [65/172] - loss: 0.3863
Epoch 2 [66/172] - loss: 0.3518
Epoch 2 [67/172] - loss: 0.2117
Epoch 2 [68/172] - loss: 0.3189
Epoch 2 [69/172] - loss: 0.2572
Epoch 2 [70/172] - loss: 0.4280, acc: 0.7812
Epoch 2 [71/172] - loss: 0.4671
Epoch 2 [72/172] - loss: 0.3276
Epoch 2 [73/172] - loss: 0.1638
Epoch 2 [74/172] - loss: 0.2080
Epoch 2 [75/172] - loss: 0.3134
Epoch 2 [76/172] - loss: 0.3564
Epoch 2 [77/172] - loss: 0.2726
Epoch 2 [78/172] - loss: 0.2584
Epoch 2 [79/172] - loss: 0.3105
Epoch 2 [80/172] - loss: 0.2189, acc: 0.8750
Epoch 2 [81/172] - loss: 0.3182
Epoch 2 [82/172] - loss: 0.3366
Epoch 2 [83/172] - loss: 0.2750
Epoch 2 [84/172] - loss: 0.4431
Epoch 2 [85/172] - loss: 0.3096
Epoch 2 [86/172] - loss: 0.2898
Epoch 2 [87/172] - loss: 0.5170
Epoch 2 [88/172] - loss: 0.4013
Epoch 2 [89/172] - loss: 0.1766
Epoch 2 [90/172] - loss: 0.4250, acc: 0.7188
Epoch 2 [91/172] - loss: 0.1207
Epoch 2 [92/172] - loss: 0.3210
Epoch 2 [93/172] - loss: 0.4111
Epoch 2 [94/172] - loss: 0.1974
Epoch 2 [95/172] - loss: 0.4229
Epoch 2 [96/172] - loss: 0.1810
Epoch 2 [97/172] - loss: 0.2223
Epoch 2 [98/172] - loss: 0.2338
Epoch 2 [99/172] - loss: 0.2094
Epoch 2 [100/172] - loss: 0.3655, acc: 0.8750
Epoch 2 [101/172] - loss: 0.1755
Epoch 2 [102/172] - loss: 0.3042
Epoch 2 [103/172] - loss: 0.2787
Epoch 2 [104/172] - loss: 0.4628
Epoch 2 [105/172] - loss: 0.2760
Epoch 2 [106/172] - loss: 0.4396
Epoch 2 [107/172] - loss: 0.1966
Epoch 2 [108/172] - loss: 0.6044
Epoch 2 [109/172] - loss: 0.2501
Epoch 2 [110/172] - loss: 0.3649, acc: 0.8438
Epoch 2 [111/172] - loss: 0.1768
Epoch 2 [112/172] - loss: 0.3106
Epoch 2 [113/172] - loss: 0.1969
Epoch 2 [114/172] - loss: 0.2717
Epoch 2 [115/172] - loss: 0.2185
Epoch 2 [116/172] - loss: 0.2450
Epoch 2 [117/172] - loss: 0.5374
Epoch 2 [118/172] - loss: 0.1619
Epoch 2 [119/172] - loss: 0.2869
Epoch 2 [120/172] - loss: 0.2335, acc: 0.9375
Epoch 2 [121/172] - loss: 0.2442
Epoch 2 [122/172] - loss: 0.4733
Epoch 2 [123/172] - loss: 0.3034
Epoch 2 [124/172] - loss: 0.2696
Epoch 2 [125/172] - loss: 0.2075
Epoch 2 [126/172] - loss: 0.2108
Epoch 2 [127/172] - loss: 0.2276
Epoch 2 [128/172] - loss: 0.2967

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4744, log_difficulty=0.3883, weight=2.9414
neutral: count=2949.0, difficulty=0.3995, log_difficulty=0.3361, weight=2.6804
negative: count=3294.0, difficulty=0.4648, log_difficulty=0.3817, weight=2.9085

当前batch的pt分布：
positive: min=0.4343, max=0.9094, mean=0.7769
neutral: min=0.5874, max=0.9471, mean=0.8398
negative: min=0.0877, max=0.9180, mean=0.6521

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.3368
焦点损失: 0.0776
边界损失: 0.2988
总损失: 0.2438
Epoch 2 [129/172] - loss: 0.2438
Epoch 2 [130/172] - loss: 0.2928, acc: 0.8125
Epoch 2 [131/172] - loss: 0.3131
Epoch 2 [132/172] - loss: 0.3223
Epoch 2 [133/172] - loss: 0.1757
Epoch 2 [134/172] - loss: 0.4245
Epoch 2 [135/172] - loss: 0.5293
Epoch 2 [136/172] - loss: 0.1925
Epoch 2 [137/172] - loss: 0.2126
Epoch 2 [138/172] - loss: 0.2384
Epoch 2 [139/172] - loss: 0.3797
Epoch 2 [140/172] - loss: 0.3634, acc: 0.8125
Epoch 2 [141/172] - loss: 0.3651
Epoch 2 [142/172] - loss: 0.1986
Epoch 2 [143/172] - loss: 0.1722
Epoch 2 [144/172] - loss: 0.1817
Epoch 2 [145/172] - loss: 0.6196
Epoch 2 [146/172] - loss: 0.1512
Epoch 2 [147/172] - loss: 0.2017
Epoch 2 [148/172] - loss: 0.3025
Epoch 2 [149/172] - loss: 0.1851
Epoch 2 [150/172] - loss: 0.1935, acc: 0.9062
Epoch 2 [151/172] - loss: 0.2686
Epoch 2 [152/172] - loss: 0.2508
Epoch 2 [153/172] - loss: 0.2429
Epoch 2 [154/172] - loss: 0.1804
Epoch 2 [155/172] - loss: 0.3653
Epoch 2 [156/172] - loss: 0.1986
Epoch 2 [157/172] - loss: 0.1519
Epoch 2 [158/172] - loss: 0.2490
Epoch 2 [159/172] - loss: 0.4015
Epoch 2 [160/172] - loss: 0.1330, acc: 0.9375
Epoch 2 [161/172] - loss: 0.2367
Epoch 2 [162/172] - loss: 0.1959
Epoch 2 [163/172] - loss: 0.3959
Epoch 2 [164/172] - loss: 0.3865
Epoch 2 [165/172] - loss: 0.2569
Epoch 2 [166/172] - loss: 0.2940
Epoch 2 [167/172] - loss: 0.3328
Epoch 2 [168/172] - loss: 0.2269
Epoch 2 [169/172] - loss: 0.2116
Epoch 2 [170/172] - loss: 0.2380, acc: 0.8438
Epoch 2 [171/172] - loss: 0.4535
Epoch 2 [172/172] - loss: 0.6374

类别准确率:
positive: 0.8287 (387/467)
neutral: 0.3133 (26/83)
negative: 0.6120 (153/250)

Epoch 2/10
Train Loss: 0.3001, Train Acc: 0.8687
Val Loss: 0.7313, Val Acc: 0.7075
Epoch 3 [1/172] - loss: 0.1428, acc: 0.9375
Epoch 3 [2/172] - loss: 0.1948
Epoch 3 [3/172] - loss: 0.0817
Epoch 3 [4/172] - loss: 0.1454
Epoch 3 [5/172] - loss: 0.3305
Epoch 3 [6/172] - loss: 0.2213
Epoch 3 [7/172] - loss: 0.1000
Epoch 3 [8/172] - loss: 0.1353
Epoch 3 [9/172] - loss: 0.1982
Epoch 3 [10/172] - loss: 0.2105, acc: 0.9062
Epoch 3 [11/172] - loss: 0.1152
Epoch 3 [12/172] - loss: 0.0969
Epoch 3 [13/172] - loss: 0.1152
Epoch 3 [14/172] - loss: 0.1647
Epoch 3 [15/172] - loss: 0.1225
Epoch 3 [16/172] - loss: 0.2267
Epoch 3 [17/172] - loss: 0.1839
Epoch 3 [18/172] - loss: 0.1503
Epoch 3 [19/172] - loss: 0.1227
Epoch 3 [20/172] - loss: 0.1083, acc: 1.0000
Epoch 3 [21/172] - loss: 0.2063
Epoch 3 [22/172] - loss: 0.2893
Epoch 3 [23/172] - loss: 0.1088
Epoch 3 [24/172] - loss: 0.1367
Epoch 3 [25/172] - loss: 0.1363
Epoch 3 [26/172] - loss: 0.0986
Epoch 3 [27/172] - loss: 0.1607
Epoch 3 [28/172] - loss: 0.1576
Epoch 3 [29/172] - loss: 0.1304
Epoch 3 [30/172] - loss: 0.3103, acc: 0.8750
Epoch 3 [31/172] - loss: 0.0814
Epoch 3 [32/172] - loss: 0.1023
Epoch 3 [33/172] - loss: 0.1258
Epoch 3 [34/172] - loss: 0.1586
Epoch 3 [35/172] - loss: 0.1705
Epoch 3 [36/172] - loss: 0.1495
Epoch 3 [37/172] - loss: 0.0928
Epoch 3 [38/172] - loss: 0.1971
Epoch 3 [39/172] - loss: 0.0890
Epoch 3 [40/172] - loss: 0.1141, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1266
Epoch 3 [42/172] - loss: 0.1557
Epoch 3 [43/172] - loss: 0.1294
Epoch 3 [44/172] - loss: 0.1270
Epoch 3 [45/172] - loss: 0.1243
Epoch 3 [46/172] - loss: 0.1235
Epoch 3 [47/172] - loss: 0.0565
Epoch 3 [48/172] - loss: 0.1651
Epoch 3 [49/172] - loss: 0.0837
Epoch 3 [50/172] - loss: 0.1108, acc: 0.9375
Epoch 3 [51/172] - loss: 0.2562
Epoch 3 [52/172] - loss: 0.2266
Epoch 3 [53/172] - loss: 0.1029
Epoch 3 [54/172] - loss: 0.2487
Epoch 3 [55/172] - loss: 0.1501
Epoch 3 [56/172] - loss: 0.0902

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.4222, log_difficulty=0.3522, weight=2.7612
neutral: count=3923.0, difficulty=0.3444, log_difficulty=0.2959, weight=2.4797
negative: count=4382.0, difficulty=0.4175, log_difficulty=0.3489, weight=2.7443

当前batch的pt分布：
positive: min=0.4771, max=0.9821, mean=0.8164
neutral: min=0.2620, max=0.9540, mean=0.7376
negative: min=0.9094, max=0.9858, mean=0.9516

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9091
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2653
焦点损失: 0.0471
边界损失: 0.2634
总损失: 0.1552
Epoch 3 [57/172] - loss: 0.1552
Epoch 3 [58/172] - loss: 0.1061
Epoch 3 [59/172] - loss: 0.1199
Epoch 3 [60/172] - loss: 0.0980, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1326
Epoch 3 [62/172] - loss: 0.1044
Epoch 3 [63/172] - loss: 0.0747
Epoch 3 [64/172] - loss: 0.1626
Epoch 3 [65/172] - loss: 0.0844
Epoch 3 [66/172] - loss: 0.1624
Epoch 3 [67/172] - loss: 0.0820
Epoch 3 [68/172] - loss: 0.0675
Epoch 3 [69/172] - loss: 0.2202
Epoch 3 [70/172] - loss: 0.0680, acc: 0.9688
Epoch 3 [71/172] - loss: 0.1233
Epoch 3 [72/172] - loss: 0.1315
Epoch 3 [73/172] - loss: 0.1010
Epoch 3 [74/172] - loss: 0.1035
Epoch 3 [75/172] - loss: 0.1481
Epoch 3 [76/172] - loss: 0.0706
Epoch 3 [77/172] - loss: 0.0986
Epoch 3 [78/172] - loss: 0.3545
Epoch 3 [79/172] - loss: 0.0833
Epoch 3 [80/172] - loss: 0.4093, acc: 0.8125
Epoch 3 [81/172] - loss: 0.1010
Epoch 3 [82/172] - loss: 0.2736
Epoch 3 [83/172] - loss: 0.1193
Epoch 3 [84/172] - loss: 0.0731
Epoch 3 [85/172] - loss: 0.0899
Epoch 3 [86/172] - loss: 0.0791
Epoch 3 [87/172] - loss: 0.3000
Epoch 3 [88/172] - loss: 0.1590
Epoch 3 [89/172] - loss: 0.0976
Epoch 3 [90/172] - loss: 0.1089, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1322
Epoch 3 [92/172] - loss: 0.1514
Epoch 3 [93/172] - loss: 0.2878
Epoch 3 [94/172] - loss: 0.1768
Epoch 3 [95/172] - loss: 0.1393
Epoch 3 [96/172] - loss: 0.1829
Epoch 3 [97/172] - loss: 0.0680
Epoch 3 [98/172] - loss: 0.1042
Epoch 3 [99/172] - loss: 0.0963
Epoch 3 [100/172] - loss: 0.1322, acc: 0.9375
Epoch 3 [101/172] - loss: 0.2275
Epoch 3 [102/172] - loss: 0.0582
Epoch 3 [103/172] - loss: 0.3327
Epoch 3 [104/172] - loss: 0.1600
Epoch 3 [105/172] - loss: 0.0946
Epoch 3 [106/172] - loss: 0.1041
Epoch 3 [107/172] - loss: 0.0928
Epoch 3 [108/172] - loss: 0.0856
Epoch 3 [109/172] - loss: 0.1199
Epoch 3 [110/172] - loss: 0.1740, acc: 0.9062
Epoch 3 [111/172] - loss: 0.1448
Epoch 3 [112/172] - loss: 0.0877
Epoch 3 [113/172] - loss: 0.0938
Epoch 3 [114/172] - loss: 0.1335
Epoch 3 [115/172] - loss: 0.1996
Epoch 3 [116/172] - loss: 0.1378
Epoch 3 [117/172] - loss: 0.1963
Epoch 3 [118/172] - loss: 0.1460
Epoch 3 [119/172] - loss: 0.1087
Epoch 3 [120/172] - loss: 0.2719, acc: 0.9062
Epoch 3 [121/172] - loss: 0.1028
Epoch 3 [122/172] - loss: 0.0967
Epoch 3 [123/172] - loss: 0.1495
Epoch 3 [124/172] - loss: 0.1043
Epoch 3 [125/172] - loss: 0.0960
Epoch 3 [126/172] - loss: 0.2271
Epoch 3 [127/172] - loss: 0.1023
Epoch 3 [128/172] - loss: 0.0771
Epoch 3 [129/172] - loss: 0.0938
Epoch 3 [130/172] - loss: 0.1004, acc: 0.9375
Epoch 3 [131/172] - loss: 0.1119
Epoch 3 [132/172] - loss: 0.0720
Epoch 3 [133/172] - loss: 0.0938
Epoch 3 [134/172] - loss: 0.0656
Epoch 3 [135/172] - loss: 0.1581
Epoch 3 [136/172] - loss: 0.1173
Epoch 3 [137/172] - loss: 0.0982
Epoch 3 [138/172] - loss: 0.1156
Epoch 3 [139/172] - loss: 0.1336
Epoch 3 [140/172] - loss: 0.1632, acc: 0.9375
Epoch 3 [141/172] - loss: 0.1344
Epoch 3 [142/172] - loss: 0.1697
Epoch 3 [143/172] - loss: 0.0722
Epoch 3 [144/172] - loss: 0.2748
Epoch 3 [145/172] - loss: 0.0996
Epoch 3 [146/172] - loss: 0.1617
Epoch 3 [147/172] - loss: 0.0698
Epoch 3 [148/172] - loss: 0.1226
Epoch 3 [149/172] - loss: 0.1683
Epoch 3 [150/172] - loss: 0.2355, acc: 0.8438
Epoch 3 [151/172] - loss: 0.1461
Epoch 3 [152/172] - loss: 0.2000
Epoch 3 [153/172] - loss: 0.1851
Epoch 3 [154/172] - loss: 0.2275
Epoch 3 [155/172] - loss: 0.0539
Epoch 3 [156/172] - loss: 0.1424

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3764, log_difficulty=0.3195, weight=2.5974
neutral: count=4903.0, difficulty=0.2995, log_difficulty=0.2620, weight=2.3099
negative: count=5500.0, difficulty=0.3769, log_difficulty=0.3198, weight=2.5992

当前batch的pt分布：
positive: min=0.5057, max=0.9900, mean=0.8083
neutral: min=0.7482, max=0.9892, mean=0.9044
negative: min=0.4523, max=0.9664, mean=0.7949

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1972
焦点损失: 0.0175
边界损失: 0.2434
总损失: 0.0949
Epoch 3 [157/172] - loss: 0.0949
Epoch 3 [158/172] - loss: 0.3463
Epoch 3 [159/172] - loss: 0.0911
Epoch 3 [160/172] - loss: 0.2938, acc: 0.9062
Epoch 3 [161/172] - loss: 0.1756
Epoch 3 [162/172] - loss: 0.1119
Epoch 3 [163/172] - loss: 0.0866
Epoch 3 [164/172] - loss: 0.0688
Epoch 3 [165/172] - loss: 0.0715
Epoch 3 [166/172] - loss: 0.0802
Epoch 3 [167/172] - loss: 0.1374
Epoch 3 [168/172] - loss: 0.0804
Epoch 3 [169/172] - loss: 0.0567
Epoch 3 [170/172] - loss: 0.1838, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1267
Epoch 3 [172/172] - loss: 0.0902

类别准确率:
positive: 0.8801 (411/467)
neutral: 0.2530 (21/83)
negative: 0.5760 (144/250)

Epoch 3/10
Train Loss: 0.1310, Train Acc: 0.9596
Val Loss: 0.7540, Val Acc: 0.7200
Epoch 4 [1/172] - loss: 0.0728, acc: 0.9688
Epoch 4 [2/172] - loss: 0.1221
Epoch 4 [3/172] - loss: 0.0685
Epoch 4 [4/172] - loss: 0.1042
Epoch 4 [5/172] - loss: 0.0706
Epoch 4 [6/172] - loss: 0.0726
Epoch 4 [7/172] - loss: 0.0953
Epoch 4 [8/172] - loss: 0.0601
Epoch 4 [9/172] - loss: 0.2128
Epoch 4 [10/172] - loss: 0.1136, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0563
Epoch 4 [12/172] - loss: 0.0660
Epoch 4 [13/172] - loss: 0.1093
Epoch 4 [14/172] - loss: 0.1292
Epoch 4 [15/172] - loss: 0.0576
Epoch 4 [16/172] - loss: 0.0775
Epoch 4 [17/172] - loss: 0.0765
Epoch 4 [18/172] - loss: 0.0708
Epoch 4 [19/172] - loss: 0.0602
Epoch 4 [20/172] - loss: 0.0712, acc: 0.9688
Epoch 4 [21/172] - loss: 0.0967
Epoch 4 [22/172] - loss: 0.0505
Epoch 4 [23/172] - loss: 0.1456
Epoch 4 [24/172] - loss: 0.0633
Epoch 4 [25/172] - loss: 0.0579
Epoch 4 [26/172] - loss: 0.3612
Epoch 4 [27/172] - loss: 0.0554
Epoch 4 [28/172] - loss: 0.1439
Epoch 4 [29/172] - loss: 0.1611
Epoch 4 [30/172] - loss: 0.0794, acc: 0.9688
Epoch 4 [31/172] - loss: 0.0863
Epoch 4 [32/172] - loss: 0.0795
Epoch 4 [33/172] - loss: 0.0750
Epoch 4 [34/172] - loss: 0.0622
Epoch 4 [35/172] - loss: 0.1501
Epoch 4 [36/172] - loss: 0.0641
Epoch 4 [37/172] - loss: 0.0448
Epoch 4 [38/172] - loss: 0.0486
Epoch 4 [39/172] - loss: 0.1406
Epoch 4 [40/172] - loss: 0.1390, acc: 0.9375
Epoch 4 [41/172] - loss: 0.1100
Epoch 4 [42/172] - loss: 0.1910
Epoch 4 [43/172] - loss: 0.1113
Epoch 4 [44/172] - loss: 0.0867
Epoch 4 [45/172] - loss: 0.0766
Epoch 4 [46/172] - loss: 0.0547
Epoch 4 [47/172] - loss: 0.0701
Epoch 4 [48/172] - loss: 0.0576
Epoch 4 [49/172] - loss: 0.0907
Epoch 4 [50/172] - loss: 0.1188, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0653
Epoch 4 [52/172] - loss: 0.0858
Epoch 4 [53/172] - loss: 0.0715
Epoch 4 [54/172] - loss: 0.0987
Epoch 4 [55/172] - loss: 0.1688
Epoch 4 [56/172] - loss: 0.0633
Epoch 4 [57/172] - loss: 0.0524
Epoch 4 [58/172] - loss: 0.0557
Epoch 4 [59/172] - loss: 0.0576
Epoch 4 [60/172] - loss: 0.0559, acc: 1.0000
Epoch 4 [61/172] - loss: 0.0844
Epoch 4 [62/172] - loss: 0.0726
Epoch 4 [63/172] - loss: 0.0754
Epoch 4 [64/172] - loss: 0.0549
Epoch 4 [65/172] - loss: 0.0916
Epoch 4 [66/172] - loss: 0.0761
Epoch 4 [67/172] - loss: 0.0644
Epoch 4 [68/172] - loss: 0.0788
Epoch 4 [69/172] - loss: 0.0818
Epoch 4 [70/172] - loss: 0.0713, acc: 0.9688
Epoch 4 [71/172] - loss: 0.0569
Epoch 4 [72/172] - loss: 0.0575
Epoch 4 [73/172] - loss: 0.0529
Epoch 4 [74/172] - loss: 0.1764
Epoch 4 [75/172] - loss: 0.0599
Epoch 4 [76/172] - loss: 0.0465
Epoch 4 [77/172] - loss: 0.0668
Epoch 4 [78/172] - loss: 0.0594
Epoch 4 [79/172] - loss: 0.0486
Epoch 4 [80/172] - loss: 0.0551, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1258
Epoch 4 [82/172] - loss: 0.0600
Epoch 4 [83/172] - loss: 0.0621
Epoch 4 [84/172] - loss: 0.0682

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3379, log_difficulty=0.2911, weight=2.4556
neutral: count=5865.0, difficulty=0.2664, log_difficulty=0.2362, weight=2.1809
negative: count=6629.0, difficulty=0.3408, log_difficulty=0.2933, weight=2.4664

当前batch的pt分布：
positive: min=0.6109, max=0.9785, mean=0.8327
neutral: min=0.7467, max=0.9946, mean=0.9437
negative: min=0.7091, max=0.9891, mean=0.9187

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1342
焦点损失: 0.0051
边界损失: 0.2067
总损失: 0.0610
Epoch 4 [85/172] - loss: 0.0610
Epoch 4 [86/172] - loss: 0.1047
Epoch 4 [87/172] - loss: 0.0711
Epoch 4 [88/172] - loss: 0.0489
Epoch 4 [89/172] - loss: 0.0491
Epoch 4 [90/172] - loss: 0.1103, acc: 0.9375
Epoch 4 [91/172] - loss: 0.1614
Epoch 4 [92/172] - loss: 0.1202
Epoch 4 [93/172] - loss: 0.0502
Epoch 4 [94/172] - loss: 0.0435
Epoch 4 [95/172] - loss: 0.0857
Epoch 4 [96/172] - loss: 0.1123
Epoch 4 [97/172] - loss: 0.1969
Epoch 4 [98/172] - loss: 0.0537
Epoch 4 [99/172] - loss: 0.1220
Epoch 4 [100/172] - loss: 0.0696, acc: 1.0000
Epoch 4 [101/172] - loss: 0.0748
Epoch 4 [102/172] - loss: 0.0756
Epoch 4 [103/172] - loss: 0.1164
Epoch 4 [104/172] - loss: 0.0578
Epoch 4 [105/172] - loss: 0.2135
Epoch 4 [106/172] - loss: 0.0578
Epoch 4 [107/172] - loss: 0.0630
Epoch 4 [108/172] - loss: 0.1276
Epoch 4 [109/172] - loss: 0.0874
Epoch 4 [110/172] - loss: 0.1904, acc: 0.8750
Epoch 4 [111/172] - loss: 0.0804
Epoch 4 [112/172] - loss: 0.0474
Epoch 4 [113/172] - loss: 0.0603
Epoch 4 [114/172] - loss: 0.1358
Epoch 4 [115/172] - loss: 0.1087
Epoch 4 [116/172] - loss: 0.0758
Epoch 4 [117/172] - loss: 0.0510
Epoch 4 [118/172] - loss: 0.0820
Epoch 4 [119/172] - loss: 0.0947
Epoch 4 [120/172] - loss: 0.0636, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1190
Epoch 4 [122/172] - loss: 0.1128
Epoch 4 [123/172] - loss: 0.0526
Epoch 4 [124/172] - loss: 0.0506
Epoch 4 [125/172] - loss: 0.0991
Epoch 4 [126/172] - loss: 0.2566
Epoch 4 [127/172] - loss: 0.1656
Epoch 4 [128/172] - loss: 0.0560
Epoch 4 [129/172] - loss: 0.0564
Epoch 4 [130/172] - loss: 0.0607, acc: 0.9688
Epoch 4 [131/172] - loss: 0.0469
Epoch 4 [132/172] - loss: 0.0789
Epoch 4 [133/172] - loss: 0.0661
Epoch 4 [134/172] - loss: 0.0606
Epoch 4 [135/172] - loss: 0.0668
Epoch 4 [136/172] - loss: 0.0723
Epoch 4 [137/172] - loss: 0.0823
Epoch 4 [138/172] - loss: 0.0514
Epoch 4 [139/172] - loss: 0.0505
Epoch 4 [140/172] - loss: 0.0896, acc: 0.9688
Epoch 4 [141/172] - loss: 0.2156
Epoch 4 [142/172] - loss: 0.0633
Epoch 4 [143/172] - loss: 0.1250
Epoch 4 [144/172] - loss: 0.1108
Epoch 4 [145/172] - loss: 0.1422
Epoch 4 [146/172] - loss: 0.1448
Epoch 4 [147/172] - loss: 0.0669
Epoch 4 [148/172] - loss: 0.1599
Epoch 4 [149/172] - loss: 0.0727
Epoch 4 [150/172] - loss: 0.1804, acc: 0.9062
Epoch 4 [151/172] - loss: 0.1661
Epoch 4 [152/172] - loss: 0.0576
Epoch 4 [153/172] - loss: 0.0481
Epoch 4 [154/172] - loss: 0.1274
Epoch 4 [155/172] - loss: 0.0579
Epoch 4 [156/172] - loss: 0.1061
Epoch 4 [157/172] - loss: 0.2599
Epoch 4 [158/172] - loss: 0.0632
Epoch 4 [159/172] - loss: 0.0713
Epoch 4 [160/172] - loss: 0.0616, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1553
Epoch 4 [162/172] - loss: 0.0848
Epoch 4 [163/172] - loss: 0.0996
Epoch 4 [164/172] - loss: 0.0663
Epoch 4 [165/172] - loss: 0.1480
Epoch 4 [166/172] - loss: 0.0840
Epoch 4 [167/172] - loss: 0.0821
Epoch 4 [168/172] - loss: 0.0512
Epoch 4 [169/172] - loss: 0.3199
Epoch 4 [170/172] - loss: 0.1470, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0886
Epoch 4 [172/172] - loss: 0.0591

类别准确率:
positive: 0.8544 (399/467)
neutral: 0.3012 (25/83)
negative: 0.5840 (146/250)

Epoch 4/10
Train Loss: 0.1151, Train Acc: 0.9616
Val Loss: 0.7493, Val Acc: 0.7125
Epoch 5 [1/172] - loss: 0.0530, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1064
Epoch 5 [3/172] - loss: 0.0545
Epoch 5 [4/172] - loss: 0.0714
Epoch 5 [5/172] - loss: 0.0501
Epoch 5 [6/172] - loss: 0.0516
Epoch 5 [7/172] - loss: 0.0614
Epoch 5 [8/172] - loss: 0.0599
Epoch 5 [9/172] - loss: 0.1176
Epoch 5 [10/172] - loss: 0.0485, acc: 1.0000
Epoch 5 [11/172] - loss: 0.0671
Epoch 5 [12/172] - loss: 0.0666

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.3078, log_difficulty=0.2683, weight=2.3417
neutral: count=6845.0, difficulty=0.2423, log_difficulty=0.2169, weight=2.0847
negative: count=7694.0, difficulty=0.3118, log_difficulty=0.2714, weight=2.3571

当前batch的pt分布：
positive: min=0.6476, max=0.9762, mean=0.8586
neutral: min=0.9683, max=0.9947, mean=0.9827
negative: min=0.7511, max=0.9960, mean=0.8775

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1191
焦点损失: 0.0031
边界损失: 0.1991
总损失: 0.0553
Epoch 5 [13/172] - loss: 0.0553
Epoch 5 [14/172] - loss: 0.0682
Epoch 5 [15/172] - loss: 0.0533
Epoch 5 [16/172] - loss: 0.0535
Epoch 5 [17/172] - loss: 0.0720
Epoch 5 [18/172] - loss: 0.0569
Epoch 5 [19/172] - loss: 0.1166
Epoch 5 [20/172] - loss: 0.0943, acc: 0.9375
Epoch 5 [21/172] - loss: 0.1451
Epoch 5 [22/172] - loss: 0.1344
Epoch 5 [23/172] - loss: 0.0472
Epoch 5 [24/172] - loss: 0.0628
Epoch 5 [25/172] - loss: 0.0475
Epoch 5 [26/172] - loss: 0.0883
Epoch 5 [27/172] - loss: 0.0617
Epoch 5 [28/172] - loss: 0.0512
Epoch 5 [29/172] - loss: 0.0759
Epoch 5 [30/172] - loss: 0.1463, acc: 0.9375
Epoch 5 [31/172] - loss: 0.0462
Epoch 5 [32/172] - loss: 0.0536
Epoch 5 [33/172] - loss: 0.0477
Epoch 5 [34/172] - loss: 0.0568
Epoch 5 [35/172] - loss: 0.0443
Epoch 5 [36/172] - loss: 0.0485
Epoch 5 [37/172] - loss: 0.0614
Epoch 5 [38/172] - loss: 0.0596
Epoch 5 [39/172] - loss: 0.2192
Epoch 5 [40/172] - loss: 0.0690, acc: 0.9688
Epoch 5 [41/172] - loss: 0.0611
Epoch 5 [42/172] - loss: 0.0695
Epoch 5 [43/172] - loss: 0.1363
Epoch 5 [44/172] - loss: 0.0887
Epoch 5 [45/172] - loss: 0.2014
Epoch 5 [46/172] - loss: 0.1327
Epoch 5 [47/172] - loss: 0.0530
Epoch 5 [48/172] - loss: 0.0666
Epoch 5 [49/172] - loss: 0.0647
Epoch 5 [50/172] - loss: 0.0761, acc: 1.0000
Epoch 5 [51/172] - loss: 0.0633
Epoch 5 [52/172] - loss: 0.0779
Epoch 5 [53/172] - loss: 0.1241
Epoch 5 [54/172] - loss: 0.1086
Epoch 5 [55/172] - loss: 0.1290
Epoch 5 [56/172] - loss: 0.0705
Epoch 5 [57/172] - loss: 0.0527
Epoch 5 [58/172] - loss: 0.0597
Epoch 5 [59/172] - loss: 0.1418
Epoch 5 [60/172] - loss: 0.0508, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0602
Epoch 5 [62/172] - loss: 0.0757
Epoch 5 [63/172] - loss: 0.1134
Epoch 5 [64/172] - loss: 0.0518
Epoch 5 [65/172] - loss: 0.0552
Epoch 5 [66/172] - loss: 0.0607
Epoch 5 [67/172] - loss: 0.0475
Epoch 5 [68/172] - loss: 0.0730
Epoch 5 [69/172] - loss: 0.0566
Epoch 5 [70/172] - loss: 0.0479, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0688
Epoch 5 [72/172] - loss: 0.0739
Epoch 5 [73/172] - loss: 0.0528
Epoch 5 [74/172] - loss: 0.0755
Epoch 5 [75/172] - loss: 0.0433
Epoch 5 [76/172] - loss: 0.0525
Epoch 5 [77/172] - loss: 0.0474
Epoch 5 [78/172] - loss: 0.0678
Epoch 5 [79/172] - loss: 0.0683
Epoch 5 [80/172] - loss: 0.0540, acc: 1.0000
Epoch 5 [81/172] - loss: 0.0814
Epoch 5 [82/172] - loss: 0.0795
Epoch 5 [83/172] - loss: 0.0536
Epoch 5 [84/172] - loss: 0.0450
Epoch 5 [85/172] - loss: 0.1446
Epoch 5 [86/172] - loss: 0.0553
Epoch 5 [87/172] - loss: 0.0805
Epoch 5 [88/172] - loss: 0.0604
Epoch 5 [89/172] - loss: 0.0432
Epoch 5 [90/172] - loss: 0.1870, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0599
Epoch 5 [92/172] - loss: 0.0500
Epoch 5 [93/172] - loss: 0.1943
Epoch 5 [94/172] - loss: 0.0470
Epoch 5 [95/172] - loss: 0.1450
Epoch 5 [96/172] - loss: 0.0461
Epoch 5 [97/172] - loss: 0.0508
Epoch 5 [98/172] - loss: 0.0793
Epoch 5 [99/172] - loss: 0.1758
Epoch 5 [100/172] - loss: 0.1010, acc: 0.9375
Epoch 5 [101/172] - loss: 0.0527
Epoch 5 [102/172] - loss: 0.0484
Epoch 5 [103/172] - loss: 0.0819
Epoch 5 [104/172] - loss: 0.1180
Epoch 5 [105/172] - loss: 0.2611
Epoch 5 [106/172] - loss: 0.0739
Epoch 5 [107/172] - loss: 0.0531
Epoch 5 [108/172] - loss: 0.0851
Epoch 5 [109/172] - loss: 0.0726
Epoch 5 [110/172] - loss: 0.0480, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0468
Epoch 5 [112/172] - loss: 0.1109

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2827, log_difficulty=0.2490, weight=2.2450
neutral: count=7825.0, difficulty=0.2226, log_difficulty=0.2010, weight=2.0050
negative: count=8780.0, difficulty=0.2868, log_difficulty=0.2521, weight=2.2607

当前batch的pt分布：
positive: min=0.2758, max=0.9867, mean=0.7584
neutral: min=0.8303, max=0.9734, mean=0.9171
negative: min=0.8767, max=0.9964, mean=0.9593

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8125
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2048
焦点损失: 0.0438
边界损失: 0.2174
总损失: 0.1280
Epoch 5 [113/172] - loss: 0.1280
Epoch 5 [114/172] - loss: 0.1756
Epoch 5 [115/172] - loss: 0.1114
Epoch 5 [116/172] - loss: 0.0477
Epoch 5 [117/172] - loss: 0.1219
Epoch 5 [118/172] - loss: 0.0462
Epoch 5 [119/172] - loss: 0.0492
Epoch 5 [120/172] - loss: 0.0549, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0548
Epoch 5 [122/172] - loss: 0.0460
Epoch 5 [123/172] - loss: 0.0551
Epoch 5 [124/172] - loss: 0.0698
Epoch 5 [125/172] - loss: 0.0457
Epoch 5 [126/172] - loss: 0.0793
Epoch 5 [127/172] - loss: 0.0694
Epoch 5 [128/172] - loss: 0.0708
Epoch 5 [129/172] - loss: 0.0950
Epoch 5 [130/172] - loss: 0.0497, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0729
Epoch 5 [132/172] - loss: 0.1263
Epoch 5 [133/172] - loss: 0.1018
Epoch 5 [134/172] - loss: 0.1949
Epoch 5 [135/172] - loss: 0.0439
Epoch 5 [136/172] - loss: 0.1011
Epoch 5 [137/172] - loss: 0.0499
Epoch 5 [138/172] - loss: 0.1540
Epoch 5 [139/172] - loss: 0.2940
Epoch 5 [140/172] - loss: 0.1034, acc: 0.9375
Epoch 5 [141/172] - loss: 0.0461
Epoch 5 [142/172] - loss: 0.0429
Epoch 5 [143/172] - loss: 0.0464
Epoch 5 [144/172] - loss: 0.0432
Epoch 5 [145/172] - loss: 0.1792
Epoch 5 [146/172] - loss: 0.0481
Epoch 5 [147/172] - loss: 0.0516
Epoch 5 [148/172] - loss: 0.0422
Epoch 5 [149/172] - loss: 0.0471
Epoch 5 [150/172] - loss: 0.1082, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0496
Epoch 5 [152/172] - loss: 0.0444
Epoch 5 [153/172] - loss: 0.0594
Epoch 5 [154/172] - loss: 0.0921
Epoch 5 [155/172] - loss: 0.1570
Epoch 5 [156/172] - loss: 0.0553
Epoch 5 [157/172] - loss: 0.0523
Epoch 5 [158/172] - loss: 0.0577
Epoch 5 [159/172] - loss: 0.0440
Epoch 5 [160/172] - loss: 0.0431, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0431
Epoch 5 [162/172] - loss: 0.0600
Epoch 5 [163/172] - loss: 0.1620
Epoch 5 [164/172] - loss: 0.0541
Epoch 5 [165/172] - loss: 0.1146
Epoch 5 [166/172] - loss: 0.0567
Epoch 5 [167/172] - loss: 0.0982
Epoch 5 [168/172] - loss: 0.0446
Epoch 5 [169/172] - loss: 0.0547
Epoch 5 [170/172] - loss: 0.0473, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0542
Epoch 5 [172/172] - loss: 0.0649

类别准确率:
positive: 0.8266 (386/467)
neutral: 0.2651 (22/83)
negative: 0.6880 (172/250)

Epoch 5/10
Train Loss: 0.0657, Train Acc: 0.9899
Val Loss: 0.7542, Val Acc: 0.7250
Epoch 6 [1/172] - loss: 0.0709, acc: 1.0000
Epoch 6 [2/172] - loss: 0.0662
Epoch 6 [3/172] - loss: 0.0469
Epoch 6 [4/172] - loss: 0.0454
Epoch 6 [5/172] - loss: 0.1209
Epoch 6 [6/172] - loss: 0.0577
Epoch 6 [7/172] - loss: 0.0783
Epoch 6 [8/172] - loss: 0.0653
Epoch 6 [9/172] - loss: 0.0440
Epoch 6 [10/172] - loss: 0.0448, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0411
Epoch 6 [12/172] - loss: 0.0457
Epoch 6 [13/172] - loss: 0.0547
Epoch 6 [14/172] - loss: 0.0430
Epoch 6 [15/172] - loss: 0.0437
Epoch 6 [16/172] - loss: 0.1637
Epoch 6 [17/172] - loss: 0.0450
Epoch 6 [18/172] - loss: 0.0432
Epoch 6 [19/172] - loss: 0.0474
Epoch 6 [20/172] - loss: 0.0459, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0503
Epoch 6 [22/172] - loss: 0.0555
Epoch 6 [23/172] - loss: 0.0625
Epoch 6 [24/172] - loss: 0.0446
Epoch 6 [25/172] - loss: 0.0453
Epoch 6 [26/172] - loss: 0.0448
Epoch 6 [27/172] - loss: 0.0550
Epoch 6 [28/172] - loss: 0.0477
Epoch 6 [29/172] - loss: 0.0448
Epoch 6 [30/172] - loss: 0.0419, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0445
Epoch 6 [32/172] - loss: 0.0440
Epoch 6 [33/172] - loss: 0.0475
Epoch 6 [34/172] - loss: 0.0450
Epoch 6 [35/172] - loss: 0.0410
Epoch 6 [36/172] - loss: 0.0497
Epoch 6 [37/172] - loss: 0.0484
Epoch 6 [38/172] - loss: 0.0440
Epoch 6 [39/172] - loss: 0.1117
Epoch 6 [40/172] - loss: 0.1117, acc: 0.9375

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2618, log_difficulty=0.2325, weight=2.1626
neutral: count=8815.0, difficulty=0.2059, log_difficulty=0.1872, weight=1.9360
negative: count=9870.0, difficulty=0.2664, log_difficulty=0.2362, weight=2.1810

当前batch的pt分布：
positive: min=0.1230, max=0.9927, mean=0.8821
neutral: min=0.9582, max=0.9948, mean=0.9741
negative: min=0.7354, max=0.9846, mean=0.8883

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1291
焦点损失: 0.0500
边界损失: 0.1700
总损失: 0.1237
Epoch 6 [41/172] - loss: 0.1237
Epoch 6 [42/172] - loss: 0.0499
Epoch 6 [43/172] - loss: 0.1307
Epoch 6 [44/172] - loss: 0.0437
Epoch 6 [45/172] - loss: 0.0697
Epoch 6 [46/172] - loss: 0.0838
Epoch 6 [47/172] - loss: 0.0450
Epoch 6 [48/172] - loss: 0.0465
Epoch 6 [49/172] - loss: 0.0631
Epoch 6 [50/172] - loss: 0.1168, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1138
Epoch 6 [52/172] - loss: 0.1520
Epoch 6 [53/172] - loss: 0.0487
Epoch 6 [54/172] - loss: 0.0970
Epoch 6 [55/172] - loss: 0.0481
Epoch 6 [56/172] - loss: 0.0960
Epoch 6 [57/172] - loss: 0.0471
Epoch 6 [58/172] - loss: 0.0513
Epoch 6 [59/172] - loss: 0.0602
Epoch 6 [60/172] - loss: 0.0568, acc: 1.0000
Epoch 6 [61/172] - loss: 0.0566
Epoch 6 [62/172] - loss: 0.0877
Epoch 6 [63/172] - loss: 0.0481
Epoch 6 [64/172] - loss: 0.0927
Epoch 6 [65/172] - loss: 0.0741
Epoch 6 [66/172] - loss: 0.0690
Epoch 6 [67/172] - loss: 0.0451
Epoch 6 [68/172] - loss: 0.2513
Epoch 6 [69/172] - loss: 0.0645
Epoch 6 [70/172] - loss: 0.0449, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0576
Epoch 6 [72/172] - loss: 0.0526
Epoch 6 [73/172] - loss: 0.2711
Epoch 6 [74/172] - loss: 0.0450
Epoch 6 [75/172] - loss: 0.0692
Epoch 6 [76/172] - loss: 0.0440
Epoch 6 [77/172] - loss: 0.0568
Epoch 6 [78/172] - loss: 0.0628
Epoch 6 [79/172] - loss: 0.0430
Epoch 6 [80/172] - loss: 0.0781, acc: 0.9375
Epoch 6 [81/172] - loss: 0.0597
Epoch 6 [82/172] - loss: 0.0586
Epoch 6 [83/172] - loss: 0.0471
Epoch 6 [84/172] - loss: 0.0695
Epoch 6 [85/172] - loss: 0.2711
Epoch 6 [86/172] - loss: 0.0935
Epoch 6 [87/172] - loss: 0.0765
Epoch 6 [88/172] - loss: 0.0848
Epoch 6 [89/172] - loss: 0.0461
Epoch 6 [90/172] - loss: 0.0421, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0434
Epoch 6 [92/172] - loss: 0.0412
Epoch 6 [93/172] - loss: 0.0451
Epoch 6 [94/172] - loss: 0.0508
Epoch 6 [95/172] - loss: 0.0560
Epoch 6 [96/172] - loss: 0.0413
Epoch 6 [97/172] - loss: 0.0585
Epoch 6 [98/172] - loss: 0.0764
Epoch 6 [99/172] - loss: 0.0428
Epoch 6 [100/172] - loss: 0.0632, acc: 0.9688
Epoch 6 [101/172] - loss: 0.0768
Epoch 6 [102/172] - loss: 0.0507
Epoch 6 [103/172] - loss: 0.0494
Epoch 6 [104/172] - loss: 0.0940
Epoch 6 [105/172] - loss: 0.0694
Epoch 6 [106/172] - loss: 0.0857
Epoch 6 [107/172] - loss: 0.0435
Epoch 6 [108/172] - loss: 0.0451
Epoch 6 [109/172] - loss: 0.1630
Epoch 6 [110/172] - loss: 0.0579, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0718
Epoch 6 [112/172] - loss: 0.0493
Epoch 6 [113/172] - loss: 0.0785
Epoch 6 [114/172] - loss: 0.0393
Epoch 6 [115/172] - loss: 0.1900
Epoch 6 [116/172] - loss: 0.1285
Epoch 6 [117/172] - loss: 0.0525
Epoch 6 [118/172] - loss: 0.0407
Epoch 6 [119/172] - loss: 0.1504
Epoch 6 [120/172] - loss: 0.0516, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0538
Epoch 6 [122/172] - loss: 0.0681
Epoch 6 [123/172] - loss: 0.0566
Epoch 6 [124/172] - loss: 0.0956
Epoch 6 [125/172] - loss: 0.0639
Epoch 6 [126/172] - loss: 0.0829
Epoch 6 [127/172] - loss: 0.1245
Epoch 6 [128/172] - loss: 0.0649
Epoch 6 [129/172] - loss: 0.0454
Epoch 6 [130/172] - loss: 0.2049, acc: 0.9688
Epoch 6 [131/172] - loss: 0.0497
Epoch 6 [132/172] - loss: 0.1679
Epoch 6 [133/172] - loss: 0.0485
Epoch 6 [134/172] - loss: 0.0772
Epoch 6 [135/172] - loss: 0.0512
Epoch 6 [136/172] - loss: 0.0472
Epoch 6 [137/172] - loss: 0.0654
Epoch 6 [138/172] - loss: 0.0537
Epoch 6 [139/172] - loss: 0.0586
Epoch 6 [140/172] - loss: 0.0610, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2443, log_difficulty=0.2186, weight=2.0929
neutral: count=9796.0, difficulty=0.1935, log_difficulty=0.1769, weight=1.8844
negative: count=10972.0, difficulty=0.2498, log_difficulty=0.2230, weight=2.1150

当前batch的pt分布：
positive: min=0.8850, max=0.9919, mean=0.9586
neutral: min=0.7805, max=0.9952, mean=0.9542
negative: min=0.7565, max=0.9766, mean=0.8981

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0723
焦点损失: 0.0014
边界损失: 0.1722
总损失: 0.0451
Epoch 6 [141/172] - loss: 0.0451
Epoch 6 [142/172] - loss: 0.0557
Epoch 6 [143/172] - loss: 0.0557
Epoch 6 [144/172] - loss: 0.0585
Epoch 6 [145/172] - loss: 0.0429
Epoch 6 [146/172] - loss: 0.0522
Epoch 6 [147/172] - loss: 0.1084
Epoch 6 [148/172] - loss: 0.0799
Epoch 6 [149/172] - loss: 0.0689
Epoch 6 [150/172] - loss: 0.0428, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0432
Epoch 6 [152/172] - loss: 0.0666
Epoch 6 [153/172] - loss: 0.0472
Epoch 6 [154/172] - loss: 0.0397
Epoch 6 [155/172] - loss: 0.0614
Epoch 6 [156/172] - loss: 0.0476
Epoch 6 [157/172] - loss: 0.0444
Epoch 6 [158/172] - loss: 0.0456
Epoch 6 [159/172] - loss: 0.0759
Epoch 6 [160/172] - loss: 0.1342, acc: 0.9688
Epoch 6 [161/172] - loss: 0.0464
Epoch 6 [162/172] - loss: 0.0691
Epoch 6 [163/172] - loss: 0.0559
Epoch 6 [164/172] - loss: 0.0567
Epoch 6 [165/172] - loss: 0.2837
Epoch 6 [166/172] - loss: 0.0448
Epoch 6 [167/172] - loss: 0.0433
Epoch 6 [168/172] - loss: 0.0491
Epoch 6 [169/172] - loss: 0.0493
Epoch 6 [170/172] - loss: 0.0442, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0422
Epoch 6 [172/172] - loss: 0.0430

类别准确率:
positive: 0.7645 (357/467)
neutral: 0.2771 (23/83)
negative: 0.7000 (175/250)

Epoch 6/10
Train Loss: 0.0705, Train Acc: 0.9859
Val Loss: 0.8078, Val Acc: 0.6937
Epoch 7 [1/172] - loss: 0.0458, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0402
Epoch 7 [3/172] - loss: 0.0426
Epoch 7 [4/172] - loss: 0.0437
Epoch 7 [5/172] - loss: 0.0392
Epoch 7 [6/172] - loss: 0.0431
Epoch 7 [7/172] - loss: 0.0786
Epoch 7 [8/172] - loss: 0.0917
Epoch 7 [9/172] - loss: 0.0444
Epoch 7 [10/172] - loss: 0.0406, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0406
Epoch 7 [12/172] - loss: 0.1209
Epoch 7 [13/172] - loss: 0.0435
Epoch 7 [14/172] - loss: 0.0525
Epoch 7 [15/172] - loss: 0.0649
Epoch 7 [16/172] - loss: 0.0466
Epoch 7 [17/172] - loss: 0.0673
Epoch 7 [18/172] - loss: 0.0422
Epoch 7 [19/172] - loss: 0.0443
Epoch 7 [20/172] - loss: 0.0433, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0473
Epoch 7 [22/172] - loss: 0.0403
Epoch 7 [23/172] - loss: 0.0396
Epoch 7 [24/172] - loss: 0.0400
Epoch 7 [25/172] - loss: 0.0395
Epoch 7 [26/172] - loss: 0.0602
Epoch 7 [27/172] - loss: 0.0464
Epoch 7 [28/172] - loss: 0.0491
Epoch 7 [29/172] - loss: 0.0835
Epoch 7 [30/172] - loss: 0.0823, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0498
Epoch 7 [32/172] - loss: 0.0414
Epoch 7 [33/172] - loss: 0.0557
Epoch 7 [34/172] - loss: 0.0408
Epoch 7 [35/172] - loss: 0.0655
Epoch 7 [36/172] - loss: 0.1130
Epoch 7 [37/172] - loss: 0.0435
Epoch 7 [38/172] - loss: 0.0403
Epoch 7 [39/172] - loss: 0.0467
Epoch 7 [40/172] - loss: 0.0405, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0453
Epoch 7 [42/172] - loss: 0.0432
Epoch 7 [43/172] - loss: 0.0440
Epoch 7 [44/172] - loss: 0.0441
Epoch 7 [45/172] - loss: 0.0445
Epoch 7 [46/172] - loss: 0.0578
Epoch 7 [47/172] - loss: 0.0659
Epoch 7 [48/172] - loss: 0.0396
Epoch 7 [49/172] - loss: 0.0393
Epoch 7 [50/172] - loss: 0.0477, acc: 1.0000
Epoch 7 [51/172] - loss: 0.2050
Epoch 7 [52/172] - loss: 0.0385
Epoch 7 [53/172] - loss: 0.0381
Epoch 7 [54/172] - loss: 0.0430
Epoch 7 [55/172] - loss: 0.0472
Epoch 7 [56/172] - loss: 0.0418
Epoch 7 [57/172] - loss: 0.0780
Epoch 7 [58/172] - loss: 0.0617
Epoch 7 [59/172] - loss: 0.0441
Epoch 7 [60/172] - loss: 0.0558, acc: 0.9688
Epoch 7 [61/172] - loss: 0.1744
Epoch 7 [62/172] - loss: 0.0448
Epoch 7 [63/172] - loss: 0.2359
Epoch 7 [64/172] - loss: 0.0441
Epoch 7 [65/172] - loss: 0.0923
Epoch 7 [66/172] - loss: 0.0425
Epoch 7 [67/172] - loss: 0.0531
Epoch 7 [68/172] - loss: 0.0546

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.2288, log_difficulty=0.2060, weight=2.0302
neutral: count=10756.0, difficulty=0.1808, log_difficulty=0.1662, weight=1.8308
negative: count=12072.0, difficulty=0.2340, log_difficulty=0.2102, weight=2.0512

当前batch的pt分布：
positive: min=0.8743, max=0.9867, mean=0.9457
neutral: min=0.9622, max=0.9943, mean=0.9836
negative: min=0.7121, max=0.9834, mean=0.8866

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0770
焦点损失: 0.0022
边界损失: 0.1751
总损失: 0.0471
Epoch 7 [69/172] - loss: 0.0471
Epoch 7 [70/172] - loss: 0.0454, acc: 1.0000
Epoch 7 [71/172] - loss: 0.0547
Epoch 7 [72/172] - loss: 0.0763
Epoch 7 [73/172] - loss: 0.0528
Epoch 7 [74/172] - loss: 0.0417
Epoch 7 [75/172] - loss: 0.0424
Epoch 7 [76/172] - loss: 0.0653
Epoch 7 [77/172] - loss: 0.0480
Epoch 7 [78/172] - loss: 0.0434
Epoch 7 [79/172] - loss: 0.0646
Epoch 7 [80/172] - loss: 0.1181, acc: 0.9375
Epoch 7 [81/172] - loss: 0.0493
Epoch 7 [82/172] - loss: 0.0512
Epoch 7 [83/172] - loss: 0.1240
Epoch 7 [84/172] - loss: 0.0423
Epoch 7 [85/172] - loss: 0.0446
Epoch 7 [86/172] - loss: 0.0423
Epoch 7 [87/172] - loss: 0.0481
Epoch 7 [88/172] - loss: 0.0483
Epoch 7 [89/172] - loss: 0.0423
Epoch 7 [90/172] - loss: 0.0455, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0564
Epoch 7 [92/172] - loss: 0.0454
Epoch 7 [93/172] - loss: 0.1148
Epoch 7 [94/172] - loss: 0.0428
Epoch 7 [95/172] - loss: 0.0453
Epoch 7 [96/172] - loss: 0.0469
Epoch 7 [97/172] - loss: 0.0670
Epoch 7 [98/172] - loss: 0.1258
Epoch 7 [99/172] - loss: 0.0426
Epoch 7 [100/172] - loss: 0.0409, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0418
Epoch 7 [102/172] - loss: 0.0434
Epoch 7 [103/172] - loss: 0.0544
Epoch 7 [104/172] - loss: 0.0584
Epoch 7 [105/172] - loss: 0.0563
Epoch 7 [106/172] - loss: 0.0620
Epoch 7 [107/172] - loss: 0.0419
Epoch 7 [108/172] - loss: 0.0405
Epoch 7 [109/172] - loss: 0.0688
Epoch 7 [110/172] - loss: 0.0530, acc: 1.0000
Epoch 7 [111/172] - loss: 0.0591
Epoch 7 [112/172] - loss: 0.0451
Epoch 7 [113/172] - loss: 0.0429
Epoch 7 [114/172] - loss: 0.0396
Epoch 7 [115/172] - loss: 0.0413
Epoch 7 [116/172] - loss: 0.0539
Epoch 7 [117/172] - loss: 0.0560
Epoch 7 [118/172] - loss: 0.0472
Epoch 7 [119/172] - loss: 0.0435
Epoch 7 [120/172] - loss: 0.0426, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0438
Epoch 7 [122/172] - loss: 0.0418
Epoch 7 [123/172] - loss: 0.0397
Epoch 7 [124/172] - loss: 0.0532
Epoch 7 [125/172] - loss: 0.0396
Epoch 7 [126/172] - loss: 0.0408
Epoch 7 [127/172] - loss: 0.0410
Epoch 7 [128/172] - loss: 0.0399
Epoch 7 [129/172] - loss: 0.0444
Epoch 7 [130/172] - loss: 0.0584, acc: 0.9688
Epoch 7 [131/172] - loss: 0.0913
Epoch 7 [132/172] - loss: 0.2057
Epoch 7 [133/172] - loss: 0.0408
Epoch 7 [134/172] - loss: 0.0454
Epoch 7 [135/172] - loss: 0.0422
Epoch 7 [136/172] - loss: 0.0425
Epoch 7 [137/172] - loss: 0.1209
Epoch 7 [138/172] - loss: 0.0396
Epoch 7 [139/172] - loss: 0.0564
Epoch 7 [140/172] - loss: 0.0506, acc: 1.0000
Epoch 7 [141/172] - loss: 0.0455
Epoch 7 [142/172] - loss: 0.0414
Epoch 7 [143/172] - loss: 0.0529
Epoch 7 [144/172] - loss: 0.0462
Epoch 7 [145/172] - loss: 0.1711
Epoch 7 [146/172] - loss: 0.1827
Epoch 7 [147/172] - loss: 0.0438
Epoch 7 [148/172] - loss: 0.0619
Epoch 7 [149/172] - loss: 0.0473
Epoch 7 [150/172] - loss: 0.0551, acc: 0.9688
Epoch 7 [151/172] - loss: 0.0727
Epoch 7 [152/172] - loss: 0.0375
Epoch 7 [153/172] - loss: 0.0416
Epoch 7 [154/172] - loss: 0.0733
Epoch 7 [155/172] - loss: 0.0389
Epoch 7 [156/172] - loss: 0.0806
Epoch 7 [157/172] - loss: 0.0532
Epoch 7 [158/172] - loss: 0.0514
Epoch 7 [159/172] - loss: 0.0424
Epoch 7 [160/172] - loss: 0.0397, acc: 1.0000
Epoch 7 [161/172] - loss: 0.0401
Epoch 7 [162/172] - loss: 0.0612
Epoch 7 [163/172] - loss: 0.0504
Epoch 7 [164/172] - loss: 0.1104
Epoch 7 [165/172] - loss: 0.1859
Epoch 7 [166/172] - loss: 0.0399
Epoch 7 [167/172] - loss: 0.1066
Epoch 7 [168/172] - loss: 0.1055

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.2156, log_difficulty=0.1952, weight=1.9762
neutral: count=11731.0, difficulty=0.1707, log_difficulty=0.1576, weight=1.7880
negative: count=13173.0, difficulty=0.2206, log_difficulty=0.1993, weight=1.9966

当前batch的pt分布：
positive: min=0.8998, max=0.9952, mean=0.9654
neutral: min=0.9104, max=0.9960, mean=0.9718
negative: min=0.8475, max=0.9885, mean=0.9364

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0457
焦点损失: 0.0004
边界损失: 0.1577
总损失: 0.0400
Epoch 7 [169/172] - loss: 0.0400
Epoch 7 [170/172] - loss: 0.0556, acc: 1.0000
Epoch 7 [171/172] - loss: 0.0410
Epoch 7 [172/172] - loss: 0.0384

类别准确率:
positive: 0.8544 (399/467)
neutral: 0.3976 (33/83)
negative: 0.5320 (133/250)

Epoch 7/10
Train Loss: 0.0664, Train Acc: 0.9798
Val Loss: 0.8795, Val Acc: 0.7063
Epoch 8 [1/172] - loss: 0.0650, acc: 0.9688
Epoch 8 [2/172] - loss: 0.0726
Epoch 8 [3/172] - loss: 0.0434
Epoch 8 [4/172] - loss: 0.0413
Epoch 8 [5/172] - loss: 0.0382
Epoch 8 [6/172] - loss: 0.1494
Epoch 8 [7/172] - loss: 0.0414
Epoch 8 [8/172] - loss: 0.0396
Epoch 8 [9/172] - loss: 0.0458
Epoch 8 [10/172] - loss: 0.1151, acc: 0.9688
Epoch 8 [11/172] - loss: 0.0477
Epoch 8 [12/172] - loss: 0.0577
Epoch 8 [13/172] - loss: 0.0402
Epoch 8 [14/172] - loss: 0.0425
Epoch 8 [15/172] - loss: 0.0539
Epoch 8 [16/172] - loss: 0.0404
Epoch 8 [17/172] - loss: 0.1697
Epoch 8 [18/172] - loss: 0.0398
Epoch 8 [19/172] - loss: 0.0507
Epoch 8 [20/172] - loss: 0.0434, acc: 1.0000
Epoch 8 [21/172] - loss: 0.0414
Epoch 8 [22/172] - loss: 0.0465
Epoch 8 [23/172] - loss: 0.0457
Epoch 8 [24/172] - loss: 0.0465
Epoch 8 [25/172] - loss: 0.0426
Epoch 8 [26/172] - loss: 0.0434
Epoch 8 [27/172] - loss: 0.0943
Epoch 8 [28/172] - loss: 0.0487
Epoch 8 [29/172] - loss: 0.0435
Epoch 8 [30/172] - loss: 0.0388, acc: 1.0000
Epoch 8 [31/172] - loss: 0.0396
Epoch 8 [32/172] - loss: 0.0413
Epoch 8 [33/172] - loss: 0.0459
Epoch 8 [34/172] - loss: 0.0539
Epoch 8 [35/172] - loss: 0.0403
Epoch 8 [36/172] - loss: 0.0432
Epoch 8 [37/172] - loss: 0.0494
Epoch 8 [38/172] - loss: 0.0597
Epoch 8 [39/172] - loss: 0.0435
Epoch 8 [40/172] - loss: 0.0405, acc: 1.0000
Epoch 8 [41/172] - loss: 0.0492
Epoch 8 [42/172] - loss: 0.0839
Epoch 8 [43/172] - loss: 0.0406
Epoch 8 [44/172] - loss: 0.0412
Epoch 8 [45/172] - loss: 0.0433
Epoch 8 [46/172] - loss: 0.0589
Epoch 8 [47/172] - loss: 0.0407
Epoch 8 [48/172] - loss: 0.0596
Epoch 8 [49/172] - loss: 0.0967
Epoch 8 [50/172] - loss: 0.0453, acc: 1.0000
Epoch 8 [51/172] - loss: 0.0407
Epoch 8 [52/172] - loss: 0.0398
Epoch 8 [53/172] - loss: 0.0464
Epoch 8 [54/172] - loss: 0.1115
Epoch 8 [55/172] - loss: 0.0408
Epoch 8 [56/172] - loss: 0.1087
Epoch 8 [57/172] - loss: 0.0394
Epoch 8 [58/172] - loss: 0.0410
Epoch 8 [59/172] - loss: 0.0501
Epoch 8 [60/172] - loss: 0.0444, acc: 1.0000
Epoch 8 [61/172] - loss: 0.0407
Epoch 8 [62/172] - loss: 0.0409
Epoch 8 [63/172] - loss: 0.0386
Epoch 8 [64/172] - loss: 0.0400
Epoch 8 [65/172] - loss: 0.0381
Epoch 8 [66/172] - loss: 0.0815
Epoch 8 [67/172] - loss: 0.0665
Epoch 8 [68/172] - loss: 0.0414
Epoch 8 [69/172] - loss: 0.0392
Epoch 8 [70/172] - loss: 0.0731, acc: 0.9688
Epoch 8 [71/172] - loss: 0.0626
Epoch 8 [72/172] - loss: 0.0444
Epoch 8 [73/172] - loss: 0.0720
Epoch 8 [74/172] - loss: 0.0501
Epoch 8 [75/172] - loss: 0.0406
Epoch 8 [76/172] - loss: 0.0893
Epoch 8 [77/172] - loss: 0.0394
Epoch 8 [78/172] - loss: 0.0623
Epoch 8 [79/172] - loss: 0.0472
Epoch 8 [80/172] - loss: 0.0499, acc: 1.0000
Epoch 8 [81/172] - loss: 0.0628
Epoch 8 [82/172] - loss: 0.0439
Epoch 8 [83/172] - loss: 0.0440
Epoch 8 [84/172] - loss: 0.0460
Epoch 8 [85/172] - loss: 0.0436
Epoch 8 [86/172] - loss: 0.0419
Epoch 8 [87/172] - loss: 0.0627
Epoch 8 [88/172] - loss: 0.0541
Epoch 8 [89/172] - loss: 0.0451
Epoch 8 [90/172] - loss: 0.0425, acc: 1.0000
Epoch 8 [91/172] - loss: 0.1484
Epoch 8 [92/172] - loss: 0.0424
Epoch 8 [93/172] - loss: 0.0386
Epoch 8 [94/172] - loss: 0.0552
Epoch 8 [95/172] - loss: 0.0436
Epoch 8 [96/172] - loss: 0.0422

=== 第 1301 次迭代调试信息 ===
当前类别统计：
positive: count=14487.0, difficulty=0.2037, log_difficulty=0.1854, weight=1.9269
neutral: count=12738.0, difficulty=0.1620, log_difficulty=0.1502, weight=1.7509
negative: count=14288.0, difficulty=0.2086, log_difficulty=0.1895, weight=1.9473

当前batch的pt分布：
positive: min=0.7899, max=0.9944, mean=0.9424
neutral: min=0.2856, max=0.9813, mean=0.8467
negative: min=0.9178, max=0.9941, mean=0.9670

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9333
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1226
焦点损失: 0.0254
边界损失: 0.1823
总损失: 0.0790
Epoch 8 [97/172] - loss: 0.0790
Epoch 8 [98/172] - loss: 0.0426
Epoch 8 [99/172] - loss: 0.0414
Epoch 8 [100/172] - loss: 0.0447, acc: 1.0000
Epoch 8 [101/172] - loss: 0.0742
Epoch 8 [102/172] - loss: 0.0623
Epoch 8 [103/172] - loss: 0.0745
Epoch 8 [104/172] - loss: 0.0431
Epoch 8 [105/172] - loss: 0.0413
Epoch 8 [106/172] - loss: 0.0416
Epoch 8 [107/172] - loss: 0.0409
Epoch 8 [108/172] - loss: 0.0388
Epoch 8 [109/172] - loss: 0.0713
Epoch 8 [110/172] - loss: 0.0481, acc: 1.0000
Epoch 8 [111/172] - loss: 0.1002
Epoch 8 [112/172] - loss: 0.0558
Epoch 8 [113/172] - loss: 0.0387
Epoch 8 [114/172] - loss: 0.0400
Epoch 8 [115/172] - loss: 0.0396
Epoch 8 [116/172] - loss: 0.0405
Epoch 8 [117/172] - loss: 0.0420
Epoch 8 [118/172] - loss: 0.0408
Epoch 8 [119/172] - loss: 0.0402
Epoch 8 [120/172] - loss: 0.0409, acc: 1.0000
Epoch 8 [121/172] - loss: 0.0614
Epoch 8 [122/172] - loss: 0.0419
Epoch 8 [123/172] - loss: 0.0404
Epoch 8 [124/172] - loss: 0.0381
Epoch 8 [125/172] - loss: 0.0611
Epoch 8 [126/172] - loss: 0.0470
Epoch 8 [127/172] - loss: 0.0698
Epoch 8 [128/172] - loss: 0.0647
Epoch 8 [129/172] - loss: 0.0445
Epoch 8 [130/172] - loss: 0.0505, acc: 0.9688
Epoch 8 [131/172] - loss: 0.0392
Epoch 8 [132/172] - loss: 0.0396
Epoch 8 [133/172] - loss: 0.0460
Epoch 8 [134/172] - loss: 0.0476
Epoch 8 [135/172] - loss: 0.0392
Epoch 8 [136/172] - loss: 0.0421
Epoch 8 [137/172] - loss: 0.0436
Epoch 8 [138/172] - loss: 0.0562
Epoch 8 [139/172] - loss: 0.0472
Epoch 8 [140/172] - loss: 0.0399, acc: 1.0000
Epoch 8 [141/172] - loss: 0.0391
Epoch 8 [142/172] - loss: 0.0407
Epoch 8 [143/172] - loss: 0.0396
Epoch 8 [144/172] - loss: 0.0452
Epoch 8 [145/172] - loss: 0.0469
Epoch 8 [146/172] - loss: 0.0391
Epoch 8 [147/172] - loss: 0.0412
Epoch 8 [148/172] - loss: 0.0416
Epoch 8 [149/172] - loss: 0.0416
Epoch 8 [150/172] - loss: 0.0745, acc: 0.9688
Epoch 8 [151/172] - loss: 0.0467
Epoch 8 [152/172] - loss: 0.0496
Epoch 8 [153/172] - loss: 0.0414
Epoch 8 [154/172] - loss: 0.0642
Epoch 8 [155/172] - loss: 0.0399
Epoch 8 [156/172] - loss: 0.0467
Epoch 8 [157/172] - loss: 0.0426
Epoch 8 [158/172] - loss: 0.0432
Epoch 8 [159/172] - loss: 0.0484
Epoch 8 [160/172] - loss: 0.0404, acc: 1.0000
Epoch 8 [161/172] - loss: 0.0397
Epoch 8 [162/172] - loss: 0.0481
Epoch 8 [163/172] - loss: 0.0404
Epoch 8 [164/172] - loss: 0.0452
Epoch 8 [165/172] - loss: 0.0392
Epoch 8 [166/172] - loss: 0.0493
Epoch 8 [167/172] - loss: 0.0382
Epoch 8 [168/172] - loss: 0.0412
Epoch 8 [169/172] - loss: 0.0518
Epoch 8 [170/172] - loss: 0.0420, acc: 1.0000
Epoch 8 [171/172] - loss: 0.0426
Epoch 8 [172/172] - loss: 0.0382

类别准确率:
positive: 0.8266 (386/467)
neutral: 0.3133 (26/83)
negative: 0.6480 (162/250)

Epoch 8/10
Train Loss: 0.0431, Train Acc: 1.0000
Val Loss: 0.8361, Val Acc: 0.7175
Early stopping triggered!
Best validation accuracy: 0.7250

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_102024-exqxkk4w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.3_Multimodal_iterations_20250118_102022
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/exqxkk4w
wandb: updating run config
wandb: uploading history steps 141-143, summary, console lines 1744-1770; uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇██
wandb:  train_acc ▂▁▃▃▅▆▇▆▇▅▆█▇█▆▇▇▆█▇█▇█████▇████████████
wandb: train_loss ▇██▆▄▃▃▃▂▁▁▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1374
wandb:  train_acc 1
wandb: train_loss 0.04197
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.3_Multimodal_iterations_20250118_102022 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/exqxkk4w
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_102024-exqxkk4w/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_103244-9w42h3se
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.3_Multimodal_epochs_20250118_103244
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/9w42h3se
wandb: uploading history steps 0-0, summary; updating run config; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▄▅▆▇█
wandb:  train_acc ▁▄▇▇██▇█
wandb: train_loss █▅▂▂▁▁▁▁
wandb:    val_acc ▁▆▇▆█▄▆▇
wandb:   val_loss ▁▁▂▂▂▅█▆
wandb: 
wandb: Run summary:
wandb:      epoch 8
wandb:  train_acc 1
wandb: train_loss 0.04315
wandb:    val_acc 0.7175
wandb:   val_loss 0.83609
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.3_Multimodal_epochs_20250118_103244 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/9w42h3se
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_103244-9w42h3se/logs

