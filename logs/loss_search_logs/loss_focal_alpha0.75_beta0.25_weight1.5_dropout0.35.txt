=== 命令 ===
python main.py --loss_type focal --alpha 0.75 --beta 0.25 --neural_init_weight 1.5 --dropout 0.35 --name loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.35 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.35
text_dim: 128
image_dim: 256
dropout: 0.35
loss_type: focal
alpha: 0.75
beta: 0.25
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6827, log_difficulty=0.5204, weight=3.6019
neutral: count=7.0, difficulty=0.7088, log_difficulty=0.5358, weight=3.6791
negative: count=13.0, difficulty=0.6651, log_difficulty=0.5099, weight=3.5493

当前batch的pt分布：
positive: min=0.1697, max=0.5562, mean=0.3173
neutral: min=0.1899, max=0.3917, mean=0.2912
negative: min=0.0779, max=0.5316, mean=0.3349

当前batch准确率：
整体准确率: 0.3125
positive 准确率: 0.3333
neutral 准确率: 0.1429
negative 准确率: 0.3846

损失分量：
基础交叉熵: 1.2025
焦点损失: 0.4491
边界损失: 0.7697
总损失: 1.4044
Epoch 1 [1/172] - loss: 1.4044, acc: 0.3125
Epoch 1 [2/172] - loss: 1.1285
Epoch 1 [3/172] - loss: 1.1454
Epoch 1 [4/172] - loss: 1.2500
Epoch 1 [5/172] - loss: 1.1282
Epoch 1 [6/172] - loss: 1.5802
Epoch 1 [7/172] - loss: 1.6263
Epoch 1 [8/172] - loss: 1.1543
Epoch 1 [9/172] - loss: 1.6460
Epoch 1 [10/172] - loss: 1.2123, acc: 0.4062
Epoch 1 [11/172] - loss: 1.1986
Epoch 1 [12/172] - loss: 1.2925
Epoch 1 [13/172] - loss: 1.5909
Epoch 1 [14/172] - loss: 1.3203
Epoch 1 [15/172] - loss: 1.1908
Epoch 1 [16/172] - loss: 0.9643
Epoch 1 [17/172] - loss: 0.9858
Epoch 1 [18/172] - loss: 1.1665
Epoch 1 [19/172] - loss: 1.2112
Epoch 1 [20/172] - loss: 1.0711, acc: 0.4062
Epoch 1 [21/172] - loss: 1.4324
Epoch 1 [22/172] - loss: 1.1182
Epoch 1 [23/172] - loss: 1.1868
Epoch 1 [24/172] - loss: 1.4651
Epoch 1 [25/172] - loss: 1.0913
Epoch 1 [26/172] - loss: 1.2753
Epoch 1 [27/172] - loss: 1.0647
Epoch 1 [28/172] - loss: 1.2050
Epoch 1 [29/172] - loss: 1.0290
Epoch 1 [30/172] - loss: 1.0562, acc: 0.5312
Epoch 1 [31/172] - loss: 1.0866
Epoch 1 [32/172] - loss: 1.0590
Epoch 1 [33/172] - loss: 0.8261
Epoch 1 [34/172] - loss: 1.1651
Epoch 1 [35/172] - loss: 1.1072
Epoch 1 [36/172] - loss: 0.8376
Epoch 1 [37/172] - loss: 0.9770
Epoch 1 [38/172] - loss: 1.0246
Epoch 1 [39/172] - loss: 0.8210
Epoch 1 [40/172] - loss: 1.0243, acc: 0.4375
Epoch 1 [41/172] - loss: 1.1054
Epoch 1 [42/172] - loss: 0.9059
Epoch 1 [43/172] - loss: 1.2248
Epoch 1 [44/172] - loss: 1.2495
Epoch 1 [45/172] - loss: 1.1513
Epoch 1 [46/172] - loss: 0.8866
Epoch 1 [47/172] - loss: 1.2768
Epoch 1 [48/172] - loss: 1.0546
Epoch 1 [49/172] - loss: 1.1791
Epoch 1 [50/172] - loss: 1.0789, acc: 0.4688
Epoch 1 [51/172] - loss: 1.3282
Epoch 1 [52/172] - loss: 0.9387
Epoch 1 [53/172] - loss: 1.1195
Epoch 1 [54/172] - loss: 1.0492
Epoch 1 [55/172] - loss: 0.8305
Epoch 1 [56/172] - loss: 1.1315
Epoch 1 [57/172] - loss: 1.2395
Epoch 1 [58/172] - loss: 0.7162
Epoch 1 [59/172] - loss: 0.9260
Epoch 1 [60/172] - loss: 0.9146, acc: 0.7188
Epoch 1 [61/172] - loss: 1.0466
Epoch 1 [62/172] - loss: 0.8997
Epoch 1 [63/172] - loss: 1.0851
Epoch 1 [64/172] - loss: 0.9331
Epoch 1 [65/172] - loss: 0.9537
Epoch 1 [66/172] - loss: 1.1843
Epoch 1 [67/172] - loss: 1.0475
Epoch 1 [68/172] - loss: 0.9355
Epoch 1 [69/172] - loss: 0.9883
Epoch 1 [70/172] - loss: 0.9463, acc: 0.6250
Epoch 1 [71/172] - loss: 0.8758
Epoch 1 [72/172] - loss: 1.1156
Epoch 1 [73/172] - loss: 0.8336
Epoch 1 [74/172] - loss: 0.7591
Epoch 1 [75/172] - loss: 0.9715
Epoch 1 [76/172] - loss: 0.8261
Epoch 1 [77/172] - loss: 0.9075
Epoch 1 [78/172] - loss: 1.1041
Epoch 1 [79/172] - loss: 1.1540
Epoch 1 [80/172] - loss: 0.7753, acc: 0.5938
Epoch 1 [81/172] - loss: 1.0936
Epoch 1 [82/172] - loss: 0.8378
Epoch 1 [83/172] - loss: 0.9841
Epoch 1 [84/172] - loss: 1.1371
Epoch 1 [85/172] - loss: 1.0632
Epoch 1 [86/172] - loss: 1.4236
Epoch 1 [87/172] - loss: 0.9916
Epoch 1 [88/172] - loss: 1.5818
Epoch 1 [89/172] - loss: 1.1187
Epoch 1 [90/172] - loss: 1.0587, acc: 0.4062
Epoch 1 [91/172] - loss: 0.7310
Epoch 1 [92/172] - loss: 0.9505
Epoch 1 [93/172] - loss: 1.1730
Epoch 1 [94/172] - loss: 0.8155
Epoch 1 [95/172] - loss: 0.9920
Epoch 1 [96/172] - loss: 0.9806
Epoch 1 [97/172] - loss: 1.2554
Epoch 1 [98/172] - loss: 0.7367
Epoch 1 [99/172] - loss: 1.0361
Epoch 1 [100/172] - loss: 0.9613, acc: 0.5000

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.6065, log_difficulty=0.4740, weight=3.3702
neutral: count=983.0, difficulty=0.6226, log_difficulty=0.4841, weight=3.4203
negative: count=1119.0, difficulty=0.6026, log_difficulty=0.4717, weight=3.3583

当前batch的pt分布：
positive: min=0.1929, max=0.5373, mean=0.3406
neutral: min=0.2466, max=0.7740, mean=0.5232
negative: min=0.2289, max=0.5419, mean=0.3734

当前batch准确率：
整体准确率: 0.3750
positive 准确率: 0.3333
neutral 准确率: 0.7500
negative 准确率: 0.3125

损失分量：
基础交叉熵: 1.0214
焦点损失: 0.3247
边界损失: 0.6885
总损失: 0.9923
Epoch 1 [101/172] - loss: 0.9923
Epoch 1 [102/172] - loss: 0.9467
Epoch 1 [103/172] - loss: 0.9393
Epoch 1 [104/172] - loss: 0.6982
Epoch 1 [105/172] - loss: 0.8480
Epoch 1 [106/172] - loss: 1.3826
Epoch 1 [107/172] - loss: 0.7625
Epoch 1 [108/172] - loss: 1.0088
Epoch 1 [109/172] - loss: 0.7645
Epoch 1 [110/172] - loss: 0.9222, acc: 0.5625
Epoch 1 [111/172] - loss: 1.0318
Epoch 1 [112/172] - loss: 0.6034
Epoch 1 [113/172] - loss: 0.6387
Epoch 1 [114/172] - loss: 0.6004
Epoch 1 [115/172] - loss: 0.7338
Epoch 1 [116/172] - loss: 0.9279
Epoch 1 [117/172] - loss: 0.9056
Epoch 1 [118/172] - loss: 0.6773
Epoch 1 [119/172] - loss: 0.8142
Epoch 1 [120/172] - loss: 0.6192, acc: 0.7500
Epoch 1 [121/172] - loss: 0.5957
Epoch 1 [122/172] - loss: 1.0198
Epoch 1 [123/172] - loss: 0.9787
Epoch 1 [124/172] - loss: 0.8465
Epoch 1 [125/172] - loss: 0.7590
Epoch 1 [126/172] - loss: 1.2436
Epoch 1 [127/172] - loss: 0.5591
Epoch 1 [128/172] - loss: 0.7757
Epoch 1 [129/172] - loss: 0.8848
Epoch 1 [130/172] - loss: 0.7022, acc: 0.5938
Epoch 1 [131/172] - loss: 0.4262
Epoch 1 [132/172] - loss: 0.8109
Epoch 1 [133/172] - loss: 0.8238
Epoch 1 [134/172] - loss: 0.8686
Epoch 1 [135/172] - loss: 0.6873
Epoch 1 [136/172] - loss: 0.6249
Epoch 1 [137/172] - loss: 0.7360
Epoch 1 [138/172] - loss: 0.8296
Epoch 1 [139/172] - loss: 0.5905
Epoch 1 [140/172] - loss: 0.7336, acc: 0.6875
Epoch 1 [141/172] - loss: 0.7635
Epoch 1 [142/172] - loss: 0.6736
Epoch 1 [143/172] - loss: 0.6806
Epoch 1 [144/172] - loss: 0.5458
Epoch 1 [145/172] - loss: 0.8073
Epoch 1 [146/172] - loss: 0.9950
Epoch 1 [147/172] - loss: 1.0853
Epoch 1 [148/172] - loss: 0.7977
Epoch 1 [149/172] - loss: 0.5914
Epoch 1 [150/172] - loss: 0.7168, acc: 0.6875
Epoch 1 [151/172] - loss: 1.0870
Epoch 1 [152/172] - loss: 0.9016
Epoch 1 [153/172] - loss: 0.8112
Epoch 1 [154/172] - loss: 0.6408
Epoch 1 [155/172] - loss: 0.6071
Epoch 1 [156/172] - loss: 1.2124
Epoch 1 [157/172] - loss: 0.5178
Epoch 1 [158/172] - loss: 0.6682
Epoch 1 [159/172] - loss: 0.7510
Epoch 1 [160/172] - loss: 0.5122, acc: 0.6875
Epoch 1 [161/172] - loss: 0.8090
Epoch 1 [162/172] - loss: 0.6113
Epoch 1 [163/172] - loss: 0.5709
Epoch 1 [164/172] - loss: 0.6787
Epoch 1 [165/172] - loss: 0.9481
Epoch 1 [166/172] - loss: 0.7761
Epoch 1 [167/172] - loss: 0.7481
Epoch 1 [168/172] - loss: 0.7145
Epoch 1 [169/172] - loss: 0.7063
Epoch 1 [170/172] - loss: 0.5971, acc: 0.7188
Epoch 1 [171/172] - loss: 0.5109
Epoch 1 [172/172] - loss: 0.9366

类别准确率:
positive: 0.5310 (248/467)
neutral: 0.7831 (65/83)
negative: 0.5240 (131/250)

Epoch 1/10
Train Loss: 0.6910, Train Acc: 0.6828
Val Loss: 0.8832, Val Acc: 0.5550
Epoch 2 [1/172] - loss: 0.5819, acc: 0.8438
Epoch 2 [2/172] - loss: 0.6876
Epoch 2 [3/172] - loss: 0.4905
Epoch 2 [4/172] - loss: 0.4861
Epoch 2 [5/172] - loss: 0.6768
Epoch 2 [6/172] - loss: 0.6066
Epoch 2 [7/172] - loss: 0.5168
Epoch 2 [8/172] - loss: 0.6123
Epoch 2 [9/172] - loss: 0.4757
Epoch 2 [10/172] - loss: 0.5717, acc: 0.7812
Epoch 2 [11/172] - loss: 0.5363
Epoch 2 [12/172] - loss: 0.6406
Epoch 2 [13/172] - loss: 0.7708
Epoch 2 [14/172] - loss: 0.7351
Epoch 2 [15/172] - loss: 0.6940
Epoch 2 [16/172] - loss: 0.5024
Epoch 2 [17/172] - loss: 0.5104
Epoch 2 [18/172] - loss: 0.9244
Epoch 2 [19/172] - loss: 0.5740
Epoch 2 [20/172] - loss: 0.4126, acc: 0.8125
Epoch 2 [21/172] - loss: 0.7048
Epoch 2 [22/172] - loss: 0.4814
Epoch 2 [23/172] - loss: 0.3570
Epoch 2 [24/172] - loss: 0.9003
Epoch 2 [25/172] - loss: 0.5633
Epoch 2 [26/172] - loss: 0.3367
Epoch 2 [27/172] - loss: 0.5562
Epoch 2 [28/172] - loss: 0.3746

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5566, log_difficulty=0.4425, weight=3.2126
neutral: count=1952.0, difficulty=0.5421, log_difficulty=0.4332, weight=3.1658
negative: count=2216.0, difficulty=0.5553, log_difficulty=0.4417, weight=3.2084

当前batch的pt分布：
positive: min=0.3104, max=0.9347, mean=0.5697
neutral: min=0.3181, max=0.9277, mean=0.6368
negative: min=0.3689, max=0.8799, mean=0.5868

当前batch准确率：
整体准确率: 0.7188
positive 准确率: 0.6667
neutral 准确率: 0.7273
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.5683
焦点损失: 0.1076
边界损失: 0.4710
总损失: 0.3757
Epoch 2 [29/172] - loss: 0.3757
Epoch 2 [30/172] - loss: 0.4754, acc: 0.7812
Epoch 2 [31/172] - loss: 0.4342
Epoch 2 [32/172] - loss: 0.4661
Epoch 2 [33/172] - loss: 0.6594
Epoch 2 [34/172] - loss: 0.4824
Epoch 2 [35/172] - loss: 0.3533
Epoch 2 [36/172] - loss: 0.6240
Epoch 2 [37/172] - loss: 0.5121
Epoch 2 [38/172] - loss: 0.3541
Epoch 2 [39/172] - loss: 0.6279
Epoch 2 [40/172] - loss: 0.5785, acc: 0.6562
Epoch 2 [41/172] - loss: 0.3424
Epoch 2 [42/172] - loss: 0.4065
Epoch 2 [43/172] - loss: 0.3291
Epoch 2 [44/172] - loss: 0.6513
Epoch 2 [45/172] - loss: 0.3634
Epoch 2 [46/172] - loss: 0.2839
Epoch 2 [47/172] - loss: 0.4900
Epoch 2 [48/172] - loss: 0.3814
Epoch 2 [49/172] - loss: 0.3952
Epoch 2 [50/172] - loss: 0.4591, acc: 0.7188
Epoch 2 [51/172] - loss: 0.4310
Epoch 2 [52/172] - loss: 0.4749
Epoch 2 [53/172] - loss: 0.2841
Epoch 2 [54/172] - loss: 0.4267
Epoch 2 [55/172] - loss: 0.5402
Epoch 2 [56/172] - loss: 0.4557
Epoch 2 [57/172] - loss: 0.2973
Epoch 2 [58/172] - loss: 0.3982
Epoch 2 [59/172] - loss: 0.5759
Epoch 2 [60/172] - loss: 0.3191, acc: 0.7812
Epoch 2 [61/172] - loss: 0.4558
Epoch 2 [62/172] - loss: 0.1986
Epoch 2 [63/172] - loss: 0.5511
Epoch 2 [64/172] - loss: 0.3989
Epoch 2 [65/172] - loss: 0.6074
Epoch 2 [66/172] - loss: 0.3517
Epoch 2 [67/172] - loss: 0.2582
Epoch 2 [68/172] - loss: 0.4045
Epoch 2 [69/172] - loss: 0.1844
Epoch 2 [70/172] - loss: 0.6768, acc: 0.7500
Epoch 2 [71/172] - loss: 0.7609
Epoch 2 [72/172] - loss: 0.5657
Epoch 2 [73/172] - loss: 0.2971
Epoch 2 [74/172] - loss: 0.4581
Epoch 2 [75/172] - loss: 0.3098
Epoch 2 [76/172] - loss: 0.5456
Epoch 2 [77/172] - loss: 0.6154
Epoch 2 [78/172] - loss: 0.4427
Epoch 2 [79/172] - loss: 0.3847
Epoch 2 [80/172] - loss: 0.3184, acc: 0.8750
Epoch 2 [81/172] - loss: 0.3184
Epoch 2 [82/172] - loss: 0.4295
Epoch 2 [83/172] - loss: 0.2913
Epoch 2 [84/172] - loss: 0.4403
Epoch 2 [85/172] - loss: 0.5222
Epoch 2 [86/172] - loss: 0.5345
Epoch 2 [87/172] - loss: 0.7972
Epoch 2 [88/172] - loss: 0.2696
Epoch 2 [89/172] - loss: 0.2208
Epoch 2 [90/172] - loss: 0.5481, acc: 0.7188
Epoch 2 [91/172] - loss: 0.3466
Epoch 2 [92/172] - loss: 0.3712
Epoch 2 [93/172] - loss: 0.3226
Epoch 2 [94/172] - loss: 0.4464
Epoch 2 [95/172] - loss: 0.4658
Epoch 2 [96/172] - loss: 0.2794
Epoch 2 [97/172] - loss: 0.2708
Epoch 2 [98/172] - loss: 0.3256
Epoch 2 [99/172] - loss: 0.2997
Epoch 2 [100/172] - loss: 0.5369, acc: 0.6875
Epoch 2 [101/172] - loss: 0.3252
Epoch 2 [102/172] - loss: 0.3162
Epoch 2 [103/172] - loss: 0.2802
Epoch 2 [104/172] - loss: 0.7748
Epoch 2 [105/172] - loss: 0.2267
Epoch 2 [106/172] - loss: 0.4456
Epoch 2 [107/172] - loss: 0.3076
Epoch 2 [108/172] - loss: 0.5063
Epoch 2 [109/172] - loss: 0.2219
Epoch 2 [110/172] - loss: 0.2570, acc: 0.8750
Epoch 2 [111/172] - loss: 0.6044
Epoch 2 [112/172] - loss: 0.3690
Epoch 2 [113/172] - loss: 0.2567
Epoch 2 [114/172] - loss: 0.4773
Epoch 2 [115/172] - loss: 0.2663
Epoch 2 [116/172] - loss: 0.5048
Epoch 2 [117/172] - loss: 0.4188
Epoch 2 [118/172] - loss: 0.2392
Epoch 2 [119/172] - loss: 0.3138
Epoch 2 [120/172] - loss: 0.1697, acc: 0.9375
Epoch 2 [121/172] - loss: 0.1929
Epoch 2 [122/172] - loss: 0.8943
Epoch 2 [123/172] - loss: 0.3583
Epoch 2 [124/172] - loss: 0.3598
Epoch 2 [125/172] - loss: 0.2544
Epoch 2 [126/172] - loss: 0.2318
Epoch 2 [127/172] - loss: 0.3208
Epoch 2 [128/172] - loss: 0.5250

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.5055, log_difficulty=0.4091, weight=3.0456
neutral: count=2949.0, difficulty=0.4509, log_difficulty=0.3722, weight=2.8611
negative: count=3294.0, difficulty=0.5057, log_difficulty=0.4093, weight=3.0463

当前batch的pt分布：
positive: min=0.3190, max=0.9087, mean=0.6589
neutral: min=0.0634, max=0.9908, mean=0.7258
negative: min=0.0872, max=0.9364, mean=0.5797

当前batch准确率：
整体准确率: 0.7500
positive 准确率: 0.7000
neutral 准确率: 0.9091
negative 准确率: 0.6364

损失分量：
基础交叉熵: 0.5614
焦点损失: 0.2124
边界损失: 0.3531
总损失: 0.5629
Epoch 2 [129/172] - loss: 0.5629
Epoch 2 [130/172] - loss: 0.4165, acc: 0.8438
Epoch 2 [131/172] - loss: 0.2672
Epoch 2 [132/172] - loss: 0.2950
Epoch 2 [133/172] - loss: 0.4497
Epoch 2 [134/172] - loss: 0.2674
Epoch 2 [135/172] - loss: 0.3896
Epoch 2 [136/172] - loss: 0.5487
Epoch 2 [137/172] - loss: 0.3914
Epoch 2 [138/172] - loss: 0.2461
Epoch 2 [139/172] - loss: 0.4223
Epoch 2 [140/172] - loss: 0.3238, acc: 0.8125
Epoch 2 [141/172] - loss: 0.3124
Epoch 2 [142/172] - loss: 0.3561
Epoch 2 [143/172] - loss: 0.2734
Epoch 2 [144/172] - loss: 0.3614
Epoch 2 [145/172] - loss: 0.9576
Epoch 2 [146/172] - loss: 0.2124
Epoch 2 [147/172] - loss: 0.4475
Epoch 2 [148/172] - loss: 0.3771
Epoch 2 [149/172] - loss: 0.4195
Epoch 2 [150/172] - loss: 0.3040, acc: 0.7812
Epoch 2 [151/172] - loss: 0.2121
Epoch 2 [152/172] - loss: 0.2374
Epoch 2 [153/172] - loss: 0.3407
Epoch 2 [154/172] - loss: 0.1966
Epoch 2 [155/172] - loss: 0.2687
Epoch 2 [156/172] - loss: 0.2616
Epoch 2 [157/172] - loss: 0.2629
Epoch 2 [158/172] - loss: 0.1985
Epoch 2 [159/172] - loss: 0.3561
Epoch 2 [160/172] - loss: 0.2169, acc: 0.9062
Epoch 2 [161/172] - loss: 0.2288
Epoch 2 [162/172] - loss: 0.2141
Epoch 2 [163/172] - loss: 0.2847
Epoch 2 [164/172] - loss: 0.3647
Epoch 2 [165/172] - loss: 0.4636
Epoch 2 [166/172] - loss: 0.6700
Epoch 2 [167/172] - loss: 0.3634
Epoch 2 [168/172] - loss: 0.2354
Epoch 2 [169/172] - loss: 0.2890
Epoch 2 [170/172] - loss: 0.1830, acc: 0.9062
Epoch 2 [171/172] - loss: 0.6350
Epoch 2 [172/172] - loss: 0.6116

类别准确率:
positive: 0.8051 (376/467)
neutral: 0.4940 (41/83)
negative: 0.4960 (124/250)

Epoch 2/10
Train Loss: 0.3486, Train Acc: 0.8586
Val Loss: 0.8080, Val Acc: 0.6763
Epoch 3 [1/172] - loss: 0.1922, acc: 0.9375
Epoch 3 [2/172] - loss: 0.1010
Epoch 3 [3/172] - loss: 0.1064
Epoch 3 [4/172] - loss: 0.2180
Epoch 3 [5/172] - loss: 0.1483
Epoch 3 [6/172] - loss: 0.1465
Epoch 3 [7/172] - loss: 0.1307
Epoch 3 [8/172] - loss: 0.1528
Epoch 3 [9/172] - loss: 0.2541
Epoch 3 [10/172] - loss: 0.1755, acc: 0.9375
Epoch 3 [11/172] - loss: 0.1968
Epoch 3 [12/172] - loss: 0.1813
Epoch 3 [13/172] - loss: 0.1371
Epoch 3 [14/172] - loss: 0.1239
Epoch 3 [15/172] - loss: 0.1258
Epoch 3 [16/172] - loss: 0.1850
Epoch 3 [17/172] - loss: 0.1687
Epoch 3 [18/172] - loss: 0.2183
Epoch 3 [19/172] - loss: 0.2018
Epoch 3 [20/172] - loss: 0.1000, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1026
Epoch 3 [22/172] - loss: 0.2469
Epoch 3 [23/172] - loss: 0.2059
Epoch 3 [24/172] - loss: 0.2451
Epoch 3 [25/172] - loss: 0.2023
Epoch 3 [26/172] - loss: 0.1451
Epoch 3 [27/172] - loss: 0.1811
Epoch 3 [28/172] - loss: 0.0848
Epoch 3 [29/172] - loss: 0.5458
Epoch 3 [30/172] - loss: 0.2976, acc: 0.8438
Epoch 3 [31/172] - loss: 0.1203
Epoch 3 [32/172] - loss: 0.2004
Epoch 3 [33/172] - loss: 0.2782
Epoch 3 [34/172] - loss: 0.1718
Epoch 3 [35/172] - loss: 0.4234
Epoch 3 [36/172] - loss: 0.1284
Epoch 3 [37/172] - loss: 0.2100
Epoch 3 [38/172] - loss: 0.1345
Epoch 3 [39/172] - loss: 0.1031
Epoch 3 [40/172] - loss: 0.1534, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1248
Epoch 3 [42/172] - loss: 0.2175
Epoch 3 [43/172] - loss: 0.0797
Epoch 3 [44/172] - loss: 0.1348
Epoch 3 [45/172] - loss: 0.3152
Epoch 3 [46/172] - loss: 0.4108
Epoch 3 [47/172] - loss: 0.0804
Epoch 3 [48/172] - loss: 0.0971
Epoch 3 [49/172] - loss: 0.1549
Epoch 3 [50/172] - loss: 0.1425, acc: 0.9688
Epoch 3 [51/172] - loss: 0.1516
Epoch 3 [52/172] - loss: 0.2034
Epoch 3 [53/172] - loss: 0.1453
Epoch 3 [54/172] - loss: 0.1858
Epoch 3 [55/172] - loss: 0.1137
Epoch 3 [56/172] - loss: 0.2087

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.4550, log_difficulty=0.3750, weight=2.8749
neutral: count=3923.0, difficulty=0.3911, log_difficulty=0.3301, weight=2.6506
negative: count=4382.0, difficulty=0.4549, log_difficulty=0.3750, weight=2.8748

当前batch的pt分布：
positive: min=0.2849, max=0.9296, mean=0.6733
neutral: min=0.0074, max=0.9623, mean=0.7045
negative: min=0.5984, max=0.9516, mean=0.8653

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8182
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.4717
焦点损失: 0.1891
边界损失: 0.3125
总损失: 0.4591
Epoch 3 [57/172] - loss: 0.4591
Epoch 3 [58/172] - loss: 0.1694
Epoch 3 [59/172] - loss: 0.3575
Epoch 3 [60/172] - loss: 0.1654, acc: 0.9375
Epoch 3 [61/172] - loss: 0.1704
Epoch 3 [62/172] - loss: 0.1967
Epoch 3 [63/172] - loss: 0.0985
Epoch 3 [64/172] - loss: 0.2436
Epoch 3 [65/172] - loss: 0.1620
Epoch 3 [66/172] - loss: 0.1481
Epoch 3 [67/172] - loss: 0.1890
Epoch 3 [68/172] - loss: 0.1648
Epoch 3 [69/172] - loss: 0.2316
Epoch 3 [70/172] - loss: 0.1080, acc: 0.9375
Epoch 3 [71/172] - loss: 0.0913
Epoch 3 [72/172] - loss: 0.1652
Epoch 3 [73/172] - loss: 0.1066
Epoch 3 [74/172] - loss: 0.1598
Epoch 3 [75/172] - loss: 0.1692
Epoch 3 [76/172] - loss: 0.3042
Epoch 3 [77/172] - loss: 0.1394
Epoch 3 [78/172] - loss: 0.2340
Epoch 3 [79/172] - loss: 0.0875
Epoch 3 [80/172] - loss: 0.2825, acc: 0.9375
Epoch 3 [81/172] - loss: 0.1005
Epoch 3 [82/172] - loss: 0.1882
Epoch 3 [83/172] - loss: 0.1482
Epoch 3 [84/172] - loss: 0.1483
Epoch 3 [85/172] - loss: 0.1275
Epoch 3 [86/172] - loss: 0.1211
Epoch 3 [87/172] - loss: 0.2942
Epoch 3 [88/172] - loss: 0.1976
Epoch 3 [89/172] - loss: 0.0902
Epoch 3 [90/172] - loss: 0.0835, acc: 1.0000
Epoch 3 [91/172] - loss: 0.3212
Epoch 3 [92/172] - loss: 0.2728
Epoch 3 [93/172] - loss: 0.1782
Epoch 3 [94/172] - loss: 0.0901
Epoch 3 [95/172] - loss: 0.0727
Epoch 3 [96/172] - loss: 0.2044
Epoch 3 [97/172] - loss: 0.1170
Epoch 3 [98/172] - loss: 0.1632
Epoch 3 [99/172] - loss: 0.1085
Epoch 3 [100/172] - loss: 0.3212, acc: 0.9062
Epoch 3 [101/172] - loss: 0.3491
Epoch 3 [102/172] - loss: 0.0789
Epoch 3 [103/172] - loss: 0.1437
Epoch 3 [104/172] - loss: 0.0829
Epoch 3 [105/172] - loss: 0.1208
Epoch 3 [106/172] - loss: 0.1197
Epoch 3 [107/172] - loss: 0.0760
Epoch 3 [108/172] - loss: 0.0933
Epoch 3 [109/172] - loss: 0.1268
Epoch 3 [110/172] - loss: 0.2274, acc: 0.9062
Epoch 3 [111/172] - loss: 0.3310
Epoch 3 [112/172] - loss: 0.2194
Epoch 3 [113/172] - loss: 0.0820
Epoch 3 [114/172] - loss: 0.1566
Epoch 3 [115/172] - loss: 0.0820
Epoch 3 [116/172] - loss: 0.1074
Epoch 3 [117/172] - loss: 0.1314
Epoch 3 [118/172] - loss: 0.2119
Epoch 3 [119/172] - loss: 0.2028
Epoch 3 [120/172] - loss: 0.1828, acc: 0.9375
Epoch 3 [121/172] - loss: 0.2400
Epoch 3 [122/172] - loss: 0.1276
Epoch 3 [123/172] - loss: 0.1057
Epoch 3 [124/172] - loss: 0.1756
Epoch 3 [125/172] - loss: 0.1320
Epoch 3 [126/172] - loss: 0.3948
Epoch 3 [127/172] - loss: 0.1548
Epoch 3 [128/172] - loss: 0.0926
Epoch 3 [129/172] - loss: 0.0751
Epoch 3 [130/172] - loss: 0.1232, acc: 0.9375
Epoch 3 [131/172] - loss: 0.1417
Epoch 3 [132/172] - loss: 0.1013
Epoch 3 [133/172] - loss: 0.2526
Epoch 3 [134/172] - loss: 0.0641
Epoch 3 [135/172] - loss: 0.0768
Epoch 3 [136/172] - loss: 0.1918
Epoch 3 [137/172] - loss: 0.0936
Epoch 3 [138/172] - loss: 0.1177
Epoch 3 [139/172] - loss: 0.1676
Epoch 3 [140/172] - loss: 0.1082, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1920
Epoch 3 [142/172] - loss: 0.2928
Epoch 3 [143/172] - loss: 0.1181
Epoch 3 [144/172] - loss: 0.2438
Epoch 3 [145/172] - loss: 0.1395
Epoch 3 [146/172] - loss: 0.1250
Epoch 3 [147/172] - loss: 0.1866
Epoch 3 [148/172] - loss: 0.1570
Epoch 3 [149/172] - loss: 0.3106
Epoch 3 [150/172] - loss: 0.2243, acc: 0.9062
Epoch 3 [151/172] - loss: 0.3288
Epoch 3 [152/172] - loss: 0.2821
Epoch 3 [153/172] - loss: 0.1215
Epoch 3 [154/172] - loss: 0.1652
Epoch 3 [155/172] - loss: 0.0982
Epoch 3 [156/172] - loss: 0.1214

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.4110, log_difficulty=0.3443, weight=2.7215
neutral: count=4903.0, difficulty=0.3430, log_difficulty=0.2949, weight=2.4746
negative: count=5500.0, difficulty=0.4092, log_difficulty=0.3430, weight=2.7150

当前batch的pt分布：
positive: min=0.5846, max=0.9591, mean=0.8205
neutral: min=0.7080, max=0.9952, mean=0.8629
negative: min=0.4323, max=0.8988, mean=0.7323

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.2300
焦点损失: 0.0165
边界损失: 0.2708
总损失: 0.1010
Epoch 3 [157/172] - loss: 0.1010
Epoch 3 [158/172] - loss: 0.1180
Epoch 3 [159/172] - loss: 0.1750
Epoch 3 [160/172] - loss: 0.3762, acc: 0.8438
Epoch 3 [161/172] - loss: 0.4088
Epoch 3 [162/172] - loss: 0.4474
Epoch 3 [163/172] - loss: 0.3823
Epoch 3 [164/172] - loss: 0.0835
Epoch 3 [165/172] - loss: 0.1311
Epoch 3 [166/172] - loss: 0.0947
Epoch 3 [167/172] - loss: 0.1355
Epoch 3 [168/172] - loss: 0.1892
Epoch 3 [169/172] - loss: 0.1408
Epoch 3 [170/172] - loss: 0.2729, acc: 0.8438
Epoch 3 [171/172] - loss: 0.1456
Epoch 3 [172/172] - loss: 0.0981

类别准确率:
positive: 0.8779 (410/467)
neutral: 0.4217 (35/83)
negative: 0.4080 (102/250)

Epoch 3/10
Train Loss: 0.2062, Train Acc: 0.9111
Val Loss: 0.7782, Val Acc: 0.6837
Epoch 4 [1/172] - loss: 0.0722, acc: 1.0000
Epoch 4 [2/172] - loss: 0.0973
Epoch 4 [3/172] - loss: 0.0872
Epoch 4 [4/172] - loss: 0.1048
Epoch 4 [5/172] - loss: 0.0900
Epoch 4 [6/172] - loss: 0.0772
Epoch 4 [7/172] - loss: 0.1288
Epoch 4 [8/172] - loss: 0.0980
Epoch 4 [9/172] - loss: 0.1414
Epoch 4 [10/172] - loss: 0.1471, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0591
Epoch 4 [12/172] - loss: 0.1159
Epoch 4 [13/172] - loss: 0.1868
Epoch 4 [14/172] - loss: 0.0790
Epoch 4 [15/172] - loss: 0.0674
Epoch 4 [16/172] - loss: 0.0792
Epoch 4 [17/172] - loss: 0.0819
Epoch 4 [18/172] - loss: 0.1113
Epoch 4 [19/172] - loss: 0.0631
Epoch 4 [20/172] - loss: 0.0889, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1291
Epoch 4 [22/172] - loss: 0.0660
Epoch 4 [23/172] - loss: 0.1469
Epoch 4 [24/172] - loss: 0.0613
Epoch 4 [25/172] - loss: 0.0838
Epoch 4 [26/172] - loss: 0.1280
Epoch 4 [27/172] - loss: 0.0873
Epoch 4 [28/172] - loss: 0.0725
Epoch 4 [29/172] - loss: 0.0872
Epoch 4 [30/172] - loss: 0.0879, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1314
Epoch 4 [32/172] - loss: 0.1983
Epoch 4 [33/172] - loss: 0.0789
Epoch 4 [34/172] - loss: 0.0681
Epoch 4 [35/172] - loss: 0.1314
Epoch 4 [36/172] - loss: 0.0763
Epoch 4 [37/172] - loss: 0.0556
Epoch 4 [38/172] - loss: 0.0619
Epoch 4 [39/172] - loss: 0.0790
Epoch 4 [40/172] - loss: 0.1785, acc: 0.9062
Epoch 4 [41/172] - loss: 0.0843
Epoch 4 [42/172] - loss: 0.1933
Epoch 4 [43/172] - loss: 0.1311
Epoch 4 [44/172] - loss: 0.0668
Epoch 4 [45/172] - loss: 0.0582
Epoch 4 [46/172] - loss: 0.0632
Epoch 4 [47/172] - loss: 0.0590
Epoch 4 [48/172] - loss: 0.1028
Epoch 4 [49/172] - loss: 0.2233
Epoch 4 [50/172] - loss: 0.2121, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0631
Epoch 4 [52/172] - loss: 0.0926
Epoch 4 [53/172] - loss: 0.0607
Epoch 4 [54/172] - loss: 0.1085
Epoch 4 [55/172] - loss: 0.1900
Epoch 4 [56/172] - loss: 0.1068
Epoch 4 [57/172] - loss: 0.0533
Epoch 4 [58/172] - loss: 0.1147
Epoch 4 [59/172] - loss: 0.0832
Epoch 4 [60/172] - loss: 0.0536, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1396
Epoch 4 [62/172] - loss: 0.1210
Epoch 4 [63/172] - loss: 0.0642
Epoch 4 [64/172] - loss: 0.0655
Epoch 4 [65/172] - loss: 0.0915
Epoch 4 [66/172] - loss: 0.0625
Epoch 4 [67/172] - loss: 0.0606
Epoch 4 [68/172] - loss: 0.0948
Epoch 4 [69/172] - loss: 0.1336
Epoch 4 [70/172] - loss: 0.0986, acc: 0.9688
Epoch 4 [71/172] - loss: 0.0888
Epoch 4 [72/172] - loss: 0.0576
Epoch 4 [73/172] - loss: 0.1102
Epoch 4 [74/172] - loss: 0.2787
Epoch 4 [75/172] - loss: 0.0624
Epoch 4 [76/172] - loss: 0.0540
Epoch 4 [77/172] - loss: 0.0738
Epoch 4 [78/172] - loss: 0.0660
Epoch 4 [79/172] - loss: 0.0850
Epoch 4 [80/172] - loss: 0.0660, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1143
Epoch 4 [82/172] - loss: 0.0745
Epoch 4 [83/172] - loss: 0.1041
Epoch 4 [84/172] - loss: 0.0966

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3733, log_difficulty=0.3172, weight=2.5861
neutral: count=5865.0, difficulty=0.3057, log_difficulty=0.2667, weight=2.3336
negative: count=6629.0, difficulty=0.3715, log_difficulty=0.3159, weight=2.5796

当前batch的pt分布：
positive: min=0.5253, max=0.9510, mean=0.8103
neutral: min=0.9267, max=0.9964, mean=0.9776
negative: min=0.6739, max=0.9790, mean=0.8852

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1515
焦点损失: 0.0070
边界损失: 0.2137
总损失: 0.0671
Epoch 4 [85/172] - loss: 0.0671
Epoch 4 [86/172] - loss: 0.0803
Epoch 4 [87/172] - loss: 0.0738
Epoch 4 [88/172] - loss: 0.0866
Epoch 4 [89/172] - loss: 0.0614
Epoch 4 [90/172] - loss: 0.0763, acc: 0.9688
Epoch 4 [91/172] - loss: 0.2740
Epoch 4 [92/172] - loss: 0.1662
Epoch 4 [93/172] - loss: 0.0751
Epoch 4 [94/172] - loss: 0.0484
Epoch 4 [95/172] - loss: 0.1607
Epoch 4 [96/172] - loss: 0.1296
Epoch 4 [97/172] - loss: 0.0632
Epoch 4 [98/172] - loss: 0.0563
Epoch 4 [99/172] - loss: 0.0677
Epoch 4 [100/172] - loss: 0.1315, acc: 0.9375
Epoch 4 [101/172] - loss: 0.0560
Epoch 4 [102/172] - loss: 0.1971
Epoch 4 [103/172] - loss: 0.1820
Epoch 4 [104/172] - loss: 0.0617
Epoch 4 [105/172] - loss: 0.3200
Epoch 4 [106/172] - loss: 0.0636
Epoch 4 [107/172] - loss: 0.0499
Epoch 4 [108/172] - loss: 0.0610
Epoch 4 [109/172] - loss: 0.0793
Epoch 4 [110/172] - loss: 0.2259, acc: 0.8438
Epoch 4 [111/172] - loss: 0.1332
Epoch 4 [112/172] - loss: 0.0806
Epoch 4 [113/172] - loss: 0.1035
Epoch 4 [114/172] - loss: 0.0662
Epoch 4 [115/172] - loss: 0.1299
Epoch 4 [116/172] - loss: 0.0572
Epoch 4 [117/172] - loss: 0.0594
Epoch 4 [118/172] - loss: 0.0937
Epoch 4 [119/172] - loss: 0.0772
Epoch 4 [120/172] - loss: 0.0596, acc: 1.0000
Epoch 4 [121/172] - loss: 0.0798
Epoch 4 [122/172] - loss: 0.0823
Epoch 4 [123/172] - loss: 0.0709
Epoch 4 [124/172] - loss: 0.0856
Epoch 4 [125/172] - loss: 0.1062
Epoch 4 [126/172] - loss: 0.3157
Epoch 4 [127/172] - loss: 0.1316
Epoch 4 [128/172] - loss: 0.1087
Epoch 4 [129/172] - loss: 0.1045
Epoch 4 [130/172] - loss: 0.0672, acc: 0.9688
Epoch 4 [131/172] - loss: 0.0505
Epoch 4 [132/172] - loss: 0.0547
Epoch 4 [133/172] - loss: 0.0575
Epoch 4 [134/172] - loss: 0.0638
Epoch 4 [135/172] - loss: 0.0984
Epoch 4 [136/172] - loss: 0.0820
Epoch 4 [137/172] - loss: 0.1368
Epoch 4 [138/172] - loss: 0.0590
Epoch 4 [139/172] - loss: 0.0950
Epoch 4 [140/172] - loss: 0.0954, acc: 0.9375
Epoch 4 [141/172] - loss: 0.1670
Epoch 4 [142/172] - loss: 0.0613
Epoch 4 [143/172] - loss: 0.0746
Epoch 4 [144/172] - loss: 0.0571
Epoch 4 [145/172] - loss: 0.1008
Epoch 4 [146/172] - loss: 0.0696
Epoch 4 [147/172] - loss: 0.0655
Epoch 4 [148/172] - loss: 0.0647
Epoch 4 [149/172] - loss: 0.1334
Epoch 4 [150/172] - loss: 0.1640, acc: 0.9062
Epoch 4 [151/172] - loss: 0.1362
Epoch 4 [152/172] - loss: 0.0605
Epoch 4 [153/172] - loss: 0.0521
Epoch 4 [154/172] - loss: 0.1812
Epoch 4 [155/172] - loss: 0.0848
Epoch 4 [156/172] - loss: 0.0842
Epoch 4 [157/172] - loss: 0.2045
Epoch 4 [158/172] - loss: 0.0552
Epoch 4 [159/172] - loss: 0.0519
Epoch 4 [160/172] - loss: 0.2090, acc: 0.8750
Epoch 4 [161/172] - loss: 0.0919
Epoch 4 [162/172] - loss: 0.0728
Epoch 4 [163/172] - loss: 0.0877
Epoch 4 [164/172] - loss: 0.0742
Epoch 4 [165/172] - loss: 0.1106
Epoch 4 [166/172] - loss: 0.0612
Epoch 4 [167/172] - loss: 0.1328
Epoch 4 [168/172] - loss: 0.0670
Epoch 4 [169/172] - loss: 0.2680
Epoch 4 [170/172] - loss: 0.1436, acc: 0.9375
Epoch 4 [171/172] - loss: 0.0956
Epoch 4 [172/172] - loss: 0.0683

类别准确率:
positive: 0.8501 (397/467)
neutral: 0.2048 (17/83)
negative: 0.5960 (149/250)

Epoch 4/10
Train Loss: 0.1121, Train Acc: 0.9596
Val Loss: 0.7576, Val Acc: 0.7037
Epoch 5 [1/172] - loss: 0.0517, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0976
Epoch 5 [3/172] - loss: 0.0623
Epoch 5 [4/172] - loss: 0.0876
Epoch 5 [5/172] - loss: 0.0770
Epoch 5 [6/172] - loss: 0.1406
Epoch 5 [7/172] - loss: 0.0720
Epoch 5 [8/172] - loss: 0.1273
Epoch 5 [9/172] - loss: 0.1526
Epoch 5 [10/172] - loss: 0.0588, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1085
Epoch 5 [12/172] - loss: 0.0809

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.3402, log_difficulty=0.2928, weight=2.4641
neutral: count=6845.0, difficulty=0.2761, log_difficulty=0.2438, weight=2.2189
negative: count=7694.0, difficulty=0.3423, log_difficulty=0.2944, weight=2.4719

当前batch的pt分布：
positive: min=0.2800, max=0.9802, mean=0.8093
neutral: min=0.9424, max=0.9974, mean=0.9794
negative: min=0.7660, max=0.9614, mean=0.8979

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1505
焦点损失: 0.0207
边界损失: 0.2003
总损失: 0.0882
Epoch 5 [13/172] - loss: 0.0882
Epoch 5 [14/172] - loss: 0.1202
Epoch 5 [15/172] - loss: 0.0537
Epoch 5 [16/172] - loss: 0.0483
Epoch 5 [17/172] - loss: 0.0835
Epoch 5 [18/172] - loss: 0.0518
Epoch 5 [19/172] - loss: 0.1402
Epoch 5 [20/172] - loss: 0.0748, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1031
Epoch 5 [22/172] - loss: 0.2533
Epoch 5 [23/172] - loss: 0.0480
Epoch 5 [24/172] - loss: 0.0651
Epoch 5 [25/172] - loss: 0.0479
Epoch 5 [26/172] - loss: 0.2125
Epoch 5 [27/172] - loss: 0.0506
Epoch 5 [28/172] - loss: 0.0613
Epoch 5 [29/172] - loss: 0.0496
Epoch 5 [30/172] - loss: 0.0579, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0877
Epoch 5 [32/172] - loss: 0.0487
Epoch 5 [33/172] - loss: 0.1231
Epoch 5 [34/172] - loss: 0.0567
Epoch 5 [35/172] - loss: 0.0480
Epoch 5 [36/172] - loss: 0.0457
Epoch 5 [37/172] - loss: 0.0647
Epoch 5 [38/172] - loss: 0.0518
Epoch 5 [39/172] - loss: 0.1993
Epoch 5 [40/172] - loss: 0.0679, acc: 0.9688
Epoch 5 [41/172] - loss: 0.0480
Epoch 5 [42/172] - loss: 0.0771
Epoch 5 [43/172] - loss: 0.0728
Epoch 5 [44/172] - loss: 0.0728
Epoch 5 [45/172] - loss: 0.0632
Epoch 5 [46/172] - loss: 0.1123
Epoch 5 [47/172] - loss: 0.0434
Epoch 5 [48/172] - loss: 0.1163
Epoch 5 [49/172] - loss: 0.0894
Epoch 5 [50/172] - loss: 0.1257, acc: 0.9688
Epoch 5 [51/172] - loss: 0.1127
Epoch 5 [52/172] - loss: 0.0472
Epoch 5 [53/172] - loss: 0.0670
Epoch 5 [54/172] - loss: 0.0629
Epoch 5 [55/172] - loss: 0.0623
Epoch 5 [56/172] - loss: 0.0748
Epoch 5 [57/172] - loss: 0.1818
Epoch 5 [58/172] - loss: 0.0546
Epoch 5 [59/172] - loss: 0.0844
Epoch 5 [60/172] - loss: 0.0505, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0738
Epoch 5 [62/172] - loss: 0.0583
Epoch 5 [63/172] - loss: 0.1680
Epoch 5 [64/172] - loss: 0.0593
Epoch 5 [65/172] - loss: 0.0543
Epoch 5 [66/172] - loss: 0.0563
Epoch 5 [67/172] - loss: 0.0445
Epoch 5 [68/172] - loss: 0.0783
Epoch 5 [69/172] - loss: 0.0562
Epoch 5 [70/172] - loss: 0.0482, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0820
Epoch 5 [72/172] - loss: 0.0883
Epoch 5 [73/172] - loss: 0.1113
Epoch 5 [74/172] - loss: 0.1021
Epoch 5 [75/172] - loss: 0.0439
Epoch 5 [76/172] - loss: 0.0450
Epoch 5 [77/172] - loss: 0.0450
Epoch 5 [78/172] - loss: 0.1030
Epoch 5 [79/172] - loss: 0.0474
Epoch 5 [80/172] - loss: 0.0441, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1316
Epoch 5 [82/172] - loss: 0.1814
Epoch 5 [83/172] - loss: 0.0476
Epoch 5 [84/172] - loss: 0.0425
Epoch 5 [85/172] - loss: 0.1055
Epoch 5 [86/172] - loss: 0.0842
Epoch 5 [87/172] - loss: 0.1159
Epoch 5 [88/172] - loss: 0.0575
Epoch 5 [89/172] - loss: 0.0566
Epoch 5 [90/172] - loss: 0.0688, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1510
Epoch 5 [92/172] - loss: 0.0712
Epoch 5 [93/172] - loss: 0.2043
Epoch 5 [94/172] - loss: 0.0476
Epoch 5 [95/172] - loss: 0.0577
Epoch 5 [96/172] - loss: 0.1976
Epoch 5 [97/172] - loss: 0.0623
Epoch 5 [98/172] - loss: 0.0477
Epoch 5 [99/172] - loss: 0.0635
Epoch 5 [100/172] - loss: 0.0516, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0752
Epoch 5 [102/172] - loss: 0.0588
Epoch 5 [103/172] - loss: 0.0613
Epoch 5 [104/172] - loss: 0.1219
Epoch 5 [105/172] - loss: 0.2209
Epoch 5 [106/172] - loss: 0.0593
Epoch 5 [107/172] - loss: 0.0619
Epoch 5 [108/172] - loss: 0.0895
Epoch 5 [109/172] - loss: 0.0480
Epoch 5 [110/172] - loss: 0.0568, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0680
Epoch 5 [112/172] - loss: 0.0561

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.3110, log_difficulty=0.2708, weight=2.3540
neutral: count=7825.0, difficulty=0.2520, log_difficulty=0.2247, weight=2.1236
negative: count=8780.0, difficulty=0.3162, log_difficulty=0.2747, weight=2.3737

当前batch的pt分布：
positive: min=0.4565, max=0.9685, mean=0.8128
neutral: min=0.6425, max=0.9846, mean=0.8832
negative: min=0.9575, max=0.9956, mean=0.9712

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1670
焦点损失: 0.0179
边界损失: 0.2226
总损失: 0.0869
Epoch 5 [113/172] - loss: 0.0869
Epoch 5 [114/172] - loss: 0.2124
Epoch 5 [115/172] - loss: 0.0975
Epoch 5 [116/172] - loss: 0.0439
Epoch 5 [117/172] - loss: 0.1294
Epoch 5 [118/172] - loss: 0.0657
Epoch 5 [119/172] - loss: 0.0737
Epoch 5 [120/172] - loss: 0.2081, acc: 0.9688
Epoch 5 [121/172] - loss: 0.0592
Epoch 5 [122/172] - loss: 0.0592
Epoch 5 [123/172] - loss: 0.0656
Epoch 5 [124/172] - loss: 0.0622
Epoch 5 [125/172] - loss: 0.0738
Epoch 5 [126/172] - loss: 0.0577
Epoch 5 [127/172] - loss: 0.1585
Epoch 5 [128/172] - loss: 0.0850
Epoch 5 [129/172] - loss: 0.0687
Epoch 5 [130/172] - loss: 0.0509, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0504
Epoch 5 [132/172] - loss: 0.1157
Epoch 5 [133/172] - loss: 0.1261
Epoch 5 [134/172] - loss: 0.1332
Epoch 5 [135/172] - loss: 0.0572
Epoch 5 [136/172] - loss: 0.0625
Epoch 5 [137/172] - loss: 0.0722
Epoch 5 [138/172] - loss: 0.1372
Epoch 5 [139/172] - loss: 0.1669
Epoch 5 [140/172] - loss: 0.0935, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0514
Epoch 5 [142/172] - loss: 0.0756
Epoch 5 [143/172] - loss: 0.0503
Epoch 5 [144/172] - loss: 0.0611
Epoch 5 [145/172] - loss: 0.0653
Epoch 5 [146/172] - loss: 0.0604
Epoch 5 [147/172] - loss: 0.0755
Epoch 5 [148/172] - loss: 0.0462
Epoch 5 [149/172] - loss: 0.1006
Epoch 5 [150/172] - loss: 0.0562, acc: 1.0000
Epoch 5 [151/172] - loss: 0.0594
Epoch 5 [152/172] - loss: 0.0565
Epoch 5 [153/172] - loss: 0.0724
Epoch 5 [154/172] - loss: 0.0752
Epoch 5 [155/172] - loss: 0.0435
Epoch 5 [156/172] - loss: 0.0610
Epoch 5 [157/172] - loss: 0.0610
Epoch 5 [158/172] - loss: 0.0447
Epoch 5 [159/172] - loss: 0.0465
Epoch 5 [160/172] - loss: 0.0505, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0708
Epoch 5 [162/172] - loss: 0.0675
Epoch 5 [163/172] - loss: 0.1111
Epoch 5 [164/172] - loss: 0.0482
Epoch 5 [165/172] - loss: 0.0976
Epoch 5 [166/172] - loss: 0.1098
Epoch 5 [167/172] - loss: 0.1539
Epoch 5 [168/172] - loss: 0.0456
Epoch 5 [169/172] - loss: 0.0534
Epoch 5 [170/172] - loss: 0.0731, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1090
Epoch 5 [172/172] - loss: 0.0763

类别准确率:
positive: 0.8630 (403/467)
neutral: 0.2530 (21/83)
negative: 0.5280 (132/250)

Epoch 5/10
Train Loss: 0.0762, Train Acc: 0.9778
Val Loss: 0.8476, Val Acc: 0.6950
Epoch 6 [1/172] - loss: 0.0640, acc: 1.0000
Epoch 6 [2/172] - loss: 0.0573
Epoch 6 [3/172] - loss: 0.0418
Epoch 6 [4/172] - loss: 0.0541
Epoch 6 [5/172] - loss: 0.0978
Epoch 6 [6/172] - loss: 0.0558
Epoch 6 [7/172] - loss: 0.0833
Epoch 6 [8/172] - loss: 0.0768
Epoch 6 [9/172] - loss: 0.0516
Epoch 6 [10/172] - loss: 0.0488, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0458
Epoch 6 [12/172] - loss: 0.0558
Epoch 6 [13/172] - loss: 0.0553
Epoch 6 [14/172] - loss: 0.0409
Epoch 6 [15/172] - loss: 0.0563
Epoch 6 [16/172] - loss: 0.1662
Epoch 6 [17/172] - loss: 0.0547
Epoch 6 [18/172] - loss: 0.0533
Epoch 6 [19/172] - loss: 0.0743
Epoch 6 [20/172] - loss: 0.0503, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0477
Epoch 6 [22/172] - loss: 0.0483
Epoch 6 [23/172] - loss: 0.0461
Epoch 6 [24/172] - loss: 0.0517
Epoch 6 [25/172] - loss: 0.0649
Epoch 6 [26/172] - loss: 0.0754
Epoch 6 [27/172] - loss: 0.1294
Epoch 6 [28/172] - loss: 0.0445
Epoch 6 [29/172] - loss: 0.0589
Epoch 6 [30/172] - loss: 0.0419, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0591
Epoch 6 [32/172] - loss: 0.0430
Epoch 6 [33/172] - loss: 0.0456
Epoch 6 [34/172] - loss: 0.0463
Epoch 6 [35/172] - loss: 0.0533
Epoch 6 [36/172] - loss: 0.0536
Epoch 6 [37/172] - loss: 0.0466
Epoch 6 [38/172] - loss: 0.0453
Epoch 6 [39/172] - loss: 0.0492
Epoch 6 [40/172] - loss: 0.0455, acc: 1.0000

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2880, log_difficulty=0.2531, weight=2.2655
neutral: count=8815.0, difficulty=0.2333, log_difficulty=0.2097, weight=2.0484
negative: count=9870.0, difficulty=0.2935, log_difficulty=0.2574, weight=2.2869

当前batch的pt分布：
positive: min=0.2828, max=0.9946, mean=0.8859
neutral: min=0.8814, max=0.9899, mean=0.9596
negative: min=0.7398, max=0.9608, mean=0.9241

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0993
焦点损失: 0.0200
边界损失: 0.1706
总损失: 0.0766
Epoch 6 [41/172] - loss: 0.0766
Epoch 6 [42/172] - loss: 0.0436
Epoch 6 [43/172] - loss: 0.1687
Epoch 6 [44/172] - loss: 0.0419
Epoch 6 [45/172] - loss: 0.0594
Epoch 6 [46/172] - loss: 0.0523
Epoch 6 [47/172] - loss: 0.0501
Epoch 6 [48/172] - loss: 0.0424
Epoch 6 [49/172] - loss: 0.0434
Epoch 6 [50/172] - loss: 0.0570, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0678
Epoch 6 [52/172] - loss: 0.0507
Epoch 6 [53/172] - loss: 0.0552
Epoch 6 [54/172] - loss: 0.1404
Epoch 6 [55/172] - loss: 0.0507
Epoch 6 [56/172] - loss: 0.0827
Epoch 6 [57/172] - loss: 0.0475
Epoch 6 [58/172] - loss: 0.0472
Epoch 6 [59/172] - loss: 0.1136
Epoch 6 [60/172] - loss: 0.0655, acc: 1.0000
Epoch 6 [61/172] - loss: 0.0403
Epoch 6 [62/172] - loss: 0.0489
Epoch 6 [63/172] - loss: 0.0716
Epoch 6 [64/172] - loss: 0.2530
Epoch 6 [65/172] - loss: 0.0595
Epoch 6 [66/172] - loss: 0.0815
Epoch 6 [67/172] - loss: 0.1350
Epoch 6 [68/172] - loss: 0.0648
Epoch 6 [69/172] - loss: 0.2999
Epoch 6 [70/172] - loss: 0.0413, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0429
Epoch 6 [72/172] - loss: 0.1183
Epoch 6 [73/172] - loss: 0.1900
Epoch 6 [74/172] - loss: 0.0585
Epoch 6 [75/172] - loss: 0.0671
Epoch 6 [76/172] - loss: 0.0560
Epoch 6 [77/172] - loss: 0.1345
Epoch 6 [78/172] - loss: 0.1637
Epoch 6 [79/172] - loss: 0.0469
Epoch 6 [80/172] - loss: 0.0646, acc: 1.0000
Epoch 6 [81/172] - loss: 0.0598
Epoch 6 [82/172] - loss: 0.0687
Epoch 6 [83/172] - loss: 0.0906
Epoch 6 [84/172] - loss: 0.0751
Epoch 6 [85/172] - loss: 0.0550
Epoch 6 [86/172] - loss: 0.0786
Epoch 6 [87/172] - loss: 0.0535
Epoch 6 [88/172] - loss: 0.0989
Epoch 6 [89/172] - loss: 0.0622
Epoch 6 [90/172] - loss: 0.0469, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0455
Epoch 6 [92/172] - loss: 0.0502
Epoch 6 [93/172] - loss: 0.0586
Epoch 6 [94/172] - loss: 0.0649
Epoch 6 [95/172] - loss: 0.1217
Epoch 6 [96/172] - loss: 0.0516
Epoch 6 [97/172] - loss: 0.0442
Epoch 6 [98/172] - loss: 0.0828
Epoch 6 [99/172] - loss: 0.0626
Epoch 6 [100/172] - loss: 0.0484, acc: 1.0000
Epoch 6 [101/172] - loss: 0.0862
Epoch 6 [102/172] - loss: 0.0443
Epoch 6 [103/172] - loss: 0.0476
Epoch 6 [104/172] - loss: 0.0762
Epoch 6 [105/172] - loss: 0.0637
Epoch 6 [106/172] - loss: 0.0723
Epoch 6 [107/172] - loss: 0.0502
Epoch 6 [108/172] - loss: 0.0468
Epoch 6 [109/172] - loss: 0.1728
Epoch 6 [110/172] - loss: 0.0532, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0459
Epoch 6 [112/172] - loss: 0.0421
Epoch 6 [113/172] - loss: 0.1350
Epoch 6 [114/172] - loss: 0.0420
Epoch 6 [115/172] - loss: 0.1128
Epoch 6 [116/172] - loss: 0.2047
Epoch 6 [117/172] - loss: 0.0633
Epoch 6 [118/172] - loss: 0.0438
Epoch 6 [119/172] - loss: 0.1058
Epoch 6 [120/172] - loss: 0.1993, acc: 0.9375
Epoch 6 [121/172] - loss: 0.0675
Epoch 6 [122/172] - loss: 0.0895
Epoch 6 [123/172] - loss: 0.0416
Epoch 6 [124/172] - loss: 0.0552
Epoch 6 [125/172] - loss: 0.0526
Epoch 6 [126/172] - loss: 0.1791
Epoch 6 [127/172] - loss: 0.1494
Epoch 6 [128/172] - loss: 0.0972
Epoch 6 [129/172] - loss: 0.0587
Epoch 6 [130/172] - loss: 0.1196, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1755
Epoch 6 [132/172] - loss: 0.1201
Epoch 6 [133/172] - loss: 0.0492
Epoch 6 [134/172] - loss: 0.0559
Epoch 6 [135/172] - loss: 0.1189
Epoch 6 [136/172] - loss: 0.0681
Epoch 6 [137/172] - loss: 0.0574
Epoch 6 [138/172] - loss: 0.1464
Epoch 6 [139/172] - loss: 0.0664
Epoch 6 [140/172] - loss: 0.0495, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2690, log_difficulty=0.2382, weight=2.1912
neutral: count=9796.0, difficulty=0.2190, log_difficulty=0.1980, weight=1.9902
negative: count=10972.0, difficulty=0.2735, log_difficulty=0.2417, weight=2.2087

当前batch的pt分布：
positive: min=0.8526, max=0.9962, mean=0.9589
neutral: min=0.9255, max=0.9783, mean=0.9524
negative: min=0.6440, max=0.9811, mean=0.8978

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0741
焦点损失: 0.0023
边界损失: 0.1720
总损失: 0.0467
Epoch 6 [141/172] - loss: 0.0467
Epoch 6 [142/172] - loss: 0.0464
Epoch 6 [143/172] - loss: 0.0715
Epoch 6 [144/172] - loss: 0.0618
Epoch 6 [145/172] - loss: 0.0453
Epoch 6 [146/172] - loss: 0.0482
Epoch 6 [147/172] - loss: 0.0575
Epoch 6 [148/172] - loss: 0.0855
Epoch 6 [149/172] - loss: 0.0450
Epoch 6 [150/172] - loss: 0.0421, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0759
Epoch 6 [152/172] - loss: 0.0628
Epoch 6 [153/172] - loss: 0.0496
Epoch 6 [154/172] - loss: 0.0581
Epoch 6 [155/172] - loss: 0.0555
Epoch 6 [156/172] - loss: 0.0559
Epoch 6 [157/172] - loss: 0.0570
Epoch 6 [158/172] - loss: 0.0508
Epoch 6 [159/172] - loss: 0.0652
Epoch 6 [160/172] - loss: 0.1015, acc: 0.9375
Epoch 6 [161/172] - loss: 0.1116
Epoch 6 [162/172] - loss: 0.0450
Epoch 6 [163/172] - loss: 0.0460
Epoch 6 [164/172] - loss: 0.0665
Epoch 6 [165/172] - loss: 0.2913
Epoch 6 [166/172] - loss: 0.0668
Epoch 6 [167/172] - loss: 0.0557
Epoch 6 [168/172] - loss: 0.0816
Epoch 6 [169/172] - loss: 0.1836
Epoch 6 [170/172] - loss: 0.0428, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0763
Epoch 6 [172/172] - loss: 0.0849

类别准确率:
positive: 0.7944 (371/467)
neutral: 0.3614 (30/83)
negative: 0.5800 (145/250)

Epoch 6/10
Train Loss: 0.0892, Train Acc: 0.9758
Val Loss: 0.8289, Val Acc: 0.6825
Epoch 7 [1/172] - loss: 0.0534, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0447
Epoch 7 [3/172] - loss: 0.0470
Epoch 7 [4/172] - loss: 0.0654
Epoch 7 [5/172] - loss: 0.0447
Epoch 7 [6/172] - loss: 0.0430
Epoch 7 [7/172] - loss: 0.0587
Epoch 7 [8/172] - loss: 0.1674
Epoch 7 [9/172] - loss: 0.0441
Epoch 7 [10/172] - loss: 0.0423, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0551
Epoch 7 [12/172] - loss: 0.1152
Epoch 7 [13/172] - loss: 0.0521
Epoch 7 [14/172] - loss: 0.0445
Epoch 7 [15/172] - loss: 0.1810
Epoch 7 [16/172] - loss: 0.0577
Epoch 7 [17/172] - loss: 0.0945
Epoch 7 [18/172] - loss: 0.0512
Epoch 7 [19/172] - loss: 0.0448
Epoch 7 [20/172] - loss: 0.0430, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0663
Epoch 7 [22/172] - loss: 0.0435
Epoch 7 [23/172] - loss: 0.0788
Epoch 7 [24/172] - loss: 0.0496
Epoch 7 [25/172] - loss: 0.0561
Epoch 7 [26/172] - loss: 0.0837
Epoch 7 [27/172] - loss: 0.0562
Epoch 7 [28/172] - loss: 0.0734
Epoch 7 [29/172] - loss: 0.0527
Epoch 7 [30/172] - loss: 0.1028, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0487
Epoch 7 [32/172] - loss: 0.0445
Epoch 7 [33/172] - loss: 0.0510
Epoch 7 [34/172] - loss: 0.0638
Epoch 7 [35/172] - loss: 0.0504
Epoch 7 [36/172] - loss: 0.2113
Epoch 7 [37/172] - loss: 0.0441
Epoch 7 [38/172] - loss: 0.0476
Epoch 7 [39/172] - loss: 0.0463
Epoch 7 [40/172] - loss: 0.0443, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0419
Epoch 7 [42/172] - loss: 0.0455
Epoch 7 [43/172] - loss: 0.0465
Epoch 7 [44/172] - loss: 0.0604
Epoch 7 [45/172] - loss: 0.0456
Epoch 7 [46/172] - loss: 0.0707
Epoch 7 [47/172] - loss: 0.0704
Epoch 7 [48/172] - loss: 0.0424
Epoch 7 [49/172] - loss: 0.0419
Epoch 7 [50/172] - loss: 0.0416, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1039
Epoch 7 [52/172] - loss: 0.0472
Epoch 7 [53/172] - loss: 0.1193
Epoch 7 [54/172] - loss: 0.0589
Epoch 7 [55/172] - loss: 0.0486
Epoch 7 [56/172] - loss: 0.1082
Epoch 7 [57/172] - loss: 0.1552
Epoch 7 [58/172] - loss: 0.0849
Epoch 7 [59/172] - loss: 0.0465
Epoch 7 [60/172] - loss: 0.0700, acc: 0.9688
Epoch 7 [61/172] - loss: 0.0629
Epoch 7 [62/172] - loss: 0.0661
Epoch 7 [63/172] - loss: 0.1345
Epoch 7 [64/172] - loss: 0.0484
Epoch 7 [65/172] - loss: 0.0609
Epoch 7 [66/172] - loss: 0.0493
Epoch 7 [67/172] - loss: 0.0685
Epoch 7 [68/172] - loss: 0.0723

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.2534, log_difficulty=0.2259, weight=2.1293
neutral: count=10756.0, difficulty=0.2062, log_difficulty=0.1875, weight=1.9374
negative: count=12072.0, difficulty=0.2568, log_difficulty=0.2286, weight=2.1428

当前batch的pt分布：
positive: min=0.7818, max=0.9913, mean=0.9467
neutral: min=0.9675, max=0.9849, mean=0.9755
negative: min=0.7798, max=0.9679, mean=0.9043

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0689
焦点损失: 0.0010
边界损失: 0.1692
总损失: 0.0439
Epoch 7 [69/172] - loss: 0.0439
Epoch 7 [70/172] - loss: 0.0616, acc: 0.9688
Epoch 7 [71/172] - loss: 0.0553
Epoch 7 [72/172] - loss: 0.0539
Epoch 7 [73/172] - loss: 0.0620
Epoch 7 [74/172] - loss: 0.0452
Epoch 7 [75/172] - loss: 0.0425
Epoch 7 [76/172] - loss: 0.0466
Epoch 7 [77/172] - loss: 0.0449
Epoch 7 [78/172] - loss: 0.0427
Epoch 7 [79/172] - loss: 0.0599
Epoch 7 [80/172] - loss: 0.0762, acc: 0.9375
Epoch 7 [81/172] - loss: 0.0428
Epoch 7 [82/172] - loss: 0.0498
Epoch 7 [83/172] - loss: 0.0701
Epoch 7 [84/172] - loss: 0.0480
Epoch 7 [85/172] - loss: 0.0506
Epoch 7 [86/172] - loss: 0.0506
Epoch 7 [87/172] - loss: 0.0448
Epoch 7 [88/172] - loss: 0.0496
Epoch 7 [89/172] - loss: 0.0504
Epoch 7 [90/172] - loss: 0.0514, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0430
Epoch 7 [92/172] - loss: 0.0739
Epoch 7 [93/172] - loss: 0.0530
Epoch 7 [94/172] - loss: 0.0489
Epoch 7 [95/172] - loss: 0.0426
Epoch 7 [96/172] - loss: 0.0563
Epoch 7 [97/172] - loss: 0.0476
Epoch 7 [98/172] - loss: 0.0789
Epoch 7 [99/172] - loss: 0.0495
Epoch 7 [100/172] - loss: 0.0430, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0433
Epoch 7 [102/172] - loss: 0.0423
Epoch 7 [103/172] - loss: 0.0569
Epoch 7 [104/172] - loss: 0.0402
Epoch 7 [105/172] - loss: 0.0539
Epoch 7 [106/172] - loss: 0.0662
Epoch 7 [107/172] - loss: 0.0452
Epoch 7 [108/172] - loss: 0.0443
Epoch 7 [109/172] - loss: 0.0552
Epoch 7 [110/172] - loss: 0.0725, acc: 0.9688
Epoch 7 [111/172] - loss: 0.0479
Epoch 7 [112/172] - loss: 0.0468
Epoch 7 [113/172] - loss: 0.0409
Epoch 7 [114/172] - loss: 0.0422
Epoch 7 [115/172] - loss: 0.0416
Epoch 7 [116/172] - loss: 0.1108
Epoch 7 [117/172] - loss: 0.0556
Epoch 7 [118/172] - loss: 0.0469
Epoch 7 [119/172] - loss: 0.0443
Epoch 7 [120/172] - loss: 0.0526, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0480
Epoch 7 [122/172] - loss: 0.0627
Epoch 7 [123/172] - loss: 0.0430
Epoch 7 [124/172] - loss: 0.0695
Epoch 7 [125/172] - loss: 0.0403
Epoch 7 [126/172] - loss: 0.0433
Epoch 7 [127/172] - loss: 0.0472
Epoch 7 [128/172] - loss: 0.0455
Epoch 7 [129/172] - loss: 0.0453
Epoch 7 [130/172] - loss: 0.0478, acc: 1.0000
Epoch 7 [131/172] - loss: 0.0827
Epoch 7 [132/172] - loss: 0.0912
Epoch 7 [133/172] - loss: 0.0412
Epoch 7 [134/172] - loss: 0.0604
Epoch 7 [135/172] - loss: 0.0509
Epoch 7 [136/172] - loss: 0.0590
Epoch 7 [137/172] - loss: 0.0546
Epoch 7 [138/172] - loss: 0.0385
Epoch 7 [139/172] - loss: 0.0850
Epoch 7 [140/172] - loss: 0.0586, acc: 0.9688
Epoch 7 [141/172] - loss: 0.1067
Epoch 7 [142/172] - loss: 0.0551
Epoch 7 [143/172] - loss: 0.0598
Epoch 7 [144/172] - loss: 0.0427
Epoch 7 [145/172] - loss: 0.0730
Epoch 7 [146/172] - loss: 0.0822
Epoch 7 [147/172] - loss: 0.0461
Epoch 7 [148/172] - loss: 0.0574
Epoch 7 [149/172] - loss: 0.0701
Epoch 7 [150/172] - loss: 0.0441, acc: 1.0000
Epoch 7 [151/172] - loss: 0.0842
Epoch 7 [152/172] - loss: 0.0413
Epoch 7 [153/172] - loss: 0.0454
Epoch 7 [154/172] - loss: 0.0584
Epoch 7 [155/172] - loss: 0.0544
Epoch 7 [156/172] - loss: 0.1847
Epoch 7 [157/172] - loss: 0.0508
Epoch 7 [158/172] - loss: 0.0776
Epoch 7 [159/172] - loss: 0.0414
Epoch 7 [160/172] - loss: 0.0510, acc: 1.0000
Epoch 7 [161/172] - loss: 0.0462
Epoch 7 [162/172] - loss: 0.0508
Epoch 7 [163/172] - loss: 0.0674
Epoch 7 [164/172] - loss: 0.0587
Epoch 7 [165/172] - loss: 0.0819
Epoch 7 [166/172] - loss: 0.0551
Epoch 7 [167/172] - loss: 0.0540
Epoch 7 [168/172] - loss: 0.0533

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.2386, log_difficulty=0.2140, weight=2.0700
neutral: count=11731.0, difficulty=0.1948, log_difficulty=0.1780, weight=1.8900
negative: count=13173.0, difficulty=0.2425, log_difficulty=0.2171, weight=2.0857

当前batch的pt分布：
positive: min=0.8827, max=0.9863, mean=0.9528
neutral: min=0.9594, max=0.9874, mean=0.9748
negative: min=0.7446, max=0.9827, mean=0.9164

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0578
焦点损失: 0.0008
边界损失: 0.1641
总损失: 0.0422
Epoch 7 [169/172] - loss: 0.0422
Epoch 7 [170/172] - loss: 0.0730, acc: 0.9688
Epoch 7 [171/172] - loss: 0.0429
Epoch 7 [172/172] - loss: 0.0404

类别准确率:
positive: 0.7966 (372/467)
neutral: 0.3373 (28/83)
negative: 0.6120 (153/250)

Epoch 7/10
Train Loss: 0.0554, Train Acc: 0.9919
Val Loss: 0.8545, Val Acc: 0.6913
Early stopping triggered!
Best validation accuracy: 0.7037

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_122214-2fhtakpr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.35_Multimodal_iterations_20250118_122213
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/2fhtakpr
wandb: uploading wandb-summary.json; uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:  train_acc ▁▂▃▁▂▃▅▆▅▅▇▇▆▇▇█▇▇█▇███▇████████████▇███
wandb: train_loss █▇▆▆▅▃▄▃▃▄▂▂▃▃▃▂▁▂▂▁▁▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 0.96875
wandb: train_loss 0.07305
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.35_Multimodal_iterations_20250118_122213 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/2fhtakpr
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_122214-2fhtakpr/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_123247-vl8a5r80
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.35_Multimodal_epochs_20250118_123247
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/vl8a5r80
wandb: uploading history steps 0-0, summary; updating run config
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▅▆▇███
wandb: train_loss █▄▃▂▁▁▁
wandb:    val_acc ▁▇▇██▇▇
wandb:   val_loss █▄▂▁▆▅▆
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.99192
wandb: train_loss 0.05542
wandb:    val_acc 0.69125
wandb:   val_loss 0.85448
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.35_Multimodal_epochs_20250118_123247 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/vl8a5r80
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_123247-vl8a5r80/logs

