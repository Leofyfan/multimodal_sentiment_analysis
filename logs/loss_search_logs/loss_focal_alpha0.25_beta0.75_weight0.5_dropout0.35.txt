=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 0.5 --dropout 0.35 --name loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.35 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.35
text_dim: 128
image_dim: 256
dropout: 0.35
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6851, log_difficulty=0.5218, weight=3.6090
neutral: count=7.0, difficulty=0.7092, log_difficulty=0.5360, weight=3.6801
negative: count=13.0, difficulty=0.6654, log_difficulty=0.5100, weight=3.5502

当前batch的pt分布：
positive: min=0.1670, max=0.5561, mean=0.3149
neutral: min=0.1823, max=0.3897, mean=0.2908
negative: min=0.0805, max=0.5295, mean=0.3346

当前batch准确率：
整体准确率: 0.2812
positive 准确率: 0.2500
neutral 准确率: 0.1429
negative 准确率: 0.3846

损失分量：
基础交叉熵: 1.2053
焦点损失: 0.4507
边界损失: 0.7668
总损失: 0.9810
Epoch 1 [1/172] - loss: 0.9810, acc: 0.2812
Epoch 1 [2/172] - loss: 0.8733
Epoch 1 [3/172] - loss: 0.9749
Epoch 1 [4/172] - loss: 1.0063
Epoch 1 [5/172] - loss: 0.9819
Epoch 1 [6/172] - loss: 0.9155
Epoch 1 [7/172] - loss: 1.0160
Epoch 1 [8/172] - loss: 0.9866
Epoch 1 [9/172] - loss: 0.9004
Epoch 1 [10/172] - loss: 0.9873, acc: 0.4062
Epoch 1 [11/172] - loss: 1.0013
Epoch 1 [12/172] - loss: 0.8300
Epoch 1 [13/172] - loss: 0.8789
Epoch 1 [14/172] - loss: 0.9916
Epoch 1 [15/172] - loss: 0.8348
Epoch 1 [16/172] - loss: 0.8877
Epoch 1 [17/172] - loss: 0.8589
Epoch 1 [18/172] - loss: 0.9368
Epoch 1 [19/172] - loss: 0.9009
Epoch 1 [20/172] - loss: 0.8287, acc: 0.5625
Epoch 1 [21/172] - loss: 0.9157
Epoch 1 [22/172] - loss: 0.9514
Epoch 1 [23/172] - loss: 0.8801
Epoch 1 [24/172] - loss: 0.9636
Epoch 1 [25/172] - loss: 1.0248
Epoch 1 [26/172] - loss: 0.8195
Epoch 1 [27/172] - loss: 0.8956
Epoch 1 [28/172] - loss: 0.7960
Epoch 1 [29/172] - loss: 0.8863
Epoch 1 [30/172] - loss: 0.9292, acc: 0.3125
Epoch 1 [31/172] - loss: 0.9227
Epoch 1 [32/172] - loss: 0.8093
Epoch 1 [33/172] - loss: 0.7636
Epoch 1 [34/172] - loss: 0.7895
Epoch 1 [35/172] - loss: 0.9548
Epoch 1 [36/172] - loss: 0.8008
Epoch 1 [37/172] - loss: 0.7632
Epoch 1 [38/172] - loss: 0.7788
Epoch 1 [39/172] - loss: 0.8050
Epoch 1 [40/172] - loss: 0.8812, acc: 0.4062
Epoch 1 [41/172] - loss: 0.7639
Epoch 1 [42/172] - loss: 0.8658
Epoch 1 [43/172] - loss: 0.7935
Epoch 1 [44/172] - loss: 0.7660
Epoch 1 [45/172] - loss: 0.7979
Epoch 1 [46/172] - loss: 0.7007
Epoch 1 [47/172] - loss: 0.7020
Epoch 1 [48/172] - loss: 0.7632
Epoch 1 [49/172] - loss: 0.8240
Epoch 1 [50/172] - loss: 0.7224, acc: 0.4688
Epoch 1 [51/172] - loss: 0.7276
Epoch 1 [52/172] - loss: 0.7957
Epoch 1 [53/172] - loss: 0.9957
Epoch 1 [54/172] - loss: 0.6741
Epoch 1 [55/172] - loss: 0.6831
Epoch 1 [56/172] - loss: 0.5729
Epoch 1 [57/172] - loss: 0.9290
Epoch 1 [58/172] - loss: 0.5121
Epoch 1 [59/172] - loss: 0.8826
Epoch 1 [60/172] - loss: 0.6339, acc: 0.5625
Epoch 1 [61/172] - loss: 0.9039
Epoch 1 [62/172] - loss: 0.6245
Epoch 1 [63/172] - loss: 0.7544
Epoch 1 [64/172] - loss: 0.6905
Epoch 1 [65/172] - loss: 0.8156
Epoch 1 [66/172] - loss: 0.7898
Epoch 1 [67/172] - loss: 0.6511
Epoch 1 [68/172] - loss: 0.8250
Epoch 1 [69/172] - loss: 0.6423
Epoch 1 [70/172] - loss: 0.5718, acc: 0.5625
Epoch 1 [71/172] - loss: 0.5126
Epoch 1 [72/172] - loss: 0.7337
Epoch 1 [73/172] - loss: 0.5786
Epoch 1 [74/172] - loss: 0.7779
Epoch 1 [75/172] - loss: 0.4439
Epoch 1 [76/172] - loss: 0.6341
Epoch 1 [77/172] - loss: 0.7524
Epoch 1 [78/172] - loss: 0.5115
Epoch 1 [79/172] - loss: 0.6838
Epoch 1 [80/172] - loss: 0.4387, acc: 0.8125
Epoch 1 [81/172] - loss: 0.6424
Epoch 1 [82/172] - loss: 0.8373
Epoch 1 [83/172] - loss: 0.6976
Epoch 1 [84/172] - loss: 0.6566
Epoch 1 [85/172] - loss: 0.7610
Epoch 1 [86/172] - loss: 0.6686
Epoch 1 [87/172] - loss: 0.7590
Epoch 1 [88/172] - loss: 0.7052
Epoch 1 [89/172] - loss: 0.8401
Epoch 1 [90/172] - loss: 0.6924, acc: 0.5000
Epoch 1 [91/172] - loss: 0.5418
Epoch 1 [92/172] - loss: 0.5527
Epoch 1 [93/172] - loss: 0.6826
Epoch 1 [94/172] - loss: 0.5495
Epoch 1 [95/172] - loss: 0.5586
Epoch 1 [96/172] - loss: 0.4556
Epoch 1 [97/172] - loss: 0.5788
Epoch 1 [98/172] - loss: 0.5515
Epoch 1 [99/172] - loss: 0.6968
Epoch 1 [100/172] - loss: 0.6551, acc: 0.5625

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5414, log_difficulty=0.4327, weight=3.1634
neutral: count=983.0, difficulty=0.6070, log_difficulty=0.4744, weight=3.3719
negative: count=1119.0, difficulty=0.5780, log_difficulty=0.4562, weight=3.2809

当前batch的pt分布：
positive: min=0.1637, max=0.8579, mean=0.6173
neutral: min=0.5133, max=0.9956, mean=0.6866
negative: min=0.0905, max=0.9647, mean=0.4940

当前batch准确率：
整体准确率: 0.7500
positive 准确率: 0.9167
neutral 准确率: 1.0000
negative 准确率: 0.5625

损失分量：
基础交叉熵: 0.7527
焦点损失: 0.3153
边界损失: 0.3872
总损失: 0.5478
Epoch 1 [101/172] - loss: 0.5478
Epoch 1 [102/172] - loss: 0.6127
Epoch 1 [103/172] - loss: 0.6570
Epoch 1 [104/172] - loss: 0.4843
Epoch 1 [105/172] - loss: 0.7271
Epoch 1 [106/172] - loss: 0.8110
Epoch 1 [107/172] - loss: 0.5675
Epoch 1 [108/172] - loss: 0.5571
Epoch 1 [109/172] - loss: 0.6468
Epoch 1 [110/172] - loss: 0.5925, acc: 0.6562
Epoch 1 [111/172] - loss: 0.6650
Epoch 1 [112/172] - loss: 0.5264
Epoch 1 [113/172] - loss: 0.4301
Epoch 1 [114/172] - loss: 0.5335
Epoch 1 [115/172] - loss: 0.5940
Epoch 1 [116/172] - loss: 0.5108
Epoch 1 [117/172] - loss: 0.5018
Epoch 1 [118/172] - loss: 0.4039
Epoch 1 [119/172] - loss: 0.4140
Epoch 1 [120/172] - loss: 0.3456, acc: 0.7812
Epoch 1 [121/172] - loss: 0.4215
Epoch 1 [122/172] - loss: 0.6089
Epoch 1 [123/172] - loss: 0.4362
Epoch 1 [124/172] - loss: 0.5013
Epoch 1 [125/172] - loss: 0.3983
Epoch 1 [126/172] - loss: 0.6010
Epoch 1 [127/172] - loss: 0.4263
Epoch 1 [128/172] - loss: 0.5102
Epoch 1 [129/172] - loss: 0.6111
Epoch 1 [130/172] - loss: 0.3565, acc: 0.8125
Epoch 1 [131/172] - loss: 0.4413
Epoch 1 [132/172] - loss: 0.7185
Epoch 1 [133/172] - loss: 0.5700
Epoch 1 [134/172] - loss: 0.3082
Epoch 1 [135/172] - loss: 0.4892
Epoch 1 [136/172] - loss: 0.3994
Epoch 1 [137/172] - loss: 0.4205
Epoch 1 [138/172] - loss: 0.3487
Epoch 1 [139/172] - loss: 0.3816
Epoch 1 [140/172] - loss: 0.3802, acc: 0.7188
Epoch 1 [141/172] - loss: 0.4097
Epoch 1 [142/172] - loss: 0.3450
Epoch 1 [143/172] - loss: 0.5573
Epoch 1 [144/172] - loss: 0.4408
Epoch 1 [145/172] - loss: 0.5348
Epoch 1 [146/172] - loss: 0.4860
Epoch 1 [147/172] - loss: 0.7207
Epoch 1 [148/172] - loss: 0.5039
Epoch 1 [149/172] - loss: 0.3554
Epoch 1 [150/172] - loss: 0.4778, acc: 0.7500
Epoch 1 [151/172] - loss: 0.4699
Epoch 1 [152/172] - loss: 0.4521
Epoch 1 [153/172] - loss: 0.3517
Epoch 1 [154/172] - loss: 0.4013
Epoch 1 [155/172] - loss: 0.3986
Epoch 1 [156/172] - loss: 0.6230
Epoch 1 [157/172] - loss: 0.4156
Epoch 1 [158/172] - loss: 0.3976
Epoch 1 [159/172] - loss: 0.6305
Epoch 1 [160/172] - loss: 0.3661, acc: 0.7812
Epoch 1 [161/172] - loss: 0.3926
Epoch 1 [162/172] - loss: 0.4036
Epoch 1 [163/172] - loss: 0.4216
Epoch 1 [164/172] - loss: 0.5763
Epoch 1 [165/172] - loss: 0.4623
Epoch 1 [166/172] - loss: 0.4664
Epoch 1 [167/172] - loss: 0.3344
Epoch 1 [168/172] - loss: 0.4723
Epoch 1 [169/172] - loss: 0.4527
Epoch 1 [170/172] - loss: 0.3665, acc: 0.7812
Epoch 1 [171/172] - loss: 0.3688
Epoch 1 [172/172] - loss: 0.3964

类别准确率:
positive: 0.7345 (343/467)
neutral: 0.6024 (50/83)
negative: 0.5680 (142/250)

Epoch 1/10
Train Loss: 0.4327, Train Acc: 0.7616
Val Loss: 0.7944, Val Acc: 0.6687
Epoch 2 [1/172] - loss: 0.3150, acc: 0.8438
Epoch 2 [2/172] - loss: 0.2705
Epoch 2 [3/172] - loss: 0.2454
Epoch 2 [4/172] - loss: 0.3975
Epoch 2 [5/172] - loss: 0.4822
Epoch 2 [6/172] - loss: 0.4100
Epoch 2 [7/172] - loss: 0.3831
Epoch 2 [8/172] - loss: 0.4618
Epoch 2 [9/172] - loss: 0.2338
Epoch 2 [10/172] - loss: 0.3518, acc: 0.8438
Epoch 2 [11/172] - loss: 0.2790
Epoch 2 [12/172] - loss: 0.2969
Epoch 2 [13/172] - loss: 0.3982
Epoch 2 [14/172] - loss: 0.4325
Epoch 2 [15/172] - loss: 0.3533
Epoch 2 [16/172] - loss: 0.3497
Epoch 2 [17/172] - loss: 0.4416
Epoch 2 [18/172] - loss: 0.4602
Epoch 2 [19/172] - loss: 0.3097
Epoch 2 [20/172] - loss: 0.2673, acc: 0.9062
Epoch 2 [21/172] - loss: 0.3415
Epoch 2 [22/172] - loss: 0.3982
Epoch 2 [23/172] - loss: 0.2360
Epoch 2 [24/172] - loss: 0.4739
Epoch 2 [25/172] - loss: 0.2913
Epoch 2 [26/172] - loss: 0.2125
Epoch 2 [27/172] - loss: 0.3096
Epoch 2 [28/172] - loss: 0.4312

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4557, log_difficulty=0.3755, weight=2.8773
neutral: count=1952.0, difficulty=0.4602, log_difficulty=0.3786, weight=2.8929
negative: count=2216.0, difficulty=0.4841, log_difficulty=0.3948, weight=2.9740

当前batch的pt分布：
positive: min=0.3549, max=0.9816, mean=0.7487
neutral: min=0.4885, max=0.9788, mean=0.8157
negative: min=0.0561, max=0.9869, mean=0.6058

当前batch准确率：
整体准确率: 0.7812
positive 准确率: 0.7778
neutral 准确率: 1.0000
negative 准确率: 0.5833

损失分量：
基础交叉熵: 0.4790
焦点损失: 0.2026
边界损失: 0.2811
总损失: 0.3608
Epoch 2 [29/172] - loss: 0.3608
Epoch 2 [30/172] - loss: 0.3080, acc: 0.8750
Epoch 2 [31/172] - loss: 0.3545
Epoch 2 [32/172] - loss: 0.3978
Epoch 2 [33/172] - loss: 0.3687
Epoch 2 [34/172] - loss: 0.3450
Epoch 2 [35/172] - loss: 0.2669
Epoch 2 [36/172] - loss: 0.3477
Epoch 2 [37/172] - loss: 0.3180
Epoch 2 [38/172] - loss: 0.2879
Epoch 2 [39/172] - loss: 0.3331
Epoch 2 [40/172] - loss: 0.4862, acc: 0.6562
Epoch 2 [41/172] - loss: 0.2819
Epoch 2 [42/172] - loss: 0.2395
Epoch 2 [43/172] - loss: 0.2066
Epoch 2 [44/172] - loss: 0.3117
Epoch 2 [45/172] - loss: 0.2565
Epoch 2 [46/172] - loss: 0.2677
Epoch 2 [47/172] - loss: 0.3146
Epoch 2 [48/172] - loss: 0.3779
Epoch 2 [49/172] - loss: 0.2514
Epoch 2 [50/172] - loss: 0.3354, acc: 0.8125
Epoch 2 [51/172] - loss: 0.3486
Epoch 2 [52/172] - loss: 0.2031
Epoch 2 [53/172] - loss: 0.3508
Epoch 2 [54/172] - loss: 0.3037
Epoch 2 [55/172] - loss: 0.2917
Epoch 2 [56/172] - loss: 0.2125
Epoch 2 [57/172] - loss: 0.2316
Epoch 2 [58/172] - loss: 0.4166
Epoch 2 [59/172] - loss: 0.4165
Epoch 2 [60/172] - loss: 0.2667, acc: 0.8750
Epoch 2 [61/172] - loss: 0.2079
Epoch 2 [62/172] - loss: 0.2050
Epoch 2 [63/172] - loss: 0.3596
Epoch 2 [64/172] - loss: 0.2609
Epoch 2 [65/172] - loss: 0.3203
Epoch 2 [66/172] - loss: 0.2418
Epoch 2 [67/172] - loss: 0.2168
Epoch 2 [68/172] - loss: 0.3316
Epoch 2 [69/172] - loss: 0.2227
Epoch 2 [70/172] - loss: 0.3677, acc: 0.8125
Epoch 2 [71/172] - loss: 0.2564
Epoch 2 [72/172] - loss: 0.2594
Epoch 2 [73/172] - loss: 0.2875
Epoch 2 [74/172] - loss: 0.2826
Epoch 2 [75/172] - loss: 0.2814
Epoch 2 [76/172] - loss: 0.3089
Epoch 2 [77/172] - loss: 0.2370
Epoch 2 [78/172] - loss: 0.3508
Epoch 2 [79/172] - loss: 0.3203
Epoch 2 [80/172] - loss: 0.2176, acc: 0.9375
Epoch 2 [81/172] - loss: 0.2468
Epoch 2 [82/172] - loss: 0.2549
Epoch 2 [83/172] - loss: 0.2525
Epoch 2 [84/172] - loss: 0.2806
Epoch 2 [85/172] - loss: 0.2482
Epoch 2 [86/172] - loss: 0.1977
Epoch 2 [87/172] - loss: 0.6855
Epoch 2 [88/172] - loss: 0.2301
Epoch 2 [89/172] - loss: 0.2569
Epoch 2 [90/172] - loss: 0.2961, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1570
Epoch 2 [92/172] - loss: 0.3351
Epoch 2 [93/172] - loss: 0.2648
Epoch 2 [94/172] - loss: 0.1806
Epoch 2 [95/172] - loss: 0.2896
Epoch 2 [96/172] - loss: 0.1819
Epoch 2 [97/172] - loss: 0.2862
Epoch 2 [98/172] - loss: 0.1776
Epoch 2 [99/172] - loss: 0.1551
Epoch 2 [100/172] - loss: 0.2593, acc: 0.9062
Epoch 2 [101/172] - loss: 0.2321
Epoch 2 [102/172] - loss: 0.1806
Epoch 2 [103/172] - loss: 0.3893
Epoch 2 [104/172] - loss: 0.2990
Epoch 2 [105/172] - loss: 0.2082
Epoch 2 [106/172] - loss: 0.1867
Epoch 2 [107/172] - loss: 0.2965
Epoch 2 [108/172] - loss: 0.3549
Epoch 2 [109/172] - loss: 0.1691
Epoch 2 [110/172] - loss: 0.2612, acc: 0.9062
Epoch 2 [111/172] - loss: 0.2838
Epoch 2 [112/172] - loss: 0.1685
Epoch 2 [113/172] - loss: 0.1693
Epoch 2 [114/172] - loss: 0.2127
Epoch 2 [115/172] - loss: 0.2234
Epoch 2 [116/172] - loss: 0.3000
Epoch 2 [117/172] - loss: 0.3985
Epoch 2 [118/172] - loss: 0.2057
Epoch 2 [119/172] - loss: 0.2640
Epoch 2 [120/172] - loss: 0.1899, acc: 0.9375
Epoch 2 [121/172] - loss: 0.2330
Epoch 2 [122/172] - loss: 0.4604
Epoch 2 [123/172] - loss: 0.3001
Epoch 2 [124/172] - loss: 0.2516
Epoch 2 [125/172] - loss: 0.1864
Epoch 2 [126/172] - loss: 0.2157
Epoch 2 [127/172] - loss: 0.2595
Epoch 2 [128/172] - loss: 0.2435

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3891, log_difficulty=0.3286, weight=2.6432
neutral: count=2949.0, difficulty=0.3537, log_difficulty=0.3029, weight=2.5143
negative: count=3294.0, difficulty=0.4055, log_difficulty=0.3404, weight=2.7019

当前batch的pt分布：
positive: min=0.4045, max=0.9992, mean=0.8306
neutral: min=0.2966, max=0.9921, mean=0.8373
negative: min=0.2392, max=0.9941, mean=0.7352

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9000
neutral 准确率: 0.9091
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.2777
焦点损失: 0.0621
边界损失: 0.2524
总损失: 0.2303
Epoch 2 [129/172] - loss: 0.2303
Epoch 2 [130/172] - loss: 0.2812, acc: 0.8750
Epoch 2 [131/172] - loss: 0.2125
Epoch 2 [132/172] - loss: 0.2768
Epoch 2 [133/172] - loss: 0.2367
Epoch 2 [134/172] - loss: 0.2505
Epoch 2 [135/172] - loss: 0.4384
Epoch 2 [136/172] - loss: 0.2567
Epoch 2 [137/172] - loss: 0.1668
Epoch 2 [138/172] - loss: 0.2337
Epoch 2 [139/172] - loss: 0.2952
Epoch 2 [140/172] - loss: 0.2412, acc: 0.9375
Epoch 2 [141/172] - loss: 0.2270
Epoch 2 [142/172] - loss: 0.1946
Epoch 2 [143/172] - loss: 0.2484
Epoch 2 [144/172] - loss: 0.3619
Epoch 2 [145/172] - loss: 0.4452
Epoch 2 [146/172] - loss: 0.2131
Epoch 2 [147/172] - loss: 0.2163
Epoch 2 [148/172] - loss: 0.2501
Epoch 2 [149/172] - loss: 0.2297
Epoch 2 [150/172] - loss: 0.2278, acc: 0.8750
Epoch 2 [151/172] - loss: 0.2427
Epoch 2 [152/172] - loss: 0.2536
Epoch 2 [153/172] - loss: 0.2261
Epoch 2 [154/172] - loss: 0.1534
Epoch 2 [155/172] - loss: 0.2345
Epoch 2 [156/172] - loss: 0.2114
Epoch 2 [157/172] - loss: 0.1873
Epoch 2 [158/172] - loss: 0.2213
Epoch 2 [159/172] - loss: 0.2204
Epoch 2 [160/172] - loss: 0.1970, acc: 0.9375
Epoch 2 [161/172] - loss: 0.2810
Epoch 2 [162/172] - loss: 0.1868
Epoch 2 [163/172] - loss: 0.2994
Epoch 2 [164/172] - loss: 0.2324
Epoch 2 [165/172] - loss: 0.4156
Epoch 2 [166/172] - loss: 0.3578
Epoch 2 [167/172] - loss: 0.2994
Epoch 2 [168/172] - loss: 0.1746
Epoch 2 [169/172] - loss: 0.1593
Epoch 2 [170/172] - loss: 0.2349, acc: 0.9062
Epoch 2 [171/172] - loss: 0.3286
Epoch 2 [172/172] - loss: 0.3154

类别准确率:
positive: 0.8672 (405/467)
neutral: 0.2410 (20/83)
negative: 0.6800 (170/250)

Epoch 2/10
Train Loss: 0.2569, Train Acc: 0.9030
Val Loss: 0.6705, Val Acc: 0.7438
Epoch 3 [1/172] - loss: 0.1697, acc: 0.9688
Epoch 3 [2/172] - loss: 0.1833
Epoch 3 [3/172] - loss: 0.1447
Epoch 3 [4/172] - loss: 0.1767
Epoch 3 [5/172] - loss: 0.1703
Epoch 3 [6/172] - loss: 0.1610
Epoch 3 [7/172] - loss: 0.1632
Epoch 3 [8/172] - loss: 0.1719
Epoch 3 [9/172] - loss: 0.1694
Epoch 3 [10/172] - loss: 0.1476, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1660
Epoch 3 [12/172] - loss: 0.1378
Epoch 3 [13/172] - loss: 0.1609
Epoch 3 [14/172] - loss: 0.1351
Epoch 3 [15/172] - loss: 0.1499
Epoch 3 [16/172] - loss: 0.2373
Epoch 3 [17/172] - loss: 0.1974
Epoch 3 [18/172] - loss: 0.2455
Epoch 3 [19/172] - loss: 0.1539
Epoch 3 [20/172] - loss: 0.1456, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1239
Epoch 3 [22/172] - loss: 0.2415
Epoch 3 [23/172] - loss: 0.1653
Epoch 3 [24/172] - loss: 0.1948
Epoch 3 [25/172] - loss: 0.1728
Epoch 3 [26/172] - loss: 0.1391
Epoch 3 [27/172] - loss: 0.1391
Epoch 3 [28/172] - loss: 0.1292
Epoch 3 [29/172] - loss: 0.1567
Epoch 3 [30/172] - loss: 0.1823, acc: 0.9688
Epoch 3 [31/172] - loss: 0.1526
Epoch 3 [32/172] - loss: 0.1495
Epoch 3 [33/172] - loss: 0.1434
Epoch 3 [34/172] - loss: 0.1940
Epoch 3 [35/172] - loss: 0.2489
Epoch 3 [36/172] - loss: 0.1604
Epoch 3 [37/172] - loss: 0.1547
Epoch 3 [38/172] - loss: 0.1764
Epoch 3 [39/172] - loss: 0.1400
Epoch 3 [40/172] - loss: 0.1682, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1690
Epoch 3 [42/172] - loss: 0.1595
Epoch 3 [43/172] - loss: 0.1507
Epoch 3 [44/172] - loss: 0.1169
Epoch 3 [45/172] - loss: 0.1643
Epoch 3 [46/172] - loss: 0.1880
Epoch 3 [47/172] - loss: 0.1556
Epoch 3 [48/172] - loss: 0.1549
Epoch 3 [49/172] - loss: 0.1286
Epoch 3 [50/172] - loss: 0.1337, acc: 1.0000
Epoch 3 [51/172] - loss: 0.1657
Epoch 3 [52/172] - loss: 0.2257
Epoch 3 [53/172] - loss: 0.1558
Epoch 3 [54/172] - loss: 0.1654
Epoch 3 [55/172] - loss: 0.1482
Epoch 3 [56/172] - loss: 0.1545

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3319, log_difficulty=0.2866, weight=2.4331
neutral: count=3923.0, difficulty=0.2908, log_difficulty=0.2552, weight=2.2762
negative: count=4382.0, difficulty=0.3435, log_difficulty=0.2953, weight=2.4764

当前batch的pt分布：
positive: min=0.2236, max=0.9891, mean=0.8495
neutral: min=0.0226, max=0.9848, mean=0.8284
negative: min=0.9746, max=0.9984, mean=0.9914

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9091
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2610
焦点损失: 0.1440
边界损失: 0.1874
总损失: 0.2236
Epoch 3 [57/172] - loss: 0.2236
Epoch 3 [58/172] - loss: 0.1953
Epoch 3 [59/172] - loss: 0.1440
Epoch 3 [60/172] - loss: 0.1418, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1516
Epoch 3 [62/172] - loss: 0.1481
Epoch 3 [63/172] - loss: 0.1504
Epoch 3 [64/172] - loss: 0.1701
Epoch 3 [65/172] - loss: 0.1521
Epoch 3 [66/172] - loss: 0.1609
Epoch 3 [67/172] - loss: 0.1296
Epoch 3 [68/172] - loss: 0.1534
Epoch 3 [69/172] - loss: 0.1992
Epoch 3 [70/172] - loss: 0.1256, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1793
Epoch 3 [72/172] - loss: 0.1657
Epoch 3 [73/172] - loss: 0.1342
Epoch 3 [74/172] - loss: 0.1810
Epoch 3 [75/172] - loss: 0.1333
Epoch 3 [76/172] - loss: 0.1234
Epoch 3 [77/172] - loss: 0.1417
Epoch 3 [78/172] - loss: 0.1572
Epoch 3 [79/172] - loss: 0.1815
Epoch 3 [80/172] - loss: 0.2034, acc: 0.9375
Epoch 3 [81/172] - loss: 0.1595
Epoch 3 [82/172] - loss: 0.1760
Epoch 3 [83/172] - loss: 0.1424
Epoch 3 [84/172] - loss: 0.1338
Epoch 3 [85/172] - loss: 0.1271
Epoch 3 [86/172] - loss: 0.1414
Epoch 3 [87/172] - loss: 0.2596
Epoch 3 [88/172] - loss: 0.1611
Epoch 3 [89/172] - loss: 0.1245
Epoch 3 [90/172] - loss: 0.1235, acc: 1.0000
Epoch 3 [91/172] - loss: 0.2577
Epoch 3 [92/172] - loss: 0.1697
Epoch 3 [93/172] - loss: 0.2115
Epoch 3 [94/172] - loss: 0.1516
Epoch 3 [95/172] - loss: 0.1290
Epoch 3 [96/172] - loss: 0.1634
Epoch 3 [97/172] - loss: 0.1359
Epoch 3 [98/172] - loss: 0.1370
Epoch 3 [99/172] - loss: 0.1424
Epoch 3 [100/172] - loss: 0.1789, acc: 0.9375
Epoch 3 [101/172] - loss: 0.1452
Epoch 3 [102/172] - loss: 0.1383
Epoch 3 [103/172] - loss: 0.2932
Epoch 3 [104/172] - loss: 0.2058
Epoch 3 [105/172] - loss: 0.1313
Epoch 3 [106/172] - loss: 0.1623
Epoch 3 [107/172] - loss: 0.1388
Epoch 3 [108/172] - loss: 0.1449
Epoch 3 [109/172] - loss: 0.1428
Epoch 3 [110/172] - loss: 0.1248, acc: 1.0000
Epoch 3 [111/172] - loss: 0.1538
Epoch 3 [112/172] - loss: 0.1381
Epoch 3 [113/172] - loss: 0.1322
Epoch 3 [114/172] - loss: 0.1321
Epoch 3 [115/172] - loss: 0.1721
Epoch 3 [116/172] - loss: 0.1316
Epoch 3 [117/172] - loss: 0.1902
Epoch 3 [118/172] - loss: 0.1382
Epoch 3 [119/172] - loss: 0.1491
Epoch 3 [120/172] - loss: 0.2220, acc: 0.9375
Epoch 3 [121/172] - loss: 0.2199
Epoch 3 [122/172] - loss: 0.1455
Epoch 3 [123/172] - loss: 0.1670
Epoch 3 [124/172] - loss: 0.1574
Epoch 3 [125/172] - loss: 0.1585
Epoch 3 [126/172] - loss: 0.2323
Epoch 3 [127/172] - loss: 0.2046
Epoch 3 [128/172] - loss: 0.1287
Epoch 3 [129/172] - loss: 0.1254
Epoch 3 [130/172] - loss: 0.1245, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1809
Epoch 3 [132/172] - loss: 0.1250
Epoch 3 [133/172] - loss: 0.1327
Epoch 3 [134/172] - loss: 0.1496
Epoch 3 [135/172] - loss: 0.1317
Epoch 3 [136/172] - loss: 0.1529
Epoch 3 [137/172] - loss: 0.1482
Epoch 3 [138/172] - loss: 0.1772
Epoch 3 [139/172] - loss: 0.1506
Epoch 3 [140/172] - loss: 0.1572, acc: 1.0000
Epoch 3 [141/172] - loss: 0.1633
Epoch 3 [142/172] - loss: 0.1553
Epoch 3 [143/172] - loss: 0.1593
Epoch 3 [144/172] - loss: 0.2387
Epoch 3 [145/172] - loss: 0.1353
Epoch 3 [146/172] - loss: 0.1423
Epoch 3 [147/172] - loss: 0.1522
Epoch 3 [148/172] - loss: 0.1619
Epoch 3 [149/172] - loss: 0.1566
Epoch 3 [150/172] - loss: 0.1554, acc: 0.9375
Epoch 3 [151/172] - loss: 0.2040
Epoch 3 [152/172] - loss: 0.1944
Epoch 3 [153/172] - loss: 0.1340
Epoch 3 [154/172] - loss: 0.2165
Epoch 3 [155/172] - loss: 0.1148
Epoch 3 [156/172] - loss: 0.1202

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2867, log_difficulty=0.2520, weight=2.2602
neutral: count=4903.0, difficulty=0.2452, log_difficulty=0.2193, weight=2.0966
negative: count=5500.0, difficulty=0.2958, log_difficulty=0.2591, weight=2.2955

当前batch的pt分布：
positive: min=0.4976, max=0.9962, mean=0.9168
neutral: min=0.9006, max=0.9966, mean=0.9701
negative: min=0.3379, max=0.9975, mean=0.9039

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.0895
焦点损失: 0.0180
边界损失: 0.1687
总损失: 0.1368
Epoch 3 [157/172] - loss: 0.1368
Epoch 3 [158/172] - loss: 0.2315
Epoch 3 [159/172] - loss: 0.1686
Epoch 3 [160/172] - loss: 0.1719, acc: 0.9688
Epoch 3 [161/172] - loss: 0.2445
Epoch 3 [162/172] - loss: 0.1645
Epoch 3 [163/172] - loss: 0.1366
Epoch 3 [164/172] - loss: 0.1168
Epoch 3 [165/172] - loss: 0.1264
Epoch 3 [166/172] - loss: 0.1227
Epoch 3 [167/172] - loss: 0.1471
Epoch 3 [168/172] - loss: 0.1426
Epoch 3 [169/172] - loss: 0.1266
Epoch 3 [170/172] - loss: 0.2298, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1438
Epoch 3 [172/172] - loss: 0.1255

类别准确率:
positive: 0.8437 (394/467)
neutral: 0.3373 (28/83)
negative: 0.6280 (157/250)

Epoch 3/10
Train Loss: 0.1585, Train Acc: 0.9657
Val Loss: 0.8398, Val Acc: 0.7238
Epoch 4 [1/172] - loss: 0.1119, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1692
Epoch 4 [3/172] - loss: 0.1277
Epoch 4 [4/172] - loss: 0.1322
Epoch 4 [5/172] - loss: 0.1427
Epoch 4 [6/172] - loss: 0.1125
Epoch 4 [7/172] - loss: 0.1208
Epoch 4 [8/172] - loss: 0.1348
Epoch 4 [9/172] - loss: 0.1644
Epoch 4 [10/172] - loss: 0.1726, acc: 0.9688
Epoch 4 [11/172] - loss: 0.1218
Epoch 4 [12/172] - loss: 0.1365
Epoch 4 [13/172] - loss: 0.1538
Epoch 4 [14/172] - loss: 0.1714
Epoch 4 [15/172] - loss: 0.1675
Epoch 4 [16/172] - loss: 0.1138
Epoch 4 [17/172] - loss: 0.1185
Epoch 4 [18/172] - loss: 0.1340
Epoch 4 [19/172] - loss: 0.1208
Epoch 4 [20/172] - loss: 0.1271, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1509
Epoch 4 [22/172] - loss: 0.1249
Epoch 4 [23/172] - loss: 0.1500
Epoch 4 [24/172] - loss: 0.1110
Epoch 4 [25/172] - loss: 0.1189
Epoch 4 [26/172] - loss: 0.1825
Epoch 4 [27/172] - loss: 0.1199
Epoch 4 [28/172] - loss: 0.1657
Epoch 4 [29/172] - loss: 0.1526
Epoch 4 [30/172] - loss: 0.1566, acc: 0.9688
Epoch 4 [31/172] - loss: 0.2240
Epoch 4 [32/172] - loss: 0.1247
Epoch 4 [33/172] - loss: 0.1374
Epoch 4 [34/172] - loss: 0.1236
Epoch 4 [35/172] - loss: 0.1631
Epoch 4 [36/172] - loss: 0.1170
Epoch 4 [37/172] - loss: 0.1104
Epoch 4 [38/172] - loss: 0.1430
Epoch 4 [39/172] - loss: 0.1676
Epoch 4 [40/172] - loss: 0.1652, acc: 0.9688
Epoch 4 [41/172] - loss: 0.1232
Epoch 4 [42/172] - loss: 0.1338
Epoch 4 [43/172] - loss: 0.1456
Epoch 4 [44/172] - loss: 0.1219
Epoch 4 [45/172] - loss: 0.1193
Epoch 4 [46/172] - loss: 0.1170
Epoch 4 [47/172] - loss: 0.1337
Epoch 4 [48/172] - loss: 0.1339
Epoch 4 [49/172] - loss: 0.1300
Epoch 4 [50/172] - loss: 0.1326, acc: 0.9688
Epoch 4 [51/172] - loss: 0.1227
Epoch 4 [52/172] - loss: 0.1524
Epoch 4 [53/172] - loss: 0.1180
Epoch 4 [54/172] - loss: 0.1457
Epoch 4 [55/172] - loss: 0.1800
Epoch 4 [56/172] - loss: 0.1250
Epoch 4 [57/172] - loss: 0.1129
Epoch 4 [58/172] - loss: 0.1157
Epoch 4 [59/172] - loss: 0.1238
Epoch 4 [60/172] - loss: 0.1135, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1226
Epoch 4 [62/172] - loss: 0.1610
Epoch 4 [63/172] - loss: 0.1281
Epoch 4 [64/172] - loss: 0.1174
Epoch 4 [65/172] - loss: 0.1182
Epoch 4 [66/172] - loss: 0.1236
Epoch 4 [67/172] - loss: 0.1161
Epoch 4 [68/172] - loss: 0.1152
Epoch 4 [69/172] - loss: 0.1271
Epoch 4 [70/172] - loss: 0.1176, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1116
Epoch 4 [72/172] - loss: 0.1201
Epoch 4 [73/172] - loss: 0.1183
Epoch 4 [74/172] - loss: 0.1940
Epoch 4 [75/172] - loss: 0.1211
Epoch 4 [76/172] - loss: 0.1108
Epoch 4 [77/172] - loss: 0.1247
Epoch 4 [78/172] - loss: 0.1151
Epoch 4 [79/172] - loss: 0.1139
Epoch 4 [80/172] - loss: 0.1135, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1562
Epoch 4 [82/172] - loss: 0.1347
Epoch 4 [83/172] - loss: 0.1278
Epoch 4 [84/172] - loss: 0.1123

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2504, log_difficulty=0.2235, weight=2.1175
neutral: count=5865.0, difficulty=0.2131, log_difficulty=0.1931, weight=1.9657
negative: count=6629.0, difficulty=0.2585, log_difficulty=0.2299, weight=2.1496

当前batch的pt分布：
positive: min=0.7417, max=0.9880, mean=0.9120
neutral: min=0.8136, max=0.9993, mean=0.9714
negative: min=0.2120, max=0.9999, mean=0.9000

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.1074
焦点损失: 0.0304
边界损失: 0.1683
总损失: 0.1426
Epoch 4 [85/172] - loss: 0.1426
Epoch 4 [86/172] - loss: 0.1359
Epoch 4 [87/172] - loss: 0.1402
Epoch 4 [88/172] - loss: 0.1258
Epoch 4 [89/172] - loss: 0.1203
Epoch 4 [90/172] - loss: 0.1124, acc: 1.0000
Epoch 4 [91/172] - loss: 0.2167
Epoch 4 [92/172] - loss: 0.2235
Epoch 4 [93/172] - loss: 0.1109
Epoch 4 [94/172] - loss: 0.1159
Epoch 4 [95/172] - loss: 0.1431
Epoch 4 [96/172] - loss: 0.1247
Epoch 4 [97/172] - loss: 0.1223
Epoch 4 [98/172] - loss: 0.1091
Epoch 4 [99/172] - loss: 0.1245
Epoch 4 [100/172] - loss: 0.1268, acc: 0.9688
Epoch 4 [101/172] - loss: 0.1376
Epoch 4 [102/172] - loss: 0.1301
Epoch 4 [103/172] - loss: 0.1177
Epoch 4 [104/172] - loss: 0.1124
Epoch 4 [105/172] - loss: 0.1671
Epoch 4 [106/172] - loss: 0.1115
Epoch 4 [107/172] - loss: 0.1240
Epoch 4 [108/172] - loss: 0.1411
Epoch 4 [109/172] - loss: 0.1283
Epoch 4 [110/172] - loss: 0.3026, acc: 0.9062
Epoch 4 [111/172] - loss: 0.1209
Epoch 4 [112/172] - loss: 0.1314
Epoch 4 [113/172] - loss: 0.1150
Epoch 4 [114/172] - loss: 0.1295
Epoch 4 [115/172] - loss: 0.1184
Epoch 4 [116/172] - loss: 0.1213
Epoch 4 [117/172] - loss: 0.1235
Epoch 4 [118/172] - loss: 0.1301
Epoch 4 [119/172] - loss: 0.1334
Epoch 4 [120/172] - loss: 0.1158, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1333
Epoch 4 [122/172] - loss: 0.1276
Epoch 4 [123/172] - loss: 0.1098
Epoch 4 [124/172] - loss: 0.1240
Epoch 4 [125/172] - loss: 0.1285
Epoch 4 [126/172] - loss: 0.1800
Epoch 4 [127/172] - loss: 0.1456
Epoch 4 [128/172] - loss: 0.1297
Epoch 4 [129/172] - loss: 0.1090
Epoch 4 [130/172] - loss: 0.1130, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1139
Epoch 4 [132/172] - loss: 0.1106
Epoch 4 [133/172] - loss: 0.1300
Epoch 4 [134/172] - loss: 0.1110
Epoch 4 [135/172] - loss: 0.1316
Epoch 4 [136/172] - loss: 0.1481
Epoch 4 [137/172] - loss: 0.1337
Epoch 4 [138/172] - loss: 0.1107
Epoch 4 [139/172] - loss: 0.1117
Epoch 4 [140/172] - loss: 0.1134, acc: 1.0000
Epoch 4 [141/172] - loss: 0.1549
Epoch 4 [142/172] - loss: 0.1193
Epoch 4 [143/172] - loss: 0.1209
Epoch 4 [144/172] - loss: 0.1145
Epoch 4 [145/172] - loss: 0.1772
Epoch 4 [146/172] - loss: 0.1171
Epoch 4 [147/172] - loss: 0.1229
Epoch 4 [148/172] - loss: 0.1093
Epoch 4 [149/172] - loss: 0.1095
Epoch 4 [150/172] - loss: 0.1619, acc: 0.9688
Epoch 4 [151/172] - loss: 0.1767
Epoch 4 [152/172] - loss: 0.1095
Epoch 4 [153/172] - loss: 0.1115
Epoch 4 [154/172] - loss: 0.1585
Epoch 4 [155/172] - loss: 0.1107
Epoch 4 [156/172] - loss: 0.1150
Epoch 4 [157/172] - loss: 0.1353
Epoch 4 [158/172] - loss: 0.1112
Epoch 4 [159/172] - loss: 0.1191
Epoch 4 [160/172] - loss: 0.1151, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1228
Epoch 4 [162/172] - loss: 0.1176
Epoch 4 [163/172] - loss: 0.1375
Epoch 4 [164/172] - loss: 0.1163
Epoch 4 [165/172] - loss: 0.1632
Epoch 4 [166/172] - loss: 0.1124
Epoch 4 [167/172] - loss: 0.1255
Epoch 4 [168/172] - loss: 0.1146
Epoch 4 [169/172] - loss: 0.1421
Epoch 4 [170/172] - loss: 0.1510, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1229
Epoch 4 [172/172] - loss: 0.1538

类别准确率:
positive: 0.9400 (439/467)
neutral: 0.2048 (17/83)
negative: 0.4120 (103/250)

Epoch 4/10
Train Loss: 0.1288, Train Acc: 0.9879
Val Loss: 1.1169, Val Acc: 0.6987
Epoch 5 [1/172] - loss: 0.1095, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1275
Epoch 5 [3/172] - loss: 0.1116
Epoch 5 [4/172] - loss: 0.1494
Epoch 5 [5/172] - loss: 0.1113
Epoch 5 [6/172] - loss: 0.1424
Epoch 5 [7/172] - loss: 0.1083
Epoch 5 [8/172] - loss: 0.1253
Epoch 5 [9/172] - loss: 0.2090
Epoch 5 [10/172] - loss: 0.1118, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1611
Epoch 5 [12/172] - loss: 0.1087

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2223, log_difficulty=0.2007, weight=2.0037
neutral: count=6845.0, difficulty=0.1887, log_difficulty=0.1729, weight=1.8644
negative: count=7694.0, difficulty=0.2299, log_difficulty=0.2069, weight=2.0346

当前batch的pt分布：
positive: min=0.1182, max=0.9983, mean=0.9011
neutral: min=0.9743, max=0.9996, mean=0.9919
negative: min=0.9306, max=0.9978, mean=0.9766

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0933
焦点损失: 0.0514
边界损失: 0.1527
总损失: 0.1403
Epoch 5 [13/172] - loss: 0.1403
Epoch 5 [14/172] - loss: 0.1395
Epoch 5 [15/172] - loss: 0.1144
Epoch 5 [16/172] - loss: 0.1089
Epoch 5 [17/172] - loss: 0.1136
Epoch 5 [18/172] - loss: 0.1157
Epoch 5 [19/172] - loss: 0.1235
Epoch 5 [20/172] - loss: 0.1160, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1354
Epoch 5 [22/172] - loss: 0.1805
Epoch 5 [23/172] - loss: 0.1091
Epoch 5 [24/172] - loss: 0.1801
Epoch 5 [25/172] - loss: 0.1077
Epoch 5 [26/172] - loss: 0.1299
Epoch 5 [27/172] - loss: 0.1253
Epoch 5 [28/172] - loss: 0.1087
Epoch 5 [29/172] - loss: 0.1093
Epoch 5 [30/172] - loss: 0.1106, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1092
Epoch 5 [32/172] - loss: 0.1134
Epoch 5 [33/172] - loss: 0.1106
Epoch 5 [34/172] - loss: 0.1163
Epoch 5 [35/172] - loss: 0.1064
Epoch 5 [36/172] - loss: 0.1067
Epoch 5 [37/172] - loss: 0.1091
Epoch 5 [38/172] - loss: 0.1144
Epoch 5 [39/172] - loss: 0.1343
Epoch 5 [40/172] - loss: 0.1148, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1103
Epoch 5 [42/172] - loss: 0.1085
Epoch 5 [43/172] - loss: 0.1224
Epoch 5 [44/172] - loss: 0.1111
Epoch 5 [45/172] - loss: 0.1064
Epoch 5 [46/172] - loss: 0.1130
Epoch 5 [47/172] - loss: 0.1066
Epoch 5 [48/172] - loss: 0.1177
Epoch 5 [49/172] - loss: 0.1122
Epoch 5 [50/172] - loss: 0.1191, acc: 1.0000
Epoch 5 [51/172] - loss: 0.1258
Epoch 5 [52/172] - loss: 0.1269
Epoch 5 [53/172] - loss: 0.1331
Epoch 5 [54/172] - loss: 0.1105
Epoch 5 [55/172] - loss: 0.1187
Epoch 5 [56/172] - loss: 0.1189
Epoch 5 [57/172] - loss: 0.1083
Epoch 5 [58/172] - loss: 0.1064
Epoch 5 [59/172] - loss: 0.1291
Epoch 5 [60/172] - loss: 0.1095, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1116
Epoch 5 [62/172] - loss: 0.1096
Epoch 5 [63/172] - loss: 0.1365
Epoch 5 [64/172] - loss: 0.1141
Epoch 5 [65/172] - loss: 0.1124
Epoch 5 [66/172] - loss: 0.1145
Epoch 5 [67/172] - loss: 0.1074
Epoch 5 [68/172] - loss: 0.1113
Epoch 5 [69/172] - loss: 0.1109
Epoch 5 [70/172] - loss: 0.1095, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1166
Epoch 5 [72/172] - loss: 0.1068
Epoch 5 [73/172] - loss: 0.1136
Epoch 5 [74/172] - loss: 0.1206
Epoch 5 [75/172] - loss: 0.1095
Epoch 5 [76/172] - loss: 0.1082
Epoch 5 [77/172] - loss: 0.1088
Epoch 5 [78/172] - loss: 0.1452
Epoch 5 [79/172] - loss: 0.1072
Epoch 5 [80/172] - loss: 0.1174, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1342
Epoch 5 [82/172] - loss: 0.1150
Epoch 5 [83/172] - loss: 0.1087
Epoch 5 [84/172] - loss: 0.1106
Epoch 5 [85/172] - loss: 0.1349
Epoch 5 [86/172] - loss: 0.1142
Epoch 5 [87/172] - loss: 0.1165
Epoch 5 [88/172] - loss: 0.1256
Epoch 5 [89/172] - loss: 0.1119
Epoch 5 [90/172] - loss: 0.1835, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1092
Epoch 5 [92/172] - loss: 0.1104
Epoch 5 [93/172] - loss: 0.1081
Epoch 5 [94/172] - loss: 0.1129
Epoch 5 [95/172] - loss: 0.1167
Epoch 5 [96/172] - loss: 0.1135
Epoch 5 [97/172] - loss: 0.1205
Epoch 5 [98/172] - loss: 0.1087
Epoch 5 [99/172] - loss: 0.1766
Epoch 5 [100/172] - loss: 0.1162, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1115
Epoch 5 [102/172] - loss: 0.1082
Epoch 5 [103/172] - loss: 0.1107
Epoch 5 [104/172] - loss: 0.1561
Epoch 5 [105/172] - loss: 0.2174
Epoch 5 [106/172] - loss: 0.1067
Epoch 5 [107/172] - loss: 0.1225
Epoch 5 [108/172] - loss: 0.1265
Epoch 5 [109/172] - loss: 0.1128
Epoch 5 [110/172] - loss: 0.1095, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1215
Epoch 5 [112/172] - loss: 0.1073

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.1984, log_difficulty=0.1810, weight=1.9050
neutral: count=7825.0, difficulty=0.1690, log_difficulty=0.1561, weight=1.7807
negative: count=8780.0, difficulty=0.2064, log_difficulty=0.1877, weight=1.9384

当前batch的pt分布：
positive: min=0.4603, max=0.9931, mean=0.9087
neutral: min=0.9364, max=0.9976, mean=0.9797
negative: min=0.9984, max=1.0000, mean=0.9990

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0625
焦点损失: 0.0077
边界损失: 0.1634
总损失: 0.1262
Epoch 5 [113/172] - loss: 0.1262
Epoch 5 [114/172] - loss: 0.1156
Epoch 5 [115/172] - loss: 0.1128
Epoch 5 [116/172] - loss: 0.1078
Epoch 5 [117/172] - loss: 0.1117
Epoch 5 [118/172] - loss: 0.1120
Epoch 5 [119/172] - loss: 0.1071
Epoch 5 [120/172] - loss: 0.1089, acc: 1.0000
Epoch 5 [121/172] - loss: 0.1119
Epoch 5 [122/172] - loss: 0.1082
Epoch 5 [123/172] - loss: 0.1132
Epoch 5 [124/172] - loss: 0.1076
Epoch 5 [125/172] - loss: 0.1076
Epoch 5 [126/172] - loss: 0.1078
Epoch 5 [127/172] - loss: 0.1122
Epoch 5 [128/172] - loss: 0.1106
Epoch 5 [129/172] - loss: 0.1295
Epoch 5 [130/172] - loss: 0.1068, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1120
Epoch 5 [132/172] - loss: 0.1333
Epoch 5 [133/172] - loss: 0.1212
Epoch 5 [134/172] - loss: 0.1276
Epoch 5 [135/172] - loss: 0.1327
Epoch 5 [136/172] - loss: 0.1074
Epoch 5 [137/172] - loss: 0.1164
Epoch 5 [138/172] - loss: 0.1219
Epoch 5 [139/172] - loss: 0.1930
Epoch 5 [140/172] - loss: 0.1173, acc: 1.0000
Epoch 5 [141/172] - loss: 0.1125
Epoch 5 [142/172] - loss: 0.1149
Epoch 5 [143/172] - loss: 0.1060
Epoch 5 [144/172] - loss: 0.1172
Epoch 5 [145/172] - loss: 0.1470
Epoch 5 [146/172] - loss: 0.1077
Epoch 5 [147/172] - loss: 0.1167
Epoch 5 [148/172] - loss: 0.1058
Epoch 5 [149/172] - loss: 0.1237
Epoch 5 [150/172] - loss: 0.1348, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1086
Epoch 5 [152/172] - loss: 0.1073
Epoch 5 [153/172] - loss: 0.1067
Epoch 5 [154/172] - loss: 0.1093
Epoch 5 [155/172] - loss: 0.1788
Epoch 5 [156/172] - loss: 0.1113
Epoch 5 [157/172] - loss: 0.1240
Epoch 5 [158/172] - loss: 0.1076
Epoch 5 [159/172] - loss: 0.1071
Epoch 5 [160/172] - loss: 0.1077, acc: 1.0000
Epoch 5 [161/172] - loss: 0.1072
Epoch 5 [162/172] - loss: 0.1147
Epoch 5 [163/172] - loss: 0.1563
Epoch 5 [164/172] - loss: 0.1067
Epoch 5 [165/172] - loss: 0.1611
Epoch 5 [166/172] - loss: 0.1159
Epoch 5 [167/172] - loss: 0.1120
Epoch 5 [168/172] - loss: 0.1071
Epoch 5 [169/172] - loss: 0.1083
Epoch 5 [170/172] - loss: 0.1099, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1106
Epoch 5 [172/172] - loss: 0.1211

类别准确率:
positive: 0.8994 (420/467)
neutral: 0.2771 (23/83)
negative: 0.5160 (129/250)

Epoch 5/10
Train Loss: 0.1173, Train Acc: 0.9919
Val Loss: 0.9371, Val Acc: 0.7150
Early stopping triggered!
Best validation accuracy: 0.7438

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_051609-mctqmvum
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.35_Multimodal_iterations_20250118_051608
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/mctqmvum
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███
wandb:  train_acc ▁▄▂▃▄▆▃▄▆▆▆▇▅▇▆▇▇███▇███▇███████████████
wandb: train_loss ██▅▄▆▃▃▃▃▃▂▂▂▂▁▁▁▁▂▁▁▂▂▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▂▁
wandb: 
wandb: Run summary:
wandb:  iteration 858
wandb:  train_acc 1
wandb: train_loss 0.1099
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.35_Multimodal_iterations_20250118_051608 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/mctqmvum
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_051609-mctqmvum/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_052331-9u9966do
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.35_Multimodal_epochs_20250118_052331
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/9u9966do
wandb: uploading history steps 0-0, summary; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▃▅▆█
wandb:  train_acc ▁▅▇██
wandb: train_loss █▄▂▁▁
wandb:    val_acc ▁█▆▄▅
wandb:   val_loss ▃▁▄█▅
wandb: 
wandb: Run summary:
wandb:      epoch 5
wandb:  train_acc 0.99192
wandb: train_loss 0.11734
wandb:    val_acc 0.715
wandb:   val_loss 0.93712
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.35_Multimodal_epochs_20250118_052331 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/9u9966do
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_052331-9u9966do/logs

