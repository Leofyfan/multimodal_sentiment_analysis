=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 1.5 --dropout 0.35 --name loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.35 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.35
text_dim: 128
image_dim: 256
dropout: 0.35
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6769, log_difficulty=0.5169, weight=3.5847
neutral: count=7.0, difficulty=0.6688, log_difficulty=0.5121, weight=3.5605
negative: count=13.0, difficulty=0.6518, log_difficulty=0.5019, weight=3.5094

当前batch的pt分布：
positive: min=0.1938, max=0.4653, mean=0.3231
neutral: min=0.2028, max=0.4228, mean=0.3312
negative: min=0.2120, max=0.4939, mean=0.3482

当前batch准确率：
整体准确率: 0.2812
positive 准确率: 0.3333
neutral 准确率: 0.4286
negative 准确率: 0.1538

损失分量：
基础交叉熵: 1.1261
焦点损失: 0.3717
边界损失: 0.8179
总损失: 0.9434
Epoch 1 [1/172] - loss: 0.9434, acc: 0.2812
Epoch 1 [2/172] - loss: 0.9619
Epoch 1 [3/172] - loss: 0.9541
Epoch 1 [4/172] - loss: 0.9050
Epoch 1 [5/172] - loss: 0.8709
Epoch 1 [6/172] - loss: 1.1178
Epoch 1 [7/172] - loss: 0.9063
Epoch 1 [8/172] - loss: 0.8259
Epoch 1 [9/172] - loss: 0.8446
Epoch 1 [10/172] - loss: 0.9180, acc: 0.4375
Epoch 1 [11/172] - loss: 0.8347
Epoch 1 [12/172] - loss: 0.9093
Epoch 1 [13/172] - loss: 0.7512
Epoch 1 [14/172] - loss: 0.9676
Epoch 1 [15/172] - loss: 0.9316
Epoch 1 [16/172] - loss: 0.9002
Epoch 1 [17/172] - loss: 0.8253
Epoch 1 [18/172] - loss: 0.8728
Epoch 1 [19/172] - loss: 0.7825
Epoch 1 [20/172] - loss: 0.8030, acc: 0.4062
Epoch 1 [21/172] - loss: 0.9669
Epoch 1 [22/172] - loss: 0.8308
Epoch 1 [23/172] - loss: 0.8122
Epoch 1 [24/172] - loss: 0.8447
Epoch 1 [25/172] - loss: 0.7168
Epoch 1 [26/172] - loss: 0.8691
Epoch 1 [27/172] - loss: 0.7623
Epoch 1 [28/172] - loss: 0.8475
Epoch 1 [29/172] - loss: 0.8921
Epoch 1 [30/172] - loss: 0.7560, acc: 0.5312
Epoch 1 [31/172] - loss: 0.8492
Epoch 1 [32/172] - loss: 0.6658
Epoch 1 [33/172] - loss: 0.6937
Epoch 1 [34/172] - loss: 0.6576
Epoch 1 [35/172] - loss: 0.7453
Epoch 1 [36/172] - loss: 0.5502
Epoch 1 [37/172] - loss: 0.6728
Epoch 1 [38/172] - loss: 0.7714
Epoch 1 [39/172] - loss: 0.6884
Epoch 1 [40/172] - loss: 0.6309, acc: 0.6562
Epoch 1 [41/172] - loss: 0.7692
Epoch 1 [42/172] - loss: 0.5716
Epoch 1 [43/172] - loss: 0.6448
Epoch 1 [44/172] - loss: 0.8142
Epoch 1 [45/172] - loss: 0.7844
Epoch 1 [46/172] - loss: 0.5837
Epoch 1 [47/172] - loss: 0.7143
Epoch 1 [48/172] - loss: 0.7567
Epoch 1 [49/172] - loss: 0.6597
Epoch 1 [50/172] - loss: 0.5612, acc: 0.6562
Epoch 1 [51/172] - loss: 0.6496
Epoch 1 [52/172] - loss: 0.6889
Epoch 1 [53/172] - loss: 0.6454
Epoch 1 [54/172] - loss: 0.7197
Epoch 1 [55/172] - loss: 0.5847
Epoch 1 [56/172] - loss: 0.5464
Epoch 1 [57/172] - loss: 0.9343
Epoch 1 [58/172] - loss: 0.5587
Epoch 1 [59/172] - loss: 0.7600
Epoch 1 [60/172] - loss: 0.5203, acc: 0.7188
Epoch 1 [61/172] - loss: 0.6733
Epoch 1 [62/172] - loss: 0.6500
Epoch 1 [63/172] - loss: 0.6163
Epoch 1 [64/172] - loss: 0.5541
Epoch 1 [65/172] - loss: 0.7193
Epoch 1 [66/172] - loss: 0.6185
Epoch 1 [67/172] - loss: 0.8420
Epoch 1 [68/172] - loss: 0.5570
Epoch 1 [69/172] - loss: 0.6815
Epoch 1 [70/172] - loss: 0.5879, acc: 0.6250
Epoch 1 [71/172] - loss: 0.3621
Epoch 1 [72/172] - loss: 0.6023
Epoch 1 [73/172] - loss: 0.5959
Epoch 1 [74/172] - loss: 0.5830
Epoch 1 [75/172] - loss: 0.4130
Epoch 1 [76/172] - loss: 0.5655
Epoch 1 [77/172] - loss: 0.5528
Epoch 1 [78/172] - loss: 0.5765
Epoch 1 [79/172] - loss: 0.5663
Epoch 1 [80/172] - loss: 0.3572, acc: 0.8125
Epoch 1 [81/172] - loss: 0.5957
Epoch 1 [82/172] - loss: 0.6838
Epoch 1 [83/172] - loss: 0.6795
Epoch 1 [84/172] - loss: 0.5266
Epoch 1 [85/172] - loss: 0.5191
Epoch 1 [86/172] - loss: 0.4442
Epoch 1 [87/172] - loss: 0.4164
Epoch 1 [88/172] - loss: 0.7424
Epoch 1 [89/172] - loss: 0.7744
Epoch 1 [90/172] - loss: 0.7101, acc: 0.5312
Epoch 1 [91/172] - loss: 0.4383
Epoch 1 [92/172] - loss: 0.5801
Epoch 1 [93/172] - loss: 0.4987
Epoch 1 [94/172] - loss: 0.4299
Epoch 1 [95/172] - loss: 0.5282
Epoch 1 [96/172] - loss: 0.4308
Epoch 1 [97/172] - loss: 0.4497
Epoch 1 [98/172] - loss: 0.4827
Epoch 1 [99/172] - loss: 0.6530
Epoch 1 [100/172] - loss: 0.4573, acc: 0.6875

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5584, log_difficulty=0.4437, weight=3.2183
neutral: count=983.0, difficulty=0.5066, log_difficulty=0.4099, weight=3.0494
negative: count=1119.0, difficulty=0.5011, log_difficulty=0.4062, weight=3.0311

当前batch的pt分布：
positive: min=0.0731, max=0.9768, mean=0.4844
neutral: min=0.3264, max=0.9985, mean=0.7053
negative: min=0.0986, max=0.8815, mean=0.4880

当前batch准确率：
整体准确率: 0.5938
positive 准确率: 0.5833
neutral 准确率: 0.7500
negative 准确率: 0.5625

损失分量：
基础交叉熵: 0.9136
焦点损失: 0.4546
边界损失: 0.3700
总损失: 0.6323
Epoch 1 [101/172] - loss: 0.6323
Epoch 1 [102/172] - loss: 0.6387
Epoch 1 [103/172] - loss: 0.4821
Epoch 1 [104/172] - loss: 0.3616
Epoch 1 [105/172] - loss: 0.5218
Epoch 1 [106/172] - loss: 0.6089
Epoch 1 [107/172] - loss: 0.3943
Epoch 1 [108/172] - loss: 0.5610
Epoch 1 [109/172] - loss: 0.5082
Epoch 1 [110/172] - loss: 0.4826, acc: 0.7812
Epoch 1 [111/172] - loss: 0.5662
Epoch 1 [112/172] - loss: 0.4415
Epoch 1 [113/172] - loss: 0.3500
Epoch 1 [114/172] - loss: 0.5018
Epoch 1 [115/172] - loss: 0.4759
Epoch 1 [116/172] - loss: 0.4917
Epoch 1 [117/172] - loss: 0.5171
Epoch 1 [118/172] - loss: 0.3240
Epoch 1 [119/172] - loss: 0.4445
Epoch 1 [120/172] - loss: 0.3656, acc: 0.8438
Epoch 1 [121/172] - loss: 0.3714
Epoch 1 [122/172] - loss: 0.6134
Epoch 1 [123/172] - loss: 0.3174
Epoch 1 [124/172] - loss: 0.4006
Epoch 1 [125/172] - loss: 0.3204
Epoch 1 [126/172] - loss: 0.5829
Epoch 1 [127/172] - loss: 0.3456
Epoch 1 [128/172] - loss: 0.3362
Epoch 1 [129/172] - loss: 0.4756
Epoch 1 [130/172] - loss: 0.3878, acc: 0.8125
Epoch 1 [131/172] - loss: 0.2510
Epoch 1 [132/172] - loss: 0.4005
Epoch 1 [133/172] - loss: 0.3594
Epoch 1 [134/172] - loss: 0.4265
Epoch 1 [135/172] - loss: 0.5235
Epoch 1 [136/172] - loss: 0.3388
Epoch 1 [137/172] - loss: 0.4532
Epoch 1 [138/172] - loss: 0.3462
Epoch 1 [139/172] - loss: 0.3220
Epoch 1 [140/172] - loss: 0.3639, acc: 0.8125
Epoch 1 [141/172] - loss: 0.4369
Epoch 1 [142/172] - loss: 0.4842
Epoch 1 [143/172] - loss: 0.5804
Epoch 1 [144/172] - loss: 0.3022
Epoch 1 [145/172] - loss: 0.4395
Epoch 1 [146/172] - loss: 0.4636
Epoch 1 [147/172] - loss: 0.5611
Epoch 1 [148/172] - loss: 0.4192
Epoch 1 [149/172] - loss: 0.3337
Epoch 1 [150/172] - loss: 0.4747, acc: 0.6875
Epoch 1 [151/172] - loss: 0.4522
Epoch 1 [152/172] - loss: 0.4048
Epoch 1 [153/172] - loss: 0.3612
Epoch 1 [154/172] - loss: 0.3988
Epoch 1 [155/172] - loss: 0.3322
Epoch 1 [156/172] - loss: 0.6479
Epoch 1 [157/172] - loss: 0.4111
Epoch 1 [158/172] - loss: 0.3602
Epoch 1 [159/172] - loss: 0.5416
Epoch 1 [160/172] - loss: 0.3173, acc: 0.7500
Epoch 1 [161/172] - loss: 0.3338
Epoch 1 [162/172] - loss: 0.3336
Epoch 1 [163/172] - loss: 0.5276
Epoch 1 [164/172] - loss: 0.4782
Epoch 1 [165/172] - loss: 0.3956
Epoch 1 [166/172] - loss: 0.3716
Epoch 1 [167/172] - loss: 0.3817
Epoch 1 [168/172] - loss: 0.5204
Epoch 1 [169/172] - loss: 0.4357
Epoch 1 [170/172] - loss: 0.3637, acc: 0.8438
Epoch 1 [171/172] - loss: 0.3023
Epoch 1 [172/172] - loss: 0.3672

类别准确率:
positive: 0.7088 (331/467)
neutral: 0.6265 (52/83)
negative: 0.5240 (131/250)

Epoch 1/10
Train Loss: 0.4026, Train Acc: 0.7859
Val Loss: 0.8154, Val Acc: 0.6425
Epoch 2 [1/172] - loss: 0.2772, acc: 0.8438
Epoch 2 [2/172] - loss: 0.2328
Epoch 2 [3/172] - loss: 0.2463
Epoch 2 [4/172] - loss: 0.3575
Epoch 2 [5/172] - loss: 0.4625
Epoch 2 [6/172] - loss: 0.3464
Epoch 2 [7/172] - loss: 0.3215
Epoch 2 [8/172] - loss: 0.3228
Epoch 2 [9/172] - loss: 0.2573
Epoch 2 [10/172] - loss: 0.3196, acc: 0.8750
Epoch 2 [11/172] - loss: 0.3085
Epoch 2 [12/172] - loss: 0.2685
Epoch 2 [13/172] - loss: 0.3936
Epoch 2 [14/172] - loss: 0.2521
Epoch 2 [15/172] - loss: 0.4082
Epoch 2 [16/172] - loss: 0.3339
Epoch 2 [17/172] - loss: 0.3996
Epoch 2 [18/172] - loss: 0.4384
Epoch 2 [19/172] - loss: 0.3637
Epoch 2 [20/172] - loss: 0.2458, acc: 0.9375
Epoch 2 [21/172] - loss: 0.2593
Epoch 2 [22/172] - loss: 0.3278
Epoch 2 [23/172] - loss: 0.2419
Epoch 2 [24/172] - loss: 0.4424
Epoch 2 [25/172] - loss: 0.2764
Epoch 2 [26/172] - loss: 0.2020
Epoch 2 [27/172] - loss: 0.2696
Epoch 2 [28/172] - loss: 0.2595

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4580, log_difficulty=0.3771, weight=2.8854
neutral: count=1952.0, difficulty=0.3763, log_difficulty=0.3194, weight=2.5971
negative: count=2216.0, difficulty=0.4255, log_difficulty=0.3545, weight=2.7727

当前batch的pt分布：
positive: min=0.4235, max=0.9851, mean=0.8503
neutral: min=0.5157, max=0.9963, mean=0.8537
negative: min=0.0208, max=0.9867, mean=0.7229

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.3384
焦点损失: 0.1502
边界损失: 0.2255
总损失: 0.2732
Epoch 2 [29/172] - loss: 0.2732
Epoch 2 [30/172] - loss: 0.3015, acc: 0.9062
Epoch 2 [31/172] - loss: 0.2827
Epoch 2 [32/172] - loss: 0.3028
Epoch 2 [33/172] - loss: 0.2471
Epoch 2 [34/172] - loss: 0.3401
Epoch 2 [35/172] - loss: 0.2083
Epoch 2 [36/172] - loss: 0.3397
Epoch 2 [37/172] - loss: 0.2174
Epoch 2 [38/172] - loss: 0.2994
Epoch 2 [39/172] - loss: 0.3351
Epoch 2 [40/172] - loss: 0.3275, acc: 0.7812
Epoch 2 [41/172] - loss: 0.2339
Epoch 2 [42/172] - loss: 0.1716
Epoch 2 [43/172] - loss: 0.2025
Epoch 2 [44/172] - loss: 0.4226
Epoch 2 [45/172] - loss: 0.2643
Epoch 2 [46/172] - loss: 0.2321
Epoch 2 [47/172] - loss: 0.2320
Epoch 2 [48/172] - loss: 0.3283
Epoch 2 [49/172] - loss: 0.2519
Epoch 2 [50/172] - loss: 0.3268, acc: 0.8125
Epoch 2 [51/172] - loss: 0.3339
Epoch 2 [52/172] - loss: 0.2628
Epoch 2 [53/172] - loss: 0.1963
Epoch 2 [54/172] - loss: 0.2239
Epoch 2 [55/172] - loss: 0.3157
Epoch 2 [56/172] - loss: 0.3056
Epoch 2 [57/172] - loss: 0.2947
Epoch 2 [58/172] - loss: 0.2791
Epoch 2 [59/172] - loss: 0.3558
Epoch 2 [60/172] - loss: 0.2481, acc: 0.9062
Epoch 2 [61/172] - loss: 0.1699
Epoch 2 [62/172] - loss: 0.2123
Epoch 2 [63/172] - loss: 0.3541
Epoch 2 [64/172] - loss: 0.2226
Epoch 2 [65/172] - loss: 0.2698
Epoch 2 [66/172] - loss: 0.2810
Epoch 2 [67/172] - loss: 0.1893
Epoch 2 [68/172] - loss: 0.3255
Epoch 2 [69/172] - loss: 0.2241
Epoch 2 [70/172] - loss: 0.3010, acc: 0.8438
Epoch 2 [71/172] - loss: 0.3490
Epoch 2 [72/172] - loss: 0.3039
Epoch 2 [73/172] - loss: 0.2557
Epoch 2 [74/172] - loss: 0.2512
Epoch 2 [75/172] - loss: 0.2725
Epoch 2 [76/172] - loss: 0.2024
Epoch 2 [77/172] - loss: 0.2600
Epoch 2 [78/172] - loss: 0.3218
Epoch 2 [79/172] - loss: 0.2789
Epoch 2 [80/172] - loss: 0.2081, acc: 0.9688
Epoch 2 [81/172] - loss: 0.2890
Epoch 2 [82/172] - loss: 0.2953
Epoch 2 [83/172] - loss: 0.2617
Epoch 2 [84/172] - loss: 0.2764
Epoch 2 [85/172] - loss: 0.2567
Epoch 2 [86/172] - loss: 0.2304
Epoch 2 [87/172] - loss: 0.5859
Epoch 2 [88/172] - loss: 0.2557
Epoch 2 [89/172] - loss: 0.2636
Epoch 2 [90/172] - loss: 0.2503, acc: 0.8438
Epoch 2 [91/172] - loss: 0.1793
Epoch 2 [92/172] - loss: 0.2916
Epoch 2 [93/172] - loss: 0.2237
Epoch 2 [94/172] - loss: 0.2130
Epoch 2 [95/172] - loss: 0.2493
Epoch 2 [96/172] - loss: 0.1978
Epoch 2 [97/172] - loss: 0.2770
Epoch 2 [98/172] - loss: 0.2115
Epoch 2 [99/172] - loss: 0.1820
Epoch 2 [100/172] - loss: 0.2347, acc: 0.8750
Epoch 2 [101/172] - loss: 0.1898
Epoch 2 [102/172] - loss: 0.2399
Epoch 2 [103/172] - loss: 0.2118
Epoch 2 [104/172] - loss: 0.3185
Epoch 2 [105/172] - loss: 0.1927
Epoch 2 [106/172] - loss: 0.2127
Epoch 2 [107/172] - loss: 0.1723
Epoch 2 [108/172] - loss: 0.2880
Epoch 2 [109/172] - loss: 0.2709
Epoch 2 [110/172] - loss: 0.2221, acc: 0.8438
Epoch 2 [111/172] - loss: 0.2265
Epoch 2 [112/172] - loss: 0.1563
Epoch 2 [113/172] - loss: 0.1996
Epoch 2 [114/172] - loss: 0.2133
Epoch 2 [115/172] - loss: 0.2299
Epoch 2 [116/172] - loss: 0.2453
Epoch 2 [117/172] - loss: 0.4400
Epoch 2 [118/172] - loss: 0.2134
Epoch 2 [119/172] - loss: 0.2488
Epoch 2 [120/172] - loss: 0.2709, acc: 0.9062
Epoch 2 [121/172] - loss: 0.2173
Epoch 2 [122/172] - loss: 0.4367
Epoch 2 [123/172] - loss: 0.1978
Epoch 2 [124/172] - loss: 0.1821
Epoch 2 [125/172] - loss: 0.2169
Epoch 2 [126/172] - loss: 0.1720
Epoch 2 [127/172] - loss: 0.1680
Epoch 2 [128/172] - loss: 0.2436

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3895, log_difficulty=0.3290, weight=2.6448
neutral: count=2949.0, difficulty=0.2913, log_difficulty=0.2557, weight=2.2783
negative: count=3294.0, difficulty=0.3608, log_difficulty=0.3081, weight=2.5403

当前batch的pt分布：
positive: min=0.4543, max=0.9826, mean=0.8339
neutral: min=0.1719, max=0.9994, mean=0.8305
negative: min=0.0938, max=0.9826, mean=0.7811

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.9000
neutral 准确率: 0.8182
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.2980
焦点损失: 0.1188
边界损失: 0.2232
总损失: 0.2402
Epoch 2 [129/172] - loss: 0.2402
Epoch 2 [130/172] - loss: 0.2696, acc: 0.8438
Epoch 2 [131/172] - loss: 0.2473
Epoch 2 [132/172] - loss: 0.2669
Epoch 2 [133/172] - loss: 0.2472
Epoch 2 [134/172] - loss: 0.1795
Epoch 2 [135/172] - loss: 0.3264
Epoch 2 [136/172] - loss: 0.1583
Epoch 2 [137/172] - loss: 0.2373
Epoch 2 [138/172] - loss: 0.2161
Epoch 2 [139/172] - loss: 0.1987
Epoch 2 [140/172] - loss: 0.2402, acc: 0.8750
Epoch 2 [141/172] - loss: 0.2431
Epoch 2 [142/172] - loss: 0.3611
Epoch 2 [143/172] - loss: 0.3182
Epoch 2 [144/172] - loss: 0.2187
Epoch 2 [145/172] - loss: 0.3157
Epoch 2 [146/172] - loss: 0.1577
Epoch 2 [147/172] - loss: 0.2473
Epoch 2 [148/172] - loss: 0.2113
Epoch 2 [149/172] - loss: 0.1777
Epoch 2 [150/172] - loss: 0.2796, acc: 0.9062
Epoch 2 [151/172] - loss: 0.2135
Epoch 2 [152/172] - loss: 0.1832
Epoch 2 [153/172] - loss: 0.2077
Epoch 2 [154/172] - loss: 0.2264
Epoch 2 [155/172] - loss: 0.2350
Epoch 2 [156/172] - loss: 0.3074
Epoch 2 [157/172] - loss: 0.1788
Epoch 2 [158/172] - loss: 0.2957
Epoch 2 [159/172] - loss: 0.1909
Epoch 2 [160/172] - loss: 0.2087, acc: 0.9375
Epoch 2 [161/172] - loss: 0.2306
Epoch 2 [162/172] - loss: 0.2071
Epoch 2 [163/172] - loss: 0.3501
Epoch 2 [164/172] - loss: 0.2134
Epoch 2 [165/172] - loss: 0.2859
Epoch 2 [166/172] - loss: 0.3198
Epoch 2 [167/172] - loss: 0.2420
Epoch 2 [168/172] - loss: 0.1510
Epoch 2 [169/172] - loss: 0.1775
Epoch 2 [170/172] - loss: 0.1872, acc: 0.9062
Epoch 2 [171/172] - loss: 0.3176
Epoch 2 [172/172] - loss: 0.3243

类别准确率:
positive: 0.8694 (406/467)
neutral: 0.2771 (23/83)
negative: 0.6000 (150/250)

Epoch 2/10
Train Loss: 0.2425, Train Acc: 0.9051
Val Loss: 0.7695, Val Acc: 0.7238
Epoch 3 [1/172] - loss: 0.2180, acc: 0.9688
Epoch 3 [2/172] - loss: 0.1703
Epoch 3 [3/172] - loss: 0.1342
Epoch 3 [4/172] - loss: 0.2251
Epoch 3 [5/172] - loss: 0.1484
Epoch 3 [6/172] - loss: 0.1535
Epoch 3 [7/172] - loss: 0.1362
Epoch 3 [8/172] - loss: 0.2208
Epoch 3 [9/172] - loss: 0.2034
Epoch 3 [10/172] - loss: 0.1678, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1535
Epoch 3 [12/172] - loss: 0.1579
Epoch 3 [13/172] - loss: 0.1272
Epoch 3 [14/172] - loss: 0.1523
Epoch 3 [15/172] - loss: 0.1387
Epoch 3 [16/172] - loss: 0.2847
Epoch 3 [17/172] - loss: 0.2182
Epoch 3 [18/172] - loss: 0.2523
Epoch 3 [19/172] - loss: 0.1307
Epoch 3 [20/172] - loss: 0.1335, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1794
Epoch 3 [22/172] - loss: 0.1798
Epoch 3 [23/172] - loss: 0.1559
Epoch 3 [24/172] - loss: 0.1669
Epoch 3 [25/172] - loss: 0.1220
Epoch 3 [26/172] - loss: 0.1405
Epoch 3 [27/172] - loss: 0.1582
Epoch 3 [28/172] - loss: 0.1390
Epoch 3 [29/172] - loss: 0.1739
Epoch 3 [30/172] - loss: 0.1745, acc: 0.9375
Epoch 3 [31/172] - loss: 0.1488
Epoch 3 [32/172] - loss: 0.2050
Epoch 3 [33/172] - loss: 0.1391
Epoch 3 [34/172] - loss: 0.1932
Epoch 3 [35/172] - loss: 0.1750
Epoch 3 [36/172] - loss: 0.1431
Epoch 3 [37/172] - loss: 0.2049
Epoch 3 [38/172] - loss: 0.1196
Epoch 3 [39/172] - loss: 0.1535
Epoch 3 [40/172] - loss: 0.1915, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1248
Epoch 3 [42/172] - loss: 0.1860
Epoch 3 [43/172] - loss: 0.1255
Epoch 3 [44/172] - loss: 0.1302
Epoch 3 [45/172] - loss: 0.2089
Epoch 3 [46/172] - loss: 0.1787
Epoch 3 [47/172] - loss: 0.1277
Epoch 3 [48/172] - loss: 0.2460
Epoch 3 [49/172] - loss: 0.1174
Epoch 3 [50/172] - loss: 0.1372, acc: 0.9688
Epoch 3 [51/172] - loss: 0.1642
Epoch 3 [52/172] - loss: 0.2672
Epoch 3 [53/172] - loss: 0.1329
Epoch 3 [54/172] - loss: 0.1759
Epoch 3 [55/172] - loss: 0.1216
Epoch 3 [56/172] - loss: 0.1796

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3298, log_difficulty=0.2850, weight=2.4252
neutral: count=3923.0, difficulty=0.2419, log_difficulty=0.2167, weight=2.0834
negative: count=4382.0, difficulty=0.3069, log_difficulty=0.2676, weight=2.3382

当前batch的pt分布：
positive: min=0.0165, max=0.9988, mean=0.7476
neutral: min=0.0091, max=0.9875, mean=0.7969
negative: min=0.9698, max=0.9973, mean=0.9870

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.8182
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.5160
焦点损失: 0.4049
边界损失: 0.1831
总损失: 0.3644
Epoch 3 [57/172] - loss: 0.3644
Epoch 3 [58/172] - loss: 0.1378
Epoch 3 [59/172] - loss: 0.1322
Epoch 3 [60/172] - loss: 0.1633, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1566
Epoch 3 [62/172] - loss: 0.1548
Epoch 3 [63/172] - loss: 0.1625
Epoch 3 [64/172] - loss: 0.1636
Epoch 3 [65/172] - loss: 0.1600
Epoch 3 [66/172] - loss: 0.1616
Epoch 3 [67/172] - loss: 0.1559
Epoch 3 [68/172] - loss: 0.1441
Epoch 3 [69/172] - loss: 0.1632
Epoch 3 [70/172] - loss: 0.1200, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1645
Epoch 3 [72/172] - loss: 0.2287
Epoch 3 [73/172] - loss: 0.1357
Epoch 3 [74/172] - loss: 0.1862
Epoch 3 [75/172] - loss: 0.1577
Epoch 3 [76/172] - loss: 0.1285
Epoch 3 [77/172] - loss: 0.1406
Epoch 3 [78/172] - loss: 0.2390
Epoch 3 [79/172] - loss: 0.1468
Epoch 3 [80/172] - loss: 0.1995, acc: 0.9062
Epoch 3 [81/172] - loss: 0.1670
Epoch 3 [82/172] - loss: 0.1901
Epoch 3 [83/172] - loss: 0.1347
Epoch 3 [84/172] - loss: 0.1209
Epoch 3 [85/172] - loss: 0.1562
Epoch 3 [86/172] - loss: 0.1408
Epoch 3 [87/172] - loss: 0.1790
Epoch 3 [88/172] - loss: 0.1472
Epoch 3 [89/172] - loss: 0.1281
Epoch 3 [90/172] - loss: 0.1365, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1376
Epoch 3 [92/172] - loss: 0.2106
Epoch 3 [93/172] - loss: 0.1899
Epoch 3 [94/172] - loss: 0.1812
Epoch 3 [95/172] - loss: 0.1234
Epoch 3 [96/172] - loss: 0.1732
Epoch 3 [97/172] - loss: 0.1288
Epoch 3 [98/172] - loss: 0.1512
Epoch 3 [99/172] - loss: 0.1335
Epoch 3 [100/172] - loss: 0.2046, acc: 0.9688
Epoch 3 [101/172] - loss: 0.2384
Epoch 3 [102/172] - loss: 0.1220
Epoch 3 [103/172] - loss: 0.1695
Epoch 3 [104/172] - loss: 0.1343
Epoch 3 [105/172] - loss: 0.1190
Epoch 3 [106/172] - loss: 0.1836
Epoch 3 [107/172] - loss: 0.1207
Epoch 3 [108/172] - loss: 0.1344
Epoch 3 [109/172] - loss: 0.1162
Epoch 3 [110/172] - loss: 0.2121, acc: 0.9375
Epoch 3 [111/172] - loss: 0.1478
Epoch 3 [112/172] - loss: 0.1408
Epoch 3 [113/172] - loss: 0.1255
Epoch 3 [114/172] - loss: 0.1283
Epoch 3 [115/172] - loss: 0.1226
Epoch 3 [116/172] - loss: 0.1271
Epoch 3 [117/172] - loss: 0.1462
Epoch 3 [118/172] - loss: 0.1472
Epoch 3 [119/172] - loss: 0.1817
Epoch 3 [120/172] - loss: 0.1854, acc: 0.9375
Epoch 3 [121/172] - loss: 0.1311
Epoch 3 [122/172] - loss: 0.1502
Epoch 3 [123/172] - loss: 0.1318
Epoch 3 [124/172] - loss: 0.2002
Epoch 3 [125/172] - loss: 0.1149
Epoch 3 [126/172] - loss: 0.2418
Epoch 3 [127/172] - loss: 0.1500
Epoch 3 [128/172] - loss: 0.1291
Epoch 3 [129/172] - loss: 0.1100
Epoch 3 [130/172] - loss: 0.1508, acc: 0.9688
Epoch 3 [131/172] - loss: 0.1618
Epoch 3 [132/172] - loss: 0.1351
Epoch 3 [133/172] - loss: 0.1234
Epoch 3 [134/172] - loss: 0.1099
Epoch 3 [135/172] - loss: 0.1472
Epoch 3 [136/172] - loss: 0.1248
Epoch 3 [137/172] - loss: 0.1222
Epoch 3 [138/172] - loss: 0.1664
Epoch 3 [139/172] - loss: 0.1408
Epoch 3 [140/172] - loss: 0.1566, acc: 0.9375
Epoch 3 [141/172] - loss: 0.2325
Epoch 3 [142/172] - loss: 0.1575
Epoch 3 [143/172] - loss: 0.1625
Epoch 3 [144/172] - loss: 0.2516
Epoch 3 [145/172] - loss: 0.1427
Epoch 3 [146/172] - loss: 0.1343
Epoch 3 [147/172] - loss: 0.1453
Epoch 3 [148/172] - loss: 0.1676
Epoch 3 [149/172] - loss: 0.2106
Epoch 3 [150/172] - loss: 0.2344, acc: 0.9375
Epoch 3 [151/172] - loss: 0.2029
Epoch 3 [152/172] - loss: 0.1946
Epoch 3 [153/172] - loss: 0.1526
Epoch 3 [154/172] - loss: 0.2279
Epoch 3 [155/172] - loss: 0.1136
Epoch 3 [156/172] - loss: 0.1499

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2847, log_difficulty=0.2505, weight=2.2524
neutral: count=4903.0, difficulty=0.2049, log_difficulty=0.1864, weight=1.9319
negative: count=5500.0, difficulty=0.2645, log_difficulty=0.2347, weight=2.1734

当前batch的pt分布：
positive: min=0.7968, max=0.9964, mean=0.9522
neutral: min=0.9341, max=0.9969, mean=0.9813
negative: min=0.0153, max=0.9992, mean=0.8852

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1598
焦点损失: 0.1265
边界损失: 0.1493
总损失: 0.1807
Epoch 3 [157/172] - loss: 0.1807
Epoch 3 [158/172] - loss: 0.1932
Epoch 3 [159/172] - loss: 0.1307
Epoch 3 [160/172] - loss: 0.2021, acc: 0.9375
Epoch 3 [161/172] - loss: 0.2075
Epoch 3 [162/172] - loss: 0.1328
Epoch 3 [163/172] - loss: 0.2089
Epoch 3 [164/172] - loss: 0.1137
Epoch 3 [165/172] - loss: 0.1498
Epoch 3 [166/172] - loss: 0.1555
Epoch 3 [167/172] - loss: 0.1190
Epoch 3 [168/172] - loss: 0.1341
Epoch 3 [169/172] - loss: 0.1135
Epoch 3 [170/172] - loss: 0.1756, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1629
Epoch 3 [172/172] - loss: 0.1596

类别准确率:
positive: 0.9143 (427/467)
neutral: 0.3012 (25/83)
negative: 0.4280 (107/250)

Epoch 3/10
Train Loss: 0.1587, Train Acc: 0.9677
Val Loss: 0.8994, Val Acc: 0.6987
Epoch 4 [1/172] - loss: 0.1711, acc: 0.9688
Epoch 4 [2/172] - loss: 0.1341
Epoch 4 [3/172] - loss: 0.1483
Epoch 4 [4/172] - loss: 0.1241
Epoch 4 [5/172] - loss: 0.1280
Epoch 4 [6/172] - loss: 0.1180
Epoch 4 [7/172] - loss: 0.1272
Epoch 4 [8/172] - loss: 0.1102
Epoch 4 [9/172] - loss: 0.1690
Epoch 4 [10/172] - loss: 0.1354, acc: 0.9375
Epoch 4 [11/172] - loss: 0.1178
Epoch 4 [12/172] - loss: 0.1432
Epoch 4 [13/172] - loss: 0.1901
Epoch 4 [14/172] - loss: 0.1266
Epoch 4 [15/172] - loss: 0.1111
Epoch 4 [16/172] - loss: 0.1160
Epoch 4 [17/172] - loss: 0.1182
Epoch 4 [18/172] - loss: 0.1556
Epoch 4 [19/172] - loss: 0.1221
Epoch 4 [20/172] - loss: 0.1213, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1856
Epoch 4 [22/172] - loss: 0.1348
Epoch 4 [23/172] - loss: 0.1309
Epoch 4 [24/172] - loss: 0.1133
Epoch 4 [25/172] - loss: 0.1116
Epoch 4 [26/172] - loss: 0.1751
Epoch 4 [27/172] - loss: 0.1129
Epoch 4 [28/172] - loss: 0.1552
Epoch 4 [29/172] - loss: 0.1120
Epoch 4 [30/172] - loss: 0.1296, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1521
Epoch 4 [32/172] - loss: 0.1137
Epoch 4 [33/172] - loss: 0.1232
Epoch 4 [34/172] - loss: 0.1102
Epoch 4 [35/172] - loss: 0.1383
Epoch 4 [36/172] - loss: 0.1372
Epoch 4 [37/172] - loss: 0.1086
Epoch 4 [38/172] - loss: 0.1105
Epoch 4 [39/172] - loss: 0.1743
Epoch 4 [40/172] - loss: 0.1387, acc: 1.0000
Epoch 4 [41/172] - loss: 0.1166
Epoch 4 [42/172] - loss: 0.1480
Epoch 4 [43/172] - loss: 0.1774
Epoch 4 [44/172] - loss: 0.1379
Epoch 4 [45/172] - loss: 0.1159
Epoch 4 [46/172] - loss: 0.1104
Epoch 4 [47/172] - loss: 0.1530
Epoch 4 [48/172] - loss: 0.1225
Epoch 4 [49/172] - loss: 0.1157
Epoch 4 [50/172] - loss: 0.1583, acc: 0.9688
Epoch 4 [51/172] - loss: 0.1123
Epoch 4 [52/172] - loss: 0.1416
Epoch 4 [53/172] - loss: 0.1116
Epoch 4 [54/172] - loss: 0.1251
Epoch 4 [55/172] - loss: 0.2055
Epoch 4 [56/172] - loss: 0.1293
Epoch 4 [57/172] - loss: 0.1130
Epoch 4 [58/172] - loss: 0.1096
Epoch 4 [59/172] - loss: 0.1173
Epoch 4 [60/172] - loss: 0.1152, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1415
Epoch 4 [62/172] - loss: 0.1230
Epoch 4 [63/172] - loss: 0.1240
Epoch 4 [64/172] - loss: 0.1205
Epoch 4 [65/172] - loss: 0.1372
Epoch 4 [66/172] - loss: 0.1165
Epoch 4 [67/172] - loss: 0.1142
Epoch 4 [68/172] - loss: 0.1263
Epoch 4 [69/172] - loss: 0.1470
Epoch 4 [70/172] - loss: 0.1301, acc: 0.9688
Epoch 4 [71/172] - loss: 0.1249
Epoch 4 [72/172] - loss: 0.1125
Epoch 4 [73/172] - loss: 0.1096
Epoch 4 [74/172] - loss: 0.1849
Epoch 4 [75/172] - loss: 0.1228
Epoch 4 [76/172] - loss: 0.1097
Epoch 4 [77/172] - loss: 0.1257
Epoch 4 [78/172] - loss: 0.1185
Epoch 4 [79/172] - loss: 0.1275
Epoch 4 [80/172] - loss: 0.1594, acc: 0.9688
Epoch 4 [81/172] - loss: 0.1293
Epoch 4 [82/172] - loss: 0.1212
Epoch 4 [83/172] - loss: 0.1114
Epoch 4 [84/172] - loss: 0.1222

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2487, log_difficulty=0.2221, weight=2.1104
neutral: count=5865.0, difficulty=0.1792, log_difficulty=0.1649, weight=1.8243
negative: count=6629.0, difficulty=0.2312, log_difficulty=0.2080, weight=2.0401

当前batch的pt分布：
positive: min=0.3450, max=0.9983, mean=0.8454
neutral: min=0.9691, max=0.9997, mean=0.9944
negative: min=0.8839, max=0.9987, mean=0.9736

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1198
焦点损失: 0.0323
边界损失: 0.1733
总损失: 0.1470
Epoch 4 [85/172] - loss: 0.1470
Epoch 4 [86/172] - loss: 0.1975
Epoch 4 [87/172] - loss: 0.1184
Epoch 4 [88/172] - loss: 0.1132
Epoch 4 [89/172] - loss: 0.1231
Epoch 4 [90/172] - loss: 0.1154, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1564
Epoch 4 [92/172] - loss: 0.1586
Epoch 4 [93/172] - loss: 0.1130
Epoch 4 [94/172] - loss: 0.1093
Epoch 4 [95/172] - loss: 0.1534
Epoch 4 [96/172] - loss: 0.1180
Epoch 4 [97/172] - loss: 0.1265
Epoch 4 [98/172] - loss: 0.1268
Epoch 4 [99/172] - loss: 0.1157
Epoch 4 [100/172] - loss: 0.1263, acc: 0.9688
Epoch 4 [101/172] - loss: 0.1161
Epoch 4 [102/172] - loss: 0.1220
Epoch 4 [103/172] - loss: 0.1205
Epoch 4 [104/172] - loss: 0.1236
Epoch 4 [105/172] - loss: 0.1412
Epoch 4 [106/172] - loss: 0.1086
Epoch 4 [107/172] - loss: 0.1136
Epoch 4 [108/172] - loss: 0.1253
Epoch 4 [109/172] - loss: 0.1272
Epoch 4 [110/172] - loss: 0.1693, acc: 0.9062
Epoch 4 [111/172] - loss: 0.1251
Epoch 4 [112/172] - loss: 0.1146
Epoch 4 [113/172] - loss: 0.1128
Epoch 4 [114/172] - loss: 0.1442
Epoch 4 [115/172] - loss: 0.1286
Epoch 4 [116/172] - loss: 0.1953
Epoch 4 [117/172] - loss: 0.1091
Epoch 4 [118/172] - loss: 0.1444
Epoch 4 [119/172] - loss: 0.1148
Epoch 4 [120/172] - loss: 0.1521, acc: 0.9688
Epoch 4 [121/172] - loss: 0.1594
Epoch 4 [122/172] - loss: 0.1858
Epoch 4 [123/172] - loss: 0.1107
Epoch 4 [124/172] - loss: 0.1110
Epoch 4 [125/172] - loss: 0.1935
Epoch 4 [126/172] - loss: 0.1489
Epoch 4 [127/172] - loss: 0.1425
Epoch 4 [128/172] - loss: 0.1128
Epoch 4 [129/172] - loss: 0.1171
Epoch 4 [130/172] - loss: 0.1157, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1343
Epoch 4 [132/172] - loss: 0.1149
Epoch 4 [133/172] - loss: 0.1182
Epoch 4 [134/172] - loss: 0.1109
Epoch 4 [135/172] - loss: 0.1276
Epoch 4 [136/172] - loss: 0.1277
Epoch 4 [137/172] - loss: 0.1135
Epoch 4 [138/172] - loss: 0.1068
Epoch 4 [139/172] - loss: 0.1144
Epoch 4 [140/172] - loss: 0.1214, acc: 1.0000
Epoch 4 [141/172] - loss: 0.2238
Epoch 4 [142/172] - loss: 0.1208
Epoch 4 [143/172] - loss: 0.1273
Epoch 4 [144/172] - loss: 0.1439
Epoch 4 [145/172] - loss: 0.1949
Epoch 4 [146/172] - loss: 0.1440
Epoch 4 [147/172] - loss: 0.1293
Epoch 4 [148/172] - loss: 0.1330
Epoch 4 [149/172] - loss: 0.1149
Epoch 4 [150/172] - loss: 0.1840, acc: 0.9375
Epoch 4 [151/172] - loss: 0.2207
Epoch 4 [152/172] - loss: 0.1227
Epoch 4 [153/172] - loss: 0.1595
Epoch 4 [154/172] - loss: 0.2536
Epoch 4 [155/172] - loss: 0.1524
Epoch 4 [156/172] - loss: 0.1333
Epoch 4 [157/172] - loss: 0.1596
Epoch 4 [158/172] - loss: 0.1089
Epoch 4 [159/172] - loss: 0.1220
Epoch 4 [160/172] - loss: 0.1142, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1303
Epoch 4 [162/172] - loss: 0.1591
Epoch 4 [163/172] - loss: 0.1207
Epoch 4 [164/172] - loss: 0.1116
Epoch 4 [165/172] - loss: 0.1279
Epoch 4 [166/172] - loss: 0.1317
Epoch 4 [167/172] - loss: 0.1609
Epoch 4 [168/172] - loss: 0.1140
Epoch 4 [169/172] - loss: 0.1751
Epoch 4 [170/172] - loss: 0.1354, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1169
Epoch 4 [172/172] - loss: 0.1273

类别准确率:
positive: 0.8865 (414/467)
neutral: 0.3373 (28/83)
negative: 0.5720 (143/250)

Epoch 4/10
Train Loss: 0.1322, Train Acc: 0.9798
Val Loss: 0.8566, Val Acc: 0.7312
Epoch 5 [1/172] - loss: 0.1096, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1419
Epoch 5 [3/172] - loss: 0.1114
Epoch 5 [4/172] - loss: 0.1360
Epoch 5 [5/172] - loss: 0.1113
Epoch 5 [6/172] - loss: 0.1216
Epoch 5 [7/172] - loss: 0.1121
Epoch 5 [8/172] - loss: 0.1618
Epoch 5 [9/172] - loss: 0.1302
Epoch 5 [10/172] - loss: 0.1310, acc: 0.9688
Epoch 5 [11/172] - loss: 0.1157
Epoch 5 [12/172] - loss: 0.1101

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2217, log_difficulty=0.2002, weight=2.0011
neutral: count=6845.0, difficulty=0.1586, log_difficulty=0.1472, weight=1.7360
negative: count=7694.0, difficulty=0.2077, log_difficulty=0.1887, weight=1.9435

当前batch的pt分布：
positive: min=0.3865, max=0.9965, mean=0.9287
neutral: min=0.9903, max=0.9996, mean=0.9974
negative: min=0.8762, max=0.9979, mean=0.9719

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0527
焦点损失: 0.0108
边界损失: 0.1548
总损失: 0.1215
Epoch 5 [13/172] - loss: 0.1215
Epoch 5 [14/172] - loss: 0.1583
Epoch 5 [15/172] - loss: 0.1096
Epoch 5 [16/172] - loss: 0.1117
Epoch 5 [17/172] - loss: 0.1376
Epoch 5 [18/172] - loss: 0.1099
Epoch 5 [19/172] - loss: 0.1485
Epoch 5 [20/172] - loss: 0.1258, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1570
Epoch 5 [22/172] - loss: 0.1512
Epoch 5 [23/172] - loss: 0.1091
Epoch 5 [24/172] - loss: 0.1288
Epoch 5 [25/172] - loss: 0.1096
Epoch 5 [26/172] - loss: 0.1348
Epoch 5 [27/172] - loss: 0.1106
Epoch 5 [28/172] - loss: 0.1119
Epoch 5 [29/172] - loss: 0.1106
Epoch 5 [30/172] - loss: 0.1203, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1204
Epoch 5 [32/172] - loss: 0.1070
Epoch 5 [33/172] - loss: 0.1195
Epoch 5 [34/172] - loss: 0.1123
Epoch 5 [35/172] - loss: 0.1106
Epoch 5 [36/172] - loss: 0.1076
Epoch 5 [37/172] - loss: 0.1074
Epoch 5 [38/172] - loss: 0.1086
Epoch 5 [39/172] - loss: 0.1918
Epoch 5 [40/172] - loss: 0.1108, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1201
Epoch 5 [42/172] - loss: 0.1125
Epoch 5 [43/172] - loss: 0.1282
Epoch 5 [44/172] - loss: 0.1267
Epoch 5 [45/172] - loss: 0.1072
Epoch 5 [46/172] - loss: 0.1313
Epoch 5 [47/172] - loss: 0.1058
Epoch 5 [48/172] - loss: 0.1119
Epoch 5 [49/172] - loss: 0.1084
Epoch 5 [50/172] - loss: 0.1337, acc: 0.9688
Epoch 5 [51/172] - loss: 0.1209
Epoch 5 [52/172] - loss: 0.1106
Epoch 5 [53/172] - loss: 0.1168
Epoch 5 [54/172] - loss: 0.1165
Epoch 5 [55/172] - loss: 0.1161
Epoch 5 [56/172] - loss: 0.1823
Epoch 5 [57/172] - loss: 0.1099
Epoch 5 [58/172] - loss: 0.1065
Epoch 5 [59/172] - loss: 0.1242
Epoch 5 [60/172] - loss: 0.1117, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1103
Epoch 5 [62/172] - loss: 0.1083
Epoch 5 [63/172] - loss: 0.1399
Epoch 5 [64/172] - loss: 0.1318
Epoch 5 [65/172] - loss: 0.1200
Epoch 5 [66/172] - loss: 0.1127
Epoch 5 [67/172] - loss: 0.1071
Epoch 5 [68/172] - loss: 0.1189
Epoch 5 [69/172] - loss: 0.1272
Epoch 5 [70/172] - loss: 0.1083, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1156
Epoch 5 [72/172] - loss: 0.1096
Epoch 5 [73/172] - loss: 0.1113
Epoch 5 [74/172] - loss: 0.1397
Epoch 5 [75/172] - loss: 0.1083
Epoch 5 [76/172] - loss: 0.1297
Epoch 5 [77/172] - loss: 0.1079
Epoch 5 [78/172] - loss: 0.1196
Epoch 5 [79/172] - loss: 0.1121
Epoch 5 [80/172] - loss: 0.1077, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1273
Epoch 5 [82/172] - loss: 0.1244
Epoch 5 [83/172] - loss: 0.1106
Epoch 5 [84/172] - loss: 0.1079
Epoch 5 [85/172] - loss: 0.1440
Epoch 5 [86/172] - loss: 0.1100
Epoch 5 [87/172] - loss: 0.1360
Epoch 5 [88/172] - loss: 0.1568
Epoch 5 [89/172] - loss: 0.1127
Epoch 5 [90/172] - loss: 0.1811, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1518
Epoch 5 [92/172] - loss: 0.1085
Epoch 5 [93/172] - loss: 0.1149
Epoch 5 [94/172] - loss: 0.1074
Epoch 5 [95/172] - loss: 0.1132
Epoch 5 [96/172] - loss: 0.1075
Epoch 5 [97/172] - loss: 0.1237
Epoch 5 [98/172] - loss: 0.1081
Epoch 5 [99/172] - loss: 0.1911
Epoch 5 [100/172] - loss: 0.1103, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1102
Epoch 5 [102/172] - loss: 0.1119
Epoch 5 [103/172] - loss: 0.1477
Epoch 5 [104/172] - loss: 0.1980
Epoch 5 [105/172] - loss: 0.1899
Epoch 5 [106/172] - loss: 0.1143
Epoch 5 [107/172] - loss: 0.1166
Epoch 5 [108/172] - loss: 0.1780
Epoch 5 [109/172] - loss: 0.1220
Epoch 5 [110/172] - loss: 0.1106, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1543
Epoch 5 [112/172] - loss: 0.1336

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.1990, log_difficulty=0.1815, weight=1.9075
neutral: count=7825.0, difficulty=0.1422, log_difficulty=0.1330, weight=1.6650
negative: count=8780.0, difficulty=0.1880, log_difficulty=0.1723, weight=1.8614

当前batch的pt分布：
positive: min=0.0483, max=0.9989, mean=0.8359
neutral: min=0.9152, max=0.9997, mean=0.9703
negative: min=0.9966, max=0.9999, mean=0.9990

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1681
焦点损失: 0.0927
边界损失: 0.1713
总损失: 0.1727
Epoch 5 [113/172] - loss: 0.1727
Epoch 5 [114/172] - loss: 0.1208
Epoch 5 [115/172] - loss: 0.1227
Epoch 5 [116/172] - loss: 0.1081
Epoch 5 [117/172] - loss: 0.1678
Epoch 5 [118/172] - loss: 0.1075
Epoch 5 [119/172] - loss: 0.1065
Epoch 5 [120/172] - loss: 0.1148, acc: 1.0000
Epoch 5 [121/172] - loss: 0.1192
Epoch 5 [122/172] - loss: 0.1145
Epoch 5 [123/172] - loss: 0.1177
Epoch 5 [124/172] - loss: 0.1093
Epoch 5 [125/172] - loss: 0.1082
Epoch 5 [126/172] - loss: 0.1280
Epoch 5 [127/172] - loss: 0.1184
Epoch 5 [128/172] - loss: 0.1110
Epoch 5 [129/172] - loss: 0.1788
Epoch 5 [130/172] - loss: 0.1097, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1124
Epoch 5 [132/172] - loss: 0.1519
Epoch 5 [133/172] - loss: 0.1571
Epoch 5 [134/172] - loss: 0.1798
Epoch 5 [135/172] - loss: 0.1061
Epoch 5 [136/172] - loss: 0.1267
Epoch 5 [137/172] - loss: 0.1158
Epoch 5 [138/172] - loss: 0.1378
Epoch 5 [139/172] - loss: 0.1800
Epoch 5 [140/172] - loss: 0.1237, acc: 0.9688
Epoch 5 [141/172] - loss: 0.1114
Epoch 5 [142/172] - loss: 0.1195
Epoch 5 [143/172] - loss: 0.1071
Epoch 5 [144/172] - loss: 0.1083
Epoch 5 [145/172] - loss: 0.1265
Epoch 5 [146/172] - loss: 0.1092
Epoch 5 [147/172] - loss: 0.1331
Epoch 5 [148/172] - loss: 0.1066
Epoch 5 [149/172] - loss: 0.1153
Epoch 5 [150/172] - loss: 0.1559, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1102
Epoch 5 [152/172] - loss: 0.1072
Epoch 5 [153/172] - loss: 0.1072
Epoch 5 [154/172] - loss: 0.1151
Epoch 5 [155/172] - loss: 0.1198
Epoch 5 [156/172] - loss: 0.1210
Epoch 5 [157/172] - loss: 0.1127
Epoch 5 [158/172] - loss: 0.1164
Epoch 5 [159/172] - loss: 0.1106
Epoch 5 [160/172] - loss: 0.1086, acc: 1.0000
Epoch 5 [161/172] - loss: 0.1176
Epoch 5 [162/172] - loss: 0.1109
Epoch 5 [163/172] - loss: 0.1288
Epoch 5 [164/172] - loss: 0.1076
Epoch 5 [165/172] - loss: 0.1357
Epoch 5 [166/172] - loss: 0.1123
Epoch 5 [167/172] - loss: 0.1251
Epoch 5 [168/172] - loss: 0.1073
Epoch 5 [169/172] - loss: 0.1101
Epoch 5 [170/172] - loss: 0.1286, acc: 0.9688
Epoch 5 [171/172] - loss: 0.1147
Epoch 5 [172/172] - loss: 0.1260

类别准确率:
positive: 0.8972 (419/467)
neutral: 0.3373 (28/83)
negative: 0.5320 (133/250)

Epoch 5/10
Train Loss: 0.1171, Train Acc: 0.9919
Val Loss: 0.9242, Val Acc: 0.7250
Epoch 6 [1/172] - loss: 0.1317, acc: 1.0000
Epoch 6 [2/172] - loss: 0.1187
Epoch 6 [3/172] - loss: 0.1063
Epoch 6 [4/172] - loss: 0.1081
Epoch 6 [5/172] - loss: 0.1354
Epoch 6 [6/172] - loss: 0.1085
Epoch 6 [7/172] - loss: 0.1217
Epoch 6 [8/172] - loss: 0.1189
Epoch 6 [9/172] - loss: 0.1100
Epoch 6 [10/172] - loss: 0.1090, acc: 1.0000
Epoch 6 [11/172] - loss: 0.1085
Epoch 6 [12/172] - loss: 0.1124
Epoch 6 [13/172] - loss: 0.1108
Epoch 6 [14/172] - loss: 0.1067
Epoch 6 [15/172] - loss: 0.1091
Epoch 6 [16/172] - loss: 0.1453
Epoch 6 [17/172] - loss: 0.1087
Epoch 6 [18/172] - loss: 0.1097
Epoch 6 [19/172] - loss: 0.1088
Epoch 6 [20/172] - loss: 0.1219, acc: 0.9688
Epoch 6 [21/172] - loss: 0.1225
Epoch 6 [22/172] - loss: 0.1119
Epoch 6 [23/172] - loss: 0.1119
Epoch 6 [24/172] - loss: 0.1084
Epoch 6 [25/172] - loss: 0.1065
Epoch 6 [26/172] - loss: 0.1177
Epoch 6 [27/172] - loss: 0.1236
Epoch 6 [28/172] - loss: 0.1116
Epoch 6 [29/172] - loss: 0.1086
Epoch 6 [30/172] - loss: 0.1071, acc: 1.0000
Epoch 6 [31/172] - loss: 0.1077
Epoch 6 [32/172] - loss: 0.1058
Epoch 6 [33/172] - loss: 0.1063
Epoch 6 [34/172] - loss: 0.1069
Epoch 6 [35/172] - loss: 0.1172
Epoch 6 [36/172] - loss: 0.1086
Epoch 6 [37/172] - loss: 0.1063
Epoch 6 [38/172] - loss: 0.1067
Epoch 6 [39/172] - loss: 0.1105
Epoch 6 [40/172] - loss: 0.1480, acc: 0.9375

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1811, log_difficulty=0.1665, weight=1.8323
neutral: count=8815.0, difficulty=0.1291, log_difficulty=0.1214, weight=1.6071
negative: count=9870.0, difficulty=0.1713, log_difficulty=0.1581, weight=1.7905

当前batch的pt分布：
positive: min=0.0165, max=0.9981, mean=0.9045
neutral: min=0.9735, max=0.9990, mean=0.9933
negative: min=0.9708, max=0.9973, mean=0.9844

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1379
焦点损失: 0.1240
边界损失: 0.1400
总损失: 0.1618
Epoch 6 [41/172] - loss: 0.1618
Epoch 6 [42/172] - loss: 0.1112
Epoch 6 [43/172] - loss: 0.1967
Epoch 6 [44/172] - loss: 0.1061
Epoch 6 [45/172] - loss: 0.1217
Epoch 6 [46/172] - loss: 0.1492
Epoch 6 [47/172] - loss: 0.1104
Epoch 6 [48/172] - loss: 0.1106
Epoch 6 [49/172] - loss: 0.1176
Epoch 6 [50/172] - loss: 0.1393, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1656
Epoch 6 [52/172] - loss: 0.1337
Epoch 6 [53/172] - loss: 0.1070
Epoch 6 [54/172] - loss: 0.1414
Epoch 6 [55/172] - loss: 0.1085
Epoch 6 [56/172] - loss: 0.1329
Epoch 6 [57/172] - loss: 0.1065
Epoch 6 [58/172] - loss: 0.1060
Epoch 6 [59/172] - loss: 0.1087
Epoch 6 [60/172] - loss: 0.1088, acc: 1.0000
Epoch 6 [61/172] - loss: 0.1309
Epoch 6 [62/172] - loss: 0.1232
Epoch 6 [63/172] - loss: 0.1108
Epoch 6 [64/172] - loss: 0.1838
Epoch 6 [65/172] - loss: 0.1204
Epoch 6 [66/172] - loss: 0.1085
Epoch 6 [67/172] - loss: 0.1075
Epoch 6 [68/172] - loss: 0.1251
Epoch 6 [69/172] - loss: 0.1581
Epoch 6 [70/172] - loss: 0.1055, acc: 1.0000
Epoch 6 [71/172] - loss: 0.1091
Epoch 6 [72/172] - loss: 0.1086
Epoch 6 [73/172] - loss: 0.1274
Epoch 6 [74/172] - loss: 0.1064
Epoch 6 [75/172] - loss: 0.1114
Epoch 6 [76/172] - loss: 0.1094
Epoch 6 [77/172] - loss: 0.1196
Epoch 6 [78/172] - loss: 0.1163
Epoch 6 [79/172] - loss: 0.1122
Epoch 6 [80/172] - loss: 0.1354, acc: 0.9688
Epoch 6 [81/172] - loss: 0.1241
Epoch 6 [82/172] - loss: 0.1273
Epoch 6 [83/172] - loss: 0.1085
Epoch 6 [84/172] - loss: 0.1047
Epoch 6 [85/172] - loss: 0.1201
Epoch 6 [86/172] - loss: 0.1190
Epoch 6 [87/172] - loss: 0.1123
Epoch 6 [88/172] - loss: 0.1237
Epoch 6 [89/172] - loss: 0.1113
Epoch 6 [90/172] - loss: 0.1082, acc: 1.0000
Epoch 6 [91/172] - loss: 0.1080
Epoch 6 [92/172] - loss: 0.1071
Epoch 6 [93/172] - loss: 0.1041
Epoch 6 [94/172] - loss: 0.1365
Epoch 6 [95/172] - loss: 0.1178
Epoch 6 [96/172] - loss: 0.1049
Epoch 6 [97/172] - loss: 0.1076
Epoch 6 [98/172] - loss: 0.1165
Epoch 6 [99/172] - loss: 0.1058
Epoch 6 [100/172] - loss: 0.1159, acc: 0.9688
Epoch 6 [101/172] - loss: 0.1116
Epoch 6 [102/172] - loss: 0.1058
Epoch 6 [103/172] - loss: 0.1154
Epoch 6 [104/172] - loss: 0.1761
Epoch 6 [105/172] - loss: 0.1233
Epoch 6 [106/172] - loss: 0.1188
Epoch 6 [107/172] - loss: 0.1530
Epoch 6 [108/172] - loss: 0.1057
Epoch 6 [109/172] - loss: 0.1602
Epoch 6 [110/172] - loss: 0.1122, acc: 1.0000
Epoch 6 [111/172] - loss: 0.1071
Epoch 6 [112/172] - loss: 0.1074
Epoch 6 [113/172] - loss: 0.1135
Epoch 6 [114/172] - loss: 0.1120
Epoch 6 [115/172] - loss: 0.1116
Epoch 6 [116/172] - loss: 0.2547
Epoch 6 [117/172] - loss: 0.1101
Epoch 6 [118/172] - loss: 0.1072
Epoch 6 [119/172] - loss: 0.2270
Epoch 6 [120/172] - loss: 0.1075, acc: 1.0000
Epoch 6 [121/172] - loss: 0.1078
Epoch 6 [122/172] - loss: 0.1318
Epoch 6 [123/172] - loss: 0.1068
Epoch 6 [124/172] - loss: 0.1092
Epoch 6 [125/172] - loss: 0.1304
Epoch 6 [126/172] - loss: 0.1289
Epoch 6 [127/172] - loss: 0.1396
Epoch 6 [128/172] - loss: 0.1360
Epoch 6 [129/172] - loss: 0.1123
Epoch 6 [130/172] - loss: 0.1492, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1258
Epoch 6 [132/172] - loss: 0.1520
Epoch 6 [133/172] - loss: 0.1054
Epoch 6 [134/172] - loss: 0.1232
Epoch 6 [135/172] - loss: 0.1081
Epoch 6 [136/172] - loss: 0.1064
Epoch 6 [137/172] - loss: 0.1131
Epoch 6 [138/172] - loss: 0.1438
Epoch 6 [139/172] - loss: 0.1085
Epoch 6 [140/172] - loss: 0.1093, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1668, log_difficulty=0.1543, weight=1.7713
neutral: count=9796.0, difficulty=0.1192, log_difficulty=0.1126, weight=1.5631
negative: count=10972.0, difficulty=0.1575, log_difficulty=0.1463, weight=1.7313

当前batch的pt分布：
positive: min=0.9848, max=0.9998, mean=0.9957
neutral: min=0.9644, max=0.9989, mean=0.9915
negative: min=0.9199, max=0.9967, mean=0.9752

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0142
焦点损失: 0.0000
边界损失: 0.1416
总损失: 0.1063
Epoch 6 [141/172] - loss: 0.1063
Epoch 6 [142/172] - loss: 0.1067
Epoch 6 [143/172] - loss: 0.1094
Epoch 6 [144/172] - loss: 0.1305
Epoch 6 [145/172] - loss: 0.1083
Epoch 6 [146/172] - loss: 0.1284
Epoch 6 [147/172] - loss: 0.1206
Epoch 6 [148/172] - loss: 0.1107
Epoch 6 [149/172] - loss: 0.1128
Epoch 6 [150/172] - loss: 0.1061, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1087
Epoch 6 [152/172] - loss: 0.1139
Epoch 6 [153/172] - loss: 0.1096
Epoch 6 [154/172] - loss: 0.1116
Epoch 6 [155/172] - loss: 0.1342
Epoch 6 [156/172] - loss: 0.1349
Epoch 6 [157/172] - loss: 0.1117
Epoch 6 [158/172] - loss: 0.1099
Epoch 6 [159/172] - loss: 0.1120
Epoch 6 [160/172] - loss: 0.1639, acc: 0.9688
Epoch 6 [161/172] - loss: 0.1200
Epoch 6 [162/172] - loss: 0.1201
Epoch 6 [163/172] - loss: 0.1164
Epoch 6 [164/172] - loss: 0.1274
Epoch 6 [165/172] - loss: 0.2935
Epoch 6 [166/172] - loss: 0.1082
Epoch 6 [167/172] - loss: 0.1328
Epoch 6 [168/172] - loss: 0.1078
Epoch 6 [169/172] - loss: 0.1296
Epoch 6 [170/172] - loss: 0.1093, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1181
Epoch 6 [172/172] - loss: 0.1555

类别准确率:
positive: 0.8244 (385/467)
neutral: 0.3614 (30/83)
negative: 0.6480 (162/250)

Epoch 6/10
Train Loss: 0.1335, Train Acc: 0.9758
Val Loss: 0.8587, Val Acc: 0.7212
Epoch 7 [1/172] - loss: 0.1094, acc: 1.0000
Epoch 7 [2/172] - loss: 0.1077
Epoch 7 [3/172] - loss: 0.1068
Epoch 7 [4/172] - loss: 0.1117
Epoch 7 [5/172] - loss: 0.1059
Epoch 7 [6/172] - loss: 0.1096
Epoch 7 [7/172] - loss: 0.1058
Epoch 7 [8/172] - loss: 0.1416
Epoch 7 [9/172] - loss: 0.1060
Epoch 7 [10/172] - loss: 0.1111, acc: 1.0000
Epoch 7 [11/172] - loss: 0.1053
Epoch 7 [12/172] - loss: 0.1388
Epoch 7 [13/172] - loss: 0.1112
Epoch 7 [14/172] - loss: 0.1059
Epoch 7 [15/172] - loss: 0.1362
Epoch 7 [16/172] - loss: 0.1205
Epoch 7 [17/172] - loss: 0.1656
Epoch 7 [18/172] - loss: 0.1045
Epoch 7 [19/172] - loss: 0.1097
Epoch 7 [20/172] - loss: 0.1091, acc: 1.0000
Epoch 7 [21/172] - loss: 0.1222
Epoch 7 [22/172] - loss: 0.1087
Epoch 7 [23/172] - loss: 0.1089
Epoch 7 [24/172] - loss: 0.1357
Epoch 7 [25/172] - loss: 0.1074
Epoch 7 [26/172] - loss: 0.1344
Epoch 7 [27/172] - loss: 0.1140
Epoch 7 [28/172] - loss: 0.1307
Epoch 7 [29/172] - loss: 0.1163
Epoch 7 [30/172] - loss: 0.1394, acc: 0.9688
Epoch 7 [31/172] - loss: 0.1167
Epoch 7 [32/172] - loss: 0.1074
Epoch 7 [33/172] - loss: 0.1101
Epoch 7 [34/172] - loss: 0.1099
Epoch 7 [35/172] - loss: 0.1067
Epoch 7 [36/172] - loss: 0.1676
Epoch 7 [37/172] - loss: 0.1120
Epoch 7 [38/172] - loss: 0.1182
Epoch 7 [39/172] - loss: 0.1094
Epoch 7 [40/172] - loss: 0.1066, acc: 1.0000
Epoch 7 [41/172] - loss: 0.1057
Epoch 7 [42/172] - loss: 0.1085
Epoch 7 [43/172] - loss: 0.1076
Epoch 7 [44/172] - loss: 0.1192
Epoch 7 [45/172] - loss: 0.1773
Epoch 7 [46/172] - loss: 0.1295
Epoch 7 [47/172] - loss: 0.1216
Epoch 7 [48/172] - loss: 0.1053
Epoch 7 [49/172] - loss: 0.1072
Epoch 7 [50/172] - loss: 0.1049, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1410
Epoch 7 [52/172] - loss: 0.1066
Epoch 7 [53/172] - loss: 0.1064
Epoch 7 [54/172] - loss: 0.1152
Epoch 7 [55/172] - loss: 0.1064
Epoch 7 [56/172] - loss: 0.1060
Epoch 7 [57/172] - loss: 0.1066
Epoch 7 [58/172] - loss: 0.1098
Epoch 7 [59/172] - loss: 0.1062
Epoch 7 [60/172] - loss: 0.1174, acc: 1.0000
Epoch 7 [61/172] - loss: 0.1104
Epoch 7 [62/172] - loss: 0.1071
Epoch 7 [63/172] - loss: 0.1429
Epoch 7 [64/172] - loss: 0.1178
Epoch 7 [65/172] - loss: 0.1122
Epoch 7 [66/172] - loss: 0.1075
Epoch 7 [67/172] - loss: 0.1074
Epoch 7 [68/172] - loss: 0.1423

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1550, log_difficulty=0.1441, weight=1.7204
neutral: count=10756.0, difficulty=0.1107, log_difficulty=0.1050, weight=1.5250
negative: count=12072.0, difficulty=0.1464, log_difficulty=0.1366, weight=1.6831

当前batch的pt分布：
positive: min=0.9136, max=0.9999, mean=0.9877
neutral: min=0.9905, max=0.9998, mean=0.9970
negative: min=0.9517, max=0.9984, mean=0.9745

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0161
焦点损失: 0.0000
边界损失: 0.1425
总损失: 0.1069
Epoch 7 [69/172] - loss: 0.1069
Epoch 7 [70/172] - loss: 0.1065, acc: 1.0000
Epoch 7 [71/172] - loss: 0.1182
Epoch 7 [72/172] - loss: 0.1282
Epoch 7 [73/172] - loss: 0.1249
Epoch 7 [74/172] - loss: 0.1051
Epoch 7 [75/172] - loss: 0.1069
Epoch 7 [76/172] - loss: 0.1077
Epoch 7 [77/172] - loss: 0.1186
Epoch 7 [78/172] - loss: 0.1049
Epoch 7 [79/172] - loss: 0.1163
Epoch 7 [80/172] - loss: 0.1223, acc: 0.9688
Epoch 7 [81/172] - loss: 0.1057
Epoch 7 [82/172] - loss: 0.1187
Epoch 7 [83/172] - loss: 0.1352
Epoch 7 [84/172] - loss: 0.1092
Epoch 7 [85/172] - loss: 0.1108
Epoch 7 [86/172] - loss: 0.1075
Epoch 7 [87/172] - loss: 0.1081
Epoch 7 [88/172] - loss: 0.1199
Epoch 7 [89/172] - loss: 0.1064
Epoch 7 [90/172] - loss: 0.1071, acc: 1.0000
Epoch 7 [91/172] - loss: 0.1066
Epoch 7 [92/172] - loss: 0.1076
Epoch 7 [93/172] - loss: 0.1152
Epoch 7 [94/172] - loss: 0.1057
Epoch 7 [95/172] - loss: 0.1092
Epoch 7 [96/172] - loss: 0.1114
Epoch 7 [97/172] - loss: 0.1095
Epoch 7 [98/172] - loss: 0.1213
Epoch 7 [99/172] - loss: 0.1066
Epoch 7 [100/172] - loss: 0.1104, acc: 1.0000
Epoch 7 [101/172] - loss: 0.1064
Epoch 7 [102/172] - loss: 0.1162
Epoch 7 [103/172] - loss: 0.1085
Epoch 7 [104/172] - loss: 0.1995
Epoch 7 [105/172] - loss: 0.1208
Epoch 7 [106/172] - loss: 0.1274
Epoch 7 [107/172] - loss: 0.1053
Epoch 7 [108/172] - loss: 0.1060
Epoch 7 [109/172] - loss: 0.1555
Epoch 7 [110/172] - loss: 0.1228, acc: 0.9688
Epoch 7 [111/172] - loss: 0.1075
Epoch 7 [112/172] - loss: 0.1089
Epoch 7 [113/172] - loss: 0.1054
Epoch 7 [114/172] - loss: 0.1059
Epoch 7 [115/172] - loss: 0.1043
Epoch 7 [116/172] - loss: 0.1161
Epoch 7 [117/172] - loss: 0.1119
Epoch 7 [118/172] - loss: 0.1138
Epoch 7 [119/172] - loss: 0.1126
Epoch 7 [120/172] - loss: 0.1255, acc: 0.9688
Epoch 7 [121/172] - loss: 0.1176
Epoch 7 [122/172] - loss: 0.1104
Epoch 7 [123/172] - loss: 0.1060
Epoch 7 [124/172] - loss: 0.1132
Epoch 7 [125/172] - loss: 0.1056
Epoch 7 [126/172] - loss: 0.1066
Epoch 7 [127/172] - loss: 0.1093
Epoch 7 [128/172] - loss: 0.1118
Epoch 7 [129/172] - loss: 0.1058
Epoch 7 [130/172] - loss: 0.1116, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1433
Epoch 7 [132/172] - loss: 0.1677
Epoch 7 [133/172] - loss: 0.1046
Epoch 7 [134/172] - loss: 0.1139
Epoch 7 [135/172] - loss: 0.1170
Epoch 7 [136/172] - loss: 0.1089
Epoch 7 [137/172] - loss: 0.1141
Epoch 7 [138/172] - loss: 0.1047
Epoch 7 [139/172] - loss: 0.1449
Epoch 7 [140/172] - loss: 0.1068, acc: 1.0000
Epoch 7 [141/172] - loss: 0.1338
Epoch 7 [142/172] - loss: 0.1113
Epoch 7 [143/172] - loss: 0.1207
Epoch 7 [144/172] - loss: 0.1068
Epoch 7 [145/172] - loss: 0.1212
Epoch 7 [146/172] - loss: 0.1376
Epoch 7 [147/172] - loss: 0.1101
Epoch 7 [148/172] - loss: 0.1268
Epoch 7 [149/172] - loss: 0.1058
Epoch 7 [150/172] - loss: 0.1084, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1318
Epoch 7 [152/172] - loss: 0.1053
Epoch 7 [153/172] - loss: 0.1056
Epoch 7 [154/172] - loss: 0.1291
Epoch 7 [155/172] - loss: 0.1062
Epoch 7 [156/172] - loss: 0.1454
Epoch 7 [157/172] - loss: 0.1083
Epoch 7 [158/172] - loss: 0.1107
Epoch 7 [159/172] - loss: 0.1054
Epoch 7 [160/172] - loss: 0.1067, acc: 1.0000
Epoch 7 [161/172] - loss: 0.1059
Epoch 7 [162/172] - loss: 0.1074
Epoch 7 [163/172] - loss: 0.1115
Epoch 7 [164/172] - loss: 0.1575
Epoch 7 [165/172] - loss: 0.1356
Epoch 7 [166/172] - loss: 0.1080
Epoch 7 [167/172] - loss: 0.1147
Epoch 7 [168/172] - loss: 0.1180

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1443, log_difficulty=0.1348, weight=1.6738
neutral: count=11731.0, difficulty=0.1037, log_difficulty=0.0987, weight=1.4935
negative: count=13173.0, difficulty=0.1366, log_difficulty=0.1281, weight=1.6404

当前batch的pt分布：
positive: min=0.9357, max=0.9993, mean=0.9873
neutral: min=0.9631, max=0.9989, mean=0.9923
negative: min=0.9670, max=0.9970, mean=0.9873

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0115
焦点损失: 0.0000
边界损失: 0.1405
总损失: 0.1054
Epoch 7 [169/172] - loss: 0.1054
Epoch 7 [170/172] - loss: 0.1162, acc: 1.0000
Epoch 7 [171/172] - loss: 0.1063
Epoch 7 [172/172] - loss: 0.1040

类别准确率:
positive: 0.8587 (401/467)
neutral: 0.2771 (23/83)
negative: 0.5920 (148/250)

Epoch 7/10
Train Loss: 0.1138, Train Acc: 0.9939
Val Loss: 0.9350, Val Acc: 0.7150
Early stopping triggered!
Best validation accuracy: 0.7312

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_065434-35s19ejp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.35_Multimodal_iterations_20250118_065433
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/35s19ejp
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█
wandb:  train_acc ▁▃▄▃▅▆▇▇▇▆▆▇▇▇█▇▇▇██▇█▇█████████████████
wandb: train_loss ██▄▄▂▂▂▃▂▂▂▁▁▂▂▂▁▂▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 1
wandb: train_loss 0.11617
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.35_Multimodal_iterations_20250118_065433 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/35s19ejp
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_065434-35s19ejp/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_070441-is1247vy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.35_Multimodal_epochs_20250118_070441
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/is1247vy
wandb: uploading summary; updating run config; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▅▇██▇█
wandb: train_loss █▄▂▁▁▁▁
wandb:    val_acc ▁▇▅██▇▇
wandb:   val_loss ▃▁▆▅█▅█
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.99394
wandb: train_loss 0.11385
wandb:    val_acc 0.715
wandb:   val_loss 0.93496
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.35_Multimodal_epochs_20250118_070441 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/is1247vy
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_070441-is1247vy/logs

