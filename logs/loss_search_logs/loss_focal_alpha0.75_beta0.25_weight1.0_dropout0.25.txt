=== 命令 ===
python main.py --loss_type focal --alpha 0.75 --beta 0.25 --neural_init_weight 1.0 --dropout 0.25 --name loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.25 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.25
text_dim: 128
image_dim: 256
dropout: 0.25
loss_type: focal
alpha: 0.75
beta: 0.25
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6810, log_difficulty=0.5194, weight=3.5970
neutral: count=7.0, difficulty=0.6627, log_difficulty=0.5085, weight=3.5423
negative: count=13.0, difficulty=0.6164, log_difficulty=0.4802, weight=3.4010

当前batch的pt分布：
positive: min=0.1931, max=0.4082, mean=0.3190
neutral: min=0.2107, max=0.3840, mean=0.3373
negative: min=0.2006, max=0.8703, mean=0.3836

当前batch准确率：
整体准确率: 0.3438
positive 准确率: 0.2500
neutral 准确率: 0.2857
negative 准确率: 0.4615

损失分量：
基础交叉熵: 1.0917
焦点损失: 0.3506
边界损失: 0.8411
总损失: 1.1339
Epoch 1 [1/172] - loss: 1.1339, acc: 0.3438
Epoch 1 [2/172] - loss: 1.3099
Epoch 1 [3/172] - loss: 1.4468
Epoch 1 [4/172] - loss: 1.0806
Epoch 1 [5/172] - loss: 1.1128
Epoch 1 [6/172] - loss: 1.5973
Epoch 1 [7/172] - loss: 1.0282
Epoch 1 [8/172] - loss: 1.7225
Epoch 1 [9/172] - loss: 1.2604
Epoch 1 [10/172] - loss: 1.2421, acc: 0.4375
Epoch 1 [11/172] - loss: 1.0348
Epoch 1 [12/172] - loss: 1.1938
Epoch 1 [13/172] - loss: 1.0302
Epoch 1 [14/172] - loss: 1.1814
Epoch 1 [15/172] - loss: 1.0150
Epoch 1 [16/172] - loss: 0.9918
Epoch 1 [17/172] - loss: 1.1432
Epoch 1 [18/172] - loss: 0.8744
Epoch 1 [19/172] - loss: 1.1734
Epoch 1 [20/172] - loss: 0.9602, acc: 0.4062
Epoch 1 [21/172] - loss: 1.0019
Epoch 1 [22/172] - loss: 1.1263
Epoch 1 [23/172] - loss: 1.1430
Epoch 1 [24/172] - loss: 1.3713
Epoch 1 [25/172] - loss: 1.1513
Epoch 1 [26/172] - loss: 1.3026
Epoch 1 [27/172] - loss: 1.0445
Epoch 1 [28/172] - loss: 0.9944
Epoch 1 [29/172] - loss: 1.0519
Epoch 1 [30/172] - loss: 1.0262, acc: 0.4688
Epoch 1 [31/172] - loss: 1.3601
Epoch 1 [32/172] - loss: 1.0183
Epoch 1 [33/172] - loss: 0.9619
Epoch 1 [34/172] - loss: 1.0218
Epoch 1 [35/172] - loss: 1.1955
Epoch 1 [36/172] - loss: 0.7015
Epoch 1 [37/172] - loss: 1.0377
Epoch 1 [38/172] - loss: 0.9613
Epoch 1 [39/172] - loss: 1.0027
Epoch 1 [40/172] - loss: 0.9783, acc: 0.5625
Epoch 1 [41/172] - loss: 0.8732
Epoch 1 [42/172] - loss: 0.7904
Epoch 1 [43/172] - loss: 1.1620
Epoch 1 [44/172] - loss: 1.1199
Epoch 1 [45/172] - loss: 1.0572
Epoch 1 [46/172] - loss: 0.9102
Epoch 1 [47/172] - loss: 1.0743
Epoch 1 [48/172] - loss: 0.6612
Epoch 1 [49/172] - loss: 0.8737
Epoch 1 [50/172] - loss: 0.9352, acc: 0.5000
Epoch 1 [51/172] - loss: 0.8993
Epoch 1 [52/172] - loss: 0.8941
Epoch 1 [53/172] - loss: 1.0849
Epoch 1 [54/172] - loss: 0.8696
Epoch 1 [55/172] - loss: 0.9511
Epoch 1 [56/172] - loss: 0.9028
Epoch 1 [57/172] - loss: 1.0981
Epoch 1 [58/172] - loss: 0.4818
Epoch 1 [59/172] - loss: 1.1216
Epoch 1 [60/172] - loss: 0.7571, acc: 0.7500
Epoch 1 [61/172] - loss: 0.7504
Epoch 1 [62/172] - loss: 0.9013
Epoch 1 [63/172] - loss: 0.7503
Epoch 1 [64/172] - loss: 0.6174
Epoch 1 [65/172] - loss: 0.6556
Epoch 1 [66/172] - loss: 0.8479
Epoch 1 [67/172] - loss: 0.7296
Epoch 1 [68/172] - loss: 1.0212
Epoch 1 [69/172] - loss: 1.2660
Epoch 1 [70/172] - loss: 0.9634, acc: 0.5938
Epoch 1 [71/172] - loss: 0.7369
Epoch 1 [72/172] - loss: 0.8182
Epoch 1 [73/172] - loss: 0.8894
Epoch 1 [74/172] - loss: 0.8288
Epoch 1 [75/172] - loss: 0.5951
Epoch 1 [76/172] - loss: 0.5872
Epoch 1 [77/172] - loss: 0.8753
Epoch 1 [78/172] - loss: 0.5774
Epoch 1 [79/172] - loss: 0.8935
Epoch 1 [80/172] - loss: 0.4468, acc: 0.8438
Epoch 1 [81/172] - loss: 0.8150
Epoch 1 [82/172] - loss: 0.9698
Epoch 1 [83/172] - loss: 0.8997
Epoch 1 [84/172] - loss: 0.7019
Epoch 1 [85/172] - loss: 0.6480
Epoch 1 [86/172] - loss: 0.7558
Epoch 1 [87/172] - loss: 0.6203
Epoch 1 [88/172] - loss: 0.8878
Epoch 1 [89/172] - loss: 0.8608
Epoch 1 [90/172] - loss: 0.7226, acc: 0.6250
Epoch 1 [91/172] - loss: 0.7600
Epoch 1 [92/172] - loss: 0.5043
Epoch 1 [93/172] - loss: 0.6194
Epoch 1 [94/172] - loss: 0.5134
Epoch 1 [95/172] - loss: 0.5040
Epoch 1 [96/172] - loss: 0.8193
Epoch 1 [97/172] - loss: 0.5708
Epoch 1 [98/172] - loss: 0.6154
Epoch 1 [99/172] - loss: 1.2949
Epoch 1 [100/172] - loss: 0.9999, acc: 0.5938

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5742, log_difficulty=0.4538, weight=3.2689
neutral: count=983.0, difficulty=0.5637, log_difficulty=0.4470, weight=3.2351
negative: count=1119.0, difficulty=0.5756, log_difficulty=0.4546, weight=3.2732

当前batch的pt分布：
positive: min=0.1718, max=0.9307, mean=0.4474
neutral: min=0.5073, max=0.9618, mean=0.7316
negative: min=0.1634, max=0.7425, mean=0.3945

当前batch准确率：
整体准确率: 0.5312
positive 准确率: 0.5000
neutral 准确率: 1.0000
negative 准确率: 0.4375

损失分量：
基础交叉熵: 0.9114
焦点损失: 0.3252
边界损失: 0.5260
总损失: 0.9292
Epoch 1 [101/172] - loss: 0.9292
Epoch 1 [102/172] - loss: 0.7493
Epoch 1 [103/172] - loss: 0.6946
Epoch 1 [104/172] - loss: 0.3993
Epoch 1 [105/172] - loss: 0.7918
Epoch 1 [106/172] - loss: 0.8515
Epoch 1 [107/172] - loss: 0.5292
Epoch 1 [108/172] - loss: 0.7234
Epoch 1 [109/172] - loss: 0.6170
Epoch 1 [110/172] - loss: 0.7466, acc: 0.7188
Epoch 1 [111/172] - loss: 0.7734
Epoch 1 [112/172] - loss: 0.5120
Epoch 1 [113/172] - loss: 0.5527
Epoch 1 [114/172] - loss: 0.6127
Epoch 1 [115/172] - loss: 0.5474
Epoch 1 [116/172] - loss: 0.6477
Epoch 1 [117/172] - loss: 0.5160
Epoch 1 [118/172] - loss: 0.5289
Epoch 1 [119/172] - loss: 0.5756
Epoch 1 [120/172] - loss: 0.4411, acc: 0.8125
Epoch 1 [121/172] - loss: 0.5235
Epoch 1 [122/172] - loss: 0.6124
Epoch 1 [123/172] - loss: 0.4279
Epoch 1 [124/172] - loss: 0.6122
Epoch 1 [125/172] - loss: 0.4013
Epoch 1 [126/172] - loss: 0.6835
Epoch 1 [127/172] - loss: 0.6515
Epoch 1 [128/172] - loss: 0.5346
Epoch 1 [129/172] - loss: 0.7110
Epoch 1 [130/172] - loss: 0.3615, acc: 0.8438
Epoch 1 [131/172] - loss: 0.3013
Epoch 1 [132/172] - loss: 0.7857
Epoch 1 [133/172] - loss: 0.7222
Epoch 1 [134/172] - loss: 0.5095
Epoch 1 [135/172] - loss: 0.5786
Epoch 1 [136/172] - loss: 0.5145
Epoch 1 [137/172] - loss: 0.5517
Epoch 1 [138/172] - loss: 0.6168
Epoch 1 [139/172] - loss: 0.4708
Epoch 1 [140/172] - loss: 0.4818, acc: 0.8750
Epoch 1 [141/172] - loss: 0.5233
Epoch 1 [142/172] - loss: 0.5001
Epoch 1 [143/172] - loss: 0.4841
Epoch 1 [144/172] - loss: 0.4771
Epoch 1 [145/172] - loss: 0.6032
Epoch 1 [146/172] - loss: 0.6127
Epoch 1 [147/172] - loss: 0.7533
Epoch 1 [148/172] - loss: 0.3770
Epoch 1 [149/172] - loss: 0.3948
Epoch 1 [150/172] - loss: 0.5734, acc: 0.5938
Epoch 1 [151/172] - loss: 0.6722
Epoch 1 [152/172] - loss: 0.5387
Epoch 1 [153/172] - loss: 0.4386
Epoch 1 [154/172] - loss: 0.4664
Epoch 1 [155/172] - loss: 0.5794
Epoch 1 [156/172] - loss: 0.5989
Epoch 1 [157/172] - loss: 0.5087
Epoch 1 [158/172] - loss: 0.4970
Epoch 1 [159/172] - loss: 0.9146
Epoch 1 [160/172] - loss: 0.6787, acc: 0.7188
Epoch 1 [161/172] - loss: 0.5213
Epoch 1 [162/172] - loss: 0.5471
Epoch 1 [163/172] - loss: 0.5180
Epoch 1 [164/172] - loss: 0.6016
Epoch 1 [165/172] - loss: 0.5927
Epoch 1 [166/172] - loss: 0.4201
Epoch 1 [167/172] - loss: 0.5077
Epoch 1 [168/172] - loss: 0.6510
Epoch 1 [169/172] - loss: 0.4533
Epoch 1 [170/172] - loss: 0.3105, acc: 0.8438
Epoch 1 [171/172] - loss: 0.3937
Epoch 1 [172/172] - loss: 0.4259

类别准确率:
positive: 0.8180 (382/467)
neutral: 0.4337 (36/83)
negative: 0.5960 (149/250)

Epoch 1/10
Train Loss: 0.5339, Train Acc: 0.7394
Val Loss: 0.6728, Val Acc: 0.7087
Epoch 2 [1/172] - loss: 0.4119, acc: 0.8750
Epoch 2 [2/172] - loss: 0.2869
Epoch 2 [3/172] - loss: 0.2650
Epoch 2 [4/172] - loss: 0.5133
Epoch 2 [5/172] - loss: 0.5189
Epoch 2 [6/172] - loss: 0.5239
Epoch 2 [7/172] - loss: 0.3308
Epoch 2 [8/172] - loss: 0.4277
Epoch 2 [9/172] - loss: 0.4919
Epoch 2 [10/172] - loss: 0.3503, acc: 0.9062
Epoch 2 [11/172] - loss: 0.3059
Epoch 2 [12/172] - loss: 0.2275
Epoch 2 [13/172] - loss: 0.4254
Epoch 2 [14/172] - loss: 0.3680
Epoch 2 [15/172] - loss: 0.5065
Epoch 2 [16/172] - loss: 0.3398
Epoch 2 [17/172] - loss: 0.4530
Epoch 2 [18/172] - loss: 0.4442
Epoch 2 [19/172] - loss: 0.2835
Epoch 2 [20/172] - loss: 0.2813, acc: 0.9375
Epoch 2 [21/172] - loss: 0.3184
Epoch 2 [22/172] - loss: 0.2464
Epoch 2 [23/172] - loss: 0.2889
Epoch 2 [24/172] - loss: 0.8434
Epoch 2 [25/172] - loss: 0.5811
Epoch 2 [26/172] - loss: 0.2263
Epoch 2 [27/172] - loss: 0.2882
Epoch 2 [28/172] - loss: 0.2344

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5119, log_difficulty=0.4133, weight=3.0667
neutral: count=1952.0, difficulty=0.4680, log_difficulty=0.3839, weight=2.9195
negative: count=2216.0, difficulty=0.5109, log_difficulty=0.4127, weight=3.0634

当前batch的pt分布：
positive: min=0.4041, max=0.8722, mean=0.6714
neutral: min=0.5595, max=0.9407, mean=0.7714
negative: min=0.0712, max=0.9507, mean=0.5959

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.8889
neutral 准确率: 1.0000
negative 准确率: 0.6667

损失分量：
基础交叉熵: 0.4805
焦点损失: 0.1362
边界损失: 0.3427
总损失: 0.3981
Epoch 2 [29/172] - loss: 0.3981
Epoch 2 [30/172] - loss: 0.2742, acc: 0.9062
Epoch 2 [31/172] - loss: 0.3508
Epoch 2 [32/172] - loss: 0.3922
Epoch 2 [33/172] - loss: 0.3126
Epoch 2 [34/172] - loss: 0.5298
Epoch 2 [35/172] - loss: 0.2846
Epoch 2 [36/172] - loss: 0.4190
Epoch 2 [37/172] - loss: 0.1683
Epoch 2 [38/172] - loss: 0.3404
Epoch 2 [39/172] - loss: 0.2340
Epoch 2 [40/172] - loss: 0.4961, acc: 0.7188
Epoch 2 [41/172] - loss: 0.3086
Epoch 2 [42/172] - loss: 0.2116
Epoch 2 [43/172] - loss: 0.1774
Epoch 2 [44/172] - loss: 0.5070
Epoch 2 [45/172] - loss: 0.2888
Epoch 2 [46/172] - loss: 0.2175
Epoch 2 [47/172] - loss: 0.3389
Epoch 2 [48/172] - loss: 0.4430
Epoch 2 [49/172] - loss: 0.3274
Epoch 2 [50/172] - loss: 0.3014, acc: 0.9062
Epoch 2 [51/172] - loss: 0.3557
Epoch 2 [52/172] - loss: 0.2165
Epoch 2 [53/172] - loss: 0.2602
Epoch 2 [54/172] - loss: 0.2730
Epoch 2 [55/172] - loss: 0.2832
Epoch 2 [56/172] - loss: 0.2163
Epoch 2 [57/172] - loss: 0.2647
Epoch 2 [58/172] - loss: 0.6230
Epoch 2 [59/172] - loss: 0.4374
Epoch 2 [60/172] - loss: 0.2654, acc: 0.8750
Epoch 2 [61/172] - loss: 0.1495
Epoch 2 [62/172] - loss: 0.1415
Epoch 2 [63/172] - loss: 0.2471
Epoch 2 [64/172] - loss: 0.3369
Epoch 2 [65/172] - loss: 0.2383
Epoch 2 [66/172] - loss: 0.2099
Epoch 2 [67/172] - loss: 0.2560
Epoch 2 [68/172] - loss: 0.3358
Epoch 2 [69/172] - loss: 0.2121
Epoch 2 [70/172] - loss: 0.5598, acc: 0.8125
Epoch 2 [71/172] - loss: 0.4005
Epoch 2 [72/172] - loss: 0.4133
Epoch 2 [73/172] - loss: 0.2687
Epoch 2 [74/172] - loss: 0.2778
Epoch 2 [75/172] - loss: 0.2049
Epoch 2 [76/172] - loss: 0.2780
Epoch 2 [77/172] - loss: 0.3155
Epoch 2 [78/172] - loss: 0.3416
Epoch 2 [79/172] - loss: 0.3573
Epoch 2 [80/172] - loss: 0.1909, acc: 0.9375
Epoch 2 [81/172] - loss: 0.3041
Epoch 2 [82/172] - loss: 0.2619
Epoch 2 [83/172] - loss: 0.2782
Epoch 2 [84/172] - loss: 0.2318
Epoch 2 [85/172] - loss: 0.2151
Epoch 2 [86/172] - loss: 0.2452
Epoch 2 [87/172] - loss: 0.7522
Epoch 2 [88/172] - loss: 0.2531
Epoch 2 [89/172] - loss: 0.1652
Epoch 2 [90/172] - loss: 0.2836, acc: 0.9062
Epoch 2 [91/172] - loss: 0.1935
Epoch 2 [92/172] - loss: 0.4437
Epoch 2 [93/172] - loss: 0.1845
Epoch 2 [94/172] - loss: 0.1467
Epoch 2 [95/172] - loss: 0.3787
Epoch 2 [96/172] - loss: 0.2123
Epoch 2 [97/172] - loss: 0.2826
Epoch 2 [98/172] - loss: 0.2689
Epoch 2 [99/172] - loss: 0.1512
Epoch 2 [100/172] - loss: 0.2614, acc: 0.9375
Epoch 2 [101/172] - loss: 0.1856
Epoch 2 [102/172] - loss: 0.1655
Epoch 2 [103/172] - loss: 0.3154
Epoch 2 [104/172] - loss: 0.3255
Epoch 2 [105/172] - loss: 0.1518
Epoch 2 [106/172] - loss: 0.2152
Epoch 2 [107/172] - loss: 0.2652
Epoch 2 [108/172] - loss: 0.5158
Epoch 2 [109/172] - loss: 0.1925
Epoch 2 [110/172] - loss: 0.1942, acc: 0.9375
Epoch 2 [111/172] - loss: 0.1636
Epoch 2 [112/172] - loss: 0.1614
Epoch 2 [113/172] - loss: 0.1052
Epoch 2 [114/172] - loss: 0.2362
Epoch 2 [115/172] - loss: 0.2041
Epoch 2 [116/172] - loss: 0.2053
Epoch 2 [117/172] - loss: 0.4645
Epoch 2 [118/172] - loss: 0.1633
Epoch 2 [119/172] - loss: 0.2456
Epoch 2 [120/172] - loss: 0.1696, acc: 0.8750
Epoch 2 [121/172] - loss: 0.3657
Epoch 2 [122/172] - loss: 0.3895
Epoch 2 [123/172] - loss: 0.3517
Epoch 2 [124/172] - loss: 0.3109
Epoch 2 [125/172] - loss: 0.1830
Epoch 2 [126/172] - loss: 0.2595
Epoch 2 [127/172] - loss: 0.1646
Epoch 2 [128/172] - loss: 0.3793

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4536, log_difficulty=0.3741, weight=2.8703
neutral: count=2949.0, difficulty=0.3850, log_difficulty=0.3257, weight=2.6287
negative: count=3294.0, difficulty=0.4539, log_difficulty=0.3743, weight=2.8713

当前batch的pt分布：
positive: min=0.3667, max=0.9438, mean=0.7082
neutral: min=0.4266, max=0.9351, mean=0.7728
negative: min=0.2952, max=0.9191, mean=0.6972

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.8000
neutral 准确率: 0.9091
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.3618
焦点损失: 0.0576
边界损失: 0.3343
总损失: 0.2052
Epoch 2 [129/172] - loss: 0.2052
Epoch 2 [130/172] - loss: 0.1870, acc: 0.9688
Epoch 2 [131/172] - loss: 0.2886
Epoch 2 [132/172] - loss: 0.2099
Epoch 2 [133/172] - loss: 0.1847
Epoch 2 [134/172] - loss: 0.3554
Epoch 2 [135/172] - loss: 0.4793
Epoch 2 [136/172] - loss: 0.2437
Epoch 2 [137/172] - loss: 0.1321
Epoch 2 [138/172] - loss: 0.1862
Epoch 2 [139/172] - loss: 0.2475
Epoch 2 [140/172] - loss: 0.3156, acc: 0.8750
Epoch 2 [141/172] - loss: 0.3101
Epoch 2 [142/172] - loss: 0.2246
Epoch 2 [143/172] - loss: 0.2477
Epoch 2 [144/172] - loss: 0.2010
Epoch 2 [145/172] - loss: 0.7981
Epoch 2 [146/172] - loss: 0.2757
Epoch 2 [147/172] - loss: 0.3306
Epoch 2 [148/172] - loss: 0.2521
Epoch 2 [149/172] - loss: 0.2156
Epoch 2 [150/172] - loss: 0.3910, acc: 0.8750
Epoch 2 [151/172] - loss: 0.2135
Epoch 2 [152/172] - loss: 0.1494
Epoch 2 [153/172] - loss: 0.2326
Epoch 2 [154/172] - loss: 0.1777
Epoch 2 [155/172] - loss: 0.2857
Epoch 2 [156/172] - loss: 0.1271
Epoch 2 [157/172] - loss: 0.1244
Epoch 2 [158/172] - loss: 0.1386
Epoch 2 [159/172] - loss: 0.2887
Epoch 2 [160/172] - loss: 0.1568, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1311
Epoch 2 [162/172] - loss: 0.1790
Epoch 2 [163/172] - loss: 0.2093
Epoch 2 [164/172] - loss: 0.4411
Epoch 2 [165/172] - loss: 0.3246
Epoch 2 [166/172] - loss: 0.4357
Epoch 2 [167/172] - loss: 0.2727
Epoch 2 [168/172] - loss: 0.2306
Epoch 2 [169/172] - loss: 0.1508
Epoch 2 [170/172] - loss: 0.1868, acc: 0.9375
Epoch 2 [171/172] - loss: 0.4273
Epoch 2 [172/172] - loss: 0.3908

类别准确率:
positive: 0.8266 (386/467)
neutral: 0.3494 (29/83)
negative: 0.5640 (141/250)

Epoch 2/10
Train Loss: 0.2555, Train Acc: 0.8869
Val Loss: 0.6950, Val Acc: 0.6950
Epoch 3 [1/172] - loss: 0.1565, acc: 0.9375
Epoch 3 [2/172] - loss: 0.2179
Epoch 3 [3/172] - loss: 0.0757
Epoch 3 [4/172] - loss: 0.1752
Epoch 3 [5/172] - loss: 0.1177
Epoch 3 [6/172] - loss: 0.0923
Epoch 3 [7/172] - loss: 0.1400
Epoch 3 [8/172] - loss: 0.1547
Epoch 3 [9/172] - loss: 0.1036
Epoch 3 [10/172] - loss: 0.1178, acc: 0.9375
Epoch 3 [11/172] - loss: 0.0906
Epoch 3 [12/172] - loss: 0.1160
Epoch 3 [13/172] - loss: 0.1544
Epoch 3 [14/172] - loss: 0.1025
Epoch 3 [15/172] - loss: 0.1435
Epoch 3 [16/172] - loss: 0.2214
Epoch 3 [17/172] - loss: 0.2856
Epoch 3 [18/172] - loss: 0.1398
Epoch 3 [19/172] - loss: 0.1755
Epoch 3 [20/172] - loss: 0.0795, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1212
Epoch 3 [22/172] - loss: 0.3302
Epoch 3 [23/172] - loss: 0.0776
Epoch 3 [24/172] - loss: 0.1274
Epoch 3 [25/172] - loss: 0.2084
Epoch 3 [26/172] - loss: 0.1434
Epoch 3 [27/172] - loss: 0.1568
Epoch 3 [28/172] - loss: 0.1092
Epoch 3 [29/172] - loss: 0.1498
Epoch 3 [30/172] - loss: 0.1880, acc: 0.8438
Epoch 3 [31/172] - loss: 0.1119
Epoch 3 [32/172] - loss: 0.1720
Epoch 3 [33/172] - loss: 0.0952
Epoch 3 [34/172] - loss: 0.1429
Epoch 3 [35/172] - loss: 0.1982
Epoch 3 [36/172] - loss: 0.1516
Epoch 3 [37/172] - loss: 0.1793
Epoch 3 [38/172] - loss: 0.1025
Epoch 3 [39/172] - loss: 0.1168
Epoch 3 [40/172] - loss: 0.1279, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1663
Epoch 3 [42/172] - loss: 0.1575
Epoch 3 [43/172] - loss: 0.1289
Epoch 3 [44/172] - loss: 0.1204
Epoch 3 [45/172] - loss: 0.2391
Epoch 3 [46/172] - loss: 0.1057
Epoch 3 [47/172] - loss: 0.0764
Epoch 3 [48/172] - loss: 0.0978
Epoch 3 [49/172] - loss: 0.2407
Epoch 3 [50/172] - loss: 0.1617, acc: 0.9688
Epoch 3 [51/172] - loss: 0.1986
Epoch 3 [52/172] - loss: 0.3262
Epoch 3 [53/172] - loss: 0.1377
Epoch 3 [54/172] - loss: 0.2816
Epoch 3 [55/172] - loss: 0.1283
Epoch 3 [56/172] - loss: 0.1717

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.4040, log_difficulty=0.3394, weight=2.6968
neutral: count=3923.0, difficulty=0.3342, log_difficulty=0.2883, weight=2.4416
negative: count=4382.0, difficulty=0.4051, log_difficulty=0.3401, weight=2.7004

当前batch的pt分布：
positive: min=0.5477, max=0.9681, mean=0.7927
neutral: min=0.0180, max=0.9631, mean=0.6995
negative: min=0.8534, max=0.9754, mean=0.9227

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3801
焦点损失: 0.1504
边界损失: 0.2752
总损失: 0.3456
Epoch 3 [57/172] - loss: 0.3456
Epoch 3 [58/172] - loss: 0.1506
Epoch 3 [59/172] - loss: 0.1365
Epoch 3 [60/172] - loss: 0.1166, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1159
Epoch 3 [62/172] - loss: 0.1399
Epoch 3 [63/172] - loss: 0.1049
Epoch 3 [64/172] - loss: 0.1061
Epoch 3 [65/172] - loss: 0.1694
Epoch 3 [66/172] - loss: 0.1164
Epoch 3 [67/172] - loss: 0.1552
Epoch 3 [68/172] - loss: 0.1070
Epoch 3 [69/172] - loss: 0.2075
Epoch 3 [70/172] - loss: 0.0702, acc: 1.0000
Epoch 3 [71/172] - loss: 0.2302
Epoch 3 [72/172] - loss: 0.2386
Epoch 3 [73/172] - loss: 0.0874
Epoch 3 [74/172] - loss: 0.1636
Epoch 3 [75/172] - loss: 0.0710
Epoch 3 [76/172] - loss: 0.0899
Epoch 3 [77/172] - loss: 0.1589
Epoch 3 [78/172] - loss: 0.2658
Epoch 3 [79/172] - loss: 0.0957
Epoch 3 [80/172] - loss: 0.2849, acc: 0.8750
Epoch 3 [81/172] - loss: 0.1361
Epoch 3 [82/172] - loss: 0.1753
Epoch 3 [83/172] - loss: 0.1544
Epoch 3 [84/172] - loss: 0.0790
Epoch 3 [85/172] - loss: 0.1743
Epoch 3 [86/172] - loss: 0.0857
Epoch 3 [87/172] - loss: 0.1571
Epoch 3 [88/172] - loss: 0.2133
Epoch 3 [89/172] - loss: 0.0660
Epoch 3 [90/172] - loss: 0.0931, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1254
Epoch 3 [92/172] - loss: 0.1171
Epoch 3 [93/172] - loss: 0.1360
Epoch 3 [94/172] - loss: 0.0938
Epoch 3 [95/172] - loss: 0.0689
Epoch 3 [96/172] - loss: 0.1231
Epoch 3 [97/172] - loss: 0.0831
Epoch 3 [98/172] - loss: 0.0813
Epoch 3 [99/172] - loss: 0.0702
Epoch 3 [100/172] - loss: 0.1537, acc: 0.9375
Epoch 3 [101/172] - loss: 0.1174
Epoch 3 [102/172] - loss: 0.0858
Epoch 3 [103/172] - loss: 0.2597
Epoch 3 [104/172] - loss: 0.0847
Epoch 3 [105/172] - loss: 0.0709
Epoch 3 [106/172] - loss: 0.1036
Epoch 3 [107/172] - loss: 0.0734
Epoch 3 [108/172] - loss: 0.0766
Epoch 3 [109/172] - loss: 0.0609
Epoch 3 [110/172] - loss: 0.2980, acc: 0.8750
Epoch 3 [111/172] - loss: 0.1012
Epoch 3 [112/172] - loss: 0.0737
Epoch 3 [113/172] - loss: 0.0815
Epoch 3 [114/172] - loss: 0.0863
Epoch 3 [115/172] - loss: 0.1353
Epoch 3 [116/172] - loss: 0.0884
Epoch 3 [117/172] - loss: 0.0820
Epoch 3 [118/172] - loss: 0.0922
Epoch 3 [119/172] - loss: 0.1215
Epoch 3 [120/172] - loss: 0.1597, acc: 0.9688
Epoch 3 [121/172] - loss: 0.2594
Epoch 3 [122/172] - loss: 0.1025
Epoch 3 [123/172] - loss: 0.0766
Epoch 3 [124/172] - loss: 0.2088
Epoch 3 [125/172] - loss: 0.0894
Epoch 3 [126/172] - loss: 0.4454
Epoch 3 [127/172] - loss: 0.1365
Epoch 3 [128/172] - loss: 0.0686
Epoch 3 [129/172] - loss: 0.0564
Epoch 3 [130/172] - loss: 0.0943, acc: 0.9688
Epoch 3 [131/172] - loss: 0.1718
Epoch 3 [132/172] - loss: 0.1627
Epoch 3 [133/172] - loss: 0.1840
Epoch 3 [134/172] - loss: 0.0743
Epoch 3 [135/172] - loss: 0.1158
Epoch 3 [136/172] - loss: 0.0925
Epoch 3 [137/172] - loss: 0.0836
Epoch 3 [138/172] - loss: 0.0951
Epoch 3 [139/172] - loss: 0.1439
Epoch 3 [140/172] - loss: 0.1015, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1019
Epoch 3 [142/172] - loss: 0.1034
Epoch 3 [143/172] - loss: 0.0996
Epoch 3 [144/172] - loss: 0.1421
Epoch 3 [145/172] - loss: 0.0956
Epoch 3 [146/172] - loss: 0.1122
Epoch 3 [147/172] - loss: 0.0889
Epoch 3 [148/172] - loss: 0.1061
Epoch 3 [149/172] - loss: 0.1046
Epoch 3 [150/172] - loss: 0.1621, acc: 0.9375
Epoch 3 [151/172] - loss: 0.2069
Epoch 3 [152/172] - loss: 0.1345
Epoch 3 [153/172] - loss: 0.1366
Epoch 3 [154/172] - loss: 0.2227
Epoch 3 [155/172] - loss: 0.0625
Epoch 3 [156/172] - loss: 0.1090

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3616, log_difficulty=0.3087, weight=2.5435
neutral: count=4903.0, difficulty=0.2908, log_difficulty=0.2552, weight=2.2762
negative: count=5500.0, difficulty=0.3639, log_difficulty=0.3103, weight=2.5516

当前batch的pt分布：
positive: min=0.6641, max=0.9535, mean=0.8736
neutral: min=0.8146, max=0.9822, mean=0.9309
negative: min=0.7243, max=0.9867, mean=0.8607

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1219
焦点损失: 0.0027
边界损失: 0.2022
总损失: 0.0556
Epoch 3 [157/172] - loss: 0.0556
Epoch 3 [158/172] - loss: 0.2680
Epoch 3 [159/172] - loss: 0.0787
Epoch 3 [160/172] - loss: 0.2281, acc: 0.9375
Epoch 3 [161/172] - loss: 0.1582
Epoch 3 [162/172] - loss: 0.0940
Epoch 3 [163/172] - loss: 0.1159
Epoch 3 [164/172] - loss: 0.0738
Epoch 3 [165/172] - loss: 0.0623
Epoch 3 [166/172] - loss: 0.0711
Epoch 3 [167/172] - loss: 0.1025
Epoch 3 [168/172] - loss: 0.0805
Epoch 3 [169/172] - loss: 0.0607
Epoch 3 [170/172] - loss: 0.1398, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1236
Epoch 3 [172/172] - loss: 0.0845

类别准确率:
positive: 0.8737 (408/467)
neutral: 0.3253 (27/83)
negative: 0.6280 (157/250)

Epoch 3/10
Train Loss: 0.1123, Train Acc: 0.9677
Val Loss: 0.6901, Val Acc: 0.7400
Epoch 4 [1/172] - loss: 0.0652, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1326
Epoch 4 [3/172] - loss: 0.0697
Epoch 4 [4/172] - loss: 0.1416
Epoch 4 [5/172] - loss: 0.0707
Epoch 4 [6/172] - loss: 0.0763
Epoch 4 [7/172] - loss: 0.0662
Epoch 4 [8/172] - loss: 0.0687
Epoch 4 [9/172] - loss: 0.2251
Epoch 4 [10/172] - loss: 0.1315, acc: 0.9375
Epoch 4 [11/172] - loss: 0.0630
Epoch 4 [12/172] - loss: 0.0598
Epoch 4 [13/172] - loss: 0.0943
Epoch 4 [14/172] - loss: 0.1409
Epoch 4 [15/172] - loss: 0.0513
Epoch 4 [16/172] - loss: 0.0529
Epoch 4 [17/172] - loss: 0.0656
Epoch 4 [18/172] - loss: 0.0698
Epoch 4 [19/172] - loss: 0.0666
Epoch 4 [20/172] - loss: 0.0653, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1177
Epoch 4 [22/172] - loss: 0.0574
Epoch 4 [23/172] - loss: 0.1011
Epoch 4 [24/172] - loss: 0.0529
Epoch 4 [25/172] - loss: 0.0852
Epoch 4 [26/172] - loss: 0.2333
Epoch 4 [27/172] - loss: 0.0533
Epoch 4 [28/172] - loss: 0.1396
Epoch 4 [29/172] - loss: 0.0480
Epoch 4 [30/172] - loss: 0.0892, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1042
Epoch 4 [32/172] - loss: 0.0706
Epoch 4 [33/172] - loss: 0.1006
Epoch 4 [34/172] - loss: 0.0635
Epoch 4 [35/172] - loss: 0.1158
Epoch 4 [36/172] - loss: 0.0615
Epoch 4 [37/172] - loss: 0.0479
Epoch 4 [38/172] - loss: 0.2125
Epoch 4 [39/172] - loss: 0.1860
Epoch 4 [40/172] - loss: 0.1272, acc: 0.9375
Epoch 4 [41/172] - loss: 0.0640
Epoch 4 [42/172] - loss: 0.0983
Epoch 4 [43/172] - loss: 0.1031
Epoch 4 [44/172] - loss: 0.0569
Epoch 4 [45/172] - loss: 0.0497
Epoch 4 [46/172] - loss: 0.0669
Epoch 4 [47/172] - loss: 0.0633
Epoch 4 [48/172] - loss: 0.0498
Epoch 4 [49/172] - loss: 0.0591
Epoch 4 [50/172] - loss: 0.2111, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0646
Epoch 4 [52/172] - loss: 0.0857
Epoch 4 [53/172] - loss: 0.0600
Epoch 4 [54/172] - loss: 0.0617
Epoch 4 [55/172] - loss: 0.2963
Epoch 4 [56/172] - loss: 0.0707
Epoch 4 [57/172] - loss: 0.0569
Epoch 4 [58/172] - loss: 0.0620
Epoch 4 [59/172] - loss: 0.0495
Epoch 4 [60/172] - loss: 0.0527, acc: 1.0000
Epoch 4 [61/172] - loss: 0.0602
Epoch 4 [62/172] - loss: 0.1316
Epoch 4 [63/172] - loss: 0.0639
Epoch 4 [64/172] - loss: 0.0569
Epoch 4 [65/172] - loss: 0.0830
Epoch 4 [66/172] - loss: 0.0869
Epoch 4 [67/172] - loss: 0.0555
Epoch 4 [68/172] - loss: 0.0529
Epoch 4 [69/172] - loss: 0.0649
Epoch 4 [70/172] - loss: 0.1589, acc: 0.9688
Epoch 4 [71/172] - loss: 0.0589
Epoch 4 [72/172] - loss: 0.0596
Epoch 4 [73/172] - loss: 0.0470
Epoch 4 [74/172] - loss: 0.2903
Epoch 4 [75/172] - loss: 0.1632
Epoch 4 [76/172] - loss: 0.0486
Epoch 4 [77/172] - loss: 0.1308
Epoch 4 [78/172] - loss: 0.0515
Epoch 4 [79/172] - loss: 0.0471
Epoch 4 [80/172] - loss: 0.0473, acc: 1.0000
Epoch 4 [81/172] - loss: 0.0910
Epoch 4 [82/172] - loss: 0.0662
Epoch 4 [83/172] - loss: 0.0477
Epoch 4 [84/172] - loss: 0.0448

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3242, log_difficulty=0.2808, weight=2.4040
neutral: count=5865.0, difficulty=0.2591, log_difficulty=0.2304, weight=2.1519
negative: count=6629.0, difficulty=0.3269, log_difficulty=0.2828, weight=2.4142

当前batch的pt分布：
positive: min=0.5286, max=0.9778, mean=0.8217
neutral: min=0.7265, max=0.9965, mean=0.9223
negative: min=0.4442, max=0.9699, mean=0.8720

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.1697
焦点损失: 0.0150
边界损失: 0.2222
总损失: 0.0825
Epoch 4 [85/172] - loss: 0.0825
Epoch 4 [86/172] - loss: 0.0620
Epoch 4 [87/172] - loss: 0.0741
Epoch 4 [88/172] - loss: 0.0689
Epoch 4 [89/172] - loss: 0.0591
Epoch 4 [90/172] - loss: 0.0466, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1561
Epoch 4 [92/172] - loss: 0.1679
Epoch 4 [93/172] - loss: 0.0514
Epoch 4 [94/172] - loss: 0.0486
Epoch 4 [95/172] - loss: 0.2308
Epoch 4 [96/172] - loss: 0.1097
Epoch 4 [97/172] - loss: 0.0656
Epoch 4 [98/172] - loss: 0.0601
Epoch 4 [99/172] - loss: 0.0878
Epoch 4 [100/172] - loss: 0.0550, acc: 1.0000
Epoch 4 [101/172] - loss: 0.1061
Epoch 4 [102/172] - loss: 0.0804
Epoch 4 [103/172] - loss: 0.0476
Epoch 4 [104/172] - loss: 0.0460
Epoch 4 [105/172] - loss: 0.0682
Epoch 4 [106/172] - loss: 0.0523
Epoch 4 [107/172] - loss: 0.0472
Epoch 4 [108/172] - loss: 0.0671
Epoch 4 [109/172] - loss: 0.0484
Epoch 4 [110/172] - loss: 0.5050, acc: 0.8438
Epoch 4 [111/172] - loss: 0.0488
Epoch 4 [112/172] - loss: 0.0465
Epoch 4 [113/172] - loss: 0.0540
Epoch 4 [114/172] - loss: 0.0595
Epoch 4 [115/172] - loss: 0.0586
Epoch 4 [116/172] - loss: 0.0596
Epoch 4 [117/172] - loss: 0.0507
Epoch 4 [118/172] - loss: 0.0665
Epoch 4 [119/172] - loss: 0.0522
Epoch 4 [120/172] - loss: 0.0606, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1430
Epoch 4 [122/172] - loss: 0.2224
Epoch 4 [123/172] - loss: 0.0506
Epoch 4 [124/172] - loss: 0.0452
Epoch 4 [125/172] - loss: 0.0738
Epoch 4 [126/172] - loss: 0.1669
Epoch 4 [127/172] - loss: 0.0953
Epoch 4 [128/172] - loss: 0.0535
Epoch 4 [129/172] - loss: 0.0673
Epoch 4 [130/172] - loss: 0.0473, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0535
Epoch 4 [132/172] - loss: 0.0571
Epoch 4 [133/172] - loss: 0.0756
Epoch 4 [134/172] - loss: 0.0667
Epoch 4 [135/172] - loss: 0.0924
Epoch 4 [136/172] - loss: 0.0696
Epoch 4 [137/172] - loss: 0.0601
Epoch 4 [138/172] - loss: 0.0521
Epoch 4 [139/172] - loss: 0.0921
Epoch 4 [140/172] - loss: 0.2725, acc: 0.9375
Epoch 4 [141/172] - loss: 0.1003
Epoch 4 [142/172] - loss: 0.0553
Epoch 4 [143/172] - loss: 0.0490
Epoch 4 [144/172] - loss: 0.0586
Epoch 4 [145/172] - loss: 0.1561
Epoch 4 [146/172] - loss: 0.0548
Epoch 4 [147/172] - loss: 0.0662
Epoch 4 [148/172] - loss: 0.0506
Epoch 4 [149/172] - loss: 0.0491
Epoch 4 [150/172] - loss: 0.1142, acc: 0.9688
Epoch 4 [151/172] - loss: 0.2058
Epoch 4 [152/172] - loss: 0.0434
Epoch 4 [153/172] - loss: 0.0526
Epoch 4 [154/172] - loss: 0.1026
Epoch 4 [155/172] - loss: 0.0568
Epoch 4 [156/172] - loss: 0.0874
Epoch 4 [157/172] - loss: 0.2441
Epoch 4 [158/172] - loss: 0.0503
Epoch 4 [159/172] - loss: 0.0646
Epoch 4 [160/172] - loss: 0.0569, acc: 1.0000
Epoch 4 [161/172] - loss: 0.0709
Epoch 4 [162/172] - loss: 0.1331
Epoch 4 [163/172] - loss: 0.0704
Epoch 4 [164/172] - loss: 0.0570
Epoch 4 [165/172] - loss: 0.2643
Epoch 4 [166/172] - loss: 0.0706
Epoch 4 [167/172] - loss: 0.0860
Epoch 4 [168/172] - loss: 0.0522
Epoch 4 [169/172] - loss: 0.1440
Epoch 4 [170/172] - loss: 0.2096, acc: 0.9375
Epoch 4 [171/172] - loss: 0.0579
Epoch 4 [172/172] - loss: 0.0835

类别准确率:
positive: 0.9358 (437/467)
neutral: 0.3012 (25/83)
negative: 0.4440 (111/250)

Epoch 4/10
Train Loss: 0.1072, Train Acc: 0.9737
Val Loss: 0.8073, Val Acc: 0.7163
Epoch 5 [1/172] - loss: 0.0448, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0649
Epoch 5 [3/172] - loss: 0.0431
Epoch 5 [4/172] - loss: 0.0696
Epoch 5 [5/172] - loss: 0.0548
Epoch 5 [6/172] - loss: 0.1054
Epoch 5 [7/172] - loss: 0.0505
Epoch 5 [8/172] - loss: 0.1375
Epoch 5 [9/172] - loss: 0.0703
Epoch 5 [10/172] - loss: 0.0520, acc: 1.0000
Epoch 5 [11/172] - loss: 0.0771
Epoch 5 [12/172] - loss: 0.0467

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2940, log_difficulty=0.2578, weight=2.2888
neutral: count=6845.0, difficulty=0.2339, log_difficulty=0.2101, weight=2.0507
negative: count=7694.0, difficulty=0.2987, log_difficulty=0.2614, weight=2.3068

当前batch的pt分布：
positive: min=0.5777, max=0.9849, mean=0.8624
neutral: min=0.9122, max=0.9948, mean=0.9720
negative: min=0.8358, max=0.9793, mean=0.9164

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1067
焦点损失: 0.0050
边界损失: 0.1904
总损失: 0.0562
Epoch 5 [13/172] - loss: 0.0562
Epoch 5 [14/172] - loss: 0.1646
Epoch 5 [15/172] - loss: 0.0512
Epoch 5 [16/172] - loss: 0.0445
Epoch 5 [17/172] - loss: 0.1813
Epoch 5 [18/172] - loss: 0.0573
Epoch 5 [19/172] - loss: 0.0631
Epoch 5 [20/172] - loss: 0.1162, acc: 0.9375
Epoch 5 [21/172] - loss: 0.1005
Epoch 5 [22/172] - loss: 0.3005
Epoch 5 [23/172] - loss: 0.0608
Epoch 5 [24/172] - loss: 0.0556
Epoch 5 [25/172] - loss: 0.0631
Epoch 5 [26/172] - loss: 0.1047
Epoch 5 [27/172] - loss: 0.0550
Epoch 5 [28/172] - loss: 0.0469
Epoch 5 [29/172] - loss: 0.0628
Epoch 5 [30/172] - loss: 0.0728, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1038
Epoch 5 [32/172] - loss: 0.0459
Epoch 5 [33/172] - loss: 0.0598
Epoch 5 [34/172] - loss: 0.0588
Epoch 5 [35/172] - loss: 0.0593
Epoch 5 [36/172] - loss: 0.0826
Epoch 5 [37/172] - loss: 0.0509
Epoch 5 [38/172] - loss: 0.0482
Epoch 5 [39/172] - loss: 0.1020
Epoch 5 [40/172] - loss: 0.0720, acc: 0.9688
Epoch 5 [41/172] - loss: 0.0550
Epoch 5 [42/172] - loss: 0.0570
Epoch 5 [43/172] - loss: 0.1053
Epoch 5 [44/172] - loss: 0.0597
Epoch 5 [45/172] - loss: 0.0466
Epoch 5 [46/172] - loss: 0.0572
Epoch 5 [47/172] - loss: 0.0570
Epoch 5 [48/172] - loss: 0.0849
Epoch 5 [49/172] - loss: 0.0470
Epoch 5 [50/172] - loss: 0.0910, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0580
Epoch 5 [52/172] - loss: 0.0560
Epoch 5 [53/172] - loss: 0.0591
Epoch 5 [54/172] - loss: 0.0496
Epoch 5 [55/172] - loss: 0.0915
Epoch 5 [56/172] - loss: 0.0542
Epoch 5 [57/172] - loss: 0.0598
Epoch 5 [58/172] - loss: 0.0440
Epoch 5 [59/172] - loss: 0.1664
Epoch 5 [60/172] - loss: 0.0529, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0467
Epoch 5 [62/172] - loss: 0.0655
Epoch 5 [63/172] - loss: 0.1118
Epoch 5 [64/172] - loss: 0.0522
Epoch 5 [65/172] - loss: 0.0457
Epoch 5 [66/172] - loss: 0.0574
Epoch 5 [67/172] - loss: 0.0637
Epoch 5 [68/172] - loss: 0.0477
Epoch 5 [69/172] - loss: 0.0589
Epoch 5 [70/172] - loss: 0.0495, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0522
Epoch 5 [72/172] - loss: 0.0474
Epoch 5 [73/172] - loss: 0.0522
Epoch 5 [74/172] - loss: 0.0602
Epoch 5 [75/172] - loss: 0.0550
Epoch 5 [76/172] - loss: 0.0728
Epoch 5 [77/172] - loss: 0.0863
Epoch 5 [78/172] - loss: 0.0654
Epoch 5 [79/172] - loss: 0.0517
Epoch 5 [80/172] - loss: 0.0444, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1363
Epoch 5 [82/172] - loss: 0.1284
Epoch 5 [83/172] - loss: 0.0500
Epoch 5 [84/172] - loss: 0.0655
Epoch 5 [85/172] - loss: 0.1296
Epoch 5 [86/172] - loss: 0.0484
Epoch 5 [87/172] - loss: 0.1003
Epoch 5 [88/172] - loss: 0.1531
Epoch 5 [89/172] - loss: 0.1583
Epoch 5 [90/172] - loss: 0.1356, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0563
Epoch 5 [92/172] - loss: 0.0451
Epoch 5 [93/172] - loss: 0.0667
Epoch 5 [94/172] - loss: 0.0462
Epoch 5 [95/172] - loss: 0.0577
Epoch 5 [96/172] - loss: 0.1459
Epoch 5 [97/172] - loss: 0.0737
Epoch 5 [98/172] - loss: 0.0534
Epoch 5 [99/172] - loss: 0.0866
Epoch 5 [100/172] - loss: 0.0703, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0522
Epoch 5 [102/172] - loss: 0.0570
Epoch 5 [103/172] - loss: 0.0762
Epoch 5 [104/172] - loss: 0.1399
Epoch 5 [105/172] - loss: 0.2000
Epoch 5 [106/172] - loss: 0.0529
Epoch 5 [107/172] - loss: 0.0707
Epoch 5 [108/172] - loss: 0.0889
Epoch 5 [109/172] - loss: 0.0491
Epoch 5 [110/172] - loss: 0.0448, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0715
Epoch 5 [112/172] - loss: 0.0500

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2704, log_difficulty=0.2393, weight=2.1967
neutral: count=7825.0, difficulty=0.2153, log_difficulty=0.1950, weight=1.9751
negative: count=8780.0, difficulty=0.2761, log_difficulty=0.2438, weight=2.2189

当前batch的pt分布：
positive: min=0.3397, max=0.9960, mean=0.8073
neutral: min=0.4696, max=0.9966, mean=0.8820
negative: min=0.9257, max=0.9970, mean=0.9685

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9375
neutral 准确率: 0.9091
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1752
焦点损失: 0.0249
边界损失: 0.2199
总损失: 0.0948
Epoch 5 [113/172] - loss: 0.0948
Epoch 5 [114/172] - loss: 0.0717
Epoch 5 [115/172] - loss: 0.0696
Epoch 5 [116/172] - loss: 0.0449
Epoch 5 [117/172] - loss: 0.0556
Epoch 5 [118/172] - loss: 0.0443
Epoch 5 [119/172] - loss: 0.0485
Epoch 5 [120/172] - loss: 0.0609, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0595
Epoch 5 [122/172] - loss: 0.0478
Epoch 5 [123/172] - loss: 0.0588
Epoch 5 [124/172] - loss: 0.0594
Epoch 5 [125/172] - loss: 0.0426
Epoch 5 [126/172] - loss: 0.0611
Epoch 5 [127/172] - loss: 0.0705
Epoch 5 [128/172] - loss: 0.1017
Epoch 5 [129/172] - loss: 0.0877
Epoch 5 [130/172] - loss: 0.0439, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0512
Epoch 5 [132/172] - loss: 0.1398
Epoch 5 [133/172] - loss: 0.1089
Epoch 5 [134/172] - loss: 0.1070
Epoch 5 [135/172] - loss: 0.0526
Epoch 5 [136/172] - loss: 0.0673
Epoch 5 [137/172] - loss: 0.0828
Epoch 5 [138/172] - loss: 0.0942
Epoch 5 [139/172] - loss: 0.1838
Epoch 5 [140/172] - loss: 0.2072, acc: 0.9688
Epoch 5 [141/172] - loss: 0.1040
Epoch 5 [142/172] - loss: 0.0801
Epoch 5 [143/172] - loss: 0.0608
Epoch 5 [144/172] - loss: 0.0477
Epoch 5 [145/172] - loss: 0.0555
Epoch 5 [146/172] - loss: 0.0701
Epoch 5 [147/172] - loss: 0.0758
Epoch 5 [148/172] - loss: 0.0410
Epoch 5 [149/172] - loss: 0.0486
Epoch 5 [150/172] - loss: 0.0806, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0588
Epoch 5 [152/172] - loss: 0.0649
Epoch 5 [153/172] - loss: 0.0415
Epoch 5 [154/172] - loss: 0.0436
Epoch 5 [155/172] - loss: 0.0433
Epoch 5 [156/172] - loss: 0.1043
Epoch 5 [157/172] - loss: 0.0955
Epoch 5 [158/172] - loss: 0.0472
Epoch 5 [159/172] - loss: 0.0606
Epoch 5 [160/172] - loss: 0.0526, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0570
Epoch 5 [162/172] - loss: 0.0551
Epoch 5 [163/172] - loss: 0.0670
Epoch 5 [164/172] - loss: 0.0445
Epoch 5 [165/172] - loss: 0.0756
Epoch 5 [166/172] - loss: 0.0612
Epoch 5 [167/172] - loss: 0.0771
Epoch 5 [168/172] - loss: 0.0478
Epoch 5 [169/172] - loss: 0.0487
Epoch 5 [170/172] - loss: 0.0474, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0483
Epoch 5 [172/172] - loss: 0.1302

类别准确率:
positive: 0.8223 (384/467)
neutral: 0.3614 (30/83)
negative: 0.6400 (160/250)

Epoch 5/10
Train Loss: 0.0635, Train Acc: 0.9838
Val Loss: 0.7167, Val Acc: 0.7175
Epoch 6 [1/172] - loss: 0.1258, acc: 0.9375
Epoch 6 [2/172] - loss: 0.0615
Epoch 6 [3/172] - loss: 0.0436
Epoch 6 [4/172] - loss: 0.0447
Epoch 6 [5/172] - loss: 0.1242
Epoch 6 [6/172] - loss: 0.0448
Epoch 6 [7/172] - loss: 0.0575
Epoch 6 [8/172] - loss: 0.0991
Epoch 6 [9/172] - loss: 0.0597
Epoch 6 [10/172] - loss: 0.0513, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0504
Epoch 6 [12/172] - loss: 0.0429
Epoch 6 [13/172] - loss: 0.0505
Epoch 6 [14/172] - loss: 0.0419
Epoch 6 [15/172] - loss: 0.0521
Epoch 6 [16/172] - loss: 0.1962
Epoch 6 [17/172] - loss: 0.0534
Epoch 6 [18/172] - loss: 0.0557
Epoch 6 [19/172] - loss: 0.0440
Epoch 6 [20/172] - loss: 0.0441, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0752
Epoch 6 [22/172] - loss: 0.0438
Epoch 6 [23/172] - loss: 0.0690
Epoch 6 [24/172] - loss: 0.0440
Epoch 6 [25/172] - loss: 0.1093
Epoch 6 [26/172] - loss: 0.0535
Epoch 6 [27/172] - loss: 0.0613
Epoch 6 [28/172] - loss: 0.0458
Epoch 6 [29/172] - loss: 0.0453
Epoch 6 [30/172] - loss: 0.0417, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0403
Epoch 6 [32/172] - loss: 0.0427
Epoch 6 [33/172] - loss: 0.0449
Epoch 6 [34/172] - loss: 0.0415
Epoch 6 [35/172] - loss: 0.0418
Epoch 6 [36/172] - loss: 0.0452
Epoch 6 [37/172] - loss: 0.0435
Epoch 6 [38/172] - loss: 0.0466
Epoch 6 [39/172] - loss: 0.0533
Epoch 6 [40/172] - loss: 0.0636, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2509, log_difficulty=0.2239, weight=2.1195
neutral: count=8815.0, difficulty=0.1994, log_difficulty=0.1818, weight=1.9091
negative: count=9870.0, difficulty=0.2560, log_difficulty=0.2279, weight=2.1395

当前batch的pt分布：
positive: min=0.0596, max=0.9960, mean=0.8607
neutral: min=0.8788, max=0.9956, mean=0.9531
negative: min=0.8375, max=0.9782, mean=0.9257

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1502
焦点损失: 0.0778
边界损失: 0.1677
总损失: 0.1655
Epoch 6 [41/172] - loss: 0.1655
Epoch 6 [42/172] - loss: 0.0472
Epoch 6 [43/172] - loss: 0.1199
Epoch 6 [44/172] - loss: 0.0468
Epoch 6 [45/172] - loss: 0.0561
Epoch 6 [46/172] - loss: 0.0462
Epoch 6 [47/172] - loss: 0.0568
Epoch 6 [48/172] - loss: 0.0467
Epoch 6 [49/172] - loss: 0.0461
Epoch 6 [50/172] - loss: 0.0546, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0675
Epoch 6 [52/172] - loss: 0.0708
Epoch 6 [53/172] - loss: 0.0441
Epoch 6 [54/172] - loss: 0.1262
Epoch 6 [55/172] - loss: 0.0460
Epoch 6 [56/172] - loss: 0.0527
Epoch 6 [57/172] - loss: 0.0416
Epoch 6 [58/172] - loss: 0.0521
Epoch 6 [59/172] - loss: 0.0466
Epoch 6 [60/172] - loss: 0.0786, acc: 0.9375
Epoch 6 [61/172] - loss: 0.0445
Epoch 6 [62/172] - loss: 0.1099
Epoch 6 [63/172] - loss: 0.0537
Epoch 6 [64/172] - loss: 0.0852
Epoch 6 [65/172] - loss: 0.0436
Epoch 6 [66/172] - loss: 0.0460
Epoch 6 [67/172] - loss: 0.0433
Epoch 6 [68/172] - loss: 0.0888
Epoch 6 [69/172] - loss: 0.0526
Epoch 6 [70/172] - loss: 0.0446, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0678
Epoch 6 [72/172] - loss: 0.0833
Epoch 6 [73/172] - loss: 0.0519
Epoch 6 [74/172] - loss: 0.0410
Epoch 6 [75/172] - loss: 0.0571
Epoch 6 [76/172] - loss: 0.0499
Epoch 6 [77/172] - loss: 0.0606
Epoch 6 [78/172] - loss: 0.0512
Epoch 6 [79/172] - loss: 0.0469
Epoch 6 [80/172] - loss: 0.0470, acc: 1.0000
Epoch 6 [81/172] - loss: 0.0531
Epoch 6 [82/172] - loss: 0.0449
Epoch 6 [83/172] - loss: 0.0403
Epoch 6 [84/172] - loss: 0.0693
Epoch 6 [85/172] - loss: 0.0958
Epoch 6 [86/172] - loss: 0.0532
Epoch 6 [87/172] - loss: 0.0567
Epoch 6 [88/172] - loss: 0.0573
Epoch 6 [89/172] - loss: 0.0428
Epoch 6 [90/172] - loss: 0.1209, acc: 0.9688
Epoch 6 [91/172] - loss: 0.0558
Epoch 6 [92/172] - loss: 0.0467
Epoch 6 [93/172] - loss: 0.0408
Epoch 6 [94/172] - loss: 0.0437
Epoch 6 [95/172] - loss: 0.0820
Epoch 6 [96/172] - loss: 0.0442
Epoch 6 [97/172] - loss: 0.0440
Epoch 6 [98/172] - loss: 0.0438
Epoch 6 [99/172] - loss: 0.0404
Epoch 6 [100/172] - loss: 0.0425, acc: 1.0000
Epoch 6 [101/172] - loss: 0.0739
Epoch 6 [102/172] - loss: 0.0437
Epoch 6 [103/172] - loss: 0.0695
Epoch 6 [104/172] - loss: 0.0809
Epoch 6 [105/172] - loss: 0.0429
Epoch 6 [106/172] - loss: 0.0846
Epoch 6 [107/172] - loss: 0.0434
Epoch 6 [108/172] - loss: 0.0423
Epoch 6 [109/172] - loss: 0.1249
Epoch 6 [110/172] - loss: 0.1129, acc: 0.9688
Epoch 6 [111/172] - loss: 0.0409
Epoch 6 [112/172] - loss: 0.0414
Epoch 6 [113/172] - loss: 0.0474
Epoch 6 [114/172] - loss: 0.0518
Epoch 6 [115/172] - loss: 0.0580
Epoch 6 [116/172] - loss: 0.1150
Epoch 6 [117/172] - loss: 0.0412
Epoch 6 [118/172] - loss: 0.0436
Epoch 6 [119/172] - loss: 0.0960
Epoch 6 [120/172] - loss: 0.0443, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0535
Epoch 6 [122/172] - loss: 0.0534
Epoch 6 [123/172] - loss: 0.0417
Epoch 6 [124/172] - loss: 0.0415
Epoch 6 [125/172] - loss: 0.0470
Epoch 6 [126/172] - loss: 0.0747
Epoch 6 [127/172] - loss: 0.0841
Epoch 6 [128/172] - loss: 0.0579
Epoch 6 [129/172] - loss: 0.0476
Epoch 6 [130/172] - loss: 0.1325, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1655
Epoch 6 [132/172] - loss: 0.0455
Epoch 6 [133/172] - loss: 0.0434
Epoch 6 [134/172] - loss: 0.0476
Epoch 6 [135/172] - loss: 0.0455
Epoch 6 [136/172] - loss: 0.0488
Epoch 6 [137/172] - loss: 0.0429
Epoch 6 [138/172] - loss: 0.0453
Epoch 6 [139/172] - loss: 0.0515
Epoch 6 [140/172] - loss: 0.0477, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2334, log_difficulty=0.2098, weight=2.0489
neutral: count=9796.0, difficulty=0.1853, log_difficulty=0.1700, weight=1.8501
negative: count=10972.0, difficulty=0.2387, log_difficulty=0.2140, weight=2.0702

当前batch的pt分布：
positive: min=0.9521, max=0.9953, mean=0.9804
neutral: min=0.9253, max=0.9957, mean=0.9662
negative: min=0.8412, max=0.9949, mean=0.9346

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0443
焦点损失: 0.0003
边界损失: 0.1570
总损失: 0.0397
Epoch 6 [141/172] - loss: 0.0397
Epoch 6 [142/172] - loss: 0.0399
Epoch 6 [143/172] - loss: 0.0560
Epoch 6 [144/172] - loss: 0.0462
Epoch 6 [145/172] - loss: 0.0425
Epoch 6 [146/172] - loss: 0.0418
Epoch 6 [147/172] - loss: 0.0450
Epoch 6 [148/172] - loss: 0.0527
Epoch 6 [149/172] - loss: 0.0524
Epoch 6 [150/172] - loss: 0.0404, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0432
Epoch 6 [152/172] - loss: 0.0467
Epoch 6 [153/172] - loss: 0.0647
Epoch 6 [154/172] - loss: 0.0414
Epoch 6 [155/172] - loss: 0.0569
Epoch 6 [156/172] - loss: 0.1358
Epoch 6 [157/172] - loss: 0.0429
Epoch 6 [158/172] - loss: 0.0554
Epoch 6 [159/172] - loss: 0.0459
Epoch 6 [160/172] - loss: 0.0494, acc: 1.0000
Epoch 6 [161/172] - loss: 0.0437
Epoch 6 [162/172] - loss: 0.0448
Epoch 6 [163/172] - loss: 0.0543
Epoch 6 [164/172] - loss: 0.0838
Epoch 6 [165/172] - loss: 0.1408
Epoch 6 [166/172] - loss: 0.0453
Epoch 6 [167/172] - loss: 0.0531
Epoch 6 [168/172] - loss: 0.0487
Epoch 6 [169/172] - loss: 0.1053
Epoch 6 [170/172] - loss: 0.0411, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0412
Epoch 6 [172/172] - loss: 0.0466

类别准确率:
positive: 0.8522 (398/467)
neutral: 0.2771 (23/83)
negative: 0.6400 (160/250)

Epoch 6/10
Train Loss: 0.0589, Train Acc: 0.9859
Val Loss: 0.7394, Val Acc: 0.7262
Early stopping triggered!
Best validation accuracy: 0.7400

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_110748-c89db64o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.25_Multimodal_iterations_20250118_110746
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/c89db64o
wandb: uploading history steps 105-106, summary, console lines 1310-1339; uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████
wandb:  train_acc ▁▂▂▅▄▇▅▆▅▇▇▇▇▇██▇▇█▇▇███▇███████████████
wandb: train_loss █▇▇▆▄▇▆▃▃▄▂▃▂▁▁▂▁▁▃▂▂▂▁▁▁▄▂▁▂▁▁▁▁▁▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1030
wandb:  train_acc 1
wandb: train_loss 0.04107
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.25_Multimodal_iterations_20250118_110746 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/c89db64o
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_110748-c89db64o/logs
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_111708-kwo74rhu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.25_Multimodal_epochs_20250118_111708
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/kwo74rhu
wandb: uploading summary; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▄▅▇█
wandb:  train_acc ▁▅▇███
wandb: train_loss █▄▂▂▁▁
wandb:    val_acc ▃▁█▄▄▆
wandb:   val_loss ▁▂▂█▃▄
wandb: 
wandb: Run summary:
wandb:      epoch 6
wandb:  train_acc 0.98586
wandb: train_loss 0.0589
wandb:    val_acc 0.72625
wandb:   val_loss 0.73944
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.25_Multimodal_epochs_20250118_111708 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/kwo74rhu
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_111708-kwo74rhu/logs

