=== 命令 ===
python main.py --loss_type focal --alpha 0.75 --beta 0.25 --neural_init_weight 1.0 --dropout 0.2 --name loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.2 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.2
text_dim: 128
image_dim: 256
dropout: 0.2
loss_type: focal
alpha: 0.75
beta: 0.25
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6766, log_difficulty=0.5168, weight=3.5838
neutral: count=7.0, difficulty=0.6573, log_difficulty=0.5052, weight=3.5259
negative: count=13.0, difficulty=0.6502, log_difficulty=0.5009, weight=3.5045

当前batch的pt分布：
positive: min=0.1813, max=0.4268, mean=0.3234
neutral: min=0.2183, max=0.5200, mean=0.3427
negative: min=0.2406, max=0.4405, mean=0.3498

当前batch准确率：
整体准确率: 0.3750
positive 准确率: 0.3333
neutral 准确率: 0.2857
negative 准确率: 0.4615

损失分量：
基础交叉熵: 1.1071
焦点损失: 0.3497
边界损失: 0.8542
总损失: 1.1425
Epoch 1 [1/172] - loss: 1.1425, acc: 0.3750
Epoch 1 [2/172] - loss: 1.2297
Epoch 1 [3/172] - loss: 1.1416
Epoch 1 [4/172] - loss: 1.1627
Epoch 1 [5/172] - loss: 0.9752
Epoch 1 [6/172] - loss: 1.5092
Epoch 1 [7/172] - loss: 1.2480
Epoch 1 [8/172] - loss: 1.2643
Epoch 1 [9/172] - loss: 1.1025
Epoch 1 [10/172] - loss: 1.3412, acc: 0.3750
Epoch 1 [11/172] - loss: 1.1774
Epoch 1 [12/172] - loss: 1.0048
Epoch 1 [13/172] - loss: 1.0623
Epoch 1 [14/172] - loss: 1.3229
Epoch 1 [15/172] - loss: 1.1108
Epoch 1 [16/172] - loss: 1.1217
Epoch 1 [17/172] - loss: 1.2386
Epoch 1 [18/172] - loss: 1.3074
Epoch 1 [19/172] - loss: 1.0438
Epoch 1 [20/172] - loss: 1.1766, acc: 0.3438
Epoch 1 [21/172] - loss: 1.1329
Epoch 1 [22/172] - loss: 0.8684
Epoch 1 [23/172] - loss: 1.1043
Epoch 1 [24/172] - loss: 1.2317
Epoch 1 [25/172] - loss: 1.1330
Epoch 1 [26/172] - loss: 1.2505
Epoch 1 [27/172] - loss: 1.0430
Epoch 1 [28/172] - loss: 0.9035
Epoch 1 [29/172] - loss: 1.1548
Epoch 1 [30/172] - loss: 0.9162, acc: 0.5938
Epoch 1 [31/172] - loss: 1.0287
Epoch 1 [32/172] - loss: 0.9312
Epoch 1 [33/172] - loss: 0.9488
Epoch 1 [34/172] - loss: 1.0958
Epoch 1 [35/172] - loss: 1.0019
Epoch 1 [36/172] - loss: 0.9581
Epoch 1 [37/172] - loss: 0.9651
Epoch 1 [38/172] - loss: 1.0460
Epoch 1 [39/172] - loss: 0.7634
Epoch 1 [40/172] - loss: 0.9210, acc: 0.6250
Epoch 1 [41/172] - loss: 0.8668
Epoch 1 [42/172] - loss: 0.7628
Epoch 1 [43/172] - loss: 0.8960
Epoch 1 [44/172] - loss: 0.9562
Epoch 1 [45/172] - loss: 1.1089
Epoch 1 [46/172] - loss: 0.8814
Epoch 1 [47/172] - loss: 1.0292
Epoch 1 [48/172] - loss: 0.7146
Epoch 1 [49/172] - loss: 1.1242
Epoch 1 [50/172] - loss: 0.8362, acc: 0.5000
Epoch 1 [51/172] - loss: 0.8009
Epoch 1 [52/172] - loss: 0.9092
Epoch 1 [53/172] - loss: 1.4159
Epoch 1 [54/172] - loss: 1.0263
Epoch 1 [55/172] - loss: 0.7170
Epoch 1 [56/172] - loss: 0.7900
Epoch 1 [57/172] - loss: 1.0384
Epoch 1 [58/172] - loss: 0.8703
Epoch 1 [59/172] - loss: 1.0300
Epoch 1 [60/172] - loss: 0.6962, acc: 0.6875
Epoch 1 [61/172] - loss: 0.8821
Epoch 1 [62/172] - loss: 0.9347
Epoch 1 [63/172] - loss: 0.9279
Epoch 1 [64/172] - loss: 0.6388
Epoch 1 [65/172] - loss: 0.9071
Epoch 1 [66/172] - loss: 0.7951
Epoch 1 [67/172] - loss: 0.7306
Epoch 1 [68/172] - loss: 0.9248
Epoch 1 [69/172] - loss: 0.9548
Epoch 1 [70/172] - loss: 0.7583, acc: 0.6250
Epoch 1 [71/172] - loss: 0.5172
Epoch 1 [72/172] - loss: 0.7322
Epoch 1 [73/172] - loss: 1.0072
Epoch 1 [74/172] - loss: 0.7064
Epoch 1 [75/172] - loss: 0.4616
Epoch 1 [76/172] - loss: 0.6683
Epoch 1 [77/172] - loss: 0.9038
Epoch 1 [78/172] - loss: 0.8310
Epoch 1 [79/172] - loss: 0.8078
Epoch 1 [80/172] - loss: 0.6642, acc: 0.7500
Epoch 1 [81/172] - loss: 0.6981
Epoch 1 [82/172] - loss: 1.0086
Epoch 1 [83/172] - loss: 0.8622
Epoch 1 [84/172] - loss: 0.5641
Epoch 1 [85/172] - loss: 0.5983
Epoch 1 [86/172] - loss: 0.8642
Epoch 1 [87/172] - loss: 0.6702
Epoch 1 [88/172] - loss: 1.1101
Epoch 1 [89/172] - loss: 0.8381
Epoch 1 [90/172] - loss: 0.7542, acc: 0.6562
Epoch 1 [91/172] - loss: 0.7475
Epoch 1 [92/172] - loss: 0.7803
Epoch 1 [93/172] - loss: 0.6549
Epoch 1 [94/172] - loss: 0.4619
Epoch 1 [95/172] - loss: 0.5187
Epoch 1 [96/172] - loss: 0.7831
Epoch 1 [97/172] - loss: 0.6235
Epoch 1 [98/172] - loss: 0.5771
Epoch 1 [99/172] - loss: 0.7696
Epoch 1 [100/172] - loss: 0.8076, acc: 0.7188

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5822, log_difficulty=0.4588, weight=3.2941
neutral: count=983.0, difficulty=0.5585, log_difficulty=0.4437, weight=3.2187
negative: count=1119.0, difficulty=0.5688, log_difficulty=0.4503, weight=3.2515

当前batch的pt分布：
positive: min=0.1036, max=0.8065, mean=0.4470
neutral: min=0.4907, max=0.9559, mean=0.7464
negative: min=0.1174, max=0.6927, mean=0.3922

当前batch准确率：
整体准确率: 0.5625
positive 准确率: 0.5833
neutral 准确率: 1.0000
negative 准确率: 0.4375

损失分量：
基础交叉熵: 0.9149
焦点损失: 0.3359
边界损失: 0.5228
总损失: 0.9535
Epoch 1 [101/172] - loss: 0.9535
Epoch 1 [102/172] - loss: 0.5893
Epoch 1 [103/172] - loss: 0.5284
Epoch 1 [104/172] - loss: 0.4106
Epoch 1 [105/172] - loss: 0.8345
Epoch 1 [106/172] - loss: 1.0495
Epoch 1 [107/172] - loss: 0.6249
Epoch 1 [108/172] - loss: 0.9571
Epoch 1 [109/172] - loss: 0.6462
Epoch 1 [110/172] - loss: 0.7605, acc: 0.6250
Epoch 1 [111/172] - loss: 0.9464
Epoch 1 [112/172] - loss: 0.6898
Epoch 1 [113/172] - loss: 0.4799
Epoch 1 [114/172] - loss: 0.6364
Epoch 1 [115/172] - loss: 0.5788
Epoch 1 [116/172] - loss: 0.8338
Epoch 1 [117/172] - loss: 0.6710
Epoch 1 [118/172] - loss: 0.4521
Epoch 1 [119/172] - loss: 0.6963
Epoch 1 [120/172] - loss: 0.3678, acc: 0.8125
Epoch 1 [121/172] - loss: 0.4795
Epoch 1 [122/172] - loss: 0.7289
Epoch 1 [123/172] - loss: 0.3526
Epoch 1 [124/172] - loss: 0.6012
Epoch 1 [125/172] - loss: 0.7496
Epoch 1 [126/172] - loss: 0.6601
Epoch 1 [127/172] - loss: 0.5493
Epoch 1 [128/172] - loss: 0.3891
Epoch 1 [129/172] - loss: 0.7559
Epoch 1 [130/172] - loss: 0.5177, acc: 0.6875
Epoch 1 [131/172] - loss: 0.2835
Epoch 1 [132/172] - loss: 0.6610
Epoch 1 [133/172] - loss: 0.7545
Epoch 1 [134/172] - loss: 0.3668
Epoch 1 [135/172] - loss: 0.6746
Epoch 1 [136/172] - loss: 0.7070
Epoch 1 [137/172] - loss: 0.5730
Epoch 1 [138/172] - loss: 0.5163
Epoch 1 [139/172] - loss: 0.4719
Epoch 1 [140/172] - loss: 0.3598, acc: 0.8125
Epoch 1 [141/172] - loss: 0.4508
Epoch 1 [142/172] - loss: 0.3669
Epoch 1 [143/172] - loss: 0.6089
Epoch 1 [144/172] - loss: 0.4268
Epoch 1 [145/172] - loss: 0.6356
Epoch 1 [146/172] - loss: 0.8595
Epoch 1 [147/172] - loss: 0.8946
Epoch 1 [148/172] - loss: 0.5133
Epoch 1 [149/172] - loss: 0.4121
Epoch 1 [150/172] - loss: 0.5620, acc: 0.6562
Epoch 1 [151/172] - loss: 0.7677
Epoch 1 [152/172] - loss: 0.5572
Epoch 1 [153/172] - loss: 0.5202
Epoch 1 [154/172] - loss: 0.4480
Epoch 1 [155/172] - loss: 0.5397
Epoch 1 [156/172] - loss: 0.9428
Epoch 1 [157/172] - loss: 0.7743
Epoch 1 [158/172] - loss: 0.5061
Epoch 1 [159/172] - loss: 0.5437
Epoch 1 [160/172] - loss: 0.4864, acc: 0.8125
Epoch 1 [161/172] - loss: 0.4011
Epoch 1 [162/172] - loss: 0.5512
Epoch 1 [163/172] - loss: 0.4115
Epoch 1 [164/172] - loss: 0.6483
Epoch 1 [165/172] - loss: 0.4538
Epoch 1 [166/172] - loss: 0.4412
Epoch 1 [167/172] - loss: 0.4869
Epoch 1 [168/172] - loss: 0.4105
Epoch 1 [169/172] - loss: 0.4017
Epoch 1 [170/172] - loss: 0.4862, acc: 0.8125
Epoch 1 [171/172] - loss: 0.3061
Epoch 1 [172/172] - loss: 0.5012

类别准确率:
positive: 0.6981 (326/467)
neutral: 0.7349 (61/83)
negative: 0.5480 (137/250)

Epoch 1/10
Train Loss: 0.4881, Train Acc: 0.7879
Val Loss: 0.7932, Val Acc: 0.6550
Epoch 2 [1/172] - loss: 0.4126, acc: 0.7812
Epoch 2 [2/172] - loss: 0.3487
Epoch 2 [3/172] - loss: 0.2717
Epoch 2 [4/172] - loss: 0.3146
Epoch 2 [5/172] - loss: 0.4401
Epoch 2 [6/172] - loss: 0.4485
Epoch 2 [7/172] - loss: 0.3116
Epoch 2 [8/172] - loss: 0.4316
Epoch 2 [9/172] - loss: 0.5606
Epoch 2 [10/172] - loss: 0.3705, acc: 0.8438
Epoch 2 [11/172] - loss: 0.2429
Epoch 2 [12/172] - loss: 0.5089
Epoch 2 [13/172] - loss: 0.4103
Epoch 2 [14/172] - loss: 0.2412
Epoch 2 [15/172] - loss: 0.4494
Epoch 2 [16/172] - loss: 0.3989
Epoch 2 [17/172] - loss: 0.3407
Epoch 2 [18/172] - loss: 0.5479
Epoch 2 [19/172] - loss: 0.3949
Epoch 2 [20/172] - loss: 0.3405, acc: 0.8125
Epoch 2 [21/172] - loss: 0.3691
Epoch 2 [22/172] - loss: 0.2338
Epoch 2 [23/172] - loss: 0.1215
Epoch 2 [24/172] - loss: 0.5792
Epoch 2 [25/172] - loss: 0.4598
Epoch 2 [26/172] - loss: 0.2280
Epoch 2 [27/172] - loss: 0.3655
Epoch 2 [28/172] - loss: 0.2710

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5125, log_difficulty=0.4137, weight=3.0687
neutral: count=1952.0, difficulty=0.4614, log_difficulty=0.3794, weight=2.8971
negative: count=2216.0, difficulty=0.5131, log_difficulty=0.4141, weight=3.0707

当前batch的pt分布：
positive: min=0.3285, max=0.9420, mean=0.6480
neutral: min=0.5110, max=0.9515, mean=0.7666
negative: min=0.1495, max=0.8593, mean=0.6100

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8889
neutral 准确率: 1.0000
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.4568
焦点损失: 0.0972
边界损失: 0.3712
总损失: 0.3156
Epoch 2 [29/172] - loss: 0.3156
Epoch 2 [30/172] - loss: 0.3948, acc: 0.9375
Epoch 2 [31/172] - loss: 0.2599
Epoch 2 [32/172] - loss: 0.3290
Epoch 2 [33/172] - loss: 0.2634
Epoch 2 [34/172] - loss: 0.3838
Epoch 2 [35/172] - loss: 0.2720
Epoch 2 [36/172] - loss: 0.5915
Epoch 2 [37/172] - loss: 0.2991
Epoch 2 [38/172] - loss: 0.2793
Epoch 2 [39/172] - loss: 0.5845
Epoch 2 [40/172] - loss: 0.4084, acc: 0.7188
Epoch 2 [41/172] - loss: 0.3431
Epoch 2 [42/172] - loss: 0.2030
Epoch 2 [43/172] - loss: 0.1620
Epoch 2 [44/172] - loss: 0.4950
Epoch 2 [45/172] - loss: 0.2022
Epoch 2 [46/172] - loss: 0.2362
Epoch 2 [47/172] - loss: 0.3855
Epoch 2 [48/172] - loss: 0.3202
Epoch 2 [49/172] - loss: 0.2901
Epoch 2 [50/172] - loss: 0.3025, acc: 0.7812
Epoch 2 [51/172] - loss: 0.2509
Epoch 2 [52/172] - loss: 0.2455
Epoch 2 [53/172] - loss: 0.3201
Epoch 2 [54/172] - loss: 0.2196
Epoch 2 [55/172] - loss: 0.3338
Epoch 2 [56/172] - loss: 0.3758
Epoch 2 [57/172] - loss: 0.3147
Epoch 2 [58/172] - loss: 0.2148
Epoch 2 [59/172] - loss: 0.3909
Epoch 2 [60/172] - loss: 0.2776, acc: 0.8750
Epoch 2 [61/172] - loss: 0.1678
Epoch 2 [62/172] - loss: 0.2238
Epoch 2 [63/172] - loss: 0.3328
Epoch 2 [64/172] - loss: 0.3893
Epoch 2 [65/172] - loss: 0.2693
Epoch 2 [66/172] - loss: 0.2773
Epoch 2 [67/172] - loss: 0.1742
Epoch 2 [68/172] - loss: 0.2462
Epoch 2 [69/172] - loss: 0.1551
Epoch 2 [70/172] - loss: 0.3945, acc: 0.7500
Epoch 2 [71/172] - loss: 0.2875
Epoch 2 [72/172] - loss: 0.3289
Epoch 2 [73/172] - loss: 0.3115
Epoch 2 [74/172] - loss: 0.3597
Epoch 2 [75/172] - loss: 0.2374
Epoch 2 [76/172] - loss: 0.2703
Epoch 2 [77/172] - loss: 0.2895
Epoch 2 [78/172] - loss: 0.3861
Epoch 2 [79/172] - loss: 0.2690
Epoch 2 [80/172] - loss: 0.2634, acc: 0.9062
Epoch 2 [81/172] - loss: 0.2136
Epoch 2 [82/172] - loss: 0.1387
Epoch 2 [83/172] - loss: 0.2470
Epoch 2 [84/172] - loss: 0.2104
Epoch 2 [85/172] - loss: 0.2155
Epoch 2 [86/172] - loss: 0.2592
Epoch 2 [87/172] - loss: 0.8986
Epoch 2 [88/172] - loss: 0.3323
Epoch 2 [89/172] - loss: 0.1015
Epoch 2 [90/172] - loss: 0.2847, acc: 0.8125
Epoch 2 [91/172] - loss: 0.1105
Epoch 2 [92/172] - loss: 0.2697
Epoch 2 [93/172] - loss: 0.1829
Epoch 2 [94/172] - loss: 0.2272
Epoch 2 [95/172] - loss: 0.4023
Epoch 2 [96/172] - loss: 0.1763
Epoch 2 [97/172] - loss: 0.1904
Epoch 2 [98/172] - loss: 0.1844
Epoch 2 [99/172] - loss: 0.1731
Epoch 2 [100/172] - loss: 0.1656, acc: 0.9375
Epoch 2 [101/172] - loss: 0.1590
Epoch 2 [102/172] - loss: 0.1637
Epoch 2 [103/172] - loss: 0.3167
Epoch 2 [104/172] - loss: 0.3170
Epoch 2 [105/172] - loss: 0.1697
Epoch 2 [106/172] - loss: 0.1588
Epoch 2 [107/172] - loss: 0.2734
Epoch 2 [108/172] - loss: 0.3975
Epoch 2 [109/172] - loss: 0.2864
Epoch 2 [110/172] - loss: 0.3088, acc: 0.8125
Epoch 2 [111/172] - loss: 0.1117
Epoch 2 [112/172] - loss: 0.1830
Epoch 2 [113/172] - loss: 0.1348
Epoch 2 [114/172] - loss: 0.1969
Epoch 2 [115/172] - loss: 0.3017
Epoch 2 [116/172] - loss: 0.4552
Epoch 2 [117/172] - loss: 0.5348
Epoch 2 [118/172] - loss: 0.1562
Epoch 2 [119/172] - loss: 0.1495
Epoch 2 [120/172] - loss: 0.2409, acc: 0.9062
Epoch 2 [121/172] - loss: 0.1692
Epoch 2 [122/172] - loss: 0.4559
Epoch 2 [123/172] - loss: 0.2349
Epoch 2 [124/172] - loss: 0.2867
Epoch 2 [125/172] - loss: 0.1417
Epoch 2 [126/172] - loss: 0.1977
Epoch 2 [127/172] - loss: 0.1228
Epoch 2 [128/172] - loss: 0.1952

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4546, log_difficulty=0.3747, weight=2.8737
neutral: count=2949.0, difficulty=0.3708, log_difficulty=0.3154, weight=2.5769
negative: count=3294.0, difficulty=0.4560, log_difficulty=0.3757, weight=2.8784

当前batch的pt分布：
positive: min=0.3599, max=0.9414, mean=0.7387
neutral: min=0.4724, max=0.9706, mean=0.7731
negative: min=0.1456, max=0.8958, mean=0.6169

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.7273

损失分量：
基础交叉熵: 0.4151
焦点损失: 0.1019
边界损失: 0.3245
总损失: 0.2984
Epoch 2 [129/172] - loss: 0.2984
Epoch 2 [130/172] - loss: 0.1877, acc: 0.9062
Epoch 2 [131/172] - loss: 0.2319
Epoch 2 [132/172] - loss: 0.3696
Epoch 2 [133/172] - loss: 0.1703
Epoch 2 [134/172] - loss: 0.1962
Epoch 2 [135/172] - loss: 0.6740
Epoch 2 [136/172] - loss: 0.2263
Epoch 2 [137/172] - loss: 0.1467
Epoch 2 [138/172] - loss: 0.1649
Epoch 2 [139/172] - loss: 0.4209
Epoch 2 [140/172] - loss: 0.2731, acc: 0.8438
Epoch 2 [141/172] - loss: 0.2108
Epoch 2 [142/172] - loss: 0.2345
Epoch 2 [143/172] - loss: 0.1809
Epoch 2 [144/172] - loss: 0.1640
Epoch 2 [145/172] - loss: 0.5196
Epoch 2 [146/172] - loss: 0.2155
Epoch 2 [147/172] - loss: 0.2605
Epoch 2 [148/172] - loss: 0.1538
Epoch 2 [149/172] - loss: 0.1657
Epoch 2 [150/172] - loss: 0.1931, acc: 0.9062
Epoch 2 [151/172] - loss: 0.3113
Epoch 2 [152/172] - loss: 0.1233
Epoch 2 [153/172] - loss: 0.2146
Epoch 2 [154/172] - loss: 0.1143
Epoch 2 [155/172] - loss: 0.1578
Epoch 2 [156/172] - loss: 0.1807
Epoch 2 [157/172] - loss: 0.1441
Epoch 2 [158/172] - loss: 0.1659
Epoch 2 [159/172] - loss: 0.1532
Epoch 2 [160/172] - loss: 0.1763, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1540
Epoch 2 [162/172] - loss: 0.1040
Epoch 2 [163/172] - loss: 0.3489
Epoch 2 [164/172] - loss: 0.2779
Epoch 2 [165/172] - loss: 0.4281
Epoch 2 [166/172] - loss: 0.4176
Epoch 2 [167/172] - loss: 0.3638
Epoch 2 [168/172] - loss: 0.1201
Epoch 2 [169/172] - loss: 0.1311
Epoch 2 [170/172] - loss: 0.2160, acc: 0.9062
Epoch 2 [171/172] - loss: 0.2602
Epoch 2 [172/172] - loss: 0.8833

类别准确率:
positive: 0.8608 (402/467)
neutral: 0.2530 (21/83)
negative: 0.6560 (164/250)

Epoch 2/10
Train Loss: 0.2715, Train Acc: 0.9071
Val Loss: 0.6444, Val Acc: 0.7338
Epoch 3 [1/172] - loss: 0.1346, acc: 0.9375
Epoch 3 [2/172] - loss: 0.1547
Epoch 3 [3/172] - loss: 0.0825
Epoch 3 [4/172] - loss: 0.1124
Epoch 3 [5/172] - loss: 0.1534
Epoch 3 [6/172] - loss: 0.1069
Epoch 3 [7/172] - loss: 0.1021
Epoch 3 [8/172] - loss: 0.1690
Epoch 3 [9/172] - loss: 0.1434
Epoch 3 [10/172] - loss: 0.1017, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1714
Epoch 3 [12/172] - loss: 0.0893
Epoch 3 [13/172] - loss: 0.1394
Epoch 3 [14/172] - loss: 0.0677
Epoch 3 [15/172] - loss: 0.0848
Epoch 3 [16/172] - loss: 0.3139
Epoch 3 [17/172] - loss: 0.1371
Epoch 3 [18/172] - loss: 0.1820
Epoch 3 [19/172] - loss: 0.0849
Epoch 3 [20/172] - loss: 0.1181, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1318
Epoch 3 [22/172] - loss: 0.3193
Epoch 3 [23/172] - loss: 0.1035
Epoch 3 [24/172] - loss: 0.0944
Epoch 3 [25/172] - loss: 0.1836
Epoch 3 [26/172] - loss: 0.0867
Epoch 3 [27/172] - loss: 0.1259
Epoch 3 [28/172] - loss: 0.0822
Epoch 3 [29/172] - loss: 0.1837
Epoch 3 [30/172] - loss: 0.1468, acc: 0.9062
Epoch 3 [31/172] - loss: 0.1150
Epoch 3 [32/172] - loss: 0.1120
Epoch 3 [33/172] - loss: 0.1805
Epoch 3 [34/172] - loss: 0.1184
Epoch 3 [35/172] - loss: 0.1864
Epoch 3 [36/172] - loss: 0.1035
Epoch 3 [37/172] - loss: 0.1380
Epoch 3 [38/172] - loss: 0.0835
Epoch 3 [39/172] - loss: 0.0737
Epoch 3 [40/172] - loss: 0.0914, acc: 1.0000
Epoch 3 [41/172] - loss: 0.0844
Epoch 3 [42/172] - loss: 0.0962
Epoch 3 [43/172] - loss: 0.0796
Epoch 3 [44/172] - loss: 0.0633
Epoch 3 [45/172] - loss: 0.1742
Epoch 3 [46/172] - loss: 0.1281
Epoch 3 [47/172] - loss: 0.0642
Epoch 3 [48/172] - loss: 0.1198
Epoch 3 [49/172] - loss: 0.0934
Epoch 3 [50/172] - loss: 0.1268, acc: 0.9688
Epoch 3 [51/172] - loss: 0.0890
Epoch 3 [52/172] - loss: 0.2404
Epoch 3 [53/172] - loss: 0.0917
Epoch 3 [54/172] - loss: 0.0988
Epoch 3 [55/172] - loss: 0.0680
Epoch 3 [56/172] - loss: 0.1397

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.4026, log_difficulty=0.3383, weight=2.6915
neutral: count=3923.0, difficulty=0.3204, log_difficulty=0.2779, weight=2.3895
negative: count=4382.0, difficulty=0.4012, log_difficulty=0.3373, weight=2.6866

当前batch的pt分布：
positive: min=0.3085, max=0.9824, mean=0.7757
neutral: min=0.0149, max=0.9554, mean=0.7228
negative: min=0.8972, max=0.9859, mean=0.9512

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9091
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3776
焦点损失: 0.1642
边界损失: 0.2539
总损失: 0.3618
Epoch 3 [57/172] - loss: 0.3618
Epoch 3 [58/172] - loss: 0.0950
Epoch 3 [59/172] - loss: 0.0877
Epoch 3 [60/172] - loss: 0.1133, acc: 0.9375
Epoch 3 [61/172] - loss: 0.0772
Epoch 3 [62/172] - loss: 0.0828
Epoch 3 [63/172] - loss: 0.0884
Epoch 3 [64/172] - loss: 0.1320
Epoch 3 [65/172] - loss: 0.1331
Epoch 3 [66/172] - loss: 0.1612
Epoch 3 [67/172] - loss: 0.0856
Epoch 3 [68/172] - loss: 0.0790
Epoch 3 [69/172] - loss: 0.1559
Epoch 3 [70/172] - loss: 0.0657, acc: 1.0000
Epoch 3 [71/172] - loss: 0.0942
Epoch 3 [72/172] - loss: 0.1974
Epoch 3 [73/172] - loss: 0.0715
Epoch 3 [74/172] - loss: 0.1090
Epoch 3 [75/172] - loss: 0.1093
Epoch 3 [76/172] - loss: 0.0546
Epoch 3 [77/172] - loss: 0.0749
Epoch 3 [78/172] - loss: 0.2058
Epoch 3 [79/172] - loss: 0.1344
Epoch 3 [80/172] - loss: 0.2835, acc: 0.9375
Epoch 3 [81/172] - loss: 0.0889
Epoch 3 [82/172] - loss: 0.1066
Epoch 3 [83/172] - loss: 0.0729
Epoch 3 [84/172] - loss: 0.0725
Epoch 3 [85/172] - loss: 0.0799
Epoch 3 [86/172] - loss: 0.0946
Epoch 3 [87/172] - loss: 0.1307
Epoch 3 [88/172] - loss: 0.1214
Epoch 3 [89/172] - loss: 0.0863
Epoch 3 [90/172] - loss: 0.0604, acc: 1.0000
Epoch 3 [91/172] - loss: 0.0739
Epoch 3 [92/172] - loss: 0.1211
Epoch 3 [93/172] - loss: 0.1702
Epoch 3 [94/172] - loss: 0.1091
Epoch 3 [95/172] - loss: 0.0941
Epoch 3 [96/172] - loss: 0.1627
Epoch 3 [97/172] - loss: 0.1111
Epoch 3 [98/172] - loss: 0.2235
Epoch 3 [99/172] - loss: 0.0651
Epoch 3 [100/172] - loss: 0.0962, acc: 0.9688
Epoch 3 [101/172] - loss: 0.2084
Epoch 3 [102/172] - loss: 0.0489
Epoch 3 [103/172] - loss: 0.2622
Epoch 3 [104/172] - loss: 0.1638
Epoch 3 [105/172] - loss: 0.0616
Epoch 3 [106/172] - loss: 0.0699
Epoch 3 [107/172] - loss: 0.1585
Epoch 3 [108/172] - loss: 0.0748
Epoch 3 [109/172] - loss: 0.0674
Epoch 3 [110/172] - loss: 0.1538, acc: 0.9375
Epoch 3 [111/172] - loss: 0.0768
Epoch 3 [112/172] - loss: 0.0866
Epoch 3 [113/172] - loss: 0.0704
Epoch 3 [114/172] - loss: 0.1075
Epoch 3 [115/172] - loss: 0.2360
Epoch 3 [116/172] - loss: 0.0894
Epoch 3 [117/172] - loss: 0.2038
Epoch 3 [118/172] - loss: 0.1233
Epoch 3 [119/172] - loss: 0.0946
Epoch 3 [120/172] - loss: 0.1945, acc: 0.9688
Epoch 3 [121/172] - loss: 0.2148
Epoch 3 [122/172] - loss: 0.1018
Epoch 3 [123/172] - loss: 0.0758
Epoch 3 [124/172] - loss: 0.0896
Epoch 3 [125/172] - loss: 0.0588
Epoch 3 [126/172] - loss: 0.2111
Epoch 3 [127/172] - loss: 0.1936
Epoch 3 [128/172] - loss: 0.0584
Epoch 3 [129/172] - loss: 0.0703
Epoch 3 [130/172] - loss: 0.0656, acc: 1.0000
Epoch 3 [131/172] - loss: 0.2387
Epoch 3 [132/172] - loss: 0.0757
Epoch 3 [133/172] - loss: 0.1334
Epoch 3 [134/172] - loss: 0.0577
Epoch 3 [135/172] - loss: 0.0816
Epoch 3 [136/172] - loss: 0.0924
Epoch 3 [137/172] - loss: 0.0655
Epoch 3 [138/172] - loss: 0.0713
Epoch 3 [139/172] - loss: 0.0676
Epoch 3 [140/172] - loss: 0.1765, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1348
Epoch 3 [142/172] - loss: 0.2158
Epoch 3 [143/172] - loss: 0.0652
Epoch 3 [144/172] - loss: 0.1406
Epoch 3 [145/172] - loss: 0.1091
Epoch 3 [146/172] - loss: 0.0986
Epoch 3 [147/172] - loss: 0.1103
Epoch 3 [148/172] - loss: 0.0850
Epoch 3 [149/172] - loss: 0.1180
Epoch 3 [150/172] - loss: 0.0813, acc: 0.9688
Epoch 3 [151/172] - loss: 0.1997
Epoch 3 [152/172] - loss: 0.2877
Epoch 3 [153/172] - loss: 0.1419
Epoch 3 [154/172] - loss: 0.1619
Epoch 3 [155/172] - loss: 0.0651
Epoch 3 [156/172] - loss: 0.1074

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3557, log_difficulty=0.3043, weight=2.5214
neutral: count=4903.0, difficulty=0.2804, log_difficulty=0.2472, weight=2.2360
negative: count=5500.0, difficulty=0.3550, log_difficulty=0.3038, weight=2.5189

当前batch的pt分布：
positive: min=0.7176, max=0.9804, mean=0.8852
neutral: min=0.8696, max=0.9762, mean=0.9357
negative: min=0.1308, max=0.9636, mean=0.7477

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8000

损失分量：
基础交叉熵: 0.2029
焦点损失: 0.0662
边界损失: 0.1997
总损失: 0.1749
Epoch 3 [157/172] - loss: 0.1749
Epoch 3 [158/172] - loss: 0.3578
Epoch 3 [159/172] - loss: 0.1208
Epoch 3 [160/172] - loss: 0.2220, acc: 0.8750
Epoch 3 [161/172] - loss: 0.1099
Epoch 3 [162/172] - loss: 0.1156
Epoch 3 [163/172] - loss: 0.1263
Epoch 3 [164/172] - loss: 0.0615
Epoch 3 [165/172] - loss: 0.0869
Epoch 3 [166/172] - loss: 0.0846
Epoch 3 [167/172] - loss: 0.0639
Epoch 3 [168/172] - loss: 0.0644
Epoch 3 [169/172] - loss: 0.0574
Epoch 3 [170/172] - loss: 0.1221, acc: 0.9688
Epoch 3 [171/172] - loss: 0.2121
Epoch 3 [172/172] - loss: 0.0706

类别准确率:
positive: 0.8351 (390/467)
neutral: 0.2892 (24/83)
negative: 0.6920 (173/250)

Epoch 3/10
Train Loss: 0.1282, Train Acc: 0.9475
Val Loss: 0.7009, Val Acc: 0.7338
Epoch 4 [1/172] - loss: 0.0687, acc: 1.0000
Epoch 4 [2/172] - loss: 0.0711
Epoch 4 [3/172] - loss: 0.0649
Epoch 4 [4/172] - loss: 0.0952
Epoch 4 [5/172] - loss: 0.1431
Epoch 4 [6/172] - loss: 0.0478
Epoch 4 [7/172] - loss: 0.0842
Epoch 4 [8/172] - loss: 0.0600
Epoch 4 [9/172] - loss: 0.0828
Epoch 4 [10/172] - loss: 0.0745, acc: 0.9688
Epoch 4 [11/172] - loss: 0.1047
Epoch 4 [12/172] - loss: 0.1014
Epoch 4 [13/172] - loss: 0.0982
Epoch 4 [14/172] - loss: 0.1294
Epoch 4 [15/172] - loss: 0.0712
Epoch 4 [16/172] - loss: 0.0569
Epoch 4 [17/172] - loss: 0.0633
Epoch 4 [18/172] - loss: 0.0741
Epoch 4 [19/172] - loss: 0.0559
Epoch 4 [20/172] - loss: 0.1766, acc: 0.9375
Epoch 4 [21/172] - loss: 0.1032
Epoch 4 [22/172] - loss: 0.1260
Epoch 4 [23/172] - loss: 0.0853
Epoch 4 [24/172] - loss: 0.0620
Epoch 4 [25/172] - loss: 0.0504
Epoch 4 [26/172] - loss: 0.3253
Epoch 4 [27/172] - loss: 0.0503
Epoch 4 [28/172] - loss: 0.1094
Epoch 4 [29/172] - loss: 0.0432
Epoch 4 [30/172] - loss: 0.0748, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1029
Epoch 4 [32/172] - loss: 0.1413
Epoch 4 [33/172] - loss: 0.0496
Epoch 4 [34/172] - loss: 0.0588
Epoch 4 [35/172] - loss: 0.0745
Epoch 4 [36/172] - loss: 0.0849
Epoch 4 [37/172] - loss: 0.0500
Epoch 4 [38/172] - loss: 0.0551
Epoch 4 [39/172] - loss: 0.1142
Epoch 4 [40/172] - loss: 0.1101, acc: 0.9688
Epoch 4 [41/172] - loss: 0.0562
Epoch 4 [42/172] - loss: 0.0874
Epoch 4 [43/172] - loss: 0.0911
Epoch 4 [44/172] - loss: 0.0743
Epoch 4 [45/172] - loss: 0.0508
Epoch 4 [46/172] - loss: 0.0574
Epoch 4 [47/172] - loss: 0.2075
Epoch 4 [48/172] - loss: 0.0567
Epoch 4 [49/172] - loss: 0.0865
Epoch 4 [50/172] - loss: 0.1837, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0577
Epoch 4 [52/172] - loss: 0.1017
Epoch 4 [53/172] - loss: 0.0526
Epoch 4 [54/172] - loss: 0.1058
Epoch 4 [55/172] - loss: 0.2329
Epoch 4 [56/172] - loss: 0.0731
Epoch 4 [57/172] - loss: 0.0684
Epoch 4 [58/172] - loss: 0.0482
Epoch 4 [59/172] - loss: 0.0555
Epoch 4 [60/172] - loss: 0.0640, acc: 0.9688
Epoch 4 [61/172] - loss: 0.0609
Epoch 4 [62/172] - loss: 0.0727
Epoch 4 [63/172] - loss: 0.0835
Epoch 4 [64/172] - loss: 0.0549
Epoch 4 [65/172] - loss: 0.2661
Epoch 4 [66/172] - loss: 0.0549
Epoch 4 [67/172] - loss: 0.0926
Epoch 4 [68/172] - loss: 0.0777
Epoch 4 [69/172] - loss: 0.0618
Epoch 4 [70/172] - loss: 0.0529, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1016
Epoch 4 [72/172] - loss: 0.0681
Epoch 4 [73/172] - loss: 0.0627
Epoch 4 [74/172] - loss: 0.2490
Epoch 4 [75/172] - loss: 0.0564
Epoch 4 [76/172] - loss: 0.0453
Epoch 4 [77/172] - loss: 0.0781
Epoch 4 [78/172] - loss: 0.0516
Epoch 4 [79/172] - loss: 0.0655
Epoch 4 [80/172] - loss: 0.0598, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1746
Epoch 4 [82/172] - loss: 0.0537
Epoch 4 [83/172] - loss: 0.0445
Epoch 4 [84/172] - loss: 0.0605

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3211, log_difficulty=0.2784, weight=2.3922
neutral: count=5865.0, difficulty=0.2499, log_difficulty=0.2230, weight=2.1152
negative: count=6629.0, difficulty=0.3189, log_difficulty=0.2768, weight=2.3839

当前batch的pt分布：
positive: min=0.5245, max=0.9728, mean=0.8550
neutral: min=0.5063, max=0.9964, mean=0.9182
negative: min=0.7033, max=0.9765, mean=0.9249

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1297
焦点损失: 0.0098
边界损失: 0.1999
总损失: 0.0665
Epoch 4 [85/172] - loss: 0.0665
Epoch 4 [86/172] - loss: 0.0764
Epoch 4 [87/172] - loss: 0.0765
Epoch 4 [88/172] - loss: 0.0567
Epoch 4 [89/172] - loss: 0.0465
Epoch 4 [90/172] - loss: 0.0812, acc: 0.9688
Epoch 4 [91/172] - loss: 0.1076
Epoch 4 [92/172] - loss: 0.1702
Epoch 4 [93/172] - loss: 0.0446
Epoch 4 [94/172] - loss: 0.0511
Epoch 4 [95/172] - loss: 0.1476
Epoch 4 [96/172] - loss: 0.1407
Epoch 4 [97/172] - loss: 0.0593
Epoch 4 [98/172] - loss: 0.0474
Epoch 4 [99/172] - loss: 0.0614
Epoch 4 [100/172] - loss: 0.0612, acc: 0.9688
Epoch 4 [101/172] - loss: 0.0730
Epoch 4 [102/172] - loss: 0.0841
Epoch 4 [103/172] - loss: 0.0513
Epoch 4 [104/172] - loss: 0.0460
Epoch 4 [105/172] - loss: 0.0645
Epoch 4 [106/172] - loss: 0.0877
Epoch 4 [107/172] - loss: 0.0471
Epoch 4 [108/172] - loss: 0.0635
Epoch 4 [109/172] - loss: 0.0568
Epoch 4 [110/172] - loss: 0.1483, acc: 0.9375
Epoch 4 [111/172] - loss: 0.0550
Epoch 4 [112/172] - loss: 0.0484
Epoch 4 [113/172] - loss: 0.0539
Epoch 4 [114/172] - loss: 0.0589
Epoch 4 [115/172] - loss: 0.0722
Epoch 4 [116/172] - loss: 0.0847
Epoch 4 [117/172] - loss: 0.0534
Epoch 4 [118/172] - loss: 0.0837
Epoch 4 [119/172] - loss: 0.0657
Epoch 4 [120/172] - loss: 0.0960, acc: 0.9688
Epoch 4 [121/172] - loss: 0.0798
Epoch 4 [122/172] - loss: 0.2444
Epoch 4 [123/172] - loss: 0.0708
Epoch 4 [124/172] - loss: 0.0503
Epoch 4 [125/172] - loss: 0.0561
Epoch 4 [126/172] - loss: 0.1707
Epoch 4 [127/172] - loss: 0.0798
Epoch 4 [128/172] - loss: 0.0459
Epoch 4 [129/172] - loss: 0.0565
Epoch 4 [130/172] - loss: 0.0431, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0427
Epoch 4 [132/172] - loss: 0.0500
Epoch 4 [133/172] - loss: 0.0544
Epoch 4 [134/172] - loss: 0.0678
Epoch 4 [135/172] - loss: 0.0696
Epoch 4 [136/172] - loss: 0.0868
Epoch 4 [137/172] - loss: 0.0589
Epoch 4 [138/172] - loss: 0.0556
Epoch 4 [139/172] - loss: 0.0582
Epoch 4 [140/172] - loss: 0.0499, acc: 1.0000
Epoch 4 [141/172] - loss: 0.0997
Epoch 4 [142/172] - loss: 0.0546
Epoch 4 [143/172] - loss: 0.0520
Epoch 4 [144/172] - loss: 0.0481
Epoch 4 [145/172] - loss: 0.2289
Epoch 4 [146/172] - loss: 0.0538
Epoch 4 [147/172] - loss: 0.0524
Epoch 4 [148/172] - loss: 0.0842
Epoch 4 [149/172] - loss: 0.0544
Epoch 4 [150/172] - loss: 0.0836, acc: 0.9688
Epoch 4 [151/172] - loss: 0.2987
Epoch 4 [152/172] - loss: 0.0441
Epoch 4 [153/172] - loss: 0.0485
Epoch 4 [154/172] - loss: 0.2632
Epoch 4 [155/172] - loss: 0.0537
Epoch 4 [156/172] - loss: 0.0757
Epoch 4 [157/172] - loss: 0.1505
Epoch 4 [158/172] - loss: 0.0426
Epoch 4 [159/172] - loss: 0.0654
Epoch 4 [160/172] - loss: 0.0522, acc: 1.0000
Epoch 4 [161/172] - loss: 0.0827
Epoch 4 [162/172] - loss: 0.0696
Epoch 4 [163/172] - loss: 0.0640
Epoch 4 [164/172] - loss: 0.0524
Epoch 4 [165/172] - loss: 0.1819
Epoch 4 [166/172] - loss: 0.0731
Epoch 4 [167/172] - loss: 0.1255
Epoch 4 [168/172] - loss: 0.0613
Epoch 4 [169/172] - loss: 0.1980
Epoch 4 [170/172] - loss: 0.0773, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0701
Epoch 4 [172/172] - loss: 0.0561

类别准确率:
positive: 0.8137 (380/467)
neutral: 0.1566 (13/83)
negative: 0.7320 (183/250)

Epoch 4/10
Train Loss: 0.0889, Train Acc: 0.9758
Val Loss: 0.7191, Val Acc: 0.7200
Epoch 5 [1/172] - loss: 0.0483, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0595
Epoch 5 [3/172] - loss: 0.0416
Epoch 5 [4/172] - loss: 0.0653
Epoch 5 [5/172] - loss: 0.0469
Epoch 5 [6/172] - loss: 0.0576
Epoch 5 [7/172] - loss: 0.0568
Epoch 5 [8/172] - loss: 0.0572
Epoch 5 [9/172] - loss: 0.1554
Epoch 5 [10/172] - loss: 0.0717, acc: 0.9688
Epoch 5 [11/172] - loss: 0.0707
Epoch 5 [12/172] - loss: 0.0444

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2912, log_difficulty=0.2556, weight=2.2780
neutral: count=6845.0, difficulty=0.2257, log_difficulty=0.2035, weight=2.0176
negative: count=7694.0, difficulty=0.2891, log_difficulty=0.2539, weight=2.2696

当前batch的pt分布：
positive: min=0.3625, max=0.9677, mean=0.8555
neutral: min=0.9568, max=0.9984, mean=0.9813
negative: min=0.8299, max=0.9764, mean=0.9314

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1074
焦点损失: 0.0122
边界损失: 0.1811
总损失: 0.0662
Epoch 5 [13/172] - loss: 0.0662
Epoch 5 [14/172] - loss: 0.1012
Epoch 5 [15/172] - loss: 0.0470
Epoch 5 [16/172] - loss: 0.0454
Epoch 5 [17/172] - loss: 0.0676
Epoch 5 [18/172] - loss: 0.0535
Epoch 5 [19/172] - loss: 0.0658
Epoch 5 [20/172] - loss: 0.0577, acc: 1.0000
Epoch 5 [21/172] - loss: 0.0961
Epoch 5 [22/172] - loss: 0.0908
Epoch 5 [23/172] - loss: 0.0459
Epoch 5 [24/172] - loss: 0.0442
Epoch 5 [25/172] - loss: 0.0465
Epoch 5 [26/172] - loss: 0.0472
Epoch 5 [27/172] - loss: 0.0866
Epoch 5 [28/172] - loss: 0.0444
Epoch 5 [29/172] - loss: 0.0453
Epoch 5 [30/172] - loss: 0.0465, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0498
Epoch 5 [32/172] - loss: 0.0717
Epoch 5 [33/172] - loss: 0.0694
Epoch 5 [34/172] - loss: 0.0524
Epoch 5 [35/172] - loss: 0.0419
Epoch 5 [36/172] - loss: 0.0503
Epoch 5 [37/172] - loss: 0.0481
Epoch 5 [38/172] - loss: 0.0438
Epoch 5 [39/172] - loss: 0.0740
Epoch 5 [40/172] - loss: 0.0534, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0474
Epoch 5 [42/172] - loss: 0.0455
Epoch 5 [43/172] - loss: 0.1728
Epoch 5 [44/172] - loss: 0.0572
Epoch 5 [45/172] - loss: 0.0412
Epoch 5 [46/172] - loss: 0.0734
Epoch 5 [47/172] - loss: 0.0428
Epoch 5 [48/172] - loss: 0.0496
Epoch 5 [49/172] - loss: 0.0433
Epoch 5 [50/172] - loss: 0.1278, acc: 0.9375
Epoch 5 [51/172] - loss: 0.0563
Epoch 5 [52/172] - loss: 0.0450
Epoch 5 [53/172] - loss: 0.0576
Epoch 5 [54/172] - loss: 0.0465
Epoch 5 [55/172] - loss: 0.1075
Epoch 5 [56/172] - loss: 0.0698
Epoch 5 [57/172] - loss: 0.0467
Epoch 5 [58/172] - loss: 0.1130
Epoch 5 [59/172] - loss: 0.0770
Epoch 5 [60/172] - loss: 0.0469, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0478
Epoch 5 [62/172] - loss: 0.0537
Epoch 5 [63/172] - loss: 0.1017
Epoch 5 [64/172] - loss: 0.0562
Epoch 5 [65/172] - loss: 0.0521
Epoch 5 [66/172] - loss: 0.0442
Epoch 5 [67/172] - loss: 0.0559
Epoch 5 [68/172] - loss: 0.0655
Epoch 5 [69/172] - loss: 0.0679
Epoch 5 [70/172] - loss: 0.0446, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0499
Epoch 5 [72/172] - loss: 0.0420
Epoch 5 [73/172] - loss: 0.0512
Epoch 5 [74/172] - loss: 0.0557
Epoch 5 [75/172] - loss: 0.0428
Epoch 5 [76/172] - loss: 0.0475
Epoch 5 [77/172] - loss: 0.0459
Epoch 5 [78/172] - loss: 0.0791
Epoch 5 [79/172] - loss: 0.0441
Epoch 5 [80/172] - loss: 0.0475, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1267
Epoch 5 [82/172] - loss: 0.1172
Epoch 5 [83/172] - loss: 0.0425
Epoch 5 [84/172] - loss: 0.0464
Epoch 5 [85/172] - loss: 0.0694
Epoch 5 [86/172] - loss: 0.0449
Epoch 5 [87/172] - loss: 0.0639
Epoch 5 [88/172] - loss: 0.1057
Epoch 5 [89/172] - loss: 0.0451
Epoch 5 [90/172] - loss: 0.0583, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0692
Epoch 5 [92/172] - loss: 0.0484
Epoch 5 [93/172] - loss: 0.0453
Epoch 5 [94/172] - loss: 0.0478
Epoch 5 [95/172] - loss: 0.0523
Epoch 5 [96/172] - loss: 0.0454
Epoch 5 [97/172] - loss: 0.0614
Epoch 5 [98/172] - loss: 0.0489
Epoch 5 [99/172] - loss: 0.1402
Epoch 5 [100/172] - loss: 0.0475, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0575
Epoch 5 [102/172] - loss: 0.0607
Epoch 5 [103/172] - loss: 0.0533
Epoch 5 [104/172] - loss: 0.1348
Epoch 5 [105/172] - loss: 0.2236
Epoch 5 [106/172] - loss: 0.0500
Epoch 5 [107/172] - loss: 0.0533
Epoch 5 [108/172] - loss: 0.0798
Epoch 5 [109/172] - loss: 0.0436
Epoch 5 [110/172] - loss: 0.0532, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0481
Epoch 5 [112/172] - loss: 0.0431

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2651, log_difficulty=0.2351, weight=2.1756
neutral: count=7825.0, difficulty=0.2070, log_difficulty=0.1882, weight=1.9409
negative: count=8780.0, difficulty=0.2651, log_difficulty=0.2351, weight=2.1756

当前batch的pt分布：
positive: min=0.5950, max=0.9592, mean=0.8695
neutral: min=0.8423, max=0.9823, mean=0.9393
negative: min=0.9861, max=0.9945, mean=0.9903

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0967
焦点损失: 0.0036
边界损失: 0.1854
总损失: 0.0521
Epoch 5 [113/172] - loss: 0.0521
Epoch 5 [114/172] - loss: 0.0569
Epoch 5 [115/172] - loss: 0.0472
Epoch 5 [116/172] - loss: 0.0457
Epoch 5 [117/172] - loss: 0.0566
Epoch 5 [118/172] - loss: 0.0433
Epoch 5 [119/172] - loss: 0.0434
Epoch 5 [120/172] - loss: 0.0522, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0478
Epoch 5 [122/172] - loss: 0.0484
Epoch 5 [123/172] - loss: 0.0565
Epoch 5 [124/172] - loss: 0.0491
Epoch 5 [125/172] - loss: 0.0433
Epoch 5 [126/172] - loss: 0.0449
Epoch 5 [127/172] - loss: 0.0472
Epoch 5 [128/172] - loss: 0.0439
Epoch 5 [129/172] - loss: 0.0743
Epoch 5 [130/172] - loss: 0.0426, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0486
Epoch 5 [132/172] - loss: 0.1051
Epoch 5 [133/172] - loss: 0.0817
Epoch 5 [134/172] - loss: 0.0954
Epoch 5 [135/172] - loss: 0.0417
Epoch 5 [136/172] - loss: 0.0449
Epoch 5 [137/172] - loss: 0.0523
Epoch 5 [138/172] - loss: 0.0932
Epoch 5 [139/172] - loss: 0.1169
Epoch 5 [140/172] - loss: 0.0819, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0444
Epoch 5 [142/172] - loss: 0.0493
Epoch 5 [143/172] - loss: 0.0419
Epoch 5 [144/172] - loss: 0.0415
Epoch 5 [145/172] - loss: 0.0483
Epoch 5 [146/172] - loss: 0.0427
Epoch 5 [147/172] - loss: 0.0570
Epoch 5 [148/172] - loss: 0.0440
Epoch 5 [149/172] - loss: 0.0480
Epoch 5 [150/172] - loss: 0.0743, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0474
Epoch 5 [152/172] - loss: 0.0456
Epoch 5 [153/172] - loss: 0.0498
Epoch 5 [154/172] - loss: 0.0485
Epoch 5 [155/172] - loss: 0.0639
Epoch 5 [156/172] - loss: 0.0513
Epoch 5 [157/172] - loss: 0.0753
Epoch 5 [158/172] - loss: 0.0443
Epoch 5 [159/172] - loss: 0.0423
Epoch 5 [160/172] - loss: 0.0547, acc: 0.9688
Epoch 5 [161/172] - loss: 0.0413
Epoch 5 [162/172] - loss: 0.0744
Epoch 5 [163/172] - loss: 0.1332
Epoch 5 [164/172] - loss: 0.0407
Epoch 5 [165/172] - loss: 0.0975
Epoch 5 [166/172] - loss: 0.0720
Epoch 5 [167/172] - loss: 0.0725
Epoch 5 [168/172] - loss: 0.0415
Epoch 5 [169/172] - loss: 0.0432
Epoch 5 [170/172] - loss: 0.0456, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0446
Epoch 5 [172/172] - loss: 0.0530

类别准确率:
positive: 0.8694 (406/467)
neutral: 0.3133 (26/83)
negative: 0.5880 (147/250)

Epoch 5/10
Train Loss: 0.0610, Train Acc: 0.9859
Val Loss: 0.7206, Val Acc: 0.7238
Early stopping triggered!
Best validation accuracy: 0.7338

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_105954-lst9stne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.2_Multimodal_iterations_20250118_105953
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/lst9stne
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███
wandb:  train_acc ▁▁▄▃▅▄▆▆▅▆▅▇▇▇▇▇▇▇█▇████▇███████████████
wandb: train_loss ▇█▆▅▄▃▄▃▄▃▃▃▃▂▂▂▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 858
wandb:  train_acc 1
wandb: train_loss 0.04563
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.2_Multimodal_iterations_20250118_105953 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/lst9stne
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_105954-lst9stne/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_110735-ptyr666q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.2_Multimodal_epochs_20250118_110735
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/ptyr666q
wandb: uploading summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▃▅▆█
wandb:  train_acc ▁▅▇██
wandb: train_loss █▄▂▁▁
wandb:    val_acc ▁██▇▇
wandb:   val_loss █▁▄▅▅
wandb: 
wandb: Run summary:
wandb:      epoch 5
wandb:  train_acc 0.98586
wandb: train_loss 0.061
wandb:    val_acc 0.72375
wandb:   val_loss 0.72065
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.2_Multimodal_epochs_20250118_110735 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/ptyr666q
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_110735-ptyr666q/logs

