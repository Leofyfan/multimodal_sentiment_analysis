=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 1.5 --dropout 0.2 --name loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.2 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.2
text_dim: 128
image_dim: 256
dropout: 0.2
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6995, log_difficulty=0.5304, weight=3.6518
neutral: count=7.0, difficulty=0.6955, log_difficulty=0.5280, weight=3.6400
negative: count=13.0, difficulty=0.6615, log_difficulty=0.5077, weight=3.5385

当前batch的pt分布：
positive: min=0.1747, max=0.4855, mean=0.3005
neutral: min=0.1570, max=0.4618, mean=0.3045
negative: min=0.1733, max=0.7201, mean=0.3385

当前batch准确率：
整体准确率: 0.2500
positive 准确率: 0.1667
neutral 准确率: 0.2857
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.2026
焦点损失: 0.4443
边界损失: 0.7575
总损失: 1.1799
Epoch 1 [1/172] - loss: 1.1799, acc: 0.2500
Epoch 1 [2/172] - loss: 1.0238
Epoch 1 [3/172] - loss: 1.0521
Epoch 1 [4/172] - loss: 1.0849
Epoch 1 [5/172] - loss: 1.3041
Epoch 1 [6/172] - loss: 1.1453
Epoch 1 [7/172] - loss: 1.0509
Epoch 1 [8/172] - loss: 1.0667
Epoch 1 [9/172] - loss: 0.9221
Epoch 1 [10/172] - loss: 0.9979, acc: 0.4688
Epoch 1 [11/172] - loss: 0.9268
Epoch 1 [12/172] - loss: 1.0419
Epoch 1 [13/172] - loss: 0.9857
Epoch 1 [14/172] - loss: 1.2792
Epoch 1 [15/172] - loss: 1.0439
Epoch 1 [16/172] - loss: 0.9749
Epoch 1 [17/172] - loss: 1.0864
Epoch 1 [18/172] - loss: 0.9229
Epoch 1 [19/172] - loss: 1.1058
Epoch 1 [20/172] - loss: 0.9643, acc: 0.4375
Epoch 1 [21/172] - loss: 0.9095
Epoch 1 [22/172] - loss: 0.9866
Epoch 1 [23/172] - loss: 0.9094
Epoch 1 [24/172] - loss: 1.0554
Epoch 1 [25/172] - loss: 0.9326
Epoch 1 [26/172] - loss: 0.9044
Epoch 1 [27/172] - loss: 0.9410
Epoch 1 [28/172] - loss: 0.8024
Epoch 1 [29/172] - loss: 0.9016
Epoch 1 [30/172] - loss: 0.8913, acc: 0.4688
Epoch 1 [31/172] - loss: 0.8516
Epoch 1 [32/172] - loss: 0.9019
Epoch 1 [33/172] - loss: 0.8105
Epoch 1 [34/172] - loss: 0.6093
Epoch 1 [35/172] - loss: 0.9978
Epoch 1 [36/172] - loss: 0.6200
Epoch 1 [37/172] - loss: 0.8832
Epoch 1 [38/172] - loss: 0.8636
Epoch 1 [39/172] - loss: 0.6410
Epoch 1 [40/172] - loss: 0.8244, acc: 0.6562
Epoch 1 [41/172] - loss: 0.8090
Epoch 1 [42/172] - loss: 0.6010
Epoch 1 [43/172] - loss: 0.7499
Epoch 1 [44/172] - loss: 1.1717
Epoch 1 [45/172] - loss: 1.0037
Epoch 1 [46/172] - loss: 0.7888
Epoch 1 [47/172] - loss: 0.8855
Epoch 1 [48/172] - loss: 0.7093
Epoch 1 [49/172] - loss: 0.8605
Epoch 1 [50/172] - loss: 0.8358, acc: 0.6562
Epoch 1 [51/172] - loss: 0.7452
Epoch 1 [52/172] - loss: 0.8273
Epoch 1 [53/172] - loss: 0.8150
Epoch 1 [54/172] - loss: 0.7298
Epoch 1 [55/172] - loss: 0.6575
Epoch 1 [56/172] - loss: 0.6744
Epoch 1 [57/172] - loss: 0.8358
Epoch 1 [58/172] - loss: 0.6499
Epoch 1 [59/172] - loss: 0.9100
Epoch 1 [60/172] - loss: 0.6178, acc: 0.7500
Epoch 1 [61/172] - loss: 0.8424
Epoch 1 [62/172] - loss: 0.7124
Epoch 1 [63/172] - loss: 0.7414
Epoch 1 [64/172] - loss: 0.4806
Epoch 1 [65/172] - loss: 0.6290
Epoch 1 [66/172] - loss: 0.9028
Epoch 1 [67/172] - loss: 0.7288
Epoch 1 [68/172] - loss: 0.8700
Epoch 1 [69/172] - loss: 0.9361
Epoch 1 [70/172] - loss: 0.7997, acc: 0.6562
Epoch 1 [71/172] - loss: 0.5432
Epoch 1 [72/172] - loss: 0.6840
Epoch 1 [73/172] - loss: 0.7458
Epoch 1 [74/172] - loss: 0.6662
Epoch 1 [75/172] - loss: 0.4605
Epoch 1 [76/172] - loss: 0.6399
Epoch 1 [77/172] - loss: 0.5138
Epoch 1 [78/172] - loss: 0.6562
Epoch 1 [79/172] - loss: 0.8886
Epoch 1 [80/172] - loss: 0.5410, acc: 0.6875
Epoch 1 [81/172] - loss: 0.7864
Epoch 1 [82/172] - loss: 0.8337
Epoch 1 [83/172] - loss: 0.5981
Epoch 1 [84/172] - loss: 0.4711
Epoch 1 [85/172] - loss: 0.5777
Epoch 1 [86/172] - loss: 0.7474
Epoch 1 [87/172] - loss: 0.4639
Epoch 1 [88/172] - loss: 0.7340
Epoch 1 [89/172] - loss: 0.9055
Epoch 1 [90/172] - loss: 0.6538, acc: 0.6562
Epoch 1 [91/172] - loss: 0.5554
Epoch 1 [92/172] - loss: 0.5509
Epoch 1 [93/172] - loss: 0.5611
Epoch 1 [94/172] - loss: 0.5618
Epoch 1 [95/172] - loss: 0.6720
Epoch 1 [96/172] - loss: 0.7503
Epoch 1 [97/172] - loss: 0.6508
Epoch 1 [98/172] - loss: 0.5094
Epoch 1 [99/172] - loss: 0.7492
Epoch 1 [100/172] - loss: 0.8209, acc: 0.6562

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5621, log_difficulty=0.4460, weight=3.2301
neutral: count=983.0, difficulty=0.5501, log_difficulty=0.4383, weight=3.1916
negative: count=1119.0, difficulty=0.5389, log_difficulty=0.4310, weight=3.1552

当前batch的pt分布：
positive: min=0.1680, max=0.9201, mean=0.5011
neutral: min=0.5798, max=0.9519, mean=0.7111
negative: min=0.0955, max=0.8676, mean=0.4293

当前batch准确率：
整体准确率: 0.6562
positive 准确率: 0.5833
neutral 准确率: 1.0000
negative 准确率: 0.6250

损失分量：
基础交叉熵: 0.8507
焦点损失: 0.3136
边界损失: 0.4889
总损失: 0.7429
Epoch 1 [101/172] - loss: 0.7429
Epoch 1 [102/172] - loss: 0.6273
Epoch 1 [103/172] - loss: 0.5960
Epoch 1 [104/172] - loss: 0.4777
Epoch 1 [105/172] - loss: 0.7914
Epoch 1 [106/172] - loss: 0.8410
Epoch 1 [107/172] - loss: 0.5956
Epoch 1 [108/172] - loss: 0.7539
Epoch 1 [109/172] - loss: 0.6670
Epoch 1 [110/172] - loss: 0.7294, acc: 0.6562
Epoch 1 [111/172] - loss: 0.6404
Epoch 1 [112/172] - loss: 0.4523
Epoch 1 [113/172] - loss: 0.4633
Epoch 1 [114/172] - loss: 0.5136
Epoch 1 [115/172] - loss: 0.5375
Epoch 1 [116/172] - loss: 0.5815
Epoch 1 [117/172] - loss: 0.6108
Epoch 1 [118/172] - loss: 0.3305
Epoch 1 [119/172] - loss: 0.4496
Epoch 1 [120/172] - loss: 0.3480, acc: 0.8125
Epoch 1 [121/172] - loss: 0.4554
Epoch 1 [122/172] - loss: 0.7272
Epoch 1 [123/172] - loss: 0.4218
Epoch 1 [124/172] - loss: 0.6058
Epoch 1 [125/172] - loss: 0.4351
Epoch 1 [126/172] - loss: 0.7676
Epoch 1 [127/172] - loss: 0.4281
Epoch 1 [128/172] - loss: 0.3947
Epoch 1 [129/172] - loss: 0.5529
Epoch 1 [130/172] - loss: 0.4696, acc: 0.7188
Epoch 1 [131/172] - loss: 0.3047
Epoch 1 [132/172] - loss: 0.5611
Epoch 1 [133/172] - loss: 0.4751
Epoch 1 [134/172] - loss: 0.4570
Epoch 1 [135/172] - loss: 0.4936
Epoch 1 [136/172] - loss: 0.4573
Epoch 1 [137/172] - loss: 0.4999
Epoch 1 [138/172] - loss: 0.4496
Epoch 1 [139/172] - loss: 0.3582
Epoch 1 [140/172] - loss: 0.3887, acc: 0.7812
Epoch 1 [141/172] - loss: 0.3929
Epoch 1 [142/172] - loss: 0.4827
Epoch 1 [143/172] - loss: 0.3743
Epoch 1 [144/172] - loss: 0.3684
Epoch 1 [145/172] - loss: 0.4708
Epoch 1 [146/172] - loss: 0.5370
Epoch 1 [147/172] - loss: 0.7289
Epoch 1 [148/172] - loss: 0.4159
Epoch 1 [149/172] - loss: 0.3291
Epoch 1 [150/172] - loss: 0.5756, acc: 0.7188
Epoch 1 [151/172] - loss: 0.6367
Epoch 1 [152/172] - loss: 0.4228
Epoch 1 [153/172] - loss: 0.3867
Epoch 1 [154/172] - loss: 0.3617
Epoch 1 [155/172] - loss: 0.4412
Epoch 1 [156/172] - loss: 0.7347
Epoch 1 [157/172] - loss: 0.3689
Epoch 1 [158/172] - loss: 0.3441
Epoch 1 [159/172] - loss: 0.6119
Epoch 1 [160/172] - loss: 0.3841, acc: 0.9062
Epoch 1 [161/172] - loss: 0.3433
Epoch 1 [162/172] - loss: 0.4710
Epoch 1 [163/172] - loss: 0.6198
Epoch 1 [164/172] - loss: 0.5176
Epoch 1 [165/172] - loss: 0.4785
Epoch 1 [166/172] - loss: 0.4063
Epoch 1 [167/172] - loss: 0.4591
Epoch 1 [168/172] - loss: 0.4811
Epoch 1 [169/172] - loss: 0.4778
Epoch 1 [170/172] - loss: 0.3683, acc: 0.9062
Epoch 1 [171/172] - loss: 0.3533
Epoch 1 [172/172] - loss: 0.3610

类别准确率:
positive: 0.5889 (275/467)
neutral: 0.6265 (52/83)
negative: 0.7000 (175/250)

Epoch 1/10
Train Loss: 0.4404, Train Acc: 0.7899
Val Loss: 0.8267, Val Acc: 0.6275
Epoch 2 [1/172] - loss: 0.4216, acc: 0.8438
Epoch 2 [2/172] - loss: 0.2543
Epoch 2 [3/172] - loss: 0.3217
Epoch 2 [4/172] - loss: 0.4808
Epoch 2 [5/172] - loss: 0.5026
Epoch 2 [6/172] - loss: 0.5048
Epoch 2 [7/172] - loss: 0.3027
Epoch 2 [8/172] - loss: 0.3411
Epoch 2 [9/172] - loss: 0.2948
Epoch 2 [10/172] - loss: 0.3108, acc: 0.9062
Epoch 2 [11/172] - loss: 0.2685
Epoch 2 [12/172] - loss: 0.2241
Epoch 2 [13/172] - loss: 0.3605
Epoch 2 [14/172] - loss: 0.3599
Epoch 2 [15/172] - loss: 0.4094
Epoch 2 [16/172] - loss: 0.3652
Epoch 2 [17/172] - loss: 0.4581
Epoch 2 [18/172] - loss: 0.4534
Epoch 2 [19/172] - loss: 0.2765
Epoch 2 [20/172] - loss: 0.3376, acc: 0.8438
Epoch 2 [21/172] - loss: 0.3281
Epoch 2 [22/172] - loss: 0.3192
Epoch 2 [23/172] - loss: 0.2443
Epoch 2 [24/172] - loss: 0.4975
Epoch 2 [25/172] - loss: 0.2856
Epoch 2 [26/172] - loss: 0.1990
Epoch 2 [27/172] - loss: 0.2805
Epoch 2 [28/172] - loss: 0.2705

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4849, log_difficulty=0.3954, weight=2.9768
neutral: count=1952.0, difficulty=0.4270, log_difficulty=0.3556, weight=2.7778
negative: count=2216.0, difficulty=0.4651, log_difficulty=0.3819, weight=2.9096

当前batch的pt分布：
positive: min=0.3850, max=0.9776, mean=0.7093
neutral: min=0.4797, max=0.9726, mean=0.8028
negative: min=0.0631, max=0.9378, mean=0.6657

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8889
neutral 准确率: 1.0000
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.4140
焦点损失: 0.1272
边界损失: 0.2951
总损失: 0.3327
Epoch 2 [29/172] - loss: 0.3327
Epoch 2 [30/172] - loss: 0.4704, acc: 0.9062
Epoch 2 [31/172] - loss: 0.2437
Epoch 2 [32/172] - loss: 0.2601
Epoch 2 [33/172] - loss: 0.3834
Epoch 2 [34/172] - loss: 0.2731
Epoch 2 [35/172] - loss: 0.2795
Epoch 2 [36/172] - loss: 0.4070
Epoch 2 [37/172] - loss: 0.2350
Epoch 2 [38/172] - loss: 0.3570
Epoch 2 [39/172] - loss: 0.3563
Epoch 2 [40/172] - loss: 0.2460, acc: 0.9062
Epoch 2 [41/172] - loss: 0.3941
Epoch 2 [42/172] - loss: 0.2174
Epoch 2 [43/172] - loss: 0.1918
Epoch 2 [44/172] - loss: 0.5813
Epoch 2 [45/172] - loss: 0.2426
Epoch 2 [46/172] - loss: 0.3255
Epoch 2 [47/172] - loss: 0.2663
Epoch 2 [48/172] - loss: 0.2747
Epoch 2 [49/172] - loss: 0.2467
Epoch 2 [50/172] - loss: 0.3201, acc: 0.8750
Epoch 2 [51/172] - loss: 0.3380
Epoch 2 [52/172] - loss: 0.2953
Epoch 2 [53/172] - loss: 0.2877
Epoch 2 [54/172] - loss: 0.2409
Epoch 2 [55/172] - loss: 0.2682
Epoch 2 [56/172] - loss: 0.2555
Epoch 2 [57/172] - loss: 0.1919
Epoch 2 [58/172] - loss: 0.2683
Epoch 2 [59/172] - loss: 0.3990
Epoch 2 [60/172] - loss: 0.2141, acc: 0.8750
Epoch 2 [61/172] - loss: 0.1703
Epoch 2 [62/172] - loss: 0.1803
Epoch 2 [63/172] - loss: 0.3094
Epoch 2 [64/172] - loss: 0.3563
Epoch 2 [65/172] - loss: 0.2685
Epoch 2 [66/172] - loss: 0.1566
Epoch 2 [67/172] - loss: 0.1421
Epoch 2 [68/172] - loss: 0.4298
Epoch 2 [69/172] - loss: 0.1914
Epoch 2 [70/172] - loss: 0.3241, acc: 0.9062
Epoch 2 [71/172] - loss: 0.3722
Epoch 2 [72/172] - loss: 0.3026
Epoch 2 [73/172] - loss: 0.2133
Epoch 2 [74/172] - loss: 0.1909
Epoch 2 [75/172] - loss: 0.1746
Epoch 2 [76/172] - loss: 0.2582
Epoch 2 [77/172] - loss: 0.1933
Epoch 2 [78/172] - loss: 0.3119
Epoch 2 [79/172] - loss: 0.3488
Epoch 2 [80/172] - loss: 0.1460, acc: 0.9688
Epoch 2 [81/172] - loss: 0.1798
Epoch 2 [82/172] - loss: 0.3145
Epoch 2 [83/172] - loss: 0.2375
Epoch 2 [84/172] - loss: 0.3119
Epoch 2 [85/172] - loss: 0.2265
Epoch 2 [86/172] - loss: 0.2873
Epoch 2 [87/172] - loss: 0.5664
Epoch 2 [88/172] - loss: 0.2742
Epoch 2 [89/172] - loss: 0.1426
Epoch 2 [90/172] - loss: 0.2152, acc: 0.9688
Epoch 2 [91/172] - loss: 0.1520
Epoch 2 [92/172] - loss: 0.2605
Epoch 2 [93/172] - loss: 0.2116
Epoch 2 [94/172] - loss: 0.1795
Epoch 2 [95/172] - loss: 0.4328
Epoch 2 [96/172] - loss: 0.1664
Epoch 2 [97/172] - loss: 0.2308
Epoch 2 [98/172] - loss: 0.2738
Epoch 2 [99/172] - loss: 0.2168
Epoch 2 [100/172] - loss: 0.2141, acc: 0.9062
Epoch 2 [101/172] - loss: 0.1734
Epoch 2 [102/172] - loss: 0.1752
Epoch 2 [103/172] - loss: 0.2828
Epoch 2 [104/172] - loss: 0.3204
Epoch 2 [105/172] - loss: 0.2933
Epoch 2 [106/172] - loss: 0.1747
Epoch 2 [107/172] - loss: 0.1577
Epoch 2 [108/172] - loss: 0.2715
Epoch 2 [109/172] - loss: 0.2258
Epoch 2 [110/172] - loss: 0.2553, acc: 0.9062
Epoch 2 [111/172] - loss: 0.1875
Epoch 2 [112/172] - loss: 0.1656
Epoch 2 [113/172] - loss: 0.1801
Epoch 2 [114/172] - loss: 0.1946
Epoch 2 [115/172] - loss: 0.2505
Epoch 2 [116/172] - loss: 0.2195
Epoch 2 [117/172] - loss: 0.3294
Epoch 2 [118/172] - loss: 0.1694
Epoch 2 [119/172] - loss: 0.2089
Epoch 2 [120/172] - loss: 0.2904, acc: 0.9062
Epoch 2 [121/172] - loss: 0.2253
Epoch 2 [122/172] - loss: 0.6421
Epoch 2 [123/172] - loss: 0.1802
Epoch 2 [124/172] - loss: 0.3108
Epoch 2 [125/172] - loss: 0.1467
Epoch 2 [126/172] - loss: 0.1863
Epoch 2 [127/172] - loss: 0.1443
Epoch 2 [128/172] - loss: 0.3509

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4142, log_difficulty=0.3466, weight=2.7328
neutral: count=2949.0, difficulty=0.3361, log_difficulty=0.2897, weight=2.4487
negative: count=3294.0, difficulty=0.3974, log_difficulty=0.3346, weight=2.6730

当前batch的pt分布：
positive: min=0.4396, max=0.9832, mean=0.7914
neutral: min=0.8366, max=0.9813, mean=0.9049
negative: min=0.0504, max=0.9618, mean=0.6798

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.8000
neutral 准确率: 1.0000
negative 准确率: 0.7273

损失分量：
基础交叉熵: 0.3674
焦点损失: 0.1808
边界损失: 0.2267
总损失: 0.3554
Epoch 2 [129/172] - loss: 0.3554
Epoch 2 [130/172] - loss: 0.1636, acc: 1.0000
Epoch 2 [131/172] - loss: 0.2813
Epoch 2 [132/172] - loss: 0.2614
Epoch 2 [133/172] - loss: 0.1765
Epoch 2 [134/172] - loss: 0.2781
Epoch 2 [135/172] - loss: 0.3915
Epoch 2 [136/172] - loss: 0.2724
Epoch 2 [137/172] - loss: 0.1759
Epoch 2 [138/172] - loss: 0.2563
Epoch 2 [139/172] - loss: 0.2141
Epoch 2 [140/172] - loss: 0.3247, acc: 0.8125
Epoch 2 [141/172] - loss: 0.2228
Epoch 2 [142/172] - loss: 0.2001
Epoch 2 [143/172] - loss: 0.2125
Epoch 2 [144/172] - loss: 0.1714
Epoch 2 [145/172] - loss: 0.4231
Epoch 2 [146/172] - loss: 0.1905
Epoch 2 [147/172] - loss: 0.2238
Epoch 2 [148/172] - loss: 0.2006
Epoch 2 [149/172] - loss: 0.1917
Epoch 2 [150/172] - loss: 0.3097, acc: 0.9062
Epoch 2 [151/172] - loss: 0.3391
Epoch 2 [152/172] - loss: 0.2369
Epoch 2 [153/172] - loss: 0.1664
Epoch 2 [154/172] - loss: 0.1499
Epoch 2 [155/172] - loss: 0.2271
Epoch 2 [156/172] - loss: 0.1725
Epoch 2 [157/172] - loss: 0.1311
Epoch 2 [158/172] - loss: 0.3480
Epoch 2 [159/172] - loss: 0.1987
Epoch 2 [160/172] - loss: 0.1946, acc: 0.9062
Epoch 2 [161/172] - loss: 0.1334
Epoch 2 [162/172] - loss: 0.2837
Epoch 2 [163/172] - loss: 0.3204
Epoch 2 [164/172] - loss: 0.2238
Epoch 2 [165/172] - loss: 0.4302
Epoch 2 [166/172] - loss: 0.2472
Epoch 2 [167/172] - loss: 0.2718
Epoch 2 [168/172] - loss: 0.2119
Epoch 2 [169/172] - loss: 0.1716
Epoch 2 [170/172] - loss: 0.1546, acc: 0.9375
Epoch 2 [171/172] - loss: 0.3088
Epoch 2 [172/172] - loss: 0.4360

类别准确率:
positive: 0.9143 (427/467)
neutral: 0.3253 (27/83)
negative: 0.3920 (98/250)

Epoch 2/10
Train Loss: 0.2541, Train Acc: 0.9172
Val Loss: 0.7622, Val Acc: 0.6900
Epoch 3 [1/172] - loss: 0.2760, acc: 0.8750
Epoch 3 [2/172] - loss: 0.1572
Epoch 3 [3/172] - loss: 0.1274
Epoch 3 [4/172] - loss: 0.1582
Epoch 3 [5/172] - loss: 0.1907
Epoch 3 [6/172] - loss: 0.1133
Epoch 3 [7/172] - loss: 0.2333
Epoch 3 [8/172] - loss: 0.1996
Epoch 3 [9/172] - loss: 0.1779
Epoch 3 [10/172] - loss: 0.1085, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1782
Epoch 3 [12/172] - loss: 0.1290
Epoch 3 [13/172] - loss: 0.0990
Epoch 3 [14/172] - loss: 0.1183
Epoch 3 [15/172] - loss: 0.1476
Epoch 3 [16/172] - loss: 0.2535
Epoch 3 [17/172] - loss: 0.1603
Epoch 3 [18/172] - loss: 0.2615
Epoch 3 [19/172] - loss: 0.1344
Epoch 3 [20/172] - loss: 0.1192, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1536
Epoch 3 [22/172] - loss: 0.2402
Epoch 3 [23/172] - loss: 0.1236
Epoch 3 [24/172] - loss: 0.2294
Epoch 3 [25/172] - loss: 0.1001
Epoch 3 [26/172] - loss: 0.1853
Epoch 3 [27/172] - loss: 0.0978
Epoch 3 [28/172] - loss: 0.1692
Epoch 3 [29/172] - loss: 0.2204
Epoch 3 [30/172] - loss: 0.1640, acc: 0.9375
Epoch 3 [31/172] - loss: 0.1159
Epoch 3 [32/172] - loss: 0.1266
Epoch 3 [33/172] - loss: 0.1289
Epoch 3 [34/172] - loss: 0.1152
Epoch 3 [35/172] - loss: 0.2061
Epoch 3 [36/172] - loss: 0.1167
Epoch 3 [37/172] - loss: 0.1647
Epoch 3 [38/172] - loss: 0.0988
Epoch 3 [39/172] - loss: 0.1040
Epoch 3 [40/172] - loss: 0.2283, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1299
Epoch 3 [42/172] - loss: 0.1297
Epoch 3 [43/172] - loss: 0.1104
Epoch 3 [44/172] - loss: 0.0986
Epoch 3 [45/172] - loss: 0.2600
Epoch 3 [46/172] - loss: 0.1236
Epoch 3 [47/172] - loss: 0.1018
Epoch 3 [48/172] - loss: 0.1557
Epoch 3 [49/172] - loss: 0.1114
Epoch 3 [50/172] - loss: 0.1219, acc: 1.0000
Epoch 3 [51/172] - loss: 0.1929
Epoch 3 [52/172] - loss: 0.2233
Epoch 3 [53/172] - loss: 0.1858
Epoch 3 [54/172] - loss: 0.1794
Epoch 3 [55/172] - loss: 0.1647
Epoch 3 [56/172] - loss: 0.0986

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3586, log_difficulty=0.3065, weight=2.5323
neutral: count=3923.0, difficulty=0.2858, log_difficulty=0.2514, weight=2.2570
negative: count=4382.0, difficulty=0.3432, log_difficulty=0.2950, weight=2.4751

当前batch的pt分布：
positive: min=0.5303, max=0.9952, mean=0.8075
neutral: min=0.1001, max=0.9780, mean=0.6862
negative: min=0.9606, max=0.9972, mean=0.9825

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 1.0000
neutral 准确率: 0.6875
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3673
焦点损失: 0.1555
边界损失: 0.2428
总损失: 0.2981
Epoch 3 [57/172] - loss: 0.2981
Epoch 3 [58/172] - loss: 0.0938
Epoch 3 [59/172] - loss: 0.1372
Epoch 3 [60/172] - loss: 0.1018, acc: 1.0000
Epoch 3 [61/172] - loss: 0.1312
Epoch 3 [62/172] - loss: 0.0941
Epoch 3 [63/172] - loss: 0.1888
Epoch 3 [64/172] - loss: 0.1677
Epoch 3 [65/172] - loss: 0.0899
Epoch 3 [66/172] - loss: 0.1974
Epoch 3 [67/172] - loss: 0.1043
Epoch 3 [68/172] - loss: 0.1098
Epoch 3 [69/172] - loss: 0.2379
Epoch 3 [70/172] - loss: 0.0888, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1350
Epoch 3 [72/172] - loss: 0.2669
Epoch 3 [73/172] - loss: 0.1058
Epoch 3 [74/172] - loss: 0.2459
Epoch 3 [75/172] - loss: 0.1110
Epoch 3 [76/172] - loss: 0.0916
Epoch 3 [77/172] - loss: 0.1311
Epoch 3 [78/172] - loss: 0.1931
Epoch 3 [79/172] - loss: 0.1012
Epoch 3 [80/172] - loss: 0.2241, acc: 0.8125
Epoch 3 [81/172] - loss: 0.0997
Epoch 3 [82/172] - loss: 0.2337
Epoch 3 [83/172] - loss: 0.1360
Epoch 3 [84/172] - loss: 0.0881
Epoch 3 [85/172] - loss: 0.1067
Epoch 3 [86/172] - loss: 0.1057
Epoch 3 [87/172] - loss: 0.1554
Epoch 3 [88/172] - loss: 0.1545
Epoch 3 [89/172] - loss: 0.1029
Epoch 3 [90/172] - loss: 0.0930, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1023
Epoch 3 [92/172] - loss: 0.1578
Epoch 3 [93/172] - loss: 0.1399
Epoch 3 [94/172] - loss: 0.1151
Epoch 3 [95/172] - loss: 0.1032
Epoch 3 [96/172] - loss: 0.1670
Epoch 3 [97/172] - loss: 0.1629
Epoch 3 [98/172] - loss: 0.1021
Epoch 3 [99/172] - loss: 0.1212
Epoch 3 [100/172] - loss: 0.1410, acc: 0.9688
Epoch 3 [101/172] - loss: 0.2717
Epoch 3 [102/172] - loss: 0.1211
Epoch 3 [103/172] - loss: 0.2113
Epoch 3 [104/172] - loss: 0.1229
Epoch 3 [105/172] - loss: 0.1006
Epoch 3 [106/172] - loss: 0.1173
Epoch 3 [107/172] - loss: 0.1206
Epoch 3 [108/172] - loss: 0.1200
Epoch 3 [109/172] - loss: 0.1281
Epoch 3 [110/172] - loss: 0.2171, acc: 0.9062
Epoch 3 [111/172] - loss: 0.2504
Epoch 3 [112/172] - loss: 0.1220
Epoch 3 [113/172] - loss: 0.1184
Epoch 3 [114/172] - loss: 0.1078
Epoch 3 [115/172] - loss: 0.1159
Epoch 3 [116/172] - loss: 0.1117
Epoch 3 [117/172] - loss: 0.1330
Epoch 3 [118/172] - loss: 0.1336
Epoch 3 [119/172] - loss: 0.1863
Epoch 3 [120/172] - loss: 0.2562, acc: 0.9375
Epoch 3 [121/172] - loss: 0.2241
Epoch 3 [122/172] - loss: 0.1334
Epoch 3 [123/172] - loss: 0.1367
Epoch 3 [124/172] - loss: 0.1051
Epoch 3 [125/172] - loss: 0.1141
Epoch 3 [126/172] - loss: 0.2153
Epoch 3 [127/172] - loss: 0.1488
Epoch 3 [128/172] - loss: 0.1095
Epoch 3 [129/172] - loss: 0.1007
Epoch 3 [130/172] - loss: 0.1229, acc: 0.9688
Epoch 3 [131/172] - loss: 0.1177
Epoch 3 [132/172] - loss: 0.0940
Epoch 3 [133/172] - loss: 0.1233
Epoch 3 [134/172] - loss: 0.0899
Epoch 3 [135/172] - loss: 0.1584
Epoch 3 [136/172] - loss: 0.0942
Epoch 3 [137/172] - loss: 0.1028
Epoch 3 [138/172] - loss: 0.1187
Epoch 3 [139/172] - loss: 0.1121
Epoch 3 [140/172] - loss: 0.1194, acc: 1.0000
Epoch 3 [141/172] - loss: 0.2444
Epoch 3 [142/172] - loss: 0.1310
Epoch 3 [143/172] - loss: 0.1013
Epoch 3 [144/172] - loss: 0.2092
Epoch 3 [145/172] - loss: 0.1460
Epoch 3 [146/172] - loss: 0.1040
Epoch 3 [147/172] - loss: 0.1399
Epoch 3 [148/172] - loss: 0.1677
Epoch 3 [149/172] - loss: 0.1441
Epoch 3 [150/172] - loss: 0.2160, acc: 0.9375
Epoch 3 [151/172] - loss: 0.2378
Epoch 3 [152/172] - loss: 0.1027
Epoch 3 [153/172] - loss: 0.1535
Epoch 3 [154/172] - loss: 0.2359
Epoch 3 [155/172] - loss: 0.0858
Epoch 3 [156/172] - loss: 0.0982

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3141, log_difficulty=0.2731, weight=2.3656
neutral: count=4903.0, difficulty=0.2461, log_difficulty=0.2200, weight=2.1001
negative: count=5500.0, difficulty=0.2996, log_difficulty=0.2621, weight=2.3104

当前batch的pt分布：
positive: min=0.8159, max=0.9902, mean=0.9294
neutral: min=0.8802, max=0.9882, mean=0.9505
negative: min=0.8301, max=0.9793, mean=0.9128

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0725
焦点损失: 0.0006
边界损失: 0.1731
总损失: 0.0873
Epoch 3 [157/172] - loss: 0.0873
Epoch 3 [158/172] - loss: 0.1738
Epoch 3 [159/172] - loss: 0.0975
Epoch 3 [160/172] - loss: 0.1461, acc: 0.9688
Epoch 3 [161/172] - loss: 0.2914
Epoch 3 [162/172] - loss: 0.2451
Epoch 3 [163/172] - loss: 0.1322
Epoch 3 [164/172] - loss: 0.0846
Epoch 3 [165/172] - loss: 0.1114
Epoch 3 [166/172] - loss: 0.0931
Epoch 3 [167/172] - loss: 0.1251
Epoch 3 [168/172] - loss: 0.1023
Epoch 3 [169/172] - loss: 0.1481
Epoch 3 [170/172] - loss: 0.1136, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1034
Epoch 3 [172/172] - loss: 0.0937

类别准确率:
positive: 0.8844 (413/467)
neutral: 0.2048 (17/83)
negative: 0.5520 (138/250)

Epoch 3/10
Train Loss: 0.1343, Train Acc: 0.9677
Val Loss: 0.8012, Val Acc: 0.7100
Epoch 4 [1/172] - loss: 0.1275, acc: 0.9688
Epoch 4 [2/172] - loss: 0.0870
Epoch 4 [3/172] - loss: 0.1056
Epoch 4 [4/172] - loss: 0.1310
Epoch 4 [5/172] - loss: 0.1339
Epoch 4 [6/172] - loss: 0.0872
Epoch 4 [7/172] - loss: 0.1005
Epoch 4 [8/172] - loss: 0.0889
Epoch 4 [9/172] - loss: 0.1048
Epoch 4 [10/172] - loss: 0.1683, acc: 0.9375
Epoch 4 [11/172] - loss: 0.0992
Epoch 4 [12/172] - loss: 0.1063
Epoch 4 [13/172] - loss: 0.1776
Epoch 4 [14/172] - loss: 0.1016
Epoch 4 [15/172] - loss: 0.0807
Epoch 4 [16/172] - loss: 0.0853
Epoch 4 [17/172] - loss: 0.0912
Epoch 4 [18/172] - loss: 0.1245
Epoch 4 [19/172] - loss: 0.0967
Epoch 4 [20/172] - loss: 0.0926, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1015
Epoch 4 [22/172] - loss: 0.1370
Epoch 4 [23/172] - loss: 0.1041
Epoch 4 [24/172] - loss: 0.0795
Epoch 4 [25/172] - loss: 0.0793
Epoch 4 [26/172] - loss: 0.1686
Epoch 4 [27/172] - loss: 0.0857
Epoch 4 [28/172] - loss: 0.1447
Epoch 4 [29/172] - loss: 0.0853
Epoch 4 [30/172] - loss: 0.2136, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1528
Epoch 4 [32/172] - loss: 0.1019
Epoch 4 [33/172] - loss: 0.1031
Epoch 4 [34/172] - loss: 0.0872
Epoch 4 [35/172] - loss: 0.1463
Epoch 4 [36/172] - loss: 0.0919
Epoch 4 [37/172] - loss: 0.0768
Epoch 4 [38/172] - loss: 0.1223
Epoch 4 [39/172] - loss: 0.1654
Epoch 4 [40/172] - loss: 0.1666, acc: 0.9062
Epoch 4 [41/172] - loss: 0.1046
Epoch 4 [42/172] - loss: 0.1634
Epoch 4 [43/172] - loss: 0.1343
Epoch 4 [44/172] - loss: 0.0994
Epoch 4 [45/172] - loss: 0.0805
Epoch 4 [46/172] - loss: 0.2163
Epoch 4 [47/172] - loss: 0.1544
Epoch 4 [48/172] - loss: 0.1262
Epoch 4 [49/172] - loss: 0.0867
Epoch 4 [50/172] - loss: 0.2277, acc: 0.9375
Epoch 4 [51/172] - loss: 0.0818
Epoch 4 [52/172] - loss: 0.1718
Epoch 4 [53/172] - loss: 0.0785
Epoch 4 [54/172] - loss: 0.1008
Epoch 4 [55/172] - loss: 0.1694
Epoch 4 [56/172] - loss: 0.1237
Epoch 4 [57/172] - loss: 0.0869
Epoch 4 [58/172] - loss: 0.1070
Epoch 4 [59/172] - loss: 0.0813
Epoch 4 [60/172] - loss: 0.0904, acc: 1.0000
Epoch 4 [61/172] - loss: 0.0940
Epoch 4 [62/172] - loss: 0.1161
Epoch 4 [63/172] - loss: 0.0879
Epoch 4 [64/172] - loss: 0.0894
Epoch 4 [65/172] - loss: 0.1041
Epoch 4 [66/172] - loss: 0.0936
Epoch 4 [67/172] - loss: 0.0886
Epoch 4 [68/172] - loss: 0.1091
Epoch 4 [69/172] - loss: 0.0976
Epoch 4 [70/172] - loss: 0.0864, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0903
Epoch 4 [72/172] - loss: 0.1017
Epoch 4 [73/172] - loss: 0.0826
Epoch 4 [74/172] - loss: 0.2507
Epoch 4 [75/172] - loss: 0.1691
Epoch 4 [76/172] - loss: 0.0812
Epoch 4 [77/172] - loss: 0.1363
Epoch 4 [78/172] - loss: 0.1321
Epoch 4 [79/172] - loss: 0.1338
Epoch 4 [80/172] - loss: 0.0895, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1244
Epoch 4 [82/172] - loss: 0.0859
Epoch 4 [83/172] - loss: 0.0845
Epoch 4 [84/172] - loss: 0.0783

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2783, log_difficulty=0.2455, weight=2.2276
neutral: count=5865.0, difficulty=0.2165, log_difficulty=0.1960, weight=1.9798
negative: count=6629.0, difficulty=0.2655, log_difficulty=0.2354, weight=2.1772

当前batch的pt分布：
positive: min=0.5237, max=0.9955, mean=0.8719
neutral: min=0.9587, max=0.9983, mean=0.9861
negative: min=0.5102, max=0.9957, mean=0.9303

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1022
焦点损失: 0.0093
边界损失: 0.1831
总损失: 0.1018
Epoch 4 [85/172] - loss: 0.1018
Epoch 4 [86/172] - loss: 0.1058
Epoch 4 [87/172] - loss: 0.0851
Epoch 4 [88/172] - loss: 0.0847
Epoch 4 [89/172] - loss: 0.0848
Epoch 4 [90/172] - loss: 0.1117, acc: 0.9688
Epoch 4 [91/172] - loss: 0.2543
Epoch 4 [92/172] - loss: 0.1789
Epoch 4 [93/172] - loss: 0.0791
Epoch 4 [94/172] - loss: 0.0780
Epoch 4 [95/172] - loss: 0.1098
Epoch 4 [96/172] - loss: 0.0861
Epoch 4 [97/172] - loss: 0.1775
Epoch 4 [98/172] - loss: 0.1002
Epoch 4 [99/172] - loss: 0.0891
Epoch 4 [100/172] - loss: 0.0799, acc: 1.0000
Epoch 4 [101/172] - loss: 0.0919
Epoch 4 [102/172] - loss: 0.0914
Epoch 4 [103/172] - loss: 0.0919
Epoch 4 [104/172] - loss: 0.0876
Epoch 4 [105/172] - loss: 0.2257
Epoch 4 [106/172] - loss: 0.0848
Epoch 4 [107/172] - loss: 0.0820
Epoch 4 [108/172] - loss: 0.2442
Epoch 4 [109/172] - loss: 0.0826
Epoch 4 [110/172] - loss: 0.2981, acc: 0.8438
Epoch 4 [111/172] - loss: 0.0799
Epoch 4 [112/172] - loss: 0.1018
Epoch 4 [113/172] - loss: 0.0897
Epoch 4 [114/172] - loss: 0.1157
Epoch 4 [115/172] - loss: 0.1782
Epoch 4 [116/172] - loss: 0.1156
Epoch 4 [117/172] - loss: 0.1209
Epoch 4 [118/172] - loss: 0.1138
Epoch 4 [119/172] - loss: 0.1051
Epoch 4 [120/172] - loss: 0.1365, acc: 0.8750
Epoch 4 [121/172] - loss: 0.1526
Epoch 4 [122/172] - loss: 0.2424
Epoch 4 [123/172] - loss: 0.0849
Epoch 4 [124/172] - loss: 0.0954
Epoch 4 [125/172] - loss: 0.1136
Epoch 4 [126/172] - loss: 0.1206
Epoch 4 [127/172] - loss: 0.1606
Epoch 4 [128/172] - loss: 0.0905
Epoch 4 [129/172] - loss: 0.1081
Epoch 4 [130/172] - loss: 0.1085, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0869
Epoch 4 [132/172] - loss: 0.0972
Epoch 4 [133/172] - loss: 0.0970
Epoch 4 [134/172] - loss: 0.1052
Epoch 4 [135/172] - loss: 0.1060
Epoch 4 [136/172] - loss: 0.1257
Epoch 4 [137/172] - loss: 0.1218
Epoch 4 [138/172] - loss: 0.0862
Epoch 4 [139/172] - loss: 0.0869
Epoch 4 [140/172] - loss: 0.0920, acc: 1.0000
Epoch 4 [141/172] - loss: 0.1033
Epoch 4 [142/172] - loss: 0.1141
Epoch 4 [143/172] - loss: 0.0933
Epoch 4 [144/172] - loss: 0.0883
Epoch 4 [145/172] - loss: 0.2410
Epoch 4 [146/172] - loss: 0.0859
Epoch 4 [147/172] - loss: 0.0986
Epoch 4 [148/172] - loss: 0.1001
Epoch 4 [149/172] - loss: 0.1003
Epoch 4 [150/172] - loss: 0.1211, acc: 0.9688
Epoch 4 [151/172] - loss: 0.1294
Epoch 4 [152/172] - loss: 0.0799
Epoch 4 [153/172] - loss: 0.0839
Epoch 4 [154/172] - loss: 0.2069
Epoch 4 [155/172] - loss: 0.0881
Epoch 4 [156/172] - loss: 0.1039
Epoch 4 [157/172] - loss: 0.2992
Epoch 4 [158/172] - loss: 0.0781
Epoch 4 [159/172] - loss: 0.0866
Epoch 4 [160/172] - loss: 0.1068, acc: 0.9688
Epoch 4 [161/172] - loss: 0.1808
Epoch 4 [162/172] - loss: 0.0805
Epoch 4 [163/172] - loss: 0.1039
Epoch 4 [164/172] - loss: 0.0805
Epoch 4 [165/172] - loss: 0.1335
Epoch 4 [166/172] - loss: 0.1122
Epoch 4 [167/172] - loss: 0.1207
Epoch 4 [168/172] - loss: 0.0913
Epoch 4 [169/172] - loss: 0.1050
Epoch 4 [170/172] - loss: 0.1353, acc: 0.9375
Epoch 4 [171/172] - loss: 0.0887
Epoch 4 [172/172] - loss: 0.0945

类别准确率:
positive: 0.8094 (378/467)
neutral: 0.3494 (29/83)
negative: 0.6480 (162/250)

Epoch 4/10
Train Loss: 0.1186, Train Acc: 0.9657
Val Loss: 0.8206, Val Acc: 0.7113
Epoch 5 [1/172] - loss: 0.0795, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0848
Epoch 5 [3/172] - loss: 0.0787
Epoch 5 [4/172] - loss: 0.0856
Epoch 5 [5/172] - loss: 0.0784
Epoch 5 [6/172] - loss: 0.0983
Epoch 5 [7/172] - loss: 0.0802
Epoch 5 [8/172] - loss: 0.1639
Epoch 5 [9/172] - loss: 0.1115
Epoch 5 [10/172] - loss: 0.0811, acc: 1.0000
Epoch 5 [11/172] - loss: 0.0808
Epoch 5 [12/172] - loss: 0.0768

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2512, log_difficulty=0.2241, weight=2.1204
neutral: count=6845.0, difficulty=0.1929, log_difficulty=0.1764, weight=1.8819
negative: count=7694.0, difficulty=0.2414, log_difficulty=0.2162, weight=2.0812

当前batch的pt分布：
positive: min=0.2286, max=0.9885, mean=0.8934
neutral: min=0.9683, max=0.9991, mean=0.9911
negative: min=0.9399, max=0.9947, mean=0.9712

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0824
焦点损失: 0.0268
边界损失: 0.1568
总损失: 0.1068
Epoch 5 [13/172] - loss: 0.1068
Epoch 5 [14/172] - loss: 0.1777
Epoch 5 [15/172] - loss: 0.0767
Epoch 5 [16/172] - loss: 0.0778
Epoch 5 [17/172] - loss: 0.0899
Epoch 5 [18/172] - loss: 0.0787
Epoch 5 [19/172] - loss: 0.1177
Epoch 5 [20/172] - loss: 0.1008, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1342
Epoch 5 [22/172] - loss: 0.2289
Epoch 5 [23/172] - loss: 0.0891
Epoch 5 [24/172] - loss: 0.2081
Epoch 5 [25/172] - loss: 0.0769
Epoch 5 [26/172] - loss: 0.0808
Epoch 5 [27/172] - loss: 0.0783
Epoch 5 [28/172] - loss: 0.1101
Epoch 5 [29/172] - loss: 0.0778
Epoch 5 [30/172] - loss: 0.0962, acc: 0.9688
Epoch 5 [31/172] - loss: 0.0793
Epoch 5 [32/172] - loss: 0.0759
Epoch 5 [33/172] - loss: 0.0966
Epoch 5 [34/172] - loss: 0.0743
Epoch 5 [35/172] - loss: 0.0765
Epoch 5 [36/172] - loss: 0.0757
Epoch 5 [37/172] - loss: 0.0803
Epoch 5 [38/172] - loss: 0.0888
Epoch 5 [39/172] - loss: 0.1761
Epoch 5 [40/172] - loss: 0.0863, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0790
Epoch 5 [42/172] - loss: 0.0788
Epoch 5 [43/172] - loss: 0.1533
Epoch 5 [44/172] - loss: 0.1398
Epoch 5 [45/172] - loss: 0.0810
Epoch 5 [46/172] - loss: 0.0997
Epoch 5 [47/172] - loss: 0.0762
Epoch 5 [48/172] - loss: 0.0852
Epoch 5 [49/172] - loss: 0.0816
Epoch 5 [50/172] - loss: 0.1191, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0860
Epoch 5 [52/172] - loss: 0.0806
Epoch 5 [53/172] - loss: 0.0903
Epoch 5 [54/172] - loss: 0.0810
Epoch 5 [55/172] - loss: 0.0841
Epoch 5 [56/172] - loss: 0.0800
Epoch 5 [57/172] - loss: 0.0819
Epoch 5 [58/172] - loss: 0.0751
Epoch 5 [59/172] - loss: 0.0909
Epoch 5 [60/172] - loss: 0.1003, acc: 0.9688
Epoch 5 [61/172] - loss: 0.2184
Epoch 5 [62/172] - loss: 0.0747
Epoch 5 [63/172] - loss: 0.1992
Epoch 5 [64/172] - loss: 0.0962
Epoch 5 [65/172] - loss: 0.1581
Epoch 5 [66/172] - loss: 0.0751
Epoch 5 [67/172] - loss: 0.0769
Epoch 5 [68/172] - loss: 0.2178
Epoch 5 [69/172] - loss: 0.0871
Epoch 5 [70/172] - loss: 0.2078, acc: 0.9062
Epoch 5 [71/172] - loss: 0.1415
Epoch 5 [72/172] - loss: 0.1514
Epoch 5 [73/172] - loss: 0.1729
Epoch 5 [74/172] - loss: 0.1754
Epoch 5 [75/172] - loss: 0.0810
Epoch 5 [76/172] - loss: 0.0834
Epoch 5 [77/172] - loss: 0.0832
Epoch 5 [78/172] - loss: 0.1327
Epoch 5 [79/172] - loss: 0.1094
Epoch 5 [80/172] - loss: 0.1107, acc: 1.0000
Epoch 5 [81/172] - loss: 0.2333
Epoch 5 [82/172] - loss: 0.1345
Epoch 5 [83/172] - loss: 0.0961
Epoch 5 [84/172] - loss: 0.0885
Epoch 5 [85/172] - loss: 0.1727
Epoch 5 [86/172] - loss: 0.1279
Epoch 5 [87/172] - loss: 0.1420
Epoch 5 [88/172] - loss: 0.1082
Epoch 5 [89/172] - loss: 0.0883
Epoch 5 [90/172] - loss: 0.1009, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1074
Epoch 5 [92/172] - loss: 0.0873
Epoch 5 [93/172] - loss: 0.0823
Epoch 5 [94/172] - loss: 0.0811
Epoch 5 [95/172] - loss: 0.1246
Epoch 5 [96/172] - loss: 0.1211
Epoch 5 [97/172] - loss: 0.1056
Epoch 5 [98/172] - loss: 0.0846
Epoch 5 [99/172] - loss: 0.1264
Epoch 5 [100/172] - loss: 0.0866, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1092
Epoch 5 [102/172] - loss: 0.0866
Epoch 5 [103/172] - loss: 0.0905
Epoch 5 [104/172] - loss: 0.1384
Epoch 5 [105/172] - loss: 0.1788
Epoch 5 [106/172] - loss: 0.0840
Epoch 5 [107/172] - loss: 0.0851
Epoch 5 [108/172] - loss: 0.1157
Epoch 5 [109/172] - loss: 0.0774
Epoch 5 [110/172] - loss: 0.1070, acc: 0.9688
Epoch 5 [111/172] - loss: 0.0840
Epoch 5 [112/172] - loss: 0.0762

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2276, log_difficulty=0.2051, weight=2.0254
neutral: count=7825.0, difficulty=0.1761, log_difficulty=0.1622, weight=1.8109
negative: count=8780.0, difficulty=0.2218, log_difficulty=0.2004, weight=2.0018

当前batch的pt分布：
positive: min=0.0914, max=0.9918, mean=0.8564
neutral: min=0.7493, max=0.9893, mean=0.9410
negative: min=0.9888, max=0.9982, mean=0.9947

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1451
焦点损失: 0.0633
边界损失: 0.1715
总损失: 0.1497
Epoch 5 [113/172] - loss: 0.1497
Epoch 5 [114/172] - loss: 0.2031
Epoch 5 [115/172] - loss: 0.0970
Epoch 5 [116/172] - loss: 0.0751
Epoch 5 [117/172] - loss: 0.0954
Epoch 5 [118/172] - loss: 0.0732
Epoch 5 [119/172] - loss: 0.0787
Epoch 5 [120/172] - loss: 0.0990, acc: 0.9688
Epoch 5 [121/172] - loss: 0.0878
Epoch 5 [122/172] - loss: 0.0876
Epoch 5 [123/172] - loss: 0.1140
Epoch 5 [124/172] - loss: 0.0840
Epoch 5 [125/172] - loss: 0.0764
Epoch 5 [126/172] - loss: 0.0764
Epoch 5 [127/172] - loss: 0.1070
Epoch 5 [128/172] - loss: 0.0772
Epoch 5 [129/172] - loss: 0.1092
Epoch 5 [130/172] - loss: 0.0811, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0851
Epoch 5 [132/172] - loss: 0.1294
Epoch 5 [133/172] - loss: 0.1697
Epoch 5 [134/172] - loss: 0.0991
Epoch 5 [135/172] - loss: 0.1558
Epoch 5 [136/172] - loss: 0.0954
Epoch 5 [137/172] - loss: 0.1097
Epoch 5 [138/172] - loss: 0.1346
Epoch 5 [139/172] - loss: 0.2155
Epoch 5 [140/172] - loss: 0.1084, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0938
Epoch 5 [142/172] - loss: 0.0814
Epoch 5 [143/172] - loss: 0.0757
Epoch 5 [144/172] - loss: 0.0860
Epoch 5 [145/172] - loss: 0.0984
Epoch 5 [146/172] - loss: 0.0764
Epoch 5 [147/172] - loss: 0.1092
Epoch 5 [148/172] - loss: 0.0753
Epoch 5 [149/172] - loss: 0.1681
Epoch 5 [150/172] - loss: 0.1451, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0842
Epoch 5 [152/172] - loss: 0.0783
Epoch 5 [153/172] - loss: 0.0769
Epoch 5 [154/172] - loss: 0.0828
Epoch 5 [155/172] - loss: 0.1015
Epoch 5 [156/172] - loss: 0.0913
Epoch 5 [157/172] - loss: 0.0835
Epoch 5 [158/172] - loss: 0.0835
Epoch 5 [159/172] - loss: 0.0906
Epoch 5 [160/172] - loss: 0.0851, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0783
Epoch 5 [162/172] - loss: 0.0966
Epoch 5 [163/172] - loss: 0.1238
Epoch 5 [164/172] - loss: 0.0780
Epoch 5 [165/172] - loss: 0.1741
Epoch 5 [166/172] - loss: 0.1130
Epoch 5 [167/172] - loss: 0.0985
Epoch 5 [168/172] - loss: 0.0862
Epoch 5 [169/172] - loss: 0.1268
Epoch 5 [170/172] - loss: 0.0855, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0879
Epoch 5 [172/172] - loss: 0.0904

类别准确率:
positive: 0.8865 (414/467)
neutral: 0.2651 (22/83)
negative: 0.5840 (146/250)

Epoch 5/10
Train Loss: 0.0989, Train Acc: 0.9899
Val Loss: 0.7764, Val Acc: 0.7275
Epoch 6 [1/172] - loss: 0.0953, acc: 1.0000
Epoch 6 [2/172] - loss: 0.0940
Epoch 6 [3/172] - loss: 0.0758
Epoch 6 [4/172] - loss: 0.1140
Epoch 6 [5/172] - loss: 0.1342
Epoch 6 [6/172] - loss: 0.0758
Epoch 6 [7/172] - loss: 0.0823
Epoch 6 [8/172] - loss: 0.1167
Epoch 6 [9/172] - loss: 0.0837
Epoch 6 [10/172] - loss: 0.0770, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0768
Epoch 6 [12/172] - loss: 0.0755
Epoch 6 [13/172] - loss: 0.1007
Epoch 6 [14/172] - loss: 0.0739
Epoch 6 [15/172] - loss: 0.0807
Epoch 6 [16/172] - loss: 0.1215
Epoch 6 [17/172] - loss: 0.0886
Epoch 6 [18/172] - loss: 0.0821
Epoch 6 [19/172] - loss: 0.0834
Epoch 6 [20/172] - loss: 0.0765, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0916
Epoch 6 [22/172] - loss: 0.0874
Epoch 6 [23/172] - loss: 0.0793
Epoch 6 [24/172] - loss: 0.0775
Epoch 6 [25/172] - loss: 0.0851
Epoch 6 [26/172] - loss: 0.0893
Epoch 6 [27/172] - loss: 0.0880
Epoch 6 [28/172] - loss: 0.0812
Epoch 6 [29/172] - loss: 0.0793
Epoch 6 [30/172] - loss: 0.0779, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0811
Epoch 6 [32/172] - loss: 0.0757
Epoch 6 [33/172] - loss: 0.0757
Epoch 6 [34/172] - loss: 0.0741
Epoch 6 [35/172] - loss: 0.0738
Epoch 6 [36/172] - loss: 0.0766
Epoch 6 [37/172] - loss: 0.0801
Epoch 6 [38/172] - loss: 0.0764
Epoch 6 [39/172] - loss: 0.0957
Epoch 6 [40/172] - loss: 0.0884, acc: 1.0000

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2093, log_difficulty=0.1900, weight=1.9501
neutral: count=8815.0, difficulty=0.1613, log_difficulty=0.1496, weight=1.7479
negative: count=9870.0, difficulty=0.2042, log_difficulty=0.1858, weight=1.9292

当前batch的pt分布：
positive: min=0.0620, max=0.9988, mean=0.8913
neutral: min=0.9626, max=0.9968, mean=0.9846
negative: min=0.9253, max=0.9978, mean=0.9625

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1134
焦点损失: 0.0762
边界损失: 0.1494
总损失: 0.1490
Epoch 6 [41/172] - loss: 0.1490
Epoch 6 [42/172] - loss: 0.0768
Epoch 6 [43/172] - loss: 0.1366
Epoch 6 [44/172] - loss: 0.0811
Epoch 6 [45/172] - loss: 0.1361
Epoch 6 [46/172] - loss: 0.0813
Epoch 6 [47/172] - loss: 0.0856
Epoch 6 [48/172] - loss: 0.0748
Epoch 6 [49/172] - loss: 0.0789
Epoch 6 [50/172] - loss: 0.1344, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0821
Epoch 6 [52/172] - loss: 0.0874
Epoch 6 [53/172] - loss: 0.0744
Epoch 6 [54/172] - loss: 0.2271
Epoch 6 [55/172] - loss: 0.0943
Epoch 6 [56/172] - loss: 0.0769
Epoch 6 [57/172] - loss: 0.0781
Epoch 6 [58/172] - loss: 0.0734
Epoch 6 [59/172] - loss: 0.1720
Epoch 6 [60/172] - loss: 0.0921, acc: 1.0000
Epoch 6 [61/172] - loss: 0.0774
Epoch 6 [62/172] - loss: 0.1226
Epoch 6 [63/172] - loss: 0.0797
Epoch 6 [64/172] - loss: 0.1573
Epoch 6 [65/172] - loss: 0.0827
Epoch 6 [66/172] - loss: 0.0821
Epoch 6 [67/172] - loss: 0.0747
Epoch 6 [68/172] - loss: 0.1267
Epoch 6 [69/172] - loss: 0.1224
Epoch 6 [70/172] - loss: 0.0750, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0893
Epoch 6 [72/172] - loss: 0.0979
Epoch 6 [73/172] - loss: 0.0895
Epoch 6 [74/172] - loss: 0.0736
Epoch 6 [75/172] - loss: 0.0898
Epoch 6 [76/172] - loss: 0.0756
Epoch 6 [77/172] - loss: 0.1059
Epoch 6 [78/172] - loss: 0.0962
Epoch 6 [79/172] - loss: 0.0741
Epoch 6 [80/172] - loss: 0.1544, acc: 0.9375
Epoch 6 [81/172] - loss: 0.0995
Epoch 6 [82/172] - loss: 0.0918
Epoch 6 [83/172] - loss: 0.0743
Epoch 6 [84/172] - loss: 0.0734
Epoch 6 [85/172] - loss: 0.0898
Epoch 6 [86/172] - loss: 0.0811
Epoch 6 [87/172] - loss: 0.0852
Epoch 6 [88/172] - loss: 0.0910
Epoch 6 [89/172] - loss: 0.0737
Epoch 6 [90/172] - loss: 0.0750, acc: 1.0000
Epoch 6 [91/172] - loss: 0.1525
Epoch 6 [92/172] - loss: 0.0764
Epoch 6 [93/172] - loss: 0.1270
Epoch 6 [94/172] - loss: 0.1396
Epoch 6 [95/172] - loss: 0.0817
Epoch 6 [96/172] - loss: 0.0734
Epoch 6 [97/172] - loss: 0.1078
Epoch 6 [98/172] - loss: 0.1010
Epoch 6 [99/172] - loss: 0.0894
Epoch 6 [100/172] - loss: 0.0734, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1222
Epoch 6 [102/172] - loss: 0.0807
Epoch 6 [103/172] - loss: 0.1017
Epoch 6 [104/172] - loss: 0.1113
Epoch 6 [105/172] - loss: 0.0856
Epoch 6 [106/172] - loss: 0.1068
Epoch 6 [107/172] - loss: 0.0834
Epoch 6 [108/172] - loss: 0.0840
Epoch 6 [109/172] - loss: 0.1833
Epoch 6 [110/172] - loss: 0.0979, acc: 0.9688
Epoch 6 [111/172] - loss: 0.0762
Epoch 6 [112/172] - loss: 0.0904
Epoch 6 [113/172] - loss: 0.1088
Epoch 6 [114/172] - loss: 0.0773
Epoch 6 [115/172] - loss: 0.0953
Epoch 6 [116/172] - loss: 0.2946
Epoch 6 [117/172] - loss: 0.0746
Epoch 6 [118/172] - loss: 0.0762
Epoch 6 [119/172] - loss: 0.1554
Epoch 6 [120/172] - loss: 0.0785, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0826
Epoch 6 [122/172] - loss: 0.1016
Epoch 6 [123/172] - loss: 0.0860
Epoch 6 [124/172] - loss: 0.0757
Epoch 6 [125/172] - loss: 0.1020
Epoch 6 [126/172] - loss: 0.0878
Epoch 6 [127/172] - loss: 0.1331
Epoch 6 [128/172] - loss: 0.0852
Epoch 6 [129/172] - loss: 0.0833
Epoch 6 [130/172] - loss: 0.1266, acc: 0.9375
Epoch 6 [131/172] - loss: 0.1008
Epoch 6 [132/172] - loss: 0.0949
Epoch 6 [133/172] - loss: 0.0820
Epoch 6 [134/172] - loss: 0.0754
Epoch 6 [135/172] - loss: 0.0980
Epoch 6 [136/172] - loss: 0.0960
Epoch 6 [137/172] - loss: 0.0782
Epoch 6 [138/172] - loss: 0.1177
Epoch 6 [139/172] - loss: 0.0877
Epoch 6 [140/172] - loss: 0.0960, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1940, log_difficulty=0.1773, weight=1.8865
neutral: count=9796.0, difficulty=0.1499, log_difficulty=0.1396, weight=1.6982
negative: count=10972.0, difficulty=0.1897, log_difficulty=0.1737, weight=1.8687

当前batch的pt分布：
positive: min=0.9668, max=0.9978, mean=0.9860
neutral: min=0.7568, max=0.9976, mean=0.9643
negative: min=0.6691, max=0.9935, mean=0.9164

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0551
焦点损失: 0.0031
边界损失: 0.1625
总损失: 0.0841
Epoch 6 [141/172] - loss: 0.0841
Epoch 6 [142/172] - loss: 0.0733
Epoch 6 [143/172] - loss: 0.0847
Epoch 6 [144/172] - loss: 0.0780
Epoch 6 [145/172] - loss: 0.0770
Epoch 6 [146/172] - loss: 0.0786
Epoch 6 [147/172] - loss: 0.0877
Epoch 6 [148/172] - loss: 0.0833
Epoch 6 [149/172] - loss: 0.0750
Epoch 6 [150/172] - loss: 0.0735, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0993
Epoch 6 [152/172] - loss: 0.0810
Epoch 6 [153/172] - loss: 0.0770
Epoch 6 [154/172] - loss: 0.0751
Epoch 6 [155/172] - loss: 0.0986
Epoch 6 [156/172] - loss: 0.0906
Epoch 6 [157/172] - loss: 0.0874
Epoch 6 [158/172] - loss: 0.0802
Epoch 6 [159/172] - loss: 0.0754
Epoch 6 [160/172] - loss: 0.0986, acc: 0.9688
Epoch 6 [161/172] - loss: 0.0747
Epoch 6 [162/172] - loss: 0.0795
Epoch 6 [163/172] - loss: 0.0763
Epoch 6 [164/172] - loss: 0.1243
Epoch 6 [165/172] - loss: 0.2520
Epoch 6 [166/172] - loss: 0.0871
Epoch 6 [167/172] - loss: 0.0795
Epoch 6 [168/172] - loss: 0.0806
Epoch 6 [169/172] - loss: 0.1086
Epoch 6 [170/172] - loss: 0.0727, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0768
Epoch 6 [172/172] - loss: 0.0824

类别准确率:
positive: 0.8137 (380/467)
neutral: 0.2410 (20/83)
negative: 0.6240 (156/250)

Epoch 6/10
Train Loss: 0.0960, Train Acc: 0.9838
Val Loss: 0.9779, Val Acc: 0.6950
Epoch 7 [1/172] - loss: 0.0755, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0717
Epoch 7 [3/172] - loss: 0.0721
Epoch 7 [4/172] - loss: 0.0846
Epoch 7 [5/172] - loss: 0.0800
Epoch 7 [6/172] - loss: 0.0731
Epoch 7 [7/172] - loss: 0.0737
Epoch 7 [8/172] - loss: 0.1352
Epoch 7 [9/172] - loss: 0.0731
Epoch 7 [10/172] - loss: 0.0747, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0790
Epoch 7 [12/172] - loss: 0.1085
Epoch 7 [13/172] - loss: 0.0793
Epoch 7 [14/172] - loss: 0.0807
Epoch 7 [15/172] - loss: 0.2646
Epoch 7 [16/172] - loss: 0.1093
Epoch 7 [17/172] - loss: 0.1117
Epoch 7 [18/172] - loss: 0.2092
Epoch 7 [19/172] - loss: 0.0750
Epoch 7 [20/172] - loss: 0.0765, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0833
Epoch 7 [22/172] - loss: 0.0777
Epoch 7 [23/172] - loss: 0.0733
Epoch 7 [24/172] - loss: 0.0774
Epoch 7 [25/172] - loss: 0.0962
Epoch 7 [26/172] - loss: 0.1180
Epoch 7 [27/172] - loss: 0.0851
Epoch 7 [28/172] - loss: 0.0914
Epoch 7 [29/172] - loss: 0.0904
Epoch 7 [30/172] - loss: 0.1230, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0791
Epoch 7 [32/172] - loss: 0.0789
Epoch 7 [33/172] - loss: 0.1186
Epoch 7 [34/172] - loss: 0.1647
Epoch 7 [35/172] - loss: 0.0866
Epoch 7 [36/172] - loss: 0.1907
Epoch 7 [37/172] - loss: 0.1413
Epoch 7 [38/172] - loss: 0.0733
Epoch 7 [39/172] - loss: 0.0942
Epoch 7 [40/172] - loss: 0.0810, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0814
Epoch 7 [42/172] - loss: 0.1071
Epoch 7 [43/172] - loss: 0.1043
Epoch 7 [44/172] - loss: 0.1024
Epoch 7 [45/172] - loss: 0.0969
Epoch 7 [46/172] - loss: 0.1164
Epoch 7 [47/172] - loss: 0.0929
Epoch 7 [48/172] - loss: 0.0788
Epoch 7 [49/172] - loss: 0.0751
Epoch 7 [50/172] - loss: 0.0774, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1133
Epoch 7 [52/172] - loss: 0.0865
Epoch 7 [53/172] - loss: 0.0883
Epoch 7 [54/172] - loss: 0.0894
Epoch 7 [55/172] - loss: 0.1038
Epoch 7 [56/172] - loss: 0.0852
Epoch 7 [57/172] - loss: 0.1737
Epoch 7 [58/172] - loss: 0.0905
Epoch 7 [59/172] - loss: 0.0799
Epoch 7 [60/172] - loss: 0.1065, acc: 0.9688
Epoch 7 [61/172] - loss: 0.0939
Epoch 7 [62/172] - loss: 0.0804
Epoch 7 [63/172] - loss: 0.1413
Epoch 7 [64/172] - loss: 0.0832
Epoch 7 [65/172] - loss: 0.1284
Epoch 7 [66/172] - loss: 0.0754
Epoch 7 [67/172] - loss: 0.0802
Epoch 7 [68/172] - loss: 0.1168

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1813, log_difficulty=0.1666, weight=1.8329
neutral: count=10756.0, difficulty=0.1399, log_difficulty=0.1309, weight=1.6547
negative: count=12072.0, difficulty=0.1779, log_difficulty=0.1638, weight=1.8188

当前batch的pt分布：
positive: min=0.9704, max=0.9946, mean=0.9842
neutral: min=0.9516, max=0.9984, mean=0.9870
negative: min=0.8092, max=0.9906, mean=0.9356

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0382
焦点损失: 0.0005
边界损失: 0.1531
总损失: 0.0770
Epoch 7 [69/172] - loss: 0.0770
Epoch 7 [70/172] - loss: 0.0955, acc: 0.9688
Epoch 7 [71/172] - loss: 0.0782
Epoch 7 [72/172] - loss: 0.0846
Epoch 7 [73/172] - loss: 0.0878
Epoch 7 [74/172] - loss: 0.0778
Epoch 7 [75/172] - loss: 0.0783
Epoch 7 [76/172] - loss: 0.1036
Epoch 7 [77/172] - loss: 0.0951
Epoch 7 [78/172] - loss: 0.0773
Epoch 7 [79/172] - loss: 0.1014
Epoch 7 [80/172] - loss: 0.1374, acc: 0.9375
Epoch 7 [81/172] - loss: 0.0837
Epoch 7 [82/172] - loss: 0.0796
Epoch 7 [83/172] - loss: 0.1806
Epoch 7 [84/172] - loss: 0.0797
Epoch 7 [85/172] - loss: 0.0785
Epoch 7 [86/172] - loss: 0.0857
Epoch 7 [87/172] - loss: 0.0834
Epoch 7 [88/172] - loss: 0.0810
Epoch 7 [89/172] - loss: 0.0755
Epoch 7 [90/172] - loss: 0.0749, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0771
Epoch 7 [92/172] - loss: 0.0789
Epoch 7 [93/172] - loss: 0.0982
Epoch 7 [94/172] - loss: 0.0741
Epoch 7 [95/172] - loss: 0.0739
Epoch 7 [96/172] - loss: 0.0855
Epoch 7 [97/172] - loss: 0.1065
Epoch 7 [98/172] - loss: 0.0879
Epoch 7 [99/172] - loss: 0.0734
Epoch 7 [100/172] - loss: 0.1089, acc: 0.9688
Epoch 7 [101/172] - loss: 0.1327
Epoch 7 [102/172] - loss: 0.0763
Epoch 7 [103/172] - loss: 0.0753
Epoch 7 [104/172] - loss: 0.0762
Epoch 7 [105/172] - loss: 0.0871
Epoch 7 [106/172] - loss: 0.0922
Epoch 7 [107/172] - loss: 0.0815
Epoch 7 [108/172] - loss: 0.0765
Epoch 7 [109/172] - loss: 0.1230
Epoch 7 [110/172] - loss: 0.0840, acc: 1.0000
Epoch 7 [111/172] - loss: 0.0957
Epoch 7 [112/172] - loss: 0.0896
Epoch 7 [113/172] - loss: 0.0743
Epoch 7 [114/172] - loss: 0.0741
Epoch 7 [115/172] - loss: 0.0797
Epoch 7 [116/172] - loss: 0.1834
Epoch 7 [117/172] - loss: 0.1067
Epoch 7 [118/172] - loss: 0.0827
Epoch 7 [119/172] - loss: 0.0900
Epoch 7 [120/172] - loss: 0.0778, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0914
Epoch 7 [122/172] - loss: 0.0751
Epoch 7 [123/172] - loss: 0.0859
Epoch 7 [124/172] - loss: 0.1656
Epoch 7 [125/172] - loss: 0.0804
Epoch 7 [126/172] - loss: 0.0754
Epoch 7 [127/172] - loss: 0.0793
Epoch 7 [128/172] - loss: 0.0739
Epoch 7 [129/172] - loss: 0.0789
Epoch 7 [130/172] - loss: 0.0795, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1597
Epoch 7 [132/172] - loss: 0.2048
Epoch 7 [133/172] - loss: 0.0801
Epoch 7 [134/172] - loss: 0.0808
Epoch 7 [135/172] - loss: 0.0863
Epoch 7 [136/172] - loss: 0.0759
Epoch 7 [137/172] - loss: 0.1229
Epoch 7 [138/172] - loss: 0.0754
Epoch 7 [139/172] - loss: 0.2021
Epoch 7 [140/172] - loss: 0.1222, acc: 0.9688
Epoch 7 [141/172] - loss: 0.0919
Epoch 7 [142/172] - loss: 0.1110
Epoch 7 [143/172] - loss: 0.1336
Epoch 7 [144/172] - loss: 0.0932
Epoch 7 [145/172] - loss: 0.1329
Epoch 7 [146/172] - loss: 0.1494
Epoch 7 [147/172] - loss: 0.0933
Epoch 7 [148/172] - loss: 0.0910
Epoch 7 [149/172] - loss: 0.0794
Epoch 7 [150/172] - loss: 0.0849, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1214
Epoch 7 [152/172] - loss: 0.0747
Epoch 7 [153/172] - loss: 0.0774
Epoch 7 [154/172] - loss: 0.1984
Epoch 7 [155/172] - loss: 0.0779
Epoch 7 [156/172] - loss: 0.1290
Epoch 7 [157/172] - loss: 0.1101
Epoch 7 [158/172] - loss: 0.0894
Epoch 7 [159/172] - loss: 0.0939
Epoch 7 [160/172] - loss: 0.0924, acc: 0.9688
Epoch 7 [161/172] - loss: 0.0820
Epoch 7 [162/172] - loss: 0.1029
Epoch 7 [163/172] - loss: 0.0811
Epoch 7 [164/172] - loss: 0.1274
Epoch 7 [165/172] - loss: 0.0984
Epoch 7 [166/172] - loss: 0.1103
Epoch 7 [167/172] - loss: 0.0869
Epoch 7 [168/172] - loss: 0.0780

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1706, log_difficulty=0.1575, weight=1.7877
neutral: count=11731.0, difficulty=0.1319, log_difficulty=0.1239, weight=1.6195
negative: count=13173.0, difficulty=0.1679, log_difficulty=0.1552, weight=1.7760

当前batch的pt分布：
positive: min=0.8213, max=0.9987, mean=0.9564
neutral: min=0.9691, max=0.9970, mean=0.9890
negative: min=0.7578, max=0.9957, mean=0.9547

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0373
焦点损失: 0.0008
边界损失: 0.1532
总损失: 0.0773
Epoch 7 [169/172] - loss: 0.0773
Epoch 7 [170/172] - loss: 0.1117, acc: 0.9688
Epoch 7 [171/172] - loss: 0.0806
Epoch 7 [172/172] - loss: 0.0728

类别准确率:
positive: 0.8415 (393/467)
neutral: 0.2771 (23/83)
negative: 0.6160 (154/250)

Epoch 7/10
Train Loss: 0.0935, Train Acc: 0.9798
Val Loss: 0.9630, Val Acc: 0.7125
Epoch 8 [1/172] - loss: 0.0860, acc: 1.0000
Epoch 8 [2/172] - loss: 0.0877
Epoch 8 [3/172] - loss: 0.0919
Epoch 8 [4/172] - loss: 0.0729
Epoch 8 [5/172] - loss: 0.0742
Epoch 8 [6/172] - loss: 0.1134
Epoch 8 [7/172] - loss: 0.0736
Epoch 8 [8/172] - loss: 0.0748
Epoch 8 [9/172] - loss: 0.0784
Epoch 8 [10/172] - loss: 0.0849, acc: 0.9688
Epoch 8 [11/172] - loss: 0.0820
Epoch 8 [12/172] - loss: 0.0822
Epoch 8 [13/172] - loss: 0.0751
Epoch 8 [14/172] - loss: 0.0848
Epoch 8 [15/172] - loss: 0.0849
Epoch 8 [16/172] - loss: 0.0730
Epoch 8 [17/172] - loss: 0.0775
Epoch 8 [18/172] - loss: 0.0714
Epoch 8 [19/172] - loss: 0.0809
Epoch 8 [20/172] - loss: 0.0752, acc: 1.0000
Epoch 8 [21/172] - loss: 0.0753
Epoch 8 [22/172] - loss: 0.0757
Epoch 8 [23/172] - loss: 0.0864
Epoch 8 [24/172] - loss: 0.0936
Epoch 8 [25/172] - loss: 0.1188
Epoch 8 [26/172] - loss: 0.0979
Epoch 8 [27/172] - loss: 0.1124
Epoch 8 [28/172] - loss: 0.0797
Epoch 8 [29/172] - loss: 0.0902
Epoch 8 [30/172] - loss: 0.0733, acc: 1.0000
Epoch 8 [31/172] - loss: 0.0722
Epoch 8 [32/172] - loss: 0.0740
Epoch 8 [33/172] - loss: 0.0830
Epoch 8 [34/172] - loss: 0.0795
Epoch 8 [35/172] - loss: 0.0744
Epoch 8 [36/172] - loss: 0.0760
Epoch 8 [37/172] - loss: 0.1662
Epoch 8 [38/172] - loss: 0.0883
Epoch 8 [39/172] - loss: 0.1094
Epoch 8 [40/172] - loss: 0.0731, acc: 1.0000
Epoch 8 [41/172] - loss: 0.0765
Epoch 8 [42/172] - loss: 0.1501
Epoch 8 [43/172] - loss: 0.1404
Epoch 8 [44/172] - loss: 0.0871
Epoch 8 [45/172] - loss: 0.0765
Epoch 8 [46/172] - loss: 0.0827
Epoch 8 [47/172] - loss: 0.0733
Epoch 8 [48/172] - loss: 0.1054
Epoch 8 [49/172] - loss: 0.0727
Epoch 8 [50/172] - loss: 0.0742, acc: 1.0000
Epoch 8 [51/172] - loss: 0.0776
Epoch 8 [52/172] - loss: 0.0731
Epoch 8 [53/172] - loss: 0.1400
Epoch 8 [54/172] - loss: 0.0766
Epoch 8 [55/172] - loss: 0.0720
Epoch 8 [56/172] - loss: 0.0765
Epoch 8 [57/172] - loss: 0.0719
Epoch 8 [58/172] - loss: 0.0783
Epoch 8 [59/172] - loss: 0.0789
Epoch 8 [60/172] - loss: 0.0770, acc: 1.0000
Epoch 8 [61/172] - loss: 0.0748
Epoch 8 [62/172] - loss: 0.0743
Epoch 8 [63/172] - loss: 0.0713
Epoch 8 [64/172] - loss: 0.0729
Epoch 8 [65/172] - loss: 0.0713
Epoch 8 [66/172] - loss: 0.0824
Epoch 8 [67/172] - loss: 0.0822
Epoch 8 [68/172] - loss: 0.0736
Epoch 8 [69/172] - loss: 0.0870
Epoch 8 [70/172] - loss: 0.0725, acc: 1.0000
Epoch 8 [71/172] - loss: 0.1141
Epoch 8 [72/172] - loss: 0.0729
Epoch 8 [73/172] - loss: 0.0811
Epoch 8 [74/172] - loss: 0.0759
Epoch 8 [75/172] - loss: 0.0734
Epoch 8 [76/172] - loss: 0.1215
Epoch 8 [77/172] - loss: 0.0717
Epoch 8 [78/172] - loss: 0.1169
Epoch 8 [79/172] - loss: 0.1195
Epoch 8 [80/172] - loss: 0.0754, acc: 1.0000
Epoch 8 [81/172] - loss: 0.0780
Epoch 8 [82/172] - loss: 0.0860
Epoch 8 [83/172] - loss: 0.0733
Epoch 8 [84/172] - loss: 0.0747
Epoch 8 [85/172] - loss: 0.0778
Epoch 8 [86/172] - loss: 0.1127
Epoch 8 [87/172] - loss: 0.0729
Epoch 8 [88/172] - loss: 0.0793
Epoch 8 [89/172] - loss: 0.0727
Epoch 8 [90/172] - loss: 0.0786, acc: 1.0000
Epoch 8 [91/172] - loss: 0.0897
Epoch 8 [92/172] - loss: 0.0816
Epoch 8 [93/172] - loss: 0.0735
Epoch 8 [94/172] - loss: 0.0779
Epoch 8 [95/172] - loss: 0.0791
Epoch 8 [96/172] - loss: 0.0767

=== 第 1301 次迭代调试信息 ===
当前类别统计：
positive: count=14487.0, difficulty=0.1608, log_difficulty=0.1491, weight=1.7456
neutral: count=12738.0, difficulty=0.1245, log_difficulty=0.1173, weight=1.5866
negative: count=14288.0, difficulty=0.1578, log_difficulty=0.1466, weight=1.7328

当前batch的pt分布：
positive: min=0.8774, max=0.9996, mean=0.9712
neutral: min=0.1620, max=0.9894, mean=0.8571
negative: min=0.9741, max=0.9990, mean=0.9910

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 0.8667
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1313
焦点损失: 0.0692
边界损失: 0.1577
总损失: 0.1337
Epoch 8 [97/172] - loss: 0.1337
Epoch 8 [98/172] - loss: 0.0790
Epoch 8 [99/172] - loss: 0.0814
Epoch 8 [100/172] - loss: 0.0924, acc: 0.9688
Epoch 8 [101/172] - loss: 0.0868
Epoch 8 [102/172] - loss: 0.0935
Epoch 8 [103/172] - loss: 0.1026
Epoch 8 [104/172] - loss: 0.0878
Epoch 8 [105/172] - loss: 0.0761
Epoch 8 [106/172] - loss: 0.0861
Epoch 8 [107/172] - loss: 0.0866
Epoch 8 [108/172] - loss: 0.0801
Epoch 8 [109/172] - loss: 0.0901
Epoch 8 [110/172] - loss: 0.0859, acc: 1.0000
Epoch 8 [111/172] - loss: 0.1222
Epoch 8 [112/172] - loss: 0.0902
Epoch 8 [113/172] - loss: 0.0722
Epoch 8 [114/172] - loss: 0.0715
Epoch 8 [115/172] - loss: 0.0736
Epoch 8 [116/172] - loss: 0.0723
Epoch 8 [117/172] - loss: 0.0739
Epoch 8 [118/172] - loss: 0.0793
Epoch 8 [119/172] - loss: 0.0719
Epoch 8 [120/172] - loss: 0.0759, acc: 1.0000
Epoch 8 [121/172] - loss: 0.1000
Epoch 8 [122/172] - loss: 0.0734
Epoch 8 [123/172] - loss: 0.0738
Epoch 8 [124/172] - loss: 0.0727
Epoch 8 [125/172] - loss: 0.0796
Epoch 8 [126/172] - loss: 0.0808
Epoch 8 [127/172] - loss: 0.0821
Epoch 8 [128/172] - loss: 0.1015
Epoch 8 [129/172] - loss: 0.1909
Epoch 8 [130/172] - loss: 0.0776, acc: 1.0000
Epoch 8 [131/172] - loss: 0.0778
Epoch 8 [132/172] - loss: 0.0796
Epoch 8 [133/172] - loss: 0.0828
Epoch 8 [134/172] - loss: 0.0730
Epoch 8 [135/172] - loss: 0.0714
Epoch 8 [136/172] - loss: 0.0796
Epoch 8 [137/172] - loss: 0.0815
Epoch 8 [138/172] - loss: 0.0884
Epoch 8 [139/172] - loss: 0.0771
Epoch 8 [140/172] - loss: 0.0797, acc: 1.0000
Epoch 8 [141/172] - loss: 0.0726
Epoch 8 [142/172] - loss: 0.0845
Epoch 8 [143/172] - loss: 0.0732
Epoch 8 [144/172] - loss: 0.0806
Epoch 8 [145/172] - loss: 0.0786
Epoch 8 [146/172] - loss: 0.0726
Epoch 8 [147/172] - loss: 0.0728
Epoch 8 [148/172] - loss: 0.0767
Epoch 8 [149/172] - loss: 0.0735
Epoch 8 [150/172] - loss: 0.0754, acc: 1.0000
Epoch 8 [151/172] - loss: 0.1019
Epoch 8 [152/172] - loss: 0.0849
Epoch 8 [153/172] - loss: 0.0735
Epoch 8 [154/172] - loss: 0.1644
Epoch 8 [155/172] - loss: 0.0789
Epoch 8 [156/172] - loss: 0.0750
Epoch 8 [157/172] - loss: 0.0796
Epoch 8 [158/172] - loss: 0.0753
Epoch 8 [159/172] - loss: 0.0812
Epoch 8 [160/172] - loss: 0.0735, acc: 1.0000
Epoch 8 [161/172] - loss: 0.0766
Epoch 8 [162/172] - loss: 0.1244
Epoch 8 [163/172] - loss: 0.0741
Epoch 8 [164/172] - loss: 0.0733
Epoch 8 [165/172] - loss: 0.0711
Epoch 8 [166/172] - loss: 0.0785
Epoch 8 [167/172] - loss: 0.0725
Epoch 8 [168/172] - loss: 0.0757
Epoch 8 [169/172] - loss: 0.0766
Epoch 8 [170/172] - loss: 0.0745, acc: 1.0000
Epoch 8 [171/172] - loss: 0.0767
Epoch 8 [172/172] - loss: 0.0713

类别准确率:
positive: 0.8501 (397/467)
neutral: 0.2651 (22/83)
negative: 0.6120 (153/250)

Epoch 8/10
Train Loss: 0.0784, Train Acc: 0.9980
Val Loss: 0.9382, Val Acc: 0.7150
Early stopping triggered!
Best validation accuracy: 0.7275

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_090442-qnx6tfyk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.2_Multimodal_iterations_20250118_090440
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/qnx6tfyk
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██
wandb:  train_acc ▁▁▂▄▆▆▇▆▆█▇██▇███▇█▆▇██████████▇▇▇██████
wandb: train_loss ▆█▆▇▄▄▄▃▂▃▃▁▂▁▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1374
wandb:  train_acc 1
wandb: train_loss 0.07449
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.2_Multimodal_iterations_20250118_090440 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/qnx6tfyk
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_090442-qnx6tfyk/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_091638-sgbse7et
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.2_Multimodal_epochs_20250118_091638
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/sgbse7et
wandb: uploading summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▄▅▆▇█
wandb:  train_acc ▁▅▇▇██▇█
wandb: train_loss █▄▂▂▁▁▁▁
wandb:    val_acc ▁▅▇▇█▆▇▇
wandb:   val_loss ▃▁▂▃▁██▇
wandb: 
wandb: Run summary:
wandb:      epoch 8
wandb:  train_acc 0.99798
wandb: train_loss 0.07844
wandb:    val_acc 0.715
wandb:   val_loss 0.93825
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.2_Multimodal_epochs_20250118_091638 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/sgbse7et
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_091638-sgbse7et/logs

