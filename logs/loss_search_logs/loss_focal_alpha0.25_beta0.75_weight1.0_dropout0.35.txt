=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 1.0 --dropout 0.35 --name loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.35 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.35
text_dim: 128
image_dim: 256
dropout: 0.35
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6802, log_difficulty=0.5189, weight=3.5946
neutral: count=7.0, difficulty=0.6426, log_difficulty=0.4963, weight=3.4815
negative: count=13.0, difficulty=0.6603, log_difficulty=0.5070, weight=3.5349

当前batch的pt分布：
positive: min=0.1545, max=0.4681, mean=0.3198
neutral: min=0.2095, max=0.6040, mean=0.3574
negative: min=0.1673, max=0.4470, mean=0.3397

当前batch准确率：
整体准确率: 0.2812
positive 准确率: 0.2500
neutral 准确率: 0.2857
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1297
焦点损失: 0.3801
边界损失: 0.7892
总损失: 0.9291
Epoch 1 [1/172] - loss: 0.9291, acc: 0.2812
Epoch 1 [2/172] - loss: 0.9902
Epoch 1 [3/172] - loss: 1.0016
Epoch 1 [4/172] - loss: 0.8644
Epoch 1 [5/172] - loss: 0.9036
Epoch 1 [6/172] - loss: 1.0085
Epoch 1 [7/172] - loss: 0.9522
Epoch 1 [8/172] - loss: 0.8714
Epoch 1 [9/172] - loss: 0.8736
Epoch 1 [10/172] - loss: 0.8839, acc: 0.2812
Epoch 1 [11/172] - loss: 0.9131
Epoch 1 [12/172] - loss: 0.8857
Epoch 1 [13/172] - loss: 0.8004
Epoch 1 [14/172] - loss: 0.9102
Epoch 1 [15/172] - loss: 0.9458
Epoch 1 [16/172] - loss: 0.8291
Epoch 1 [17/172] - loss: 0.7987
Epoch 1 [18/172] - loss: 0.8199
Epoch 1 [19/172] - loss: 0.8394
Epoch 1 [20/172] - loss: 0.8942, acc: 0.2812
Epoch 1 [21/172] - loss: 0.8778
Epoch 1 [22/172] - loss: 0.6457
Epoch 1 [23/172] - loss: 0.9287
Epoch 1 [24/172] - loss: 1.0276
Epoch 1 [25/172] - loss: 0.7356
Epoch 1 [26/172] - loss: 0.8324
Epoch 1 [27/172] - loss: 0.8445
Epoch 1 [28/172] - loss: 0.7015
Epoch 1 [29/172] - loss: 0.7686
Epoch 1 [30/172] - loss: 0.7004, acc: 0.6250
Epoch 1 [31/172] - loss: 0.8767
Epoch 1 [32/172] - loss: 0.7725
Epoch 1 [33/172] - loss: 0.8049
Epoch 1 [34/172] - loss: 0.7530
Epoch 1 [35/172] - loss: 0.8764
Epoch 1 [36/172] - loss: 0.6302
Epoch 1 [37/172] - loss: 0.6495
Epoch 1 [38/172] - loss: 0.7877
Epoch 1 [39/172] - loss: 0.6489
Epoch 1 [40/172] - loss: 0.6751, acc: 0.6562
Epoch 1 [41/172] - loss: 0.6077
Epoch 1 [42/172] - loss: 0.4917
Epoch 1 [43/172] - loss: 0.7558
Epoch 1 [44/172] - loss: 0.8783
Epoch 1 [45/172] - loss: 0.8893
Epoch 1 [46/172] - loss: 0.4557
Epoch 1 [47/172] - loss: 0.6864
Epoch 1 [48/172] - loss: 0.7704
Epoch 1 [49/172] - loss: 0.7062
Epoch 1 [50/172] - loss: 0.5143, acc: 0.6562
Epoch 1 [51/172] - loss: 0.6359
Epoch 1 [52/172] - loss: 0.6274
Epoch 1 [53/172] - loss: 0.6766
Epoch 1 [54/172] - loss: 0.6481
Epoch 1 [55/172] - loss: 0.5302
Epoch 1 [56/172] - loss: 0.5876
Epoch 1 [57/172] - loss: 0.7166
Epoch 1 [58/172] - loss: 0.4627
Epoch 1 [59/172] - loss: 0.8158
Epoch 1 [60/172] - loss: 0.5981, acc: 0.6562
Epoch 1 [61/172] - loss: 0.6486
Epoch 1 [62/172] - loss: 0.6039
Epoch 1 [63/172] - loss: 0.7591
Epoch 1 [64/172] - loss: 0.4869
Epoch 1 [65/172] - loss: 0.6679
Epoch 1 [66/172] - loss: 0.8110
Epoch 1 [67/172] - loss: 0.6960
Epoch 1 [68/172] - loss: 0.7081
Epoch 1 [69/172] - loss: 0.7282
Epoch 1 [70/172] - loss: 0.5154, acc: 0.6562
Epoch 1 [71/172] - loss: 0.4879
Epoch 1 [72/172] - loss: 0.6692
Epoch 1 [73/172] - loss: 0.5876
Epoch 1 [74/172] - loss: 0.6090
Epoch 1 [75/172] - loss: 0.4129
Epoch 1 [76/172] - loss: 0.6476
Epoch 1 [77/172] - loss: 0.5756
Epoch 1 [78/172] - loss: 0.6580
Epoch 1 [79/172] - loss: 0.5192
Epoch 1 [80/172] - loss: 0.3615, acc: 0.7812
Epoch 1 [81/172] - loss: 0.5782
Epoch 1 [82/172] - loss: 0.7183
Epoch 1 [83/172] - loss: 0.5962
Epoch 1 [84/172] - loss: 0.5386
Epoch 1 [85/172] - loss: 0.5358
Epoch 1 [86/172] - loss: 0.7576
Epoch 1 [87/172] - loss: 0.6520
Epoch 1 [88/172] - loss: 0.7820
Epoch 1 [89/172] - loss: 0.6690
Epoch 1 [90/172] - loss: 0.6118, acc: 0.5625
Epoch 1 [91/172] - loss: 0.4178
Epoch 1 [92/172] - loss: 0.4698
Epoch 1 [93/172] - loss: 0.5769
Epoch 1 [94/172] - loss: 0.4123
Epoch 1 [95/172] - loss: 0.5167
Epoch 1 [96/172] - loss: 0.5270
Epoch 1 [97/172] - loss: 0.4994
Epoch 1 [98/172] - loss: 0.4422
Epoch 1 [99/172] - loss: 0.6641
Epoch 1 [100/172] - loss: 0.5775, acc: 0.5938

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5608, log_difficulty=0.4452, weight=3.2262
neutral: count=983.0, difficulty=0.5296, log_difficulty=0.4250, weight=3.1250
negative: count=1119.0, difficulty=0.4984, log_difficulty=0.4044, weight=3.0219

当前batch的pt分布：
positive: min=0.0319, max=0.8181, mean=0.4723
neutral: min=0.4842, max=0.9935, mean=0.6864
negative: min=0.0503, max=0.9132, mean=0.4694

当前batch准确率：
整体准确率: 0.6875
positive 准确率: 0.6667
neutral 准确率: 1.0000
negative 准确率: 0.6250

损失分量：
基础交叉熵: 1.0126
焦点损失: 0.5706
边界损失: 0.3747
总损失: 0.7256
Epoch 1 [101/172] - loss: 0.7256
Epoch 1 [102/172] - loss: 0.6271
Epoch 1 [103/172] - loss: 0.5251
Epoch 1 [104/172] - loss: 0.4342
Epoch 1 [105/172] - loss: 0.4788
Epoch 1 [106/172] - loss: 0.8262
Epoch 1 [107/172] - loss: 0.4329
Epoch 1 [108/172] - loss: 0.6330
Epoch 1 [109/172] - loss: 0.5015
Epoch 1 [110/172] - loss: 0.5462, acc: 0.6562
Epoch 1 [111/172] - loss: 0.5582
Epoch 1 [112/172] - loss: 0.5118
Epoch 1 [113/172] - loss: 0.4265
Epoch 1 [114/172] - loss: 0.4672
Epoch 1 [115/172] - loss: 0.4846
Epoch 1 [116/172] - loss: 0.4827
Epoch 1 [117/172] - loss: 0.5693
Epoch 1 [118/172] - loss: 0.4155
Epoch 1 [119/172] - loss: 0.7595
Epoch 1 [120/172] - loss: 0.4721, acc: 0.7188
Epoch 1 [121/172] - loss: 0.3813
Epoch 1 [122/172] - loss: 0.5353
Epoch 1 [123/172] - loss: 0.4881
Epoch 1 [124/172] - loss: 0.4697
Epoch 1 [125/172] - loss: 0.3752
Epoch 1 [126/172] - loss: 0.6575
Epoch 1 [127/172] - loss: 0.4377
Epoch 1 [128/172] - loss: 0.4469
Epoch 1 [129/172] - loss: 0.5496
Epoch 1 [130/172] - loss: 0.4824, acc: 0.7188
Epoch 1 [131/172] - loss: 0.3701
Epoch 1 [132/172] - loss: 0.7117
Epoch 1 [133/172] - loss: 0.5645
Epoch 1 [134/172] - loss: 0.3349
Epoch 1 [135/172] - loss: 0.4584
Epoch 1 [136/172] - loss: 0.3943
Epoch 1 [137/172] - loss: 0.4822
Epoch 1 [138/172] - loss: 0.4028
Epoch 1 [139/172] - loss: 0.5418
Epoch 1 [140/172] - loss: 0.4193, acc: 0.7812
Epoch 1 [141/172] - loss: 0.5255
Epoch 1 [142/172] - loss: 0.4533
Epoch 1 [143/172] - loss: 0.5281
Epoch 1 [144/172] - loss: 0.3817
Epoch 1 [145/172] - loss: 0.4989
Epoch 1 [146/172] - loss: 0.5365
Epoch 1 [147/172] - loss: 0.5002
Epoch 1 [148/172] - loss: 0.4629
Epoch 1 [149/172] - loss: 0.4464
Epoch 1 [150/172] - loss: 0.4460, acc: 0.6562
Epoch 1 [151/172] - loss: 0.5190
Epoch 1 [152/172] - loss: 0.4455
Epoch 1 [153/172] - loss: 0.4270
Epoch 1 [154/172] - loss: 0.4038
Epoch 1 [155/172] - loss: 0.3564
Epoch 1 [156/172] - loss: 0.6246
Epoch 1 [157/172] - loss: 0.4917
Epoch 1 [158/172] - loss: 0.3723
Epoch 1 [159/172] - loss: 0.5268
Epoch 1 [160/172] - loss: 0.4430, acc: 0.7812
Epoch 1 [161/172] - loss: 0.3824
Epoch 1 [162/172] - loss: 0.3181
Epoch 1 [163/172] - loss: 0.4139
Epoch 1 [164/172] - loss: 0.5065
Epoch 1 [165/172] - loss: 0.3771
Epoch 1 [166/172] - loss: 0.4216
Epoch 1 [167/172] - loss: 0.4206
Epoch 1 [168/172] - loss: 0.5040
Epoch 1 [169/172] - loss: 0.3488
Epoch 1 [170/172] - loss: 0.3989, acc: 0.6875
Epoch 1 [171/172] - loss: 0.3019
Epoch 1 [172/172] - loss: 0.2916

类别准确率:
positive: 0.6702 (313/467)
neutral: 0.5663 (47/83)
negative: 0.7600 (190/250)

Epoch 1/10
Train Loss: 0.4074, Train Acc: 0.7717
Val Loss: 0.7813, Val Acc: 0.6875
Epoch 2 [1/172] - loss: 0.4028, acc: 0.8438
Epoch 2 [2/172] - loss: 0.2734
Epoch 2 [3/172] - loss: 0.3619
Epoch 2 [4/172] - loss: 0.3509
Epoch 2 [5/172] - loss: 0.3843
Epoch 2 [6/172] - loss: 0.4409
Epoch 2 [7/172] - loss: 0.3063
Epoch 2 [8/172] - loss: 0.4349
Epoch 2 [9/172] - loss: 0.2802
Epoch 2 [10/172] - loss: 0.3319, acc: 0.7812
Epoch 2 [11/172] - loss: 0.3131
Epoch 2 [12/172] - loss: 0.3165
Epoch 2 [13/172] - loss: 0.3968
Epoch 2 [14/172] - loss: 0.3280
Epoch 2 [15/172] - loss: 0.5975
Epoch 2 [16/172] - loss: 0.3660
Epoch 2 [17/172] - loss: 0.3834
Epoch 2 [18/172] - loss: 0.3786
Epoch 2 [19/172] - loss: 0.2492
Epoch 2 [20/172] - loss: 0.3416, acc: 0.7812
Epoch 2 [21/172] - loss: 0.2561
Epoch 2 [22/172] - loss: 0.3831
Epoch 2 [23/172] - loss: 0.2574
Epoch 2 [24/172] - loss: 0.6118
Epoch 2 [25/172] - loss: 0.3420
Epoch 2 [26/172] - loss: 0.2416
Epoch 2 [27/172] - loss: 0.2764
Epoch 2 [28/172] - loss: 0.2717

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4804, log_difficulty=0.3923, weight=2.9614
neutral: count=1952.0, difficulty=0.4051, log_difficulty=0.3401, weight=2.7007
negative: count=2216.0, difficulty=0.4338, log_difficulty=0.3603, weight=2.8016

当前batch的pt分布：
positive: min=0.2202, max=0.9922, mean=0.7777
neutral: min=0.2068, max=0.9815, mean=0.7861
negative: min=0.0855, max=0.9637, mean=0.6794

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.8889
neutral 准确率: 0.9091
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.4214
焦点损失: 0.1691
边界损失: 0.2493
总损失: 0.3056
Epoch 2 [29/172] - loss: 0.3056
Epoch 2 [30/172] - loss: 0.3559, acc: 0.8125
Epoch 2 [31/172] - loss: 0.2353
Epoch 2 [32/172] - loss: 0.3248
Epoch 2 [33/172] - loss: 0.2847
Epoch 2 [34/172] - loss: 0.4563
Epoch 2 [35/172] - loss: 0.2603
Epoch 2 [36/172] - loss: 0.3804
Epoch 2 [37/172] - loss: 0.2946
Epoch 2 [38/172] - loss: 0.3101
Epoch 2 [39/172] - loss: 0.5097
Epoch 2 [40/172] - loss: 0.4123, acc: 0.7812
Epoch 2 [41/172] - loss: 0.3381
Epoch 2 [42/172] - loss: 0.2980
Epoch 2 [43/172] - loss: 0.2315
Epoch 2 [44/172] - loss: 0.4096
Epoch 2 [45/172] - loss: 0.2441
Epoch 2 [46/172] - loss: 0.2857
Epoch 2 [47/172] - loss: 0.4085
Epoch 2 [48/172] - loss: 0.4012
Epoch 2 [49/172] - loss: 0.2616
Epoch 2 [50/172] - loss: 0.3043, acc: 0.7812
Epoch 2 [51/172] - loss: 0.4283
Epoch 2 [52/172] - loss: 0.3887
Epoch 2 [53/172] - loss: 0.2404
Epoch 2 [54/172] - loss: 0.2161
Epoch 2 [55/172] - loss: 0.2438
Epoch 2 [56/172] - loss: 0.2533
Epoch 2 [57/172] - loss: 0.2526
Epoch 2 [58/172] - loss: 0.4257
Epoch 2 [59/172] - loss: 0.4372
Epoch 2 [60/172] - loss: 0.2535, acc: 0.8750
Epoch 2 [61/172] - loss: 0.1995
Epoch 2 [62/172] - loss: 0.2235
Epoch 2 [63/172] - loss: 0.4119
Epoch 2 [64/172] - loss: 0.3283
Epoch 2 [65/172] - loss: 0.3302
Epoch 2 [66/172] - loss: 0.3095
Epoch 2 [67/172] - loss: 0.2225
Epoch 2 [68/172] - loss: 0.3080
Epoch 2 [69/172] - loss: 0.2646
Epoch 2 [70/172] - loss: 0.3385, acc: 0.8125
Epoch 2 [71/172] - loss: 0.3580
Epoch 2 [72/172] - loss: 0.2211
Epoch 2 [73/172] - loss: 0.3305
Epoch 2 [74/172] - loss: 0.2086
Epoch 2 [75/172] - loss: 0.1933
Epoch 2 [76/172] - loss: 0.2509
Epoch 2 [77/172] - loss: 0.3037
Epoch 2 [78/172] - loss: 0.4512
Epoch 2 [79/172] - loss: 0.2118
Epoch 2 [80/172] - loss: 0.2045, acc: 0.9062
Epoch 2 [81/172] - loss: 0.2087
Epoch 2 [82/172] - loss: 0.2355
Epoch 2 [83/172] - loss: 0.3170
Epoch 2 [84/172] - loss: 0.2951
Epoch 2 [85/172] - loss: 0.3087
Epoch 2 [86/172] - loss: 0.2739
Epoch 2 [87/172] - loss: 0.4492
Epoch 2 [88/172] - loss: 0.2813
Epoch 2 [89/172] - loss: 0.1988
Epoch 2 [90/172] - loss: 0.3278, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1637
Epoch 2 [92/172] - loss: 0.3237
Epoch 2 [93/172] - loss: 0.2210
Epoch 2 [94/172] - loss: 0.2535
Epoch 2 [95/172] - loss: 0.4242
Epoch 2 [96/172] - loss: 0.2074
Epoch 2 [97/172] - loss: 0.2193
Epoch 2 [98/172] - loss: 0.1728
Epoch 2 [99/172] - loss: 0.1710
Epoch 2 [100/172] - loss: 0.2960, acc: 0.8750
Epoch 2 [101/172] - loss: 0.2630
Epoch 2 [102/172] - loss: 0.2150
Epoch 2 [103/172] - loss: 0.3198
Epoch 2 [104/172] - loss: 0.2974
Epoch 2 [105/172] - loss: 0.2064
Epoch 2 [106/172] - loss: 0.3094
Epoch 2 [107/172] - loss: 0.2030
Epoch 2 [108/172] - loss: 0.3812
Epoch 2 [109/172] - loss: 0.2048
Epoch 2 [110/172] - loss: 0.2251, acc: 0.9062
Epoch 2 [111/172] - loss: 0.2732
Epoch 2 [112/172] - loss: 0.1959
Epoch 2 [113/172] - loss: 0.1907
Epoch 2 [114/172] - loss: 0.1927
Epoch 2 [115/172] - loss: 0.1939
Epoch 2 [116/172] - loss: 0.3568
Epoch 2 [117/172] - loss: 0.4082
Epoch 2 [118/172] - loss: 0.2357
Epoch 2 [119/172] - loss: 0.2794
Epoch 2 [120/172] - loss: 0.2103, acc: 0.9062
Epoch 2 [121/172] - loss: 0.2317
Epoch 2 [122/172] - loss: 0.3374
Epoch 2 [123/172] - loss: 0.1972
Epoch 2 [124/172] - loss: 0.2052
Epoch 2 [125/172] - loss: 0.1884
Epoch 2 [126/172] - loss: 0.2392
Epoch 2 [127/172] - loss: 0.1661
Epoch 2 [128/172] - loss: 0.2268

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4110, log_difficulty=0.3443, weight=2.7215
neutral: count=2949.0, difficulty=0.3143, log_difficulty=0.2733, weight=2.3664
negative: count=3294.0, difficulty=0.3711, log_difficulty=0.3156, weight=2.5782

当前batch的pt分布：
positive: min=0.3057, max=0.9975, mean=0.7885
neutral: min=0.8062, max=0.9906, mean=0.9309
negative: min=0.0847, max=0.9885, mean=0.7394

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.8000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.2814
焦点损失: 0.1047
边界损失: 0.2184
总损失: 0.2322
Epoch 2 [129/172] - loss: 0.2322
Epoch 2 [130/172] - loss: 0.2809, acc: 0.8125
Epoch 2 [131/172] - loss: 0.2563
Epoch 2 [132/172] - loss: 0.2308
Epoch 2 [133/172] - loss: 0.1939
Epoch 2 [134/172] - loss: 0.2473
Epoch 2 [135/172] - loss: 0.3501
Epoch 2 [136/172] - loss: 0.2055
Epoch 2 [137/172] - loss: 0.1971
Epoch 2 [138/172] - loss: 0.2670
Epoch 2 [139/172] - loss: 0.2034
Epoch 2 [140/172] - loss: 0.2654, acc: 0.8750
Epoch 2 [141/172] - loss: 0.2142
Epoch 2 [142/172] - loss: 0.2327
Epoch 2 [143/172] - loss: 0.2190
Epoch 2 [144/172] - loss: 0.1813
Epoch 2 [145/172] - loss: 0.4757
Epoch 2 [146/172] - loss: 0.2287
Epoch 2 [147/172] - loss: 0.2622
Epoch 2 [148/172] - loss: 0.2676
Epoch 2 [149/172] - loss: 0.2217
Epoch 2 [150/172] - loss: 0.1954, acc: 0.9688
Epoch 2 [151/172] - loss: 0.2123
Epoch 2 [152/172] - loss: 0.2907
Epoch 2 [153/172] - loss: 0.2226
Epoch 2 [154/172] - loss: 0.1639
Epoch 2 [155/172] - loss: 0.2020
Epoch 2 [156/172] - loss: 0.1958
Epoch 2 [157/172] - loss: 0.1616
Epoch 2 [158/172] - loss: 0.2054
Epoch 2 [159/172] - loss: 0.2453
Epoch 2 [160/172] - loss: 0.2030, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1843
Epoch 2 [162/172] - loss: 0.2246
Epoch 2 [163/172] - loss: 0.2819
Epoch 2 [164/172] - loss: 0.3338
Epoch 2 [165/172] - loss: 0.2284
Epoch 2 [166/172] - loss: 0.2607
Epoch 2 [167/172] - loss: 0.3230
Epoch 2 [168/172] - loss: 0.2396
Epoch 2 [169/172] - loss: 0.1713
Epoch 2 [170/172] - loss: 0.1961, acc: 0.9062
Epoch 2 [171/172] - loss: 0.3345
Epoch 2 [172/172] - loss: 0.4252

类别准确率:
positive: 0.9358 (437/467)
neutral: 0.2289 (19/83)
negative: 0.4320 (108/250)

Epoch 2/10
Train Loss: 0.2512, Train Acc: 0.8970
Val Loss: 0.9088, Val Acc: 0.7050
Epoch 3 [1/172] - loss: 0.2102, acc: 0.9375
Epoch 3 [2/172] - loss: 0.1689
Epoch 3 [3/172] - loss: 0.1489
Epoch 3 [4/172] - loss: 0.1545
Epoch 3 [5/172] - loss: 0.2521
Epoch 3 [6/172] - loss: 0.1477
Epoch 3 [7/172] - loss: 0.1544
Epoch 3 [8/172] - loss: 0.2033
Epoch 3 [9/172] - loss: 0.1507
Epoch 3 [10/172] - loss: 0.1689, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1769
Epoch 3 [12/172] - loss: 0.1350
Epoch 3 [13/172] - loss: 0.1816
Epoch 3 [14/172] - loss: 0.1481
Epoch 3 [15/172] - loss: 0.1683
Epoch 3 [16/172] - loss: 0.2028
Epoch 3 [17/172] - loss: 0.1799
Epoch 3 [18/172] - loss: 0.2279
Epoch 3 [19/172] - loss: 0.2345
Epoch 3 [20/172] - loss: 0.1301, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1286
Epoch 3 [22/172] - loss: 0.2097
Epoch 3 [23/172] - loss: 0.1402
Epoch 3 [24/172] - loss: 0.1858
Epoch 3 [25/172] - loss: 0.1538
Epoch 3 [26/172] - loss: 0.1515
Epoch 3 [27/172] - loss: 0.1755
Epoch 3 [28/172] - loss: 0.1539
Epoch 3 [29/172] - loss: 0.2121
Epoch 3 [30/172] - loss: 0.1816, acc: 0.9375
Epoch 3 [31/172] - loss: 0.1738
Epoch 3 [32/172] - loss: 0.1583
Epoch 3 [33/172] - loss: 0.1440
Epoch 3 [34/172] - loss: 0.1656
Epoch 3 [35/172] - loss: 0.1817
Epoch 3 [36/172] - loss: 0.1605
Epoch 3 [37/172] - loss: 0.1512
Epoch 3 [38/172] - loss: 0.1523
Epoch 3 [39/172] - loss: 0.1547
Epoch 3 [40/172] - loss: 0.1614, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1412
Epoch 3 [42/172] - loss: 0.1483
Epoch 3 [43/172] - loss: 0.1403
Epoch 3 [44/172] - loss: 0.1245
Epoch 3 [45/172] - loss: 0.2071
Epoch 3 [46/172] - loss: 0.1682
Epoch 3 [47/172] - loss: 0.1233
Epoch 3 [48/172] - loss: 0.1641
Epoch 3 [49/172] - loss: 0.1396
Epoch 3 [50/172] - loss: 0.1885, acc: 0.9375
Epoch 3 [51/172] - loss: 0.1782
Epoch 3 [52/172] - loss: 0.1441
Epoch 3 [53/172] - loss: 0.1364
Epoch 3 [54/172] - loss: 0.2020
Epoch 3 [55/172] - loss: 0.1483
Epoch 3 [56/172] - loss: 0.1802

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3494, log_difficulty=0.2996, weight=2.4982
neutral: count=3923.0, difficulty=0.2602, log_difficulty=0.2313, weight=2.1564
negative: count=4382.0, difficulty=0.3166, log_difficulty=0.2750, weight=2.3751

当前batch的pt分布：
positive: min=0.2677, max=0.9930, mean=0.8648
neutral: min=0.0063, max=0.9796, mean=0.8295
negative: min=0.9689, max=0.9975, mean=0.9887

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9091
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3010
焦点损失: 0.1953
边界损失: 0.1809
总损失: 0.2428
Epoch 3 [57/172] - loss: 0.2428
Epoch 3 [58/172] - loss: 0.1258
Epoch 3 [59/172] - loss: 0.1775
Epoch 3 [60/172] - loss: 0.1495, acc: 0.9375
Epoch 3 [61/172] - loss: 0.1576
Epoch 3 [62/172] - loss: 0.1665
Epoch 3 [63/172] - loss: 0.1452
Epoch 3 [64/172] - loss: 0.1833
Epoch 3 [65/172] - loss: 0.1534
Epoch 3 [66/172] - loss: 0.1609
Epoch 3 [67/172] - loss: 0.1332
Epoch 3 [68/172] - loss: 0.1339
Epoch 3 [69/172] - loss: 0.2054
Epoch 3 [70/172] - loss: 0.1186, acc: 1.0000
Epoch 3 [71/172] - loss: 0.2071
Epoch 3 [72/172] - loss: 0.2809
Epoch 3 [73/172] - loss: 0.1547
Epoch 3 [74/172] - loss: 0.1850
Epoch 3 [75/172] - loss: 0.1409
Epoch 3 [76/172] - loss: 0.1283
Epoch 3 [77/172] - loss: 0.1442
Epoch 3 [78/172] - loss: 0.2295
Epoch 3 [79/172] - loss: 0.1266
Epoch 3 [80/172] - loss: 0.2190, acc: 0.8750
Epoch 3 [81/172] - loss: 0.1437
Epoch 3 [82/172] - loss: 0.2052
Epoch 3 [83/172] - loss: 0.1599
Epoch 3 [84/172] - loss: 0.1566
Epoch 3 [85/172] - loss: 0.1323
Epoch 3 [86/172] - loss: 0.1345
Epoch 3 [87/172] - loss: 0.2316
Epoch 3 [88/172] - loss: 0.1926
Epoch 3 [89/172] - loss: 0.1553
Epoch 3 [90/172] - loss: 0.1382, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1554
Epoch 3 [92/172] - loss: 0.1385
Epoch 3 [93/172] - loss: 0.3286
Epoch 3 [94/172] - loss: 0.1796
Epoch 3 [95/172] - loss: 0.1302
Epoch 3 [96/172] - loss: 0.1761
Epoch 3 [97/172] - loss: 0.1626
Epoch 3 [98/172] - loss: 0.1737
Epoch 3 [99/172] - loss: 0.1295
Epoch 3 [100/172] - loss: 0.2005, acc: 0.9375
Epoch 3 [101/172] - loss: 0.2487
Epoch 3 [102/172] - loss: 0.1372
Epoch 3 [103/172] - loss: 0.1857
Epoch 3 [104/172] - loss: 0.1363
Epoch 3 [105/172] - loss: 0.1451
Epoch 3 [106/172] - loss: 0.1578
Epoch 3 [107/172] - loss: 0.2282
Epoch 3 [108/172] - loss: 0.1545
Epoch 3 [109/172] - loss: 0.1163
Epoch 3 [110/172] - loss: 0.1559, acc: 0.9688
Epoch 3 [111/172] - loss: 0.1727
Epoch 3 [112/172] - loss: 0.1268
Epoch 3 [113/172] - loss: 0.1367
Epoch 3 [114/172] - loss: 0.1605
Epoch 3 [115/172] - loss: 0.1366
Epoch 3 [116/172] - loss: 0.1493
Epoch 3 [117/172] - loss: 0.1316
Epoch 3 [118/172] - loss: 0.1388
Epoch 3 [119/172] - loss: 0.1602
Epoch 3 [120/172] - loss: 0.2576, acc: 0.9375
Epoch 3 [121/172] - loss: 0.2220
Epoch 3 [122/172] - loss: 0.1167
Epoch 3 [123/172] - loss: 0.1638
Epoch 3 [124/172] - loss: 0.1651
Epoch 3 [125/172] - loss: 0.1695
Epoch 3 [126/172] - loss: 0.2888
Epoch 3 [127/172] - loss: 0.2283
Epoch 3 [128/172] - loss: 0.1271
Epoch 3 [129/172] - loss: 0.1323
Epoch 3 [130/172] - loss: 0.1422, acc: 0.9688
Epoch 3 [131/172] - loss: 0.1909
Epoch 3 [132/172] - loss: 0.1346
Epoch 3 [133/172] - loss: 0.1496
Epoch 3 [134/172] - loss: 0.1180
Epoch 3 [135/172] - loss: 0.1568
Epoch 3 [136/172] - loss: 0.1657
Epoch 3 [137/172] - loss: 0.1520
Epoch 3 [138/172] - loss: 0.1768
Epoch 3 [139/172] - loss: 0.1850
Epoch 3 [140/172] - loss: 0.1954, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1606
Epoch 3 [142/172] - loss: 0.3406
Epoch 3 [143/172] - loss: 0.1522
Epoch 3 [144/172] - loss: 0.2274
Epoch 3 [145/172] - loss: 0.1524
Epoch 3 [146/172] - loss: 0.1748
Epoch 3 [147/172] - loss: 0.1370
Epoch 3 [148/172] - loss: 0.1808
Epoch 3 [149/172] - loss: 0.1666
Epoch 3 [150/172] - loss: 0.2036, acc: 0.9688
Epoch 3 [151/172] - loss: 0.2511
Epoch 3 [152/172] - loss: 0.1867
Epoch 3 [153/172] - loss: 0.1881
Epoch 3 [154/172] - loss: 0.1850
Epoch 3 [155/172] - loss: 0.1183
Epoch 3 [156/172] - loss: 0.1743

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3024, log_difficulty=0.2642, weight=2.3210
neutral: count=4903.0, difficulty=0.2203, log_difficulty=0.1991, weight=1.9956
negative: count=5500.0, difficulty=0.2754, log_difficulty=0.2433, weight=2.2164

当前batch的pt分布：
positive: min=0.7915, max=0.9983, mean=0.9444
neutral: min=0.9381, max=0.9998, mean=0.9731
negative: min=0.1760, max=0.9957, mean=0.8835

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.0957
焦点损失: 0.0357
边界损失: 0.1588
总损失: 0.1389
Epoch 3 [157/172] - loss: 0.1389
Epoch 3 [158/172] - loss: 0.1551
Epoch 3 [159/172] - loss: 0.1789
Epoch 3 [160/172] - loss: 0.2227, acc: 0.8438
Epoch 3 [161/172] - loss: 0.1517
Epoch 3 [162/172] - loss: 0.1936
Epoch 3 [163/172] - loss: 0.2389
Epoch 3 [164/172] - loss: 0.1192
Epoch 3 [165/172] - loss: 0.1658
Epoch 3 [166/172] - loss: 0.1687
Epoch 3 [167/172] - loss: 0.1686
Epoch 3 [168/172] - loss: 0.1296
Epoch 3 [169/172] - loss: 0.1388
Epoch 3 [170/172] - loss: 0.1741, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1418
Epoch 3 [172/172] - loss: 0.1382

类别准确率:
positive: 0.8373 (391/467)
neutral: 0.4096 (34/83)
negative: 0.5280 (132/250)

Epoch 3/10
Train Loss: 0.1640, Train Acc: 0.9495
Val Loss: 0.8816, Val Acc: 0.6963
Epoch 4 [1/172] - loss: 0.1674, acc: 0.9688
Epoch 4 [2/172] - loss: 0.1427
Epoch 4 [3/172] - loss: 0.1302
Epoch 4 [4/172] - loss: 0.1397
Epoch 4 [5/172] - loss: 0.1463
Epoch 4 [6/172] - loss: 0.1177
Epoch 4 [7/172] - loss: 0.1462
Epoch 4 [8/172] - loss: 0.1119
Epoch 4 [9/172] - loss: 0.2000
Epoch 4 [10/172] - loss: 0.1580, acc: 0.9062
Epoch 4 [11/172] - loss: 0.1237
Epoch 4 [12/172] - loss: 0.1643
Epoch 4 [13/172] - loss: 0.1830
Epoch 4 [14/172] - loss: 0.1667
Epoch 4 [15/172] - loss: 0.1452
Epoch 4 [16/172] - loss: 0.1382
Epoch 4 [17/172] - loss: 0.1178
Epoch 4 [18/172] - loss: 0.1523
Epoch 4 [19/172] - loss: 0.1199
Epoch 4 [20/172] - loss: 0.1269, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1666
Epoch 4 [22/172] - loss: 0.1238
Epoch 4 [23/172] - loss: 0.1450
Epoch 4 [24/172] - loss: 0.1116
Epoch 4 [25/172] - loss: 0.1106
Epoch 4 [26/172] - loss: 0.2128
Epoch 4 [27/172] - loss: 0.1166
Epoch 4 [28/172] - loss: 0.1554
Epoch 4 [29/172] - loss: 0.1550
Epoch 4 [30/172] - loss: 0.2054, acc: 0.9375
Epoch 4 [31/172] - loss: 0.1463
Epoch 4 [32/172] - loss: 0.1219
Epoch 4 [33/172] - loss: 0.1167
Epoch 4 [34/172] - loss: 0.1143
Epoch 4 [35/172] - loss: 0.1207
Epoch 4 [36/172] - loss: 0.1441
Epoch 4 [37/172] - loss: 0.1216
Epoch 4 [38/172] - loss: 0.1121
Epoch 4 [39/172] - loss: 0.1539
Epoch 4 [40/172] - loss: 0.2861, acc: 0.9062
Epoch 4 [41/172] - loss: 0.1696
Epoch 4 [42/172] - loss: 0.1708
Epoch 4 [43/172] - loss: 0.1278
Epoch 4 [44/172] - loss: 0.1166
Epoch 4 [45/172] - loss: 0.1380
Epoch 4 [46/172] - loss: 0.1180
Epoch 4 [47/172] - loss: 0.1393
Epoch 4 [48/172] - loss: 0.1270
Epoch 4 [49/172] - loss: 0.1284
Epoch 4 [50/172] - loss: 0.1278, acc: 0.9688
Epoch 4 [51/172] - loss: 0.1344
Epoch 4 [52/172] - loss: 0.1506
Epoch 4 [53/172] - loss: 0.1132
Epoch 4 [54/172] - loss: 0.1497
Epoch 4 [55/172] - loss: 0.1988
Epoch 4 [56/172] - loss: 0.1157
Epoch 4 [57/172] - loss: 0.1126
Epoch 4 [58/172] - loss: 0.1278
Epoch 4 [59/172] - loss: 0.1167
Epoch 4 [60/172] - loss: 0.1159, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1335
Epoch 4 [62/172] - loss: 0.1293
Epoch 4 [63/172] - loss: 0.1287
Epoch 4 [64/172] - loss: 0.1130
Epoch 4 [65/172] - loss: 0.1345
Epoch 4 [66/172] - loss: 0.1197
Epoch 4 [67/172] - loss: 0.2001
Epoch 4 [68/172] - loss: 0.1279
Epoch 4 [69/172] - loss: 0.1364
Epoch 4 [70/172] - loss: 0.1380, acc: 0.9688
Epoch 4 [71/172] - loss: 0.1419
Epoch 4 [72/172] - loss: 0.1194
Epoch 4 [73/172] - loss: 0.1169
Epoch 4 [74/172] - loss: 0.2314
Epoch 4 [75/172] - loss: 0.1154
Epoch 4 [76/172] - loss: 0.1121
Epoch 4 [77/172] - loss: 0.2054
Epoch 4 [78/172] - loss: 0.1632
Epoch 4 [79/172] - loss: 0.1164
Epoch 4 [80/172] - loss: 0.1215, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1364
Epoch 4 [82/172] - loss: 0.1168
Epoch 4 [83/172] - loss: 0.1140
Epoch 4 [84/172] - loss: 0.1141

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2662, log_difficulty=0.2360, weight=2.1800
neutral: count=5865.0, difficulty=0.1932, log_difficulty=0.1767, weight=1.8833
negative: count=6629.0, difficulty=0.2422, log_difficulty=0.2169, weight=2.0843

当前batch的pt分布：
positive: min=0.6045, max=0.9940, mean=0.9032
neutral: min=0.8531, max=0.9997, mean=0.9773
negative: min=0.5656, max=0.9989, mean=0.9372

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0825
焦点损失: 0.0062
边界损失: 0.1726
总损失: 0.1327
Epoch 4 [85/172] - loss: 0.1327
Epoch 4 [86/172] - loss: 0.1526
Epoch 4 [87/172] - loss: 0.1359
Epoch 4 [88/172] - loss: 0.1195
Epoch 4 [89/172] - loss: 0.1427
Epoch 4 [90/172] - loss: 0.1192, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1752
Epoch 4 [92/172] - loss: 0.2221
Epoch 4 [93/172] - loss: 0.1103
Epoch 4 [94/172] - loss: 0.1116
Epoch 4 [95/172] - loss: 0.1617
Epoch 4 [96/172] - loss: 0.1276
Epoch 4 [97/172] - loss: 0.1255
Epoch 4 [98/172] - loss: 0.1190
Epoch 4 [99/172] - loss: 0.1184
Epoch 4 [100/172] - loss: 0.1223, acc: 1.0000
Epoch 4 [101/172] - loss: 0.1208
Epoch 4 [102/172] - loss: 0.1451
Epoch 4 [103/172] - loss: 0.1135
Epoch 4 [104/172] - loss: 0.1200
Epoch 4 [105/172] - loss: 0.1358
Epoch 4 [106/172] - loss: 0.1104
Epoch 4 [107/172] - loss: 0.1332
Epoch 4 [108/172] - loss: 0.1564
Epoch 4 [109/172] - loss: 0.1245
Epoch 4 [110/172] - loss: 0.2881, acc: 0.8750
Epoch 4 [111/172] - loss: 0.1175
Epoch 4 [112/172] - loss: 0.1136
Epoch 4 [113/172] - loss: 0.1129
Epoch 4 [114/172] - loss: 0.1199
Epoch 4 [115/172] - loss: 0.1403
Epoch 4 [116/172] - loss: 0.1874
Epoch 4 [117/172] - loss: 0.1155
Epoch 4 [118/172] - loss: 0.1783
Epoch 4 [119/172] - loss: 0.1208
Epoch 4 [120/172] - loss: 0.1259, acc: 0.9688
Epoch 4 [121/172] - loss: 0.1288
Epoch 4 [122/172] - loss: 0.2065
Epoch 4 [123/172] - loss: 0.1143
Epoch 4 [124/172] - loss: 0.1267
Epoch 4 [125/172] - loss: 0.1323
Epoch 4 [126/172] - loss: 0.1698
Epoch 4 [127/172] - loss: 0.1304
Epoch 4 [128/172] - loss: 0.1286
Epoch 4 [129/172] - loss: 0.1083
Epoch 4 [130/172] - loss: 0.1429, acc: 0.9688
Epoch 4 [131/172] - loss: 0.1111
Epoch 4 [132/172] - loss: 0.1219
Epoch 4 [133/172] - loss: 0.1318
Epoch 4 [134/172] - loss: 0.1134
Epoch 4 [135/172] - loss: 0.1244
Epoch 4 [136/172] - loss: 0.1554
Epoch 4 [137/172] - loss: 0.1303
Epoch 4 [138/172] - loss: 0.1267
Epoch 4 [139/172] - loss: 0.1148
Epoch 4 [140/172] - loss: 0.1334, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1658
Epoch 4 [142/172] - loss: 0.1358
Epoch 4 [143/172] - loss: 0.1308
Epoch 4 [144/172] - loss: 0.1620
Epoch 4 [145/172] - loss: 0.2159
Epoch 4 [146/172] - loss: 0.1165
Epoch 4 [147/172] - loss: 0.1341
Epoch 4 [148/172] - loss: 0.1336
Epoch 4 [149/172] - loss: 0.1147
Epoch 4 [150/172] - loss: 0.1747, acc: 0.9688
Epoch 4 [151/172] - loss: 0.1871
Epoch 4 [152/172] - loss: 0.1252
Epoch 4 [153/172] - loss: 0.1180
Epoch 4 [154/172] - loss: 0.1713
Epoch 4 [155/172] - loss: 0.1689
Epoch 4 [156/172] - loss: 0.1427
Epoch 4 [157/172] - loss: 0.1593
Epoch 4 [158/172] - loss: 0.1106
Epoch 4 [159/172] - loss: 0.1104
Epoch 4 [160/172] - loss: 0.1174, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1496
Epoch 4 [162/172] - loss: 0.1427
Epoch 4 [163/172] - loss: 0.1267
Epoch 4 [164/172] - loss: 0.1224
Epoch 4 [165/172] - loss: 0.1227
Epoch 4 [166/172] - loss: 0.1282
Epoch 4 [167/172] - loss: 0.1831
Epoch 4 [168/172] - loss: 0.1259
Epoch 4 [169/172] - loss: 0.1848
Epoch 4 [170/172] - loss: 0.1435, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1314
Epoch 4 [172/172] - loss: 0.1275

类别准确率:
positive: 0.8437 (394/467)
neutral: 0.3253 (27/83)
negative: 0.5680 (142/250)

Epoch 4/10
Train Loss: 0.1366, Train Acc: 0.9737
Val Loss: 1.0035, Val Acc: 0.7037
Epoch 5 [1/172] - loss: 0.1084, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1209
Epoch 5 [3/172] - loss: 0.1136
Epoch 5 [4/172] - loss: 0.1135
Epoch 5 [5/172] - loss: 0.1219
Epoch 5 [6/172] - loss: 0.1281
Epoch 5 [7/172] - loss: 0.1156
Epoch 5 [8/172] - loss: 0.1198
Epoch 5 [9/172] - loss: 0.1414
Epoch 5 [10/172] - loss: 0.1083, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1390
Epoch 5 [12/172] - loss: 0.1096

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2372, log_difficulty=0.2129, weight=2.0643
neutral: count=6845.0, difficulty=0.1718, log_difficulty=0.1585, weight=1.7926
negative: count=7694.0, difficulty=0.2170, log_difficulty=0.1964, weight=1.9820

当前batch的pt分布：
positive: min=0.4175, max=0.9977, mean=0.9274
neutral: min=0.9965, max=0.9998, mean=0.9978
negative: min=0.9629, max=0.9970, mean=0.9823

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0482
焦点损失: 0.0087
边界损失: 0.1532
总损失: 0.1194
Epoch 5 [13/172] - loss: 0.1194
Epoch 5 [14/172] - loss: 0.1454
Epoch 5 [15/172] - loss: 0.1156
Epoch 5 [16/172] - loss: 0.1089
Epoch 5 [17/172] - loss: 0.1329
Epoch 5 [18/172] - loss: 0.1086
Epoch 5 [19/172] - loss: 0.1357
Epoch 5 [20/172] - loss: 0.1256, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1531
Epoch 5 [22/172] - loss: 0.1920
Epoch 5 [23/172] - loss: 0.1088
Epoch 5 [24/172] - loss: 0.1477
Epoch 5 [25/172] - loss: 0.1114
Epoch 5 [26/172] - loss: 0.1244
Epoch 5 [27/172] - loss: 0.1166
Epoch 5 [28/172] - loss: 0.1086
Epoch 5 [29/172] - loss: 0.1119
Epoch 5 [30/172] - loss: 0.1602, acc: 0.9688
Epoch 5 [31/172] - loss: 0.1133
Epoch 5 [32/172] - loss: 0.1120
Epoch 5 [33/172] - loss: 0.1107
Epoch 5 [34/172] - loss: 0.1742
Epoch 5 [35/172] - loss: 0.1115
Epoch 5 [36/172] - loss: 0.1148
Epoch 5 [37/172] - loss: 0.1107
Epoch 5 [38/172] - loss: 0.1073
Epoch 5 [39/172] - loss: 0.1306
Epoch 5 [40/172] - loss: 0.1238, acc: 0.9688
Epoch 5 [41/172] - loss: 0.1110
Epoch 5 [42/172] - loss: 0.1743
Epoch 5 [43/172] - loss: 0.1454
Epoch 5 [44/172] - loss: 0.1159
Epoch 5 [45/172] - loss: 0.1094
Epoch 5 [46/172] - loss: 0.1165
Epoch 5 [47/172] - loss: 0.1079
Epoch 5 [48/172] - loss: 0.1383
Epoch 5 [49/172] - loss: 0.1115
Epoch 5 [50/172] - loss: 0.1301, acc: 0.9688
Epoch 5 [51/172] - loss: 0.1262
Epoch 5 [52/172] - loss: 0.1141
Epoch 5 [53/172] - loss: 0.1229
Epoch 5 [54/172] - loss: 0.1137
Epoch 5 [55/172] - loss: 0.1292
Epoch 5 [56/172] - loss: 0.1311
Epoch 5 [57/172] - loss: 0.1148
Epoch 5 [58/172] - loss: 0.1102
Epoch 5 [59/172] - loss: 0.1482
Epoch 5 [60/172] - loss: 0.1279, acc: 0.9688
Epoch 5 [61/172] - loss: 0.1201
Epoch 5 [62/172] - loss: 0.1200
Epoch 5 [63/172] - loss: 0.1438
Epoch 5 [64/172] - loss: 0.1153
Epoch 5 [65/172] - loss: 0.1103
Epoch 5 [66/172] - loss: 0.1087
Epoch 5 [67/172] - loss: 0.1076
Epoch 5 [68/172] - loss: 0.1282
Epoch 5 [69/172] - loss: 0.1233
Epoch 5 [70/172] - loss: 0.1153, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1166
Epoch 5 [72/172] - loss: 0.1194
Epoch 5 [73/172] - loss: 0.1163
Epoch 5 [74/172] - loss: 0.1250
Epoch 5 [75/172] - loss: 0.1110
Epoch 5 [76/172] - loss: 0.1088
Epoch 5 [77/172] - loss: 0.1104
Epoch 5 [78/172] - loss: 0.1108
Epoch 5 [79/172] - loss: 0.1284
Epoch 5 [80/172] - loss: 0.1184, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1792
Epoch 5 [82/172] - loss: 0.1335
Epoch 5 [83/172] - loss: 0.1142
Epoch 5 [84/172] - loss: 0.1087
Epoch 5 [85/172] - loss: 0.1458
Epoch 5 [86/172] - loss: 0.1099
Epoch 5 [87/172] - loss: 0.1238
Epoch 5 [88/172] - loss: 0.1383
Epoch 5 [89/172] - loss: 0.1179
Epoch 5 [90/172] - loss: 0.1335, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1209
Epoch 5 [92/172] - loss: 0.1122
Epoch 5 [93/172] - loss: 0.1084
Epoch 5 [94/172] - loss: 0.1111
Epoch 5 [95/172] - loss: 0.1148
Epoch 5 [96/172] - loss: 0.1088
Epoch 5 [97/172] - loss: 0.1285
Epoch 5 [98/172] - loss: 0.1072
Epoch 5 [99/172] - loss: 0.1521
Epoch 5 [100/172] - loss: 0.1144, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1115
Epoch 5 [102/172] - loss: 0.1124
Epoch 5 [103/172] - loss: 0.1202
Epoch 5 [104/172] - loss: 0.1518
Epoch 5 [105/172] - loss: 0.1927
Epoch 5 [106/172] - loss: 0.1102
Epoch 5 [107/172] - loss: 0.1106
Epoch 5 [108/172] - loss: 0.1703
Epoch 5 [109/172] - loss: 0.1083
Epoch 5 [110/172] - loss: 0.1114, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1183
Epoch 5 [112/172] - loss: 0.1070

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2127, log_difficulty=0.1929, weight=1.9644
neutral: count=7825.0, difficulty=0.1543, log_difficulty=0.1435, weight=1.7176
negative: count=8780.0, difficulty=0.1961, log_difficulty=0.1791, weight=1.8955

当前batch的pt分布：
positive: min=0.2726, max=0.9979, mean=0.8475
neutral: min=0.9615, max=0.9961, mean=0.9821
negative: min=0.9892, max=0.9995, mean=0.9972

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1135
焦点损失: 0.0308
边界损失: 0.1736
总损失: 0.1453
Epoch 5 [113/172] - loss: 0.1453
Epoch 5 [114/172] - loss: 0.1185
Epoch 5 [115/172] - loss: 0.1177
Epoch 5 [116/172] - loss: 0.1083
Epoch 5 [117/172] - loss: 0.1172
Epoch 5 [118/172] - loss: 0.1179
Epoch 5 [119/172] - loss: 0.1086
Epoch 5 [120/172] - loss: 0.1275, acc: 0.9688
Epoch 5 [121/172] - loss: 0.1136
Epoch 5 [122/172] - loss: 0.1080
Epoch 5 [123/172] - loss: 0.1085
Epoch 5 [124/172] - loss: 0.1082
Epoch 5 [125/172] - loss: 0.1092
Epoch 5 [126/172] - loss: 0.1093
Epoch 5 [127/172] - loss: 0.1110
Epoch 5 [128/172] - loss: 0.1150
Epoch 5 [129/172] - loss: 0.1371
Epoch 5 [130/172] - loss: 0.1085, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1136
Epoch 5 [132/172] - loss: 0.1306
Epoch 5 [133/172] - loss: 0.1460
Epoch 5 [134/172] - loss: 0.1291
Epoch 5 [135/172] - loss: 0.1081
Epoch 5 [136/172] - loss: 0.1083
Epoch 5 [137/172] - loss: 0.1187
Epoch 5 [138/172] - loss: 0.1368
Epoch 5 [139/172] - loss: 0.2059
Epoch 5 [140/172] - loss: 0.1153, acc: 1.0000
Epoch 5 [141/172] - loss: 0.1238
Epoch 5 [142/172] - loss: 0.1088
Epoch 5 [143/172] - loss: 0.1077
Epoch 5 [144/172] - loss: 0.1065
Epoch 5 [145/172] - loss: 0.1255
Epoch 5 [146/172] - loss: 0.1065
Epoch 5 [147/172] - loss: 0.1211
Epoch 5 [148/172] - loss: 0.1103
Epoch 5 [149/172] - loss: 0.1105
Epoch 5 [150/172] - loss: 0.1346, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1085
Epoch 5 [152/172] - loss: 0.1079
Epoch 5 [153/172] - loss: 0.1074
Epoch 5 [154/172] - loss: 0.1091
Epoch 5 [155/172] - loss: 0.1104
Epoch 5 [156/172] - loss: 0.1237
Epoch 5 [157/172] - loss: 0.1105
Epoch 5 [158/172] - loss: 0.1077
Epoch 5 [159/172] - loss: 0.1072
Epoch 5 [160/172] - loss: 0.1096, acc: 1.0000
Epoch 5 [161/172] - loss: 0.1089
Epoch 5 [162/172] - loss: 0.1290
Epoch 5 [163/172] - loss: 0.1600
Epoch 5 [164/172] - loss: 0.1062
Epoch 5 [165/172] - loss: 0.1713
Epoch 5 [166/172] - loss: 0.1289
Epoch 5 [167/172] - loss: 0.1093
Epoch 5 [168/172] - loss: 0.1080
Epoch 5 [169/172] - loss: 0.1097
Epoch 5 [170/172] - loss: 0.1090, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1113
Epoch 5 [172/172] - loss: 0.1181

类别准确率:
positive: 0.8415 (393/467)
neutral: 0.2892 (24/83)
negative: 0.5880 (147/250)

Epoch 5/10
Train Loss: 0.1190, Train Acc: 0.9939
Val Loss: 1.0018, Val Acc: 0.7050
Early stopping triggered!
Best validation accuracy: 0.7050

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_060917-ri7r0gt8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.35_Multimodal_iterations_20250118_060916
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/ri7r0gt8
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█
wandb:  train_acc ▁▁▁▄▅▅▆▅▆▆▆▆▇▇▇▇▇█▇▇█▇█▆▇▇█▇█▇██████████
wandb: train_loss █▅▅▃▅▄▄▄▃▂▃▃▂▃▂▂▂▂▁▁▁▂▁▁▂▁▃▁▁▃▁▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 858
wandb:  train_acc 1
wandb: train_loss 0.10898
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.35_Multimodal_iterations_20250118_060916 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/ri7r0gt8
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_060917-ri7r0gt8/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_061704-yplzikv6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.35_Multimodal_epochs_20250118_061704
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/yplzikv6
wandb: uploading wandb-metadata.json; uploading requirements.txt; uploading history steps 0-0, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▃▅▆█
wandb:  train_acc ▁▅▇▇█
wandb: train_loss █▄▂▁▁
wandb:    val_acc ▁█▅██
wandb:   val_loss ▁▅▄██
wandb: 
wandb: Run summary:
wandb:      epoch 5
wandb:  train_acc 0.99394
wandb: train_loss 0.11903
wandb:    val_acc 0.705
wandb:   val_loss 1.00177
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.35_Multimodal_epochs_20250118_061704 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/yplzikv6
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_061704-yplzikv6/logs

