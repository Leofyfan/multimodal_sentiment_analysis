=== 命令 ===
python main.py --loss_type ce --alpha 0.25 --beta 0.75 --neural_init_weight 0.5 --dropout 0.15 --name loss_ce_alpha0.25_beta0.75_weight0.5_dropout0.15 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_ce_alpha0.25_beta0.75_weight0.5_dropout0.15
text_dim: 128
image_dim: 256
dropout: 0.15
loss_type: ce
alpha: 0.25
beta: 0.75
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda
Epoch 1 [1/172] - loss: 1.1572, acc: 0.3125
Epoch 1 [2/172] - loss: 1.0976
Epoch 1 [3/172] - loss: 1.0342
Epoch 1 [4/172] - loss: 1.1911
Epoch 1 [5/172] - loss: 1.1725
Epoch 1 [6/172] - loss: 1.2111
Epoch 1 [7/172] - loss: 1.1252
Epoch 1 [8/172] - loss: 1.1796
Epoch 1 [9/172] - loss: 1.0571
Epoch 1 [10/172] - loss: 1.1237, acc: 0.4375
Epoch 1 [11/172] - loss: 1.1335
Epoch 1 [12/172] - loss: 1.1051
Epoch 1 [13/172] - loss: 1.0010
Epoch 1 [14/172] - loss: 1.0772
Epoch 1 [15/172] - loss: 1.1143
Epoch 1 [16/172] - loss: 0.9447
Epoch 1 [17/172] - loss: 1.0265
Epoch 1 [18/172] - loss: 1.0386
Epoch 1 [19/172] - loss: 0.9808
Epoch 1 [20/172] - loss: 1.1507, acc: 0.4062
Epoch 1 [21/172] - loss: 0.9862
Epoch 1 [22/172] - loss: 0.8718
Epoch 1 [23/172] - loss: 1.0482
Epoch 1 [24/172] - loss: 1.1793
Epoch 1 [25/172] - loss: 0.8380
Epoch 1 [26/172] - loss: 1.1073
Epoch 1 [27/172] - loss: 1.1592
Epoch 1 [28/172] - loss: 0.8576
Epoch 1 [29/172] - loss: 0.9534
Epoch 1 [30/172] - loss: 0.8108, acc: 0.6875
Epoch 1 [31/172] - loss: 0.9561
Epoch 1 [32/172] - loss: 0.7759
Epoch 1 [33/172] - loss: 0.9081
Epoch 1 [34/172] - loss: 0.7875
Epoch 1 [35/172] - loss: 0.9625
Epoch 1 [36/172] - loss: 0.6927
Epoch 1 [37/172] - loss: 0.9221
Epoch 1 [38/172] - loss: 0.8879
Epoch 1 [39/172] - loss: 0.7463
Epoch 1 [40/172] - loss: 0.7799, acc: 0.6562
Epoch 1 [41/172] - loss: 0.6781
Epoch 1 [42/172] - loss: 0.7919
Epoch 1 [43/172] - loss: 0.9900
Epoch 1 [44/172] - loss: 1.0127
Epoch 1 [45/172] - loss: 0.9530
Epoch 1 [46/172] - loss: 0.6664
Epoch 1 [47/172] - loss: 0.8084
Epoch 1 [48/172] - loss: 0.8837
Epoch 1 [49/172] - loss: 0.7840
Epoch 1 [50/172] - loss: 0.8480, acc: 0.5938
Epoch 1 [51/172] - loss: 0.9087
Epoch 1 [52/172] - loss: 0.9828
Epoch 1 [53/172] - loss: 0.9568
Epoch 1 [54/172] - loss: 0.9493
Epoch 1 [55/172] - loss: 0.6794
Epoch 1 [56/172] - loss: 0.6886
Epoch 1 [57/172] - loss: 0.9563
Epoch 1 [58/172] - loss: 0.6407
Epoch 1 [59/172] - loss: 0.8416
Epoch 1 [60/172] - loss: 0.5991, acc: 0.7812
Epoch 1 [61/172] - loss: 0.8585
Epoch 1 [62/172] - loss: 0.6974
Epoch 1 [63/172] - loss: 0.7973
Epoch 1 [64/172] - loss: 0.6310
Epoch 1 [65/172] - loss: 0.8421
Epoch 1 [66/172] - loss: 0.9076
Epoch 1 [67/172] - loss: 0.8596
Epoch 1 [68/172] - loss: 0.8202
Epoch 1 [69/172] - loss: 0.8359
Epoch 1 [70/172] - loss: 0.7318, acc: 0.7188
Epoch 1 [71/172] - loss: 0.5105
Epoch 1 [72/172] - loss: 0.6253
Epoch 1 [73/172] - loss: 0.7089
Epoch 1 [74/172] - loss: 0.6996
Epoch 1 [75/172] - loss: 0.3550
Epoch 1 [76/172] - loss: 0.6327
Epoch 1 [77/172] - loss: 0.7074
Epoch 1 [78/172] - loss: 0.5362
Epoch 1 [79/172] - loss: 0.6212
Epoch 1 [80/172] - loss: 0.4445, acc: 0.8125
Epoch 1 [81/172] - loss: 0.5722
Epoch 1 [82/172] - loss: 0.8017
Epoch 1 [83/172] - loss: 0.7225
Epoch 1 [84/172] - loss: 0.5255
Epoch 1 [85/172] - loss: 0.6515
Epoch 1 [86/172] - loss: 0.8769
Epoch 1 [87/172] - loss: 0.5503
Epoch 1 [88/172] - loss: 1.0159
Epoch 1 [89/172] - loss: 0.8703
Epoch 1 [90/172] - loss: 0.7986, acc: 0.6562
Epoch 1 [91/172] - loss: 0.5796
Epoch 1 [92/172] - loss: 0.5692
Epoch 1 [93/172] - loss: 0.3649
Epoch 1 [94/172] - loss: 0.4449
Epoch 1 [95/172] - loss: 0.4866
Epoch 1 [96/172] - loss: 0.6615
Epoch 1 [97/172] - loss: 0.5414
Epoch 1 [98/172] - loss: 0.3899
Epoch 1 [99/172] - loss: 0.7857
Epoch 1 [100/172] - loss: 0.6650, acc: 0.7188
Epoch 1 [101/172] - loss: 1.0569
Epoch 1 [102/172] - loss: 0.6735
Epoch 1 [103/172] - loss: 0.4665
Epoch 1 [104/172] - loss: 0.4834
Epoch 1 [105/172] - loss: 0.7383
Epoch 1 [106/172] - loss: 0.7928
Epoch 1 [107/172] - loss: 0.3988
Epoch 1 [108/172] - loss: 0.6810
Epoch 1 [109/172] - loss: 0.5559
Epoch 1 [110/172] - loss: 0.6877, acc: 0.6562
Epoch 1 [111/172] - loss: 0.7618
Epoch 1 [112/172] - loss: 0.4377
Epoch 1 [113/172] - loss: 0.3203
Epoch 1 [114/172] - loss: 0.4844
Epoch 1 [115/172] - loss: 0.5970
Epoch 1 [116/172] - loss: 0.6204
Epoch 1 [117/172] - loss: 0.4273
Epoch 1 [118/172] - loss: 0.4332
Epoch 1 [119/172] - loss: 0.4133
Epoch 1 [120/172] - loss: 0.3301, acc: 0.8750
Epoch 1 [121/172] - loss: 0.4516
Epoch 1 [122/172] - loss: 0.5743
Epoch 1 [123/172] - loss: 0.4048
Epoch 1 [124/172] - loss: 0.4604
Epoch 1 [125/172] - loss: 0.3750
Epoch 1 [126/172] - loss: 0.7570
Epoch 1 [127/172] - loss: 0.3837
Epoch 1 [128/172] - loss: 0.3711
Epoch 1 [129/172] - loss: 0.6673
Epoch 1 [130/172] - loss: 0.3938, acc: 0.7812
Epoch 1 [131/172] - loss: 0.2738
Epoch 1 [132/172] - loss: 0.4868
Epoch 1 [133/172] - loss: 0.6239
Epoch 1 [134/172] - loss: 0.4498
Epoch 1 [135/172] - loss: 0.6034
Epoch 1 [136/172] - loss: 0.4095
Epoch 1 [137/172] - loss: 0.5224
Epoch 1 [138/172] - loss: 0.4135
Epoch 1 [139/172] - loss: 0.3484
Epoch 1 [140/172] - loss: 0.4040, acc: 0.8750
Epoch 1 [141/172] - loss: 0.4846
Epoch 1 [142/172] - loss: 0.5502
Epoch 1 [143/172] - loss: 0.4361
Epoch 1 [144/172] - loss: 0.3240
Epoch 1 [145/172] - loss: 0.4622
Epoch 1 [146/172] - loss: 0.5697
Epoch 1 [147/172] - loss: 0.7092
Epoch 1 [148/172] - loss: 0.5710
Epoch 1 [149/172] - loss: 0.2941
Epoch 1 [150/172] - loss: 0.5592, acc: 0.7188
Epoch 1 [151/172] - loss: 0.6124
Epoch 1 [152/172] - loss: 0.4734
Epoch 1 [153/172] - loss: 0.3440
Epoch 1 [154/172] - loss: 0.4151
Epoch 1 [155/172] - loss: 0.4631
Epoch 1 [156/172] - loss: 0.8005
Epoch 1 [157/172] - loss: 0.6636
Epoch 1 [158/172] - loss: 0.4664
Epoch 1 [159/172] - loss: 0.6897
Epoch 1 [160/172] - loss: 0.4191, acc: 0.8438
Epoch 1 [161/172] - loss: 0.3518
Epoch 1 [162/172] - loss: 0.5000
Epoch 1 [163/172] - loss: 0.5121
Epoch 1 [164/172] - loss: 0.5261
Epoch 1 [165/172] - loss: 0.3867
Epoch 1 [166/172] - loss: 0.3687
Epoch 1 [167/172] - loss: 0.4351
Epoch 1 [168/172] - loss: 0.4674
Epoch 1 [169/172] - loss: 0.5180
Epoch 1 [170/172] - loss: 0.3051, acc: 0.8438
Epoch 1 [171/172] - loss: 0.4657
Epoch 1 [172/172] - loss: 0.4289

类别准确率:
positive: 0.6231 (291/467)
neutral: 0.6506 (54/83)
negative: 0.6160 (154/250)

Epoch 1/10
Train Loss: 0.4690, Train Acc: 0.8101
Val Loss: 0.9089, Val Acc: 0.6238
Epoch 2 [1/172] - loss: 0.2921, acc: 0.8438
Epoch 2 [2/172] - loss: 0.2570
Epoch 2 [3/172] - loss: 0.2144
Epoch 2 [4/172] - loss: 0.3937
Epoch 2 [5/172] - loss: 0.4828
Epoch 2 [6/172] - loss: 0.3530
Epoch 2 [7/172] - loss: 0.2770
Epoch 2 [8/172] - loss: 0.3878
Epoch 2 [9/172] - loss: 0.3764
Epoch 2 [10/172] - loss: 0.3062, acc: 0.9688
Epoch 2 [11/172] - loss: 0.2447
Epoch 2 [12/172] - loss: 0.2520
Epoch 2 [13/172] - loss: 0.4142
Epoch 2 [14/172] - loss: 0.2586
Epoch 2 [15/172] - loss: 0.3657
Epoch 2 [16/172] - loss: 0.3852
Epoch 2 [17/172] - loss: 0.5220
Epoch 2 [18/172] - loss: 0.4733
Epoch 2 [19/172] - loss: 0.2043
Epoch 2 [20/172] - loss: 0.1818, acc: 0.9062
Epoch 2 [21/172] - loss: 0.2761
Epoch 2 [22/172] - loss: 0.2426
Epoch 2 [23/172] - loss: 0.0865
Epoch 2 [24/172] - loss: 0.5596
Epoch 2 [25/172] - loss: 0.2948
Epoch 2 [26/172] - loss: 0.1350
Epoch 2 [27/172] - loss: 0.2715
Epoch 2 [28/172] - loss: 0.2982
Epoch 2 [29/172] - loss: 0.2380
Epoch 2 [30/172] - loss: 0.3080, acc: 0.8750
Epoch 2 [31/172] - loss: 0.2693
Epoch 2 [32/172] - loss: 0.2998
Epoch 2 [33/172] - loss: 0.2529
Epoch 2 [34/172] - loss: 0.2365
Epoch 2 [35/172] - loss: 0.1590
Epoch 2 [36/172] - loss: 0.3697
Epoch 2 [37/172] - loss: 0.1456
Epoch 2 [38/172] - loss: 0.2488
Epoch 2 [39/172] - loss: 0.3322
Epoch 2 [40/172] - loss: 0.2711, acc: 0.8438
Epoch 2 [41/172] - loss: 0.2007
Epoch 2 [42/172] - loss: 0.1704
Epoch 2 [43/172] - loss: 0.2108
Epoch 2 [44/172] - loss: 0.4891
Epoch 2 [45/172] - loss: 0.1595
Epoch 2 [46/172] - loss: 0.1783
Epoch 2 [47/172] - loss: 0.4510
Epoch 2 [48/172] - loss: 0.2860
Epoch 2 [49/172] - loss: 0.2047
Epoch 2 [50/172] - loss: 0.3536, acc: 0.9062
Epoch 2 [51/172] - loss: 0.2735
Epoch 2 [52/172] - loss: 0.1146
Epoch 2 [53/172] - loss: 0.1998
Epoch 2 [54/172] - loss: 0.1576
Epoch 2 [55/172] - loss: 0.4182
Epoch 2 [56/172] - loss: 0.2433
Epoch 2 [57/172] - loss: 0.1212
Epoch 2 [58/172] - loss: 0.2459
Epoch 2 [59/172] - loss: 0.4113
Epoch 2 [60/172] - loss: 0.2284, acc: 0.9062
Epoch 2 [61/172] - loss: 0.1160
Epoch 2 [62/172] - loss: 0.1817
Epoch 2 [63/172] - loss: 0.3021
Epoch 2 [64/172] - loss: 0.1951
Epoch 2 [65/172] - loss: 0.2522
Epoch 2 [66/172] - loss: 0.2273
Epoch 2 [67/172] - loss: 0.1669
Epoch 2 [68/172] - loss: 0.4118
Epoch 2 [69/172] - loss: 0.1496
Epoch 2 [70/172] - loss: 0.4588, acc: 0.8750
Epoch 2 [71/172] - loss: 0.4342
Epoch 2 [72/172] - loss: 0.3698
Epoch 2 [73/172] - loss: 0.2870
Epoch 2 [74/172] - loss: 0.1626
Epoch 2 [75/172] - loss: 0.3469
Epoch 2 [76/172] - loss: 0.3049
Epoch 2 [77/172] - loss: 0.3114
Epoch 2 [78/172] - loss: 0.2513
Epoch 2 [79/172] - loss: 0.2479
Epoch 2 [80/172] - loss: 0.0906, acc: 1.0000
Epoch 2 [81/172] - loss: 0.1332
Epoch 2 [82/172] - loss: 0.1051
Epoch 2 [83/172] - loss: 0.2523
Epoch 2 [84/172] - loss: 0.3419
Epoch 2 [85/172] - loss: 0.3670
Epoch 2 [86/172] - loss: 0.3368
Epoch 2 [87/172] - loss: 0.6999
Epoch 2 [88/172] - loss: 0.1938
Epoch 2 [89/172] - loss: 0.0720
Epoch 2 [90/172] - loss: 0.2077, acc: 0.9062
Epoch 2 [91/172] - loss: 0.1057
Epoch 2 [92/172] - loss: 0.2623
Epoch 2 [93/172] - loss: 0.2350
Epoch 2 [94/172] - loss: 0.1245
Epoch 2 [95/172] - loss: 0.4205
Epoch 2 [96/172] - loss: 0.1034
Epoch 2 [97/172] - loss: 0.2098
Epoch 2 [98/172] - loss: 0.1682
Epoch 2 [99/172] - loss: 0.1830
Epoch 2 [100/172] - loss: 0.3485, acc: 0.8750
Epoch 2 [101/172] - loss: 0.1130
Epoch 2 [102/172] - loss: 0.1444
Epoch 2 [103/172] - loss: 0.3583
Epoch 2 [104/172] - loss: 0.1803
Epoch 2 [105/172] - loss: 0.0964
Epoch 2 [106/172] - loss: 0.1787
Epoch 2 [107/172] - loss: 0.1094
Epoch 2 [108/172] - loss: 0.4679
Epoch 2 [109/172] - loss: 0.1284
Epoch 2 [110/172] - loss: 0.3142, acc: 0.8750
Epoch 2 [111/172] - loss: 0.0957
Epoch 2 [112/172] - loss: 0.1386
Epoch 2 [113/172] - loss: 0.0801
Epoch 2 [114/172] - loss: 0.2883
Epoch 2 [115/172] - loss: 0.2658
Epoch 2 [116/172] - loss: 0.1209
Epoch 2 [117/172] - loss: 0.5633
Epoch 2 [118/172] - loss: 0.1756
Epoch 2 [119/172] - loss: 0.1896
Epoch 2 [120/172] - loss: 0.1214, acc: 0.9688
Epoch 2 [121/172] - loss: 0.1039
Epoch 2 [122/172] - loss: 0.5530
Epoch 2 [123/172] - loss: 0.1411
Epoch 2 [124/172] - loss: 0.1558
Epoch 2 [125/172] - loss: 0.2237
Epoch 2 [126/172] - loss: 0.2053
Epoch 2 [127/172] - loss: 0.1331
Epoch 2 [128/172] - loss: 0.0966
Epoch 2 [129/172] - loss: 0.1172
Epoch 2 [130/172] - loss: 0.2886, acc: 0.8438
Epoch 2 [131/172] - loss: 0.1513
Epoch 2 [132/172] - loss: 0.1942
Epoch 2 [133/172] - loss: 0.1157
Epoch 2 [134/172] - loss: 0.2964
Epoch 2 [135/172] - loss: 0.3361
Epoch 2 [136/172] - loss: 0.1542
Epoch 2 [137/172] - loss: 0.0581
Epoch 2 [138/172] - loss: 0.0913
Epoch 2 [139/172] - loss: 0.2688
Epoch 2 [140/172] - loss: 0.1535, acc: 0.9375
Epoch 2 [141/172] - loss: 0.2039
Epoch 2 [142/172] - loss: 0.1106
Epoch 2 [143/172] - loss: 0.3206
Epoch 2 [144/172] - loss: 0.2329
Epoch 2 [145/172] - loss: 0.4473
Epoch 2 [146/172] - loss: 0.2042
Epoch 2 [147/172] - loss: 0.2011
Epoch 2 [148/172] - loss: 0.1436
Epoch 2 [149/172] - loss: 0.2575
Epoch 2 [150/172] - loss: 0.1680, acc: 0.9375
Epoch 2 [151/172] - loss: 0.1705
Epoch 2 [152/172] - loss: 0.1722
Epoch 2 [153/172] - loss: 0.2164
Epoch 2 [154/172] - loss: 0.1108
Epoch 2 [155/172] - loss: 0.2747
Epoch 2 [156/172] - loss: 0.1503
Epoch 2 [157/172] - loss: 0.0800
Epoch 2 [158/172] - loss: 0.2052
Epoch 2 [159/172] - loss: 0.1510
Epoch 2 [160/172] - loss: 0.3125, acc: 0.9062
Epoch 2 [161/172] - loss: 0.1150
Epoch 2 [162/172] - loss: 0.1082
Epoch 2 [163/172] - loss: 0.5833
Epoch 2 [164/172] - loss: 0.1086
Epoch 2 [165/172] - loss: 0.3306
Epoch 2 [166/172] - loss: 0.3200
Epoch 2 [167/172] - loss: 0.3655
Epoch 2 [168/172] - loss: 0.1624
Epoch 2 [169/172] - loss: 0.0785
Epoch 2 [170/172] - loss: 0.2264, acc: 0.9062
Epoch 2 [171/172] - loss: 0.2847
Epoch 2 [172/172] - loss: 0.3432

类别准确率:
positive: 0.8887 (415/467)
neutral: 0.2410 (20/83)
negative: 0.5640 (141/250)

Epoch 2/10
Train Loss: 0.2359, Train Acc: 0.9394
Val Loss: 0.8726, Val Acc: 0.7200
Epoch 3 [1/172] - loss: 0.2073, acc: 0.9062
Epoch 3 [2/172] - loss: 0.1649
Epoch 3 [3/172] - loss: 0.0639
Epoch 3 [4/172] - loss: 0.1765
Epoch 3 [5/172] - loss: 0.2236
Epoch 3 [6/172] - loss: 0.0610
Epoch 3 [7/172] - loss: 0.0881
Epoch 3 [8/172] - loss: 0.1116
Epoch 3 [9/172] - loss: 0.2350
Epoch 3 [10/172] - loss: 0.1454, acc: 0.9375
Epoch 3 [11/172] - loss: 0.0638
Epoch 3 [12/172] - loss: 0.0587
Epoch 3 [13/172] - loss: 0.0804
Epoch 3 [14/172] - loss: 0.1182
Epoch 3 [15/172] - loss: 0.1064
Epoch 3 [16/172] - loss: 0.2407
Epoch 3 [17/172] - loss: 0.1102
Epoch 3 [18/172] - loss: 0.1869
Epoch 3 [19/172] - loss: 0.0763
Epoch 3 [20/172] - loss: 0.0868, acc: 0.9688
Epoch 3 [21/172] - loss: 0.0529
Epoch 3 [22/172] - loss: 0.3801
Epoch 3 [23/172] - loss: 0.1107
Epoch 3 [24/172] - loss: 0.0932
Epoch 3 [25/172] - loss: 0.0484
Epoch 3 [26/172] - loss: 0.1358
Epoch 3 [27/172] - loss: 0.0921
Epoch 3 [28/172] - loss: 0.0797
Epoch 3 [29/172] - loss: 0.2359
Epoch 3 [30/172] - loss: 0.2078, acc: 0.8438
Epoch 3 [31/172] - loss: 0.0806
Epoch 3 [32/172] - loss: 0.0910
Epoch 3 [33/172] - loss: 0.0799
Epoch 3 [34/172] - loss: 0.1054
Epoch 3 [35/172] - loss: 0.1408
Epoch 3 [36/172] - loss: 0.0429
Epoch 3 [37/172] - loss: 0.0977
Epoch 3 [38/172] - loss: 0.0686
Epoch 3 [39/172] - loss: 0.0497
Epoch 3 [40/172] - loss: 0.1181, acc: 0.9375
Epoch 3 [41/172] - loss: 0.0468
Epoch 3 [42/172] - loss: 0.1067
Epoch 3 [43/172] - loss: 0.0300
Epoch 3 [44/172] - loss: 0.0521
Epoch 3 [45/172] - loss: 0.1614
Epoch 3 [46/172] - loss: 0.1249
Epoch 3 [47/172] - loss: 0.0320
Epoch 3 [48/172] - loss: 0.2895
Epoch 3 [49/172] - loss: 0.0433
Epoch 3 [50/172] - loss: 0.1504, acc: 0.9688
Epoch 3 [51/172] - loss: 0.0898
Epoch 3 [52/172] - loss: 0.1833
Epoch 3 [53/172] - loss: 0.0482
Epoch 3 [54/172] - loss: 0.1195
Epoch 3 [55/172] - loss: 0.1391
Epoch 3 [56/172] - loss: 0.0512
Epoch 3 [57/172] - loss: 0.4561
Epoch 3 [58/172] - loss: 0.2173
Epoch 3 [59/172] - loss: 0.0547
Epoch 3 [60/172] - loss: 0.0598, acc: 1.0000
Epoch 3 [61/172] - loss: 0.0463
Epoch 3 [62/172] - loss: 0.1339
Epoch 3 [63/172] - loss: 0.0341
Epoch 3 [64/172] - loss: 0.1579
Epoch 3 [65/172] - loss: 0.0932
Epoch 3 [66/172] - loss: 0.2854
Epoch 3 [67/172] - loss: 0.0564
Epoch 3 [68/172] - loss: 0.0347
Epoch 3 [69/172] - loss: 0.1649
Epoch 3 [70/172] - loss: 0.0465, acc: 1.0000
Epoch 3 [71/172] - loss: 0.0483
Epoch 3 [72/172] - loss: 0.2722
Epoch 3 [73/172] - loss: 0.0478
Epoch 3 [74/172] - loss: 0.1666
Epoch 3 [75/172] - loss: 0.1285
Epoch 3 [76/172] - loss: 0.0386
Epoch 3 [77/172] - loss: 0.1652
Epoch 3 [78/172] - loss: 0.2547
Epoch 3 [79/172] - loss: 0.0690
Epoch 3 [80/172] - loss: 0.1630, acc: 0.9375
Epoch 3 [81/172] - loss: 0.1145
Epoch 3 [82/172] - loss: 0.1721
Epoch 3 [83/172] - loss: 0.0568
Epoch 3 [84/172] - loss: 0.0790
Epoch 3 [85/172] - loss: 0.1102
Epoch 3 [86/172] - loss: 0.0479
Epoch 3 [87/172] - loss: 0.1709
Epoch 3 [88/172] - loss: 0.1093
Epoch 3 [89/172] - loss: 0.0968
Epoch 3 [90/172] - loss: 0.0395, acc: 1.0000
Epoch 3 [91/172] - loss: 0.0880
Epoch 3 [92/172] - loss: 0.1040
Epoch 3 [93/172] - loss: 0.2098
Epoch 3 [94/172] - loss: 0.1137
Epoch 3 [95/172] - loss: 0.0239
Epoch 3 [96/172] - loss: 0.0624
Epoch 3 [97/172] - loss: 0.0814
Epoch 3 [98/172] - loss: 0.1352
Epoch 3 [99/172] - loss: 0.0290
Epoch 3 [100/172] - loss: 0.2223, acc: 0.9375
Epoch 3 [101/172] - loss: 0.2207
Epoch 3 [102/172] - loss: 0.0267
Epoch 3 [103/172] - loss: 0.1848
Epoch 3 [104/172] - loss: 0.0348
Epoch 3 [105/172] - loss: 0.0225
Epoch 3 [106/172] - loss: 0.1114
Epoch 3 [107/172] - loss: 0.0402
Epoch 3 [108/172] - loss: 0.0687
Epoch 3 [109/172] - loss: 0.0274
Epoch 3 [110/172] - loss: 0.1428, acc: 0.9375
Epoch 3 [111/172] - loss: 0.0927
Epoch 3 [112/172] - loss: 0.0686
Epoch 3 [113/172] - loss: 0.0229
Epoch 3 [114/172] - loss: 0.0838
Epoch 3 [115/172] - loss: 0.1486
Epoch 3 [116/172] - loss: 0.0582
Epoch 3 [117/172] - loss: 0.0636
Epoch 3 [118/172] - loss: 0.0855
Epoch 3 [119/172] - loss: 0.0885
Epoch 3 [120/172] - loss: 0.2204, acc: 0.9375
Epoch 3 [121/172] - loss: 0.1076
Epoch 3 [122/172] - loss: 0.0612
Epoch 3 [123/172] - loss: 0.0397
Epoch 3 [124/172] - loss: 0.1418
Epoch 3 [125/172] - loss: 0.0646
Epoch 3 [126/172] - loss: 0.3636
Epoch 3 [127/172] - loss: 0.1087
Epoch 3 [128/172] - loss: 0.0247
Epoch 3 [129/172] - loss: 0.0335
Epoch 3 [130/172] - loss: 0.0507, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1291
Epoch 3 [132/172] - loss: 0.0815
Epoch 3 [133/172] - loss: 0.0197
Epoch 3 [134/172] - loss: 0.0254
Epoch 3 [135/172] - loss: 0.1131
Epoch 3 [136/172] - loss: 0.1454
Epoch 3 [137/172] - loss: 0.0476
Epoch 3 [138/172] - loss: 0.1481
Epoch 3 [139/172] - loss: 0.0407
Epoch 3 [140/172] - loss: 0.1830, acc: 0.9375
Epoch 3 [141/172] - loss: 0.1691
Epoch 3 [142/172] - loss: 0.3628
Epoch 3 [143/172] - loss: 0.1816
Epoch 3 [144/172] - loss: 0.2977
Epoch 3 [145/172] - loss: 0.0734
Epoch 3 [146/172] - loss: 0.0345
Epoch 3 [147/172] - loss: 0.1485
Epoch 3 [148/172] - loss: 0.2335
Epoch 3 [149/172] - loss: 0.1517
Epoch 3 [150/172] - loss: 0.1062, acc: 0.9375
Epoch 3 [151/172] - loss: 0.5536
Epoch 3 [152/172] - loss: 0.2826
Epoch 3 [153/172] - loss: 0.0616
Epoch 3 [154/172] - loss: 0.1573
Epoch 3 [155/172] - loss: 0.0299
Epoch 3 [156/172] - loss: 0.0931
Epoch 3 [157/172] - loss: 0.1088
Epoch 3 [158/172] - loss: 0.2636
Epoch 3 [159/172] - loss: 0.0774
Epoch 3 [160/172] - loss: 0.2856, acc: 0.9062
Epoch 3 [161/172] - loss: 0.2189
Epoch 3 [162/172] - loss: 0.2145
Epoch 3 [163/172] - loss: 0.1476
Epoch 3 [164/172] - loss: 0.0437
Epoch 3 [165/172] - loss: 0.0761
Epoch 3 [166/172] - loss: 0.1176
Epoch 3 [167/172] - loss: 0.0863
Epoch 3 [168/172] - loss: 0.0737
Epoch 3 [169/172] - loss: 0.1058
Epoch 3 [170/172] - loss: 0.1469, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1476
Epoch 3 [172/172] - loss: 0.0633

类别准确率:
positive: 0.7687 (359/467)
neutral: 0.2530 (21/83)
negative: 0.7120 (178/250)

Epoch 3/10
Train Loss: 0.1361, Train Acc: 0.9556
Val Loss: 1.0160, Val Acc: 0.6975
Epoch 4 [1/172] - loss: 0.1010, acc: 0.9688
Epoch 4 [2/172] - loss: 0.0308
Epoch 4 [3/172] - loss: 0.0618
Epoch 4 [4/172] - loss: 0.0260
Epoch 4 [5/172] - loss: 0.1069
Epoch 4 [6/172] - loss: 0.0148
Epoch 4 [7/172] - loss: 0.0350
Epoch 4 [8/172] - loss: 0.0587
Epoch 4 [9/172] - loss: 0.1382
Epoch 4 [10/172] - loss: 0.0436, acc: 1.0000
Epoch 4 [11/172] - loss: 0.0673
Epoch 4 [12/172] - loss: 0.1496
Epoch 4 [13/172] - loss: 0.0844
Epoch 4 [14/172] - loss: 0.1860
Epoch 4 [15/172] - loss: 0.0515
Epoch 4 [16/172] - loss: 0.0302
Epoch 4 [17/172] - loss: 0.0480
Epoch 4 [18/172] - loss: 0.1132
Epoch 4 [19/172] - loss: 0.0156
Epoch 4 [20/172] - loss: 0.0434, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1090
Epoch 4 [22/172] - loss: 0.0731
Epoch 4 [23/172] - loss: 0.1055
Epoch 4 [24/172] - loss: 0.0318
Epoch 4 [25/172] - loss: 0.0231
Epoch 4 [26/172] - loss: 0.2637
Epoch 4 [27/172] - loss: 0.0201
Epoch 4 [28/172] - loss: 0.0539
Epoch 4 [29/172] - loss: 0.0387
Epoch 4 [30/172] - loss: 0.1376, acc: 0.9688
Epoch 4 [31/172] - loss: 0.0820
Epoch 4 [32/172] - loss: 0.0229
Epoch 4 [33/172] - loss: 0.0283
Epoch 4 [34/172] - loss: 0.0646
Epoch 4 [35/172] - loss: 0.0737
Epoch 4 [36/172] - loss: 0.0391
Epoch 4 [37/172] - loss: 0.0201
Epoch 4 [38/172] - loss: 0.0181
Epoch 4 [39/172] - loss: 0.2724
Epoch 4 [40/172] - loss: 0.1451, acc: 0.9375
Epoch 4 [41/172] - loss: 0.0272
Epoch 4 [42/172] - loss: 0.2285
Epoch 4 [43/172] - loss: 0.2630
Epoch 4 [44/172] - loss: 0.1246
Epoch 4 [45/172] - loss: 0.0253
Epoch 4 [46/172] - loss: 0.0806
Epoch 4 [47/172] - loss: 0.0293
Epoch 4 [48/172] - loss: 0.0285
Epoch 4 [49/172] - loss: 0.0320
Epoch 4 [50/172] - loss: 0.1200, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0348
Epoch 4 [52/172] - loss: 0.1581
Epoch 4 [53/172] - loss: 0.0153
Epoch 4 [54/172] - loss: 0.1242
Epoch 4 [55/172] - loss: 0.1900
Epoch 4 [56/172] - loss: 0.0716
Epoch 4 [57/172] - loss: 0.0619
Epoch 4 [58/172] - loss: 0.0201
Epoch 4 [59/172] - loss: 0.0476
Epoch 4 [60/172] - loss: 0.0760, acc: 0.9688
Epoch 4 [61/172] - loss: 0.0853
Epoch 4 [62/172] - loss: 0.1047
Epoch 4 [63/172] - loss: 0.0384
Epoch 4 [64/172] - loss: 0.0415
Epoch 4 [65/172] - loss: 0.1202
Epoch 4 [66/172] - loss: 0.0296
Epoch 4 [67/172] - loss: 0.0600
Epoch 4 [68/172] - loss: 0.0374
Epoch 4 [69/172] - loss: 0.0701
Epoch 4 [70/172] - loss: 0.0613, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1737
Epoch 4 [72/172] - loss: 0.0552
Epoch 4 [73/172] - loss: 0.0561
Epoch 4 [74/172] - loss: 0.2224
Epoch 4 [75/172] - loss: 0.0269
Epoch 4 [76/172] - loss: 0.0119
Epoch 4 [77/172] - loss: 0.0523
Epoch 4 [78/172] - loss: 0.0256
Epoch 4 [79/172] - loss: 0.0478
Epoch 4 [80/172] - loss: 0.0184, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1448
Epoch 4 [82/172] - loss: 0.0257
Epoch 4 [83/172] - loss: 0.0207
Epoch 4 [84/172] - loss: 0.0269
Epoch 4 [85/172] - loss: 0.0956
Epoch 4 [86/172] - loss: 0.1531
Epoch 4 [87/172] - loss: 0.0238
Epoch 4 [88/172] - loss: 0.0325
Epoch 4 [89/172] - loss: 0.0343
Epoch 4 [90/172] - loss: 0.0247, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1816
Epoch 4 [92/172] - loss: 0.2525
Epoch 4 [93/172] - loss: 0.0250
Epoch 4 [94/172] - loss: 0.0386
Epoch 4 [95/172] - loss: 0.0622
Epoch 4 [96/172] - loss: 0.0445
Epoch 4 [97/172] - loss: 0.0206
Epoch 4 [98/172] - loss: 0.0197
Epoch 4 [99/172] - loss: 0.0388
Epoch 4 [100/172] - loss: 0.0371, acc: 1.0000
Epoch 4 [101/172] - loss: 0.1058
Epoch 4 [102/172] - loss: 0.1590
Epoch 4 [103/172] - loss: 0.0217
Epoch 4 [104/172] - loss: 0.0130
Epoch 4 [105/172] - loss: 0.2208
Epoch 4 [106/172] - loss: 0.0147
Epoch 4 [107/172] - loss: 0.0116
Epoch 4 [108/172] - loss: 0.0833
Epoch 4 [109/172] - loss: 0.0189
Epoch 4 [110/172] - loss: 0.3767, acc: 0.8750
Epoch 4 [111/172] - loss: 0.0358
Epoch 4 [112/172] - loss: 0.0162
Epoch 4 [113/172] - loss: 0.0184
Epoch 4 [114/172] - loss: 0.0777
Epoch 4 [115/172] - loss: 0.0237
Epoch 4 [116/172] - loss: 0.2472
Epoch 4 [117/172] - loss: 0.0319
Epoch 4 [118/172] - loss: 0.1194
Epoch 4 [119/172] - loss: 0.0146
Epoch 4 [120/172] - loss: 0.0498, acc: 0.9688
Epoch 4 [121/172] - loss: 0.1872
Epoch 4 [122/172] - loss: 0.2106
Epoch 4 [123/172] - loss: 0.0727
Epoch 4 [124/172] - loss: 0.0423
Epoch 4 [125/172] - loss: 0.0317
Epoch 4 [126/172] - loss: 0.1885
Epoch 4 [127/172] - loss: 0.0474
Epoch 4 [128/172] - loss: 0.0143
Epoch 4 [129/172] - loss: 0.0125
Epoch 4 [130/172] - loss: 0.0267, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0190
Epoch 4 [132/172] - loss: 0.0343
Epoch 4 [133/172] - loss: 0.1684
Epoch 4 [134/172] - loss: 0.0255
Epoch 4 [135/172] - loss: 0.0520
Epoch 4 [136/172] - loss: 0.1570
Epoch 4 [137/172] - loss: 0.0193
Epoch 4 [138/172] - loss: 0.0108
Epoch 4 [139/172] - loss: 0.0314
Epoch 4 [140/172] - loss: 0.0618, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1346
Epoch 4 [142/172] - loss: 0.0435
Epoch 4 [143/172] - loss: 0.0255
Epoch 4 [144/172] - loss: 0.0772
Epoch 4 [145/172] - loss: 0.3825
Epoch 4 [146/172] - loss: 0.0162
Epoch 4 [147/172] - loss: 0.1280
Epoch 4 [148/172] - loss: 0.0283
Epoch 4 [149/172] - loss: 0.0201
Epoch 4 [150/172] - loss: 0.1071, acc: 0.9688
Epoch 4 [151/172] - loss: 0.1995
Epoch 4 [152/172] - loss: 0.0237
Epoch 4 [153/172] - loss: 0.0944
Epoch 4 [154/172] - loss: 0.1166
Epoch 4 [155/172] - loss: 0.0241
Epoch 4 [156/172] - loss: 0.0783
Epoch 4 [157/172] - loss: 0.4272
Epoch 4 [158/172] - loss: 0.0148
Epoch 4 [159/172] - loss: 0.0128
Epoch 4 [160/172] - loss: 0.0203, acc: 1.0000
Epoch 4 [161/172] - loss: 0.0715
Epoch 4 [162/172] - loss: 0.0462
Epoch 4 [163/172] - loss: 0.0468
Epoch 4 [164/172] - loss: 0.0255
Epoch 4 [165/172] - loss: 0.1796
Epoch 4 [166/172] - loss: 0.0796
Epoch 4 [167/172] - loss: 0.0718
Epoch 4 [168/172] - loss: 0.0238
Epoch 4 [169/172] - loss: 0.1537
Epoch 4 [170/172] - loss: 0.0803, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0343
Epoch 4 [172/172] - loss: 0.0382

类别准确率:
positive: 0.8672 (405/467)
neutral: 0.2289 (19/83)
negative: 0.5680 (142/250)

Epoch 4/10
Train Loss: 0.0829, Train Acc: 0.9717
Val Loss: 0.9400, Val Acc: 0.7075
Epoch 5 [1/172] - loss: 0.0452, acc: 0.9688
Epoch 5 [2/172] - loss: 0.0314
Epoch 5 [3/172] - loss: 0.0217
Epoch 5 [4/172] - loss: 0.0641
Epoch 5 [5/172] - loss: 0.0179
Epoch 5 [6/172] - loss: 0.0825
Epoch 5 [7/172] - loss: 0.0316
Epoch 5 [8/172] - loss: 0.0551
Epoch 5 [9/172] - loss: 0.0597
Epoch 5 [10/172] - loss: 0.0164, acc: 1.0000
Epoch 5 [11/172] - loss: 0.0620
Epoch 5 [12/172] - loss: 0.0196
Epoch 5 [13/172] - loss: 0.1195
Epoch 5 [14/172] - loss: 0.2509
Epoch 5 [15/172] - loss: 0.0774
Epoch 5 [16/172] - loss: 0.0141
Epoch 5 [17/172] - loss: 0.1141
Epoch 5 [18/172] - loss: 0.0135
Epoch 5 [19/172] - loss: 0.1097
Epoch 5 [20/172] - loss: 0.1649, acc: 0.9375
Epoch 5 [21/172] - loss: 0.1054
Epoch 5 [22/172] - loss: 0.1524
Epoch 5 [23/172] - loss: 0.0136
Epoch 5 [24/172] - loss: 0.0193
Epoch 5 [25/172] - loss: 0.0131
Epoch 5 [26/172] - loss: 0.1094
Epoch 5 [27/172] - loss: 0.0263
Epoch 5 [28/172] - loss: 0.0119
Epoch 5 [29/172] - loss: 0.0144
Epoch 5 [30/172] - loss: 0.0237, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0238
Epoch 5 [32/172] - loss: 0.0133
Epoch 5 [33/172] - loss: 0.0147
Epoch 5 [34/172] - loss: 0.0115
Epoch 5 [35/172] - loss: 0.0149
Epoch 5 [36/172] - loss: 0.0265
Epoch 5 [37/172] - loss: 0.0278
Epoch 5 [38/172] - loss: 0.0415
Epoch 5 [39/172] - loss: 0.1257
Epoch 5 [40/172] - loss: 0.0429, acc: 0.9688
Epoch 5 [41/172] - loss: 0.0269
Epoch 5 [42/172] - loss: 0.0269
Epoch 5 [43/172] - loss: 0.0495
Epoch 5 [44/172] - loss: 0.0266
Epoch 5 [45/172] - loss: 0.0494
Epoch 5 [46/172] - loss: 0.0176
Epoch 5 [47/172] - loss: 0.0167
Epoch 5 [48/172] - loss: 0.0177
Epoch 5 [49/172] - loss: 0.0110
Epoch 5 [50/172] - loss: 0.0606, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0301
Epoch 5 [52/172] - loss: 0.0104
Epoch 5 [53/172] - loss: 0.0318
Epoch 5 [54/172] - loss: 0.0197
Epoch 5 [55/172] - loss: 0.0329
Epoch 5 [56/172] - loss: 0.0347
Epoch 5 [57/172] - loss: 0.0220
Epoch 5 [58/172] - loss: 0.0163
Epoch 5 [59/172] - loss: 0.1260
Epoch 5 [60/172] - loss: 0.0226, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0235
Epoch 5 [62/172] - loss: 0.0141
Epoch 5 [63/172] - loss: 0.1150
Epoch 5 [64/172] - loss: 0.0537
Epoch 5 [65/172] - loss: 0.0145
Epoch 5 [66/172] - loss: 0.0133
Epoch 5 [67/172] - loss: 0.0147
Epoch 5 [68/172] - loss: 0.0228
Epoch 5 [69/172] - loss: 0.0628
Epoch 5 [70/172] - loss: 0.0200, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0224
Epoch 5 [72/172] - loss: 0.0425
Epoch 5 [73/172] - loss: 0.0144
Epoch 5 [74/172] - loss: 0.0309
Epoch 5 [75/172] - loss: 0.0119
Epoch 5 [76/172] - loss: 0.0104
Epoch 5 [77/172] - loss: 0.0186
Epoch 5 [78/172] - loss: 0.1083
Epoch 5 [79/172] - loss: 0.0325
Epoch 5 [80/172] - loss: 0.0569, acc: 0.9688
Epoch 5 [81/172] - loss: 0.1543
Epoch 5 [82/172] - loss: 0.1138
Epoch 5 [83/172] - loss: 0.0454
Epoch 5 [84/172] - loss: 0.0105
Epoch 5 [85/172] - loss: 0.1239
Epoch 5 [86/172] - loss: 0.0258
Epoch 5 [87/172] - loss: 0.0272
Epoch 5 [88/172] - loss: 0.1115
Epoch 5 [89/172] - loss: 0.0169
Epoch 5 [90/172] - loss: 0.0332, acc: 1.0000
Epoch 5 [91/172] - loss: 0.0138
Epoch 5 [92/172] - loss: 0.0387
Epoch 5 [93/172] - loss: 0.0111
Epoch 5 [94/172] - loss: 0.0099
Epoch 5 [95/172] - loss: 0.0226
Epoch 5 [96/172] - loss: 0.0181
Epoch 5 [97/172] - loss: 0.0440
Epoch 5 [98/172] - loss: 0.0086
Epoch 5 [99/172] - loss: 0.1563
Epoch 5 [100/172] - loss: 0.0221, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0359
Epoch 5 [102/172] - loss: 0.0169
Epoch 5 [103/172] - loss: 0.0104
Epoch 5 [104/172] - loss: 0.0725
Epoch 5 [105/172] - loss: 0.2512
Epoch 5 [106/172] - loss: 0.0121
Epoch 5 [107/172] - loss: 0.0179
Epoch 5 [108/172] - loss: 0.1947
Epoch 5 [109/172] - loss: 0.0166
Epoch 5 [110/172] - loss: 0.0147, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0168
Epoch 5 [112/172] - loss: 0.0163
Epoch 5 [113/172] - loss: 0.0352
Epoch 5 [114/172] - loss: 0.0282
Epoch 5 [115/172] - loss: 0.0610
Epoch 5 [116/172] - loss: 0.0110
Epoch 5 [117/172] - loss: 0.0798
Epoch 5 [118/172] - loss: 0.0181
Epoch 5 [119/172] - loss: 0.0082
Epoch 5 [120/172] - loss: 0.0172, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0172
Epoch 5 [122/172] - loss: 0.0117
Epoch 5 [123/172] - loss: 0.0121
Epoch 5 [124/172] - loss: 0.0143
Epoch 5 [125/172] - loss: 0.0092
Epoch 5 [126/172] - loss: 0.0394
Epoch 5 [127/172] - loss: 0.0125
Epoch 5 [128/172] - loss: 0.0171
Epoch 5 [129/172] - loss: 0.1178
Epoch 5 [130/172] - loss: 0.0099, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0218
Epoch 5 [132/172] - loss: 0.0361
Epoch 5 [133/172] - loss: 0.1641
Epoch 5 [134/172] - loss: 0.1022
Epoch 5 [135/172] - loss: 0.0104
Epoch 5 [136/172] - loss: 0.0091
Epoch 5 [137/172] - loss: 0.0316
Epoch 5 [138/172] - loss: 0.1137
Epoch 5 [139/172] - loss: 0.0932
Epoch 5 [140/172] - loss: 0.0579, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0127
Epoch 5 [142/172] - loss: 0.0102
Epoch 5 [143/172] - loss: 0.0124
Epoch 5 [144/172] - loss: 0.0163
Epoch 5 [145/172] - loss: 0.0325
Epoch 5 [146/172] - loss: 0.0123
Epoch 5 [147/172] - loss: 0.0378
Epoch 5 [148/172] - loss: 0.0136
Epoch 5 [149/172] - loss: 0.0194
Epoch 5 [150/172] - loss: 0.1325, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0098
Epoch 5 [152/172] - loss: 0.0110
Epoch 5 [153/172] - loss: 0.0100
Epoch 5 [154/172] - loss: 0.0192
Epoch 5 [155/172] - loss: 0.0119
Epoch 5 [156/172] - loss: 0.0500
Epoch 5 [157/172] - loss: 0.0129
Epoch 5 [158/172] - loss: 0.0197
Epoch 5 [159/172] - loss: 0.0093
Epoch 5 [160/172] - loss: 0.0181, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0092
Epoch 5 [162/172] - loss: 0.0276
Epoch 5 [163/172] - loss: 0.1291
Epoch 5 [164/172] - loss: 0.0069
Epoch 5 [165/172] - loss: 0.1489
Epoch 5 [166/172] - loss: 0.0339
Epoch 5 [167/172] - loss: 0.0289
Epoch 5 [168/172] - loss: 0.0151
Epoch 5 [169/172] - loss: 0.0122
Epoch 5 [170/172] - loss: 0.0081, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0148
Epoch 5 [172/172] - loss: 0.0391

类别准确率:
positive: 0.8608 (402/467)
neutral: 0.2771 (23/83)
negative: 0.5880 (147/250)

Epoch 5/10
Train Loss: 0.0334, Train Acc: 0.9960
Val Loss: 1.0083, Val Acc: 0.7150
Early stopping triggered!
Best validation accuracy: 0.7200

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_152112-tnqwchcn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_ce_alpha0.25_beta0.75_weight0.5_dropout0.15_Multimodal_iterations_20250118_152111
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/tnqwchcn
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇█
wandb:  train_acc ▁▄▄▅▄▆▅▆▆█▇█▇▆█▇▇▆▇█▇█▇█████████████████
wandb: train_loss █▆▅▅▃▃▃▂▂▃▂▂▂▁▂▁▂▁▂▂▂▁▂▂▂▁▁▃▁▁▁▁▂▁▁▁▁▁▂▁
wandb: 
wandb: Run summary:
wandb:  iteration 858
wandb:  train_acc 1
wandb: train_loss 0.00814
wandb: 
wandb: 🚀 View run loss_ce_alpha0.25_beta0.75_weight0.5_dropout0.15_Multimodal_iterations_20250118_152111 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/tnqwchcn
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_152112-tnqwchcn/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_152845-diyd73nv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_ce_alpha0.25_beta0.75_weight0.5_dropout0.15_Multimodal_epochs_20250118_152845
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/diyd73nv
wandb: uploading history steps 0-0, summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▃▅▆█
wandb:  train_acc ▁▆▆▇█
wandb: train_loss █▄▃▂▁
wandb:    val_acc ▁█▆▇█
wandb:   val_loss ▃▁█▄█
wandb: 
wandb: Run summary:
wandb:      epoch 5
wandb:  train_acc 0.99596
wandb: train_loss 0.03337
wandb:    val_acc 0.715
wandb:   val_loss 1.00835
wandb: 
wandb: 🚀 View run loss_ce_alpha0.25_beta0.75_weight0.5_dropout0.15_Multimodal_epochs_20250118_152845 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/diyd73nv
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_152845-diyd73nv/logs

