=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 1.0 --dropout 0.3 --name loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.3 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.3
text_dim: 128
image_dim: 256
dropout: 0.3
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6849, log_difficulty=0.5217, weight=3.6086
neutral: count=7.0, difficulty=0.6655, log_difficulty=0.5101, weight=3.5506
negative: count=13.0, difficulty=0.6388, log_difficulty=0.4940, weight=3.4700

当前batch的pt分布：
positive: min=0.1807, max=0.4159, mean=0.3151
neutral: min=0.2151, max=0.4199, mean=0.3345
negative: min=0.2025, max=0.7176, mean=0.3612

当前batch准确率：
整体准确率: 0.2812
positive 准确率: 0.2500
neutral 准确率: 0.2857
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1247
焦点损失: 0.3764
边界损失: 0.8412
总损失: 1.0877
Epoch 1 [1/172] - loss: 1.0877, acc: 0.2812
Epoch 1 [2/172] - loss: 1.1279
Epoch 1 [3/172] - loss: 1.2479
Epoch 1 [4/172] - loss: 1.0699
Epoch 1 [5/172] - loss: 1.0990
Epoch 1 [6/172] - loss: 1.3328
Epoch 1 [7/172] - loss: 1.2938
Epoch 1 [8/172] - loss: 1.1969
Epoch 1 [9/172] - loss: 1.1430
Epoch 1 [10/172] - loss: 1.1100, acc: 0.4062
Epoch 1 [11/172] - loss: 0.9685
Epoch 1 [12/172] - loss: 1.1015
Epoch 1 [13/172] - loss: 1.1165
Epoch 1 [14/172] - loss: 1.0827
Epoch 1 [15/172] - loss: 1.0361
Epoch 1 [16/172] - loss: 1.0678
Epoch 1 [17/172] - loss: 1.0372
Epoch 1 [18/172] - loss: 1.1047
Epoch 1 [19/172] - loss: 1.0593
Epoch 1 [20/172] - loss: 1.0362, acc: 0.3750
Epoch 1 [21/172] - loss: 1.0244
Epoch 1 [22/172] - loss: 0.8111
Epoch 1 [23/172] - loss: 0.9475
Epoch 1 [24/172] - loss: 1.0718
Epoch 1 [25/172] - loss: 0.9114
Epoch 1 [26/172] - loss: 1.0035
Epoch 1 [27/172] - loss: 0.8998
Epoch 1 [28/172] - loss: 1.0349
Epoch 1 [29/172] - loss: 1.0675
Epoch 1 [30/172] - loss: 0.8685, acc: 0.3750
Epoch 1 [31/172] - loss: 1.1935
Epoch 1 [32/172] - loss: 0.9413
Epoch 1 [33/172] - loss: 0.7720
Epoch 1 [34/172] - loss: 0.7109
Epoch 1 [35/172] - loss: 0.8442
Epoch 1 [36/172] - loss: 0.7627
Epoch 1 [37/172] - loss: 1.0010
Epoch 1 [38/172] - loss: 0.9238
Epoch 1 [39/172] - loss: 0.7392
Epoch 1 [40/172] - loss: 0.9147, acc: 0.5625
Epoch 1 [41/172] - loss: 0.7313
Epoch 1 [42/172] - loss: 0.7740
Epoch 1 [43/172] - loss: 1.0094
Epoch 1 [44/172] - loss: 1.0161
Epoch 1 [45/172] - loss: 0.9586
Epoch 1 [46/172] - loss: 0.7847
Epoch 1 [47/172] - loss: 0.8801
Epoch 1 [48/172] - loss: 0.9262
Epoch 1 [49/172] - loss: 0.7610
Epoch 1 [50/172] - loss: 0.7890, acc: 0.5312
Epoch 1 [51/172] - loss: 0.8538
Epoch 1 [52/172] - loss: 0.8088
Epoch 1 [53/172] - loss: 0.7848
Epoch 1 [54/172] - loss: 0.7775
Epoch 1 [55/172] - loss: 0.7798
Epoch 1 [56/172] - loss: 0.8578
Epoch 1 [57/172] - loss: 0.9197
Epoch 1 [58/172] - loss: 0.6899
Epoch 1 [59/172] - loss: 0.8849
Epoch 1 [60/172] - loss: 0.6970, acc: 0.7188
Epoch 1 [61/172] - loss: 1.0593
Epoch 1 [62/172] - loss: 0.7386
Epoch 1 [63/172] - loss: 0.8909
Epoch 1 [64/172] - loss: 0.8935
Epoch 1 [65/172] - loss: 0.7496
Epoch 1 [66/172] - loss: 0.9170
Epoch 1 [67/172] - loss: 0.9124
Epoch 1 [68/172] - loss: 0.9745
Epoch 1 [69/172] - loss: 0.8215
Epoch 1 [70/172] - loss: 0.7208, acc: 0.6250
Epoch 1 [71/172] - loss: 0.6392
Epoch 1 [72/172] - loss: 0.6017
Epoch 1 [73/172] - loss: 0.5560
Epoch 1 [74/172] - loss: 0.7383
Epoch 1 [75/172] - loss: 0.5509
Epoch 1 [76/172] - loss: 0.6989
Epoch 1 [77/172] - loss: 0.7058
Epoch 1 [78/172] - loss: 0.5675
Epoch 1 [79/172] - loss: 0.6919
Epoch 1 [80/172] - loss: 0.4025, acc: 0.7812
Epoch 1 [81/172] - loss: 0.6735
Epoch 1 [82/172] - loss: 1.0506
Epoch 1 [83/172] - loss: 0.6739
Epoch 1 [84/172] - loss: 0.6814
Epoch 1 [85/172] - loss: 0.5843
Epoch 1 [86/172] - loss: 0.9477
Epoch 1 [87/172] - loss: 0.5801
Epoch 1 [88/172] - loss: 0.8334
Epoch 1 [89/172] - loss: 0.9400
Epoch 1 [90/172] - loss: 0.7412, acc: 0.6562
Epoch 1 [91/172] - loss: 0.7701
Epoch 1 [92/172] - loss: 0.7162
Epoch 1 [93/172] - loss: 0.6809
Epoch 1 [94/172] - loss: 0.5184
Epoch 1 [95/172] - loss: 0.8049
Epoch 1 [96/172] - loss: 0.6529
Epoch 1 [97/172] - loss: 0.7201
Epoch 1 [98/172] - loss: 0.5391
Epoch 1 [99/172] - loss: 0.7463
Epoch 1 [100/172] - loss: 0.7084, acc: 0.6875

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5636, log_difficulty=0.4470, weight=3.2350
neutral: count=983.0, difficulty=0.5662, log_difficulty=0.4487, weight=3.2433
negative: count=1119.0, difficulty=0.5687, log_difficulty=0.4502, weight=3.2512

当前batch的pt分布：
positive: min=0.0404, max=0.8043, mean=0.4040
neutral: min=0.4241, max=0.9672, mean=0.6474
negative: min=0.1317, max=0.6084, mean=0.3482

当前batch准确率：
整体准确率: 0.4375
positive 准确率: 0.4167
neutral 准确率: 1.0000
negative 准确率: 0.3125

损失分量：
基础交叉熵: 1.0565
焦点损失: 0.4411
边界损失: 0.5304
总损失: 0.9803
Epoch 1 [101/172] - loss: 0.9803
Epoch 1 [102/172] - loss: 0.5869
Epoch 1 [103/172] - loss: 0.5667
Epoch 1 [104/172] - loss: 0.5954
Epoch 1 [105/172] - loss: 1.0017
Epoch 1 [106/172] - loss: 0.8293
Epoch 1 [107/172] - loss: 0.6485
Epoch 1 [108/172] - loss: 0.7234
Epoch 1 [109/172] - loss: 0.6908
Epoch 1 [110/172] - loss: 0.7955, acc: 0.6875
Epoch 1 [111/172] - loss: 0.5528
Epoch 1 [112/172] - loss: 0.5461
Epoch 1 [113/172] - loss: 0.4831
Epoch 1 [114/172] - loss: 0.4705
Epoch 1 [115/172] - loss: 0.6709
Epoch 1 [116/172] - loss: 0.8560
Epoch 1 [117/172] - loss: 0.5230
Epoch 1 [118/172] - loss: 0.4545
Epoch 1 [119/172] - loss: 0.5676
Epoch 1 [120/172] - loss: 0.3802, acc: 0.7812
Epoch 1 [121/172] - loss: 0.5057
Epoch 1 [122/172] - loss: 0.6533
Epoch 1 [123/172] - loss: 0.3908
Epoch 1 [124/172] - loss: 0.6027
Epoch 1 [125/172] - loss: 0.4530
Epoch 1 [126/172] - loss: 0.6565
Epoch 1 [127/172] - loss: 0.5083
Epoch 1 [128/172] - loss: 0.3016
Epoch 1 [129/172] - loss: 0.7080
Epoch 1 [130/172] - loss: 0.5795, acc: 0.7500
Epoch 1 [131/172] - loss: 0.3641
Epoch 1 [132/172] - loss: 0.4402
Epoch 1 [133/172] - loss: 0.6356
Epoch 1 [134/172] - loss: 0.4048
Epoch 1 [135/172] - loss: 0.4537
Epoch 1 [136/172] - loss: 0.4687
Epoch 1 [137/172] - loss: 0.6709
Epoch 1 [138/172] - loss: 0.5027
Epoch 1 [139/172] - loss: 0.4280
Epoch 1 [140/172] - loss: 0.4839, acc: 0.7500
Epoch 1 [141/172] - loss: 0.5314
Epoch 1 [142/172] - loss: 0.4033
Epoch 1 [143/172] - loss: 0.4687
Epoch 1 [144/172] - loss: 0.2982
Epoch 1 [145/172] - loss: 0.6456
Epoch 1 [146/172] - loss: 0.6138
Epoch 1 [147/172] - loss: 0.6599
Epoch 1 [148/172] - loss: 0.5135
Epoch 1 [149/172] - loss: 0.4604
Epoch 1 [150/172] - loss: 0.6302, acc: 0.6562
Epoch 1 [151/172] - loss: 0.7144
Epoch 1 [152/172] - loss: 0.4370
Epoch 1 [153/172] - loss: 0.4336
Epoch 1 [154/172] - loss: 0.5107
Epoch 1 [155/172] - loss: 0.5748
Epoch 1 [156/172] - loss: 0.7407
Epoch 1 [157/172] - loss: 0.5752
Epoch 1 [158/172] - loss: 0.3584
Epoch 1 [159/172] - loss: 0.5186
Epoch 1 [160/172] - loss: 0.4047, acc: 0.8125
Epoch 1 [161/172] - loss: 0.4611
Epoch 1 [162/172] - loss: 0.5595
Epoch 1 [163/172] - loss: 0.5925
Epoch 1 [164/172] - loss: 0.7289
Epoch 1 [165/172] - loss: 0.4140
Epoch 1 [166/172] - loss: 0.6079
Epoch 1 [167/172] - loss: 0.3793
Epoch 1 [168/172] - loss: 0.6113
Epoch 1 [169/172] - loss: 0.5127
Epoch 1 [170/172] - loss: 0.4418, acc: 0.8125
Epoch 1 [171/172] - loss: 0.3256
Epoch 1 [172/172] - loss: 0.4843

类别准确率:
positive: 0.6595 (308/467)
neutral: 0.5181 (43/83)
negative: 0.7760 (194/250)

Epoch 1/10
Train Loss: 0.4985, Train Acc: 0.7616
Val Loss: 0.7358, Val Acc: 0.6813
Epoch 2 [1/172] - loss: 0.4722, acc: 0.8125
Epoch 2 [2/172] - loss: 0.3131
Epoch 2 [3/172] - loss: 0.2662
Epoch 2 [4/172] - loss: 0.4432
Epoch 2 [5/172] - loss: 0.5395
Epoch 2 [6/172] - loss: 0.3704
Epoch 2 [7/172] - loss: 0.4491
Epoch 2 [8/172] - loss: 0.3671
Epoch 2 [9/172] - loss: 0.3460
Epoch 2 [10/172] - loss: 0.4178, acc: 0.9375
Epoch 2 [11/172] - loss: 0.3149
Epoch 2 [12/172] - loss: 0.3166
Epoch 2 [13/172] - loss: 0.3925
Epoch 2 [14/172] - loss: 0.2842
Epoch 2 [15/172] - loss: 0.5238
Epoch 2 [16/172] - loss: 0.4028
Epoch 2 [17/172] - loss: 0.4112
Epoch 2 [18/172] - loss: 0.4260
Epoch 2 [19/172] - loss: 0.2921
Epoch 2 [20/172] - loss: 0.2813, acc: 0.8750
Epoch 2 [21/172] - loss: 0.3239
Epoch 2 [22/172] - loss: 0.2704
Epoch 2 [23/172] - loss: 0.2996
Epoch 2 [24/172] - loss: 0.6327
Epoch 2 [25/172] - loss: 0.3669
Epoch 2 [26/172] - loss: 0.2431
Epoch 2 [27/172] - loss: 0.2344
Epoch 2 [28/172] - loss: 0.3600

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4872, log_difficulty=0.3969, weight=2.9845
neutral: count=1952.0, difficulty=0.4535, log_difficulty=0.3740, weight=2.8699
negative: count=2216.0, difficulty=0.4908, log_difficulty=0.3993, weight=2.9967

当前batch的pt分布：
positive: min=0.3191, max=0.9871, mean=0.6806
neutral: min=0.3090, max=0.9555, mean=0.7816
negative: min=0.0387, max=0.9363, mean=0.6860

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.8889
neutral 准确率: 0.9091
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.4777
焦点损失: 0.2032
边界损失: 0.2866
总损失: 0.4465
Epoch 2 [29/172] - loss: 0.4465
Epoch 2 [30/172] - loss: 0.3231, acc: 0.8750
Epoch 2 [31/172] - loss: 0.4025
Epoch 2 [32/172] - loss: 0.3535
Epoch 2 [33/172] - loss: 0.3179
Epoch 2 [34/172] - loss: 0.3577
Epoch 2 [35/172] - loss: 0.3140
Epoch 2 [36/172] - loss: 0.4213
Epoch 2 [37/172] - loss: 0.2177
Epoch 2 [38/172] - loss: 0.2861
Epoch 2 [39/172] - loss: 0.4630
Epoch 2 [40/172] - loss: 0.5167, acc: 0.8125
Epoch 2 [41/172] - loss: 0.2546
Epoch 2 [42/172] - loss: 0.2856
Epoch 2 [43/172] - loss: 0.2673
Epoch 2 [44/172] - loss: 0.5567
Epoch 2 [45/172] - loss: 0.3407
Epoch 2 [46/172] - loss: 0.3713
Epoch 2 [47/172] - loss: 0.4143
Epoch 2 [48/172] - loss: 0.3751
Epoch 2 [49/172] - loss: 0.2683
Epoch 2 [50/172] - loss: 0.3949, acc: 0.7500
Epoch 2 [51/172] - loss: 0.4319
Epoch 2 [52/172] - loss: 0.4032
Epoch 2 [53/172] - loss: 0.2731
Epoch 2 [54/172] - loss: 0.3219
Epoch 2 [55/172] - loss: 0.3236
Epoch 2 [56/172] - loss: 0.2149
Epoch 2 [57/172] - loss: 0.2157
Epoch 2 [58/172] - loss: 0.3225
Epoch 2 [59/172] - loss: 0.3569
Epoch 2 [60/172] - loss: 0.2843, acc: 0.8438
Epoch 2 [61/172] - loss: 0.2625
Epoch 2 [62/172] - loss: 0.1952
Epoch 2 [63/172] - loss: 0.3615
Epoch 2 [64/172] - loss: 0.5845
Epoch 2 [65/172] - loss: 0.3534
Epoch 2 [66/172] - loss: 0.3301
Epoch 2 [67/172] - loss: 0.2248
Epoch 2 [68/172] - loss: 0.3277
Epoch 2 [69/172] - loss: 0.2679
Epoch 2 [70/172] - loss: 0.4743, acc: 0.8125
Epoch 2 [71/172] - loss: 0.3579
Epoch 2 [72/172] - loss: 0.2819
Epoch 2 [73/172] - loss: 0.3805
Epoch 2 [74/172] - loss: 0.2573
Epoch 2 [75/172] - loss: 0.2196
Epoch 2 [76/172] - loss: 0.3896
Epoch 2 [77/172] - loss: 0.2602
Epoch 2 [78/172] - loss: 0.3143
Epoch 2 [79/172] - loss: 0.3617
Epoch 2 [80/172] - loss: 0.2608, acc: 0.8750
Epoch 2 [81/172] - loss: 0.2928
Epoch 2 [82/172] - loss: 0.3216
Epoch 2 [83/172] - loss: 0.3013
Epoch 2 [84/172] - loss: 0.2863
Epoch 2 [85/172] - loss: 0.3607
Epoch 2 [86/172] - loss: 0.2624
Epoch 2 [87/172] - loss: 0.7215
Epoch 2 [88/172] - loss: 0.2680
Epoch 2 [89/172] - loss: 0.1864
Epoch 2 [90/172] - loss: 0.2909, acc: 0.8438
Epoch 2 [91/172] - loss: 0.1626
Epoch 2 [92/172] - loss: 0.3415
Epoch 2 [93/172] - loss: 0.2465
Epoch 2 [94/172] - loss: 0.2296
Epoch 2 [95/172] - loss: 0.4224
Epoch 2 [96/172] - loss: 0.2540
Epoch 2 [97/172] - loss: 0.2426
Epoch 2 [98/172] - loss: 0.2513
Epoch 2 [99/172] - loss: 0.2014
Epoch 2 [100/172] - loss: 0.3122, acc: 0.8750
Epoch 2 [101/172] - loss: 0.2966
Epoch 2 [102/172] - loss: 0.1709
Epoch 2 [103/172] - loss: 0.3399
Epoch 2 [104/172] - loss: 0.3008
Epoch 2 [105/172] - loss: 0.1834
Epoch 2 [106/172] - loss: 0.2034
Epoch 2 [107/172] - loss: 0.1851
Epoch 2 [108/172] - loss: 0.3606
Epoch 2 [109/172] - loss: 0.2053
Epoch 2 [110/172] - loss: 0.2567, acc: 0.8438
Epoch 2 [111/172] - loss: 0.2551
Epoch 2 [112/172] - loss: 0.3225
Epoch 2 [113/172] - loss: 0.1521
Epoch 2 [114/172] - loss: 0.1860
Epoch 2 [115/172] - loss: 0.4135
Epoch 2 [116/172] - loss: 0.2746
Epoch 2 [117/172] - loss: 0.3657
Epoch 2 [118/172] - loss: 0.1579
Epoch 2 [119/172] - loss: 0.2317
Epoch 2 [120/172] - loss: 0.1925, acc: 0.9375
Epoch 2 [121/172] - loss: 0.2210
Epoch 2 [122/172] - loss: 0.4690
Epoch 2 [123/172] - loss: 0.2441
Epoch 2 [124/172] - loss: 0.2641
Epoch 2 [125/172] - loss: 0.2327
Epoch 2 [126/172] - loss: 0.3478
Epoch 2 [127/172] - loss: 0.2099
Epoch 2 [128/172] - loss: 0.2011

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4294, log_difficulty=0.3573, weight=2.7864
neutral: count=2949.0, difficulty=0.3610, log_difficulty=0.3082, weight=2.5409
negative: count=3294.0, difficulty=0.4295, log_difficulty=0.3573, weight=2.7866

当前batch的pt分布：
positive: min=0.2006, max=0.9697, mean=0.7552
neutral: min=0.5832, max=0.9630, mean=0.8545
negative: min=0.1208, max=0.9347, mean=0.7179

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8000
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.3195
焦点损失: 0.0893
边界损失: 0.2719
总损失: 0.2600
Epoch 2 [129/172] - loss: 0.2600
Epoch 2 [130/172] - loss: 0.2146, acc: 0.9375
Epoch 2 [131/172] - loss: 0.2641
Epoch 2 [132/172] - loss: 0.3701
Epoch 2 [133/172] - loss: 0.2029
Epoch 2 [134/172] - loss: 0.2741
Epoch 2 [135/172] - loss: 0.4287
Epoch 2 [136/172] - loss: 0.2902
Epoch 2 [137/172] - loss: 0.1619
Epoch 2 [138/172] - loss: 0.1967
Epoch 2 [139/172] - loss: 0.2690
Epoch 2 [140/172] - loss: 0.2443, acc: 0.9062
Epoch 2 [141/172] - loss: 0.3337
Epoch 2 [142/172] - loss: 0.2023
Epoch 2 [143/172] - loss: 0.2289
Epoch 2 [144/172] - loss: 0.2266
Epoch 2 [145/172] - loss: 0.4807
Epoch 2 [146/172] - loss: 0.2302
Epoch 2 [147/172] - loss: 0.2220
Epoch 2 [148/172] - loss: 0.2528
Epoch 2 [149/172] - loss: 0.1628
Epoch 2 [150/172] - loss: 0.2305, acc: 0.9062
Epoch 2 [151/172] - loss: 0.2178
Epoch 2 [152/172] - loss: 0.1993
Epoch 2 [153/172] - loss: 0.2404
Epoch 2 [154/172] - loss: 0.2046
Epoch 2 [155/172] - loss: 0.2222
Epoch 2 [156/172] - loss: 0.2349
Epoch 2 [157/172] - loss: 0.2293
Epoch 2 [158/172] - loss: 0.2060
Epoch 2 [159/172] - loss: 0.3283
Epoch 2 [160/172] - loss: 0.1673, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1709
Epoch 2 [162/172] - loss: 0.1468
Epoch 2 [163/172] - loss: 0.2171
Epoch 2 [164/172] - loss: 0.2337
Epoch 2 [165/172] - loss: 0.2269
Epoch 2 [166/172] - loss: 0.4704
Epoch 2 [167/172] - loss: 0.3551
Epoch 2 [168/172] - loss: 0.1622
Epoch 2 [169/172] - loss: 0.2537
Epoch 2 [170/172] - loss: 0.1460, acc: 0.9688
Epoch 2 [171/172] - loss: 0.2410
Epoch 2 [172/172] - loss: 0.3809

类别准确率:
positive: 0.8501 (397/467)
neutral: 0.3735 (31/83)
negative: 0.6160 (154/250)

Epoch 2/10
Train Loss: 0.2460, Train Acc: 0.9152
Val Loss: 0.6828, Val Acc: 0.7275
Epoch 3 [1/172] - loss: 0.1522, acc: 0.9688
Epoch 3 [2/172] - loss: 0.2556
Epoch 3 [3/172] - loss: 0.1120
Epoch 3 [4/172] - loss: 0.1630
Epoch 3 [5/172] - loss: 0.1981
Epoch 3 [6/172] - loss: 0.1178
Epoch 3 [7/172] - loss: 0.1669
Epoch 3 [8/172] - loss: 0.2011
Epoch 3 [9/172] - loss: 0.1755
Epoch 3 [10/172] - loss: 0.1577, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1264
Epoch 3 [12/172] - loss: 0.1048
Epoch 3 [13/172] - loss: 0.1216
Epoch 3 [14/172] - loss: 0.0971
Epoch 3 [15/172] - loss: 0.1088
Epoch 3 [16/172] - loss: 0.2029
Epoch 3 [17/172] - loss: 0.1408
Epoch 3 [18/172] - loss: 0.2426
Epoch 3 [19/172] - loss: 0.1165
Epoch 3 [20/172] - loss: 0.1387, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1641
Epoch 3 [22/172] - loss: 0.2800
Epoch 3 [23/172] - loss: 0.1598
Epoch 3 [24/172] - loss: 0.1478
Epoch 3 [25/172] - loss: 0.1357
Epoch 3 [26/172] - loss: 0.1381
Epoch 3 [27/172] - loss: 0.1556
Epoch 3 [28/172] - loss: 0.1389
Epoch 3 [29/172] - loss: 0.1823
Epoch 3 [30/172] - loss: 0.1707, acc: 0.9062
Epoch 3 [31/172] - loss: 0.1473
Epoch 3 [32/172] - loss: 0.1317
Epoch 3 [33/172] - loss: 0.1386
Epoch 3 [34/172] - loss: 0.1687
Epoch 3 [35/172] - loss: 0.1739
Epoch 3 [36/172] - loss: 0.1490
Epoch 3 [37/172] - loss: 0.1411
Epoch 3 [38/172] - loss: 0.0982
Epoch 3 [39/172] - loss: 0.1184
Epoch 3 [40/172] - loss: 0.1111, acc: 1.0000
Epoch 3 [41/172] - loss: 0.1462
Epoch 3 [42/172] - loss: 0.1594
Epoch 3 [43/172] - loss: 0.1018
Epoch 3 [44/172] - loss: 0.0878
Epoch 3 [45/172] - loss: 0.1442
Epoch 3 [46/172] - loss: 0.1973
Epoch 3 [47/172] - loss: 0.1031
Epoch 3 [48/172] - loss: 0.1201
Epoch 3 [49/172] - loss: 0.1656
Epoch 3 [50/172] - loss: 0.1117, acc: 1.0000
Epoch 3 [51/172] - loss: 0.2225
Epoch 3 [52/172] - loss: 0.1408
Epoch 3 [53/172] - loss: 0.1436
Epoch 3 [54/172] - loss: 0.1462
Epoch 3 [55/172] - loss: 0.1142
Epoch 3 [56/172] - loss: 0.1429

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3704, log_difficulty=0.3151, weight=2.5756
neutral: count=3923.0, difficulty=0.3041, log_difficulty=0.2655, weight=2.3277
negative: count=4382.0, difficulty=0.3734, log_difficulty=0.3173, weight=2.5865

当前batch的pt分布：
positive: min=0.3886, max=0.9944, mean=0.7746
neutral: min=0.0051, max=0.9597, mean=0.7652
negative: min=0.9621, max=0.9920, mean=0.9784

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9091
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3848
焦点损失: 0.2059
边界损失: 0.2287
总损失: 0.3559
Epoch 3 [57/172] - loss: 0.3559
Epoch 3 [58/172] - loss: 0.1367
Epoch 3 [59/172] - loss: 0.1357
Epoch 3 [60/172] - loss: 0.1393, acc: 0.9375
Epoch 3 [61/172] - loss: 0.1516
Epoch 3 [62/172] - loss: 0.1242
Epoch 3 [63/172] - loss: 0.1087
Epoch 3 [64/172] - loss: 0.2069
Epoch 3 [65/172] - loss: 0.1117
Epoch 3 [66/172] - loss: 0.1480
Epoch 3 [67/172] - loss: 0.1461
Epoch 3 [68/172] - loss: 0.0994
Epoch 3 [69/172] - loss: 0.3624
Epoch 3 [70/172] - loss: 0.1711, acc: 0.9062
Epoch 3 [71/172] - loss: 0.1244
Epoch 3 [72/172] - loss: 0.2532
Epoch 3 [73/172] - loss: 0.1473
Epoch 3 [74/172] - loss: 0.2110
Epoch 3 [75/172] - loss: 0.1645
Epoch 3 [76/172] - loss: 0.1271
Epoch 3 [77/172] - loss: 0.1061
Epoch 3 [78/172] - loss: 0.1906
Epoch 3 [79/172] - loss: 0.1241
Epoch 3 [80/172] - loss: 0.2287, acc: 0.9062
Epoch 3 [81/172] - loss: 0.1820
Epoch 3 [82/172] - loss: 0.1288
Epoch 3 [83/172] - loss: 0.1139
Epoch 3 [84/172] - loss: 0.1080
Epoch 3 [85/172] - loss: 0.1388
Epoch 3 [86/172] - loss: 0.0956
Epoch 3 [87/172] - loss: 0.2068
Epoch 3 [88/172] - loss: 0.1690
Epoch 3 [89/172] - loss: 0.1240
Epoch 3 [90/172] - loss: 0.1212, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1515
Epoch 3 [92/172] - loss: 0.1327
Epoch 3 [93/172] - loss: 0.1962
Epoch 3 [94/172] - loss: 0.1204
Epoch 3 [95/172] - loss: 0.0915
Epoch 3 [96/172] - loss: 0.1292
Epoch 3 [97/172] - loss: 0.1228
Epoch 3 [98/172] - loss: 0.0946
Epoch 3 [99/172] - loss: 0.0943
Epoch 3 [100/172] - loss: 0.2441, acc: 0.9375
Epoch 3 [101/172] - loss: 0.3044
Epoch 3 [102/172] - loss: 0.1113
Epoch 3 [103/172] - loss: 0.1357
Epoch 3 [104/172] - loss: 0.0993
Epoch 3 [105/172] - loss: 0.1404
Epoch 3 [106/172] - loss: 0.1124
Epoch 3 [107/172] - loss: 0.0885
Epoch 3 [108/172] - loss: 0.1364
Epoch 3 [109/172] - loss: 0.1020
Epoch 3 [110/172] - loss: 0.1189, acc: 1.0000
Epoch 3 [111/172] - loss: 0.1235
Epoch 3 [112/172] - loss: 0.0952
Epoch 3 [113/172] - loss: 0.0935
Epoch 3 [114/172] - loss: 0.1324
Epoch 3 [115/172] - loss: 0.0992
Epoch 3 [116/172] - loss: 0.0972
Epoch 3 [117/172] - loss: 0.1308
Epoch 3 [118/172] - loss: 0.1527
Epoch 3 [119/172] - loss: 0.1308
Epoch 3 [120/172] - loss: 0.2068, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1368
Epoch 3 [122/172] - loss: 0.1624
Epoch 3 [123/172] - loss: 0.1043
Epoch 3 [124/172] - loss: 0.1142
Epoch 3 [125/172] - loss: 0.1156
Epoch 3 [126/172] - loss: 0.3326
Epoch 3 [127/172] - loss: 0.2206
Epoch 3 [128/172] - loss: 0.0965
Epoch 3 [129/172] - loss: 0.0929
Epoch 3 [130/172] - loss: 0.1186, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1220
Epoch 3 [132/172] - loss: 0.0910
Epoch 3 [133/172] - loss: 0.1218
Epoch 3 [134/172] - loss: 0.1017
Epoch 3 [135/172] - loss: 0.1093
Epoch 3 [136/172] - loss: 0.1071
Epoch 3 [137/172] - loss: 0.1203
Epoch 3 [138/172] - loss: 0.1095
Epoch 3 [139/172] - loss: 0.1608
Epoch 3 [140/172] - loss: 0.0986, acc: 1.0000
Epoch 3 [141/172] - loss: 0.1898
Epoch 3 [142/172] - loss: 0.1720
Epoch 3 [143/172] - loss: 0.0885
Epoch 3 [144/172] - loss: 0.2238
Epoch 3 [145/172] - loss: 0.1254
Epoch 3 [146/172] - loss: 0.1232
Epoch 3 [147/172] - loss: 0.1262
Epoch 3 [148/172] - loss: 0.1216
Epoch 3 [149/172] - loss: 0.1153
Epoch 3 [150/172] - loss: 0.1273, acc: 0.9062
Epoch 3 [151/172] - loss: 0.2069
Epoch 3 [152/172] - loss: 0.2398
Epoch 3 [153/172] - loss: 0.3442
Epoch 3 [154/172] - loss: 0.0927
Epoch 3 [155/172] - loss: 0.0965
Epoch 3 [156/172] - loss: 0.0935

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3233, log_difficulty=0.2801, weight=2.4005
neutral: count=4903.0, difficulty=0.2608, log_difficulty=0.2317, weight=2.1587
negative: count=5500.0, difficulty=0.3259, log_difficulty=0.2821, weight=2.4104

当前batch的pt分布：
positive: min=0.5448, max=0.9901, mean=0.8860
neutral: min=0.8600, max=0.9872, mean=0.9488
negative: min=0.6816, max=0.9927, mean=0.8952

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1030
焦点损失: 0.0062
边界损失: 0.1865
总损失: 0.1007
Epoch 3 [157/172] - loss: 0.1007
Epoch 3 [158/172] - loss: 0.2170
Epoch 3 [159/172] - loss: 0.1433
Epoch 3 [160/172] - loss: 0.1782, acc: 0.9688
Epoch 3 [161/172] - loss: 0.2778
Epoch 3 [162/172] - loss: 0.1327
Epoch 3 [163/172] - loss: 0.2811
Epoch 3 [164/172] - loss: 0.1277
Epoch 3 [165/172] - loss: 0.1916
Epoch 3 [166/172] - loss: 0.1368
Epoch 3 [167/172] - loss: 0.1119
Epoch 3 [168/172] - loss: 0.1214
Epoch 3 [169/172] - loss: 0.1012
Epoch 3 [170/172] - loss: 0.2759, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1482
Epoch 3 [172/172] - loss: 0.1838

类别准确率:
positive: 0.8994 (420/467)
neutral: 0.1687 (14/83)
negative: 0.5120 (128/250)

Epoch 3/10
Train Loss: 0.1706, Train Acc: 0.9495
Val Loss: 0.7458, Val Acc: 0.7025
Epoch 4 [1/172] - loss: 0.0970, acc: 1.0000
Epoch 4 [2/172] - loss: 0.0919
Epoch 4 [3/172] - loss: 0.1212
Epoch 4 [4/172] - loss: 0.1254
Epoch 4 [5/172] - loss: 0.1402
Epoch 4 [6/172] - loss: 0.0979
Epoch 4 [7/172] - loss: 0.1116
Epoch 4 [8/172] - loss: 0.1259
Epoch 4 [9/172] - loss: 0.2040
Epoch 4 [10/172] - loss: 0.1380, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0897
Epoch 4 [12/172] - loss: 0.1147
Epoch 4 [13/172] - loss: 0.1591
Epoch 4 [14/172] - loss: 0.1323
Epoch 4 [15/172] - loss: 0.0865
Epoch 4 [16/172] - loss: 0.1035
Epoch 4 [17/172] - loss: 0.1876
Epoch 4 [18/172] - loss: 0.1261
Epoch 4 [19/172] - loss: 0.1378
Epoch 4 [20/172] - loss: 0.0953, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1659
Epoch 4 [22/172] - loss: 0.1024
Epoch 4 [23/172] - loss: 0.1068
Epoch 4 [24/172] - loss: 0.0978
Epoch 4 [25/172] - loss: 0.0955
Epoch 4 [26/172] - loss: 0.2870
Epoch 4 [27/172] - loss: 0.0979
Epoch 4 [28/172] - loss: 0.1615
Epoch 4 [29/172] - loss: 0.0864
Epoch 4 [30/172] - loss: 0.2350, acc: 0.9375
Epoch 4 [31/172] - loss: 0.1593
Epoch 4 [32/172] - loss: 0.1373
Epoch 4 [33/172] - loss: 0.1153
Epoch 4 [34/172] - loss: 0.0946
Epoch 4 [35/172] - loss: 0.1696
Epoch 4 [36/172] - loss: 0.0953
Epoch 4 [37/172] - loss: 0.1190
Epoch 4 [38/172] - loss: 0.0932
Epoch 4 [39/172] - loss: 0.2977
Epoch 4 [40/172] - loss: 0.1549, acc: 0.9688
Epoch 4 [41/172] - loss: 0.1091
Epoch 4 [42/172] - loss: 0.1462
Epoch 4 [43/172] - loss: 0.1009
Epoch 4 [44/172] - loss: 0.1280
Epoch 4 [45/172] - loss: 0.0819
Epoch 4 [46/172] - loss: 0.1070
Epoch 4 [47/172] - loss: 0.1063
Epoch 4 [48/172] - loss: 0.0889
Epoch 4 [49/172] - loss: 0.0913
Epoch 4 [50/172] - loss: 0.2366, acc: 0.9688
Epoch 4 [51/172] - loss: 0.1387
Epoch 4 [52/172] - loss: 0.1139
Epoch 4 [53/172] - loss: 0.0954
Epoch 4 [54/172] - loss: 0.1749
Epoch 4 [55/172] - loss: 0.2387
Epoch 4 [56/172] - loss: 0.0957
Epoch 4 [57/172] - loss: 0.0866
Epoch 4 [58/172] - loss: 0.1028
Epoch 4 [59/172] - loss: 0.0866
Epoch 4 [60/172] - loss: 0.1267, acc: 0.9688
Epoch 4 [61/172] - loss: 0.0914
Epoch 4 [62/172] - loss: 0.1323
Epoch 4 [63/172] - loss: 0.0874
Epoch 4 [64/172] - loss: 0.0845
Epoch 4 [65/172] - loss: 0.2062
Epoch 4 [66/172] - loss: 0.1094
Epoch 4 [67/172] - loss: 0.0969
Epoch 4 [68/172] - loss: 0.1310
Epoch 4 [69/172] - loss: 0.1058
Epoch 4 [70/172] - loss: 0.1183, acc: 0.9375
Epoch 4 [71/172] - loss: 0.0941
Epoch 4 [72/172] - loss: 0.1048
Epoch 4 [73/172] - loss: 0.0966
Epoch 4 [74/172] - loss: 0.1528
Epoch 4 [75/172] - loss: 0.1387
Epoch 4 [76/172] - loss: 0.0882
Epoch 4 [77/172] - loss: 0.1213
Epoch 4 [78/172] - loss: 0.0890
Epoch 4 [79/172] - loss: 0.0926
Epoch 4 [80/172] - loss: 0.0863, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1740
Epoch 4 [82/172] - loss: 0.0985
Epoch 4 [83/172] - loss: 0.0957
Epoch 4 [84/172] - loss: 0.0901

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2894, log_difficulty=0.2542, weight=2.2708
neutral: count=5865.0, difficulty=0.2318, log_difficulty=0.2084, weight=2.0422
negative: count=6629.0, difficulty=0.2903, log_difficulty=0.2548, weight=2.2742

当前batch的pt分布：
positive: min=0.4779, max=0.9669, mean=0.8479
neutral: min=0.8446, max=0.9970, mean=0.9718
negative: min=0.0392, max=0.9969, mean=0.8622

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.2050
焦点损失: 0.0991
边界损失: 0.1861
总损失: 0.2058
Epoch 4 [85/172] - loss: 0.2058
Epoch 4 [86/172] - loss: 0.1184
Epoch 4 [87/172] - loss: 0.1011
Epoch 4 [88/172] - loss: 0.0842
Epoch 4 [89/172] - loss: 0.0905
Epoch 4 [90/172] - loss: 0.0891, acc: 1.0000
Epoch 4 [91/172] - loss: 0.2048
Epoch 4 [92/172] - loss: 0.2100
Epoch 4 [93/172] - loss: 0.0803
Epoch 4 [94/172] - loss: 0.0836
Epoch 4 [95/172] - loss: 0.1472
Epoch 4 [96/172] - loss: 0.1104
Epoch 4 [97/172] - loss: 0.0847
Epoch 4 [98/172] - loss: 0.0874
Epoch 4 [99/172] - loss: 0.1079
Epoch 4 [100/172] - loss: 0.0877, acc: 1.0000
Epoch 4 [101/172] - loss: 0.0875
Epoch 4 [102/172] - loss: 0.0939
Epoch 4 [103/172] - loss: 0.2277
Epoch 4 [104/172] - loss: 0.0837
Epoch 4 [105/172] - loss: 0.1530
Epoch 4 [106/172] - loss: 0.1378
Epoch 4 [107/172] - loss: 0.0879
Epoch 4 [108/172] - loss: 0.1037
Epoch 4 [109/172] - loss: 0.1125
Epoch 4 [110/172] - loss: 0.2365, acc: 0.9062
Epoch 4 [111/172] - loss: 0.0959
Epoch 4 [112/172] - loss: 0.0805
Epoch 4 [113/172] - loss: 0.0996
Epoch 4 [114/172] - loss: 0.0925
Epoch 4 [115/172] - loss: 0.1519
Epoch 4 [116/172] - loss: 0.1111
Epoch 4 [117/172] - loss: 0.0807
Epoch 4 [118/172] - loss: 0.0964
Epoch 4 [119/172] - loss: 0.0805
Epoch 4 [120/172] - loss: 0.0887, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1216
Epoch 4 [122/172] - loss: 0.1997
Epoch 4 [123/172] - loss: 0.0834
Epoch 4 [124/172] - loss: 0.1064
Epoch 4 [125/172] - loss: 0.0992
Epoch 4 [126/172] - loss: 0.1280
Epoch 4 [127/172] - loss: 0.1077
Epoch 4 [128/172] - loss: 0.0921
Epoch 4 [129/172] - loss: 0.0962
Epoch 4 [130/172] - loss: 0.1340, acc: 0.9688
Epoch 4 [131/172] - loss: 0.1363
Epoch 4 [132/172] - loss: 0.0875
Epoch 4 [133/172] - loss: 0.1252
Epoch 4 [134/172] - loss: 0.0897
Epoch 4 [135/172] - loss: 0.1058
Epoch 4 [136/172] - loss: 0.1346
Epoch 4 [137/172] - loss: 0.1040
Epoch 4 [138/172] - loss: 0.0866
Epoch 4 [139/172] - loss: 0.0844
Epoch 4 [140/172] - loss: 0.1071, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1499
Epoch 4 [142/172] - loss: 0.1183
Epoch 4 [143/172] - loss: 0.0995
Epoch 4 [144/172] - loss: 0.0891
Epoch 4 [145/172] - loss: 0.3045
Epoch 4 [146/172] - loss: 0.1006
Epoch 4 [147/172] - loss: 0.1187
Epoch 4 [148/172] - loss: 0.1057
Epoch 4 [149/172] - loss: 0.0898
Epoch 4 [150/172] - loss: 0.2038, acc: 0.9375
Epoch 4 [151/172] - loss: 0.2307
Epoch 4 [152/172] - loss: 0.0802
Epoch 4 [153/172] - loss: 0.0800
Epoch 4 [154/172] - loss: 0.1426
Epoch 4 [155/172] - loss: 0.0840
Epoch 4 [156/172] - loss: 0.1083
Epoch 4 [157/172] - loss: 0.2652
Epoch 4 [158/172] - loss: 0.0840
Epoch 4 [159/172] - loss: 0.0856
Epoch 4 [160/172] - loss: 0.1311, acc: 0.9375
Epoch 4 [161/172] - loss: 0.0933
Epoch 4 [162/172] - loss: 0.1039
Epoch 4 [163/172] - loss: 0.1069
Epoch 4 [164/172] - loss: 0.0905
Epoch 4 [165/172] - loss: 0.1004
Epoch 4 [166/172] - loss: 0.0830
Epoch 4 [167/172] - loss: 0.0949
Epoch 4 [168/172] - loss: 0.0825
Epoch 4 [169/172] - loss: 0.1627
Epoch 4 [170/172] - loss: 0.1479, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1424
Epoch 4 [172/172] - loss: 0.1114

类别准确率:
positive: 0.9036 (422/467)
neutral: 0.2651 (22/83)
negative: 0.6000 (150/250)

Epoch 4/10
Train Loss: 0.1179, Train Acc: 0.9737
Val Loss: 0.7503, Val Acc: 0.7425
Epoch 5 [1/172] - loss: 0.0786, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0953
Epoch 5 [3/172] - loss: 0.0829
Epoch 5 [4/172] - loss: 0.1307
Epoch 5 [5/172] - loss: 0.0814
Epoch 5 [6/172] - loss: 0.0897
Epoch 5 [7/172] - loss: 0.0965
Epoch 5 [8/172] - loss: 0.1254
Epoch 5 [9/172] - loss: 0.1108
Epoch 5 [10/172] - loss: 0.0811, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1131
Epoch 5 [12/172] - loss: 0.0827

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2614, log_difficulty=0.2322, weight=2.1610
neutral: count=6845.0, difficulty=0.2071, log_difficulty=0.1882, weight=1.9411
negative: count=7694.0, difficulty=0.2627, log_difficulty=0.2332, weight=2.1661

当前batch的pt分布：
positive: min=0.1519, max=0.9948, mean=0.8736
neutral: min=0.8477, max=0.9999, mean=0.9674
negative: min=0.8736, max=0.9873, mean=0.9576

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1123
焦点损失: 0.0416
边界损失: 0.1646
总损失: 0.1272
Epoch 5 [13/172] - loss: 0.1272
Epoch 5 [14/172] - loss: 0.1488
Epoch 5 [15/172] - loss: 0.0795
Epoch 5 [16/172] - loss: 0.0779
Epoch 5 [17/172] - loss: 0.1005
Epoch 5 [18/172] - loss: 0.0810
Epoch 5 [19/172] - loss: 0.1366
Epoch 5 [20/172] - loss: 0.0944, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1596
Epoch 5 [22/172] - loss: 0.2552
Epoch 5 [23/172] - loss: 0.0799
Epoch 5 [24/172] - loss: 0.1125
Epoch 5 [25/172] - loss: 0.0885
Epoch 5 [26/172] - loss: 0.0832
Epoch 5 [27/172] - loss: 0.0764
Epoch 5 [28/172] - loss: 0.1171
Epoch 5 [29/172] - loss: 0.0780
Epoch 5 [30/172] - loss: 0.0838, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0803
Epoch 5 [32/172] - loss: 0.0797
Epoch 5 [33/172] - loss: 0.0971
Epoch 5 [34/172] - loss: 0.0963
Epoch 5 [35/172] - loss: 0.0855
Epoch 5 [36/172] - loss: 0.0800
Epoch 5 [37/172] - loss: 0.0821
Epoch 5 [38/172] - loss: 0.0785
Epoch 5 [39/172] - loss: 0.3374
Epoch 5 [40/172] - loss: 0.0897, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0822
Epoch 5 [42/172] - loss: 0.0800
Epoch 5 [43/172] - loss: 0.1192
Epoch 5 [44/172] - loss: 0.0863
Epoch 5 [45/172] - loss: 0.0791
Epoch 5 [46/172] - loss: 0.1193
Epoch 5 [47/172] - loss: 0.0928
Epoch 5 [48/172] - loss: 0.0987
Epoch 5 [49/172] - loss: 0.0947
Epoch 5 [50/172] - loss: 0.1046, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0877
Epoch 5 [52/172] - loss: 0.0839
Epoch 5 [53/172] - loss: 0.1100
Epoch 5 [54/172] - loss: 0.0865
Epoch 5 [55/172] - loss: 0.1292
Epoch 5 [56/172] - loss: 0.0916
Epoch 5 [57/172] - loss: 0.0828
Epoch 5 [58/172] - loss: 0.0775
Epoch 5 [59/172] - loss: 0.1142
Epoch 5 [60/172] - loss: 0.0832, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0774
Epoch 5 [62/172] - loss: 0.0977
Epoch 5 [63/172] - loss: 0.1749
Epoch 5 [64/172] - loss: 0.0821
Epoch 5 [65/172] - loss: 0.0849
Epoch 5 [66/172] - loss: 0.0966
Epoch 5 [67/172] - loss: 0.0761
Epoch 5 [68/172] - loss: 0.1001
Epoch 5 [69/172] - loss: 0.0907
Epoch 5 [70/172] - loss: 0.1391, acc: 0.9688
Epoch 5 [71/172] - loss: 0.0883
Epoch 5 [72/172] - loss: 0.1371
Epoch 5 [73/172] - loss: 0.1204
Epoch 5 [74/172] - loss: 0.2351
Epoch 5 [75/172] - loss: 0.0838
Epoch 5 [76/172] - loss: 0.0906
Epoch 5 [77/172] - loss: 0.0776
Epoch 5 [78/172] - loss: 0.1027
Epoch 5 [79/172] - loss: 0.0930
Epoch 5 [80/172] - loss: 0.0940, acc: 0.9688
Epoch 5 [81/172] - loss: 0.1172
Epoch 5 [82/172] - loss: 0.1867
Epoch 5 [83/172] - loss: 0.0806
Epoch 5 [84/172] - loss: 0.0789
Epoch 5 [85/172] - loss: 0.1792
Epoch 5 [86/172] - loss: 0.0829
Epoch 5 [87/172] - loss: 0.1083
Epoch 5 [88/172] - loss: 0.1070
Epoch 5 [89/172] - loss: 0.0822
Epoch 5 [90/172] - loss: 0.1053, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0785
Epoch 5 [92/172] - loss: 0.0814
Epoch 5 [93/172] - loss: 0.0860
Epoch 5 [94/172] - loss: 0.0928
Epoch 5 [95/172] - loss: 0.1009
Epoch 5 [96/172] - loss: 0.1749
Epoch 5 [97/172] - loss: 0.0968
Epoch 5 [98/172] - loss: 0.0778
Epoch 5 [99/172] - loss: 0.1007
Epoch 5 [100/172] - loss: 0.1552, acc: 0.9688
Epoch 5 [101/172] - loss: 0.0812
Epoch 5 [102/172] - loss: 0.0909
Epoch 5 [103/172] - loss: 0.1092
Epoch 5 [104/172] - loss: 0.2271
Epoch 5 [105/172] - loss: 0.2147
Epoch 5 [106/172] - loss: 0.0910
Epoch 5 [107/172] - loss: 0.0964
Epoch 5 [108/172] - loss: 0.1001
Epoch 5 [109/172] - loss: 0.0843
Epoch 5 [110/172] - loss: 0.0898, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1003
Epoch 5 [112/172] - loss: 0.0805

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2374, log_difficulty=0.2130, weight=2.0651
neutral: count=7825.0, difficulty=0.1877, log_difficulty=0.1720, weight=1.8602
negative: count=8780.0, difficulty=0.2403, log_difficulty=0.2153, weight=2.0767

当前batch的pt分布：
positive: min=0.3196, max=0.9966, mean=0.7657
neutral: min=0.6598, max=0.9975, mean=0.9317
negative: min=0.9526, max=0.9981, mean=0.9863

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1866
焦点损失: 0.0362
边界损失: 0.2204
总损失: 0.1474
Epoch 5 [113/172] - loss: 0.1474
Epoch 5 [114/172] - loss: 0.1740
Epoch 5 [115/172] - loss: 0.0959
Epoch 5 [116/172] - loss: 0.0995
Epoch 5 [117/172] - loss: 0.0772
Epoch 5 [118/172] - loss: 0.1040
Epoch 5 [119/172] - loss: 0.0801
Epoch 5 [120/172] - loss: 0.1091, acc: 0.9688
Epoch 5 [121/172] - loss: 0.0912
Epoch 5 [122/172] - loss: 0.0937
Epoch 5 [123/172] - loss: 0.0979
Epoch 5 [124/172] - loss: 0.0796
Epoch 5 [125/172] - loss: 0.0800
Epoch 5 [126/172] - loss: 0.1035
Epoch 5 [127/172] - loss: 0.0967
Epoch 5 [128/172] - loss: 0.1127
Epoch 5 [129/172] - loss: 0.1605
Epoch 5 [130/172] - loss: 0.0909, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0950
Epoch 5 [132/172] - loss: 0.1326
Epoch 5 [133/172] - loss: 0.1503
Epoch 5 [134/172] - loss: 0.0962
Epoch 5 [135/172] - loss: 0.0751
Epoch 5 [136/172] - loss: 0.0810
Epoch 5 [137/172] - loss: 0.1341
Epoch 5 [138/172] - loss: 0.1467
Epoch 5 [139/172] - loss: 0.2318
Epoch 5 [140/172] - loss: 0.0904, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0806
Epoch 5 [142/172] - loss: 0.0795
Epoch 5 [143/172] - loss: 0.0863
Epoch 5 [144/172] - loss: 0.0768
Epoch 5 [145/172] - loss: 0.0945
Epoch 5 [146/172] - loss: 0.0772
Epoch 5 [147/172] - loss: 0.1068
Epoch 5 [148/172] - loss: 0.0746
Epoch 5 [149/172] - loss: 0.0808
Epoch 5 [150/172] - loss: 0.1320, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0827
Epoch 5 [152/172] - loss: 0.0756
Epoch 5 [153/172] - loss: 0.1242
Epoch 5 [154/172] - loss: 0.0951
Epoch 5 [155/172] - loss: 0.0759
Epoch 5 [156/172] - loss: 0.0872
Epoch 5 [157/172] - loss: 0.0777
Epoch 5 [158/172] - loss: 0.0760
Epoch 5 [159/172] - loss: 0.0748
Epoch 5 [160/172] - loss: 0.0748, acc: 1.0000
Epoch 5 [161/172] - loss: 0.1047
Epoch 5 [162/172] - loss: 0.0912
Epoch 5 [163/172] - loss: 0.1496
Epoch 5 [164/172] - loss: 0.0756
Epoch 5 [165/172] - loss: 0.1926
Epoch 5 [166/172] - loss: 0.1000
Epoch 5 [167/172] - loss: 0.0936
Epoch 5 [168/172] - loss: 0.0766
Epoch 5 [169/172] - loss: 0.0848
Epoch 5 [170/172] - loss: 0.1363, acc: 0.9375
Epoch 5 [171/172] - loss: 0.0777
Epoch 5 [172/172] - loss: 0.1311

类别准确率:
positive: 0.8009 (374/467)
neutral: 0.3253 (27/83)
negative: 0.6560 (164/250)

Epoch 5/10
Train Loss: 0.1011, Train Acc: 0.9899
Val Loss: 0.7750, Val Acc: 0.7063
Epoch 6 [1/172] - loss: 0.0978, acc: 1.0000
Epoch 6 [2/172] - loss: 0.0929
Epoch 6 [3/172] - loss: 0.0839
Epoch 6 [4/172] - loss: 0.0820
Epoch 6 [5/172] - loss: 0.1723
Epoch 6 [6/172] - loss: 0.0773
Epoch 6 [7/172] - loss: 0.0834
Epoch 6 [8/172] - loss: 0.0932
Epoch 6 [9/172] - loss: 0.0872
Epoch 6 [10/172] - loss: 0.0802, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0779
Epoch 6 [12/172] - loss: 0.0789
Epoch 6 [13/172] - loss: 0.0866
Epoch 6 [14/172] - loss: 0.0769
Epoch 6 [15/172] - loss: 0.0769
Epoch 6 [16/172] - loss: 0.1535
Epoch 6 [17/172] - loss: 0.0790
Epoch 6 [18/172] - loss: 0.0838
Epoch 6 [19/172] - loss: 0.1156
Epoch 6 [20/172] - loss: 0.0769, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0778
Epoch 6 [22/172] - loss: 0.0796
Epoch 6 [23/172] - loss: 0.0866
Epoch 6 [24/172] - loss: 0.0854
Epoch 6 [25/172] - loss: 0.1368
Epoch 6 [26/172] - loss: 0.0909
Epoch 6 [27/172] - loss: 0.0974
Epoch 6 [28/172] - loss: 0.0747
Epoch 6 [29/172] - loss: 0.0776
Epoch 6 [30/172] - loss: 0.0819, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0736
Epoch 6 [32/172] - loss: 0.0791
Epoch 6 [33/172] - loss: 0.1322
Epoch 6 [34/172] - loss: 0.0753
Epoch 6 [35/172] - loss: 0.0741
Epoch 6 [36/172] - loss: 0.0796
Epoch 6 [37/172] - loss: 0.0756
Epoch 6 [38/172] - loss: 0.0770
Epoch 6 [39/172] - loss: 0.1006
Epoch 6 [40/172] - loss: 0.1119, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2179, log_difficulty=0.1971, weight=1.9857
neutral: count=8815.0, difficulty=0.1722, log_difficulty=0.1589, weight=1.7943
negative: count=9870.0, difficulty=0.2208, log_difficulty=0.1995, weight=1.9974

当前batch的pt分布：
positive: min=0.0655, max=0.9973, mean=0.8965
neutral: min=0.9572, max=0.9977, mean=0.9794
negative: min=0.8189, max=0.9954, mean=0.9447

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1184
焦点损失: 0.0742
边界损失: 0.1526
总损失: 0.1500
Epoch 6 [41/172] - loss: 0.1500
Epoch 6 [42/172] - loss: 0.0774
Epoch 6 [43/172] - loss: 0.1145
Epoch 6 [44/172] - loss: 0.0733
Epoch 6 [45/172] - loss: 0.1640
Epoch 6 [46/172] - loss: 0.0999
Epoch 6 [47/172] - loss: 0.0780
Epoch 6 [48/172] - loss: 0.0835
Epoch 6 [49/172] - loss: 0.0815
Epoch 6 [50/172] - loss: 0.1405, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1015
Epoch 6 [52/172] - loss: 0.0982
Epoch 6 [53/172] - loss: 0.0772
Epoch 6 [54/172] - loss: 0.1628
Epoch 6 [55/172] - loss: 0.0951
Epoch 6 [56/172] - loss: 0.0825
Epoch 6 [57/172] - loss: 0.0807
Epoch 6 [58/172] - loss: 0.0820
Epoch 6 [59/172] - loss: 0.1214
Epoch 6 [60/172] - loss: 0.0903, acc: 0.9688
Epoch 6 [61/172] - loss: 0.0763
Epoch 6 [62/172] - loss: 0.1699
Epoch 6 [63/172] - loss: 0.0952
Epoch 6 [64/172] - loss: 0.1957
Epoch 6 [65/172] - loss: 0.1504
Epoch 6 [66/172] - loss: 0.0981
Epoch 6 [67/172] - loss: 0.0764
Epoch 6 [68/172] - loss: 0.1638
Epoch 6 [69/172] - loss: 0.0916
Epoch 6 [70/172] - loss: 0.0822, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0991
Epoch 6 [72/172] - loss: 0.0868
Epoch 6 [73/172] - loss: 0.0897
Epoch 6 [74/172] - loss: 0.0750
Epoch 6 [75/172] - loss: 0.0858
Epoch 6 [76/172] - loss: 0.0785
Epoch 6 [77/172] - loss: 0.0953
Epoch 6 [78/172] - loss: 0.0957
Epoch 6 [79/172] - loss: 0.0747
Epoch 6 [80/172] - loss: 0.1167, acc: 0.9688
Epoch 6 [81/172] - loss: 0.1015
Epoch 6 [82/172] - loss: 0.0757
Epoch 6 [83/172] - loss: 0.0774
Epoch 6 [84/172] - loss: 0.0739
Epoch 6 [85/172] - loss: 0.0854
Epoch 6 [86/172] - loss: 0.1001
Epoch 6 [87/172] - loss: 0.0882
Epoch 6 [88/172] - loss: 0.0921
Epoch 6 [89/172] - loss: 0.0850
Epoch 6 [90/172] - loss: 0.0778, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0744
Epoch 6 [92/172] - loss: 0.0765
Epoch 6 [93/172] - loss: 0.0769
Epoch 6 [94/172] - loss: 0.1015
Epoch 6 [95/172] - loss: 0.0792
Epoch 6 [96/172] - loss: 0.0782
Epoch 6 [97/172] - loss: 0.0845
Epoch 6 [98/172] - loss: 0.0828
Epoch 6 [99/172] - loss: 0.0767
Epoch 6 [100/172] - loss: 0.0768, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1140
Epoch 6 [102/172] - loss: 0.0750
Epoch 6 [103/172] - loss: 0.0831
Epoch 6 [104/172] - loss: 0.1370
Epoch 6 [105/172] - loss: 0.1052
Epoch 6 [106/172] - loss: 0.0838
Epoch 6 [107/172] - loss: 0.0759
Epoch 6 [108/172] - loss: 0.0776
Epoch 6 [109/172] - loss: 0.1762
Epoch 6 [110/172] - loss: 0.0825, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0858
Epoch 6 [112/172] - loss: 0.0822
Epoch 6 [113/172] - loss: 0.1057
Epoch 6 [114/172] - loss: 0.0758
Epoch 6 [115/172] - loss: 0.0890
Epoch 6 [116/172] - loss: 0.1623
Epoch 6 [117/172] - loss: 0.0741
Epoch 6 [118/172] - loss: 0.0737
Epoch 6 [119/172] - loss: 0.1690
Epoch 6 [120/172] - loss: 0.0791, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0814
Epoch 6 [122/172] - loss: 0.0910
Epoch 6 [123/172] - loss: 0.0824
Epoch 6 [124/172] - loss: 0.0748
Epoch 6 [125/172] - loss: 0.0845
Epoch 6 [126/172] - loss: 0.0841
Epoch 6 [127/172] - loss: 0.1335
Epoch 6 [128/172] - loss: 0.0813
Epoch 6 [129/172] - loss: 0.0792
Epoch 6 [130/172] - loss: 0.1786, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1055
Epoch 6 [132/172] - loss: 0.2667
Epoch 6 [133/172] - loss: 0.1118
Epoch 6 [134/172] - loss: 0.0857
Epoch 6 [135/172] - loss: 0.0736
Epoch 6 [136/172] - loss: 0.0810
Epoch 6 [137/172] - loss: 0.0795
Epoch 6 [138/172] - loss: 0.0852
Epoch 6 [139/172] - loss: 0.0808
Epoch 6 [140/172] - loss: 0.3466, acc: 0.9375

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2015, log_difficulty=0.1836, weight=1.9180
neutral: count=9796.0, difficulty=0.1594, log_difficulty=0.1479, weight=1.7397
negative: count=10972.0, difficulty=0.2051, log_difficulty=0.1866, weight=1.9328

当前batch的pt分布：
positive: min=0.9573, max=0.9995, mean=0.9853
neutral: min=0.9103, max=0.9973, mean=0.9737
negative: min=0.3079, max=0.9982, mean=0.8887

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9231

损失分量：
基础交叉熵: 0.0767
焦点损失: 0.0196
边界损失: 0.1596
总损失: 0.0988
Epoch 6 [141/172] - loss: 0.0988
Epoch 6 [142/172] - loss: 0.0875
Epoch 6 [143/172] - loss: 0.1745
Epoch 6 [144/172] - loss: 0.0869
Epoch 6 [145/172] - loss: 0.2021
Epoch 6 [146/172] - loss: 0.0965
Epoch 6 [147/172] - loss: 0.0881
Epoch 6 [148/172] - loss: 0.0842
Epoch 6 [149/172] - loss: 0.0987
Epoch 6 [150/172] - loss: 0.0752, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0884
Epoch 6 [152/172] - loss: 0.0927
Epoch 6 [153/172] - loss: 0.0799
Epoch 6 [154/172] - loss: 0.0784
Epoch 6 [155/172] - loss: 0.1654
Epoch 6 [156/172] - loss: 0.0891
Epoch 6 [157/172] - loss: 0.0909
Epoch 6 [158/172] - loss: 0.0996
Epoch 6 [159/172] - loss: 0.0847
Epoch 6 [160/172] - loss: 0.1043, acc: 0.9688
Epoch 6 [161/172] - loss: 0.0960
Epoch 6 [162/172] - loss: 0.0841
Epoch 6 [163/172] - loss: 0.1121
Epoch 6 [164/172] - loss: 0.1045
Epoch 6 [165/172] - loss: 0.2276
Epoch 6 [166/172] - loss: 0.1030
Epoch 6 [167/172] - loss: 0.1500
Epoch 6 [168/172] - loss: 0.0767
Epoch 6 [169/172] - loss: 0.0892
Epoch 6 [170/172] - loss: 0.0788, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0793
Epoch 6 [172/172] - loss: 0.0824

类别准确率:
positive: 0.8587 (401/467)
neutral: 0.2289 (19/83)
negative: 0.5760 (144/250)

Epoch 6/10
Train Loss: 0.1039, Train Acc: 0.9818
Val Loss: 0.8688, Val Acc: 0.7050
Epoch 7 [1/172] - loss: 0.0773, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0763
Epoch 7 [3/172] - loss: 0.0765
Epoch 7 [4/172] - loss: 0.0838
Epoch 7 [5/172] - loss: 0.0727
Epoch 7 [6/172] - loss: 0.0825
Epoch 7 [7/172] - loss: 0.0833
Epoch 7 [8/172] - loss: 0.0858
Epoch 7 [9/172] - loss: 0.0731
Epoch 7 [10/172] - loss: 0.0776, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0962
Epoch 7 [12/172] - loss: 0.1014
Epoch 7 [13/172] - loss: 0.0802
Epoch 7 [14/172] - loss: 0.0873
Epoch 7 [15/172] - loss: 0.0905
Epoch 7 [16/172] - loss: 0.0812
Epoch 7 [17/172] - loss: 0.1120
Epoch 7 [18/172] - loss: 0.0769
Epoch 7 [19/172] - loss: 0.0801
Epoch 7 [20/172] - loss: 0.0790, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0824
Epoch 7 [22/172] - loss: 0.0801
Epoch 7 [23/172] - loss: 0.0780
Epoch 7 [24/172] - loss: 0.0780
Epoch 7 [25/172] - loss: 0.0786
Epoch 7 [26/172] - loss: 0.1098
Epoch 7 [27/172] - loss: 0.0842
Epoch 7 [28/172] - loss: 0.0864
Epoch 7 [29/172] - loss: 0.0803
Epoch 7 [30/172] - loss: 0.1477, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0749
Epoch 7 [32/172] - loss: 0.0804
Epoch 7 [33/172] - loss: 0.0799
Epoch 7 [34/172] - loss: 0.0772
Epoch 7 [35/172] - loss: 0.0746
Epoch 7 [36/172] - loss: 0.1292
Epoch 7 [37/172] - loss: 0.0759
Epoch 7 [38/172] - loss: 0.0753
Epoch 7 [39/172] - loss: 0.0841
Epoch 7 [40/172] - loss: 0.0745, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0769
Epoch 7 [42/172] - loss: 0.0760
Epoch 7 [43/172] - loss: 0.0760
Epoch 7 [44/172] - loss: 0.0875
Epoch 7 [45/172] - loss: 0.0774
Epoch 7 [46/172] - loss: 0.0897
Epoch 7 [47/172] - loss: 0.1772
Epoch 7 [48/172] - loss: 0.0747
Epoch 7 [49/172] - loss: 0.0882
Epoch 7 [50/172] - loss: 0.0757, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1367
Epoch 7 [52/172] - loss: 0.0809
Epoch 7 [53/172] - loss: 0.0742
Epoch 7 [54/172] - loss: 0.0906
Epoch 7 [55/172] - loss: 0.0817
Epoch 7 [56/172] - loss: 0.0844
Epoch 7 [57/172] - loss: 0.0803
Epoch 7 [58/172] - loss: 0.0862
Epoch 7 [59/172] - loss: 0.0739
Epoch 7 [60/172] - loss: 0.0827, acc: 1.0000
Epoch 7 [61/172] - loss: 0.0844
Epoch 7 [62/172] - loss: 0.0792
Epoch 7 [63/172] - loss: 0.1764
Epoch 7 [64/172] - loss: 0.0781
Epoch 7 [65/172] - loss: 0.0938
Epoch 7 [66/172] - loss: 0.0752
Epoch 7 [67/172] - loss: 0.0798
Epoch 7 [68/172] - loss: 0.0872

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1887, log_difficulty=0.1729, weight=1.8643
neutral: count=10756.0, difficulty=0.1482, log_difficulty=0.1382, weight=1.6911
negative: count=12072.0, difficulty=0.1920, log_difficulty=0.1756, weight=1.8781

当前batch的pt分布：
positive: min=0.9269, max=0.9991, mean=0.9811
neutral: min=0.9797, max=0.9994, mean=0.9927
negative: min=0.8551, max=0.9883, mean=0.9512

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0300
焦点损失: 0.0002
边界损失: 0.1488
总损失: 0.0745
Epoch 7 [69/172] - loss: 0.0745
Epoch 7 [70/172] - loss: 0.0886, acc: 0.9688
Epoch 7 [71/172] - loss: 0.0767
Epoch 7 [72/172] - loss: 0.0916
Epoch 7 [73/172] - loss: 0.0821
Epoch 7 [74/172] - loss: 0.0781
Epoch 7 [75/172] - loss: 0.0751
Epoch 7 [76/172] - loss: 0.0836
Epoch 7 [77/172] - loss: 0.0909
Epoch 7 [78/172] - loss: 0.0811
Epoch 7 [79/172] - loss: 0.1031
Epoch 7 [80/172] - loss: 0.0854, acc: 1.0000
Epoch 7 [81/172] - loss: 0.0755
Epoch 7 [82/172] - loss: 0.0765
Epoch 7 [83/172] - loss: 0.0982
Epoch 7 [84/172] - loss: 0.0836
Epoch 7 [85/172] - loss: 0.0786
Epoch 7 [86/172] - loss: 0.0752
Epoch 7 [87/172] - loss: 0.0762
Epoch 7 [88/172] - loss: 0.0751
Epoch 7 [89/172] - loss: 0.0750
Epoch 7 [90/172] - loss: 0.0826, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0786
Epoch 7 [92/172] - loss: 0.0877
Epoch 7 [93/172] - loss: 0.1141
Epoch 7 [94/172] - loss: 0.0752
Epoch 7 [95/172] - loss: 0.0769
Epoch 7 [96/172] - loss: 0.0836
Epoch 7 [97/172] - loss: 0.0963
Epoch 7 [98/172] - loss: 0.0975
Epoch 7 [99/172] - loss: 0.0750
Epoch 7 [100/172] - loss: 0.0762, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0753
Epoch 7 [102/172] - loss: 0.0780
Epoch 7 [103/172] - loss: 0.0738
Epoch 7 [104/172] - loss: 0.0817
Epoch 7 [105/172] - loss: 0.1095
Epoch 7 [106/172] - loss: 0.1017
Epoch 7 [107/172] - loss: 0.0725
Epoch 7 [108/172] - loss: 0.0732
Epoch 7 [109/172] - loss: 0.0862
Epoch 7 [110/172] - loss: 0.0895, acc: 0.9688
Epoch 7 [111/172] - loss: 0.0783
Epoch 7 [112/172] - loss: 0.0832
Epoch 7 [113/172] - loss: 0.0757
Epoch 7 [114/172] - loss: 0.0740
Epoch 7 [115/172] - loss: 0.0745
Epoch 7 [116/172] - loss: 0.1004
Epoch 7 [117/172] - loss: 0.0785
Epoch 7 [118/172] - loss: 0.0845
Epoch 7 [119/172] - loss: 0.0773
Epoch 7 [120/172] - loss: 0.1201, acc: 0.9688
Epoch 7 [121/172] - loss: 0.0819
Epoch 7 [122/172] - loss: 0.0843
Epoch 7 [123/172] - loss: 0.0791
Epoch 7 [124/172] - loss: 0.0846
Epoch 7 [125/172] - loss: 0.0726
Epoch 7 [126/172] - loss: 0.0725
Epoch 7 [127/172] - loss: 0.0764
Epoch 7 [128/172] - loss: 0.0751
Epoch 7 [129/172] - loss: 0.0799
Epoch 7 [130/172] - loss: 0.0759, acc: 1.0000
Epoch 7 [131/172] - loss: 0.0957
Epoch 7 [132/172] - loss: 0.2046
Epoch 7 [133/172] - loss: 0.0838
Epoch 7 [134/172] - loss: 0.0810
Epoch 7 [135/172] - loss: 0.0759
Epoch 7 [136/172] - loss: 0.0741
Epoch 7 [137/172] - loss: 0.0872
Epoch 7 [138/172] - loss: 0.0772
Epoch 7 [139/172] - loss: 0.1415
Epoch 7 [140/172] - loss: 0.0798, acc: 1.0000
Epoch 7 [141/172] - loss: 0.0912
Epoch 7 [142/172] - loss: 0.0747
Epoch 7 [143/172] - loss: 0.0837
Epoch 7 [144/172] - loss: 0.0855
Epoch 7 [145/172] - loss: 0.0986
Epoch 7 [146/172] - loss: 0.1159
Epoch 7 [147/172] - loss: 0.0783
Epoch 7 [148/172] - loss: 0.0810
Epoch 7 [149/172] - loss: 0.0739
Epoch 7 [150/172] - loss: 0.0735, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1113
Epoch 7 [152/172] - loss: 0.0730
Epoch 7 [153/172] - loss: 0.0749
Epoch 7 [154/172] - loss: 0.1001
Epoch 7 [155/172] - loss: 0.0828
Epoch 7 [156/172] - loss: 0.1539
Epoch 7 [157/172] - loss: 0.0749
Epoch 7 [158/172] - loss: 0.0773
Epoch 7 [159/172] - loss: 0.0727
Epoch 7 [160/172] - loss: 0.0758, acc: 1.0000
Epoch 7 [161/172] - loss: 0.0761
Epoch 7 [162/172] - loss: 0.0737
Epoch 7 [163/172] - loss: 0.0932
Epoch 7 [164/172] - loss: 0.0791
Epoch 7 [165/172] - loss: 0.0867
Epoch 7 [166/172] - loss: 0.0749
Epoch 7 [167/172] - loss: 0.0786
Epoch 7 [168/172] - loss: 0.0764

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1769, log_difficulty=0.1629, weight=1.8144
neutral: count=11731.0, difficulty=0.1387, log_difficulty=0.1299, weight=1.6494
negative: count=13173.0, difficulty=0.1796, log_difficulty=0.1652, weight=1.8261

当前batch的pt分布：
positive: min=0.8345, max=0.9961, mean=0.9690
neutral: min=0.9467, max=0.9994, mean=0.9856
negative: min=0.8284, max=0.9958, mean=0.9617

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0305
焦点损失: 0.0004
边界损失: 0.1496
总损失: 0.0752
Epoch 7 [169/172] - loss: 0.0752
Epoch 7 [170/172] - loss: 0.0889, acc: 1.0000
Epoch 7 [171/172] - loss: 0.0751
Epoch 7 [172/172] - loss: 0.0720

类别准确率:
positive: 0.8630 (403/467)
neutral: 0.2410 (20/83)
negative: 0.5640 (141/250)

Epoch 7/10
Train Loss: 0.0782, Train Acc: 0.9980
Val Loss: 0.9179, Val Acc: 0.7050
Early stopping triggered!
Best validation accuracy: 0.7425

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_083441-19gwzing
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.3_Multimodal_iterations_20250118_083440
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/19gwzing
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████
wandb:  train_acc ▁▃▄▆▅▆▆▇▆▅▆▇▇███▇███████████████████████
wandb: train_loss ██▆▆▆▂▃▃▂▂▁▂▁▁▁▂▂▁▁▂▂▁▁▁▁▂▁▁▁▁▁▁▁▂▃▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 1
wandb: train_loss 0.08886
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.3_Multimodal_iterations_20250118_083440 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/19gwzing
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_083441-19gwzing/logs
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_084509-nwm8almv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.3_Multimodal_epochs_20250118_084509
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/nwm8almv
wandb: uploading summary; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▆▇▇███
wandb: train_loss █▄▃▂▁▁▁
wandb:    val_acc ▁▆▃█▄▄▄
wandb:   val_loss ▃▁▃▃▄▇█
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.99798
wandb: train_loss 0.07816
wandb:    val_acc 0.705
wandb:   val_loss 0.91794
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.3_Multimodal_epochs_20250118_084509 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/nwm8almv
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_084509-nwm8almv/logs

