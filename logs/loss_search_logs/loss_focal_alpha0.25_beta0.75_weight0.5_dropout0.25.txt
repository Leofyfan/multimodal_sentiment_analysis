=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 0.5 --dropout 0.25 --name loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.25 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.25
text_dim: 128
image_dim: 256
dropout: 0.25
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6955, log_difficulty=0.5280, weight=3.6399
neutral: count=7.0, difficulty=0.6999, log_difficulty=0.5306, weight=3.6530
negative: count=13.0, difficulty=0.6703, log_difficulty=0.5130, weight=3.5649

当前batch的pt分布：
positive: min=0.1730, max=0.5002, mean=0.3045
neutral: min=0.1806, max=0.3819, mean=0.3001
negative: min=0.2280, max=0.4472, mean=0.3297

当前batch准确率：
整体准确率: 0.2188
positive 准确率: 0.1667
neutral 准确率: 0.1429
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1968
焦点损失: 0.4277
边界损失: 0.7614
总损失: 0.9578
Epoch 1 [1/172] - loss: 0.9578, acc: 0.2188
Epoch 1 [2/172] - loss: 0.9252
Epoch 1 [3/172] - loss: 0.9341
Epoch 1 [4/172] - loss: 0.9518
Epoch 1 [5/172] - loss: 0.9371
Epoch 1 [6/172] - loss: 0.8988
Epoch 1 [7/172] - loss: 0.9072
Epoch 1 [8/172] - loss: 0.9012
Epoch 1 [9/172] - loss: 0.9018
Epoch 1 [10/172] - loss: 0.9873, acc: 0.4062
Epoch 1 [11/172] - loss: 0.7733
Epoch 1 [12/172] - loss: 0.8405
Epoch 1 [13/172] - loss: 0.8462
Epoch 1 [14/172] - loss: 0.9348
Epoch 1 [15/172] - loss: 0.8047
Epoch 1 [16/172] - loss: 0.7754
Epoch 1 [17/172] - loss: 0.7981
Epoch 1 [18/172] - loss: 0.8214
Epoch 1 [19/172] - loss: 0.7723
Epoch 1 [20/172] - loss: 0.8454, acc: 0.3125
Epoch 1 [21/172] - loss: 0.8680
Epoch 1 [22/172] - loss: 0.7265
Epoch 1 [23/172] - loss: 0.9569
Epoch 1 [24/172] - loss: 0.7409
Epoch 1 [25/172] - loss: 0.7340
Epoch 1 [26/172] - loss: 0.7887
Epoch 1 [27/172] - loss: 0.9623
Epoch 1 [28/172] - loss: 0.7905
Epoch 1 [29/172] - loss: 0.7156
Epoch 1 [30/172] - loss: 0.6903, acc: 0.7188
Epoch 1 [31/172] - loss: 0.7864
Epoch 1 [32/172] - loss: 0.7210
Epoch 1 [33/172] - loss: 0.8226
Epoch 1 [34/172] - loss: 0.6502
Epoch 1 [35/172] - loss: 1.0485
Epoch 1 [36/172] - loss: 0.6623
Epoch 1 [37/172] - loss: 0.7728
Epoch 1 [38/172] - loss: 0.7441
Epoch 1 [39/172] - loss: 0.6840
Epoch 1 [40/172] - loss: 0.7409, acc: 0.5625
Epoch 1 [41/172] - loss: 0.7444
Epoch 1 [42/172] - loss: 0.4428
Epoch 1 [43/172] - loss: 0.7084
Epoch 1 [44/172] - loss: 0.8663
Epoch 1 [45/172] - loss: 0.8654
Epoch 1 [46/172] - loss: 0.4980
Epoch 1 [47/172] - loss: 0.7139
Epoch 1 [48/172] - loss: 0.5311
Epoch 1 [49/172] - loss: 0.7755
Epoch 1 [50/172] - loss: 0.6365, acc: 0.6250
Epoch 1 [51/172] - loss: 0.6525
Epoch 1 [52/172] - loss: 0.6924
Epoch 1 [53/172] - loss: 0.7373
Epoch 1 [54/172] - loss: 0.7005
Epoch 1 [55/172] - loss: 0.4750
Epoch 1 [56/172] - loss: 0.5488
Epoch 1 [57/172] - loss: 0.6453
Epoch 1 [58/172] - loss: 0.6318
Epoch 1 [59/172] - loss: 0.6676
Epoch 1 [60/172] - loss: 0.4749, acc: 0.7812
Epoch 1 [61/172] - loss: 0.6433
Epoch 1 [62/172] - loss: 0.7627
Epoch 1 [63/172] - loss: 0.5931
Epoch 1 [64/172] - loss: 0.5870
Epoch 1 [65/172] - loss: 0.6610
Epoch 1 [66/172] - loss: 0.5850
Epoch 1 [67/172] - loss: 0.5823
Epoch 1 [68/172] - loss: 0.7047
Epoch 1 [69/172] - loss: 0.7489
Epoch 1 [70/172] - loss: 0.4980, acc: 0.7500
Epoch 1 [71/172] - loss: 0.4655
Epoch 1 [72/172] - loss: 0.6657
Epoch 1 [73/172] - loss: 0.5718
Epoch 1 [74/172] - loss: 0.6200
Epoch 1 [75/172] - loss: 0.4197
Epoch 1 [76/172] - loss: 0.6338
Epoch 1 [77/172] - loss: 0.5643
Epoch 1 [78/172] - loss: 0.5528
Epoch 1 [79/172] - loss: 0.6410
Epoch 1 [80/172] - loss: 0.4916, acc: 0.7188
Epoch 1 [81/172] - loss: 0.5688
Epoch 1 [82/172] - loss: 0.5850
Epoch 1 [83/172] - loss: 0.4541
Epoch 1 [84/172] - loss: 0.4871
Epoch 1 [85/172] - loss: 0.4471
Epoch 1 [86/172] - loss: 0.6609
Epoch 1 [87/172] - loss: 0.4931
Epoch 1 [88/172] - loss: 0.7477
Epoch 1 [89/172] - loss: 0.6741
Epoch 1 [90/172] - loss: 0.4887, acc: 0.6562
Epoch 1 [91/172] - loss: 0.4627
Epoch 1 [92/172] - loss: 0.5049
Epoch 1 [93/172] - loss: 0.5298
Epoch 1 [94/172] - loss: 0.3448
Epoch 1 [95/172] - loss: 0.4814
Epoch 1 [96/172] - loss: 0.5784
Epoch 1 [97/172] - loss: 0.4522
Epoch 1 [98/172] - loss: 0.4145
Epoch 1 [99/172] - loss: 0.6167
Epoch 1 [100/172] - loss: 0.5355, acc: 0.6562

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5618, log_difficulty=0.4459, weight=3.2293
neutral: count=983.0, difficulty=0.5089, log_difficulty=0.4114, weight=3.0568
negative: count=1119.0, difficulty=0.4841, log_difficulty=0.3948, weight=2.9739

当前batch的pt分布：
positive: min=0.0398, max=0.8236, mean=0.4821
neutral: min=0.1845, max=0.9993, mean=0.5584
negative: min=0.1615, max=0.9076, mean=0.5162

当前batch准确率：
整体准确率: 0.6250
positive 准确率: 0.5833
neutral 准确率: 0.7500
negative 准确率: 0.6250

损失分量：
基础交叉熵: 0.8848
焦点损失: 0.4031
边界损失: 0.4114
总损失: 0.6238
Epoch 1 [101/172] - loss: 0.6238
Epoch 1 [102/172] - loss: 0.4539
Epoch 1 [103/172] - loss: 0.5370
Epoch 1 [104/172] - loss: 0.3982
Epoch 1 [105/172] - loss: 0.6614
Epoch 1 [106/172] - loss: 0.8302
Epoch 1 [107/172] - loss: 0.5187
Epoch 1 [108/172] - loss: 0.5885
Epoch 1 [109/172] - loss: 0.4376
Epoch 1 [110/172] - loss: 0.5736, acc: 0.6875
Epoch 1 [111/172] - loss: 0.5969
Epoch 1 [112/172] - loss: 0.4385
Epoch 1 [113/172] - loss: 0.4378
Epoch 1 [114/172] - loss: 0.4584
Epoch 1 [115/172] - loss: 0.4425
Epoch 1 [116/172] - loss: 0.4523
Epoch 1 [117/172] - loss: 0.5677
Epoch 1 [118/172] - loss: 0.4029
Epoch 1 [119/172] - loss: 0.5239
Epoch 1 [120/172] - loss: 0.3104, acc: 0.9062
Epoch 1 [121/172] - loss: 0.3828
Epoch 1 [122/172] - loss: 0.5305
Epoch 1 [123/172] - loss: 0.3840
Epoch 1 [124/172] - loss: 0.6081
Epoch 1 [125/172] - loss: 0.3812
Epoch 1 [126/172] - loss: 0.6347
Epoch 1 [127/172] - loss: 0.3933
Epoch 1 [128/172] - loss: 0.4175
Epoch 1 [129/172] - loss: 0.4792
Epoch 1 [130/172] - loss: 0.3659, acc: 0.8438
Epoch 1 [131/172] - loss: 0.3323
Epoch 1 [132/172] - loss: 0.5219
Epoch 1 [133/172] - loss: 0.4296
Epoch 1 [134/172] - loss: 0.4809
Epoch 1 [135/172] - loss: 0.3493
Epoch 1 [136/172] - loss: 0.3870
Epoch 1 [137/172] - loss: 0.4238
Epoch 1 [138/172] - loss: 0.3183
Epoch 1 [139/172] - loss: 0.3107
Epoch 1 [140/172] - loss: 0.3788, acc: 0.8125
Epoch 1 [141/172] - loss: 0.4474
Epoch 1 [142/172] - loss: 0.3162
Epoch 1 [143/172] - loss: 0.4451
Epoch 1 [144/172] - loss: 0.3777
Epoch 1 [145/172] - loss: 0.3458
Epoch 1 [146/172] - loss: 0.4967
Epoch 1 [147/172] - loss: 0.6645
Epoch 1 [148/172] - loss: 0.4172
Epoch 1 [149/172] - loss: 0.3446
Epoch 1 [150/172] - loss: 0.5233, acc: 0.6250
Epoch 1 [151/172] - loss: 0.6156
Epoch 1 [152/172] - loss: 0.3020
Epoch 1 [153/172] - loss: 0.4068
Epoch 1 [154/172] - loss: 0.2951
Epoch 1 [155/172] - loss: 0.3946
Epoch 1 [156/172] - loss: 0.4516
Epoch 1 [157/172] - loss: 0.4812
Epoch 1 [158/172] - loss: 0.2532
Epoch 1 [159/172] - loss: 0.4493
Epoch 1 [160/172] - loss: 0.3135, acc: 0.8438
Epoch 1 [161/172] - loss: 0.3012
Epoch 1 [162/172] - loss: 0.4921
Epoch 1 [163/172] - loss: 0.3705
Epoch 1 [164/172] - loss: 0.4646
Epoch 1 [165/172] - loss: 0.4161
Epoch 1 [166/172] - loss: 0.3896
Epoch 1 [167/172] - loss: 0.3598
Epoch 1 [168/172] - loss: 0.4701
Epoch 1 [169/172] - loss: 0.3846
Epoch 1 [170/172] - loss: 0.3546, acc: 0.8438
Epoch 1 [171/172] - loss: 0.3114
Epoch 1 [172/172] - loss: 0.3060

类别准确率:
positive: 0.6381 (298/467)
neutral: 0.6627 (55/83)
negative: 0.6360 (159/250)

Epoch 1/10
Train Loss: 0.3824, Train Acc: 0.7919
Val Loss: 0.8181, Val Acc: 0.6400
Epoch 2 [1/172] - loss: 0.2741, acc: 0.9062
Epoch 2 [2/172] - loss: 0.2652
Epoch 2 [3/172] - loss: 0.2397
Epoch 2 [4/172] - loss: 0.4257
Epoch 2 [5/172] - loss: 0.4146
Epoch 2 [6/172] - loss: 0.4086
Epoch 2 [7/172] - loss: 0.3764
Epoch 2 [8/172] - loss: 0.3210
Epoch 2 [9/172] - loss: 0.3486
Epoch 2 [10/172] - loss: 0.2347, acc: 0.8750
Epoch 2 [11/172] - loss: 0.2703
Epoch 2 [12/172] - loss: 0.2351
Epoch 2 [13/172] - loss: 0.4026
Epoch 2 [14/172] - loss: 0.3052
Epoch 2 [15/172] - loss: 0.2479
Epoch 2 [16/172] - loss: 0.3461
Epoch 2 [17/172] - loss: 0.3146
Epoch 2 [18/172] - loss: 0.5014
Epoch 2 [19/172] - loss: 0.3188
Epoch 2 [20/172] - loss: 0.2600, acc: 0.8750
Epoch 2 [21/172] - loss: 0.2204
Epoch 2 [22/172] - loss: 0.3360
Epoch 2 [23/172] - loss: 0.2462
Epoch 2 [24/172] - loss: 0.4967
Epoch 2 [25/172] - loss: 0.2452
Epoch 2 [26/172] - loss: 0.1765
Epoch 2 [27/172] - loss: 0.2245
Epoch 2 [28/172] - loss: 0.2992

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4640, log_difficulty=0.3812, weight=2.9058
neutral: count=1952.0, difficulty=0.3807, log_difficulty=0.3226, weight=2.6129
negative: count=2216.0, difficulty=0.4129, log_difficulty=0.3457, weight=2.7283

当前batch的pt分布：
positive: min=0.2939, max=0.9946, mean=0.7935
neutral: min=0.3472, max=0.9860, mean=0.8283
negative: min=0.0159, max=0.9718, mean=0.7538

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.8889
neutral 准确率: 0.9091
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.3883
焦点损失: 0.1941
边界损失: 0.2256
总损失: 0.3020
Epoch 2 [29/172] - loss: 0.3020
Epoch 2 [30/172] - loss: 0.2905, acc: 0.8125
Epoch 2 [31/172] - loss: 0.2812
Epoch 2 [32/172] - loss: 0.2369
Epoch 2 [33/172] - loss: 0.3044
Epoch 2 [34/172] - loss: 0.2535
Epoch 2 [35/172] - loss: 0.1895
Epoch 2 [36/172] - loss: 0.3230
Epoch 2 [37/172] - loss: 0.1784
Epoch 2 [38/172] - loss: 0.2931
Epoch 2 [39/172] - loss: 0.2916
Epoch 2 [40/172] - loss: 0.3444, acc: 0.8125
Epoch 2 [41/172] - loss: 0.2317
Epoch 2 [42/172] - loss: 0.2008
Epoch 2 [43/172] - loss: 0.1863
Epoch 2 [44/172] - loss: 0.4265
Epoch 2 [45/172] - loss: 0.1682
Epoch 2 [46/172] - loss: 0.2136
Epoch 2 [47/172] - loss: 0.3224
Epoch 2 [48/172] - loss: 0.2847
Epoch 2 [49/172] - loss: 0.2786
Epoch 2 [50/172] - loss: 0.3271, acc: 0.8125
Epoch 2 [51/172] - loss: 0.3463
Epoch 2 [52/172] - loss: 0.2353
Epoch 2 [53/172] - loss: 0.2487
Epoch 2 [54/172] - loss: 0.1771
Epoch 2 [55/172] - loss: 0.2309
Epoch 2 [56/172] - loss: 0.1772
Epoch 2 [57/172] - loss: 0.1925
Epoch 2 [58/172] - loss: 0.2623
Epoch 2 [59/172] - loss: 0.4734
Epoch 2 [60/172] - loss: 0.2592, acc: 0.8750
Epoch 2 [61/172] - loss: 0.1824
Epoch 2 [62/172] - loss: 0.1869
Epoch 2 [63/172] - loss: 0.2413
Epoch 2 [64/172] - loss: 0.3116
Epoch 2 [65/172] - loss: 0.2649
Epoch 2 [66/172] - loss: 0.2076
Epoch 2 [67/172] - loss: 0.1746
Epoch 2 [68/172] - loss: 0.3298
Epoch 2 [69/172] - loss: 0.1916
Epoch 2 [70/172] - loss: 0.2995, acc: 0.9062
Epoch 2 [71/172] - loss: 0.3290
Epoch 2 [72/172] - loss: 0.2453
Epoch 2 [73/172] - loss: 0.3625
Epoch 2 [74/172] - loss: 0.2706
Epoch 2 [75/172] - loss: 0.2211
Epoch 2 [76/172] - loss: 0.2973
Epoch 2 [77/172] - loss: 0.2534
Epoch 2 [78/172] - loss: 0.2411
Epoch 2 [79/172] - loss: 0.2037
Epoch 2 [80/172] - loss: 0.1884, acc: 0.9375
Epoch 2 [81/172] - loss: 0.1738
Epoch 2 [82/172] - loss: 0.2175
Epoch 2 [83/172] - loss: 0.2488
Epoch 2 [84/172] - loss: 0.2424
Epoch 2 [85/172] - loss: 0.2831
Epoch 2 [86/172] - loss: 0.2702
Epoch 2 [87/172] - loss: 0.4529
Epoch 2 [88/172] - loss: 0.2090
Epoch 2 [89/172] - loss: 0.1986
Epoch 2 [90/172] - loss: 0.2367, acc: 0.9062
Epoch 2 [91/172] - loss: 0.2210
Epoch 2 [92/172] - loss: 0.3053
Epoch 2 [93/172] - loss: 0.2462
Epoch 2 [94/172] - loss: 0.2732
Epoch 2 [95/172] - loss: 0.2664
Epoch 2 [96/172] - loss: 0.2029
Epoch 2 [97/172] - loss: 0.2235
Epoch 2 [98/172] - loss: 0.2217
Epoch 2 [99/172] - loss: 0.1591
Epoch 2 [100/172] - loss: 0.2158, acc: 0.8438
Epoch 2 [101/172] - loss: 0.2155
Epoch 2 [102/172] - loss: 0.2311
Epoch 2 [103/172] - loss: 0.2994
Epoch 2 [104/172] - loss: 0.2376
Epoch 2 [105/172] - loss: 0.2150
Epoch 2 [106/172] - loss: 0.2107
Epoch 2 [107/172] - loss: 0.1931
Epoch 2 [108/172] - loss: 0.2608
Epoch 2 [109/172] - loss: 0.2026
Epoch 2 [110/172] - loss: 0.2249, acc: 0.8750
Epoch 2 [111/172] - loss: 0.1966
Epoch 2 [112/172] - loss: 0.1587
Epoch 2 [113/172] - loss: 0.1786
Epoch 2 [114/172] - loss: 0.1980
Epoch 2 [115/172] - loss: 0.2667
Epoch 2 [116/172] - loss: 0.2637
Epoch 2 [117/172] - loss: 0.3875
Epoch 2 [118/172] - loss: 0.2146
Epoch 2 [119/172] - loss: 0.1590
Epoch 2 [120/172] - loss: 0.1783, acc: 0.9375
Epoch 2 [121/172] - loss: 0.1933
Epoch 2 [122/172] - loss: 0.3839
Epoch 2 [123/172] - loss: 0.2846
Epoch 2 [124/172] - loss: 0.2109
Epoch 2 [125/172] - loss: 0.1445
Epoch 2 [126/172] - loss: 0.1963
Epoch 2 [127/172] - loss: 0.2365
Epoch 2 [128/172] - loss: 0.1790

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3895, log_difficulty=0.3289, weight=2.6446
neutral: count=2949.0, difficulty=0.2901, log_difficulty=0.2547, weight=2.2734
negative: count=3294.0, difficulty=0.3471, log_difficulty=0.2980, weight=2.4899

当前batch的pt分布：
positive: min=0.4471, max=0.9947, mean=0.8200
neutral: min=0.5412, max=0.9937, mean=0.8851
negative: min=0.0685, max=0.9873, mean=0.7884

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.2598
焦点损失: 0.0950
边界损失: 0.2234
总损失: 0.2268
Epoch 2 [129/172] - loss: 0.2268
Epoch 2 [130/172] - loss: 0.2714, acc: 0.8750
Epoch 2 [131/172] - loss: 0.1767
Epoch 2 [132/172] - loss: 0.2625
Epoch 2 [133/172] - loss: 0.1906
Epoch 2 [134/172] - loss: 0.2304
Epoch 2 [135/172] - loss: 0.3308
Epoch 2 [136/172] - loss: 0.2112
Epoch 2 [137/172] - loss: 0.1857
Epoch 2 [138/172] - loss: 0.2154
Epoch 2 [139/172] - loss: 0.1976
Epoch 2 [140/172] - loss: 0.1881, acc: 0.9375
Epoch 2 [141/172] - loss: 0.2342
Epoch 2 [142/172] - loss: 0.2180
Epoch 2 [143/172] - loss: 0.1785
Epoch 2 [144/172] - loss: 0.1620
Epoch 2 [145/172] - loss: 0.4285
Epoch 2 [146/172] - loss: 0.2013
Epoch 2 [147/172] - loss: 0.2062
Epoch 2 [148/172] - loss: 0.2247
Epoch 2 [149/172] - loss: 0.1802
Epoch 2 [150/172] - loss: 0.2414, acc: 0.9062
Epoch 2 [151/172] - loss: 0.2570
Epoch 2 [152/172] - loss: 0.1731
Epoch 2 [153/172] - loss: 0.1947
Epoch 2 [154/172] - loss: 0.1829
Epoch 2 [155/172] - loss: 0.1835
Epoch 2 [156/172] - loss: 0.2075
Epoch 2 [157/172] - loss: 0.1780
Epoch 2 [158/172] - loss: 0.2651
Epoch 2 [159/172] - loss: 0.2110
Epoch 2 [160/172] - loss: 0.1950, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1957
Epoch 2 [162/172] - loss: 0.1506
Epoch 2 [163/172] - loss: 0.3626
Epoch 2 [164/172] - loss: 0.2894
Epoch 2 [165/172] - loss: 0.3386
Epoch 2 [166/172] - loss: 0.2629
Epoch 2 [167/172] - loss: 0.3120
Epoch 2 [168/172] - loss: 0.2417
Epoch 2 [169/172] - loss: 0.1704
Epoch 2 [170/172] - loss: 0.1592, acc: 1.0000
Epoch 2 [171/172] - loss: 0.2609
Epoch 2 [172/172] - loss: 0.3838

类别准确率:
positive: 0.9101 (425/467)
neutral: 0.2892 (24/83)
negative: 0.5000 (125/250)

Epoch 2/10
Train Loss: 0.2486, Train Acc: 0.9091
Val Loss: 0.8075, Val Acc: 0.7175
Epoch 3 [1/172] - loss: 0.2431, acc: 0.9375
Epoch 3 [2/172] - loss: 0.1718
Epoch 3 [3/172] - loss: 0.1457
Epoch 3 [4/172] - loss: 0.1498
Epoch 3 [5/172] - loss: 0.1972
Epoch 3 [6/172] - loss: 0.1479
Epoch 3 [7/172] - loss: 0.1607
Epoch 3 [8/172] - loss: 0.2208
Epoch 3 [9/172] - loss: 0.1574
Epoch 3 [10/172] - loss: 0.1359, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1363
Epoch 3 [12/172] - loss: 0.1201
Epoch 3 [13/172] - loss: 0.1380
Epoch 3 [14/172] - loss: 0.1393
Epoch 3 [15/172] - loss: 0.1485
Epoch 3 [16/172] - loss: 0.2721
Epoch 3 [17/172] - loss: 0.1869
Epoch 3 [18/172] - loss: 0.1852
Epoch 3 [19/172] - loss: 0.1602
Epoch 3 [20/172] - loss: 0.1460, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1561
Epoch 3 [22/172] - loss: 0.1957
Epoch 3 [23/172] - loss: 0.1273
Epoch 3 [24/172] - loss: 0.1469
Epoch 3 [25/172] - loss: 0.1721
Epoch 3 [26/172] - loss: 0.1552
Epoch 3 [27/172] - loss: 0.1465
Epoch 3 [28/172] - loss: 0.1222
Epoch 3 [29/172] - loss: 0.1941
Epoch 3 [30/172] - loss: 0.1825, acc: 0.9062
Epoch 3 [31/172] - loss: 0.1362
Epoch 3 [32/172] - loss: 0.1884
Epoch 3 [33/172] - loss: 0.1814
Epoch 3 [34/172] - loss: 0.1813
Epoch 3 [35/172] - loss: 0.2140
Epoch 3 [36/172] - loss: 0.1611
Epoch 3 [37/172] - loss: 0.2120
Epoch 3 [38/172] - loss: 0.1194
Epoch 3 [39/172] - loss: 0.1279
Epoch 3 [40/172] - loss: 0.1395, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1511
Epoch 3 [42/172] - loss: 0.1911
Epoch 3 [43/172] - loss: 0.1301
Epoch 3 [44/172] - loss: 0.1904
Epoch 3 [45/172] - loss: 0.1362
Epoch 3 [46/172] - loss: 0.1985
Epoch 3 [47/172] - loss: 0.1413
Epoch 3 [48/172] - loss: 0.1485
Epoch 3 [49/172] - loss: 0.1318
Epoch 3 [50/172] - loss: 0.1394, acc: 1.0000
Epoch 3 [51/172] - loss: 0.1942
Epoch 3 [52/172] - loss: 0.1741
Epoch 3 [53/172] - loss: 0.1414
Epoch 3 [54/172] - loss: 0.1666
Epoch 3 [55/172] - loss: 0.1759
Epoch 3 [56/172] - loss: 0.1411

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3282, log_difficulty=0.2838, weight=2.4192
neutral: count=3923.0, difficulty=0.2417, log_difficulty=0.2165, weight=2.0826
negative: count=4382.0, difficulty=0.2937, log_difficulty=0.2575, weight=2.2874

当前batch的pt分布：
positive: min=0.0747, max=0.9965, mean=0.8585
neutral: min=0.0018, max=0.9894, mean=0.7739
negative: min=0.9730, max=0.9993, mean=0.9884

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9091
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.4105
焦点损失: 0.2880
边界损失: 0.1908
总损失: 0.2988
Epoch 3 [57/172] - loss: 0.2988
Epoch 3 [58/172] - loss: 0.1354
Epoch 3 [59/172] - loss: 0.1397
Epoch 3 [60/172] - loss: 0.1455, acc: 0.9688
Epoch 3 [61/172] - loss: 0.2441
Epoch 3 [62/172] - loss: 0.1552
Epoch 3 [63/172] - loss: 0.1496
Epoch 3 [64/172] - loss: 0.1575
Epoch 3 [65/172] - loss: 0.1697
Epoch 3 [66/172] - loss: 0.1753
Epoch 3 [67/172] - loss: 0.1383
Epoch 3 [68/172] - loss: 0.1501
Epoch 3 [69/172] - loss: 0.2337
Epoch 3 [70/172] - loss: 0.1164, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1400
Epoch 3 [72/172] - loss: 0.2037
Epoch 3 [73/172] - loss: 0.1229
Epoch 3 [74/172] - loss: 0.1842
Epoch 3 [75/172] - loss: 0.1463
Epoch 3 [76/172] - loss: 0.1853
Epoch 3 [77/172] - loss: 0.1434
Epoch 3 [78/172] - loss: 0.2502
Epoch 3 [79/172] - loss: 0.1579
Epoch 3 [80/172] - loss: 0.1351, acc: 1.0000
Epoch 3 [81/172] - loss: 0.1494
Epoch 3 [82/172] - loss: 0.1499
Epoch 3 [83/172] - loss: 0.1197
Epoch 3 [84/172] - loss: 0.1296
Epoch 3 [85/172] - loss: 0.1625
Epoch 3 [86/172] - loss: 0.1327
Epoch 3 [87/172] - loss: 0.1887
Epoch 3 [88/172] - loss: 0.1313
Epoch 3 [89/172] - loss: 0.1164
Epoch 3 [90/172] - loss: 0.1340, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1859
Epoch 3 [92/172] - loss: 0.1373
Epoch 3 [93/172] - loss: 0.2001
Epoch 3 [94/172] - loss: 0.1449
Epoch 3 [95/172] - loss: 0.1582
Epoch 3 [96/172] - loss: 0.1960
Epoch 3 [97/172] - loss: 0.1614
Epoch 3 [98/172] - loss: 0.1427
Epoch 3 [99/172] - loss: 0.1389
Epoch 3 [100/172] - loss: 0.1765, acc: 0.9688
Epoch 3 [101/172] - loss: 0.2266
Epoch 3 [102/172] - loss: 0.1231
Epoch 3 [103/172] - loss: 0.1718
Epoch 3 [104/172] - loss: 0.1286
Epoch 3 [105/172] - loss: 0.1296
Epoch 3 [106/172] - loss: 0.1307
Epoch 3 [107/172] - loss: 0.1275
Epoch 3 [108/172] - loss: 0.1297
Epoch 3 [109/172] - loss: 0.1245
Epoch 3 [110/172] - loss: 0.2042, acc: 0.9062
Epoch 3 [111/172] - loss: 0.1732
Epoch 3 [112/172] - loss: 0.1179
Epoch 3 [113/172] - loss: 0.1305
Epoch 3 [114/172] - loss: 0.1644
Epoch 3 [115/172] - loss: 0.1803
Epoch 3 [116/172] - loss: 0.1369
Epoch 3 [117/172] - loss: 0.1657
Epoch 3 [118/172] - loss: 0.1466
Epoch 3 [119/172] - loss: 0.1820
Epoch 3 [120/172] - loss: 0.1421, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1373
Epoch 3 [122/172] - loss: 0.1473
Epoch 3 [123/172] - loss: 0.1673
Epoch 3 [124/172] - loss: 0.1222
Epoch 3 [125/172] - loss: 0.1283
Epoch 3 [126/172] - loss: 0.2034
Epoch 3 [127/172] - loss: 0.1637
Epoch 3 [128/172] - loss: 0.1201
Epoch 3 [129/172] - loss: 0.1192
Epoch 3 [130/172] - loss: 0.1500, acc: 0.9688
Epoch 3 [131/172] - loss: 0.2245
Epoch 3 [132/172] - loss: 0.1158
Epoch 3 [133/172] - loss: 0.1468
Epoch 3 [134/172] - loss: 0.1228
Epoch 3 [135/172] - loss: 0.1259
Epoch 3 [136/172] - loss: 0.1389
Epoch 3 [137/172] - loss: 0.1240
Epoch 3 [138/172] - loss: 0.1525
Epoch 3 [139/172] - loss: 0.1365
Epoch 3 [140/172] - loss: 0.1402, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1821
Epoch 3 [142/172] - loss: 0.3822
Epoch 3 [143/172] - loss: 0.1809
Epoch 3 [144/172] - loss: 0.1756
Epoch 3 [145/172] - loss: 0.1354
Epoch 3 [146/172] - loss: 0.1222
Epoch 3 [147/172] - loss: 0.1397
Epoch 3 [148/172] - loss: 0.2092
Epoch 3 [149/172] - loss: 0.1162
Epoch 3 [150/172] - loss: 0.1499, acc: 0.9375
Epoch 3 [151/172] - loss: 0.2588
Epoch 3 [152/172] - loss: 0.2053
Epoch 3 [153/172] - loss: 0.1762
Epoch 3 [154/172] - loss: 0.1414
Epoch 3 [155/172] - loss: 0.1300
Epoch 3 [156/172] - loss: 0.1360

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2826, log_difficulty=0.2489, weight=2.2444
neutral: count=4903.0, difficulty=0.2057, log_difficulty=0.1871, weight=1.9354
negative: count=5500.0, difficulty=0.2543, log_difficulty=0.2266, weight=2.1328

当前batch的pt分布：
positive: min=0.4097, max=0.9951, mean=0.9169
neutral: min=0.7216, max=0.9981, mean=0.9507
negative: min=0.1118, max=0.9977, mean=0.7689

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 0.7000

损失分量：
基础交叉熵: 0.1923
焦点损失: 0.0841
边界损失: 0.1831
总损失: 0.1823
Epoch 3 [157/172] - loss: 0.1823
Epoch 3 [158/172] - loss: 0.2071
Epoch 3 [159/172] - loss: 0.1417
Epoch 3 [160/172] - loss: 0.2334, acc: 0.8438
Epoch 3 [161/172] - loss: 0.2453
Epoch 3 [162/172] - loss: 0.2154
Epoch 3 [163/172] - loss: 0.2027
Epoch 3 [164/172] - loss: 0.1335
Epoch 3 [165/172] - loss: 0.1275
Epoch 3 [166/172] - loss: 0.1405
Epoch 3 [167/172] - loss: 0.1814
Epoch 3 [168/172] - loss: 0.1196
Epoch 3 [169/172] - loss: 0.1189
Epoch 3 [170/172] - loss: 0.1639, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1221
Epoch 3 [172/172] - loss: 0.1132

类别准确率:
positive: 0.7580 (354/467)
neutral: 0.2169 (18/83)
negative: 0.7520 (188/250)

Epoch 3/10
Train Loss: 0.1655, Train Acc: 0.9414
Val Loss: 0.8688, Val Acc: 0.7000
Epoch 4 [1/172] - loss: 0.1190, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1444
Epoch 4 [3/172] - loss: 0.1475
Epoch 4 [4/172] - loss: 0.1532
Epoch 4 [5/172] - loss: 0.1500
Epoch 4 [6/172] - loss: 0.1121
Epoch 4 [7/172] - loss: 0.1303
Epoch 4 [8/172] - loss: 0.1504
Epoch 4 [9/172] - loss: 0.2033
Epoch 4 [10/172] - loss: 0.1703, acc: 0.9688
Epoch 4 [11/172] - loss: 0.1189
Epoch 4 [12/172] - loss: 0.1602
Epoch 4 [13/172] - loss: 0.1487
Epoch 4 [14/172] - loss: 0.1366
Epoch 4 [15/172] - loss: 0.1563
Epoch 4 [16/172] - loss: 0.1118
Epoch 4 [17/172] - loss: 0.1215
Epoch 4 [18/172] - loss: 0.1366
Epoch 4 [19/172] - loss: 0.1184
Epoch 4 [20/172] - loss: 0.1480, acc: 0.9688
Epoch 4 [21/172] - loss: 0.2211
Epoch 4 [22/172] - loss: 0.1162
Epoch 4 [23/172] - loss: 0.1476
Epoch 4 [24/172] - loss: 0.1106
Epoch 4 [25/172] - loss: 0.1109
Epoch 4 [26/172] - loss: 0.1648
Epoch 4 [27/172] - loss: 0.1183
Epoch 4 [28/172] - loss: 0.1425
Epoch 4 [29/172] - loss: 0.1144
Epoch 4 [30/172] - loss: 0.1315, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1516
Epoch 4 [32/172] - loss: 0.1871
Epoch 4 [33/172] - loss: 0.1271
Epoch 4 [34/172] - loss: 0.1183
Epoch 4 [35/172] - loss: 0.1217
Epoch 4 [36/172] - loss: 0.1242
Epoch 4 [37/172] - loss: 0.1083
Epoch 4 [38/172] - loss: 0.1116
Epoch 4 [39/172] - loss: 0.1759
Epoch 4 [40/172] - loss: 0.2132, acc: 0.8750
Epoch 4 [41/172] - loss: 0.1214
Epoch 4 [42/172] - loss: 0.1282
Epoch 4 [43/172] - loss: 0.1405
Epoch 4 [44/172] - loss: 0.1186
Epoch 4 [45/172] - loss: 0.1142
Epoch 4 [46/172] - loss: 0.1477
Epoch 4 [47/172] - loss: 0.1593
Epoch 4 [48/172] - loss: 0.1196
Epoch 4 [49/172] - loss: 0.1127
Epoch 4 [50/172] - loss: 0.1841, acc: 0.9688
Epoch 4 [51/172] - loss: 0.1136
Epoch 4 [52/172] - loss: 0.1255
Epoch 4 [53/172] - loss: 0.1183
Epoch 4 [54/172] - loss: 0.1368
Epoch 4 [55/172] - loss: 0.1879
Epoch 4 [56/172] - loss: 0.1198
Epoch 4 [57/172] - loss: 0.1089
Epoch 4 [58/172] - loss: 0.1164
Epoch 4 [59/172] - loss: 0.1113
Epoch 4 [60/172] - loss: 0.1144, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1184
Epoch 4 [62/172] - loss: 0.1418
Epoch 4 [63/172] - loss: 0.1287
Epoch 4 [64/172] - loss: 0.1110
Epoch 4 [65/172] - loss: 0.1284
Epoch 4 [66/172] - loss: 0.1161
Epoch 4 [67/172] - loss: 0.1203
Epoch 4 [68/172] - loss: 0.1139
Epoch 4 [69/172] - loss: 0.1284
Epoch 4 [70/172] - loss: 0.1593, acc: 0.9688
Epoch 4 [71/172] - loss: 0.1294
Epoch 4 [72/172] - loss: 0.1148
Epoch 4 [73/172] - loss: 0.1194
Epoch 4 [74/172] - loss: 0.2224
Epoch 4 [75/172] - loss: 0.1680
Epoch 4 [76/172] - loss: 0.1090
Epoch 4 [77/172] - loss: 0.1174
Epoch 4 [78/172] - loss: 0.1151
Epoch 4 [79/172] - loss: 0.1110
Epoch 4 [80/172] - loss: 0.1372, acc: 0.9375
Epoch 4 [81/172] - loss: 0.1845
Epoch 4 [82/172] - loss: 0.1123
Epoch 4 [83/172] - loss: 0.1237
Epoch 4 [84/172] - loss: 0.1284

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2476, log_difficulty=0.2212, weight=2.1061
neutral: count=5865.0, difficulty=0.1798, log_difficulty=0.1654, weight=1.8268
negative: count=6629.0, difficulty=0.2238, log_difficulty=0.2020, weight=2.0098

当前batch的pt分布：
positive: min=0.4435, max=0.9967, mean=0.8890
neutral: min=0.9844, max=0.9994, mean=0.9937
negative: min=0.0109, max=0.9981, mean=0.8852

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.2113
焦点损失: 0.1465
边界损失: 0.1659
总损失: 0.1983
Epoch 4 [85/172] - loss: 0.1983
Epoch 4 [86/172] - loss: 0.1946
Epoch 4 [87/172] - loss: 0.1713
Epoch 4 [88/172] - loss: 0.1089
Epoch 4 [89/172] - loss: 0.1186
Epoch 4 [90/172] - loss: 0.1239, acc: 1.0000
Epoch 4 [91/172] - loss: 0.2117
Epoch 4 [92/172] - loss: 0.1922
Epoch 4 [93/172] - loss: 0.1100
Epoch 4 [94/172] - loss: 0.1110
Epoch 4 [95/172] - loss: 0.1351
Epoch 4 [96/172] - loss: 0.1263
Epoch 4 [97/172] - loss: 0.1227
Epoch 4 [98/172] - loss: 0.1227
Epoch 4 [99/172] - loss: 0.1165
Epoch 4 [100/172] - loss: 0.1666, acc: 0.9375
Epoch 4 [101/172] - loss: 0.1214
Epoch 4 [102/172] - loss: 0.1165
Epoch 4 [103/172] - loss: 0.1301
Epoch 4 [104/172] - loss: 0.1172
Epoch 4 [105/172] - loss: 0.1905
Epoch 4 [106/172] - loss: 0.1149
Epoch 4 [107/172] - loss: 0.1095
Epoch 4 [108/172] - loss: 0.1463
Epoch 4 [109/172] - loss: 0.1229
Epoch 4 [110/172] - loss: 0.2471, acc: 0.9375
Epoch 4 [111/172] - loss: 0.1443
Epoch 4 [112/172] - loss: 0.1257
Epoch 4 [113/172] - loss: 0.1106
Epoch 4 [114/172] - loss: 0.1370
Epoch 4 [115/172] - loss: 0.1370
Epoch 4 [116/172] - loss: 0.1207
Epoch 4 [117/172] - loss: 0.1120
Epoch 4 [118/172] - loss: 0.1743
Epoch 4 [119/172] - loss: 0.1091
Epoch 4 [120/172] - loss: 0.1860, acc: 0.9688
Epoch 4 [121/172] - loss: 0.1270
Epoch 4 [122/172] - loss: 0.1841
Epoch 4 [123/172] - loss: 0.1256
Epoch 4 [124/172] - loss: 0.1409
Epoch 4 [125/172] - loss: 0.1296
Epoch 4 [126/172] - loss: 0.2059
Epoch 4 [127/172] - loss: 0.1985
Epoch 4 [128/172] - loss: 0.1315
Epoch 4 [129/172] - loss: 0.1107
Epoch 4 [130/172] - loss: 0.1098, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1214
Epoch 4 [132/172] - loss: 0.1128
Epoch 4 [133/172] - loss: 0.1130
Epoch 4 [134/172] - loss: 0.1244
Epoch 4 [135/172] - loss: 0.1224
Epoch 4 [136/172] - loss: 0.1372
Epoch 4 [137/172] - loss: 0.1336
Epoch 4 [138/172] - loss: 0.1252
Epoch 4 [139/172] - loss: 0.1382
Epoch 4 [140/172] - loss: 0.1571, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1503
Epoch 4 [142/172] - loss: 0.1337
Epoch 4 [143/172] - loss: 0.1141
Epoch 4 [144/172] - loss: 0.1211
Epoch 4 [145/172] - loss: 0.1739
Epoch 4 [146/172] - loss: 0.1122
Epoch 4 [147/172] - loss: 0.1537
Epoch 4 [148/172] - loss: 0.1311
Epoch 4 [149/172] - loss: 0.1303
Epoch 4 [150/172] - loss: 0.1418, acc: 0.9688
Epoch 4 [151/172] - loss: 0.2508
Epoch 4 [152/172] - loss: 0.1116
Epoch 4 [153/172] - loss: 0.1272
Epoch 4 [154/172] - loss: 0.1733
Epoch 4 [155/172] - loss: 0.1454
Epoch 4 [156/172] - loss: 0.1429
Epoch 4 [157/172] - loss: 0.1975
Epoch 4 [158/172] - loss: 0.1217
Epoch 4 [159/172] - loss: 0.1126
Epoch 4 [160/172] - loss: 0.1167, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1483
Epoch 4 [162/172] - loss: 0.1209
Epoch 4 [163/172] - loss: 0.1265
Epoch 4 [164/172] - loss: 0.1129
Epoch 4 [165/172] - loss: 0.1355
Epoch 4 [166/172] - loss: 0.1356
Epoch 4 [167/172] - loss: 0.1585
Epoch 4 [168/172] - loss: 0.1296
Epoch 4 [169/172] - loss: 0.2096
Epoch 4 [170/172] - loss: 0.1383, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1396
Epoch 4 [172/172] - loss: 0.1708

类别准确率:
positive: 0.8544 (399/467)
neutral: 0.4458 (37/83)
negative: 0.5880 (147/250)

Epoch 4/10
Train Loss: 0.1422, Train Acc: 0.9636
Val Loss: 0.8636, Val Acc: 0.7288
Epoch 5 [1/172] - loss: 0.1090, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1243
Epoch 5 [3/172] - loss: 0.1093
Epoch 5 [4/172] - loss: 0.1208
Epoch 5 [5/172] - loss: 0.1074
Epoch 5 [6/172] - loss: 0.1228
Epoch 5 [7/172] - loss: 0.1128
Epoch 5 [8/172] - loss: 0.1208
Epoch 5 [9/172] - loss: 0.1437
Epoch 5 [10/172] - loss: 0.1202, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1206
Epoch 5 [12/172] - loss: 0.1140

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2219, log_difficulty=0.2004, weight=2.0021
neutral: count=6845.0, difficulty=0.1595, log_difficulty=0.1480, weight=1.7400
negative: count=7694.0, difficulty=0.2010, log_difficulty=0.1832, weight=1.9158

当前batch的pt分布：
positive: min=0.0675, max=0.9974, mean=0.8651
neutral: min=0.9932, max=0.9996, mean=0.9971
negative: min=0.9509, max=0.9961, mean=0.9826

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8571
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1328
焦点损失: 0.0846
边界损失: 0.1556
总损失: 0.1591
Epoch 5 [13/172] - loss: 0.1591
Epoch 5 [14/172] - loss: 0.1321
Epoch 5 [15/172] - loss: 0.1084
Epoch 5 [16/172] - loss: 0.1270
Epoch 5 [17/172] - loss: 0.1144
Epoch 5 [18/172] - loss: 0.1156
Epoch 5 [19/172] - loss: 0.1758
Epoch 5 [20/172] - loss: 0.1402, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1457
Epoch 5 [22/172] - loss: 0.1951
Epoch 5 [23/172] - loss: 0.1085
Epoch 5 [24/172] - loss: 0.1177
Epoch 5 [25/172] - loss: 0.1085
Epoch 5 [26/172] - loss: 0.1370
Epoch 5 [27/172] - loss: 0.1111
Epoch 5 [28/172] - loss: 0.1325
Epoch 5 [29/172] - loss: 0.1112
Epoch 5 [30/172] - loss: 0.1168, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1126
Epoch 5 [32/172] - loss: 0.1096
Epoch 5 [33/172] - loss: 0.1346
Epoch 5 [34/172] - loss: 0.1262
Epoch 5 [35/172] - loss: 0.1085
Epoch 5 [36/172] - loss: 0.1222
Epoch 5 [37/172] - loss: 0.1131
Epoch 5 [38/172] - loss: 0.1090
Epoch 5 [39/172] - loss: 0.1689
Epoch 5 [40/172] - loss: 0.1211, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1147
Epoch 5 [42/172] - loss: 0.1334
Epoch 5 [43/172] - loss: 0.1956
Epoch 5 [44/172] - loss: 0.1181
Epoch 5 [45/172] - loss: 0.1085
Epoch 5 [46/172] - loss: 0.1286
Epoch 5 [47/172] - loss: 0.1099
Epoch 5 [48/172] - loss: 0.1472
Epoch 5 [49/172] - loss: 0.1124
Epoch 5 [50/172] - loss: 0.1221, acc: 1.0000
Epoch 5 [51/172] - loss: 0.1167
Epoch 5 [52/172] - loss: 0.1120
Epoch 5 [53/172] - loss: 0.1170
Epoch 5 [54/172] - loss: 0.1109
Epoch 5 [55/172] - loss: 0.1410
Epoch 5 [56/172] - loss: 0.1159
Epoch 5 [57/172] - loss: 0.1111
Epoch 5 [58/172] - loss: 0.1640
Epoch 5 [59/172] - loss: 0.1602
Epoch 5 [60/172] - loss: 0.1098, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1159
Epoch 5 [62/172] - loss: 0.1238
Epoch 5 [63/172] - loss: 0.1952
Epoch 5 [64/172] - loss: 0.1131
Epoch 5 [65/172] - loss: 0.1075
Epoch 5 [66/172] - loss: 0.1117
Epoch 5 [67/172] - loss: 0.1072
Epoch 5 [68/172] - loss: 0.1193
Epoch 5 [69/172] - loss: 0.1092
Epoch 5 [70/172] - loss: 0.1128, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1143
Epoch 5 [72/172] - loss: 0.1436
Epoch 5 [73/172] - loss: 0.1090
Epoch 5 [74/172] - loss: 0.1679
Epoch 5 [75/172] - loss: 0.1056
Epoch 5 [76/172] - loss: 0.1098
Epoch 5 [77/172] - loss: 0.1076
Epoch 5 [78/172] - loss: 0.1386
Epoch 5 [79/172] - loss: 0.1068
Epoch 5 [80/172] - loss: 0.1071, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1454
Epoch 5 [82/172] - loss: 0.1679
Epoch 5 [83/172] - loss: 0.1198
Epoch 5 [84/172] - loss: 0.1056
Epoch 5 [85/172] - loss: 0.1808
Epoch 5 [86/172] - loss: 0.1095
Epoch 5 [87/172] - loss: 0.1143
Epoch 5 [88/172] - loss: 0.1382
Epoch 5 [89/172] - loss: 0.1089
Epoch 5 [90/172] - loss: 0.1809, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1129
Epoch 5 [92/172] - loss: 0.1276
Epoch 5 [93/172] - loss: 0.1067
Epoch 5 [94/172] - loss: 0.1077
Epoch 5 [95/172] - loss: 0.1142
Epoch 5 [96/172] - loss: 0.1663
Epoch 5 [97/172] - loss: 0.1192
Epoch 5 [98/172] - loss: 0.1528
Epoch 5 [99/172] - loss: 0.1460
Epoch 5 [100/172] - loss: 0.1149, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1146
Epoch 5 [102/172] - loss: 0.1111
Epoch 5 [103/172] - loss: 0.1135
Epoch 5 [104/172] - loss: 0.2092
Epoch 5 [105/172] - loss: 0.2122
Epoch 5 [106/172] - loss: 0.1084
Epoch 5 [107/172] - loss: 0.1280
Epoch 5 [108/172] - loss: 0.1363
Epoch 5 [109/172] - loss: 0.1093
Epoch 5 [110/172] - loss: 0.1106, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1270
Epoch 5 [112/172] - loss: 0.1277

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.1991, log_difficulty=0.1816, weight=1.9081
neutral: count=7825.0, difficulty=0.1434, log_difficulty=0.1340, weight=1.6699
negative: count=8780.0, difficulty=0.1822, log_difficulty=0.1674, weight=1.8370

当前batch的pt分布：
positive: min=0.1171, max=0.9944, mean=0.8948
neutral: min=0.9474, max=0.9984, mean=0.9842
negative: min=0.9885, max=0.9999, mean=0.9971

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1003
焦点损失: 0.0529
边界损失: 0.1537
总损失: 0.1405
Epoch 5 [113/172] - loss: 0.1405
Epoch 5 [114/172] - loss: 0.1456
Epoch 5 [115/172] - loss: 0.1122
Epoch 5 [116/172] - loss: 0.1101
Epoch 5 [117/172] - loss: 0.1110
Epoch 5 [118/172] - loss: 0.1091
Epoch 5 [119/172] - loss: 0.1073
Epoch 5 [120/172] - loss: 0.1145, acc: 1.0000
Epoch 5 [121/172] - loss: 0.1140
Epoch 5 [122/172] - loss: 0.1152
Epoch 5 [123/172] - loss: 0.1112
Epoch 5 [124/172] - loss: 0.1108
Epoch 5 [125/172] - loss: 0.1093
Epoch 5 [126/172] - loss: 0.1111
Epoch 5 [127/172] - loss: 0.1229
Epoch 5 [128/172] - loss: 0.1157
Epoch 5 [129/172] - loss: 0.1290
Epoch 5 [130/172] - loss: 0.1066, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1245
Epoch 5 [132/172] - loss: 0.1457
Epoch 5 [133/172] - loss: 0.1379
Epoch 5 [134/172] - loss: 0.1751
Epoch 5 [135/172] - loss: 0.1102
Epoch 5 [136/172] - loss: 0.1079
Epoch 5 [137/172] - loss: 0.1205
Epoch 5 [138/172] - loss: 0.1235
Epoch 5 [139/172] - loss: 0.1986
Epoch 5 [140/172] - loss: 0.1216, acc: 1.0000
Epoch 5 [141/172] - loss: 0.1174
Epoch 5 [142/172] - loss: 0.1096
Epoch 5 [143/172] - loss: 0.1257
Epoch 5 [144/172] - loss: 0.1063
Epoch 5 [145/172] - loss: 0.1223
Epoch 5 [146/172] - loss: 0.1063
Epoch 5 [147/172] - loss: 0.1166
Epoch 5 [148/172] - loss: 0.1053
Epoch 5 [149/172] - loss: 0.1097
Epoch 5 [150/172] - loss: 0.1652, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1188
Epoch 5 [152/172] - loss: 0.1584
Epoch 5 [153/172] - loss: 0.1057
Epoch 5 [154/172] - loss: 0.1097
Epoch 5 [155/172] - loss: 0.1117
Epoch 5 [156/172] - loss: 0.1143
Epoch 5 [157/172] - loss: 0.1095
Epoch 5 [158/172] - loss: 0.1058
Epoch 5 [159/172] - loss: 0.1205
Epoch 5 [160/172] - loss: 0.1175, acc: 0.9688
Epoch 5 [161/172] - loss: 0.1298
Epoch 5 [162/172] - loss: 0.1196
Epoch 5 [163/172] - loss: 0.1346
Epoch 5 [164/172] - loss: 0.1145
Epoch 5 [165/172] - loss: 0.2014
Epoch 5 [166/172] - loss: 0.1211
Epoch 5 [167/172] - loss: 0.1406
Epoch 5 [168/172] - loss: 0.1189
Epoch 5 [169/172] - loss: 0.1100
Epoch 5 [170/172] - loss: 0.1307, acc: 0.9688
Epoch 5 [171/172] - loss: 0.1379
Epoch 5 [172/172] - loss: 0.1135

类别准确率:
positive: 0.8051 (376/467)
neutral: 0.2892 (24/83)
negative: 0.7040 (176/250)

Epoch 5/10
Train Loss: 0.1266, Train Acc: 0.9818
Val Loss: 0.8949, Val Acc: 0.7200
Epoch 6 [1/172] - loss: 0.1308, acc: 0.9688
Epoch 6 [2/172] - loss: 0.1279
Epoch 6 [3/172] - loss: 0.1180
Epoch 6 [4/172] - loss: 0.1056
Epoch 6 [5/172] - loss: 0.1302
Epoch 6 [6/172] - loss: 0.1165
Epoch 6 [7/172] - loss: 0.1198
Epoch 6 [8/172] - loss: 0.1098
Epoch 6 [9/172] - loss: 0.1106
Epoch 6 [10/172] - loss: 0.1063, acc: 1.0000
Epoch 6 [11/172] - loss: 0.1090
Epoch 6 [12/172] - loss: 0.1115
Epoch 6 [13/172] - loss: 0.1225
Epoch 6 [14/172] - loss: 0.1068
Epoch 6 [15/172] - loss: 0.1113
Epoch 6 [16/172] - loss: 0.1662
Epoch 6 [17/172] - loss: 0.1093
Epoch 6 [18/172] - loss: 0.1122
Epoch 6 [19/172] - loss: 0.1111
Epoch 6 [20/172] - loss: 0.1081, acc: 1.0000
Epoch 6 [21/172] - loss: 0.1119
Epoch 6 [22/172] - loss: 0.1090
Epoch 6 [23/172] - loss: 0.1091
Epoch 6 [24/172] - loss: 0.1098
Epoch 6 [25/172] - loss: 0.1085
Epoch 6 [26/172] - loss: 0.1236
Epoch 6 [27/172] - loss: 0.1236
Epoch 6 [28/172] - loss: 0.1097
Epoch 6 [29/172] - loss: 0.1073
Epoch 6 [30/172] - loss: 0.1058, acc: 1.0000
Epoch 6 [31/172] - loss: 0.1125
Epoch 6 [32/172] - loss: 0.1066
Epoch 6 [33/172] - loss: 0.1100
Epoch 6 [34/172] - loss: 0.1075
Epoch 6 [35/172] - loss: 0.1057
Epoch 6 [36/172] - loss: 0.1085
Epoch 6 [37/172] - loss: 0.1083
Epoch 6 [38/172] - loss: 0.1171
Epoch 6 [39/172] - loss: 0.1122
Epoch 6 [40/172] - loss: 0.1563, acc: 0.9375

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1812, log_difficulty=0.1665, weight=1.8327
neutral: count=8815.0, difficulty=0.1303, log_difficulty=0.1225, weight=1.6126
negative: count=9870.0, difficulty=0.1660, log_difficulty=0.1536, weight=1.7678

当前batch的pt分布：
positive: min=0.1100, max=0.9994, mean=0.9112
neutral: min=0.9783, max=0.9979, mean=0.9923
negative: min=0.9516, max=0.9980, mean=0.9856

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0791
焦点损失: 0.0546
边界损失: 0.1420
总损失: 0.1315
Epoch 6 [41/172] - loss: 0.1315
Epoch 6 [42/172] - loss: 0.1119
Epoch 6 [43/172] - loss: 0.1561
Epoch 6 [44/172] - loss: 0.1087
Epoch 6 [45/172] - loss: 0.1130
Epoch 6 [46/172] - loss: 0.1121
Epoch 6 [47/172] - loss: 0.1161
Epoch 6 [48/172] - loss: 0.1061
Epoch 6 [49/172] - loss: 0.1107
Epoch 6 [50/172] - loss: 0.1379, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1268
Epoch 6 [52/172] - loss: 0.1182
Epoch 6 [53/172] - loss: 0.1283
Epoch 6 [54/172] - loss: 0.1481
Epoch 6 [55/172] - loss: 0.1086
Epoch 6 [56/172] - loss: 0.1101
Epoch 6 [57/172] - loss: 0.1100
Epoch 6 [58/172] - loss: 0.1060
Epoch 6 [59/172] - loss: 0.1179
Epoch 6 [60/172] - loss: 0.1249, acc: 0.9688
Epoch 6 [61/172] - loss: 0.1064
Epoch 6 [62/172] - loss: 0.1195
Epoch 6 [63/172] - loss: 0.1146
Epoch 6 [64/172] - loss: 0.1889
Epoch 6 [65/172] - loss: 0.1167
Epoch 6 [66/172] - loss: 0.1137
Epoch 6 [67/172] - loss: 0.1114
Epoch 6 [68/172] - loss: 0.1976
Epoch 6 [69/172] - loss: 0.1257
Epoch 6 [70/172] - loss: 0.1172, acc: 1.0000
Epoch 6 [71/172] - loss: 0.1231
Epoch 6 [72/172] - loss: 0.1099
Epoch 6 [73/172] - loss: 0.1533
Epoch 6 [74/172] - loss: 0.1067
Epoch 6 [75/172] - loss: 0.1158
Epoch 6 [76/172] - loss: 0.1083
Epoch 6 [77/172] - loss: 0.1192
Epoch 6 [78/172] - loss: 0.1302
Epoch 6 [79/172] - loss: 0.1073
Epoch 6 [80/172] - loss: 0.1500, acc: 0.9375
Epoch 6 [81/172] - loss: 0.1192
Epoch 6 [82/172] - loss: 0.1090
Epoch 6 [83/172] - loss: 0.1058
Epoch 6 [84/172] - loss: 0.1062
Epoch 6 [85/172] - loss: 0.1184
Epoch 6 [86/172] - loss: 0.1129
Epoch 6 [87/172] - loss: 0.1192
Epoch 6 [88/172] - loss: 0.1235
Epoch 6 [89/172] - loss: 0.1085
Epoch 6 [90/172] - loss: 0.1305, acc: 0.9688
Epoch 6 [91/172] - loss: 0.1152
Epoch 6 [92/172] - loss: 0.1071
Epoch 6 [93/172] - loss: 0.1226
Epoch 6 [94/172] - loss: 0.1298
Epoch 6 [95/172] - loss: 0.1184
Epoch 6 [96/172] - loss: 0.1055
Epoch 6 [97/172] - loss: 0.1358
Epoch 6 [98/172] - loss: 0.1084
Epoch 6 [99/172] - loss: 0.1077
Epoch 6 [100/172] - loss: 0.1087, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1373
Epoch 6 [102/172] - loss: 0.1156
Epoch 6 [103/172] - loss: 0.1265
Epoch 6 [104/172] - loss: 0.1202
Epoch 6 [105/172] - loss: 0.1091
Epoch 6 [106/172] - loss: 0.1257
Epoch 6 [107/172] - loss: 0.1081
Epoch 6 [108/172] - loss: 0.1072
Epoch 6 [109/172] - loss: 0.1471
Epoch 6 [110/172] - loss: 0.1111, acc: 1.0000
Epoch 6 [111/172] - loss: 0.1094
Epoch 6 [112/172] - loss: 0.1067
Epoch 6 [113/172] - loss: 0.1297
Epoch 6 [114/172] - loss: 0.1069
Epoch 6 [115/172] - loss: 0.1202
Epoch 6 [116/172] - loss: 0.1750
Epoch 6 [117/172] - loss: 0.1099
Epoch 6 [118/172] - loss: 0.1143
Epoch 6 [119/172] - loss: 0.1732
Epoch 6 [120/172] - loss: 0.1083, acc: 1.0000
Epoch 6 [121/172] - loss: 0.1147
Epoch 6 [122/172] - loss: 0.2208
Epoch 6 [123/172] - loss: 0.1092
Epoch 6 [124/172] - loss: 0.1071
Epoch 6 [125/172] - loss: 0.1109
Epoch 6 [126/172] - loss: 0.1499
Epoch 6 [127/172] - loss: 0.1297
Epoch 6 [128/172] - loss: 0.1082
Epoch 6 [129/172] - loss: 0.1092
Epoch 6 [130/172] - loss: 0.1674, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1425
Epoch 6 [132/172] - loss: 0.1475
Epoch 6 [133/172] - loss: 0.1074
Epoch 6 [134/172] - loss: 0.1071
Epoch 6 [135/172] - loss: 0.1173
Epoch 6 [136/172] - loss: 0.1048
Epoch 6 [137/172] - loss: 0.1075
Epoch 6 [138/172] - loss: 0.1088
Epoch 6 [139/172] - loss: 0.1175
Epoch 6 [140/172] - loss: 0.1105, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1663, log_difficulty=0.1538, weight=1.7692
neutral: count=9796.0, difficulty=0.1204, log_difficulty=0.1137, weight=1.5684
negative: count=10972.0, difficulty=0.1533, log_difficulty=0.1426, weight=1.7131

当前batch的pt分布：
positive: min=0.9915, max=0.9993, mean=0.9969
neutral: min=0.9566, max=0.9984, mean=0.9902
negative: min=0.9541, max=0.9991, mean=0.9803

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0121
焦点损失: 0.0000
边界损失: 0.1408
总损失: 0.1056
Epoch 6 [141/172] - loss: 0.1056
Epoch 6 [142/172] - loss: 0.1429
Epoch 6 [143/172] - loss: 0.1114
Epoch 6 [144/172] - loss: 0.1072
Epoch 6 [145/172] - loss: 0.1060
Epoch 6 [146/172] - loss: 0.1098
Epoch 6 [147/172] - loss: 0.1110
Epoch 6 [148/172] - loss: 0.1147
Epoch 6 [149/172] - loss: 0.1078
Epoch 6 [150/172] - loss: 0.1093, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1110
Epoch 6 [152/172] - loss: 0.1221
Epoch 6 [153/172] - loss: 0.1119
Epoch 6 [154/172] - loss: 0.1066
Epoch 6 [155/172] - loss: 0.1247
Epoch 6 [156/172] - loss: 0.1522
Epoch 6 [157/172] - loss: 0.1079
Epoch 6 [158/172] - loss: 0.1130
Epoch 6 [159/172] - loss: 0.1219
Epoch 6 [160/172] - loss: 0.1259, acc: 0.9688
Epoch 6 [161/172] - loss: 0.1073
Epoch 6 [162/172] - loss: 0.1063
Epoch 6 [163/172] - loss: 0.1078
Epoch 6 [164/172] - loss: 0.1244
Epoch 6 [165/172] - loss: 0.1999
Epoch 6 [166/172] - loss: 0.1091
Epoch 6 [167/172] - loss: 0.1051
Epoch 6 [168/172] - loss: 0.1050
Epoch 6 [169/172] - loss: 0.1113
Epoch 6 [170/172] - loss: 0.1052, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1110
Epoch 6 [172/172] - loss: 0.1085

类别准确率:
positive: 0.8608 (402/467)
neutral: 0.1566 (13/83)
negative: 0.6600 (165/250)

Epoch 6/10
Train Loss: 0.1169, Train Acc: 0.9859
Val Loss: 1.0055, Val Acc: 0.7250
Epoch 7 [1/172] - loss: 0.1064, acc: 1.0000
Epoch 7 [2/172] - loss: 0.1097
Epoch 7 [3/172] - loss: 0.1081
Epoch 7 [4/172] - loss: 0.1084
Epoch 7 [5/172] - loss: 0.1059
Epoch 7 [6/172] - loss: 0.1067
Epoch 7 [7/172] - loss: 0.1057
Epoch 7 [8/172] - loss: 0.1081
Epoch 7 [9/172] - loss: 0.1048
Epoch 7 [10/172] - loss: 0.1071, acc: 1.0000
Epoch 7 [11/172] - loss: 0.1078
Epoch 7 [12/172] - loss: 0.1377
Epoch 7 [13/172] - loss: 0.1099
Epoch 7 [14/172] - loss: 0.1242
Epoch 7 [15/172] - loss: 0.1138
Epoch 7 [16/172] - loss: 0.1085
Epoch 7 [17/172] - loss: 0.1148
Epoch 7 [18/172] - loss: 0.1056
Epoch 7 [19/172] - loss: 0.1094
Epoch 7 [20/172] - loss: 0.1054, acc: 1.0000
Epoch 7 [21/172] - loss: 0.1118
Epoch 7 [22/172] - loss: 0.1087
Epoch 7 [23/172] - loss: 0.1065
Epoch 7 [24/172] - loss: 0.1070
Epoch 7 [25/172] - loss: 0.1193
Epoch 7 [26/172] - loss: 0.1134
Epoch 7 [27/172] - loss: 0.1091
Epoch 7 [28/172] - loss: 0.1172
Epoch 7 [29/172] - loss: 0.1166
Epoch 7 [30/172] - loss: 0.1577, acc: 0.9688
Epoch 7 [31/172] - loss: 0.1145
Epoch 7 [32/172] - loss: 0.1044
Epoch 7 [33/172] - loss: 0.1133
Epoch 7 [34/172] - loss: 0.1058
Epoch 7 [35/172] - loss: 0.1065
Epoch 7 [36/172] - loss: 0.1447
Epoch 7 [37/172] - loss: 0.1055
Epoch 7 [38/172] - loss: 0.1045
Epoch 7 [39/172] - loss: 0.1166
Epoch 7 [40/172] - loss: 0.1048, acc: 1.0000
Epoch 7 [41/172] - loss: 0.1054
Epoch 7 [42/172] - loss: 0.1084
Epoch 7 [43/172] - loss: 0.1050
Epoch 7 [44/172] - loss: 0.1102
Epoch 7 [45/172] - loss: 0.1119
Epoch 7 [46/172] - loss: 0.1281
Epoch 7 [47/172] - loss: 0.1164
Epoch 7 [48/172] - loss: 0.1055
Epoch 7 [49/172] - loss: 0.1086
Epoch 7 [50/172] - loss: 0.1078, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1359
Epoch 7 [52/172] - loss: 0.1194
Epoch 7 [53/172] - loss: 0.1045
Epoch 7 [54/172] - loss: 0.1094
Epoch 7 [55/172] - loss: 0.1098
Epoch 7 [56/172] - loss: 0.1064
Epoch 7 [57/172] - loss: 0.1138
Epoch 7 [58/172] - loss: 0.1234
Epoch 7 [59/172] - loss: 0.1060
Epoch 7 [60/172] - loss: 0.1180, acc: 0.9688
Epoch 7 [61/172] - loss: 0.1085
Epoch 7 [62/172] - loss: 0.1073
Epoch 7 [63/172] - loss: 0.1676
Epoch 7 [64/172] - loss: 0.1061
Epoch 7 [65/172] - loss: 0.1511
Epoch 7 [66/172] - loss: 0.1229
Epoch 7 [67/172] - loss: 0.1078
Epoch 7 [68/172] - loss: 0.1132

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1535, log_difficulty=0.1428, weight=1.7140
neutral: count=10756.0, difficulty=0.1116, log_difficulty=0.1058, weight=1.5288
negative: count=12072.0, difficulty=0.1420, log_difficulty=0.1328, weight=1.6638

当前batch的pt分布：
positive: min=0.9873, max=0.9989, mean=0.9942
neutral: min=0.9886, max=0.9999, mean=0.9960
negative: min=0.8954, max=0.9982, mean=0.9786

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0124
焦点损失: 0.0001
边界损失: 0.1407
总损失: 0.1056
Epoch 7 [69/172] - loss: 0.1056
Epoch 7 [70/172] - loss: 0.1091, acc: 1.0000
Epoch 7 [71/172] - loss: 0.1099
Epoch 7 [72/172] - loss: 0.1125
Epoch 7 [73/172] - loss: 0.1103
Epoch 7 [74/172] - loss: 0.1044
Epoch 7 [75/172] - loss: 0.1052
Epoch 7 [76/172] - loss: 0.1071
Epoch 7 [77/172] - loss: 0.1079
Epoch 7 [78/172] - loss: 0.1040
Epoch 7 [79/172] - loss: 0.1268
Epoch 7 [80/172] - loss: 0.1187, acc: 0.9688
Epoch 7 [81/172] - loss: 0.1050
Epoch 7 [82/172] - loss: 0.1052
Epoch 7 [83/172] - loss: 0.1260
Epoch 7 [84/172] - loss: 0.1056
Epoch 7 [85/172] - loss: 0.1092
Epoch 7 [86/172] - loss: 0.1075
Epoch 7 [87/172] - loss: 0.1207
Epoch 7 [88/172] - loss: 0.1046
Epoch 7 [89/172] - loss: 0.1073
Epoch 7 [90/172] - loss: 0.1224, acc: 0.9688
Epoch 7 [91/172] - loss: 0.1064
Epoch 7 [92/172] - loss: 0.1062
Epoch 7 [93/172] - loss: 0.1663
Epoch 7 [94/172] - loss: 0.1093
Epoch 7 [95/172] - loss: 0.1057
Epoch 7 [96/172] - loss: 0.1070
Epoch 7 [97/172] - loss: 0.1185
Epoch 7 [98/172] - loss: 0.1244
Epoch 7 [99/172] - loss: 0.1045
Epoch 7 [100/172] - loss: 0.1042, acc: 1.0000
Epoch 7 [101/172] - loss: 0.1044
Epoch 7 [102/172] - loss: 0.1070
Epoch 7 [103/172] - loss: 0.1050
Epoch 7 [104/172] - loss: 0.1047
Epoch 7 [105/172] - loss: 0.1137
Epoch 7 [106/172] - loss: 0.1209
Epoch 7 [107/172] - loss: 0.1045
Epoch 7 [108/172] - loss: 0.1048
Epoch 7 [109/172] - loss: 0.1110
Epoch 7 [110/172] - loss: 0.1189, acc: 1.0000
Epoch 7 [111/172] - loss: 0.1085
Epoch 7 [112/172] - loss: 0.1064
Epoch 7 [113/172] - loss: 0.1051
Epoch 7 [114/172] - loss: 0.1068
Epoch 7 [115/172] - loss: 0.1048
Epoch 7 [116/172] - loss: 0.1229
Epoch 7 [117/172] - loss: 0.1084
Epoch 7 [118/172] - loss: 0.1140
Epoch 7 [119/172] - loss: 0.1079
Epoch 7 [120/172] - loss: 0.1066, acc: 1.0000
Epoch 7 [121/172] - loss: 0.1086
Epoch 7 [122/172] - loss: 0.1049
Epoch 7 [123/172] - loss: 0.1045
Epoch 7 [124/172] - loss: 0.1158
Epoch 7 [125/172] - loss: 0.1047
Epoch 7 [126/172] - loss: 0.1054
Epoch 7 [127/172] - loss: 0.1067
Epoch 7 [128/172] - loss: 0.1057
Epoch 7 [129/172] - loss: 0.1078
Epoch 7 [130/172] - loss: 0.1063, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1306
Epoch 7 [132/172] - loss: 0.1364
Epoch 7 [133/172] - loss: 0.1039
Epoch 7 [134/172] - loss: 0.1113
Epoch 7 [135/172] - loss: 0.1080
Epoch 7 [136/172] - loss: 0.1052
Epoch 7 [137/172] - loss: 0.1149
Epoch 7 [138/172] - loss: 0.1111
Epoch 7 [139/172] - loss: 0.1203
Epoch 7 [140/172] - loss: 0.1149, acc: 0.9688
Epoch 7 [141/172] - loss: 0.1267
Epoch 7 [142/172] - loss: 0.1066
Epoch 7 [143/172] - loss: 0.1156
Epoch 7 [144/172] - loss: 0.1064
Epoch 7 [145/172] - loss: 0.1140
Epoch 7 [146/172] - loss: 0.1269
Epoch 7 [147/172] - loss: 0.1081
Epoch 7 [148/172] - loss: 0.1087
Epoch 7 [149/172] - loss: 0.1057
Epoch 7 [150/172] - loss: 0.1063, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1334
Epoch 7 [152/172] - loss: 0.1039
Epoch 7 [153/172] - loss: 0.1057
Epoch 7 [154/172] - loss: 0.1204
Epoch 7 [155/172] - loss: 0.1053
Epoch 7 [156/172] - loss: 0.1520
Epoch 7 [157/172] - loss: 0.1088
Epoch 7 [158/172] - loss: 0.1092
Epoch 7 [159/172] - loss: 0.1048
Epoch 7 [160/172] - loss: 0.1053, acc: 1.0000
Epoch 7 [161/172] - loss: 0.1174
Epoch 7 [162/172] - loss: 0.1141
Epoch 7 [163/172] - loss: 0.1362
Epoch 7 [164/172] - loss: 0.1216
Epoch 7 [165/172] - loss: 0.1169
Epoch 7 [166/172] - loss: 0.1170
Epoch 7 [167/172] - loss: 0.1102
Epoch 7 [168/172] - loss: 0.1047

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1426, log_difficulty=0.1333, weight=1.6664
neutral: count=11731.0, difficulty=0.1041, log_difficulty=0.0990, weight=1.4950
negative: count=13173.0, difficulty=0.1320, log_difficulty=0.1240, weight=1.6198

当前batch的pt分布：
positive: min=0.9889, max=0.9991, mean=0.9948
neutral: min=0.9928, max=0.9996, mean=0.9961
negative: min=0.9669, max=0.9975, mean=0.9887

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0072
焦点损失: 0.0000
边界损失: 0.1385
总损失: 0.1039
Epoch 7 [169/172] - loss: 0.1039
Epoch 7 [170/172] - loss: 0.1181, acc: 1.0000
Epoch 7 [171/172] - loss: 0.1044
Epoch 7 [172/172] - loss: 0.1035

类别准确率:
positive: 0.8116 (379/467)
neutral: 0.3133 (26/83)
negative: 0.6600 (165/250)

Epoch 7/10
Train Loss: 0.1123, Train Acc: 0.9899
Val Loss: 1.0102, Val Acc: 0.7125
Early stopping triggered!
Best validation accuracy: 0.7288

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_045331-lrpfqz0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.25_Multimodal_iterations_20250118_045330
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/lrpfqz0w
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇████
wandb:  train_acc ▁▃▄▅▅▇▇▇▇█▇█▇██▇███████████▇████████████
wandb: train_loss █▄▅▃▃▃▃▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 1
wandb: train_loss 0.11814
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.25_Multimodal_iterations_20250118_045330 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/lrpfqz0w
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_045331-lrpfqz0w/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_050348-0f2mr8k3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.25_Multimodal_epochs_20250118_050348
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/0f2mr8k3
wandb: uploading wandb-metadata.json; uploading requirements.txt; uploading history steps 0-0, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▅▆▇███
wandb: train_loss █▅▂▂▁▁▁
wandb:    val_acc ▁▇▆█▇█▇
wandb:   val_loss ▁▁▃▃▄██
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.9899
wandb: train_loss 0.11226
wandb:    val_acc 0.7125
wandb:   val_loss 1.01023
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.25_Multimodal_epochs_20250118_050348 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/0f2mr8k3
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_050348-0f2mr8k3/logs

