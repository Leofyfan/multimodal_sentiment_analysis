=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 0.5 --dropout 0.35 --name loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.35 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.35
text_dim: 128
image_dim: 256
dropout: 0.35
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6805, log_difficulty=0.5191, weight=3.5953
neutral: count=7.0, difficulty=0.6380, log_difficulty=0.4935, weight=3.4673
negative: count=13.0, difficulty=0.6679, log_difficulty=0.5116, weight=3.5579

当前batch的pt分布：
positive: min=0.1585, max=0.4601, mean=0.3195
neutral: min=0.2099, max=0.6015, mean=0.3620
negative: min=0.1727, max=0.4384, mean=0.3321

当前batch准确率：
整体准确率: 0.3438
positive 准确率: 0.2500
neutral 准确率: 0.4286
negative 准确率: 0.3846

损失分量：
基础交叉熵: 1.1361
焦点损失: 0.3844
边界损失: 0.7766
总损失: 1.0716
Epoch 1 [1/172] - loss: 1.0716, acc: 0.3438
Epoch 1 [2/172] - loss: 1.1473
Epoch 1 [3/172] - loss: 1.0897
Epoch 1 [4/172] - loss: 1.1421
Epoch 1 [5/172] - loss: 0.9487
Epoch 1 [6/172] - loss: 1.4340
Epoch 1 [7/172] - loss: 1.0771
Epoch 1 [8/172] - loss: 1.4116
Epoch 1 [9/172] - loss: 1.0937
Epoch 1 [10/172] - loss: 1.1172, acc: 0.3750
Epoch 1 [11/172] - loss: 0.8125
Epoch 1 [12/172] - loss: 1.1112
Epoch 1 [13/172] - loss: 0.9295
Epoch 1 [14/172] - loss: 0.9656
Epoch 1 [15/172] - loss: 1.1494
Epoch 1 [16/172] - loss: 1.2570
Epoch 1 [17/172] - loss: 1.2342
Epoch 1 [18/172] - loss: 1.0507
Epoch 1 [19/172] - loss: 1.0519
Epoch 1 [20/172] - loss: 1.1968, acc: 0.1562
Epoch 1 [21/172] - loss: 0.8815
Epoch 1 [22/172] - loss: 1.0208
Epoch 1 [23/172] - loss: 0.7909
Epoch 1 [24/172] - loss: 1.2375
Epoch 1 [25/172] - loss: 0.9968
Epoch 1 [26/172] - loss: 0.9664
Epoch 1 [27/172] - loss: 1.0074
Epoch 1 [28/172] - loss: 1.0087
Epoch 1 [29/172] - loss: 0.9950
Epoch 1 [30/172] - loss: 0.9865, acc: 0.3438
Epoch 1 [31/172] - loss: 0.9375
Epoch 1 [32/172] - loss: 0.9862
Epoch 1 [33/172] - loss: 0.9914
Epoch 1 [34/172] - loss: 0.9813
Epoch 1 [35/172] - loss: 1.0720
Epoch 1 [36/172] - loss: 0.7020
Epoch 1 [37/172] - loss: 0.8047
Epoch 1 [38/172] - loss: 1.0158
Epoch 1 [39/172] - loss: 0.8261
Epoch 1 [40/172] - loss: 0.9407, acc: 0.4688
Epoch 1 [41/172] - loss: 0.8933
Epoch 1 [42/172] - loss: 0.8230
Epoch 1 [43/172] - loss: 1.2120
Epoch 1 [44/172] - loss: 1.1273
Epoch 1 [45/172] - loss: 0.9818
Epoch 1 [46/172] - loss: 0.9616
Epoch 1 [47/172] - loss: 0.9227
Epoch 1 [48/172] - loss: 0.9590
Epoch 1 [49/172] - loss: 0.9733
Epoch 1 [50/172] - loss: 0.7161, acc: 0.6562
Epoch 1 [51/172] - loss: 0.8084
Epoch 1 [52/172] - loss: 0.8193
Epoch 1 [53/172] - loss: 0.8241
Epoch 1 [54/172] - loss: 0.8789
Epoch 1 [55/172] - loss: 0.6958
Epoch 1 [56/172] - loss: 0.7482
Epoch 1 [57/172] - loss: 0.9960
Epoch 1 [58/172] - loss: 0.6309
Epoch 1 [59/172] - loss: 0.7950
Epoch 1 [60/172] - loss: 0.5545, acc: 0.7812
Epoch 1 [61/172] - loss: 0.7903
Epoch 1 [62/172] - loss: 0.7849
Epoch 1 [63/172] - loss: 0.8288
Epoch 1 [64/172] - loss: 0.7473
Epoch 1 [65/172] - loss: 0.9518
Epoch 1 [66/172] - loss: 1.0841
Epoch 1 [67/172] - loss: 0.7132
Epoch 1 [68/172] - loss: 1.0208
Epoch 1 [69/172] - loss: 0.7849
Epoch 1 [70/172] - loss: 0.8138, acc: 0.5938
Epoch 1 [71/172] - loss: 0.5673
Epoch 1 [72/172] - loss: 0.8522
Epoch 1 [73/172] - loss: 0.6319
Epoch 1 [74/172] - loss: 0.7688
Epoch 1 [75/172] - loss: 0.5097
Epoch 1 [76/172] - loss: 0.5819
Epoch 1 [77/172] - loss: 0.7101
Epoch 1 [78/172] - loss: 0.6240
Epoch 1 [79/172] - loss: 0.7543
Epoch 1 [80/172] - loss: 0.4783, acc: 0.7500
Epoch 1 [81/172] - loss: 0.8843
Epoch 1 [82/172] - loss: 0.8685
Epoch 1 [83/172] - loss: 0.7032
Epoch 1 [84/172] - loss: 0.5425
Epoch 1 [85/172] - loss: 0.8164
Epoch 1 [86/172] - loss: 0.9206
Epoch 1 [87/172] - loss: 0.6900
Epoch 1 [88/172] - loss: 1.0342
Epoch 1 [89/172] - loss: 0.9533
Epoch 1 [90/172] - loss: 0.7418, acc: 0.5312
Epoch 1 [91/172] - loss: 0.6806
Epoch 1 [92/172] - loss: 0.6429
Epoch 1 [93/172] - loss: 0.8732
Epoch 1 [94/172] - loss: 0.5299
Epoch 1 [95/172] - loss: 0.6615
Epoch 1 [96/172] - loss: 0.5130
Epoch 1 [97/172] - loss: 0.8327
Epoch 1 [98/172] - loss: 0.4650
Epoch 1 [99/172] - loss: 1.0537
Epoch 1 [100/172] - loss: 0.7638, acc: 0.6562

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5776, log_difficulty=0.4559, weight=3.2795
neutral: count=983.0, difficulty=0.5781, log_difficulty=0.4562, weight=3.2810
negative: count=1119.0, difficulty=0.5571, log_difficulty=0.4428, weight=3.2141

当前batch的pt分布：
positive: min=0.0627, max=0.9657, mean=0.4269
neutral: min=0.3890, max=0.9835, mean=0.7067
negative: min=0.1445, max=0.8128, mean=0.4188

当前batch准确率：
整体准确率: 0.5938
positive 准确率: 0.5000
neutral 准确率: 1.0000
negative 准确率: 0.5625

损失分量：
基础交叉熵: 0.9489
焦点损失: 0.3873
边界损失: 0.5447
总损失: 0.9011
Epoch 1 [101/172] - loss: 0.9011
Epoch 1 [102/172] - loss: 0.6472
Epoch 1 [103/172] - loss: 0.6442
Epoch 1 [104/172] - loss: 0.5111
Epoch 1 [105/172] - loss: 0.7374
Epoch 1 [106/172] - loss: 0.8155
Epoch 1 [107/172] - loss: 0.5492
Epoch 1 [108/172] - loss: 0.8686
Epoch 1 [109/172] - loss: 0.4602
Epoch 1 [110/172] - loss: 0.7261, acc: 0.6562
Epoch 1 [111/172] - loss: 0.7979
Epoch 1 [112/172] - loss: 0.5959
Epoch 1 [113/172] - loss: 0.4712
Epoch 1 [114/172] - loss: 0.5215
Epoch 1 [115/172] - loss: 0.6400
Epoch 1 [116/172] - loss: 0.5728
Epoch 1 [117/172] - loss: 0.8352
Epoch 1 [118/172] - loss: 0.4885
Epoch 1 [119/172] - loss: 0.6737
Epoch 1 [120/172] - loss: 0.4791, acc: 0.7812
Epoch 1 [121/172] - loss: 0.6888
Epoch 1 [122/172] - loss: 0.6560
Epoch 1 [123/172] - loss: 0.5283
Epoch 1 [124/172] - loss: 0.6195
Epoch 1 [125/172] - loss: 0.5599
Epoch 1 [126/172] - loss: 0.9286
Epoch 1 [127/172] - loss: 0.4999
Epoch 1 [128/172] - loss: 0.4718
Epoch 1 [129/172] - loss: 0.6478
Epoch 1 [130/172] - loss: 0.3767, acc: 0.7812
Epoch 1 [131/172] - loss: 0.2893
Epoch 1 [132/172] - loss: 0.7318
Epoch 1 [133/172] - loss: 0.6286
Epoch 1 [134/172] - loss: 0.5444
Epoch 1 [135/172] - loss: 0.4132
Epoch 1 [136/172] - loss: 0.4925
Epoch 1 [137/172] - loss: 0.6685
Epoch 1 [138/172] - loss: 0.4511
Epoch 1 [139/172] - loss: 0.3776
Epoch 1 [140/172] - loss: 0.4319, acc: 0.7812
Epoch 1 [141/172] - loss: 0.5399
Epoch 1 [142/172] - loss: 0.3702
Epoch 1 [143/172] - loss: 0.5108
Epoch 1 [144/172] - loss: 0.4010
Epoch 1 [145/172] - loss: 0.5093
Epoch 1 [146/172] - loss: 0.7198
Epoch 1 [147/172] - loss: 0.6486
Epoch 1 [148/172] - loss: 0.4476
Epoch 1 [149/172] - loss: 0.3155
Epoch 1 [150/172] - loss: 0.5261, acc: 0.7812
Epoch 1 [151/172] - loss: 0.7329
Epoch 1 [152/172] - loss: 0.4968
Epoch 1 [153/172] - loss: 0.5098
Epoch 1 [154/172] - loss: 0.4296
Epoch 1 [155/172] - loss: 0.6089
Epoch 1 [156/172] - loss: 0.6774
Epoch 1 [157/172] - loss: 0.4603
Epoch 1 [158/172] - loss: 0.4191
Epoch 1 [159/172] - loss: 0.5916
Epoch 1 [160/172] - loss: 0.3810, acc: 0.8438
Epoch 1 [161/172] - loss: 0.3997
Epoch 1 [162/172] - loss: 0.5452
Epoch 1 [163/172] - loss: 0.5234
Epoch 1 [164/172] - loss: 0.5959
Epoch 1 [165/172] - loss: 0.4325
Epoch 1 [166/172] - loss: 0.3414
Epoch 1 [167/172] - loss: 0.3659
Epoch 1 [168/172] - loss: 0.5653
Epoch 1 [169/172] - loss: 0.6378
Epoch 1 [170/172] - loss: 0.3467, acc: 0.8125
Epoch 1 [171/172] - loss: 0.2846
Epoch 1 [172/172] - loss: 0.4456

类别准确率:
positive: 0.7709 (360/467)
neutral: 0.5301 (44/83)
negative: 0.6040 (151/250)

Epoch 1/10
Train Loss: 0.4585, Train Acc: 0.7899
Val Loss: 0.7137, Val Acc: 0.6937
Epoch 2 [1/172] - loss: 0.5077, acc: 0.7188
Epoch 2 [2/172] - loss: 0.3232
Epoch 2 [3/172] - loss: 0.2632
Epoch 2 [4/172] - loss: 0.5548
Epoch 2 [5/172] - loss: 0.5466
Epoch 2 [6/172] - loss: 0.5889
Epoch 2 [7/172] - loss: 0.4345
Epoch 2 [8/172] - loss: 0.3887
Epoch 2 [9/172] - loss: 0.3594
Epoch 2 [10/172] - loss: 0.3826, acc: 0.8438
Epoch 2 [11/172] - loss: 0.2978
Epoch 2 [12/172] - loss: 0.2987
Epoch 2 [13/172] - loss: 0.4833
Epoch 2 [14/172] - loss: 0.2751
Epoch 2 [15/172] - loss: 0.4159
Epoch 2 [16/172] - loss: 0.3063
Epoch 2 [17/172] - loss: 0.3869
Epoch 2 [18/172] - loss: 0.6717
Epoch 2 [19/172] - loss: 0.3968
Epoch 2 [20/172] - loss: 0.2618, acc: 0.9062
Epoch 2 [21/172] - loss: 0.2905
Epoch 2 [22/172] - loss: 0.3837
Epoch 2 [23/172] - loss: 0.2670
Epoch 2 [24/172] - loss: 0.6540
Epoch 2 [25/172] - loss: 0.5177
Epoch 2 [26/172] - loss: 0.3285
Epoch 2 [27/172] - loss: 0.2519
Epoch 2 [28/172] - loss: 0.2507

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5020, log_difficulty=0.4068, weight=3.0341
neutral: count=1952.0, difficulty=0.4546, log_difficulty=0.3747, weight=2.8735
negative: count=2216.0, difficulty=0.4882, log_difficulty=0.3976, weight=2.9879

当前batch的pt分布：
positive: min=0.3956, max=0.9121, mean=0.7439
neutral: min=0.3545, max=0.9681, mean=0.7526
negative: min=0.0847, max=0.8406, mean=0.5902

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.8889
neutral 准确率: 0.9091
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.4531
焦点损失: 0.1207
边界损失: 0.3323
总损失: 0.3457
Epoch 2 [29/172] - loss: 0.3457
Epoch 2 [30/172] - loss: 0.3839, acc: 0.8438
Epoch 2 [31/172] - loss: 0.3372
Epoch 2 [32/172] - loss: 0.3654
Epoch 2 [33/172] - loss: 0.2742
Epoch 2 [34/172] - loss: 0.4334
Epoch 2 [35/172] - loss: 0.2739
Epoch 2 [36/172] - loss: 0.4139
Epoch 2 [37/172] - loss: 0.2446
Epoch 2 [38/172] - loss: 0.3316
Epoch 2 [39/172] - loss: 0.4092
Epoch 2 [40/172] - loss: 0.3366, acc: 0.8438
Epoch 2 [41/172] - loss: 0.3830
Epoch 2 [42/172] - loss: 0.2699
Epoch 2 [43/172] - loss: 0.2058
Epoch 2 [44/172] - loss: 0.6177
Epoch 2 [45/172] - loss: 0.2148
Epoch 2 [46/172] - loss: 0.2070
Epoch 2 [47/172] - loss: 0.3175
Epoch 2 [48/172] - loss: 0.3316
Epoch 2 [49/172] - loss: 0.2947
Epoch 2 [50/172] - loss: 0.3256, acc: 0.7812
Epoch 2 [51/172] - loss: 0.3432
Epoch 2 [52/172] - loss: 0.3315
Epoch 2 [53/172] - loss: 0.2267
Epoch 2 [54/172] - loss: 0.2247
Epoch 2 [55/172] - loss: 0.2476
Epoch 2 [56/172] - loss: 0.2793
Epoch 2 [57/172] - loss: 0.2354
Epoch 2 [58/172] - loss: 0.4580
Epoch 2 [59/172] - loss: 0.5984
Epoch 2 [60/172] - loss: 0.2483, acc: 0.8750
Epoch 2 [61/172] - loss: 0.2068
Epoch 2 [62/172] - loss: 0.1753
Epoch 2 [63/172] - loss: 0.3960
Epoch 2 [64/172] - loss: 0.3172
Epoch 2 [65/172] - loss: 0.2343
Epoch 2 [66/172] - loss: 0.2918
Epoch 2 [67/172] - loss: 0.2304
Epoch 2 [68/172] - loss: 0.3955
Epoch 2 [69/172] - loss: 0.3403
Epoch 2 [70/172] - loss: 0.4026, acc: 0.8750
Epoch 2 [71/172] - loss: 0.2930
Epoch 2 [72/172] - loss: 0.3823
Epoch 2 [73/172] - loss: 0.3052
Epoch 2 [74/172] - loss: 0.2560
Epoch 2 [75/172] - loss: 0.2448
Epoch 2 [76/172] - loss: 0.2418
Epoch 2 [77/172] - loss: 0.2971
Epoch 2 [78/172] - loss: 0.2984
Epoch 2 [79/172] - loss: 0.2470
Epoch 2 [80/172] - loss: 0.2020, acc: 0.9375
Epoch 2 [81/172] - loss: 0.2079
Epoch 2 [82/172] - loss: 0.2118
Epoch 2 [83/172] - loss: 0.2401
Epoch 2 [84/172] - loss: 0.2103
Epoch 2 [85/172] - loss: 0.2733
Epoch 2 [86/172] - loss: 0.2609
Epoch 2 [87/172] - loss: 0.4851
Epoch 2 [88/172] - loss: 0.2120
Epoch 2 [89/172] - loss: 0.1446
Epoch 2 [90/172] - loss: 0.2829, acc: 0.8438
Epoch 2 [91/172] - loss: 0.1554
Epoch 2 [92/172] - loss: 0.3108
Epoch 2 [93/172] - loss: 0.1851
Epoch 2 [94/172] - loss: 0.2050
Epoch 2 [95/172] - loss: 0.4195
Epoch 2 [96/172] - loss: 0.1889
Epoch 2 [97/172] - loss: 0.2106
Epoch 2 [98/172] - loss: 0.1759
Epoch 2 [99/172] - loss: 0.1617
Epoch 2 [100/172] - loss: 0.3008, acc: 0.8438
Epoch 2 [101/172] - loss: 0.1772
Epoch 2 [102/172] - loss: 0.1801
Epoch 2 [103/172] - loss: 0.4806
Epoch 2 [104/172] - loss: 0.3311
Epoch 2 [105/172] - loss: 0.1709
Epoch 2 [106/172] - loss: 0.1938
Epoch 2 [107/172] - loss: 0.1797
Epoch 2 [108/172] - loss: 0.4618
Epoch 2 [109/172] - loss: 0.2555
Epoch 2 [110/172] - loss: 0.4058, acc: 0.8125
Epoch 2 [111/172] - loss: 0.2528
Epoch 2 [112/172] - loss: 0.2377
Epoch 2 [113/172] - loss: 0.1737
Epoch 2 [114/172] - loss: 0.2601
Epoch 2 [115/172] - loss: 0.2684
Epoch 2 [116/172] - loss: 0.2424
Epoch 2 [117/172] - loss: 0.4374
Epoch 2 [118/172] - loss: 0.2692
Epoch 2 [119/172] - loss: 0.2979
Epoch 2 [120/172] - loss: 0.2103, acc: 0.9062
Epoch 2 [121/172] - loss: 0.2016
Epoch 2 [122/172] - loss: 0.3336
Epoch 2 [123/172] - loss: 0.1891
Epoch 2 [124/172] - loss: 0.3263
Epoch 2 [125/172] - loss: 0.1200
Epoch 2 [126/172] - loss: 0.3070
Epoch 2 [127/172] - loss: 0.2322
Epoch 2 [128/172] - loss: 0.1687

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4353, log_difficulty=0.3614, weight=2.8069
neutral: count=2949.0, difficulty=0.3600, log_difficulty=0.3075, weight=2.5374
negative: count=3294.0, difficulty=0.4233, log_difficulty=0.3530, weight=2.7650

当前batch的pt分布：
positive: min=0.2595, max=0.9545, mean=0.7346
neutral: min=0.6277, max=0.9936, mean=0.8496
negative: min=0.0815, max=0.9402, mean=0.7246

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.3321
焦点损失: 0.0958
边界损失: 0.2723
总损失: 0.2689
Epoch 2 [129/172] - loss: 0.2689
Epoch 2 [130/172] - loss: 0.2669, acc: 0.8750
Epoch 2 [131/172] - loss: 0.1786
Epoch 2 [132/172] - loss: 0.2901
Epoch 2 [133/172] - loss: 0.1414
Epoch 2 [134/172] - loss: 0.3081
Epoch 2 [135/172] - loss: 0.3311
Epoch 2 [136/172] - loss: 0.4291
Epoch 2 [137/172] - loss: 0.1822
Epoch 2 [138/172] - loss: 0.2399
Epoch 2 [139/172] - loss: 0.1745
Epoch 2 [140/172] - loss: 0.1917, acc: 0.8750
Epoch 2 [141/172] - loss: 0.2410
Epoch 2 [142/172] - loss: 0.2898
Epoch 2 [143/172] - loss: 0.2812
Epoch 2 [144/172] - loss: 0.2146
Epoch 2 [145/172] - loss: 0.7036
Epoch 2 [146/172] - loss: 0.1848
Epoch 2 [147/172] - loss: 0.2375
Epoch 2 [148/172] - loss: 0.1356
Epoch 2 [149/172] - loss: 0.3531
Epoch 2 [150/172] - loss: 0.1545, acc: 0.9688
Epoch 2 [151/172] - loss: 0.2544
Epoch 2 [152/172] - loss: 0.2430
Epoch 2 [153/172] - loss: 0.1788
Epoch 2 [154/172] - loss: 0.1817
Epoch 2 [155/172] - loss: 0.2859
Epoch 2 [156/172] - loss: 0.1627
Epoch 2 [157/172] - loss: 0.1481
Epoch 2 [158/172] - loss: 0.2537
Epoch 2 [159/172] - loss: 0.3191
Epoch 2 [160/172] - loss: 0.1433, acc: 0.9688
Epoch 2 [161/172] - loss: 0.1658
Epoch 2 [162/172] - loss: 0.1895
Epoch 2 [163/172] - loss: 0.4186
Epoch 2 [164/172] - loss: 0.2162
Epoch 2 [165/172] - loss: 0.3662
Epoch 2 [166/172] - loss: 0.4113
Epoch 2 [167/172] - loss: 0.3240
Epoch 2 [168/172] - loss: 0.1915
Epoch 2 [169/172] - loss: 0.1648
Epoch 2 [170/172] - loss: 0.2144, acc: 0.8750
Epoch 2 [171/172] - loss: 0.3635
Epoch 2 [172/172] - loss: 0.4852

类别准确率:
positive: 0.9229 (431/467)
neutral: 0.2651 (22/83)
negative: 0.4240 (106/250)

Epoch 2/10
Train Loss: 0.2735, Train Acc: 0.8929
Val Loss: 0.7374, Val Acc: 0.6987
Epoch 3 [1/172] - loss: 0.2049, acc: 0.9062
Epoch 3 [2/172] - loss: 0.2727
Epoch 3 [3/172] - loss: 0.2290
Epoch 3 [4/172] - loss: 0.1698
Epoch 3 [5/172] - loss: 0.1951
Epoch 3 [6/172] - loss: 0.1446
Epoch 3 [7/172] - loss: 0.1719
Epoch 3 [8/172] - loss: 0.2148
Epoch 3 [9/172] - loss: 0.1856
Epoch 3 [10/172] - loss: 0.1801, acc: 0.9375
Epoch 3 [11/172] - loss: 0.1083
Epoch 3 [12/172] - loss: 0.1136
Epoch 3 [13/172] - loss: 0.1296
Epoch 3 [14/172] - loss: 0.1207
Epoch 3 [15/172] - loss: 0.1743
Epoch 3 [16/172] - loss: 0.1638
Epoch 3 [17/172] - loss: 0.1853
Epoch 3 [18/172] - loss: 0.2802
Epoch 3 [19/172] - loss: 0.1147
Epoch 3 [20/172] - loss: 0.1319, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1897
Epoch 3 [22/172] - loss: 0.2684
Epoch 3 [23/172] - loss: 0.1375
Epoch 3 [24/172] - loss: 0.1570
Epoch 3 [25/172] - loss: 0.1121
Epoch 3 [26/172] - loss: 0.1670
Epoch 3 [27/172] - loss: 0.1645
Epoch 3 [28/172] - loss: 0.1043
Epoch 3 [29/172] - loss: 0.1553
Epoch 3 [30/172] - loss: 0.1597, acc: 0.9375
Epoch 3 [31/172] - loss: 0.1105
Epoch 3 [32/172] - loss: 0.1202
Epoch 3 [33/172] - loss: 0.1094
Epoch 3 [34/172] - loss: 0.2330
Epoch 3 [35/172] - loss: 0.2207
Epoch 3 [36/172] - loss: 0.1092
Epoch 3 [37/172] - loss: 0.2119
Epoch 3 [38/172] - loss: 0.0994
Epoch 3 [39/172] - loss: 0.1150
Epoch 3 [40/172] - loss: 0.1346, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1337
Epoch 3 [42/172] - loss: 0.1960
Epoch 3 [43/172] - loss: 0.1258
Epoch 3 [44/172] - loss: 0.1261
Epoch 3 [45/172] - loss: 0.1953
Epoch 3 [46/172] - loss: 0.1960
Epoch 3 [47/172] - loss: 0.1256
Epoch 3 [48/172] - loss: 0.1092
Epoch 3 [49/172] - loss: 0.0998
Epoch 3 [50/172] - loss: 0.1112, acc: 1.0000
Epoch 3 [51/172] - loss: 0.2728
Epoch 3 [52/172] - loss: 0.2256
Epoch 3 [53/172] - loss: 0.1372
Epoch 3 [54/172] - loss: 0.1513
Epoch 3 [55/172] - loss: 0.1052
Epoch 3 [56/172] - loss: 0.1523

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3760, log_difficulty=0.3192, weight=2.5959
neutral: count=3923.0, difficulty=0.3050, log_difficulty=0.2662, weight=2.3309
negative: count=4382.0, difficulty=0.3680, log_difficulty=0.3133, weight=2.5666

当前batch的pt分布：
positive: min=0.5096, max=0.9830, mean=0.8344
neutral: min=0.0019, max=0.9935, mean=0.7331
negative: min=0.9693, max=0.9909, mean=0.9790

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 1.0000
neutral 准确率: 0.7500
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.4481
焦点损失: 0.2908
边界损失: 0.2123
总损失: 0.4458
Epoch 3 [57/172] - loss: 0.4458
Epoch 3 [58/172] - loss: 0.1102
Epoch 3 [59/172] - loss: 0.1313
Epoch 3 [60/172] - loss: 0.2063, acc: 0.9062
Epoch 3 [61/172] - loss: 0.1603
Epoch 3 [62/172] - loss: 0.1545
Epoch 3 [63/172] - loss: 0.1156
Epoch 3 [64/172] - loss: 0.1532
Epoch 3 [65/172] - loss: 0.1188
Epoch 3 [66/172] - loss: 0.1365
Epoch 3 [67/172] - loss: 0.1000
Epoch 3 [68/172] - loss: 0.1465
Epoch 3 [69/172] - loss: 0.1533
Epoch 3 [70/172] - loss: 0.1021, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1793
Epoch 3 [72/172] - loss: 0.3136
Epoch 3 [73/172] - loss: 0.0985
Epoch 3 [74/172] - loss: 0.1847
Epoch 3 [75/172] - loss: 0.1036
Epoch 3 [76/172] - loss: 0.1082
Epoch 3 [77/172] - loss: 0.1541
Epoch 3 [78/172] - loss: 0.2766
Epoch 3 [79/172] - loss: 0.1062
Epoch 3 [80/172] - loss: 0.2908, acc: 0.9375
Epoch 3 [81/172] - loss: 0.1215
Epoch 3 [82/172] - loss: 0.1185
Epoch 3 [83/172] - loss: 0.1216
Epoch 3 [84/172] - loss: 0.0970
Epoch 3 [85/172] - loss: 0.1278
Epoch 3 [86/172] - loss: 0.1051
Epoch 3 [87/172] - loss: 0.2267
Epoch 3 [88/172] - loss: 0.1873
Epoch 3 [89/172] - loss: 0.1106
Epoch 3 [90/172] - loss: 0.0904, acc: 1.0000
Epoch 3 [91/172] - loss: 0.3208
Epoch 3 [92/172] - loss: 0.1267
Epoch 3 [93/172] - loss: 0.3128
Epoch 3 [94/172] - loss: 0.1496
Epoch 3 [95/172] - loss: 0.1230
Epoch 3 [96/172] - loss: 0.1828
Epoch 3 [97/172] - loss: 0.1283
Epoch 3 [98/172] - loss: 0.1108
Epoch 3 [99/172] - loss: 0.1079
Epoch 3 [100/172] - loss: 0.3097, acc: 0.9375
Epoch 3 [101/172] - loss: 0.3229
Epoch 3 [102/172] - loss: 0.1676
Epoch 3 [103/172] - loss: 0.2057
Epoch 3 [104/172] - loss: 0.1134
Epoch 3 [105/172] - loss: 0.0917
Epoch 3 [106/172] - loss: 0.2244
Epoch 3 [107/172] - loss: 0.1328
Epoch 3 [108/172] - loss: 0.1108
Epoch 3 [109/172] - loss: 0.1019
Epoch 3 [110/172] - loss: 0.1746, acc: 0.9688
Epoch 3 [111/172] - loss: 0.1526
Epoch 3 [112/172] - loss: 0.1378
Epoch 3 [113/172] - loss: 0.1037
Epoch 3 [114/172] - loss: 0.1532
Epoch 3 [115/172] - loss: 0.1227
Epoch 3 [116/172] - loss: 0.1795
Epoch 3 [117/172] - loss: 0.1028
Epoch 3 [118/172] - loss: 0.1474
Epoch 3 [119/172] - loss: 0.2454
Epoch 3 [120/172] - loss: 0.1839, acc: 0.9375
Epoch 3 [121/172] - loss: 0.2134
Epoch 3 [122/172] - loss: 0.1228
Epoch 3 [123/172] - loss: 0.1353
Epoch 3 [124/172] - loss: 0.1581
Epoch 3 [125/172] - loss: 0.0944
Epoch 3 [126/172] - loss: 0.3923
Epoch 3 [127/172] - loss: 0.1478
Epoch 3 [128/172] - loss: 0.1155
Epoch 3 [129/172] - loss: 0.1343
Epoch 3 [130/172] - loss: 0.1327, acc: 0.9688
Epoch 3 [131/172] - loss: 0.2288
Epoch 3 [132/172] - loss: 0.1136
Epoch 3 [133/172] - loss: 0.1120
Epoch 3 [134/172] - loss: 0.1141
Epoch 3 [135/172] - loss: 0.1127
Epoch 3 [136/172] - loss: 0.1181
Epoch 3 [137/172] - loss: 0.1088
Epoch 3 [138/172] - loss: 0.1361
Epoch 3 [139/172] - loss: 0.1507
Epoch 3 [140/172] - loss: 0.1417, acc: 0.9375
Epoch 3 [141/172] - loss: 0.2112
Epoch 3 [142/172] - loss: 0.1721
Epoch 3 [143/172] - loss: 0.0987
Epoch 3 [144/172] - loss: 0.1785
Epoch 3 [145/172] - loss: 0.1211
Epoch 3 [146/172] - loss: 0.0885
Epoch 3 [147/172] - loss: 0.1218
Epoch 3 [148/172] - loss: 0.1409
Epoch 3 [149/172] - loss: 0.1388
Epoch 3 [150/172] - loss: 0.1079, acc: 1.0000
Epoch 3 [151/172] - loss: 0.2644
Epoch 3 [152/172] - loss: 0.2518
Epoch 3 [153/172] - loss: 0.1082
Epoch 3 [154/172] - loss: 0.1152
Epoch 3 [155/172] - loss: 0.0903
Epoch 3 [156/172] - loss: 0.1277

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3297, log_difficulty=0.2849, weight=2.4247
neutral: count=4903.0, difficulty=0.2610, log_difficulty=0.2319, weight=2.1595
negative: count=5500.0, difficulty=0.3237, log_difficulty=0.2804, weight=2.4022

当前batch的pt分布：
positive: min=0.5946, max=0.9929, mean=0.8821
neutral: min=0.7769, max=0.9980, mean=0.9406
negative: min=0.5500, max=0.9951, mean=0.8943

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1078
焦点损失: 0.0061
边界损失: 0.1905
总损失: 0.1026
Epoch 3 [157/172] - loss: 0.1026
Epoch 3 [158/172] - loss: 0.1226
Epoch 3 [159/172] - loss: 0.1221
Epoch 3 [160/172] - loss: 0.2219, acc: 0.8750
Epoch 3 [161/172] - loss: 0.3201
Epoch 3 [162/172] - loss: 0.1051
Epoch 3 [163/172] - loss: 0.2302
Epoch 3 [164/172] - loss: 0.0893
Epoch 3 [165/172] - loss: 0.1040
Epoch 3 [166/172] - loss: 0.0993
Epoch 3 [167/172] - loss: 0.1017
Epoch 3 [168/172] - loss: 0.0993
Epoch 3 [169/172] - loss: 0.0967
Epoch 3 [170/172] - loss: 0.1342, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1074
Epoch 3 [172/172] - loss: 0.1562

类别准确率:
positive: 0.8587 (401/467)
neutral: 0.3614 (30/83)
negative: 0.5520 (138/250)

Epoch 3/10
Train Loss: 0.1383, Train Acc: 0.9657
Val Loss: 0.7093, Val Acc: 0.7113
Epoch 4 [1/172] - loss: 0.0837, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1727
Epoch 4 [3/172] - loss: 0.0969
Epoch 4 [4/172] - loss: 0.1405
Epoch 4 [5/172] - loss: 0.1145
Epoch 4 [6/172] - loss: 0.0992
Epoch 4 [7/172] - loss: 0.0984
Epoch 4 [8/172] - loss: 0.0854
Epoch 4 [9/172] - loss: 0.1579
Epoch 4 [10/172] - loss: 0.0978, acc: 1.0000
Epoch 4 [11/172] - loss: 0.0811
Epoch 4 [12/172] - loss: 0.1476
Epoch 4 [13/172] - loss: 0.1294
Epoch 4 [14/172] - loss: 0.1043
Epoch 4 [15/172] - loss: 0.0804
Epoch 4 [16/172] - loss: 0.0914
Epoch 4 [17/172] - loss: 0.0963
Epoch 4 [18/172] - loss: 0.0945
Epoch 4 [19/172] - loss: 0.0967
Epoch 4 [20/172] - loss: 0.0933, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1851
Epoch 4 [22/172] - loss: 0.0809
Epoch 4 [23/172] - loss: 0.0987
Epoch 4 [24/172] - loss: 0.0810
Epoch 4 [25/172] - loss: 0.0849
Epoch 4 [26/172] - loss: 0.1505
Epoch 4 [27/172] - loss: 0.0862
Epoch 4 [28/172] - loss: 0.0921
Epoch 4 [29/172] - loss: 0.0834
Epoch 4 [30/172] - loss: 0.1289, acc: 0.9375
Epoch 4 [31/172] - loss: 0.1209
Epoch 4 [32/172] - loss: 0.0827
Epoch 4 [33/172] - loss: 0.0846
Epoch 4 [34/172] - loss: 0.0870
Epoch 4 [35/172] - loss: 0.0999
Epoch 4 [36/172] - loss: 0.0822
Epoch 4 [37/172] - loss: 0.0795
Epoch 4 [38/172] - loss: 0.1336
Epoch 4 [39/172] - loss: 0.1273
Epoch 4 [40/172] - loss: 0.1255, acc: 0.9688
Epoch 4 [41/172] - loss: 0.0855
Epoch 4 [42/172] - loss: 0.3451
Epoch 4 [43/172] - loss: 0.1613
Epoch 4 [44/172] - loss: 0.0895
Epoch 4 [45/172] - loss: 0.0899
Epoch 4 [46/172] - loss: 0.0819
Epoch 4 [47/172] - loss: 0.0938
Epoch 4 [48/172] - loss: 0.0871
Epoch 4 [49/172] - loss: 0.0852
Epoch 4 [50/172] - loss: 0.0800, acc: 1.0000
Epoch 4 [51/172] - loss: 0.1329
Epoch 4 [52/172] - loss: 0.1043
Epoch 4 [53/172] - loss: 0.0892
Epoch 4 [54/172] - loss: 0.1176
Epoch 4 [55/172] - loss: 0.1865
Epoch 4 [56/172] - loss: 0.0821
Epoch 4 [57/172] - loss: 0.0920
Epoch 4 [58/172] - loss: 0.1086
Epoch 4 [59/172] - loss: 0.0867
Epoch 4 [60/172] - loss: 0.0819, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1031
Epoch 4 [62/172] - loss: 0.1230
Epoch 4 [63/172] - loss: 0.0902
Epoch 4 [64/172] - loss: 0.0839
Epoch 4 [65/172] - loss: 0.1291
Epoch 4 [66/172] - loss: 0.1132
Epoch 4 [67/172] - loss: 0.0847
Epoch 4 [68/172] - loss: 0.0919
Epoch 4 [69/172] - loss: 0.0784
Epoch 4 [70/172] - loss: 0.0876, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0951
Epoch 4 [72/172] - loss: 0.0890
Epoch 4 [73/172] - loss: 0.0837
Epoch 4 [74/172] - loss: 0.1841
Epoch 4 [75/172] - loss: 0.0851
Epoch 4 [76/172] - loss: 0.0779
Epoch 4 [77/172] - loss: 0.0945
Epoch 4 [78/172] - loss: 0.1141
Epoch 4 [79/172] - loss: 0.0811
Epoch 4 [80/172] - loss: 0.1008, acc: 0.9688
Epoch 4 [81/172] - loss: 0.1827
Epoch 4 [82/172] - loss: 0.0851
Epoch 4 [83/172] - loss: 0.0800
Epoch 4 [84/172] - loss: 0.0873

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2904, log_difficulty=0.2549, weight=2.2746
neutral: count=5865.0, difficulty=0.2286, log_difficulty=0.2059, weight=2.0294
negative: count=6629.0, difficulty=0.2842, log_difficulty=0.2501, weight=2.2506

当前batch的pt分布：
positive: min=0.6126, max=0.9876, mean=0.8691
neutral: min=0.9123, max=0.9951, mean=0.9762
negative: min=0.9258, max=0.9988, mean=0.9737

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0879
焦点损失: 0.0041
边界损失: 0.1772
总损失: 0.0933
Epoch 4 [85/172] - loss: 0.0933
Epoch 4 [86/172] - loss: 0.0978
Epoch 4 [87/172] - loss: 0.0868
Epoch 4 [88/172] - loss: 0.0802
Epoch 4 [89/172] - loss: 0.0933
Epoch 4 [90/172] - loss: 0.0894, acc: 1.0000
Epoch 4 [91/172] - loss: 0.2622
Epoch 4 [92/172] - loss: 0.1548
Epoch 4 [93/172] - loss: 0.0806
Epoch 4 [94/172] - loss: 0.0921
Epoch 4 [95/172] - loss: 0.0864
Epoch 4 [96/172] - loss: 0.0953
Epoch 4 [97/172] - loss: 0.0868
Epoch 4 [98/172] - loss: 0.1383
Epoch 4 [99/172] - loss: 0.2035
Epoch 4 [100/172] - loss: 0.1137, acc: 0.9375
Epoch 4 [101/172] - loss: 0.0921
Epoch 4 [102/172] - loss: 0.1199
Epoch 4 [103/172] - loss: 0.0813
Epoch 4 [104/172] - loss: 0.0956
Epoch 4 [105/172] - loss: 0.2142
Epoch 4 [106/172] - loss: 0.0822
Epoch 4 [107/172] - loss: 0.0809
Epoch 4 [108/172] - loss: 0.1791
Epoch 4 [109/172] - loss: 0.1123
Epoch 4 [110/172] - loss: 0.2166, acc: 0.9062
Epoch 4 [111/172] - loss: 0.0856
Epoch 4 [112/172] - loss: 0.0882
Epoch 4 [113/172] - loss: 0.0923
Epoch 4 [114/172] - loss: 0.1063
Epoch 4 [115/172] - loss: 0.0992
Epoch 4 [116/172] - loss: 0.1005
Epoch 4 [117/172] - loss: 0.0865
Epoch 4 [118/172] - loss: 0.1975
Epoch 4 [119/172] - loss: 0.0967
Epoch 4 [120/172] - loss: 0.0916, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1083
Epoch 4 [122/172] - loss: 0.2276
Epoch 4 [123/172] - loss: 0.1035
Epoch 4 [124/172] - loss: 0.0855
Epoch 4 [125/172] - loss: 0.0995
Epoch 4 [126/172] - loss: 0.1374
Epoch 4 [127/172] - loss: 0.1292
Epoch 4 [128/172] - loss: 0.0849
Epoch 4 [129/172] - loss: 0.0882
Epoch 4 [130/172] - loss: 0.0792, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1011
Epoch 4 [132/172] - loss: 0.0801
Epoch 4 [133/172] - loss: 0.1254
Epoch 4 [134/172] - loss: 0.0785
Epoch 4 [135/172] - loss: 0.1244
Epoch 4 [136/172] - loss: 0.1127
Epoch 4 [137/172] - loss: 0.1590
Epoch 4 [138/172] - loss: 0.0935
Epoch 4 [139/172] - loss: 0.0810
Epoch 4 [140/172] - loss: 0.0874, acc: 1.0000
Epoch 4 [141/172] - loss: 0.1524
Epoch 4 [142/172] - loss: 0.1010
Epoch 4 [143/172] - loss: 0.0867
Epoch 4 [144/172] - loss: 0.1476
Epoch 4 [145/172] - loss: 0.1176
Epoch 4 [146/172] - loss: 0.0945
Epoch 4 [147/172] - loss: 0.2101
Epoch 4 [148/172] - loss: 0.0910
Epoch 4 [149/172] - loss: 0.0864
Epoch 4 [150/172] - loss: 0.1358, acc: 1.0000
Epoch 4 [151/172] - loss: 0.1808
Epoch 4 [152/172] - loss: 0.0818
Epoch 4 [153/172] - loss: 0.0859
Epoch 4 [154/172] - loss: 0.1557
Epoch 4 [155/172] - loss: 0.1453
Epoch 4 [156/172] - loss: 0.1160
Epoch 4 [157/172] - loss: 0.1510
Epoch 4 [158/172] - loss: 0.1065
Epoch 4 [159/172] - loss: 0.0813
Epoch 4 [160/172] - loss: 0.1187, acc: 0.9688
Epoch 4 [161/172] - loss: 0.1110
Epoch 4 [162/172] - loss: 0.1728
Epoch 4 [163/172] - loss: 0.1343
Epoch 4 [164/172] - loss: 0.1081
Epoch 4 [165/172] - loss: 0.1882
Epoch 4 [166/172] - loss: 0.0975
Epoch 4 [167/172] - loss: 0.1355
Epoch 4 [168/172] - loss: 0.0957
Epoch 4 [169/172] - loss: 0.2229
Epoch 4 [170/172] - loss: 0.1605, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0958
Epoch 4 [172/172] - loss: 0.1024

类别准确率:
positive: 0.8887 (415/467)
neutral: 0.2892 (24/83)
negative: 0.5280 (132/250)

Epoch 4/10
Train Loss: 0.1301, Train Acc: 0.9697
Val Loss: 0.8184, Val Acc: 0.7137
Epoch 5 [1/172] - loss: 0.0825, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0975
Epoch 5 [3/172] - loss: 0.0895
Epoch 5 [4/172] - loss: 0.0878
Epoch 5 [5/172] - loss: 0.0800
Epoch 5 [6/172] - loss: 0.0942
Epoch 5 [7/172] - loss: 0.0812
Epoch 5 [8/172] - loss: 0.2065
Epoch 5 [9/172] - loss: 0.1184
Epoch 5 [10/172] - loss: 0.0787, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1115
Epoch 5 [12/172] - loss: 0.0788

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2618, log_difficulty=0.2326, weight=2.1628
neutral: count=6845.0, difficulty=0.2044, log_difficulty=0.1860, weight=1.9298
negative: count=7694.0, difficulty=0.2570, log_difficulty=0.2287, weight=2.1434

当前batch的pt分布：
positive: min=0.5730, max=0.9920, mean=0.8993
neutral: min=0.9838, max=0.9994, mean=0.9915
negative: min=0.8141, max=0.9973, mean=0.9346

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0764
焦点损失: 0.0036
边界损失: 0.1713
总损失: 0.0896
Epoch 5 [13/172] - loss: 0.0896
Epoch 5 [14/172] - loss: 0.1288
Epoch 5 [15/172] - loss: 0.0786
Epoch 5 [16/172] - loss: 0.0989
Epoch 5 [17/172] - loss: 0.0875
Epoch 5 [18/172] - loss: 0.0815
Epoch 5 [19/172] - loss: 0.1734
Epoch 5 [20/172] - loss: 0.0822, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1583
Epoch 5 [22/172] - loss: 0.2315
Epoch 5 [23/172] - loss: 0.0752
Epoch 5 [24/172] - loss: 0.0766
Epoch 5 [25/172] - loss: 0.0795
Epoch 5 [26/172] - loss: 0.1287
Epoch 5 [27/172] - loss: 0.0826
Epoch 5 [28/172] - loss: 0.0830
Epoch 5 [29/172] - loss: 0.0770
Epoch 5 [30/172] - loss: 0.1044, acc: 0.9688
Epoch 5 [31/172] - loss: 0.0919
Epoch 5 [32/172] - loss: 0.0814
Epoch 5 [33/172] - loss: 0.0855
Epoch 5 [34/172] - loss: 0.0868
Epoch 5 [35/172] - loss: 0.0841
Epoch 5 [36/172] - loss: 0.0860
Epoch 5 [37/172] - loss: 0.0828
Epoch 5 [38/172] - loss: 0.0785
Epoch 5 [39/172] - loss: 0.2631
Epoch 5 [40/172] - loss: 0.0962, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0798
Epoch 5 [42/172] - loss: 0.1330
Epoch 5 [43/172] - loss: 0.1644
Epoch 5 [44/172] - loss: 0.0933
Epoch 5 [45/172] - loss: 0.0795
Epoch 5 [46/172] - loss: 0.0973
Epoch 5 [47/172] - loss: 0.0774
Epoch 5 [48/172] - loss: 0.0852
Epoch 5 [49/172] - loss: 0.1019
Epoch 5 [50/172] - loss: 0.0934, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0933
Epoch 5 [52/172] - loss: 0.0811
Epoch 5 [53/172] - loss: 0.1178
Epoch 5 [54/172] - loss: 0.0779
Epoch 5 [55/172] - loss: 0.0895
Epoch 5 [56/172] - loss: 0.0848
Epoch 5 [57/172] - loss: 0.0805
Epoch 5 [58/172] - loss: 0.0818
Epoch 5 [59/172] - loss: 0.1180
Epoch 5 [60/172] - loss: 0.0788, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0803
Epoch 5 [62/172] - loss: 0.0825
Epoch 5 [63/172] - loss: 0.1148
Epoch 5 [64/172] - loss: 0.1098
Epoch 5 [65/172] - loss: 0.0806
Epoch 5 [66/172] - loss: 0.0773
Epoch 5 [67/172] - loss: 0.0748
Epoch 5 [68/172] - loss: 0.1072
Epoch 5 [69/172] - loss: 0.0785
Epoch 5 [70/172] - loss: 0.0814, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0859
Epoch 5 [72/172] - loss: 0.0835
Epoch 5 [73/172] - loss: 0.0811
Epoch 5 [74/172] - loss: 0.1595
Epoch 5 [75/172] - loss: 0.0764
Epoch 5 [76/172] - loss: 0.0809
Epoch 5 [77/172] - loss: 0.0778
Epoch 5 [78/172] - loss: 0.1952
Epoch 5 [79/172] - loss: 0.0767
Epoch 5 [80/172] - loss: 0.0805, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1139
Epoch 5 [82/172] - loss: 0.0881
Epoch 5 [83/172] - loss: 0.0944
Epoch 5 [84/172] - loss: 0.0756
Epoch 5 [85/172] - loss: 0.1712
Epoch 5 [86/172] - loss: 0.0778
Epoch 5 [87/172] - loss: 0.0834
Epoch 5 [88/172] - loss: 0.1417
Epoch 5 [89/172] - loss: 0.0761
Epoch 5 [90/172] - loss: 0.1381, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0760
Epoch 5 [92/172] - loss: 0.0765
Epoch 5 [93/172] - loss: 0.0762
Epoch 5 [94/172] - loss: 0.0774
Epoch 5 [95/172] - loss: 0.0794
Epoch 5 [96/172] - loss: 0.0784
Epoch 5 [97/172] - loss: 0.1179
Epoch 5 [98/172] - loss: 0.0891
Epoch 5 [99/172] - loss: 0.1456
Epoch 5 [100/172] - loss: 0.0978, acc: 0.9688
Epoch 5 [101/172] - loss: 0.0945
Epoch 5 [102/172] - loss: 0.0798
Epoch 5 [103/172] - loss: 0.0848
Epoch 5 [104/172] - loss: 0.1091
Epoch 5 [105/172] - loss: 0.2838
Epoch 5 [106/172] - loss: 0.0805
Epoch 5 [107/172] - loss: 0.1133
Epoch 5 [108/172] - loss: 0.1490
Epoch 5 [109/172] - loss: 0.0776
Epoch 5 [110/172] - loss: 0.0797, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0953
Epoch 5 [112/172] - loss: 0.0855

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2368, log_difficulty=0.2125, weight=2.0626
neutral: count=7825.0, difficulty=0.1849, log_difficulty=0.1697, weight=1.8483
negative: count=8780.0, difficulty=0.2337, log_difficulty=0.2100, weight=2.0501

当前batch的pt分布：
positive: min=0.1385, max=0.9832, mean=0.8153
neutral: min=0.7778, max=0.9981, mean=0.9399
negative: min=0.9511, max=0.9994, mean=0.9891

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1681
焦点损失: 0.0583
边界损失: 0.1853
总损失: 0.1527
Epoch 5 [113/172] - loss: 0.1527
Epoch 5 [114/172] - loss: 0.2510
Epoch 5 [115/172] - loss: 0.0829
Epoch 5 [116/172] - loss: 0.1076
Epoch 5 [117/172] - loss: 0.0907
Epoch 5 [118/172] - loss: 0.0861
Epoch 5 [119/172] - loss: 0.0751
Epoch 5 [120/172] - loss: 0.1509, acc: 0.9375
Epoch 5 [121/172] - loss: 0.1450
Epoch 5 [122/172] - loss: 0.1366
Epoch 5 [123/172] - loss: 0.0832
Epoch 5 [124/172] - loss: 0.1010
Epoch 5 [125/172] - loss: 0.1030
Epoch 5 [126/172] - loss: 0.1211
Epoch 5 [127/172] - loss: 0.1016
Epoch 5 [128/172] - loss: 0.1294
Epoch 5 [129/172] - loss: 0.1970
Epoch 5 [130/172] - loss: 0.0790, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1091
Epoch 5 [132/172] - loss: 0.1875
Epoch 5 [133/172] - loss: 0.1398
Epoch 5 [134/172] - loss: 0.1256
Epoch 5 [135/172] - loss: 0.0776
Epoch 5 [136/172] - loss: 0.0828
Epoch 5 [137/172] - loss: 0.1213
Epoch 5 [138/172] - loss: 0.1321
Epoch 5 [139/172] - loss: 0.1365
Epoch 5 [140/172] - loss: 0.1171, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0888
Epoch 5 [142/172] - loss: 0.0939
Epoch 5 [143/172] - loss: 0.0780
Epoch 5 [144/172] - loss: 0.0841
Epoch 5 [145/172] - loss: 0.1069
Epoch 5 [146/172] - loss: 0.0793
Epoch 5 [147/172] - loss: 0.1002
Epoch 5 [148/172] - loss: 0.0799
Epoch 5 [149/172] - loss: 0.0788
Epoch 5 [150/172] - loss: 0.0971, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0881
Epoch 5 [152/172] - loss: 0.1071
Epoch 5 [153/172] - loss: 0.0748
Epoch 5 [154/172] - loss: 0.1017
Epoch 5 [155/172] - loss: 0.1458
Epoch 5 [156/172] - loss: 0.0798
Epoch 5 [157/172] - loss: 0.0839
Epoch 5 [158/172] - loss: 0.0825
Epoch 5 [159/172] - loss: 0.1314
Epoch 5 [160/172] - loss: 0.1115, acc: 0.9688
Epoch 5 [161/172] - loss: 0.1405
Epoch 5 [162/172] - loss: 0.0850
Epoch 5 [163/172] - loss: 0.1438
Epoch 5 [164/172] - loss: 0.0769
Epoch 5 [165/172] - loss: 0.1690
Epoch 5 [166/172] - loss: 0.0866
Epoch 5 [167/172] - loss: 0.0928
Epoch 5 [168/172] - loss: 0.1556
Epoch 5 [169/172] - loss: 0.0884
Epoch 5 [170/172] - loss: 0.0803, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1036
Epoch 5 [172/172] - loss: 0.0877

类别准确率:
positive: 0.9315 (435/467)
neutral: 0.2651 (22/83)
negative: 0.3640 (91/250)

Epoch 5/10
Train Loss: 0.1075, Train Acc: 0.9778
Val Loss: 0.8971, Val Acc: 0.6850
Epoch 6 [1/172] - loss: 0.1144, acc: 0.9688
Epoch 6 [2/172] - loss: 0.1080
Epoch 6 [3/172] - loss: 0.0842
Epoch 6 [4/172] - loss: 0.0811
Epoch 6 [5/172] - loss: 0.2001
Epoch 6 [6/172] - loss: 0.0831
Epoch 6 [7/172] - loss: 0.0897
Epoch 6 [8/172] - loss: 0.0903
Epoch 6 [9/172] - loss: 0.0851
Epoch 6 [10/172] - loss: 0.1120, acc: 0.9688
Epoch 6 [11/172] - loss: 0.0927
Epoch 6 [12/172] - loss: 0.0794
Epoch 6 [13/172] - loss: 0.0986
Epoch 6 [14/172] - loss: 0.0818
Epoch 6 [15/172] - loss: 0.0780
Epoch 6 [16/172] - loss: 0.1690
Epoch 6 [17/172] - loss: 0.0847
Epoch 6 [18/172] - loss: 0.0872
Epoch 6 [19/172] - loss: 0.0952
Epoch 6 [20/172] - loss: 0.0770, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0808
Epoch 6 [22/172] - loss: 0.0896
Epoch 6 [23/172] - loss: 0.0833
Epoch 6 [24/172] - loss: 0.0808
Epoch 6 [25/172] - loss: 0.0890
Epoch 6 [26/172] - loss: 0.0829
Epoch 6 [27/172] - loss: 0.1508
Epoch 6 [28/172] - loss: 0.1264
Epoch 6 [29/172] - loss: 0.0781
Epoch 6 [30/172] - loss: 0.0929, acc: 0.9688
Epoch 6 [31/172] - loss: 0.0814
Epoch 6 [32/172] - loss: 0.0767
Epoch 6 [33/172] - loss: 0.0760
Epoch 6 [34/172] - loss: 0.0776
Epoch 6 [35/172] - loss: 0.0780
Epoch 6 [36/172] - loss: 0.0803
Epoch 6 [37/172] - loss: 0.0768
Epoch 6 [38/172] - loss: 0.0803
Epoch 6 [39/172] - loss: 0.0822
Epoch 6 [40/172] - loss: 0.1554, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2185, log_difficulty=0.1976, weight=1.9881
neutral: count=8815.0, difficulty=0.1698, log_difficulty=0.1568, weight=1.7841
negative: count=9870.0, difficulty=0.2160, log_difficulty=0.1956, weight=1.9779

当前batch的pt分布：
positive: min=0.0216, max=0.9964, mean=0.8952
neutral: min=0.9516, max=0.9985, mean=0.9795
negative: min=0.7757, max=0.9943, mean=0.9333

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1567
焦点损失: 0.1151
边界损失: 0.1528
总损失: 0.1909
Epoch 6 [41/172] - loss: 0.1909
Epoch 6 [42/172] - loss: 0.0832
Epoch 6 [43/172] - loss: 0.1061
Epoch 6 [44/172] - loss: 0.0751
Epoch 6 [45/172] - loss: 0.0831
Epoch 6 [46/172] - loss: 0.0848
Epoch 6 [47/172] - loss: 0.0841
Epoch 6 [48/172] - loss: 0.0752
Epoch 6 [49/172] - loss: 0.0832
Epoch 6 [50/172] - loss: 0.1067, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1016
Epoch 6 [52/172] - loss: 0.0989
Epoch 6 [53/172] - loss: 0.0770
Epoch 6 [54/172] - loss: 0.1213
Epoch 6 [55/172] - loss: 0.0771
Epoch 6 [56/172] - loss: 0.1139
Epoch 6 [57/172] - loss: 0.0765
Epoch 6 [58/172] - loss: 0.0766
Epoch 6 [59/172] - loss: 0.1182
Epoch 6 [60/172] - loss: 0.1160, acc: 0.9688
Epoch 6 [61/172] - loss: 0.0855
Epoch 6 [62/172] - loss: 0.0827
Epoch 6 [63/172] - loss: 0.0831
Epoch 6 [64/172] - loss: 0.1728
Epoch 6 [65/172] - loss: 0.1290
Epoch 6 [66/172] - loss: 0.0771
Epoch 6 [67/172] - loss: 0.0760
Epoch 6 [68/172] - loss: 0.1400
Epoch 6 [69/172] - loss: 0.0960
Epoch 6 [70/172] - loss: 0.0742, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0845
Epoch 6 [72/172] - loss: 0.1001
Epoch 6 [73/172] - loss: 0.0931
Epoch 6 [74/172] - loss: 0.0764
Epoch 6 [75/172] - loss: 0.1011
Epoch 6 [76/172] - loss: 0.0785
Epoch 6 [77/172] - loss: 0.0919
Epoch 6 [78/172] - loss: 0.0854
Epoch 6 [79/172] - loss: 0.0804
Epoch 6 [80/172] - loss: 0.1387, acc: 0.9688
Epoch 6 [81/172] - loss: 0.0910
Epoch 6 [82/172] - loss: 0.1021
Epoch 6 [83/172] - loss: 0.0809
Epoch 6 [84/172] - loss: 0.1070
Epoch 6 [85/172] - loss: 0.1836
Epoch 6 [86/172] - loss: 0.1507
Epoch 6 [87/172] - loss: 0.0920
Epoch 6 [88/172] - loss: 0.2832
Epoch 6 [89/172] - loss: 0.0828
Epoch 6 [90/172] - loss: 0.0765, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0788
Epoch 6 [92/172] - loss: 0.0896
Epoch 6 [93/172] - loss: 0.0947
Epoch 6 [94/172] - loss: 0.1236
Epoch 6 [95/172] - loss: 0.1224
Epoch 6 [96/172] - loss: 0.0794
Epoch 6 [97/172] - loss: 0.1353
Epoch 6 [98/172] - loss: 0.0881
Epoch 6 [99/172] - loss: 0.0840
Epoch 6 [100/172] - loss: 0.0856, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1777
Epoch 6 [102/172] - loss: 0.0891
Epoch 6 [103/172] - loss: 0.0806
Epoch 6 [104/172] - loss: 0.1606
Epoch 6 [105/172] - loss: 0.0831
Epoch 6 [106/172] - loss: 0.1044
Epoch 6 [107/172] - loss: 0.0831
Epoch 6 [108/172] - loss: 0.0791
Epoch 6 [109/172] - loss: 0.1295
Epoch 6 [110/172] - loss: 0.0891, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0863
Epoch 6 [112/172] - loss: 0.0795
Epoch 6 [113/172] - loss: 0.0842
Epoch 6 [114/172] - loss: 0.0801
Epoch 6 [115/172] - loss: 0.1019
Epoch 6 [116/172] - loss: 0.1917
Epoch 6 [117/172] - loss: 0.0793
Epoch 6 [118/172] - loss: 0.1025
Epoch 6 [119/172] - loss: 0.1400
Epoch 6 [120/172] - loss: 0.0829, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0896
Epoch 6 [122/172] - loss: 0.0949
Epoch 6 [123/172] - loss: 0.0821
Epoch 6 [124/172] - loss: 0.0753
Epoch 6 [125/172] - loss: 0.1030
Epoch 6 [126/172] - loss: 0.1190
Epoch 6 [127/172] - loss: 0.1574
Epoch 6 [128/172] - loss: 0.0792
Epoch 6 [129/172] - loss: 0.0789
Epoch 6 [130/172] - loss: 0.1191, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1004
Epoch 6 [132/172] - loss: 0.0997
Epoch 6 [133/172] - loss: 0.0844
Epoch 6 [134/172] - loss: 0.0792
Epoch 6 [135/172] - loss: 0.0905
Epoch 6 [136/172] - loss: 0.0774
Epoch 6 [137/172] - loss: 0.0829
Epoch 6 [138/172] - loss: 0.0822
Epoch 6 [139/172] - loss: 0.1444
Epoch 6 [140/172] - loss: 0.0861, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2031, log_difficulty=0.1849, weight=1.9245
neutral: count=9796.0, difficulty=0.1579, log_difficulty=0.1466, weight=1.7330
negative: count=10972.0, difficulty=0.2009, log_difficulty=0.1831, weight=1.9154

当前batch的pt分布：
positive: min=0.9594, max=0.9960, mean=0.9881
neutral: min=0.9443, max=0.9989, mean=0.9828
negative: min=0.9481, max=0.9956, mean=0.9658

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0230
焦点损失: 0.0000
边界损失: 0.1463
总损失: 0.0732
Epoch 6 [141/172] - loss: 0.0732
Epoch 6 [142/172] - loss: 0.0748
Epoch 6 [143/172] - loss: 0.0835
Epoch 6 [144/172] - loss: 0.0788
Epoch 6 [145/172] - loss: 0.0751
Epoch 6 [146/172] - loss: 0.0787
Epoch 6 [147/172] - loss: 0.1561
Epoch 6 [148/172] - loss: 0.0939
Epoch 6 [149/172] - loss: 0.1125
Epoch 6 [150/172] - loss: 0.1375, acc: 0.9688
Epoch 6 [151/172] - loss: 0.1256
Epoch 6 [152/172] - loss: 0.0867
Epoch 6 [153/172] - loss: 0.0758
Epoch 6 [154/172] - loss: 0.0760
Epoch 6 [155/172] - loss: 0.1410
Epoch 6 [156/172] - loss: 0.1447
Epoch 6 [157/172] - loss: 0.0758
Epoch 6 [158/172] - loss: 0.0975
Epoch 6 [159/172] - loss: 0.0855
Epoch 6 [160/172] - loss: 0.1581, acc: 0.9375
Epoch 6 [161/172] - loss: 0.0906
Epoch 6 [162/172] - loss: 0.1049
Epoch 6 [163/172] - loss: 0.0840
Epoch 6 [164/172] - loss: 0.0915
Epoch 6 [165/172] - loss: 0.2487
Epoch 6 [166/172] - loss: 0.0868
Epoch 6 [167/172] - loss: 0.0767
Epoch 6 [168/172] - loss: 0.0803
Epoch 6 [169/172] - loss: 0.1124
Epoch 6 [170/172] - loss: 0.0762, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0888
Epoch 6 [172/172] - loss: 0.0810

类别准确率:
positive: 0.8651 (404/467)
neutral: 0.3855 (32/83)
negative: 0.4560 (114/250)

Epoch 6/10
Train Loss: 0.1024, Train Acc: 0.9818
Val Loss: 0.8982, Val Acc: 0.6875
Epoch 7 [1/172] - loss: 0.1116, acc: 0.9688
Epoch 7 [2/172] - loss: 0.0785
Epoch 7 [3/172] - loss: 0.0776
Epoch 7 [4/172] - loss: 0.0862
Epoch 7 [5/172] - loss: 0.0865
Epoch 7 [6/172] - loss: 0.0776
Epoch 7 [7/172] - loss: 0.0789
Epoch 7 [8/172] - loss: 0.1400
Epoch 7 [9/172] - loss: 0.0760
Epoch 7 [10/172] - loss: 0.0773, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0811
Epoch 7 [12/172] - loss: 0.1123
Epoch 7 [13/172] - loss: 0.0875
Epoch 7 [14/172] - loss: 0.0836
Epoch 7 [15/172] - loss: 0.1294
Epoch 7 [16/172] - loss: 0.1146
Epoch 7 [17/172] - loss: 0.1133
Epoch 7 [18/172] - loss: 0.0858
Epoch 7 [19/172] - loss: 0.0810
Epoch 7 [20/172] - loss: 0.0868, acc: 1.0000
Epoch 7 [21/172] - loss: 0.1038
Epoch 7 [22/172] - loss: 0.0777
Epoch 7 [23/172] - loss: 0.0792
Epoch 7 [24/172] - loss: 0.0884
Epoch 7 [25/172] - loss: 0.0776
Epoch 7 [26/172] - loss: 0.1072
Epoch 7 [27/172] - loss: 0.0772
Epoch 7 [28/172] - loss: 0.0916
Epoch 7 [29/172] - loss: 0.0848
Epoch 7 [30/172] - loss: 0.1172, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0797
Epoch 7 [32/172] - loss: 0.0747
Epoch 7 [33/172] - loss: 0.0832
Epoch 7 [34/172] - loss: 0.0768
Epoch 7 [35/172] - loss: 0.0761
Epoch 7 [36/172] - loss: 0.1430
Epoch 7 [37/172] - loss: 0.0789
Epoch 7 [38/172] - loss: 0.0833
Epoch 7 [39/172] - loss: 0.0914
Epoch 7 [40/172] - loss: 0.1182, acc: 0.9688
Epoch 7 [41/172] - loss: 0.0965
Epoch 7 [42/172] - loss: 0.0820
Epoch 7 [43/172] - loss: 0.0788
Epoch 7 [44/172] - loss: 0.1001
Epoch 7 [45/172] - loss: 0.0831
Epoch 7 [46/172] - loss: 0.0922
Epoch 7 [47/172] - loss: 0.1038
Epoch 7 [48/172] - loss: 0.0734
Epoch 7 [49/172] - loss: 0.0775
Epoch 7 [50/172] - loss: 0.0759, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1639
Epoch 7 [52/172] - loss: 0.0748
Epoch 7 [53/172] - loss: 0.0741
Epoch 7 [54/172] - loss: 0.0821
Epoch 7 [55/172] - loss: 0.0918
Epoch 7 [56/172] - loss: 0.0787
Epoch 7 [57/172] - loss: 0.0848
Epoch 7 [58/172] - loss: 0.0909
Epoch 7 [59/172] - loss: 0.0766
Epoch 7 [60/172] - loss: 0.0990, acc: 0.9688
Epoch 7 [61/172] - loss: 0.0808
Epoch 7 [62/172] - loss: 0.0787
Epoch 7 [63/172] - loss: 0.1452
Epoch 7 [64/172] - loss: 0.0778
Epoch 7 [65/172] - loss: 0.0925
Epoch 7 [66/172] - loss: 0.0736
Epoch 7 [67/172] - loss: 0.0785
Epoch 7 [68/172] - loss: 0.1719

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1902, log_difficulty=0.1741, weight=1.8706
neutral: count=10756.0, difficulty=0.1468, log_difficulty=0.1370, weight=1.6850
negative: count=12072.0, difficulty=0.1885, log_difficulty=0.1727, weight=1.8633

当前batch的pt分布：
positive: min=0.9423, max=0.9993, mean=0.9783
neutral: min=0.9866, max=0.9990, mean=0.9925
negative: min=0.8983, max=0.9897, mean=0.9577

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0279
焦点损失: 0.0001
边界损失: 0.1484
总损失: 0.0743
Epoch 7 [69/172] - loss: 0.0743
Epoch 7 [70/172] - loss: 0.0757, acc: 1.0000
Epoch 7 [71/172] - loss: 0.0870
Epoch 7 [72/172] - loss: 0.0826
Epoch 7 [73/172] - loss: 0.0822
Epoch 7 [74/172] - loss: 0.0751
Epoch 7 [75/172] - loss: 0.0740
Epoch 7 [76/172] - loss: 0.1067
Epoch 7 [77/172] - loss: 0.0782
Epoch 7 [78/172] - loss: 0.0770
Epoch 7 [79/172] - loss: 0.1182
Epoch 7 [80/172] - loss: 0.0857, acc: 1.0000
Epoch 7 [81/172] - loss: 0.0746
Epoch 7 [82/172] - loss: 0.0761
Epoch 7 [83/172] - loss: 0.0940
Epoch 7 [84/172] - loss: 0.1042
Epoch 7 [85/172] - loss: 0.0846
Epoch 7 [86/172] - loss: 0.0788
Epoch 7 [87/172] - loss: 0.0946
Epoch 7 [88/172] - loss: 0.0756
Epoch 7 [89/172] - loss: 0.0733
Epoch 7 [90/172] - loss: 0.0766, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0821
Epoch 7 [92/172] - loss: 0.0781
Epoch 7 [93/172] - loss: 0.1263
Epoch 7 [94/172] - loss: 0.0792
Epoch 7 [95/172] - loss: 0.0731
Epoch 7 [96/172] - loss: 0.0986
Epoch 7 [97/172] - loss: 0.0861
Epoch 7 [98/172] - loss: 0.1234
Epoch 7 [99/172] - loss: 0.0766
Epoch 7 [100/172] - loss: 0.0762, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0753
Epoch 7 [102/172] - loss: 0.0850
Epoch 7 [103/172] - loss: 0.0838
Epoch 7 [104/172] - loss: 0.0783
Epoch 7 [105/172] - loss: 0.0862
Epoch 7 [106/172] - loss: 0.0896
Epoch 7 [107/172] - loss: 0.0755
Epoch 7 [108/172] - loss: 0.0764
Epoch 7 [109/172] - loss: 0.0944
Epoch 7 [110/172] - loss: 0.0914, acc: 0.9688
Epoch 7 [111/172] - loss: 0.0780
Epoch 7 [112/172] - loss: 0.0808
Epoch 7 [113/172] - loss: 0.0747
Epoch 7 [114/172] - loss: 0.0754
Epoch 7 [115/172] - loss: 0.0746
Epoch 7 [116/172] - loss: 0.1002
Epoch 7 [117/172] - loss: 0.0812
Epoch 7 [118/172] - loss: 0.0774
Epoch 7 [119/172] - loss: 0.1001
Epoch 7 [120/172] - loss: 0.0756, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0910
Epoch 7 [122/172] - loss: 0.0763
Epoch 7 [123/172] - loss: 0.0991
Epoch 7 [124/172] - loss: 0.1900
Epoch 7 [125/172] - loss: 0.0782
Epoch 7 [126/172] - loss: 0.0739
Epoch 7 [127/172] - loss: 0.0783
Epoch 7 [128/172] - loss: 0.1473
Epoch 7 [129/172] - loss: 0.0764
Epoch 7 [130/172] - loss: 0.0759, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1362
Epoch 7 [132/172] - loss: 0.1133
Epoch 7 [133/172] - loss: 0.0737
Epoch 7 [134/172] - loss: 0.0784
Epoch 7 [135/172] - loss: 0.0788
Epoch 7 [136/172] - loss: 0.0771
Epoch 7 [137/172] - loss: 0.0924
Epoch 7 [138/172] - loss: 0.0725
Epoch 7 [139/172] - loss: 0.1279
Epoch 7 [140/172] - loss: 0.0815, acc: 1.0000
Epoch 7 [141/172] - loss: 0.1052
Epoch 7 [142/172] - loss: 0.0758
Epoch 7 [143/172] - loss: 0.1008
Epoch 7 [144/172] - loss: 0.0793
Epoch 7 [145/172] - loss: 0.0964
Epoch 7 [146/172] - loss: 0.0890
Epoch 7 [147/172] - loss: 0.0814
Epoch 7 [148/172] - loss: 0.1072
Epoch 7 [149/172] - loss: 0.0754
Epoch 7 [150/172] - loss: 0.0815, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1201
Epoch 7 [152/172] - loss: 0.0741
Epoch 7 [153/172] - loss: 0.0731
Epoch 7 [154/172] - loss: 0.0941
Epoch 7 [155/172] - loss: 0.0749
Epoch 7 [156/172] - loss: 0.1417
Epoch 7 [157/172] - loss: 0.0791
Epoch 7 [158/172] - loss: 0.0765
Epoch 7 [159/172] - loss: 0.0741
Epoch 7 [160/172] - loss: 0.0755, acc: 1.0000
Epoch 7 [161/172] - loss: 0.0742
Epoch 7 [162/172] - loss: 0.0758
Epoch 7 [163/172] - loss: 0.0973
Epoch 7 [164/172] - loss: 0.0939
Epoch 7 [165/172] - loss: 0.1171
Epoch 7 [166/172] - loss: 0.0751
Epoch 7 [167/172] - loss: 0.0784
Epoch 7 [168/172] - loss: 0.0754

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1785, log_difficulty=0.1643, weight=1.8213
neutral: count=11731.0, difficulty=0.1378, log_difficulty=0.1291, weight=1.6455
negative: count=13173.0, difficulty=0.1767, log_difficulty=0.1628, weight=1.8138

当前batch的pt分布：
positive: min=0.9106, max=0.9961, mean=0.9741
neutral: min=0.9685, max=0.9998, mean=0.9870
negative: min=0.8871, max=0.9990, mean=0.9623

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0275
焦点损失: 0.0001
边界损失: 0.1477
总损失: 0.0740
Epoch 7 [169/172] - loss: 0.0740
Epoch 7 [170/172] - loss: 0.0872, acc: 1.0000
Epoch 7 [171/172] - loss: 0.0746
Epoch 7 [172/172] - loss: 0.0745

类别准确率:
positive: 0.8587 (401/467)
neutral: 0.2892 (24/83)
negative: 0.5960 (149/250)

Epoch 7/10
Train Loss: 0.0814, Train Acc: 0.9960
Val Loss: 0.8978, Val Acc: 0.7175
Epoch 8 [1/172] - loss: 0.0767, acc: 1.0000
Epoch 8 [2/172] - loss: 0.0897
Epoch 8 [3/172] - loss: 0.0737
Epoch 8 [4/172] - loss: 0.0724
Epoch 8 [5/172] - loss: 0.0739
Epoch 8 [6/172] - loss: 0.0917
Epoch 8 [7/172] - loss: 0.0754
Epoch 8 [8/172] - loss: 0.0742
Epoch 8 [9/172] - loss: 0.0824
Epoch 8 [10/172] - loss: 0.0985, acc: 0.9688
Epoch 8 [11/172] - loss: 0.0833
Epoch 8 [12/172] - loss: 0.0940
Epoch 8 [13/172] - loss: 0.0744
Epoch 8 [14/172] - loss: 0.0779
Epoch 8 [15/172] - loss: 0.0803
Epoch 8 [16/172] - loss: 0.0775
Epoch 8 [17/172] - loss: 0.0737
Epoch 8 [18/172] - loss: 0.0739
Epoch 8 [19/172] - loss: 0.0810
Epoch 8 [20/172] - loss: 0.0734, acc: 1.0000
Epoch 8 [21/172] - loss: 0.0808
Epoch 8 [22/172] - loss: 0.0945
Epoch 8 [23/172] - loss: 0.1162
Epoch 8 [24/172] - loss: 0.0797
Epoch 8 [25/172] - loss: 0.0793
Epoch 8 [26/172] - loss: 0.0794
Epoch 8 [27/172] - loss: 0.1071
Epoch 8 [28/172] - loss: 0.0786
Epoch 8 [29/172] - loss: 0.0753
Epoch 8 [30/172] - loss: 0.0714, acc: 1.0000
Epoch 8 [31/172] - loss: 0.0749
Epoch 8 [32/172] - loss: 0.0741
Epoch 8 [33/172] - loss: 0.0768
Epoch 8 [34/172] - loss: 0.0793
Epoch 8 [35/172] - loss: 0.0785
Epoch 8 [36/172] - loss: 0.0849
Epoch 8 [37/172] - loss: 0.0951
Epoch 8 [38/172] - loss: 0.0903
Epoch 8 [39/172] - loss: 0.0772
Epoch 8 [40/172] - loss: 0.0740, acc: 1.0000
Epoch 8 [41/172] - loss: 0.0763
Epoch 8 [42/172] - loss: 0.0904
Epoch 8 [43/172] - loss: 0.0768
Epoch 8 [44/172] - loss: 0.0743
Epoch 8 [45/172] - loss: 0.0750
Epoch 8 [46/172] - loss: 0.0774
Epoch 8 [47/172] - loss: 0.0734
Epoch 8 [48/172] - loss: 0.0932
Epoch 8 [49/172] - loss: 0.0911
Epoch 8 [50/172] - loss: 0.0756, acc: 1.0000
Epoch 8 [51/172] - loss: 0.0747
Epoch 8 [52/172] - loss: 0.0733
Epoch 8 [53/172] - loss: 0.1360
Epoch 8 [54/172] - loss: 0.0769
Epoch 8 [55/172] - loss: 0.0737
Epoch 8 [56/172] - loss: 0.0756
Epoch 8 [57/172] - loss: 0.0752
Epoch 8 [58/172] - loss: 0.0750
Epoch 8 [59/172] - loss: 0.0742
Epoch 8 [60/172] - loss: 0.0728, acc: 1.0000
Epoch 8 [61/172] - loss: 0.0764
Epoch 8 [62/172] - loss: 0.0752
Epoch 8 [63/172] - loss: 0.0727
Epoch 8 [64/172] - loss: 0.0753
Epoch 8 [65/172] - loss: 0.0726
Epoch 8 [66/172] - loss: 0.0965
Epoch 8 [67/172] - loss: 0.0777
Epoch 8 [68/172] - loss: 0.0719
Epoch 8 [69/172] - loss: 0.0749
Epoch 8 [70/172] - loss: 0.0741, acc: 1.0000
Epoch 8 [71/172] - loss: 0.0992
Epoch 8 [72/172] - loss: 0.0744
Epoch 8 [73/172] - loss: 0.0997
Epoch 8 [74/172] - loss: 0.0847
Epoch 8 [75/172] - loss: 0.0733
Epoch 8 [76/172] - loss: 0.0944
Epoch 8 [77/172] - loss: 0.0715
Epoch 8 [78/172] - loss: 0.1001
Epoch 8 [79/172] - loss: 0.0760
Epoch 8 [80/172] - loss: 0.1006, acc: 0.9688
Epoch 8 [81/172] - loss: 0.0992
Epoch 8 [82/172] - loss: 0.0731
Epoch 8 [83/172] - loss: 0.0737
Epoch 8 [84/172] - loss: 0.0741
Epoch 8 [85/172] - loss: 0.0740
Epoch 8 [86/172] - loss: 0.0753
Epoch 8 [87/172] - loss: 0.0948
Epoch 8 [88/172] - loss: 0.1145
Epoch 8 [89/172] - loss: 0.1464
Epoch 8 [90/172] - loss: 0.0770, acc: 1.0000
Epoch 8 [91/172] - loss: 0.1274
Epoch 8 [92/172] - loss: 0.0831
Epoch 8 [93/172] - loss: 0.0721
Epoch 8 [94/172] - loss: 0.0953
Epoch 8 [95/172] - loss: 0.0755
Epoch 8 [96/172] - loss: 0.0730

=== 第 1301 次迭代调试信息 ===
当前类别统计：
positive: count=14487.0, difficulty=0.1681, log_difficulty=0.1554, weight=1.7770
neutral: count=12738.0, difficulty=0.1298, log_difficulty=0.1220, weight=1.6101
negative: count=14288.0, difficulty=0.1662, log_difficulty=0.1537, weight=1.7686

当前batch的pt分布：
positive: min=0.8766, max=0.9973, mean=0.9748
neutral: min=0.3294, max=0.9914, mean=0.9035
negative: min=0.9873, max=0.9990, mean=0.9952

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9333
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0693
焦点损失: 0.0169
边界损失: 0.1586
总损失: 0.0929
Epoch 8 [97/172] - loss: 0.0929
Epoch 8 [98/172] - loss: 0.0896
Epoch 8 [99/172] - loss: 0.0877
Epoch 8 [100/172] - loss: 0.0774, acc: 1.0000
Epoch 8 [101/172] - loss: 0.0777
Epoch 8 [102/172] - loss: 0.0987
Epoch 8 [103/172] - loss: 0.1365
Epoch 8 [104/172] - loss: 0.0782
Epoch 8 [105/172] - loss: 0.0736
Epoch 8 [106/172] - loss: 0.0783
Epoch 8 [107/172] - loss: 0.0989
Epoch 8 [108/172] - loss: 0.0757
Epoch 8 [109/172] - loss: 0.1059
Epoch 8 [110/172] - loss: 0.0815, acc: 1.0000
Epoch 8 [111/172] - loss: 0.1466
Epoch 8 [112/172] - loss: 0.0976
Epoch 8 [113/172] - loss: 0.0761
Epoch 8 [114/172] - loss: 0.0750
Epoch 8 [115/172] - loss: 0.0731
Epoch 8 [116/172] - loss: 0.0728
Epoch 8 [117/172] - loss: 0.0735
Epoch 8 [118/172] - loss: 0.0755
Epoch 8 [119/172] - loss: 0.0730
Epoch 8 [120/172] - loss: 0.0776, acc: 1.0000
Epoch 8 [121/172] - loss: 0.0925
Epoch 8 [122/172] - loss: 0.0774
Epoch 8 [123/172] - loss: 0.0772
Epoch 8 [124/172] - loss: 0.0739
Epoch 8 [125/172] - loss: 0.0786
Epoch 8 [126/172] - loss: 0.0807
Epoch 8 [127/172] - loss: 0.0925
Epoch 8 [128/172] - loss: 0.0969
Epoch 8 [129/172] - loss: 0.0750
Epoch 8 [130/172] - loss: 0.0833, acc: 1.0000
Epoch 8 [131/172] - loss: 0.0758
Epoch 8 [132/172] - loss: 0.0740
Epoch 8 [133/172] - loss: 0.0810
Epoch 8 [134/172] - loss: 0.0760
Epoch 8 [135/172] - loss: 0.0739
Epoch 8 [136/172] - loss: 0.0816
Epoch 8 [137/172] - loss: 0.0760
Epoch 8 [138/172] - loss: 0.0924
Epoch 8 [139/172] - loss: 0.0758
Epoch 8 [140/172] - loss: 0.0726, acc: 1.0000
Epoch 8 [141/172] - loss: 0.0718
Epoch 8 [142/172] - loss: 0.0741
Epoch 8 [143/172] - loss: 0.0774
Epoch 8 [144/172] - loss: 0.0926
Epoch 8 [145/172] - loss: 0.0751
Epoch 8 [146/172] - loss: 0.0714
Epoch 8 [147/172] - loss: 0.0740
Epoch 8 [148/172] - loss: 0.0999
Epoch 8 [149/172] - loss: 0.0744
Epoch 8 [150/172] - loss: 0.0761, acc: 1.0000
Epoch 8 [151/172] - loss: 0.0816
Epoch 8 [152/172] - loss: 0.0901
Epoch 8 [153/172] - loss: 0.0767
Epoch 8 [154/172] - loss: 0.0895
Epoch 8 [155/172] - loss: 0.1191
Epoch 8 [156/172] - loss: 0.0761
Epoch 8 [157/172] - loss: 0.0758
Epoch 8 [158/172] - loss: 0.0758
Epoch 8 [159/172] - loss: 0.0858
Epoch 8 [160/172] - loss: 0.0764, acc: 1.0000
Epoch 8 [161/172] - loss: 0.0755
Epoch 8 [162/172] - loss: 0.0795
Epoch 8 [163/172] - loss: 0.0730
Epoch 8 [164/172] - loss: 0.0790
Epoch 8 [165/172] - loss: 0.0727
Epoch 8 [166/172] - loss: 0.0772
Epoch 8 [167/172] - loss: 0.0724
Epoch 8 [168/172] - loss: 0.0733
Epoch 8 [169/172] - loss: 0.0776
Epoch 8 [170/172] - loss: 0.0800, acc: 1.0000
Epoch 8 [171/172] - loss: 0.0752
Epoch 8 [172/172] - loss: 0.0766

类别准确率:
positive: 0.8544 (399/467)
neutral: 0.2289 (19/83)
negative: 0.6160 (154/250)

Epoch 8/10
Train Loss: 0.0766, Train Acc: 1.0000
Val Loss: 0.8965, Val Acc: 0.7150
Epoch 9 [1/172] - loss: 0.0874, acc: 1.0000
Epoch 9 [2/172] - loss: 0.0801
Epoch 9 [3/172] - loss: 0.0984
Epoch 9 [4/172] - loss: 0.0765
Epoch 9 [5/172] - loss: 0.0722
Epoch 9 [6/172] - loss: 0.0732
Epoch 9 [7/172] - loss: 0.0801
Epoch 9 [8/172] - loss: 0.0954
Epoch 9 [9/172] - loss: 0.0736
Epoch 9 [10/172] - loss: 0.0778, acc: 1.0000
Epoch 9 [11/172] - loss: 0.0722
Epoch 9 [12/172] - loss: 0.1169
Epoch 9 [13/172] - loss: 0.0735
Epoch 9 [14/172] - loss: 0.0809
Epoch 9 [15/172] - loss: 0.0829
Epoch 9 [16/172] - loss: 0.0815
Epoch 9 [17/172] - loss: 0.0754
Epoch 9 [18/172] - loss: 0.0725
Epoch 9 [19/172] - loss: 0.0976
Epoch 9 [20/172] - loss: 0.0729, acc: 1.0000
Epoch 9 [21/172] - loss: 0.0724
Epoch 9 [22/172] - loss: 0.0761
Epoch 9 [23/172] - loss: 0.0721
Epoch 9 [24/172] - loss: 0.0769

=== 第 1401 次迭代调试信息 ===
当前类别统计：
positive: count=15648.0, difficulty=0.1589, log_difficulty=0.1474, weight=1.7372
neutral: count=13691.0, difficulty=0.1229, log_difficulty=0.1159, weight=1.5794
negative: count=15357.0, difficulty=0.1571, log_difficulty=0.1459, weight=1.7295

当前batch的pt分布：
positive: min=0.9265, max=0.9989, mean=0.9743
neutral: min=0.9415, max=0.9971, mean=0.9779
negative: min=0.8482, max=0.9957, mean=0.9666

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0281
焦点损失: 0.0002
边界损失: 0.1483
总损失: 0.0743
Epoch 9 [25/172] - loss: 0.0743
Epoch 9 [26/172] - loss: 0.0741
Epoch 9 [27/172] - loss: 0.0760
Epoch 9 [28/172] - loss: 0.0875
Epoch 9 [29/172] - loss: 0.0747
Epoch 9 [30/172] - loss: 0.0836, acc: 0.9688
Epoch 9 [31/172] - loss: 0.0786
Epoch 9 [32/172] - loss: 0.0744
Epoch 9 [33/172] - loss: 0.0979
Epoch 9 [34/172] - loss: 0.0779
Epoch 9 [35/172] - loss: 0.0732
Epoch 9 [36/172] - loss: 0.0736
Epoch 9 [37/172] - loss: 0.1060
Epoch 9 [38/172] - loss: 0.1599
Epoch 9 [39/172] - loss: 0.0734
Epoch 9 [40/172] - loss: 0.0721, acc: 1.0000
Epoch 9 [41/172] - loss: 0.0728
Epoch 9 [42/172] - loss: 0.0728
Epoch 9 [43/172] - loss: 0.0757
Epoch 9 [44/172] - loss: 0.0741
Epoch 9 [45/172] - loss: 0.0765
Epoch 9 [46/172] - loss: 0.0803
Epoch 9 [47/172] - loss: 0.0729
Epoch 9 [48/172] - loss: 0.0786
Epoch 9 [49/172] - loss: 0.1127
Epoch 9 [50/172] - loss: 0.0719, acc: 1.0000
Epoch 9 [51/172] - loss: 0.0753
Epoch 9 [52/172] - loss: 0.0769
Epoch 9 [53/172] - loss: 0.0769
Epoch 9 [54/172] - loss: 0.0800
Epoch 9 [55/172] - loss: 0.0935
Epoch 9 [56/172] - loss: 0.0712
Epoch 9 [57/172] - loss: 0.0717
Epoch 9 [58/172] - loss: 0.0790
Epoch 9 [59/172] - loss: 0.0832
Epoch 9 [60/172] - loss: 0.0740, acc: 1.0000
Epoch 9 [61/172] - loss: 0.0846
Epoch 9 [62/172] - loss: 0.0727
Epoch 9 [63/172] - loss: 0.1343
Epoch 9 [64/172] - loss: 0.0752
Epoch 9 [65/172] - loss: 0.0737
Epoch 9 [66/172] - loss: 0.0924
Epoch 9 [67/172] - loss: 0.0896
Epoch 9 [68/172] - loss: 0.0719
Epoch 9 [69/172] - loss: 0.0721
Epoch 9 [70/172] - loss: 0.0804, acc: 1.0000
Epoch 9 [71/172] - loss: 0.0770
Epoch 9 [72/172] - loss: 0.0889
Epoch 9 [73/172] - loss: 0.0722
Epoch 9 [74/172] - loss: 0.0734
Epoch 9 [75/172] - loss: 0.0723
Epoch 9 [76/172] - loss: 0.0725
Epoch 9 [77/172] - loss: 0.0730
Epoch 9 [78/172] - loss: 0.0850
Epoch 9 [79/172] - loss: 0.0986
Epoch 9 [80/172] - loss: 0.0818, acc: 0.9688
Epoch 9 [81/172] - loss: 0.0780
Epoch 9 [82/172] - loss: 0.1588
Epoch 9 [83/172] - loss: 0.0736
Epoch 9 [84/172] - loss: 0.0765
Epoch 9 [85/172] - loss: 0.0880
Epoch 9 [86/172] - loss: 0.0784
Epoch 9 [87/172] - loss: 0.0899
Epoch 9 [88/172] - loss: 0.0727
Epoch 9 [89/172] - loss: 0.0982
Epoch 9 [90/172] - loss: 0.0708, acc: 1.0000
Epoch 9 [91/172] - loss: 0.0833
Epoch 9 [92/172] - loss: 0.0760
Epoch 9 [93/172] - loss: 0.0783
Epoch 9 [94/172] - loss: 0.0704
Epoch 9 [95/172] - loss: 0.0743
Epoch 9 [96/172] - loss: 0.0778
Epoch 9 [97/172] - loss: 0.0715
Epoch 9 [98/172] - loss: 0.1007
Epoch 9 [99/172] - loss: 0.0762
Epoch 9 [100/172] - loss: 0.0729, acc: 1.0000
Epoch 9 [101/172] - loss: 0.0735
Epoch 9 [102/172] - loss: 0.0747
Epoch 9 [103/172] - loss: 0.0765
Epoch 9 [104/172] - loss: 0.0828
Epoch 9 [105/172] - loss: 0.1491
Epoch 9 [106/172] - loss: 0.0743
Epoch 9 [107/172] - loss: 0.0801
Epoch 9 [108/172] - loss: 0.0799
Epoch 9 [109/172] - loss: 0.1157
Epoch 9 [110/172] - loss: 0.0739, acc: 1.0000
Epoch 9 [111/172] - loss: 0.0750
Epoch 9 [112/172] - loss: 0.0727
Epoch 9 [113/172] - loss: 0.0726
Epoch 9 [114/172] - loss: 0.0726
Epoch 9 [115/172] - loss: 0.0771
Epoch 9 [116/172] - loss: 0.0732
Epoch 9 [117/172] - loss: 0.0749
Epoch 9 [118/172] - loss: 0.1351
Epoch 9 [119/172] - loss: 0.0762
Epoch 9 [120/172] - loss: 0.0781, acc: 1.0000
Epoch 9 [121/172] - loss: 0.0858
Epoch 9 [122/172] - loss: 0.1277
Epoch 9 [123/172] - loss: 0.0717
Epoch 9 [124/172] - loss: 0.0786

=== 第 1501 次迭代调试信息 ===
当前类别统计：
positive: count=16764.0, difficulty=0.1506, log_difficulty=0.1403, weight=1.7014
neutral: count=14673.0, difficulty=0.1167, log_difficulty=0.1104, weight=1.5519
negative: count=16459.0, difficulty=0.1491, log_difficulty=0.1390, weight=1.6951

当前batch的pt分布：
positive: min=0.4839, max=0.9919, mean=0.9048
neutral: min=0.9509, max=0.9987, mean=0.9836
negative: min=0.9951, max=0.9993, mean=0.9969

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0629
焦点损失: 0.0080
边界损失: 0.1639
总损失: 0.0887
Epoch 9 [125/172] - loss: 0.0887
Epoch 9 [126/172] - loss: 0.0764
Epoch 9 [127/172] - loss: 0.0716
Epoch 9 [128/172] - loss: 0.0766
Epoch 9 [129/172] - loss: 0.0857
Epoch 9 [130/172] - loss: 0.0875, acc: 0.9688
Epoch 9 [131/172] - loss: 0.0748
Epoch 9 [132/172] - loss: 0.0898
Epoch 9 [133/172] - loss: 0.1232
Epoch 9 [134/172] - loss: 0.0765
Epoch 9 [135/172] - loss: 0.0757
Epoch 9 [136/172] - loss: 0.0768
Epoch 9 [137/172] - loss: 0.0782
Epoch 9 [138/172] - loss: 0.0763
Epoch 9 [139/172] - loss: 0.0992
Epoch 9 [140/172] - loss: 0.0773, acc: 1.0000
Epoch 9 [141/172] - loss: 0.0725
Epoch 9 [142/172] - loss: 0.0738
Epoch 9 [143/172] - loss: 0.1050
Epoch 9 [144/172] - loss: 0.0749
Epoch 9 [145/172] - loss: 0.0831
Epoch 9 [146/172] - loss: 0.0840
Epoch 9 [147/172] - loss: 0.1101
Epoch 9 [148/172] - loss: 0.0721
Epoch 9 [149/172] - loss: 0.0749
Epoch 9 [150/172] - loss: 0.0730, acc: 1.0000
Epoch 9 [151/172] - loss: 0.0753
Epoch 9 [152/172] - loss: 0.0760
Epoch 9 [153/172] - loss: 0.0922
Epoch 9 [154/172] - loss: 0.0810
Epoch 9 [155/172] - loss: 0.0759
Epoch 9 [156/172] - loss: 0.1296
Epoch 9 [157/172] - loss: 0.0719
Epoch 9 [158/172] - loss: 0.0763
Epoch 9 [159/172] - loss: 0.0723
Epoch 9 [160/172] - loss: 0.0731, acc: 1.0000
Epoch 9 [161/172] - loss: 0.0737
Epoch 9 [162/172] - loss: 0.0854
Epoch 9 [163/172] - loss: 0.0744
Epoch 9 [164/172] - loss: 0.0720
Epoch 9 [165/172] - loss: 0.0726
Epoch 9 [166/172] - loss: 0.0738
Epoch 9 [167/172] - loss: 0.0787
Epoch 9 [168/172] - loss: 0.0764
Epoch 9 [169/172] - loss: 0.0809
Epoch 9 [170/172] - loss: 0.0768, acc: 1.0000
Epoch 9 [171/172] - loss: 0.0839
Epoch 9 [172/172] - loss: 0.0732

类别准确率:
positive: 0.8373 (391/467)
neutral: 0.2651 (22/83)
negative: 0.6080 (152/250)

Epoch 9/10
Train Loss: 0.0760, Train Acc: 0.9980
Val Loss: 0.9032, Val Acc: 0.7063
Epoch 10 [1/172] - loss: 0.0865, acc: 1.0000
Epoch 10 [2/172] - loss: 0.1206
Epoch 10 [3/172] - loss: 0.0720
Epoch 10 [4/172] - loss: 0.1060
Epoch 10 [5/172] - loss: 0.0898
Epoch 10 [6/172] - loss: 0.0841
Epoch 10 [7/172] - loss: 0.0732
Epoch 10 [8/172] - loss: 0.0744
Epoch 10 [9/172] - loss: 0.0740
Epoch 10 [10/172] - loss: 0.0878, acc: 1.0000
Epoch 10 [11/172] - loss: 0.0736
Epoch 10 [12/172] - loss: 0.0744
Epoch 10 [13/172] - loss: 0.0967
Epoch 10 [14/172] - loss: 0.0969
Epoch 10 [15/172] - loss: 0.0717
Epoch 10 [16/172] - loss: 0.0850
Epoch 10 [17/172] - loss: 0.0719
Epoch 10 [18/172] - loss: 0.0753
Epoch 10 [19/172] - loss: 0.0756
Epoch 10 [20/172] - loss: 0.0771, acc: 1.0000
Epoch 10 [21/172] - loss: 0.0801
Epoch 10 [22/172] - loss: 0.0754
Epoch 10 [23/172] - loss: 0.0759
Epoch 10 [24/172] - loss: 0.1080
Epoch 10 [25/172] - loss: 0.0730
Epoch 10 [26/172] - loss: 0.0723
Epoch 10 [27/172] - loss: 0.0714
Epoch 10 [28/172] - loss: 0.0721
Epoch 10 [29/172] - loss: 0.0766
Epoch 10 [30/172] - loss: 0.0719, acc: 1.0000
Epoch 10 [31/172] - loss: 0.0824
Epoch 10 [32/172] - loss: 0.0780
Epoch 10 [33/172] - loss: 0.0717
Epoch 10 [34/172] - loss: 0.0726
Epoch 10 [35/172] - loss: 0.0806
Epoch 10 [36/172] - loss: 0.1915
Epoch 10 [37/172] - loss: 0.0869
Epoch 10 [38/172] - loss: 0.0809
Epoch 10 [39/172] - loss: 0.0776
Epoch 10 [40/172] - loss: 0.0762, acc: 1.0000
Epoch 10 [41/172] - loss: 0.0734
Epoch 10 [42/172] - loss: 0.0749
Epoch 10 [43/172] - loss: 0.0725
Epoch 10 [44/172] - loss: 0.0843
Epoch 10 [45/172] - loss: 0.0728
Epoch 10 [46/172] - loss: 0.0729
Epoch 10 [47/172] - loss: 0.0728
Epoch 10 [48/172] - loss: 0.0793
Epoch 10 [49/172] - loss: 0.0718
Epoch 10 [50/172] - loss: 0.0719, acc: 1.0000
Epoch 10 [51/172] - loss: 0.0772
Epoch 10 [52/172] - loss: 0.0811

=== 第 1601 次迭代调试信息 ===
当前类别统计：
positive: count=17907.0, difficulty=0.1432, log_difficulty=0.1339, weight=1.6693
neutral: count=15634.0, difficulty=0.1113, log_difficulty=0.1055, weight=1.5275
negative: count=17538.0, difficulty=0.1423, log_difficulty=0.1331, weight=1.6654

当前batch的pt分布：
positive: min=0.9699, max=0.9989, mean=0.9863
neutral: min=0.4893, max=0.9974, mean=0.9394
negative: min=0.9660, max=0.9975, mean=0.9829

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0375
焦点损失: 0.0066
边界损失: 0.1501
总损失: 0.0801
Epoch 10 [53/172] - loss: 0.0801
Epoch 10 [54/172] - loss: 0.0749
Epoch 10 [55/172] - loss: 0.0772
Epoch 10 [56/172] - loss: 0.0720
Epoch 10 [57/172] - loss: 0.0727
Epoch 10 [58/172] - loss: 0.0835
Epoch 10 [59/172] - loss: 0.0708
Epoch 10 [60/172] - loss: 0.0735, acc: 1.0000
Epoch 10 [61/172] - loss: 0.0756
Epoch 10 [62/172] - loss: 0.0917
Epoch 10 [63/172] - loss: 0.0885
Epoch 10 [64/172] - loss: 0.0727
Epoch 10 [65/172] - loss: 0.1103
Epoch 10 [66/172] - loss: 0.0834
Epoch 10 [67/172] - loss: 0.0741
Epoch 10 [68/172] - loss: 0.0756
Epoch 10 [69/172] - loss: 0.0728
Epoch 10 [70/172] - loss: 0.0756, acc: 1.0000
Epoch 10 [71/172] - loss: 0.0776
Epoch 10 [72/172] - loss: 0.0746
Epoch 10 [73/172] - loss: 0.0754
Epoch 10 [74/172] - loss: 0.0779
Epoch 10 [75/172] - loss: 0.0746
Epoch 10 [76/172] - loss: 0.0720
Epoch 10 [77/172] - loss: 0.0727
Epoch 10 [78/172] - loss: 0.0769
Epoch 10 [79/172] - loss: 0.0751
Epoch 10 [80/172] - loss: 0.0737, acc: 1.0000
Epoch 10 [81/172] - loss: 0.0739
Epoch 10 [82/172] - loss: 0.0747
Epoch 10 [83/172] - loss: 0.1018
Epoch 10 [84/172] - loss: 0.0737
Epoch 10 [85/172] - loss: 0.0722
Epoch 10 [86/172] - loss: 0.0754
Epoch 10 [87/172] - loss: 0.0738
Epoch 10 [88/172] - loss: 0.0755
Epoch 10 [89/172] - loss: 0.0723
Epoch 10 [90/172] - loss: 0.1035, acc: 0.9688
Epoch 10 [91/172] - loss: 0.0737
Epoch 10 [92/172] - loss: 0.0721
Epoch 10 [93/172] - loss: 0.0740
Epoch 10 [94/172] - loss: 0.0765
Epoch 10 [95/172] - loss: 0.0780
Epoch 10 [96/172] - loss: 0.0768
Epoch 10 [97/172] - loss: 0.0805
Epoch 10 [98/172] - loss: 0.0764
Epoch 10 [99/172] - loss: 0.0716
Epoch 10 [100/172] - loss: 0.0728, acc: 1.0000
Epoch 10 [101/172] - loss: 0.0743
Epoch 10 [102/172] - loss: 0.0718
Epoch 10 [103/172] - loss: 0.0730
Epoch 10 [104/172] - loss: 0.0959
Epoch 10 [105/172] - loss: 0.0716
Epoch 10 [106/172] - loss: 0.1030
Epoch 10 [107/172] - loss: 0.0720
Epoch 10 [108/172] - loss: 0.0750
Epoch 10 [109/172] - loss: 0.0722
Epoch 10 [110/172] - loss: 0.0879, acc: 1.0000
Epoch 10 [111/172] - loss: 0.0835
Epoch 10 [112/172] - loss: 0.0729
Epoch 10 [113/172] - loss: 0.0789
Epoch 10 [114/172] - loss: 0.0760
Epoch 10 [115/172] - loss: 0.0776
Epoch 10 [116/172] - loss: 0.0750
Epoch 10 [117/172] - loss: 0.0732
Epoch 10 [118/172] - loss: 0.0722
Epoch 10 [119/172] - loss: 0.0737
Epoch 10 [120/172] - loss: 0.1267, acc: 0.9688
Epoch 10 [121/172] - loss: 0.0830
Epoch 10 [122/172] - loss: 0.0763
Epoch 10 [123/172] - loss: 0.0788
Epoch 10 [124/172] - loss: 0.0732
Epoch 10 [125/172] - loss: 0.0719
Epoch 10 [126/172] - loss: 0.0744
Epoch 10 [127/172] - loss: 0.0748
Epoch 10 [128/172] - loss: 0.0973
Epoch 10 [129/172] - loss: 0.0712
Epoch 10 [130/172] - loss: 0.0897, acc: 1.0000
Epoch 10 [131/172] - loss: 0.0729
Epoch 10 [132/172] - loss: 0.0937
Epoch 10 [133/172] - loss: 0.0776
Epoch 10 [134/172] - loss: 0.0806
Epoch 10 [135/172] - loss: 0.0780
Epoch 10 [136/172] - loss: 0.0728
Epoch 10 [137/172] - loss: 0.0755
Epoch 10 [138/172] - loss: 0.0732
Epoch 10 [139/172] - loss: 0.0736
Epoch 10 [140/172] - loss: 0.0724, acc: 1.0000
Epoch 10 [141/172] - loss: 0.0771
Epoch 10 [142/172] - loss: 0.0745
Epoch 10 [143/172] - loss: 0.0738
Epoch 10 [144/172] - loss: 0.1046
Epoch 10 [145/172] - loss: 0.0746
Epoch 10 [146/172] - loss: 0.0716
Epoch 10 [147/172] - loss: 0.0735
Epoch 10 [148/172] - loss: 0.0987
Epoch 10 [149/172] - loss: 0.0842
Epoch 10 [150/172] - loss: 0.0722, acc: 1.0000
Epoch 10 [151/172] - loss: 0.0759
Epoch 10 [152/172] - loss: 0.0725

=== 第 1701 次迭代调试信息 ===
当前类别统计：
positive: count=19021.0, difficulty=0.1367, log_difficulty=0.1281, weight=1.6407
neutral: count=16607.0, difficulty=0.1063, log_difficulty=0.1010, weight=1.5051
negative: count=18651.0, difficulty=0.1359, log_difficulty=0.1274, weight=1.6372

当前batch的pt分布：
positive: min=0.9312, max=0.9951, mean=0.9798
neutral: min=0.8965, max=0.9987, mean=0.9819
negative: min=0.9653, max=0.9934, mean=0.9852

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0183
焦点损失: 0.0001
边界损失: 0.1438
总损失: 0.0719
Epoch 10 [153/172] - loss: 0.0719
Epoch 10 [154/172] - loss: 0.0920
Epoch 10 [155/172] - loss: 0.0741
Epoch 10 [156/172] - loss: 0.0729
Epoch 10 [157/172] - loss: 0.0797
Epoch 10 [158/172] - loss: 0.0736
Epoch 10 [159/172] - loss: 0.0747
Epoch 10 [160/172] - loss: 0.0751, acc: 1.0000
Epoch 10 [161/172] - loss: 0.0729
Epoch 10 [162/172] - loss: 0.0727
Epoch 10 [163/172] - loss: 0.0819
Epoch 10 [164/172] - loss: 0.0734
Epoch 10 [165/172] - loss: 0.0759
Epoch 10 [166/172] - loss: 0.0729
Epoch 10 [167/172] - loss: 0.0742
Epoch 10 [168/172] - loss: 0.0711
Epoch 10 [169/172] - loss: 0.0716
Epoch 10 [170/172] - loss: 0.0731, acc: 1.0000
Epoch 10 [171/172] - loss: 0.0748
Epoch 10 [172/172] - loss: 0.0790

类别准确率:
positive: 0.8480 (396/467)
neutral: 0.2530 (21/83)
negative: 0.6000 (150/250)

Epoch 10/10
Train Loss: 0.0748, Train Acc: 1.0000
Val Loss: 0.9548, Val Acc: 0.7087
Early stopping triggered!
Best validation accuracy: 0.7175

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_074728-va3z3ysl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.35_Multimodal_iterations_20250118_074727
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/va3z3ysl
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███
wandb:  train_acc ▁▃▅▅▆▇▇▇▇█▇█▇██▇████████████████████████
wandb: train_loss ██▃▃▃▃▂▂▂▂▃▂▂▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1718
wandb:  train_acc 1
wandb: train_loss 0.0731
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.35_Multimodal_iterations_20250118_074727 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/va3z3ysl
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_074728-va3z3ysl/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_080229-e5fzb2g9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.35_Multimodal_epochs_20250118_080229
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/e5fzb2g9
wandb: uploading history steps 0-0, summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▃▄▅▆▆▇█
wandb:  train_acc ▁▄▇▇▇▇████
wandb: train_loss █▅▂▂▂▂▁▁▁▁
wandb:    val_acc ▃▄▇▇▁▂█▇▆▆
wandb:   val_loss ▁▂▁▄▆▆▆▆▇█
wandb: 
wandb: Run summary:
wandb:      epoch 10
wandb:  train_acc 1
wandb: train_loss 0.07479
wandb:    val_acc 0.70875
wandb:   val_loss 0.95478
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.35_Multimodal_epochs_20250118_080229 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/e5fzb2g9
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_080229-e5fzb2g9/logs

