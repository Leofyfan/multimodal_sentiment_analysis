=== 命令 ===
python main.py --loss_type focal --alpha 0.75 --beta 0.25 --neural_init_weight 1.5 --dropout 0.2 --name loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.2 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.2
text_dim: 128
image_dim: 256
dropout: 0.2
loss_type: focal
alpha: 0.75
beta: 0.25
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6662, log_difficulty=0.5105, weight=3.5527
neutral: count=7.0, difficulty=0.6723, log_difficulty=0.5142, weight=3.5709
negative: count=13.0, difficulty=0.6215, log_difficulty=0.4834, weight=3.4169

当前batch的pt分布：
positive: min=0.1969, max=0.4174, mean=0.3338
neutral: min=0.1967, max=0.3981, mean=0.3277
negative: min=0.1821, max=0.8493, mean=0.3785

当前batch准确率：
整体准确率: 0.4062
positive 准确率: 0.4167
neutral 准确率: 0.2857
negative 准确率: 0.4615

损失分量：
基础交叉熵: 1.0875
焦点损失: 0.3482
边界损失: 0.8495
总损失: 1.1274
Epoch 1 [1/172] - loss: 1.1274, acc: 0.4062
Epoch 1 [2/172] - loss: 1.2139
Epoch 1 [3/172] - loss: 1.2746
Epoch 1 [4/172] - loss: 1.1375
Epoch 1 [5/172] - loss: 1.1800
Epoch 1 [6/172] - loss: 1.4881
Epoch 1 [7/172] - loss: 1.2713
Epoch 1 [8/172] - loss: 1.4673
Epoch 1 [9/172] - loss: 1.2545
Epoch 1 [10/172] - loss: 1.2520, acc: 0.4062
Epoch 1 [11/172] - loss: 1.0932
Epoch 1 [12/172] - loss: 1.2199
Epoch 1 [13/172] - loss: 0.9360
Epoch 1 [14/172] - loss: 1.2231
Epoch 1 [15/172] - loss: 1.0776
Epoch 1 [16/172] - loss: 0.9554
Epoch 1 [17/172] - loss: 1.0719
Epoch 1 [18/172] - loss: 1.0762
Epoch 1 [19/172] - loss: 1.1634
Epoch 1 [20/172] - loss: 1.0784, acc: 0.4062
Epoch 1 [21/172] - loss: 0.9711
Epoch 1 [22/172] - loss: 1.0701
Epoch 1 [23/172] - loss: 0.9218
Epoch 1 [24/172] - loss: 1.1654
Epoch 1 [25/172] - loss: 0.9152
Epoch 1 [26/172] - loss: 0.8410
Epoch 1 [27/172] - loss: 1.1656
Epoch 1 [28/172] - loss: 0.8431
Epoch 1 [29/172] - loss: 0.8890
Epoch 1 [30/172] - loss: 1.0032, acc: 0.4688
Epoch 1 [31/172] - loss: 1.0690
Epoch 1 [32/172] - loss: 0.8503
Epoch 1 [33/172] - loss: 0.8943
Epoch 1 [34/172] - loss: 0.9642
Epoch 1 [35/172] - loss: 1.2646
Epoch 1 [36/172] - loss: 0.6185
Epoch 1 [37/172] - loss: 0.7467
Epoch 1 [38/172] - loss: 1.1448
Epoch 1 [39/172] - loss: 0.8802
Epoch 1 [40/172] - loss: 0.7269, acc: 0.7188
Epoch 1 [41/172] - loss: 0.6904
Epoch 1 [42/172] - loss: 0.6477
Epoch 1 [43/172] - loss: 0.8719
Epoch 1 [44/172] - loss: 1.1125
Epoch 1 [45/172] - loss: 0.8376
Epoch 1 [46/172] - loss: 0.6649
Epoch 1 [47/172] - loss: 0.8150
Epoch 1 [48/172] - loss: 1.0621
Epoch 1 [49/172] - loss: 1.0771
Epoch 1 [50/172] - loss: 0.7098, acc: 0.7188
Epoch 1 [51/172] - loss: 1.0496
Epoch 1 [52/172] - loss: 1.0700
Epoch 1 [53/172] - loss: 0.9475
Epoch 1 [54/172] - loss: 1.0192
Epoch 1 [55/172] - loss: 0.7349
Epoch 1 [56/172] - loss: 0.7050
Epoch 1 [57/172] - loss: 1.0075
Epoch 1 [58/172] - loss: 0.7848
Epoch 1 [59/172] - loss: 0.9661
Epoch 1 [60/172] - loss: 0.6584, acc: 0.7500
Epoch 1 [61/172] - loss: 1.0018
Epoch 1 [62/172] - loss: 0.7915
Epoch 1 [63/172] - loss: 0.7039
Epoch 1 [64/172] - loss: 0.7575
Epoch 1 [65/172] - loss: 0.8809
Epoch 1 [66/172] - loss: 0.7044
Epoch 1 [67/172] - loss: 0.7446
Epoch 1 [68/172] - loss: 1.1064
Epoch 1 [69/172] - loss: 0.8035
Epoch 1 [70/172] - loss: 0.7696, acc: 0.5938
Epoch 1 [71/172] - loss: 0.6478
Epoch 1 [72/172] - loss: 0.6588
Epoch 1 [73/172] - loss: 0.6906
Epoch 1 [74/172] - loss: 0.7355
Epoch 1 [75/172] - loss: 0.3892
Epoch 1 [76/172] - loss: 0.5674
Epoch 1 [77/172] - loss: 0.6017
Epoch 1 [78/172] - loss: 0.7941
Epoch 1 [79/172] - loss: 0.5700
Epoch 1 [80/172] - loss: 0.4087, acc: 0.8125
Epoch 1 [81/172] - loss: 0.7053
Epoch 1 [82/172] - loss: 0.9491
Epoch 1 [83/172] - loss: 0.8443
Epoch 1 [84/172] - loss: 0.6058
Epoch 1 [85/172] - loss: 0.6702
Epoch 1 [86/172] - loss: 0.8248
Epoch 1 [87/172] - loss: 0.6785
Epoch 1 [88/172] - loss: 0.8842
Epoch 1 [89/172] - loss: 0.9207
Epoch 1 [90/172] - loss: 0.6555, acc: 0.6562
Epoch 1 [91/172] - loss: 0.7701
Epoch 1 [92/172] - loss: 0.4931
Epoch 1 [93/172] - loss: 0.7599
Epoch 1 [94/172] - loss: 0.5763
Epoch 1 [95/172] - loss: 0.6199
Epoch 1 [96/172] - loss: 0.6196
Epoch 1 [97/172] - loss: 0.6234
Epoch 1 [98/172] - loss: 0.7454
Epoch 1 [99/172] - loss: 1.0579
Epoch 1 [100/172] - loss: 0.7838, acc: 0.5938

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5622, log_difficulty=0.4461, weight=3.2303
neutral: count=983.0, difficulty=0.5612, log_difficulty=0.4455, weight=3.2273
negative: count=1119.0, difficulty=0.5609, log_difficulty=0.4452, weight=3.2262

当前batch的pt分布：
positive: min=0.2267, max=0.8053, mean=0.4585
neutral: min=0.5562, max=0.9338, mean=0.7492
negative: min=0.1197, max=0.5960, mean=0.3873

当前batch准确率：
整体准确率: 0.5938
positive 准确率: 0.5000
neutral 准确率: 1.0000
negative 准确率: 0.5625

损失分量：
基础交叉熵: 0.8714
焦点损失: 0.2744
边界损失: 0.5741
总损失: 0.8078
Epoch 1 [101/172] - loss: 0.8078
Epoch 1 [102/172] - loss: 0.7907
Epoch 1 [103/172] - loss: 0.9802
Epoch 1 [104/172] - loss: 0.5214
Epoch 1 [105/172] - loss: 0.8514
Epoch 1 [106/172] - loss: 0.8194
Epoch 1 [107/172] - loss: 0.5944
Epoch 1 [108/172] - loss: 0.7651
Epoch 1 [109/172] - loss: 0.5430
Epoch 1 [110/172] - loss: 0.7320, acc: 0.6875
Epoch 1 [111/172] - loss: 0.7695
Epoch 1 [112/172] - loss: 0.7851
Epoch 1 [113/172] - loss: 0.3883
Epoch 1 [114/172] - loss: 0.5423
Epoch 1 [115/172] - loss: 0.6876
Epoch 1 [116/172] - loss: 0.6560
Epoch 1 [117/172] - loss: 0.6700
Epoch 1 [118/172] - loss: 0.5916
Epoch 1 [119/172] - loss: 0.6821
Epoch 1 [120/172] - loss: 0.4237, acc: 0.8750
Epoch 1 [121/172] - loss: 0.3969
Epoch 1 [122/172] - loss: 0.6356
Epoch 1 [123/172] - loss: 0.3839
Epoch 1 [124/172] - loss: 0.6425
Epoch 1 [125/172] - loss: 0.4243
Epoch 1 [126/172] - loss: 0.9384
Epoch 1 [127/172] - loss: 0.5898
Epoch 1 [128/172] - loss: 0.4426
Epoch 1 [129/172] - loss: 0.6445
Epoch 1 [130/172] - loss: 0.4469, acc: 0.7812
Epoch 1 [131/172] - loss: 0.2629
Epoch 1 [132/172] - loss: 0.4641
Epoch 1 [133/172] - loss: 0.7097
Epoch 1 [134/172] - loss: 0.4440
Epoch 1 [135/172] - loss: 0.5985
Epoch 1 [136/172] - loss: 0.4169
Epoch 1 [137/172] - loss: 0.5287
Epoch 1 [138/172] - loss: 0.3982
Epoch 1 [139/172] - loss: 0.5223
Epoch 1 [140/172] - loss: 0.3560, acc: 0.9062
Epoch 1 [141/172] - loss: 0.4557
Epoch 1 [142/172] - loss: 0.4913
Epoch 1 [143/172] - loss: 0.5468
Epoch 1 [144/172] - loss: 0.4194
Epoch 1 [145/172] - loss: 0.4187
Epoch 1 [146/172] - loss: 0.6570
Epoch 1 [147/172] - loss: 0.9556
Epoch 1 [148/172] - loss: 0.5484
Epoch 1 [149/172] - loss: 0.3332
Epoch 1 [150/172] - loss: 0.4998, acc: 0.7500
Epoch 1 [151/172] - loss: 0.6826
Epoch 1 [152/172] - loss: 0.4670
Epoch 1 [153/172] - loss: 0.4823
Epoch 1 [154/172] - loss: 0.5061
Epoch 1 [155/172] - loss: 0.6954
Epoch 1 [156/172] - loss: 1.1148
Epoch 1 [157/172] - loss: 0.6248
Epoch 1 [158/172] - loss: 0.4057
Epoch 1 [159/172] - loss: 0.8552
Epoch 1 [160/172] - loss: 0.5452, acc: 0.7500
Epoch 1 [161/172] - loss: 0.5795
Epoch 1 [162/172] - loss: 0.3723
Epoch 1 [163/172] - loss: 0.5625
Epoch 1 [164/172] - loss: 0.5934
Epoch 1 [165/172] - loss: 0.4061
Epoch 1 [166/172] - loss: 0.4367
Epoch 1 [167/172] - loss: 0.3365
Epoch 1 [168/172] - loss: 0.3898
Epoch 1 [169/172] - loss: 0.4396
Epoch 1 [170/172] - loss: 0.3674, acc: 0.8438
Epoch 1 [171/172] - loss: 0.5986
Epoch 1 [172/172] - loss: 0.5504

类别准确率:
positive: 0.7002 (327/467)
neutral: 0.7108 (59/83)
negative: 0.5160 (129/250)

Epoch 1/10
Train Loss: 0.5040, Train Acc: 0.7657
Val Loss: 0.7893, Val Acc: 0.6438
Epoch 2 [1/172] - loss: 0.5504, acc: 0.7500
Epoch 2 [2/172] - loss: 0.5228
Epoch 2 [3/172] - loss: 0.2557
Epoch 2 [4/172] - loss: 0.5197
Epoch 2 [5/172] - loss: 0.6404
Epoch 2 [6/172] - loss: 0.4943
Epoch 2 [7/172] - loss: 0.4072
Epoch 2 [8/172] - loss: 0.4846
Epoch 2 [9/172] - loss: 0.2192
Epoch 2 [10/172] - loss: 0.4826, acc: 0.7812
Epoch 2 [11/172] - loss: 0.3397
Epoch 2 [12/172] - loss: 0.3777
Epoch 2 [13/172] - loss: 0.4306
Epoch 2 [14/172] - loss: 0.4114
Epoch 2 [15/172] - loss: 0.4696
Epoch 2 [16/172] - loss: 0.3190
Epoch 2 [17/172] - loss: 0.4988
Epoch 2 [18/172] - loss: 0.3981
Epoch 2 [19/172] - loss: 0.2651
Epoch 2 [20/172] - loss: 0.2618, acc: 0.8750
Epoch 2 [21/172] - loss: 0.3453
Epoch 2 [22/172] - loss: 0.3093
Epoch 2 [23/172] - loss: 0.1535
Epoch 2 [24/172] - loss: 0.6329
Epoch 2 [25/172] - loss: 0.3620
Epoch 2 [26/172] - loss: 0.2040
Epoch 2 [27/172] - loss: 0.4229
Epoch 2 [28/172] - loss: 0.2122

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5100, log_difficulty=0.4121, weight=3.0607
neutral: count=1952.0, difficulty=0.4599, log_difficulty=0.3784, weight=2.8919
negative: count=2216.0, difficulty=0.5048, log_difficulty=0.4087, weight=3.0434

当前batch的pt分布：
positive: min=0.4775, max=0.8793, mean=0.6865
neutral: min=0.5108, max=0.9546, mean=0.7294
negative: min=0.1885, max=0.8370, mean=0.6332

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9167

损失分量：
基础交叉熵: 0.4237
焦点损失: 0.0644
边界损失: 0.3892
总损失: 0.2434
Epoch 2 [29/172] - loss: 0.2434
Epoch 2 [30/172] - loss: 0.2882, acc: 0.9062
Epoch 2 [31/172] - loss: 0.4799
Epoch 2 [32/172] - loss: 0.2451
Epoch 2 [33/172] - loss: 0.2958
Epoch 2 [34/172] - loss: 0.2682
Epoch 2 [35/172] - loss: 0.1906
Epoch 2 [36/172] - loss: 0.4705
Epoch 2 [37/172] - loss: 0.2358
Epoch 2 [38/172] - loss: 0.2934
Epoch 2 [39/172] - loss: 0.4937
Epoch 2 [40/172] - loss: 0.4429, acc: 0.7812
Epoch 2 [41/172] - loss: 0.3924
Epoch 2 [42/172] - loss: 0.1422
Epoch 2 [43/172] - loss: 0.1810
Epoch 2 [44/172] - loss: 0.5461
Epoch 2 [45/172] - loss: 0.2552
Epoch 2 [46/172] - loss: 0.2401
Epoch 2 [47/172] - loss: 0.2720
Epoch 2 [48/172] - loss: 0.2402
Epoch 2 [49/172] - loss: 0.2152
Epoch 2 [50/172] - loss: 0.4337, acc: 0.8125
Epoch 2 [51/172] - loss: 0.3654
Epoch 2 [52/172] - loss: 0.2302
Epoch 2 [53/172] - loss: 0.2516
Epoch 2 [54/172] - loss: 0.3685
Epoch 2 [55/172] - loss: 0.1859
Epoch 2 [56/172] - loss: 0.3656
Epoch 2 [57/172] - loss: 0.2505
Epoch 2 [58/172] - loss: 0.2130
Epoch 2 [59/172] - loss: 0.4079
Epoch 2 [60/172] - loss: 0.2393, acc: 0.8750
Epoch 2 [61/172] - loss: 0.1508
Epoch 2 [62/172] - loss: 0.1598
Epoch 2 [63/172] - loss: 0.5059
Epoch 2 [64/172] - loss: 0.2852
Epoch 2 [65/172] - loss: 0.3634
Epoch 2 [66/172] - loss: 0.1668
Epoch 2 [67/172] - loss: 0.1620
Epoch 2 [68/172] - loss: 0.2053
Epoch 2 [69/172] - loss: 0.1604
Epoch 2 [70/172] - loss: 0.3035, acc: 0.8438
Epoch 2 [71/172] - loss: 0.4428
Epoch 2 [72/172] - loss: 0.2538
Epoch 2 [73/172] - loss: 0.3980
Epoch 2 [74/172] - loss: 0.2275
Epoch 2 [75/172] - loss: 0.2497
Epoch 2 [76/172] - loss: 0.2025
Epoch 2 [77/172] - loss: 0.4600
Epoch 2 [78/172] - loss: 0.3055
Epoch 2 [79/172] - loss: 0.3404
Epoch 2 [80/172] - loss: 0.1778, acc: 0.9688
Epoch 2 [81/172] - loss: 0.1849
Epoch 2 [82/172] - loss: 0.1965
Epoch 2 [83/172] - loss: 0.2544
Epoch 2 [84/172] - loss: 0.3556
Epoch 2 [85/172] - loss: 0.2455
Epoch 2 [86/172] - loss: 0.2291
Epoch 2 [87/172] - loss: 0.5774
Epoch 2 [88/172] - loss: 0.2135
Epoch 2 [89/172] - loss: 0.1139
Epoch 2 [90/172] - loss: 0.4575, acc: 0.8125
Epoch 2 [91/172] - loss: 0.1807
Epoch 2 [92/172] - loss: 0.4376
Epoch 2 [93/172] - loss: 0.1869
Epoch 2 [94/172] - loss: 0.2406
Epoch 2 [95/172] - loss: 0.3812
Epoch 2 [96/172] - loss: 0.1305
Epoch 2 [97/172] - loss: 0.2342
Epoch 2 [98/172] - loss: 0.2566
Epoch 2 [99/172] - loss: 0.1401
Epoch 2 [100/172] - loss: 0.2091, acc: 0.8750
Epoch 2 [101/172] - loss: 0.2389
Epoch 2 [102/172] - loss: 0.1786
Epoch 2 [103/172] - loss: 0.1621
Epoch 2 [104/172] - loss: 0.2981
Epoch 2 [105/172] - loss: 0.2135
Epoch 2 [106/172] - loss: 0.1197
Epoch 2 [107/172] - loss: 0.3528
Epoch 2 [108/172] - loss: 0.5222
Epoch 2 [109/172] - loss: 0.1896
Epoch 2 [110/172] - loss: 0.2513, acc: 0.8125
Epoch 2 [111/172] - loss: 0.2593
Epoch 2 [112/172] - loss: 0.1192
Epoch 2 [113/172] - loss: 0.1460
Epoch 2 [114/172] - loss: 0.2357
Epoch 2 [115/172] - loss: 0.3420
Epoch 2 [116/172] - loss: 0.3009
Epoch 2 [117/172] - loss: 0.3085
Epoch 2 [118/172] - loss: 0.1472
Epoch 2 [119/172] - loss: 0.2881
Epoch 2 [120/172] - loss: 0.1728, acc: 0.9375
Epoch 2 [121/172] - loss: 0.2983
Epoch 2 [122/172] - loss: 0.5582
Epoch 2 [123/172] - loss: 0.1805
Epoch 2 [124/172] - loss: 0.4973
Epoch 2 [125/172] - loss: 0.1437
Epoch 2 [126/172] - loss: 0.1466
Epoch 2 [127/172] - loss: 0.2416
Epoch 2 [128/172] - loss: 0.2438

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4508, log_difficulty=0.3721, weight=2.8607
neutral: count=2949.0, difficulty=0.3739, log_difficulty=0.3176, weight=2.5881
negative: count=3294.0, difficulty=0.4475, log_difficulty=0.3698, weight=2.8491

当前batch的pt分布：
positive: min=0.3660, max=0.9590, mean=0.7470
neutral: min=0.6465, max=0.9884, mean=0.8352
negative: min=0.3330, max=0.9436, mean=0.6828

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.7273

损失分量：
基础交叉熵: 0.3166
焦点损失: 0.0451
边界损失: 0.2984
总损失: 0.1706
Epoch 2 [129/172] - loss: 0.1706
Epoch 2 [130/172] - loss: 0.2837, acc: 0.8125
Epoch 2 [131/172] - loss: 0.2370
Epoch 2 [132/172] - loss: 0.1862
Epoch 2 [133/172] - loss: 0.1915
Epoch 2 [134/172] - loss: 0.2491
Epoch 2 [135/172] - loss: 0.4138
Epoch 2 [136/172] - loss: 0.1349
Epoch 2 [137/172] - loss: 0.1954
Epoch 2 [138/172] - loss: 0.2652
Epoch 2 [139/172] - loss: 0.1788
Epoch 2 [140/172] - loss: 0.1677, acc: 0.8750
Epoch 2 [141/172] - loss: 0.1627
Epoch 2 [142/172] - loss: 0.2983
Epoch 2 [143/172] - loss: 0.2316
Epoch 2 [144/172] - loss: 0.1687
Epoch 2 [145/172] - loss: 0.7410
Epoch 2 [146/172] - loss: 0.1423
Epoch 2 [147/172] - loss: 0.3566
Epoch 2 [148/172] - loss: 0.2259
Epoch 2 [149/172] - loss: 0.2549
Epoch 2 [150/172] - loss: 0.2183, acc: 0.9062
Epoch 2 [151/172] - loss: 0.1907
Epoch 2 [152/172] - loss: 0.1354
Epoch 2 [153/172] - loss: 0.1791
Epoch 2 [154/172] - loss: 0.1767
Epoch 2 [155/172] - loss: 0.2316
Epoch 2 [156/172] - loss: 0.1261
Epoch 2 [157/172] - loss: 0.0938
Epoch 2 [158/172] - loss: 0.2402
Epoch 2 [159/172] - loss: 0.1961
Epoch 2 [160/172] - loss: 0.2124, acc: 0.8750
Epoch 2 [161/172] - loss: 0.1314
Epoch 2 [162/172] - loss: 0.1040
Epoch 2 [163/172] - loss: 0.2760
Epoch 2 [164/172] - loss: 0.3043
Epoch 2 [165/172] - loss: 0.3909
Epoch 2 [166/172] - loss: 0.2622
Epoch 2 [167/172] - loss: 0.2928
Epoch 2 [168/172] - loss: 0.1377
Epoch 2 [169/172] - loss: 0.1330
Epoch 2 [170/172] - loss: 0.1344, acc: 0.9688
Epoch 2 [171/172] - loss: 0.2063
Epoch 2 [172/172] - loss: 0.5944

类别准确率:
positive: 0.8929 (417/467)
neutral: 0.3133 (26/83)
negative: 0.5800 (145/250)

Epoch 2/10
Train Loss: 0.2319, Train Acc: 0.9192
Val Loss: 0.6654, Val Acc: 0.7350
Epoch 3 [1/172] - loss: 0.1124, acc: 0.9688
Epoch 3 [2/172] - loss: 0.1630
Epoch 3 [3/172] - loss: 0.0945
Epoch 3 [4/172] - loss: 0.1567
Epoch 3 [5/172] - loss: 0.1928
Epoch 3 [6/172] - loss: 0.0860
Epoch 3 [7/172] - loss: 0.0888
Epoch 3 [8/172] - loss: 0.2165
Epoch 3 [9/172] - loss: 0.2664
Epoch 3 [10/172] - loss: 0.1675, acc: 0.9375
Epoch 3 [11/172] - loss: 0.1343
Epoch 3 [12/172] - loss: 0.0713
Epoch 3 [13/172] - loss: 0.0896
Epoch 3 [14/172] - loss: 0.0939
Epoch 3 [15/172] - loss: 0.0851
Epoch 3 [16/172] - loss: 0.2887
Epoch 3 [17/172] - loss: 0.1062
Epoch 3 [18/172] - loss: 0.2309
Epoch 3 [19/172] - loss: 0.1070
Epoch 3 [20/172] - loss: 0.0801, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1326
Epoch 3 [22/172] - loss: 0.1473
Epoch 3 [23/172] - loss: 0.1238
Epoch 3 [24/172] - loss: 0.0949
Epoch 3 [25/172] - loss: 0.0741
Epoch 3 [26/172] - loss: 0.1196
Epoch 3 [27/172] - loss: 0.1316
Epoch 3 [28/172] - loss: 0.0662
Epoch 3 [29/172] - loss: 0.1206
Epoch 3 [30/172] - loss: 0.1836, acc: 0.8750
Epoch 3 [31/172] - loss: 0.0640
Epoch 3 [32/172] - loss: 0.1130
Epoch 3 [33/172] - loss: 0.1283
Epoch 3 [34/172] - loss: 0.1107
Epoch 3 [35/172] - loss: 0.1171
Epoch 3 [36/172] - loss: 0.1121
Epoch 3 [37/172] - loss: 0.1010
Epoch 3 [38/172] - loss: 0.0688
Epoch 3 [39/172] - loss: 0.0966
Epoch 3 [40/172] - loss: 0.1536, acc: 0.9062
Epoch 3 [41/172] - loss: 0.0646
Epoch 3 [42/172] - loss: 0.1775
Epoch 3 [43/172] - loss: 0.0997
Epoch 3 [44/172] - loss: 0.0758
Epoch 3 [45/172] - loss: 0.1739
Epoch 3 [46/172] - loss: 0.0843
Epoch 3 [47/172] - loss: 0.0726
Epoch 3 [48/172] - loss: 0.0834
Epoch 3 [49/172] - loss: 0.0622
Epoch 3 [50/172] - loss: 0.1381, acc: 0.9688
Epoch 3 [51/172] - loss: 0.2400
Epoch 3 [52/172] - loss: 0.2950
Epoch 3 [53/172] - loss: 0.0984
Epoch 3 [54/172] - loss: 0.1466
Epoch 3 [55/172] - loss: 0.1245
Epoch 3 [56/172] - loss: 0.1037

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3985, log_difficulty=0.3354, weight=2.6769
neutral: count=3923.0, difficulty=0.3205, log_difficulty=0.2780, weight=2.3901
negative: count=4382.0, difficulty=0.3940, log_difficulty=0.3322, weight=2.6611

当前batch的pt分布：
positive: min=0.6252, max=0.9668, mean=0.8281
neutral: min=0.0052, max=0.9685, mean=0.7480
negative: min=0.8918, max=0.9885, mean=0.9637

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3553
焦点损失: 0.1789
边界损失: 0.2389
总损失: 0.3810
Epoch 3 [57/172] - loss: 0.3810
Epoch 3 [58/172] - loss: 0.1200
Epoch 3 [59/172] - loss: 0.0966
Epoch 3 [60/172] - loss: 0.0834, acc: 1.0000
Epoch 3 [61/172] - loss: 0.1246
Epoch 3 [62/172] - loss: 0.1374
Epoch 3 [63/172] - loss: 0.0933
Epoch 3 [64/172] - loss: 0.1020
Epoch 3 [65/172] - loss: 0.1751
Epoch 3 [66/172] - loss: 0.0831
Epoch 3 [67/172] - loss: 0.0677
Epoch 3 [68/172] - loss: 0.0862
Epoch 3 [69/172] - loss: 0.1929
Epoch 3 [70/172] - loss: 0.0712, acc: 1.0000
Epoch 3 [71/172] - loss: 0.2142
Epoch 3 [72/172] - loss: 0.2651
Epoch 3 [73/172] - loss: 0.0844
Epoch 3 [74/172] - loss: 0.1627
Epoch 3 [75/172] - loss: 0.0727
Epoch 3 [76/172] - loss: 0.0629
Epoch 3 [77/172] - loss: 0.0825
Epoch 3 [78/172] - loss: 0.3486
Epoch 3 [79/172] - loss: 0.0848
Epoch 3 [80/172] - loss: 0.1697, acc: 0.9688
Epoch 3 [81/172] - loss: 0.0915
Epoch 3 [82/172] - loss: 0.1669
Epoch 3 [83/172] - loss: 0.1099
Epoch 3 [84/172] - loss: 0.0722
Epoch 3 [85/172] - loss: 0.1027
Epoch 3 [86/172] - loss: 0.0803
Epoch 3 [87/172] - loss: 0.1452
Epoch 3 [88/172] - loss: 0.3566
Epoch 3 [89/172] - loss: 0.0606
Epoch 3 [90/172] - loss: 0.1155, acc: 0.9375
Epoch 3 [91/172] - loss: 0.1616
Epoch 3 [92/172] - loss: 0.2689
Epoch 3 [93/172] - loss: 0.1618
Epoch 3 [94/172] - loss: 0.1030
Epoch 3 [95/172] - loss: 0.0703
Epoch 3 [96/172] - loss: 0.1539
Epoch 3 [97/172] - loss: 0.1805
Epoch 3 [98/172] - loss: 0.0986
Epoch 3 [99/172] - loss: 0.0852
Epoch 3 [100/172] - loss: 0.2607, acc: 0.9688
Epoch 3 [101/172] - loss: 0.3139
Epoch 3 [102/172] - loss: 0.0700
Epoch 3 [103/172] - loss: 0.2854
Epoch 3 [104/172] - loss: 0.1392
Epoch 3 [105/172] - loss: 0.0761
Epoch 3 [106/172] - loss: 0.1997
Epoch 3 [107/172] - loss: 0.0699
Epoch 3 [108/172] - loss: 0.1329
Epoch 3 [109/172] - loss: 0.1099
Epoch 3 [110/172] - loss: 0.1112, acc: 0.9375
Epoch 3 [111/172] - loss: 0.2040
Epoch 3 [112/172] - loss: 0.0642
Epoch 3 [113/172] - loss: 0.0687
Epoch 3 [114/172] - loss: 0.1214
Epoch 3 [115/172] - loss: 0.0944
Epoch 3 [116/172] - loss: 0.1015
Epoch 3 [117/172] - loss: 0.1011
Epoch 3 [118/172] - loss: 0.1017
Epoch 3 [119/172] - loss: 0.1178
Epoch 3 [120/172] - loss: 0.1416, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1120
Epoch 3 [122/172] - loss: 0.1175
Epoch 3 [123/172] - loss: 0.0904
Epoch 3 [124/172] - loss: 0.1087
Epoch 3 [125/172] - loss: 0.0747
Epoch 3 [126/172] - loss: 0.2802
Epoch 3 [127/172] - loss: 0.1096
Epoch 3 [128/172] - loss: 0.0948
Epoch 3 [129/172] - loss: 0.0788
Epoch 3 [130/172] - loss: 0.0948, acc: 0.9375
Epoch 3 [131/172] - loss: 0.1145
Epoch 3 [132/172] - loss: 0.0628
Epoch 3 [133/172] - loss: 0.1056
Epoch 3 [134/172] - loss: 0.0640
Epoch 3 [135/172] - loss: 0.0701
Epoch 3 [136/172] - loss: 0.0890
Epoch 3 [137/172] - loss: 0.0810
Epoch 3 [138/172] - loss: 0.1596
Epoch 3 [139/172] - loss: 0.0693
Epoch 3 [140/172] - loss: 0.1201, acc: 0.9375
Epoch 3 [141/172] - loss: 0.2348
Epoch 3 [142/172] - loss: 0.1703
Epoch 3 [143/172] - loss: 0.0744
Epoch 3 [144/172] - loss: 0.1244
Epoch 3 [145/172] - loss: 0.1309
Epoch 3 [146/172] - loss: 0.1169
Epoch 3 [147/172] - loss: 0.1188
Epoch 3 [148/172] - loss: 0.1681
Epoch 3 [149/172] - loss: 0.1395
Epoch 3 [150/172] - loss: 0.1643, acc: 0.9375
Epoch 3 [151/172] - loss: 0.2030
Epoch 3 [152/172] - loss: 0.1729
Epoch 3 [153/172] - loss: 0.0904
Epoch 3 [154/172] - loss: 0.2262
Epoch 3 [155/172] - loss: 0.0677
Epoch 3 [156/172] - loss: 0.0872

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3560, log_difficulty=0.3045, weight=2.5226
neutral: count=4903.0, difficulty=0.2797, log_difficulty=0.2466, weight=2.2331
negative: count=5500.0, difficulty=0.3524, log_difficulty=0.3019, weight=2.5094

当前batch的pt分布：
positive: min=0.6179, max=0.9736, mean=0.8407
neutral: min=0.8097, max=0.9883, mean=0.9272
negative: min=0.6768, max=0.9760, mean=0.8800

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1316
焦点损失: 0.0044
边界损失: 0.2069
总损失: 0.0600
Epoch 3 [157/172] - loss: 0.0600
Epoch 3 [158/172] - loss: 0.2366
Epoch 3 [159/172] - loss: 0.0754
Epoch 3 [160/172] - loss: 0.1996, acc: 0.9375
Epoch 3 [161/172] - loss: 0.2686
Epoch 3 [162/172] - loss: 0.0841
Epoch 3 [163/172] - loss: 0.1219
Epoch 3 [164/172] - loss: 0.0621
Epoch 3 [165/172] - loss: 0.1043
Epoch 3 [166/172] - loss: 0.2153
Epoch 3 [167/172] - loss: 0.1136
Epoch 3 [168/172] - loss: 0.0698
Epoch 3 [169/172] - loss: 0.0660
Epoch 3 [170/172] - loss: 0.1074, acc: 0.9688
Epoch 3 [171/172] - loss: 0.0659
Epoch 3 [172/172] - loss: 0.0734

类别准确率:
positive: 0.9079 (424/467)
neutral: 0.3253 (27/83)
negative: 0.4880 (122/250)

Epoch 3/10
Train Loss: 0.1203, Train Acc: 0.9717
Val Loss: 0.7135, Val Acc: 0.7163
Epoch 4 [1/172] - loss: 0.0786, acc: 0.9688
Epoch 4 [2/172] - loss: 0.0544
Epoch 4 [3/172] - loss: 0.0861
Epoch 4 [4/172] - loss: 0.0713
Epoch 4 [5/172] - loss: 0.1398
Epoch 4 [6/172] - loss: 0.0557
Epoch 4 [7/172] - loss: 0.0890
Epoch 4 [8/172] - loss: 0.0547
Epoch 4 [9/172] - loss: 0.1176
Epoch 4 [10/172] - loss: 0.2581, acc: 0.9375
Epoch 4 [11/172] - loss: 0.0541
Epoch 4 [12/172] - loss: 0.0600
Epoch 4 [13/172] - loss: 0.0810
Epoch 4 [14/172] - loss: 0.1051
Epoch 4 [15/172] - loss: 0.0505
Epoch 4 [16/172] - loss: 0.0691
Epoch 4 [17/172] - loss: 0.0883
Epoch 4 [18/172] - loss: 0.0640
Epoch 4 [19/172] - loss: 0.0899
Epoch 4 [20/172] - loss: 0.0681, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1849
Epoch 4 [22/172] - loss: 0.0778
Epoch 4 [23/172] - loss: 0.0728
Epoch 4 [24/172] - loss: 0.0498
Epoch 4 [25/172] - loss: 0.0472
Epoch 4 [26/172] - loss: 0.1654
Epoch 4 [27/172] - loss: 0.0547
Epoch 4 [28/172] - loss: 0.0900
Epoch 4 [29/172] - loss: 0.0540
Epoch 4 [30/172] - loss: 0.1873, acc: 0.9375
Epoch 4 [31/172] - loss: 0.0862
Epoch 4 [32/172] - loss: 0.0576
Epoch 4 [33/172] - loss: 0.1249
Epoch 4 [34/172] - loss: 0.0451
Epoch 4 [35/172] - loss: 0.1342
Epoch 4 [36/172] - loss: 0.0648
Epoch 4 [37/172] - loss: 0.0481
Epoch 4 [38/172] - loss: 0.0516
Epoch 4 [39/172] - loss: 0.1334
Epoch 4 [40/172] - loss: 0.2085, acc: 0.9375
Epoch 4 [41/172] - loss: 0.0776
Epoch 4 [42/172] - loss: 0.1021
Epoch 4 [43/172] - loss: 0.0869
Epoch 4 [44/172] - loss: 0.0557
Epoch 4 [45/172] - loss: 0.0572
Epoch 4 [46/172] - loss: 0.0548
Epoch 4 [47/172] - loss: 0.0492
Epoch 4 [48/172] - loss: 0.0670
Epoch 4 [49/172] - loss: 0.0445
Epoch 4 [50/172] - loss: 0.0574, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0553
Epoch 4 [52/172] - loss: 0.1196
Epoch 4 [53/172] - loss: 0.0486
Epoch 4 [54/172] - loss: 0.0678
Epoch 4 [55/172] - loss: 0.2560
Epoch 4 [56/172] - loss: 0.0603
Epoch 4 [57/172] - loss: 0.0652
Epoch 4 [58/172] - loss: 0.1928
Epoch 4 [59/172] - loss: 0.0526
Epoch 4 [60/172] - loss: 0.0529, acc: 1.0000
Epoch 4 [61/172] - loss: 0.0926
Epoch 4 [62/172] - loss: 0.0723
Epoch 4 [63/172] - loss: 0.0597
Epoch 4 [64/172] - loss: 0.1022
Epoch 4 [65/172] - loss: 0.0881
Epoch 4 [66/172] - loss: 0.1189
Epoch 4 [67/172] - loss: 0.0577
Epoch 4 [68/172] - loss: 0.0641
Epoch 4 [69/172] - loss: 0.0539
Epoch 4 [70/172] - loss: 0.0674, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0765
Epoch 4 [72/172] - loss: 0.0779
Epoch 4 [73/172] - loss: 0.0492
Epoch 4 [74/172] - loss: 0.3028
Epoch 4 [75/172] - loss: 0.1092
Epoch 4 [76/172] - loss: 0.0457
Epoch 4 [77/172] - loss: 0.1317
Epoch 4 [78/172] - loss: 0.0633
Epoch 4 [79/172] - loss: 0.0469
Epoch 4 [80/172] - loss: 0.0526, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1243
Epoch 4 [82/172] - loss: 0.0653
Epoch 4 [83/172] - loss: 0.0447
Epoch 4 [84/172] - loss: 0.0443

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3205, log_difficulty=0.2780, weight=2.3901
neutral: count=5865.0, difficulty=0.2489, log_difficulty=0.2222, weight=2.1111
negative: count=6629.0, difficulty=0.3164, log_difficulty=0.2749, weight=2.3746

当前batch的pt分布：
positive: min=0.3368, max=0.9563, mean=0.8093
neutral: min=0.7521, max=0.9975, mean=0.9474
negative: min=0.8378, max=0.9887, mean=0.9232

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1576
焦点损失: 0.0204
边界损失: 0.2082
总损失: 0.0886
Epoch 4 [85/172] - loss: 0.0886
Epoch 4 [86/172] - loss: 0.0724
Epoch 4 [87/172] - loss: 0.1762
Epoch 4 [88/172] - loss: 0.0540
Epoch 4 [89/172] - loss: 0.0674
Epoch 4 [90/172] - loss: 0.0588, acc: 0.9688
Epoch 4 [91/172] - loss: 0.1796
Epoch 4 [92/172] - loss: 0.2539
Epoch 4 [93/172] - loss: 0.0491
Epoch 4 [94/172] - loss: 0.0452
Epoch 4 [95/172] - loss: 0.0646
Epoch 4 [96/172] - loss: 0.0649
Epoch 4 [97/172] - loss: 0.0925
Epoch 4 [98/172] - loss: 0.0868
Epoch 4 [99/172] - loss: 0.0587
Epoch 4 [100/172] - loss: 0.0857, acc: 0.9688
Epoch 4 [101/172] - loss: 0.0633
Epoch 4 [102/172] - loss: 0.1230
Epoch 4 [103/172] - loss: 0.0745
Epoch 4 [104/172] - loss: 0.0692
Epoch 4 [105/172] - loss: 0.0685
Epoch 4 [106/172] - loss: 0.0461
Epoch 4 [107/172] - loss: 0.0476
Epoch 4 [108/172] - loss: 0.0789
Epoch 4 [109/172] - loss: 0.0520
Epoch 4 [110/172] - loss: 0.2966, acc: 0.8750
Epoch 4 [111/172] - loss: 0.0535
Epoch 4 [112/172] - loss: 0.0613
Epoch 4 [113/172] - loss: 0.0485
Epoch 4 [114/172] - loss: 0.1149
Epoch 4 [115/172] - loss: 0.0745
Epoch 4 [116/172] - loss: 0.2489
Epoch 4 [117/172] - loss: 0.0481
Epoch 4 [118/172] - loss: 0.0959
Epoch 4 [119/172] - loss: 0.0674
Epoch 4 [120/172] - loss: 0.0659, acc: 0.9688
Epoch 4 [121/172] - loss: 0.1296
Epoch 4 [122/172] - loss: 0.0668
Epoch 4 [123/172] - loss: 0.0648
Epoch 4 [124/172] - loss: 0.0682
Epoch 4 [125/172] - loss: 0.0978
Epoch 4 [126/172] - loss: 0.1835
Epoch 4 [127/172] - loss: 0.0941
Epoch 4 [128/172] - loss: 0.0661
Epoch 4 [129/172] - loss: 0.0660
Epoch 4 [130/172] - loss: 0.0605, acc: 0.9688
Epoch 4 [131/172] - loss: 0.0636
Epoch 4 [132/172] - loss: 0.0520
Epoch 4 [133/172] - loss: 0.1272
Epoch 4 [134/172] - loss: 0.0854
Epoch 4 [135/172] - loss: 0.0945
Epoch 4 [136/172] - loss: 0.1288
Epoch 4 [137/172] - loss: 0.0710
Epoch 4 [138/172] - loss: 0.0687
Epoch 4 [139/172] - loss: 0.0703
Epoch 4 [140/172] - loss: 0.1105, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1039
Epoch 4 [142/172] - loss: 0.0992
Epoch 4 [143/172] - loss: 0.0603
Epoch 4 [144/172] - loss: 0.0896
Epoch 4 [145/172] - loss: 0.2156
Epoch 4 [146/172] - loss: 0.0573
Epoch 4 [147/172] - loss: 0.1201
Epoch 4 [148/172] - loss: 0.0828
Epoch 4 [149/172] - loss: 0.1416
Epoch 4 [150/172] - loss: 0.0614, acc: 1.0000
Epoch 4 [151/172] - loss: 0.1422
Epoch 4 [152/172] - loss: 0.0839
Epoch 4 [153/172] - loss: 0.0594
Epoch 4 [154/172] - loss: 0.1812
Epoch 4 [155/172] - loss: 0.0660
Epoch 4 [156/172] - loss: 0.0561
Epoch 4 [157/172] - loss: 0.3552
Epoch 4 [158/172] - loss: 0.0764
Epoch 4 [159/172] - loss: 0.1067
Epoch 4 [160/172] - loss: 0.0633, acc: 0.9688
Epoch 4 [161/172] - loss: 0.0640
Epoch 4 [162/172] - loss: 0.0587
Epoch 4 [163/172] - loss: 0.1023
Epoch 4 [164/172] - loss: 0.0680
Epoch 4 [165/172] - loss: 0.1178
Epoch 4 [166/172] - loss: 0.1030
Epoch 4 [167/172] - loss: 0.0869
Epoch 4 [168/172] - loss: 0.1364
Epoch 4 [169/172] - loss: 0.2284
Epoch 4 [170/172] - loss: 0.1503, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0524
Epoch 4 [172/172] - loss: 0.0681

类别准确率:
positive: 0.9122 (426/467)
neutral: 0.2289 (19/83)
negative: 0.5560 (139/250)

Epoch 4/10
Train Loss: 0.1149, Train Acc: 0.9636
Val Loss: 0.6671, Val Acc: 0.7300
Epoch 5 [1/172] - loss: 0.0636, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0735
Epoch 5 [3/172] - loss: 0.0655
Epoch 5 [4/172] - loss: 0.0713
Epoch 5 [5/172] - loss: 0.0741
Epoch 5 [6/172] - loss: 0.0725
Epoch 5 [7/172] - loss: 0.0599
Epoch 5 [8/172] - loss: 0.0637
Epoch 5 [9/172] - loss: 0.0956
Epoch 5 [10/172] - loss: 0.0492, acc: 1.0000
Epoch 5 [11/172] - loss: 0.0594
Epoch 5 [12/172] - loss: 0.0592

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2931, log_difficulty=0.2570, weight=2.2851
neutral: count=6845.0, difficulty=0.2252, log_difficulty=0.2031, weight=2.0155
negative: count=7694.0, difficulty=0.2909, log_difficulty=0.2553, weight=2.2766

当前batch的pt分布：
positive: min=0.4593, max=0.9885, mean=0.8407
neutral: min=0.8788, max=0.9974, mean=0.9720
negative: min=0.5392, max=0.9910, mean=0.8455

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1530
焦点损失: 0.0134
边界损失: 0.2162
总损失: 0.0769
Epoch 5 [13/172] - loss: 0.0769
Epoch 5 [14/172] - loss: 0.0738
Epoch 5 [15/172] - loss: 0.0477
Epoch 5 [16/172] - loss: 0.0520
Epoch 5 [17/172] - loss: 0.1114
Epoch 5 [18/172] - loss: 0.0514
Epoch 5 [19/172] - loss: 0.0539
Epoch 5 [20/172] - loss: 0.0779, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1167
Epoch 5 [22/172] - loss: 0.0759
Epoch 5 [23/172] - loss: 0.0552
Epoch 5 [24/172] - loss: 0.0593
Epoch 5 [25/172] - loss: 0.0761
Epoch 5 [26/172] - loss: 0.0708
Epoch 5 [27/172] - loss: 0.0839
Epoch 5 [28/172] - loss: 0.0568
Epoch 5 [29/172] - loss: 0.0538
Epoch 5 [30/172] - loss: 0.0488, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0486
Epoch 5 [32/172] - loss: 0.0488
Epoch 5 [33/172] - loss: 0.0731
Epoch 5 [34/172] - loss: 0.0856
Epoch 5 [35/172] - loss: 0.0456
Epoch 5 [36/172] - loss: 0.0494
Epoch 5 [37/172] - loss: 0.0495
Epoch 5 [38/172] - loss: 0.0539
Epoch 5 [39/172] - loss: 0.1240
Epoch 5 [40/172] - loss: 0.0621, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0530
Epoch 5 [42/172] - loss: 0.0488
Epoch 5 [43/172] - loss: 0.2457
Epoch 5 [44/172] - loss: 0.0529
Epoch 5 [45/172] - loss: 0.0486
Epoch 5 [46/172] - loss: 0.0961
Epoch 5 [47/172] - loss: 0.0520
Epoch 5 [48/172] - loss: 0.0506
Epoch 5 [49/172] - loss: 0.0462
Epoch 5 [50/172] - loss: 0.0722, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0725
Epoch 5 [52/172] - loss: 0.0719
Epoch 5 [53/172] - loss: 0.0807
Epoch 5 [54/172] - loss: 0.0494
Epoch 5 [55/172] - loss: 0.0707
Epoch 5 [56/172] - loss: 0.0554
Epoch 5 [57/172] - loss: 0.0454
Epoch 5 [58/172] - loss: 0.1769
Epoch 5 [59/172] - loss: 0.0853
Epoch 5 [60/172] - loss: 0.0487, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0559
Epoch 5 [62/172] - loss: 0.0525
Epoch 5 [63/172] - loss: 0.0862
Epoch 5 [64/172] - loss: 0.0809
Epoch 5 [65/172] - loss: 0.0738
Epoch 5 [66/172] - loss: 0.0466
Epoch 5 [67/172] - loss: 0.0501
Epoch 5 [68/172] - loss: 0.0516
Epoch 5 [69/172] - loss: 0.0610
Epoch 5 [70/172] - loss: 0.0466, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0713
Epoch 5 [72/172] - loss: 0.0522
Epoch 5 [73/172] - loss: 0.0482
Epoch 5 [74/172] - loss: 0.0706
Epoch 5 [75/172] - loss: 0.0449
Epoch 5 [76/172] - loss: 0.0574
Epoch 5 [77/172] - loss: 0.0465
Epoch 5 [78/172] - loss: 0.0900
Epoch 5 [79/172] - loss: 0.0699
Epoch 5 [80/172] - loss: 0.0509, acc: 1.0000
Epoch 5 [81/172] - loss: 0.0924
Epoch 5 [82/172] - loss: 0.0635
Epoch 5 [83/172] - loss: 0.0490
Epoch 5 [84/172] - loss: 0.0472
Epoch 5 [85/172] - loss: 0.0560
Epoch 5 [86/172] - loss: 0.0535
Epoch 5 [87/172] - loss: 0.0563
Epoch 5 [88/172] - loss: 0.0578
Epoch 5 [89/172] - loss: 0.0589
Epoch 5 [90/172] - loss: 0.0594, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0552
Epoch 5 [92/172] - loss: 0.0461
Epoch 5 [93/172] - loss: 0.0584
Epoch 5 [94/172] - loss: 0.0445
Epoch 5 [95/172] - loss: 0.0504
Epoch 5 [96/172] - loss: 0.0451
Epoch 5 [97/172] - loss: 0.0716
Epoch 5 [98/172] - loss: 0.0460
Epoch 5 [99/172] - loss: 0.1064
Epoch 5 [100/172] - loss: 0.1205, acc: 0.9688
Epoch 5 [101/172] - loss: 0.0483
Epoch 5 [102/172] - loss: 0.0566
Epoch 5 [103/172] - loss: 0.0812
Epoch 5 [104/172] - loss: 0.0968
Epoch 5 [105/172] - loss: 0.1353
Epoch 5 [106/172] - loss: 0.0432
Epoch 5 [107/172] - loss: 0.0619
Epoch 5 [108/172] - loss: 0.1106
Epoch 5 [109/172] - loss: 0.0503
Epoch 5 [110/172] - loss: 0.0446, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0576
Epoch 5 [112/172] - loss: 0.0487

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2690, log_difficulty=0.2382, weight=2.1910
neutral: count=7825.0, difficulty=0.2063, log_difficulty=0.1876, weight=1.9380
negative: count=8780.0, difficulty=0.2684, log_difficulty=0.2378, weight=2.1889

当前batch的pt分布：
positive: min=0.3660, max=0.9809, mean=0.8456
neutral: min=0.7931, max=0.9896, mean=0.9218
negative: min=0.9780, max=0.9974, mean=0.9906

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1256
焦点损失: 0.0146
边界损失: 0.1933
总损失: 0.0722
Epoch 5 [113/172] - loss: 0.0722
Epoch 5 [114/172] - loss: 0.0612
Epoch 5 [115/172] - loss: 0.0490
Epoch 5 [116/172] - loss: 0.0426
Epoch 5 [117/172] - loss: 0.0465
Epoch 5 [118/172] - loss: 0.0587
Epoch 5 [119/172] - loss: 0.0774
Epoch 5 [120/172] - loss: 0.0530, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0496
Epoch 5 [122/172] - loss: 0.0548
Epoch 5 [123/172] - loss: 0.0496
Epoch 5 [124/172] - loss: 0.0425
Epoch 5 [125/172] - loss: 0.0455
Epoch 5 [126/172] - loss: 0.0511
Epoch 5 [127/172] - loss: 0.0459
Epoch 5 [128/172] - loss: 0.0476
Epoch 5 [129/172] - loss: 0.1037
Epoch 5 [130/172] - loss: 0.0429, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0542
Epoch 5 [132/172] - loss: 0.0866
Epoch 5 [133/172] - loss: 0.0743
Epoch 5 [134/172] - loss: 0.1431
Epoch 5 [135/172] - loss: 0.0436
Epoch 5 [136/172] - loss: 0.0486
Epoch 5 [137/172] - loss: 0.0531
Epoch 5 [138/172] - loss: 0.1122
Epoch 5 [139/172] - loss: 0.1062
Epoch 5 [140/172] - loss: 0.0488, acc: 1.0000
Epoch 5 [141/172] - loss: 0.0510
Epoch 5 [142/172] - loss: 0.0540
Epoch 5 [143/172] - loss: 0.0512
Epoch 5 [144/172] - loss: 0.0428
Epoch 5 [145/172] - loss: 0.0526
Epoch 5 [146/172] - loss: 0.0424
Epoch 5 [147/172] - loss: 0.0510
Epoch 5 [148/172] - loss: 0.0483
Epoch 5 [149/172] - loss: 0.1240
Epoch 5 [150/172] - loss: 0.1401, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0456
Epoch 5 [152/172] - loss: 0.0450
Epoch 5 [153/172] - loss: 0.0430
Epoch 5 [154/172] - loss: 0.0437
Epoch 5 [155/172] - loss: 0.0430
Epoch 5 [156/172] - loss: 0.0640
Epoch 5 [157/172] - loss: 0.0796
Epoch 5 [158/172] - loss: 0.0461
Epoch 5 [159/172] - loss: 0.0422
Epoch 5 [160/172] - loss: 0.0460, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0467
Epoch 5 [162/172] - loss: 0.0796
Epoch 5 [163/172] - loss: 0.0613
Epoch 5 [164/172] - loss: 0.0477
Epoch 5 [165/172] - loss: 0.1170
Epoch 5 [166/172] - loss: 0.0678
Epoch 5 [167/172] - loss: 0.0628
Epoch 5 [168/172] - loss: 0.0430
Epoch 5 [169/172] - loss: 0.0458
Epoch 5 [170/172] - loss: 0.0436, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0919
Epoch 5 [172/172] - loss: 0.0676

类别准确率:
positive: 0.8437 (394/467)
neutral: 0.3373 (28/83)
negative: 0.6640 (166/250)

Epoch 5/10
Train Loss: 0.0618, Train Acc: 0.9899
Val Loss: 0.6935, Val Acc: 0.7350
Early stopping triggered!
Best validation accuracy: 0.7350

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_115515-fy3wk50q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.2_Multimodal_iterations_20250118_115514
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/fy3wk50q
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:  train_acc ▁▁▂▅▃▇▅▆▅▇█▇▆▇▆█▇█▇█▇██▇▇██▇██▇█████████
wandb: train_loss █▇▅▅▆▆▅▃▄▄▃▂▄▂▂▁▂▂▁▁▁▂▂▁▂▁▁▁▁▃▁▂▁▁▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 858
wandb:  train_acc 1
wandb: train_loss 0.04361
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.2_Multimodal_iterations_20250118_115514 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/fy3wk50q
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_115515-fy3wk50q/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_120307-aam19tm5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.2_Multimodal_epochs_20250118_120307
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/aam19tm5
wandb: uploading wandb-metadata.json; uploading summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▃▅▆█
wandb:  train_acc ▁▆▇▇█
wandb: train_loss █▄▂▂▁
wandb:    val_acc ▁█▇██
wandb:   val_loss █▁▄▁▃
wandb: 
wandb: Run summary:
wandb:      epoch 5
wandb:  train_acc 0.9899
wandb: train_loss 0.0618
wandb:    val_acc 0.735
wandb:   val_loss 0.69351
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.2_Multimodal_epochs_20250118_120307 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/aam19tm5
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_120307-aam19tm5/logs

