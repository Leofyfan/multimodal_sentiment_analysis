=== 命令 ===
python main.py --loss_type focal --alpha 0.75 --beta 0.25 --neural_init_weight 1.5 --dropout 0.25 --name loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.25 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.25
text_dim: 128
image_dim: 256
dropout: 0.25
loss_type: focal
alpha: 0.75
beta: 0.25
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6788, log_difficulty=0.5180, weight=3.5902
neutral: count=7.0, difficulty=0.6645, log_difficulty=0.5095, weight=3.5476
negative: count=13.0, difficulty=0.6209, log_difficulty=0.4830, weight=3.4148

当前batch的pt分布：
positive: min=0.1952, max=0.4055, mean=0.3212
neutral: min=0.2138, max=0.3805, mean=0.3355
negative: min=0.1917, max=0.8684, mean=0.3791

当前batch准确率：
整体准确率: 0.3125
positive 准确率: 0.2500
neutral 准确率: 0.2857
negative 准确率: 0.3846

损失分量：
基础交叉熵: 1.0951
焦点损失: 0.3526
边界损失: 0.8484
总损失: 1.1414
Epoch 1 [1/172] - loss: 1.1414, acc: 0.3125
Epoch 1 [2/172] - loss: 1.2021
Epoch 1 [3/172] - loss: 1.3553
Epoch 1 [4/172] - loss: 1.2532
Epoch 1 [5/172] - loss: 1.0978
Epoch 1 [6/172] - loss: 1.6563
Epoch 1 [7/172] - loss: 1.0208
Epoch 1 [8/172] - loss: 1.4382
Epoch 1 [9/172] - loss: 1.1435
Epoch 1 [10/172] - loss: 1.4714, acc: 0.4375
Epoch 1 [11/172] - loss: 1.1783
Epoch 1 [12/172] - loss: 1.0145
Epoch 1 [13/172] - loss: 1.1532
Epoch 1 [14/172] - loss: 1.1892
Epoch 1 [15/172] - loss: 1.2319
Epoch 1 [16/172] - loss: 1.1940
Epoch 1 [17/172] - loss: 1.2079
Epoch 1 [18/172] - loss: 0.9090
Epoch 1 [19/172] - loss: 1.0936
Epoch 1 [20/172] - loss: 1.1263, acc: 0.3438
Epoch 1 [21/172] - loss: 1.1734
Epoch 1 [22/172] - loss: 0.9822
Epoch 1 [23/172] - loss: 1.1278
Epoch 1 [24/172] - loss: 1.2129
Epoch 1 [25/172] - loss: 1.0946
Epoch 1 [26/172] - loss: 1.1348
Epoch 1 [27/172] - loss: 1.0548
Epoch 1 [28/172] - loss: 1.0838
Epoch 1 [29/172] - loss: 0.9973
Epoch 1 [30/172] - loss: 0.8063, acc: 0.6250
Epoch 1 [31/172] - loss: 1.0952
Epoch 1 [32/172] - loss: 0.9551
Epoch 1 [33/172] - loss: 0.7633
Epoch 1 [34/172] - loss: 0.8744
Epoch 1 [35/172] - loss: 1.0450
Epoch 1 [36/172] - loss: 1.0928
Epoch 1 [37/172] - loss: 0.6861
Epoch 1 [38/172] - loss: 0.8169
Epoch 1 [39/172] - loss: 0.9103
Epoch 1 [40/172] - loss: 0.7683, acc: 0.6250
Epoch 1 [41/172] - loss: 1.1211
Epoch 1 [42/172] - loss: 0.7635
Epoch 1 [43/172] - loss: 0.9490
Epoch 1 [44/172] - loss: 1.0101
Epoch 1 [45/172] - loss: 1.2103
Epoch 1 [46/172] - loss: 0.7679
Epoch 1 [47/172] - loss: 0.8887
Epoch 1 [48/172] - loss: 1.0434
Epoch 1 [49/172] - loss: 1.1750
Epoch 1 [50/172] - loss: 0.9255, acc: 0.7188
Epoch 1 [51/172] - loss: 0.8468
Epoch 1 [52/172] - loss: 0.8943
Epoch 1 [53/172] - loss: 0.8444
Epoch 1 [54/172] - loss: 0.8812
Epoch 1 [55/172] - loss: 0.6386
Epoch 1 [56/172] - loss: 0.9820
Epoch 1 [57/172] - loss: 1.2263
Epoch 1 [58/172] - loss: 0.9169
Epoch 1 [59/172] - loss: 0.8739
Epoch 1 [60/172] - loss: 0.7283, acc: 0.6875
Epoch 1 [61/172] - loss: 1.0436
Epoch 1 [62/172] - loss: 0.9334
Epoch 1 [63/172] - loss: 0.8976
Epoch 1 [64/172] - loss: 0.5819
Epoch 1 [65/172] - loss: 1.0477
Epoch 1 [66/172] - loss: 1.0533
Epoch 1 [67/172] - loss: 1.1043
Epoch 1 [68/172] - loss: 1.0402
Epoch 1 [69/172] - loss: 0.7607
Epoch 1 [70/172] - loss: 0.8808, acc: 0.5938
Epoch 1 [71/172] - loss: 0.7381
Epoch 1 [72/172] - loss: 0.8543
Epoch 1 [73/172] - loss: 0.7785
Epoch 1 [74/172] - loss: 0.8957
Epoch 1 [75/172] - loss: 0.4963
Epoch 1 [76/172] - loss: 0.7846
Epoch 1 [77/172] - loss: 0.9118
Epoch 1 [78/172] - loss: 0.6795
Epoch 1 [79/172] - loss: 1.1826
Epoch 1 [80/172] - loss: 0.6968, acc: 0.6875
Epoch 1 [81/172] - loss: 1.0167
Epoch 1 [82/172] - loss: 1.1366
Epoch 1 [83/172] - loss: 1.1748
Epoch 1 [84/172] - loss: 0.7356
Epoch 1 [85/172] - loss: 0.7998
Epoch 1 [86/172] - loss: 0.8600
Epoch 1 [87/172] - loss: 0.8353
Epoch 1 [88/172] - loss: 0.7999
Epoch 1 [89/172] - loss: 0.8138
Epoch 1 [90/172] - loss: 0.7373, acc: 0.4688
Epoch 1 [91/172] - loss: 0.7300
Epoch 1 [92/172] - loss: 0.7524
Epoch 1 [93/172] - loss: 0.6907
Epoch 1 [94/172] - loss: 0.6247
Epoch 1 [95/172] - loss: 0.5633
Epoch 1 [96/172] - loss: 0.6919
Epoch 1 [97/172] - loss: 0.6950
Epoch 1 [98/172] - loss: 0.7126
Epoch 1 [99/172] - loss: 1.1045
Epoch 1 [100/172] - loss: 0.7581, acc: 0.6562

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5855, log_difficulty=0.4609, weight=3.3045
neutral: count=983.0, difficulty=0.5760, log_difficulty=0.4549, weight=3.2744
negative: count=1119.0, difficulty=0.5744, log_difficulty=0.4539, weight=3.2695

当前batch的pt分布：
positive: min=0.2087, max=0.7420, mean=0.3737
neutral: min=0.2004, max=0.7676, mean=0.4381
negative: min=0.1721, max=0.5835, mean=0.3486

当前batch准确率：
整体准确率: 0.3750
positive 准确率: 0.3333
neutral 准确率: 0.5000
negative 准确率: 0.3750

损失分量：
基础交叉熵: 1.0837
焦点损失: 0.4042
边界损失: 0.5887
总损失: 1.1422
Epoch 1 [101/172] - loss: 1.1422
Epoch 1 [102/172] - loss: 0.8176
Epoch 1 [103/172] - loss: 0.7925
Epoch 1 [104/172] - loss: 0.4350
Epoch 1 [105/172] - loss: 0.8726
Epoch 1 [106/172] - loss: 0.9050
Epoch 1 [107/172] - loss: 0.6039
Epoch 1 [108/172] - loss: 0.9171
Epoch 1 [109/172] - loss: 0.6720
Epoch 1 [110/172] - loss: 0.7390, acc: 0.7188
Epoch 1 [111/172] - loss: 0.9121
Epoch 1 [112/172] - loss: 0.6430
Epoch 1 [113/172] - loss: 0.3849
Epoch 1 [114/172] - loss: 0.7286
Epoch 1 [115/172] - loss: 0.8453
Epoch 1 [116/172] - loss: 0.6423
Epoch 1 [117/172] - loss: 0.7346
Epoch 1 [118/172] - loss: 0.5808
Epoch 1 [119/172] - loss: 0.7358
Epoch 1 [120/172] - loss: 0.4761, acc: 0.7812
Epoch 1 [121/172] - loss: 0.5137
Epoch 1 [122/172] - loss: 0.8439
Epoch 1 [123/172] - loss: 0.5056
Epoch 1 [124/172] - loss: 0.8383
Epoch 1 [125/172] - loss: 0.6935
Epoch 1 [126/172] - loss: 1.0800
Epoch 1 [127/172] - loss: 0.4654
Epoch 1 [128/172] - loss: 0.5719
Epoch 1 [129/172] - loss: 0.6718
Epoch 1 [130/172] - loss: 0.5902, acc: 0.7812
Epoch 1 [131/172] - loss: 0.2709
Epoch 1 [132/172] - loss: 0.7176
Epoch 1 [133/172] - loss: 0.4876
Epoch 1 [134/172] - loss: 0.6762
Epoch 1 [135/172] - loss: 0.4605
Epoch 1 [136/172] - loss: 0.4809
Epoch 1 [137/172] - loss: 0.6797
Epoch 1 [138/172] - loss: 0.7802
Epoch 1 [139/172] - loss: 0.4065
Epoch 1 [140/172] - loss: 0.5040, acc: 0.7812
Epoch 1 [141/172] - loss: 0.5310
Epoch 1 [142/172] - loss: 0.5516
Epoch 1 [143/172] - loss: 0.4692
Epoch 1 [144/172] - loss: 0.5886
Epoch 1 [145/172] - loss: 0.3880
Epoch 1 [146/172] - loss: 1.0369
Epoch 1 [147/172] - loss: 0.8908
Epoch 1 [148/172] - loss: 0.6239
Epoch 1 [149/172] - loss: 0.4459
Epoch 1 [150/172] - loss: 0.4962, acc: 0.7188
Epoch 1 [151/172] - loss: 0.5133
Epoch 1 [152/172] - loss: 0.4292
Epoch 1 [153/172] - loss: 0.4828
Epoch 1 [154/172] - loss: 0.4615
Epoch 1 [155/172] - loss: 0.6906
Epoch 1 [156/172] - loss: 1.0813
Epoch 1 [157/172] - loss: 0.7281
Epoch 1 [158/172] - loss: 0.5866
Epoch 1 [159/172] - loss: 0.8040
Epoch 1 [160/172] - loss: 0.4067, acc: 0.8125
Epoch 1 [161/172] - loss: 0.3330
Epoch 1 [162/172] - loss: 0.3592
Epoch 1 [163/172] - loss: 0.5773
Epoch 1 [164/172] - loss: 0.6144
Epoch 1 [165/172] - loss: 0.4454
Epoch 1 [166/172] - loss: 0.4935
Epoch 1 [167/172] - loss: 0.5536
Epoch 1 [168/172] - loss: 0.4581
Epoch 1 [169/172] - loss: 0.5806
Epoch 1 [170/172] - loss: 0.3447, acc: 0.7812
Epoch 1 [171/172] - loss: 0.3904
Epoch 1 [172/172] - loss: 0.5181

类别准确率:
positive: 0.6660 (311/467)
neutral: 0.3614 (30/83)
negative: 0.8200 (205/250)

Epoch 1/10
Train Loss: 0.5121, Train Acc: 0.7576
Val Loss: 0.7228, Val Acc: 0.6825
Epoch 2 [1/172] - loss: 0.3032, acc: 0.9062
Epoch 2 [2/172] - loss: 0.3244
Epoch 2 [3/172] - loss: 0.3318
Epoch 2 [4/172] - loss: 0.6840
Epoch 2 [5/172] - loss: 0.7058
Epoch 2 [6/172] - loss: 0.3722
Epoch 2 [7/172] - loss: 0.5927
Epoch 2 [8/172] - loss: 0.2926
Epoch 2 [9/172] - loss: 0.3264
Epoch 2 [10/172] - loss: 0.5544, acc: 0.8438
Epoch 2 [11/172] - loss: 0.3931
Epoch 2 [12/172] - loss: 0.2866
Epoch 2 [13/172] - loss: 0.4521
Epoch 2 [14/172] - loss: 0.3482
Epoch 2 [15/172] - loss: 0.4817
Epoch 2 [16/172] - loss: 0.3417
Epoch 2 [17/172] - loss: 0.4986
Epoch 2 [18/172] - loss: 0.3667
Epoch 2 [19/172] - loss: 0.5485
Epoch 2 [20/172] - loss: 0.2812, acc: 0.8438
Epoch 2 [21/172] - loss: 0.3710
Epoch 2 [22/172] - loss: 0.2508
Epoch 2 [23/172] - loss: 0.1840
Epoch 2 [24/172] - loss: 0.7493
Epoch 2 [25/172] - loss: 0.3470
Epoch 2 [26/172] - loss: 0.2562
Epoch 2 [27/172] - loss: 0.2961
Epoch 2 [28/172] - loss: 0.3781

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5242, log_difficulty=0.4215, weight=3.1074
neutral: count=1952.0, difficulty=0.4767, log_difficulty=0.3898, weight=2.9491
negative: count=2216.0, difficulty=0.5123, log_difficulty=0.4137, weight=3.0683

当前batch的pt分布：
positive: min=0.2411, max=0.9772, mean=0.6539
neutral: min=0.4181, max=0.9831, mean=0.6825
negative: min=0.2394, max=0.9084, mean=0.5960

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.8889
neutral 准确率: 1.0000
negative 准确率: 0.6667

损失分量：
基础交叉熵: 0.5034
焦点损失: 0.1013
边界损失: 0.4128
总损失: 0.3357
Epoch 2 [29/172] - loss: 0.3357
Epoch 2 [30/172] - loss: 0.1821, acc: 0.9062
Epoch 2 [31/172] - loss: 0.4583
Epoch 2 [32/172] - loss: 0.4758
Epoch 2 [33/172] - loss: 0.2063
Epoch 2 [34/172] - loss: 0.3769
Epoch 2 [35/172] - loss: 0.3137
Epoch 2 [36/172] - loss: 0.4736
Epoch 2 [37/172] - loss: 0.1895
Epoch 2 [38/172] - loss: 0.2078
Epoch 2 [39/172] - loss: 0.4552
Epoch 2 [40/172] - loss: 0.3635, acc: 0.8125
Epoch 2 [41/172] - loss: 0.3811
Epoch 2 [42/172] - loss: 0.1661
Epoch 2 [43/172] - loss: 0.3049
Epoch 2 [44/172] - loss: 0.3844
Epoch 2 [45/172] - loss: 0.3539
Epoch 2 [46/172] - loss: 0.2526
Epoch 2 [47/172] - loss: 0.5177
Epoch 2 [48/172] - loss: 0.4235
Epoch 2 [49/172] - loss: 0.3038
Epoch 2 [50/172] - loss: 0.3433, acc: 0.7812
Epoch 2 [51/172] - loss: 0.6407
Epoch 2 [52/172] - loss: 0.2743
Epoch 2 [53/172] - loss: 0.3411
Epoch 2 [54/172] - loss: 0.2889
Epoch 2 [55/172] - loss: 0.3478
Epoch 2 [56/172] - loss: 0.3441
Epoch 2 [57/172] - loss: 0.2200
Epoch 2 [58/172] - loss: 0.2820
Epoch 2 [59/172] - loss: 0.5451
Epoch 2 [60/172] - loss: 0.3248, acc: 0.8438
Epoch 2 [61/172] - loss: 0.2564
Epoch 2 [62/172] - loss: 0.2779
Epoch 2 [63/172] - loss: 0.5119
Epoch 2 [64/172] - loss: 0.3680
Epoch 2 [65/172] - loss: 0.3373
Epoch 2 [66/172] - loss: 0.2664
Epoch 2 [67/172] - loss: 0.2082
Epoch 2 [68/172] - loss: 0.3650
Epoch 2 [69/172] - loss: 0.2558
Epoch 2 [70/172] - loss: 0.4682, acc: 0.8438
Epoch 2 [71/172] - loss: 0.2740
Epoch 2 [72/172] - loss: 0.3787
Epoch 2 [73/172] - loss: 0.2735
Epoch 2 [74/172] - loss: 0.3033
Epoch 2 [75/172] - loss: 0.2154
Epoch 2 [76/172] - loss: 0.2504
Epoch 2 [77/172] - loss: 0.2705
Epoch 2 [78/172] - loss: 0.3976
Epoch 2 [79/172] - loss: 0.3148
Epoch 2 [80/172] - loss: 0.2804, acc: 0.8125
Epoch 2 [81/172] - loss: 0.3243
Epoch 2 [82/172] - loss: 0.1886
Epoch 2 [83/172] - loss: 0.4390
Epoch 2 [84/172] - loss: 0.3096
Epoch 2 [85/172] - loss: 0.2225
Epoch 2 [86/172] - loss: 0.3064
Epoch 2 [87/172] - loss: 0.6839
Epoch 2 [88/172] - loss: 0.1982
Epoch 2 [89/172] - loss: 0.1713
Epoch 2 [90/172] - loss: 0.2262, acc: 0.8438
Epoch 2 [91/172] - loss: 0.2054
Epoch 2 [92/172] - loss: 0.3496
Epoch 2 [93/172] - loss: 0.2694
Epoch 2 [94/172] - loss: 0.2647
Epoch 2 [95/172] - loss: 0.5167
Epoch 2 [96/172] - loss: 0.2711
Epoch 2 [97/172] - loss: 0.2150
Epoch 2 [98/172] - loss: 0.2646
Epoch 2 [99/172] - loss: 0.1342
Epoch 2 [100/172] - loss: 0.2362, acc: 0.9062
Epoch 2 [101/172] - loss: 0.2222
Epoch 2 [102/172] - loss: 0.1815
Epoch 2 [103/172] - loss: 0.2567
Epoch 2 [104/172] - loss: 0.3987
Epoch 2 [105/172] - loss: 0.1411
Epoch 2 [106/172] - loss: 0.2457
Epoch 2 [107/172] - loss: 0.1488
Epoch 2 [108/172] - loss: 0.6222
Epoch 2 [109/172] - loss: 0.2379
Epoch 2 [110/172] - loss: 0.3328, acc: 0.8125
Epoch 2 [111/172] - loss: 0.1755
Epoch 2 [112/172] - loss: 0.1710
Epoch 2 [113/172] - loss: 0.1673
Epoch 2 [114/172] - loss: 0.2334
Epoch 2 [115/172] - loss: 0.2269
Epoch 2 [116/172] - loss: 0.3979
Epoch 2 [117/172] - loss: 0.4122
Epoch 2 [118/172] - loss: 0.1955
Epoch 2 [119/172] - loss: 0.2089
Epoch 2 [120/172] - loss: 0.1782, acc: 0.9375
Epoch 2 [121/172] - loss: 0.1649
Epoch 2 [122/172] - loss: 0.4753
Epoch 2 [123/172] - loss: 0.2098
Epoch 2 [124/172] - loss: 0.3530
Epoch 2 [125/172] - loss: 0.1555
Epoch 2 [126/172] - loss: 0.2050
Epoch 2 [127/172] - loss: 0.1975
Epoch 2 [128/172] - loss: 0.1023

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4659, log_difficulty=0.3825, weight=2.9125
neutral: count=2949.0, difficulty=0.3911, log_difficulty=0.3301, weight=2.6505
negative: count=3294.0, difficulty=0.4554, log_difficulty=0.3753, weight=2.8763

当前batch的pt分布：
positive: min=0.4195, max=0.9421, mean=0.7182
neutral: min=0.5932, max=0.9083, mean=0.8024
negative: min=0.0818, max=0.9178, mean=0.7086

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.3581
焦点损失: 0.0876
边界损失: 0.3162
总损失: 0.2677
Epoch 2 [129/172] - loss: 0.2677
Epoch 2 [130/172] - loss: 0.3097, acc: 0.8125
Epoch 2 [131/172] - loss: 0.1810
Epoch 2 [132/172] - loss: 0.3255
Epoch 2 [133/172] - loss: 0.1559
Epoch 2 [134/172] - loss: 0.1411
Epoch 2 [135/172] - loss: 0.4853
Epoch 2 [136/172] - loss: 0.1308
Epoch 2 [137/172] - loss: 0.1323
Epoch 2 [138/172] - loss: 0.1830
Epoch 2 [139/172] - loss: 0.2373
Epoch 2 [140/172] - loss: 0.1338, acc: 0.9688
Epoch 2 [141/172] - loss: 0.2602
Epoch 2 [142/172] - loss: 0.2095
Epoch 2 [143/172] - loss: 0.2002
Epoch 2 [144/172] - loss: 0.1880
Epoch 2 [145/172] - loss: 0.8213
Epoch 2 [146/172] - loss: 0.1418
Epoch 2 [147/172] - loss: 0.2498
Epoch 2 [148/172] - loss: 0.3962
Epoch 2 [149/172] - loss: 0.3522
Epoch 2 [150/172] - loss: 0.2066, acc: 0.9062
Epoch 2 [151/172] - loss: 0.2844
Epoch 2 [152/172] - loss: 0.1888
Epoch 2 [153/172] - loss: 0.2166
Epoch 2 [154/172] - loss: 0.1619
Epoch 2 [155/172] - loss: 0.2356
Epoch 2 [156/172] - loss: 0.1730
Epoch 2 [157/172] - loss: 0.1673
Epoch 2 [158/172] - loss: 0.2302
Epoch 2 [159/172] - loss: 0.2977
Epoch 2 [160/172] - loss: 0.1820, acc: 0.8750
Epoch 2 [161/172] - loss: 0.1941
Epoch 2 [162/172] - loss: 0.1034
Epoch 2 [163/172] - loss: 0.2489
Epoch 2 [164/172] - loss: 0.2762
Epoch 2 [165/172] - loss: 0.2343
Epoch 2 [166/172] - loss: 0.4689
Epoch 2 [167/172] - loss: 0.4273
Epoch 2 [168/172] - loss: 0.1190
Epoch 2 [169/172] - loss: 0.1739
Epoch 2 [170/172] - loss: 0.1615, acc: 0.9062
Epoch 2 [171/172] - loss: 0.3056
Epoch 2 [172/172] - loss: 0.4787

类别准确率:
positive: 0.7559 (353/467)
neutral: 0.6145 (51/83)
negative: 0.4280 (107/250)

Epoch 2/10
Train Loss: 0.2543, Train Acc: 0.8828
Val Loss: 0.8323, Val Acc: 0.6388
Epoch 3 [1/172] - loss: 0.2104, acc: 0.8750
Epoch 3 [2/172] - loss: 0.1809
Epoch 3 [3/172] - loss: 0.1098
Epoch 3 [4/172] - loss: 0.1025
Epoch 3 [5/172] - loss: 0.1459
Epoch 3 [6/172] - loss: 0.1637
Epoch 3 [7/172] - loss: 0.0876
Epoch 3 [8/172] - loss: 0.1758
Epoch 3 [9/172] - loss: 0.1169
Epoch 3 [10/172] - loss: 0.1160, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1030
Epoch 3 [12/172] - loss: 0.1005
Epoch 3 [13/172] - loss: 0.1074
Epoch 3 [14/172] - loss: 0.0798
Epoch 3 [15/172] - loss: 0.1628
Epoch 3 [16/172] - loss: 0.3115
Epoch 3 [17/172] - loss: 0.1131
Epoch 3 [18/172] - loss: 0.2608
Epoch 3 [19/172] - loss: 0.1763
Epoch 3 [20/172] - loss: 0.0982, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1799
Epoch 3 [22/172] - loss: 0.3176
Epoch 3 [23/172] - loss: 0.0892
Epoch 3 [24/172] - loss: 0.1202
Epoch 3 [25/172] - loss: 0.0816
Epoch 3 [26/172] - loss: 0.0881
Epoch 3 [27/172] - loss: 0.1390
Epoch 3 [28/172] - loss: 0.1012
Epoch 3 [29/172] - loss: 0.4400
Epoch 3 [30/172] - loss: 0.2489, acc: 0.9062
Epoch 3 [31/172] - loss: 0.1047
Epoch 3 [32/172] - loss: 0.1669
Epoch 3 [33/172] - loss: 0.0668
Epoch 3 [34/172] - loss: 0.1711
Epoch 3 [35/172] - loss: 0.1014
Epoch 3 [36/172] - loss: 0.0946
Epoch 3 [37/172] - loss: 0.1193
Epoch 3 [38/172] - loss: 0.1146
Epoch 3 [39/172] - loss: 0.0599
Epoch 3 [40/172] - loss: 0.1141, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1201
Epoch 3 [42/172] - loss: 0.2360
Epoch 3 [43/172] - loss: 0.0871
Epoch 3 [44/172] - loss: 0.0651
Epoch 3 [45/172] - loss: 0.1007
Epoch 3 [46/172] - loss: 0.1008
Epoch 3 [47/172] - loss: 0.0692
Epoch 3 [48/172] - loss: 0.1963
Epoch 3 [49/172] - loss: 0.0753
Epoch 3 [50/172] - loss: 0.0796, acc: 1.0000
Epoch 3 [51/172] - loss: 0.1536
Epoch 3 [52/172] - loss: 0.1314
Epoch 3 [53/172] - loss: 0.1018
Epoch 3 [54/172] - loss: 0.2645
Epoch 3 [55/172] - loss: 0.1744
Epoch 3 [56/172] - loss: 0.0782

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.4108, log_difficulty=0.3441, weight=2.7207
neutral: count=3923.0, difficulty=0.3367, log_difficulty=0.2902, weight=2.4511
negative: count=4382.0, difficulty=0.4029, log_difficulty=0.3385, weight=2.6925

当前batch的pt分布：
positive: min=0.5942, max=0.9428, mean=0.8197
neutral: min=0.0219, max=0.9612, mean=0.7353
negative: min=0.8625, max=0.9880, mean=0.9353

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 1.0000
neutral 准确率: 0.8125
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3335
焦点损失: 0.1380
边界损失: 0.2493
总损失: 0.3167
Epoch 3 [57/172] - loss: 0.3167
Epoch 3 [58/172] - loss: 0.0837
Epoch 3 [59/172] - loss: 0.1781
Epoch 3 [60/172] - loss: 0.0877, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1279
Epoch 3 [62/172] - loss: 0.0813
Epoch 3 [63/172] - loss: 0.0681
Epoch 3 [64/172] - loss: 0.1307
Epoch 3 [65/172] - loss: 0.0874
Epoch 3 [66/172] - loss: 0.1302
Epoch 3 [67/172] - loss: 0.1064
Epoch 3 [68/172] - loss: 0.1221
Epoch 3 [69/172] - loss: 0.1536
Epoch 3 [70/172] - loss: 0.0575, acc: 1.0000
Epoch 3 [71/172] - loss: 0.0819
Epoch 3 [72/172] - loss: 0.2474
Epoch 3 [73/172] - loss: 0.0914
Epoch 3 [74/172] - loss: 0.2152
Epoch 3 [75/172] - loss: 0.1109
Epoch 3 [76/172] - loss: 0.0559
Epoch 3 [77/172] - loss: 0.0789
Epoch 3 [78/172] - loss: 0.2263
Epoch 3 [79/172] - loss: 0.0763
Epoch 3 [80/172] - loss: 0.1364, acc: 0.9062
Epoch 3 [81/172] - loss: 0.1080
Epoch 3 [82/172] - loss: 0.1727
Epoch 3 [83/172] - loss: 0.0697
Epoch 3 [84/172] - loss: 0.0659
Epoch 3 [85/172] - loss: 0.1234
Epoch 3 [86/172] - loss: 0.0750
Epoch 3 [87/172] - loss: 0.1611
Epoch 3 [88/172] - loss: 0.0915
Epoch 3 [89/172] - loss: 0.0590
Epoch 3 [90/172] - loss: 0.0753, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1608
Epoch 3 [92/172] - loss: 0.1595
Epoch 3 [93/172] - loss: 0.1541
Epoch 3 [94/172] - loss: 0.1437
Epoch 3 [95/172] - loss: 0.0655
Epoch 3 [96/172] - loss: 0.1055
Epoch 3 [97/172] - loss: 0.1466
Epoch 3 [98/172] - loss: 0.1500
Epoch 3 [99/172] - loss: 0.0692
Epoch 3 [100/172] - loss: 0.0731, acc: 0.9688
Epoch 3 [101/172] - loss: 0.1363
Epoch 3 [102/172] - loss: 0.1568
Epoch 3 [103/172] - loss: 0.1355
Epoch 3 [104/172] - loss: 0.0954
Epoch 3 [105/172] - loss: 0.1000
Epoch 3 [106/172] - loss: 0.0706
Epoch 3 [107/172] - loss: 0.1005
Epoch 3 [108/172] - loss: 0.0619
Epoch 3 [109/172] - loss: 0.0882
Epoch 3 [110/172] - loss: 0.0735, acc: 1.0000
Epoch 3 [111/172] - loss: 0.1927
Epoch 3 [112/172] - loss: 0.0910
Epoch 3 [113/172] - loss: 0.0736
Epoch 3 [114/172] - loss: 0.1228
Epoch 3 [115/172] - loss: 0.1558
Epoch 3 [116/172] - loss: 0.0757
Epoch 3 [117/172] - loss: 0.1607
Epoch 3 [118/172] - loss: 0.0610
Epoch 3 [119/172] - loss: 0.1038
Epoch 3 [120/172] - loss: 0.2260, acc: 0.9375
Epoch 3 [121/172] - loss: 0.2208
Epoch 3 [122/172] - loss: 0.0891
Epoch 3 [123/172] - loss: 0.2169
Epoch 3 [124/172] - loss: 0.0736
Epoch 3 [125/172] - loss: 0.2778
Epoch 3 [126/172] - loss: 0.1578
Epoch 3 [127/172] - loss: 0.1264
Epoch 3 [128/172] - loss: 0.0693
Epoch 3 [129/172] - loss: 0.1148
Epoch 3 [130/172] - loss: 0.0940, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1710
Epoch 3 [132/172] - loss: 0.0759
Epoch 3 [133/172] - loss: 0.1064
Epoch 3 [134/172] - loss: 0.0648
Epoch 3 [135/172] - loss: 0.0853
Epoch 3 [136/172] - loss: 0.0846
Epoch 3 [137/172] - loss: 0.1144
Epoch 3 [138/172] - loss: 0.0800
Epoch 3 [139/172] - loss: 0.1536
Epoch 3 [140/172] - loss: 0.1383, acc: 0.9688
Epoch 3 [141/172] - loss: 0.2226
Epoch 3 [142/172] - loss: 0.1440
Epoch 3 [143/172] - loss: 0.0585
Epoch 3 [144/172] - loss: 0.2512
Epoch 3 [145/172] - loss: 0.0867
Epoch 3 [146/172] - loss: 0.1237
Epoch 3 [147/172] - loss: 0.0699
Epoch 3 [148/172] - loss: 0.2469
Epoch 3 [149/172] - loss: 0.1608
Epoch 3 [150/172] - loss: 0.1548, acc: 0.9062
Epoch 3 [151/172] - loss: 0.1777
Epoch 3 [152/172] - loss: 0.2330
Epoch 3 [153/172] - loss: 0.0877
Epoch 3 [154/172] - loss: 0.0753
Epoch 3 [155/172] - loss: 0.0601
Epoch 3 [156/172] - loss: 0.0992

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3646, log_difficulty=0.3109, weight=2.5544
neutral: count=4903.0, difficulty=0.2912, log_difficulty=0.2556, weight=2.2778
negative: count=5500.0, difficulty=0.3585, log_difficulty=0.3064, weight=2.5318

当前batch的pt分布：
positive: min=0.7262, max=0.9743, mean=0.8857
neutral: min=0.6244, max=0.9925, mean=0.9242
negative: min=0.8307, max=0.9835, mean=0.8862

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1106
焦点损失: 0.0027
边界损失: 0.1934
总损失: 0.0531
Epoch 3 [157/172] - loss: 0.0531
Epoch 3 [158/172] - loss: 0.2471
Epoch 3 [159/172] - loss: 0.0679
Epoch 3 [160/172] - loss: 0.1819, acc: 0.9062
Epoch 3 [161/172] - loss: 0.2212
Epoch 3 [162/172] - loss: 0.0937
Epoch 3 [163/172] - loss: 0.3425
Epoch 3 [164/172] - loss: 0.0981
Epoch 3 [165/172] - loss: 0.0963
Epoch 3 [166/172] - loss: 0.0856
Epoch 3 [167/172] - loss: 0.0530
Epoch 3 [168/172] - loss: 0.0685
Epoch 3 [169/172] - loss: 0.0690
Epoch 3 [170/172] - loss: 0.1562, acc: 0.9375
Epoch 3 [171/172] - loss: 0.0650
Epoch 3 [172/172] - loss: 0.0613

类别准确率:
positive: 0.8887 (415/467)
neutral: 0.1566 (13/83)
negative: 0.6240 (156/250)

Epoch 3/10
Train Loss: 0.1225, Train Acc: 0.9657
Val Loss: 0.7337, Val Acc: 0.7300
Epoch 4 [1/172] - loss: 0.0520, acc: 1.0000
Epoch 4 [2/172] - loss: 0.0948
Epoch 4 [3/172] - loss: 0.0847
Epoch 4 [4/172] - loss: 0.0744
Epoch 4 [5/172] - loss: 0.0658
Epoch 4 [6/172] - loss: 0.0630
Epoch 4 [7/172] - loss: 0.0592
Epoch 4 [8/172] - loss: 0.0482
Epoch 4 [9/172] - loss: 0.2825
Epoch 4 [10/172] - loss: 0.0967, acc: 0.9375
Epoch 4 [11/172] - loss: 0.0561
Epoch 4 [12/172] - loss: 0.1553
Epoch 4 [13/172] - loss: 0.1094
Epoch 4 [14/172] - loss: 0.1244
Epoch 4 [15/172] - loss: 0.0662
Epoch 4 [16/172] - loss: 0.0469
Epoch 4 [17/172] - loss: 0.0645
Epoch 4 [18/172] - loss: 0.0692
Epoch 4 [19/172] - loss: 0.0705
Epoch 4 [20/172] - loss: 0.0723, acc: 0.9688
Epoch 4 [21/172] - loss: 0.1379
Epoch 4 [22/172] - loss: 0.0501
Epoch 4 [23/172] - loss: 0.0824
Epoch 4 [24/172] - loss: 0.0496
Epoch 4 [25/172] - loss: 0.0547
Epoch 4 [26/172] - loss: 0.2660
Epoch 4 [27/172] - loss: 0.0509
Epoch 4 [28/172] - loss: 0.0964
Epoch 4 [29/172] - loss: 0.0505
Epoch 4 [30/172] - loss: 0.0830, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1191
Epoch 4 [32/172] - loss: 0.1020
Epoch 4 [33/172] - loss: 0.0607
Epoch 4 [34/172] - loss: 0.0477
Epoch 4 [35/172] - loss: 0.1083
Epoch 4 [36/172] - loss: 0.1135
Epoch 4 [37/172] - loss: 0.0437
Epoch 4 [38/172] - loss: 0.0894
Epoch 4 [39/172] - loss: 0.3537
Epoch 4 [40/172] - loss: 0.1723, acc: 0.9375
Epoch 4 [41/172] - loss: 0.0719
Epoch 4 [42/172] - loss: 0.2442
Epoch 4 [43/172] - loss: 0.1844
Epoch 4 [44/172] - loss: 0.0623
Epoch 4 [45/172] - loss: 0.0718
Epoch 4 [46/172] - loss: 0.0778
Epoch 4 [47/172] - loss: 0.0654
Epoch 4 [48/172] - loss: 0.0583
Epoch 4 [49/172] - loss: 0.2284
Epoch 4 [50/172] - loss: 0.0510, acc: 1.0000
Epoch 4 [51/172] - loss: 0.0614
Epoch 4 [52/172] - loss: 0.1955
Epoch 4 [53/172] - loss: 0.0984
Epoch 4 [54/172] - loss: 0.0914
Epoch 4 [55/172] - loss: 0.2610
Epoch 4 [56/172] - loss: 0.1160
Epoch 4 [57/172] - loss: 0.0827
Epoch 4 [58/172] - loss: 0.0956
Epoch 4 [59/172] - loss: 0.0583
Epoch 4 [60/172] - loss: 0.0551, acc: 1.0000
Epoch 4 [61/172] - loss: 0.0587
Epoch 4 [62/172] - loss: 0.1840
Epoch 4 [63/172] - loss: 0.0596
Epoch 4 [64/172] - loss: 0.0551
Epoch 4 [65/172] - loss: 0.0838
Epoch 4 [66/172] - loss: 0.0627
Epoch 4 [67/172] - loss: 0.0715
Epoch 4 [68/172] - loss: 0.0904
Epoch 4 [69/172] - loss: 0.0630
Epoch 4 [70/172] - loss: 0.0513, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0631
Epoch 4 [72/172] - loss: 0.0635
Epoch 4 [73/172] - loss: 0.0529
Epoch 4 [74/172] - loss: 0.3336
Epoch 4 [75/172] - loss: 0.1370
Epoch 4 [76/172] - loss: 0.0486
Epoch 4 [77/172] - loss: 0.1335
Epoch 4 [78/172] - loss: 0.0781
Epoch 4 [79/172] - loss: 0.0455
Epoch 4 [80/172] - loss: 0.1050, acc: 0.9688
Epoch 4 [81/172] - loss: 0.0918
Epoch 4 [82/172] - loss: 0.0903
Epoch 4 [83/172] - loss: 0.0519
Epoch 4 [84/172] - loss: 0.0516

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3259, log_difficulty=0.2821, weight=2.4104
neutral: count=5865.0, difficulty=0.2609, log_difficulty=0.2318, weight=2.1591
negative: count=6629.0, difficulty=0.3199, log_difficulty=0.2775, weight=2.3876

当前batch的pt分布：
positive: min=0.4800, max=0.9504, mean=0.8028
neutral: min=0.6894, max=0.9967, mean=0.9296
negative: min=0.1469, max=0.9871, mean=0.8559

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.2124
焦点损失: 0.0548
边界损失: 0.2148
总损失: 0.1519
Epoch 4 [85/172] - loss: 0.1519
Epoch 4 [86/172] - loss: 0.0862
Epoch 4 [87/172] - loss: 0.2180
Epoch 4 [88/172] - loss: 0.0515
Epoch 4 [89/172] - loss: 0.0627
Epoch 4 [90/172] - loss: 0.0498, acc: 1.0000
Epoch 4 [91/172] - loss: 0.2323
Epoch 4 [92/172] - loss: 0.1919
Epoch 4 [93/172] - loss: 0.0536
Epoch 4 [94/172] - loss: 0.0462
Epoch 4 [95/172] - loss: 0.1088
Epoch 4 [96/172] - loss: 0.0806
Epoch 4 [97/172] - loss: 0.0661
Epoch 4 [98/172] - loss: 0.0518
Epoch 4 [99/172] - loss: 0.1341
Epoch 4 [100/172] - loss: 0.0886, acc: 0.9375
Epoch 4 [101/172] - loss: 0.0799
Epoch 4 [102/172] - loss: 0.1622
Epoch 4 [103/172] - loss: 0.1528
Epoch 4 [104/172] - loss: 0.1164
Epoch 4 [105/172] - loss: 0.1030
Epoch 4 [106/172] - loss: 0.1342
Epoch 4 [107/172] - loss: 0.2400
Epoch 4 [108/172] - loss: 0.1034
Epoch 4 [109/172] - loss: 0.0600
Epoch 4 [110/172] - loss: 0.2786, acc: 0.9062
Epoch 4 [111/172] - loss: 0.0504
Epoch 4 [112/172] - loss: 0.0505
Epoch 4 [113/172] - loss: 0.0666
Epoch 4 [114/172] - loss: 0.0747
Epoch 4 [115/172] - loss: 0.1083
Epoch 4 [116/172] - loss: 0.0777
Epoch 4 [117/172] - loss: 0.0583
Epoch 4 [118/172] - loss: 0.1399
Epoch 4 [119/172] - loss: 0.1448
Epoch 4 [120/172] - loss: 0.2311, acc: 0.9688
Epoch 4 [121/172] - loss: 0.1373
Epoch 4 [122/172] - loss: 0.1453
Epoch 4 [123/172] - loss: 0.0624
Epoch 4 [124/172] - loss: 0.0533
Epoch 4 [125/172] - loss: 0.0627
Epoch 4 [126/172] - loss: 0.0980
Epoch 4 [127/172] - loss: 0.0698
Epoch 4 [128/172] - loss: 0.1170
Epoch 4 [129/172] - loss: 0.0451
Epoch 4 [130/172] - loss: 0.0628, acc: 0.9688
Epoch 4 [131/172] - loss: 0.0481
Epoch 4 [132/172] - loss: 0.0635
Epoch 4 [133/172] - loss: 0.1571
Epoch 4 [134/172] - loss: 0.1407
Epoch 4 [135/172] - loss: 0.1493
Epoch 4 [136/172] - loss: 0.1961
Epoch 4 [137/172] - loss: 0.0837
Epoch 4 [138/172] - loss: 0.0657
Epoch 4 [139/172] - loss: 0.0466
Epoch 4 [140/172] - loss: 0.0826, acc: 0.9375
Epoch 4 [141/172] - loss: 0.1703
Epoch 4 [142/172] - loss: 0.1104
Epoch 4 [143/172] - loss: 0.0539
Epoch 4 [144/172] - loss: 0.0687
Epoch 4 [145/172] - loss: 0.0906
Epoch 4 [146/172] - loss: 0.0701
Epoch 4 [147/172] - loss: 0.1260
Epoch 4 [148/172] - loss: 0.0812
Epoch 4 [149/172] - loss: 0.0568
Epoch 4 [150/172] - loss: 0.1153, acc: 0.9375
Epoch 4 [151/172] - loss: 0.2029
Epoch 4 [152/172] - loss: 0.0517
Epoch 4 [153/172] - loss: 0.0450
Epoch 4 [154/172] - loss: 0.1260
Epoch 4 [155/172] - loss: 0.0906
Epoch 4 [156/172] - loss: 0.0748
Epoch 4 [157/172] - loss: 0.1109
Epoch 4 [158/172] - loss: 0.0923
Epoch 4 [159/172] - loss: 0.0576
Epoch 4 [160/172] - loss: 0.0713, acc: 1.0000
Epoch 4 [161/172] - loss: 0.0802
Epoch 4 [162/172] - loss: 0.0620
Epoch 4 [163/172] - loss: 0.0681
Epoch 4 [164/172] - loss: 0.0630
Epoch 4 [165/172] - loss: 0.1188
Epoch 4 [166/172] - loss: 0.0560
Epoch 4 [167/172] - loss: 0.1732
Epoch 4 [168/172] - loss: 0.0590
Epoch 4 [169/172] - loss: 0.1185
Epoch 4 [170/172] - loss: 0.1203, acc: 0.9375
Epoch 4 [171/172] - loss: 0.1053
Epoch 4 [172/172] - loss: 0.1182

类别准确率:
positive: 0.9251 (432/467)
neutral: 0.2892 (24/83)
negative: 0.5040 (126/250)

Epoch 4/10
Train Loss: 0.0922, Train Acc: 0.9717
Val Loss: 0.7451, Val Acc: 0.7275
Epoch 5 [1/172] - loss: 0.0484, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0708
Epoch 5 [3/172] - loss: 0.0685
Epoch 5 [4/172] - loss: 0.0873
Epoch 5 [5/172] - loss: 0.0456
Epoch 5 [6/172] - loss: 0.0747
Epoch 5 [7/172] - loss: 0.1170
Epoch 5 [8/172] - loss: 0.0934
Epoch 5 [9/172] - loss: 0.1002
Epoch 5 [10/172] - loss: 0.0502, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1353
Epoch 5 [12/172] - loss: 0.0706

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2980, log_difficulty=0.2608, weight=2.3041
neutral: count=6845.0, difficulty=0.2371, log_difficulty=0.2127, weight=2.0637
negative: count=7694.0, difficulty=0.2951, log_difficulty=0.2586, weight=2.2930

当前batch的pt分布：
positive: min=0.2394, max=0.9888, mean=0.7892
neutral: min=0.9301, max=0.9964, mean=0.9761
negative: min=0.7739, max=0.9744, mean=0.9168

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8571
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1661
焦点损失: 0.0355
边界损失: 0.2000
总损失: 0.1113
Epoch 5 [13/172] - loss: 0.1113
Epoch 5 [14/172] - loss: 0.1752
Epoch 5 [15/172] - loss: 0.0437
Epoch 5 [16/172] - loss: 0.0496
Epoch 5 [17/172] - loss: 0.0877
Epoch 5 [18/172] - loss: 0.0474
Epoch 5 [19/172] - loss: 0.0863
Epoch 5 [20/172] - loss: 0.1238, acc: 0.9375
Epoch 5 [21/172] - loss: 0.1706
Epoch 5 [22/172] - loss: 0.1872
Epoch 5 [23/172] - loss: 0.0459
Epoch 5 [24/172] - loss: 0.0533
Epoch 5 [25/172] - loss: 0.0473
Epoch 5 [26/172] - loss: 0.0739
Epoch 5 [27/172] - loss: 0.0463
Epoch 5 [28/172] - loss: 0.0458
Epoch 5 [29/172] - loss: 0.0521
Epoch 5 [30/172] - loss: 0.0504, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0551
Epoch 5 [32/172] - loss: 0.0459
Epoch 5 [33/172] - loss: 0.0507
Epoch 5 [34/172] - loss: 0.0557
Epoch 5 [35/172] - loss: 0.0488
Epoch 5 [36/172] - loss: 0.0423
Epoch 5 [37/172] - loss: 0.0597
Epoch 5 [38/172] - loss: 0.0440
Epoch 5 [39/172] - loss: 0.1781
Epoch 5 [40/172] - loss: 0.0502, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0523
Epoch 5 [42/172] - loss: 0.0823
Epoch 5 [43/172] - loss: 0.2089
Epoch 5 [44/172] - loss: 0.0577
Epoch 5 [45/172] - loss: 0.0431
Epoch 5 [46/172] - loss: 0.0640
Epoch 5 [47/172] - loss: 0.0425
Epoch 5 [48/172] - loss: 0.0598
Epoch 5 [49/172] - loss: 0.0649
Epoch 5 [50/172] - loss: 0.1348, acc: 0.9375
Epoch 5 [51/172] - loss: 0.0605
Epoch 5 [52/172] - loss: 0.0559
Epoch 5 [53/172] - loss: 0.0968
Epoch 5 [54/172] - loss: 0.0921
Epoch 5 [55/172] - loss: 0.0493
Epoch 5 [56/172] - loss: 0.0607
Epoch 5 [57/172] - loss: 0.0468
Epoch 5 [58/172] - loss: 0.0555
Epoch 5 [59/172] - loss: 0.0560
Epoch 5 [60/172] - loss: 0.0409, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0623
Epoch 5 [62/172] - loss: 0.0919
Epoch 5 [63/172] - loss: 0.1107
Epoch 5 [64/172] - loss: 0.0508
Epoch 5 [65/172] - loss: 0.0494
Epoch 5 [66/172] - loss: 0.0433
Epoch 5 [67/172] - loss: 0.0501
Epoch 5 [68/172] - loss: 0.0534
Epoch 5 [69/172] - loss: 0.0765
Epoch 5 [70/172] - loss: 0.0507, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0490
Epoch 5 [72/172] - loss: 0.0807
Epoch 5 [73/172] - loss: 0.0942
Epoch 5 [74/172] - loss: 0.1057
Epoch 5 [75/172] - loss: 0.0439
Epoch 5 [76/172] - loss: 0.0482
Epoch 5 [77/172] - loss: 0.0516
Epoch 5 [78/172] - loss: 0.0771
Epoch 5 [79/172] - loss: 0.0469
Epoch 5 [80/172] - loss: 0.0503, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1522
Epoch 5 [82/172] - loss: 0.0724
Epoch 5 [83/172] - loss: 0.0667
Epoch 5 [84/172] - loss: 0.0467
Epoch 5 [85/172] - loss: 0.1740
Epoch 5 [86/172] - loss: 0.0686
Epoch 5 [87/172] - loss: 0.1321
Epoch 5 [88/172] - loss: 0.1140
Epoch 5 [89/172] - loss: 0.0433
Epoch 5 [90/172] - loss: 0.0739, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0432
Epoch 5 [92/172] - loss: 0.0548
Epoch 5 [93/172] - loss: 0.0483
Epoch 5 [94/172] - loss: 0.0512
Epoch 5 [95/172] - loss: 0.0507
Epoch 5 [96/172] - loss: 0.0863
Epoch 5 [97/172] - loss: 0.1806
Epoch 5 [98/172] - loss: 0.0708
Epoch 5 [99/172] - loss: 0.2160
Epoch 5 [100/172] - loss: 0.1114, acc: 0.9375
Epoch 5 [101/172] - loss: 0.0761
Epoch 5 [102/172] - loss: 0.0797
Epoch 5 [103/172] - loss: 0.0806
Epoch 5 [104/172] - loss: 0.1014
Epoch 5 [105/172] - loss: 0.2137
Epoch 5 [106/172] - loss: 0.0633
Epoch 5 [107/172] - loss: 0.0639
Epoch 5 [108/172] - loss: 0.0679
Epoch 5 [109/172] - loss: 0.0570
Epoch 5 [110/172] - loss: 0.0828, acc: 0.9688
Epoch 5 [111/172] - loss: 0.0727
Epoch 5 [112/172] - loss: 0.0513

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2735, log_difficulty=0.2418, weight=2.2089
neutral: count=7825.0, difficulty=0.2162, log_difficulty=0.1957, weight=1.9786
negative: count=8780.0, difficulty=0.2730, log_difficulty=0.2414, weight=2.2069

当前batch的pt分布：
positive: min=0.3837, max=0.9593, mean=0.8162
neutral: min=0.6175, max=0.9851, mean=0.9208
negative: min=0.7830, max=0.9962, mean=0.9491

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1538
焦点损失: 0.0183
边界损失: 0.2115
总损失: 0.0828
Epoch 5 [113/172] - loss: 0.0828
Epoch 5 [114/172] - loss: 0.1402
Epoch 5 [115/172] - loss: 0.1107
Epoch 5 [116/172] - loss: 0.0462
Epoch 5 [117/172] - loss: 0.0450
Epoch 5 [118/172] - loss: 0.0695
Epoch 5 [119/172] - loss: 0.0594
Epoch 5 [120/172] - loss: 0.1068, acc: 0.9375
Epoch 5 [121/172] - loss: 0.0639
Epoch 5 [122/172] - loss: 0.0468
Epoch 5 [123/172] - loss: 0.0828
Epoch 5 [124/172] - loss: 0.0432
Epoch 5 [125/172] - loss: 0.0448
Epoch 5 [126/172] - loss: 0.0462
Epoch 5 [127/172] - loss: 0.0454
Epoch 5 [128/172] - loss: 0.0502
Epoch 5 [129/172] - loss: 0.1682
Epoch 5 [130/172] - loss: 0.0454, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0471
Epoch 5 [132/172] - loss: 0.2771
Epoch 5 [133/172] - loss: 0.1303
Epoch 5 [134/172] - loss: 0.0947
Epoch 5 [135/172] - loss: 0.0549
Epoch 5 [136/172] - loss: 0.0924
Epoch 5 [137/172] - loss: 0.0565
Epoch 5 [138/172] - loss: 0.1469
Epoch 5 [139/172] - loss: 0.1337
Epoch 5 [140/172] - loss: 0.0710, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0605
Epoch 5 [142/172] - loss: 0.0517
Epoch 5 [143/172] - loss: 0.0502
Epoch 5 [144/172] - loss: 0.0425
Epoch 5 [145/172] - loss: 0.0898
Epoch 5 [146/172] - loss: 0.1066
Epoch 5 [147/172] - loss: 0.0616
Epoch 5 [148/172] - loss: 0.0479
Epoch 5 [149/172] - loss: 0.0440
Epoch 5 [150/172] - loss: 0.1487, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0568
Epoch 5 [152/172] - loss: 0.0515
Epoch 5 [153/172] - loss: 0.0444
Epoch 5 [154/172] - loss: 0.0582
Epoch 5 [155/172] - loss: 0.0445
Epoch 5 [156/172] - loss: 0.0568
Epoch 5 [157/172] - loss: 0.0619
Epoch 5 [158/172] - loss: 0.0437
Epoch 5 [159/172] - loss: 0.0503
Epoch 5 [160/172] - loss: 0.0434, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0534
Epoch 5 [162/172] - loss: 0.0652
Epoch 5 [163/172] - loss: 0.0966
Epoch 5 [164/172] - loss: 0.0415
Epoch 5 [165/172] - loss: 0.1525
Epoch 5 [166/172] - loss: 0.0689
Epoch 5 [167/172] - loss: 0.0473
Epoch 5 [168/172] - loss: 0.0462
Epoch 5 [169/172] - loss: 0.0491
Epoch 5 [170/172] - loss: 0.0430, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0628
Epoch 5 [172/172] - loss: 0.0701

类别准确率:
positive: 0.8779 (410/467)
neutral: 0.3133 (26/83)
negative: 0.5280 (132/250)

Epoch 5/10
Train Loss: 0.0622, Train Acc: 0.9919
Val Loss: 0.7973, Val Acc: 0.7100
Epoch 6 [1/172] - loss: 0.0932, acc: 0.9688
Epoch 6 [2/172] - loss: 0.0669
Epoch 6 [3/172] - loss: 0.0400
Epoch 6 [4/172] - loss: 0.0489
Epoch 6 [5/172] - loss: 0.0478
Epoch 6 [6/172] - loss: 0.0442
Epoch 6 [7/172] - loss: 0.1123
Epoch 6 [8/172] - loss: 0.0448
Epoch 6 [9/172] - loss: 0.0420
Epoch 6 [10/172] - loss: 0.0424, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0415
Epoch 6 [12/172] - loss: 0.0484
Epoch 6 [13/172] - loss: 0.0589
Epoch 6 [14/172] - loss: 0.0421
Epoch 6 [15/172] - loss: 0.0429
Epoch 6 [16/172] - loss: 0.2093
Epoch 6 [17/172] - loss: 0.0411
Epoch 6 [18/172] - loss: 0.0591
Epoch 6 [19/172] - loss: 0.0468
Epoch 6 [20/172] - loss: 0.0496, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0493
Epoch 6 [22/172] - loss: 0.0614
Epoch 6 [23/172] - loss: 0.0440
Epoch 6 [24/172] - loss: 0.0539
Epoch 6 [25/172] - loss: 0.0496
Epoch 6 [26/172] - loss: 0.0454
Epoch 6 [27/172] - loss: 0.0559
Epoch 6 [28/172] - loss: 0.0523
Epoch 6 [29/172] - loss: 0.0454
Epoch 6 [30/172] - loss: 0.0430, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0407
Epoch 6 [32/172] - loss: 0.0422
Epoch 6 [33/172] - loss: 0.0445
Epoch 6 [34/172] - loss: 0.0405
Epoch 6 [35/172] - loss: 0.0437
Epoch 6 [36/172] - loss: 0.0549
Epoch 6 [37/172] - loss: 0.0432
Epoch 6 [38/172] - loss: 0.0402
Epoch 6 [39/172] - loss: 0.0529
Epoch 6 [40/172] - loss: 0.1923, acc: 0.9375

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2525, log_difficulty=0.2251, weight=2.1257
neutral: count=8815.0, difficulty=0.1998, log_difficulty=0.1822, weight=1.9110
negative: count=9870.0, difficulty=0.2528, log_difficulty=0.2254, weight=2.1271

当前batch的pt分布：
positive: min=0.2854, max=0.9896, mean=0.9041
neutral: min=0.9052, max=0.9958, mean=0.9633
negative: min=0.8051, max=0.9885, mean=0.9433

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0825
焦点损失: 0.0192
边界损失: 0.1618
总损失: 0.0710
Epoch 6 [41/172] - loss: 0.0710
Epoch 6 [42/172] - loss: 0.0452
Epoch 6 [43/172] - loss: 0.0503
Epoch 6 [44/172] - loss: 0.0396
Epoch 6 [45/172] - loss: 0.0682
Epoch 6 [46/172] - loss: 0.0474
Epoch 6 [47/172] - loss: 0.0425
Epoch 6 [48/172] - loss: 0.0410
Epoch 6 [49/172] - loss: 0.0426
Epoch 6 [50/172] - loss: 0.1514, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0535
Epoch 6 [52/172] - loss: 0.0545
Epoch 6 [53/172] - loss: 0.0412
Epoch 6 [54/172] - loss: 0.1150
Epoch 6 [55/172] - loss: 0.0450
Epoch 6 [56/172] - loss: 0.0464
Epoch 6 [57/172] - loss: 0.0411
Epoch 6 [58/172] - loss: 0.0413
Epoch 6 [59/172] - loss: 0.0483
Epoch 6 [60/172] - loss: 0.0546, acc: 1.0000
Epoch 6 [61/172] - loss: 0.0451
Epoch 6 [62/172] - loss: 0.1487
Epoch 6 [63/172] - loss: 0.0430
Epoch 6 [64/172] - loss: 0.0883
Epoch 6 [65/172] - loss: 0.0628
Epoch 6 [66/172] - loss: 0.0424
Epoch 6 [67/172] - loss: 0.0425
Epoch 6 [68/172] - loss: 0.0785
Epoch 6 [69/172] - loss: 0.1122
Epoch 6 [70/172] - loss: 0.0449, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0853
Epoch 6 [72/172] - loss: 0.0465
Epoch 6 [73/172] - loss: 0.0584
Epoch 6 [74/172] - loss: 0.0421
Epoch 6 [75/172] - loss: 0.0446
Epoch 6 [76/172] - loss: 0.0423
Epoch 6 [77/172] - loss: 0.0703
Epoch 6 [78/172] - loss: 0.0653
Epoch 6 [79/172] - loss: 0.0445
Epoch 6 [80/172] - loss: 0.0471, acc: 1.0000
Epoch 6 [81/172] - loss: 0.0722
Epoch 6 [82/172] - loss: 0.0602
Epoch 6 [83/172] - loss: 0.0401
Epoch 6 [84/172] - loss: 0.0432
Epoch 6 [85/172] - loss: 0.0563
Epoch 6 [86/172] - loss: 0.0528
Epoch 6 [87/172] - loss: 0.0475
Epoch 6 [88/172] - loss: 0.0633
Epoch 6 [89/172] - loss: 0.0426
Epoch 6 [90/172] - loss: 0.0687, acc: 0.9688
Epoch 6 [91/172] - loss: 0.0397
Epoch 6 [92/172] - loss: 0.0436
Epoch 6 [93/172] - loss: 0.0428
Epoch 6 [94/172] - loss: 0.0555
Epoch 6 [95/172] - loss: 0.0451
Epoch 6 [96/172] - loss: 0.0389
Epoch 6 [97/172] - loss: 0.0561
Epoch 6 [98/172] - loss: 0.0481
Epoch 6 [99/172] - loss: 0.0418
Epoch 6 [100/172] - loss: 0.0437, acc: 1.0000
Epoch 6 [101/172] - loss: 0.0914
Epoch 6 [102/172] - loss: 0.0480
Epoch 6 [103/172] - loss: 0.0494
Epoch 6 [104/172] - loss: 0.0691
Epoch 6 [105/172] - loss: 0.0458
Epoch 6 [106/172] - loss: 0.0524
Epoch 6 [107/172] - loss: 0.0720
Epoch 6 [108/172] - loss: 0.0408
Epoch 6 [109/172] - loss: 0.1222
Epoch 6 [110/172] - loss: 0.0705, acc: 0.9688
Epoch 6 [111/172] - loss: 0.0525
Epoch 6 [112/172] - loss: 0.0454
Epoch 6 [113/172] - loss: 0.0606
Epoch 6 [114/172] - loss: 0.0407
Epoch 6 [115/172] - loss: 0.0748
Epoch 6 [116/172] - loss: 0.0863
Epoch 6 [117/172] - loss: 0.0591
Epoch 6 [118/172] - loss: 0.0455
Epoch 6 [119/172] - loss: 0.0755
Epoch 6 [120/172] - loss: 0.0479, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0764
Epoch 6 [122/172] - loss: 0.0590
Epoch 6 [123/172] - loss: 0.0430
Epoch 6 [124/172] - loss: 0.0403
Epoch 6 [125/172] - loss: 0.0463
Epoch 6 [126/172] - loss: 0.0437
Epoch 6 [127/172] - loss: 0.0699
Epoch 6 [128/172] - loss: 0.0488
Epoch 6 [129/172] - loss: 0.0505
Epoch 6 [130/172] - loss: 0.0555, acc: 0.9688
Epoch 6 [131/172] - loss: 0.0472
Epoch 6 [132/172] - loss: 0.0551
Epoch 6 [133/172] - loss: 0.0961
Epoch 6 [134/172] - loss: 0.0515
Epoch 6 [135/172] - loss: 0.0434
Epoch 6 [136/172] - loss: 0.0413
Epoch 6 [137/172] - loss: 0.0441
Epoch 6 [138/172] - loss: 0.0461
Epoch 6 [139/172] - loss: 0.0434
Epoch 6 [140/172] - loss: 0.0495, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2342, log_difficulty=0.2104, weight=2.0521
neutral: count=9796.0, difficulty=0.1865, log_difficulty=0.1710, weight=1.8551
negative: count=10972.0, difficulty=0.2350, log_difficulty=0.2111, weight=2.0556

当前batch的pt分布：
positive: min=0.9469, max=0.9983, mean=0.9775
neutral: min=0.9611, max=0.9926, mean=0.9740
negative: min=0.8245, max=0.9853, mean=0.9370

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0417
焦点损失: 0.0003
边界损失: 0.1557
总损失: 0.0393
Epoch 6 [141/172] - loss: 0.0393
Epoch 6 [142/172] - loss: 0.0410
Epoch 6 [143/172] - loss: 0.0450
Epoch 6 [144/172] - loss: 0.0482
Epoch 6 [145/172] - loss: 0.0533
Epoch 6 [146/172] - loss: 0.0440
Epoch 6 [147/172] - loss: 0.0441
Epoch 6 [148/172] - loss: 0.0472
Epoch 6 [149/172] - loss: 0.0425
Epoch 6 [150/172] - loss: 0.0405, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0428
Epoch 6 [152/172] - loss: 0.0647
Epoch 6 [153/172] - loss: 0.0401
Epoch 6 [154/172] - loss: 0.0402
Epoch 6 [155/172] - loss: 0.0679
Epoch 6 [156/172] - loss: 0.0822
Epoch 6 [157/172] - loss: 0.0557
Epoch 6 [158/172] - loss: 0.0526
Epoch 6 [159/172] - loss: 0.0720
Epoch 6 [160/172] - loss: 0.0676, acc: 0.9688
Epoch 6 [161/172] - loss: 0.0425
Epoch 6 [162/172] - loss: 0.0444
Epoch 6 [163/172] - loss: 0.0813
Epoch 6 [164/172] - loss: 0.1081
Epoch 6 [165/172] - loss: 0.1833
Epoch 6 [166/172] - loss: 0.0417
Epoch 6 [167/172] - loss: 0.0433
Epoch 6 [168/172] - loss: 0.0405
Epoch 6 [169/172] - loss: 0.0756
Epoch 6 [170/172] - loss: 0.0398, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0420
Epoch 6 [172/172] - loss: 0.0431

类别准确率:
positive: 0.8801 (411/467)
neutral: 0.2771 (23/83)
negative: 0.5400 (135/250)

Epoch 6/10
Train Loss: 0.0646, Train Acc: 0.9798
Val Loss: 0.8105, Val Acc: 0.7113
Early stopping triggered!
Best validation accuracy: 0.7300

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_120321-cesdx723
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.25_Multimodal_iterations_20250118_120320
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/cesdx723
wandb: uploading wandb-summary.json; uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇██
wandb:  train_acc ▁▂▁▄▄▅▆▆▆▅▆▆▆▆▆▇▇▇▇█▇█▇█▇█▇▇████▇███████
wandb: train_loss █▆▅▆▆▃▄▂▄▂▃▂▂▂▁▁▁▂▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1030
wandb:  train_acc 1
wandb: train_loss 0.03979
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.25_Multimodal_iterations_20250118_120320 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/cesdx723
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_120321-cesdx723/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_121236-53ycvxy1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.25_Multimodal_epochs_20250118_121236
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/53ycvxy1
wandb: uploading history steps 0-0, summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▄▅▇█
wandb:  train_acc ▁▅▇▇██
wandb: train_loss █▄▂▁▁▁
wandb:    val_acc ▄▁██▆▇
wandb:   val_loss ▁█▂▂▆▇
wandb: 
wandb: Run summary:
wandb:      epoch 6
wandb:  train_acc 0.9798
wandb: train_loss 0.0646
wandb:    val_acc 0.71125
wandb:   val_loss 0.8105
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.5_dropout0.25_Multimodal_epochs_20250118_121236 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/53ycvxy1
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_121236-53ycvxy1/logs

