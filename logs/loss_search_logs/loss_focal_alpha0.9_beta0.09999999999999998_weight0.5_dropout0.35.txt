=== 命令 ===
python main.py --loss_type focal --alpha 0.9 --beta 0.09999999999999998 --neural_init_weight 0.5 --dropout 0.35 --name loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.35 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.35
text_dim: 128
image_dim: 256
dropout: 0.35
loss_type: focal
alpha: 0.9
beta: 0.09999999999999998
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6837, log_difficulty=0.5210, weight=3.6050
neutral: count=7.0, difficulty=0.7092, log_difficulty=0.5360, weight=3.6802
negative: count=13.0, difficulty=0.6650, log_difficulty=0.5098, weight=3.5490

当前batch的pt分布：
positive: min=0.1688, max=0.5512, mean=0.3163
neutral: min=0.1832, max=0.3900, mean=0.2908
negative: min=0.0776, max=0.5364, mean=0.3350

当前batch准确率：
整体准确率: 0.3125
positive 准确率: 0.3333
neutral 准确率: 0.1429
negative 准确率: 0.3846

损失分量：
基础交叉熵: 1.2042
焦点损失: 0.4507
边界损失: 0.7645
总损失: 1.5364
Epoch 1 [1/172] - loss: 1.5364, acc: 0.3125
Epoch 1 [2/172] - loss: 1.1868
Epoch 1 [3/172] - loss: 1.3896
Epoch 1 [4/172] - loss: 1.7559
Epoch 1 [5/172] - loss: 1.3723
Epoch 1 [6/172] - loss: 1.5368
Epoch 1 [7/172] - loss: 1.5031
Epoch 1 [8/172] - loss: 1.3443
Epoch 1 [9/172] - loss: 1.1472
Epoch 1 [10/172] - loss: 1.4943, acc: 0.2812
Epoch 1 [11/172] - loss: 1.5300
Epoch 1 [12/172] - loss: 1.1003
Epoch 1 [13/172] - loss: 1.4609
Epoch 1 [14/172] - loss: 1.5486
Epoch 1 [15/172] - loss: 1.5809
Epoch 1 [16/172] - loss: 1.4025
Epoch 1 [17/172] - loss: 1.4399
Epoch 1 [18/172] - loss: 1.4946
Epoch 1 [19/172] - loss: 1.1977
Epoch 1 [20/172] - loss: 1.1773, acc: 0.4375
Epoch 1 [21/172] - loss: 1.7626
Epoch 1 [22/172] - loss: 1.0202
Epoch 1 [23/172] - loss: 1.0911
Epoch 1 [24/172] - loss: 1.4069
Epoch 1 [25/172] - loss: 1.2008
Epoch 1 [26/172] - loss: 1.4997
Epoch 1 [27/172] - loss: 1.4908
Epoch 1 [28/172] - loss: 1.2580
Epoch 1 [29/172] - loss: 1.5654
Epoch 1 [30/172] - loss: 1.3252, acc: 0.2188
Epoch 1 [31/172] - loss: 1.3656
Epoch 1 [32/172] - loss: 1.1435
Epoch 1 [33/172] - loss: 1.0823
Epoch 1 [34/172] - loss: 1.4099
Epoch 1 [35/172] - loss: 1.3156
Epoch 1 [36/172] - loss: 1.0894
Epoch 1 [37/172] - loss: 1.2165
Epoch 1 [38/172] - loss: 1.0417
Epoch 1 [39/172] - loss: 1.7758
Epoch 1 [40/172] - loss: 1.1638, acc: 0.4688
Epoch 1 [41/172] - loss: 1.1624
Epoch 1 [42/172] - loss: 1.1359
Epoch 1 [43/172] - loss: 1.1236
Epoch 1 [44/172] - loss: 1.4910
Epoch 1 [45/172] - loss: 1.1855
Epoch 1 [46/172] - loss: 1.0832
Epoch 1 [47/172] - loss: 1.1914
Epoch 1 [48/172] - loss: 1.0603
Epoch 1 [49/172] - loss: 1.1843
Epoch 1 [50/172] - loss: 1.2328, acc: 0.3750
Epoch 1 [51/172] - loss: 1.0455
Epoch 1 [52/172] - loss: 1.2737
Epoch 1 [53/172] - loss: 1.3871
Epoch 1 [54/172] - loss: 1.2655
Epoch 1 [55/172] - loss: 1.3480
Epoch 1 [56/172] - loss: 1.0161
Epoch 1 [57/172] - loss: 1.5750
Epoch 1 [58/172] - loss: 0.8724
Epoch 1 [59/172] - loss: 1.0895
Epoch 1 [60/172] - loss: 1.1431, acc: 0.3438
Epoch 1 [61/172] - loss: 1.0868
Epoch 1 [62/172] - loss: 1.0921
Epoch 1 [63/172] - loss: 1.0823
Epoch 1 [64/172] - loss: 1.0141
Epoch 1 [65/172] - loss: 1.4510
Epoch 1 [66/172] - loss: 1.1859
Epoch 1 [67/172] - loss: 1.0250
Epoch 1 [68/172] - loss: 1.1419
Epoch 1 [69/172] - loss: 1.4293
Epoch 1 [70/172] - loss: 1.1017, acc: 0.4062
Epoch 1 [71/172] - loss: 0.9352
Epoch 1 [72/172] - loss: 1.3445
Epoch 1 [73/172] - loss: 1.0777
Epoch 1 [74/172] - loss: 1.1769
Epoch 1 [75/172] - loss: 0.8117
Epoch 1 [76/172] - loss: 1.0081
Epoch 1 [77/172] - loss: 1.0547
Epoch 1 [78/172] - loss: 0.9301
Epoch 1 [79/172] - loss: 0.8590
Epoch 1 [80/172] - loss: 0.7840, acc: 0.5938
Epoch 1 [81/172] - loss: 0.8158
Epoch 1 [82/172] - loss: 1.3902
Epoch 1 [83/172] - loss: 1.1798
Epoch 1 [84/172] - loss: 1.1315
Epoch 1 [85/172] - loss: 1.1912
Epoch 1 [86/172] - loss: 0.9476
Epoch 1 [87/172] - loss: 0.7088
Epoch 1 [88/172] - loss: 1.3092
Epoch 1 [89/172] - loss: 1.6408
Epoch 1 [90/172] - loss: 1.3383, acc: 0.5000
Epoch 1 [91/172] - loss: 1.0201
Epoch 1 [92/172] - loss: 0.9902
Epoch 1 [93/172] - loss: 1.0041
Epoch 1 [94/172] - loss: 0.7324
Epoch 1 [95/172] - loss: 0.9009
Epoch 1 [96/172] - loss: 0.6786
Epoch 1 [97/172] - loss: 0.9972
Epoch 1 [98/172] - loss: 0.7826
Epoch 1 [99/172] - loss: 1.2665
Epoch 1 [100/172] - loss: 1.3113, acc: 0.5625

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.6331, log_difficulty=0.4905, weight=3.4524
neutral: count=983.0, difficulty=0.6196, log_difficulty=0.4822, weight=3.4110
negative: count=1119.0, difficulty=0.6182, log_difficulty=0.4813, weight=3.4065

当前batch的pt分布：
positive: min=0.2078, max=0.6887, mean=0.4085
neutral: min=0.2707, max=0.6814, mean=0.5009
negative: min=0.1298, max=0.6013, mean=0.3695

当前batch准确率：
整体准确率: 0.5625
positive 准确率: 0.5833
neutral 准确率: 0.7500
negative 准确率: 0.5000

损失分量：
基础交叉熵: 0.9972
焦点损失: 0.3327
边界损失: 0.6787
总损失: 1.0921
Epoch 1 [101/172] - loss: 1.0921
Epoch 1 [102/172] - loss: 0.7813
Epoch 1 [103/172] - loss: 0.9372
Epoch 1 [104/172] - loss: 0.6859
Epoch 1 [105/172] - loss: 1.1191
Epoch 1 [106/172] - loss: 1.0972
Epoch 1 [107/172] - loss: 0.8273
Epoch 1 [108/172] - loss: 0.8467
Epoch 1 [109/172] - loss: 0.9936
Epoch 1 [110/172] - loss: 1.1126, acc: 0.5625
Epoch 1 [111/172] - loss: 1.1663
Epoch 1 [112/172] - loss: 0.6569
Epoch 1 [113/172] - loss: 0.9489
Epoch 1 [114/172] - loss: 0.7667
Epoch 1 [115/172] - loss: 0.8819
Epoch 1 [116/172] - loss: 0.6214
Epoch 1 [117/172] - loss: 1.0773
Epoch 1 [118/172] - loss: 0.8883
Epoch 1 [119/172] - loss: 1.0453
Epoch 1 [120/172] - loss: 0.6578, acc: 0.6562
Epoch 1 [121/172] - loss: 0.8308
Epoch 1 [122/172] - loss: 0.8886
Epoch 1 [123/172] - loss: 0.8261
Epoch 1 [124/172] - loss: 1.0113
Epoch 1 [125/172] - loss: 0.7560
Epoch 1 [126/172] - loss: 0.8265
Epoch 1 [127/172] - loss: 0.6750
Epoch 1 [128/172] - loss: 0.7028
Epoch 1 [129/172] - loss: 0.8656
Epoch 1 [130/172] - loss: 0.6725, acc: 0.6562
Epoch 1 [131/172] - loss: 0.4174
Epoch 1 [132/172] - loss: 0.5958
Epoch 1 [133/172] - loss: 0.9638
Epoch 1 [134/172] - loss: 0.6947
Epoch 1 [135/172] - loss: 0.6596
Epoch 1 [136/172] - loss: 1.0082
Epoch 1 [137/172] - loss: 0.9069
Epoch 1 [138/172] - loss: 0.7569
Epoch 1 [139/172] - loss: 0.4943
Epoch 1 [140/172] - loss: 0.5998, acc: 0.6250
Epoch 1 [141/172] - loss: 0.5850
Epoch 1 [142/172] - loss: 0.6289
Epoch 1 [143/172] - loss: 0.9131
Epoch 1 [144/172] - loss: 0.4979
Epoch 1 [145/172] - loss: 0.9844
Epoch 1 [146/172] - loss: 0.7120
Epoch 1 [147/172] - loss: 1.0488
Epoch 1 [148/172] - loss: 0.9469
Epoch 1 [149/172] - loss: 0.4981
Epoch 1 [150/172] - loss: 0.6967, acc: 0.7500
Epoch 1 [151/172] - loss: 0.8889
Epoch 1 [152/172] - loss: 0.6246
Epoch 1 [153/172] - loss: 0.7516
Epoch 1 [154/172] - loss: 0.9745
Epoch 1 [155/172] - loss: 0.7751
Epoch 1 [156/172] - loss: 0.9573
Epoch 1 [157/172] - loss: 0.4059
Epoch 1 [158/172] - loss: 0.5742
Epoch 1 [159/172] - loss: 0.9446
Epoch 1 [160/172] - loss: 0.8830, acc: 0.5625
Epoch 1 [161/172] - loss: 0.5330
Epoch 1 [162/172] - loss: 0.7994
Epoch 1 [163/172] - loss: 0.8112
Epoch 1 [164/172] - loss: 0.7541
Epoch 1 [165/172] - loss: 0.7404
Epoch 1 [166/172] - loss: 0.6691
Epoch 1 [167/172] - loss: 0.4709
Epoch 1 [168/172] - loss: 0.8064
Epoch 1 [169/172] - loss: 0.5177
Epoch 1 [170/172] - loss: 0.6217, acc: 0.5938
Epoch 1 [171/172] - loss: 0.4306
Epoch 1 [172/172] - loss: 0.8881

类别准确率:
positive: 0.6724 (314/467)
neutral: 0.4337 (36/83)
negative: 0.8200 (205/250)

Epoch 1/10
Train Loss: 0.6781, Train Acc: 0.6848
Val Loss: 0.7136, Val Acc: 0.6937
Epoch 2 [1/172] - loss: 0.6349, acc: 0.7188
Epoch 2 [2/172] - loss: 0.5173
Epoch 2 [3/172] - loss: 0.6828
Epoch 2 [4/172] - loss: 0.7412
Epoch 2 [5/172] - loss: 0.8813
Epoch 2 [6/172] - loss: 0.8631
Epoch 2 [7/172] - loss: 0.6180
Epoch 2 [8/172] - loss: 0.5051
Epoch 2 [9/172] - loss: 0.5295
Epoch 2 [10/172] - loss: 0.6156, acc: 0.7812
Epoch 2 [11/172] - loss: 0.4544
Epoch 2 [12/172] - loss: 0.5356
Epoch 2 [13/172] - loss: 0.7448
Epoch 2 [14/172] - loss: 0.3794
Epoch 2 [15/172] - loss: 0.6290
Epoch 2 [16/172] - loss: 0.5988
Epoch 2 [17/172] - loss: 0.4367
Epoch 2 [18/172] - loss: 0.7626
Epoch 2 [19/172] - loss: 0.3604
Epoch 2 [20/172] - loss: 0.3323, acc: 0.8750
Epoch 2 [21/172] - loss: 0.2915
Epoch 2 [22/172] - loss: 0.2294
Epoch 2 [23/172] - loss: 0.2817
Epoch 2 [24/172] - loss: 0.6975
Epoch 2 [25/172] - loss: 0.4993
Epoch 2 [26/172] - loss: 0.4416
Epoch 2 [27/172] - loss: 0.5116
Epoch 2 [28/172] - loss: 0.4959

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5730, log_difficulty=0.4530, weight=3.2650
neutral: count=1952.0, difficulty=0.5375, log_difficulty=0.4302, weight=3.1509
negative: count=2216.0, difficulty=0.5639, log_difficulty=0.4472, weight=3.2359

当前batch的pt分布：
positive: min=0.2858, max=0.8234, mean=0.5378
neutral: min=0.2610, max=0.8745, mean=0.5724
negative: min=0.2423, max=0.9210, mean=0.5126

当前batch准确率：
整体准确率: 0.7500
positive 准确率: 0.5556
neutral 准确率: 0.9091
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.6784
焦点损失: 0.1538
边界损失: 0.5326
总损失: 0.4991
Epoch 2 [29/172] - loss: 0.4991
Epoch 2 [30/172] - loss: 0.4173, acc: 0.7812
Epoch 2 [31/172] - loss: 0.3671
Epoch 2 [32/172] - loss: 0.4224
Epoch 2 [33/172] - loss: 0.3285
Epoch 2 [34/172] - loss: 0.6518
Epoch 2 [35/172] - loss: 0.4377
Epoch 2 [36/172] - loss: 0.7334
Epoch 2 [37/172] - loss: 0.7218
Epoch 2 [38/172] - loss: 0.4422
Epoch 2 [39/172] - loss: 0.6125
Epoch 2 [40/172] - loss: 0.6616, acc: 0.7188
Epoch 2 [41/172] - loss: 0.4209
Epoch 2 [42/172] - loss: 0.3643
Epoch 2 [43/172] - loss: 0.3860
Epoch 2 [44/172] - loss: 0.4469
Epoch 2 [45/172] - loss: 0.4459
Epoch 2 [46/172] - loss: 0.4867
Epoch 2 [47/172] - loss: 0.4364
Epoch 2 [48/172] - loss: 0.4129
Epoch 2 [49/172] - loss: 0.4286
Epoch 2 [50/172] - loss: 0.5593, acc: 0.7812
Epoch 2 [51/172] - loss: 0.4987
Epoch 2 [52/172] - loss: 0.4814
Epoch 2 [53/172] - loss: 0.2605
Epoch 2 [54/172] - loss: 0.1875
Epoch 2 [55/172] - loss: 0.2761
Epoch 2 [56/172] - loss: 0.3185
Epoch 2 [57/172] - loss: 0.2201
Epoch 2 [58/172] - loss: 0.4419
Epoch 2 [59/172] - loss: 0.5692
Epoch 2 [60/172] - loss: 0.4195, acc: 0.7812
Epoch 2 [61/172] - loss: 0.1636
Epoch 2 [62/172] - loss: 0.2644
Epoch 2 [63/172] - loss: 0.7047
Epoch 2 [64/172] - loss: 0.4881
Epoch 2 [65/172] - loss: 0.3538
Epoch 2 [66/172] - loss: 0.4495
Epoch 2 [67/172] - loss: 0.2652
Epoch 2 [68/172] - loss: 0.5702
Epoch 2 [69/172] - loss: 0.4516
Epoch 2 [70/172] - loss: 0.4692, acc: 0.7500
Epoch 2 [71/172] - loss: 0.4820
Epoch 2 [72/172] - loss: 0.4206
Epoch 2 [73/172] - loss: 0.3723
Epoch 2 [74/172] - loss: 0.2796
Epoch 2 [75/172] - loss: 0.3143
Epoch 2 [76/172] - loss: 0.3600
Epoch 2 [77/172] - loss: 0.3603
Epoch 2 [78/172] - loss: 0.4270
Epoch 2 [79/172] - loss: 0.4654
Epoch 2 [80/172] - loss: 0.2820, acc: 0.8438
Epoch 2 [81/172] - loss: 0.2965
Epoch 2 [82/172] - loss: 0.3336
Epoch 2 [83/172] - loss: 0.3708
Epoch 2 [84/172] - loss: 0.4104
Epoch 2 [85/172] - loss: 0.3714
Epoch 2 [86/172] - loss: 0.2398
Epoch 2 [87/172] - loss: 0.8547
Epoch 2 [88/172] - loss: 0.2333
Epoch 2 [89/172] - loss: 0.1813
Epoch 2 [90/172] - loss: 0.6364, acc: 0.5938
Epoch 2 [91/172] - loss: 0.3786
Epoch 2 [92/172] - loss: 0.4464
Epoch 2 [93/172] - loss: 0.3475
Epoch 2 [94/172] - loss: 0.2263
Epoch 2 [95/172] - loss: 0.5083
Epoch 2 [96/172] - loss: 0.2580
Epoch 2 [97/172] - loss: 0.2724
Epoch 2 [98/172] - loss: 0.2855
Epoch 2 [99/172] - loss: 0.2644
Epoch 2 [100/172] - loss: 0.3650, acc: 0.8438
Epoch 2 [101/172] - loss: 0.3036
Epoch 2 [102/172] - loss: 0.2823
Epoch 2 [103/172] - loss: 0.3947
Epoch 2 [104/172] - loss: 0.4208
Epoch 2 [105/172] - loss: 0.2338
Epoch 2 [106/172] - loss: 0.2652
Epoch 2 [107/172] - loss: 0.1960
Epoch 2 [108/172] - loss: 0.7391
Epoch 2 [109/172] - loss: 0.2138
Epoch 2 [110/172] - loss: 0.3648, acc: 0.7500
Epoch 2 [111/172] - loss: 0.3316
Epoch 2 [112/172] - loss: 0.1169
Epoch 2 [113/172] - loss: 0.2192
Epoch 2 [114/172] - loss: 0.2523
Epoch 2 [115/172] - loss: 0.3594
Epoch 2 [116/172] - loss: 0.2477
Epoch 2 [117/172] - loss: 0.3718
Epoch 2 [118/172] - loss: 0.2830
Epoch 2 [119/172] - loss: 0.2978
Epoch 2 [120/172] - loss: 0.2624, acc: 0.7812
Epoch 2 [121/172] - loss: 0.1395
Epoch 2 [122/172] - loss: 0.4443
Epoch 2 [123/172] - loss: 0.2741
Epoch 2 [124/172] - loss: 0.2155
Epoch 2 [125/172] - loss: 0.2624
Epoch 2 [126/172] - loss: 0.3309
Epoch 2 [127/172] - loss: 0.2801
Epoch 2 [128/172] - loss: 0.2997

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.5210, log_difficulty=0.4194, weight=3.0968
neutral: count=2949.0, difficulty=0.4564, log_difficulty=0.3759, weight=2.8797
negative: count=3294.0, difficulty=0.5100, log_difficulty=0.4121, weight=3.0604

当前batch的pt分布：
positive: min=0.3282, max=0.7934, mean=0.5968
neutral: min=0.6361, max=0.9670, mean=0.7701
negative: min=0.1199, max=0.8816, mean=0.6174

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8000
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.4631
焦点损失: 0.0893
边界损失: 0.4043
总损失: 0.2866
Epoch 2 [129/172] - loss: 0.2866
Epoch 2 [130/172] - loss: 0.3000, acc: 0.6875
Epoch 2 [131/172] - loss: 0.2794
Epoch 2 [132/172] - loss: 0.2505
Epoch 2 [133/172] - loss: 0.4661
Epoch 2 [134/172] - loss: 0.1841
Epoch 2 [135/172] - loss: 0.4477
Epoch 2 [136/172] - loss: 0.1607
Epoch 2 [137/172] - loss: 0.2106
Epoch 2 [138/172] - loss: 0.2679
Epoch 2 [139/172] - loss: 0.2175
Epoch 2 [140/172] - loss: 0.2463, acc: 0.8438
Epoch 2 [141/172] - loss: 0.1409
Epoch 2 [142/172] - loss: 0.3378
Epoch 2 [143/172] - loss: 0.2671
Epoch 2 [144/172] - loss: 0.3061
Epoch 2 [145/172] - loss: 0.9427
Epoch 2 [146/172] - loss: 0.1741
Epoch 2 [147/172] - loss: 0.2738
Epoch 2 [148/172] - loss: 0.2231
Epoch 2 [149/172] - loss: 0.4423
Epoch 2 [150/172] - loss: 0.3709, acc: 0.7812
Epoch 2 [151/172] - loss: 0.2524
Epoch 2 [152/172] - loss: 0.2971
Epoch 2 [153/172] - loss: 0.2215
Epoch 2 [154/172] - loss: 0.1599
Epoch 2 [155/172] - loss: 0.2453
Epoch 2 [156/172] - loss: 0.1507
Epoch 2 [157/172] - loss: 0.1909
Epoch 2 [158/172] - loss: 0.2139
Epoch 2 [159/172] - loss: 0.2520
Epoch 2 [160/172] - loss: 0.1903, acc: 0.8750
Epoch 2 [161/172] - loss: 0.2264
Epoch 2 [162/172] - loss: 0.1134
Epoch 2 [163/172] - loss: 0.3930
Epoch 2 [164/172] - loss: 0.2328
Epoch 2 [165/172] - loss: 0.4415
Epoch 2 [166/172] - loss: 0.4337
Epoch 2 [167/172] - loss: 0.4504
Epoch 2 [168/172] - loss: 0.1907
Epoch 2 [169/172] - loss: 0.2178
Epoch 2 [170/172] - loss: 0.2348, acc: 0.8750
Epoch 2 [171/172] - loss: 0.3825
Epoch 2 [172/172] - loss: 1.1769

类别准确率:
positive: 0.7730 (361/467)
neutral: 0.4458 (37/83)
negative: 0.6120 (153/250)

Epoch 2/10
Train Loss: 0.3338, Train Acc: 0.8727
Val Loss: 0.7154, Val Acc: 0.6887
Epoch 3 [1/172] - loss: 0.2947, acc: 0.7812
Epoch 3 [2/172] - loss: 0.1509
Epoch 3 [3/172] - loss: 0.1147
Epoch 3 [4/172] - loss: 0.1580
Epoch 3 [5/172] - loss: 0.2339
Epoch 3 [6/172] - loss: 0.0927
Epoch 3 [7/172] - loss: 0.0969
Epoch 3 [8/172] - loss: 0.1199
Epoch 3 [9/172] - loss: 0.0970
Epoch 3 [10/172] - loss: 0.2044, acc: 0.9375
Epoch 3 [11/172] - loss: 0.1174
Epoch 3 [12/172] - loss: 0.1014
Epoch 3 [13/172] - loss: 0.2280
Epoch 3 [14/172] - loss: 0.1006
Epoch 3 [15/172] - loss: 0.1553
Epoch 3 [16/172] - loss: 0.4197
Epoch 3 [17/172] - loss: 0.1895
Epoch 3 [18/172] - loss: 0.2598
Epoch 3 [19/172] - loss: 0.1536
Epoch 3 [20/172] - loss: 0.0852, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1121
Epoch 3 [22/172] - loss: 0.1313
Epoch 3 [23/172] - loss: 0.1973
Epoch 3 [24/172] - loss: 0.1755
Epoch 3 [25/172] - loss: 0.1754
Epoch 3 [26/172] - loss: 0.1172
Epoch 3 [27/172] - loss: 0.1091
Epoch 3 [28/172] - loss: 0.1003
Epoch 3 [29/172] - loss: 0.1449
Epoch 3 [30/172] - loss: 0.1517, acc: 0.9062
Epoch 3 [31/172] - loss: 0.0948
Epoch 3 [32/172] - loss: 0.1070
Epoch 3 [33/172] - loss: 0.0628
Epoch 3 [34/172] - loss: 0.1299
Epoch 3 [35/172] - loss: 0.2009
Epoch 3 [36/172] - loss: 0.1350
Epoch 3 [37/172] - loss: 0.0951
Epoch 3 [38/172] - loss: 0.1361
Epoch 3 [39/172] - loss: 0.0530
Epoch 3 [40/172] - loss: 0.1339, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1250
Epoch 3 [42/172] - loss: 0.2918
Epoch 3 [43/172] - loss: 0.0916
Epoch 3 [44/172] - loss: 0.0516
Epoch 3 [45/172] - loss: 0.0963
Epoch 3 [46/172] - loss: 0.2393
Epoch 3 [47/172] - loss: 0.0556
Epoch 3 [48/172] - loss: 0.1822
Epoch 3 [49/172] - loss: 0.2339
Epoch 3 [50/172] - loss: 0.0864, acc: 0.9375
Epoch 3 [51/172] - loss: 0.2527
Epoch 3 [52/172] - loss: 0.0767
Epoch 3 [53/172] - loss: 0.0927
Epoch 3 [54/172] - loss: 0.1463
Epoch 3 [55/172] - loss: 0.1939
Epoch 3 [56/172] - loss: 0.0800

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.4681, log_difficulty=0.3839, weight=2.9197
neutral: count=3923.0, difficulty=0.4000, log_difficulty=0.3365, weight=2.6825
negative: count=4382.0, difficulty=0.4596, log_difficulty=0.3782, weight=2.8908

当前batch的pt分布：
positive: min=0.3689, max=0.9592, mean=0.7545
neutral: min=0.3659, max=0.9542, mean=0.7086
negative: min=0.7988, max=0.9679, mean=0.9262

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.8182
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3178
焦点损失: 0.0490
边界损失: 0.2977
总损失: 0.1522
Epoch 3 [57/172] - loss: 0.1522
Epoch 3 [58/172] - loss: 0.0837
Epoch 3 [59/172] - loss: 0.1347
Epoch 3 [60/172] - loss: 0.1399, acc: 0.8750
Epoch 3 [61/172] - loss: 0.0686
Epoch 3 [62/172] - loss: 0.0639
Epoch 3 [63/172] - loss: 0.1024
Epoch 3 [64/172] - loss: 0.1754
Epoch 3 [65/172] - loss: 0.2252
Epoch 3 [66/172] - loss: 0.1805
Epoch 3 [67/172] - loss: 0.1328
Epoch 3 [68/172] - loss: 0.0658
Epoch 3 [69/172] - loss: 0.2719
Epoch 3 [70/172] - loss: 0.0579, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1383
Epoch 3 [72/172] - loss: 0.1422
Epoch 3 [73/172] - loss: 0.0635
Epoch 3 [74/172] - loss: 0.1923
Epoch 3 [75/172] - loss: 0.1769
Epoch 3 [76/172] - loss: 0.1204
Epoch 3 [77/172] - loss: 0.1154
Epoch 3 [78/172] - loss: 0.1655
Epoch 3 [79/172] - loss: 0.0430
Epoch 3 [80/172] - loss: 0.1579, acc: 0.8750
Epoch 3 [81/172] - loss: 0.1107
Epoch 3 [82/172] - loss: 0.2459
Epoch 3 [83/172] - loss: 0.1160
Epoch 3 [84/172] - loss: 0.0596
Epoch 3 [85/172] - loss: 0.1775
Epoch 3 [86/172] - loss: 0.1028
Epoch 3 [87/172] - loss: 0.2806
Epoch 3 [88/172] - loss: 0.1239
Epoch 3 [89/172] - loss: 0.0545
Epoch 3 [90/172] - loss: 0.0490, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1657
Epoch 3 [92/172] - loss: 0.1494
Epoch 3 [93/172] - loss: 0.2441
Epoch 3 [94/172] - loss: 0.0774
Epoch 3 [95/172] - loss: 0.0781
Epoch 3 [96/172] - loss: 0.1179
Epoch 3 [97/172] - loss: 0.1679
Epoch 3 [98/172] - loss: 0.2509
Epoch 3 [99/172] - loss: 0.0845
Epoch 3 [100/172] - loss: 0.2128, acc: 0.9375
Epoch 3 [101/172] - loss: 0.1342
Epoch 3 [102/172] - loss: 0.0597
Epoch 3 [103/172] - loss: 0.1085
Epoch 3 [104/172] - loss: 0.1273
Epoch 3 [105/172] - loss: 0.1000
Epoch 3 [106/172] - loss: 0.1679
Epoch 3 [107/172] - loss: 0.1112
Epoch 3 [108/172] - loss: 0.0752
Epoch 3 [109/172] - loss: 0.1233
Epoch 3 [110/172] - loss: 0.1568, acc: 0.9062
Epoch 3 [111/172] - loss: 0.3662
Epoch 3 [112/172] - loss: 0.1439
Epoch 3 [113/172] - loss: 0.0463
Epoch 3 [114/172] - loss: 0.0550
Epoch 3 [115/172] - loss: 0.0878
Epoch 3 [116/172] - loss: 0.0641
Epoch 3 [117/172] - loss: 0.0839
Epoch 3 [118/172] - loss: 0.1710
Epoch 3 [119/172] - loss: 0.1554
Epoch 3 [120/172] - loss: 0.1963, acc: 0.9062
Epoch 3 [121/172] - loss: 0.1953
Epoch 3 [122/172] - loss: 0.0958
Epoch 3 [123/172] - loss: 0.1106
Epoch 3 [124/172] - loss: 0.1514
Epoch 3 [125/172] - loss: 0.1852
Epoch 3 [126/172] - loss: 0.3130
Epoch 3 [127/172] - loss: 0.3462
Epoch 3 [128/172] - loss: 0.0577
Epoch 3 [129/172] - loss: 0.1119
Epoch 3 [130/172] - loss: 0.0902, acc: 1.0000
Epoch 3 [131/172] - loss: 0.0855
Epoch 3 [132/172] - loss: 0.1045
Epoch 3 [133/172] - loss: 0.1477
Epoch 3 [134/172] - loss: 0.0801
Epoch 3 [135/172] - loss: 0.1027
Epoch 3 [136/172] - loss: 0.0707
Epoch 3 [137/172] - loss: 0.0928
Epoch 3 [138/172] - loss: 0.1032
Epoch 3 [139/172] - loss: 0.0914
Epoch 3 [140/172] - loss: 0.2404, acc: 0.9375
Epoch 3 [141/172] - loss: 0.0981
Epoch 3 [142/172] - loss: 0.3254
Epoch 3 [143/172] - loss: 0.0647
Epoch 3 [144/172] - loss: 0.1883
Epoch 3 [145/172] - loss: 0.1181
Epoch 3 [146/172] - loss: 0.0910
Epoch 3 [147/172] - loss: 0.1636
Epoch 3 [148/172] - loss: 0.0731
Epoch 3 [149/172] - loss: 0.0830
Epoch 3 [150/172] - loss: 0.0900, acc: 0.9688
Epoch 3 [151/172] - loss: 0.1464
Epoch 3 [152/172] - loss: 0.4735
Epoch 3 [153/172] - loss: 0.0772
Epoch 3 [154/172] - loss: 0.1030
Epoch 3 [155/172] - loss: 0.0327
Epoch 3 [156/172] - loss: 0.1740

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.4206, log_difficulty=0.3511, weight=2.7553
neutral: count=4903.0, difficulty=0.3523, log_difficulty=0.3018, weight=2.5089
negative: count=5500.0, difficulty=0.4178, log_difficulty=0.3491, weight=2.7457

当前batch的pt分布：
positive: min=0.3532, max=0.9701, mean=0.7917
neutral: min=0.8166, max=0.9693, mean=0.8895
negative: min=0.2448, max=0.9506, mean=0.7492

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.2452
焦点损失: 0.0426
边界损失: 0.2461
总损失: 0.1299
Epoch 3 [157/172] - loss: 0.1299
Epoch 3 [158/172] - loss: 0.2745
Epoch 3 [159/172] - loss: 0.1799
Epoch 3 [160/172] - loss: 0.3155, acc: 0.8438
Epoch 3 [161/172] - loss: 0.1242
Epoch 3 [162/172] - loss: 0.1171
Epoch 3 [163/172] - loss: 0.1668
Epoch 3 [164/172] - loss: 0.0551
Epoch 3 [165/172] - loss: 0.0549
Epoch 3 [166/172] - loss: 0.0963
Epoch 3 [167/172] - loss: 0.0560
Epoch 3 [168/172] - loss: 0.0426
Epoch 3 [169/172] - loss: 0.0546
Epoch 3 [170/172] - loss: 0.0847, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1080
Epoch 3 [172/172] - loss: 0.1956

类别准确率:
positive: 0.8801 (411/467)
neutral: 0.2892 (24/83)
negative: 0.5440 (136/250)

Epoch 3/10
Train Loss: 0.1285, Train Acc: 0.9354
Val Loss: 0.6871, Val Acc: 0.7137
Epoch 4 [1/172] - loss: 0.0638, acc: 0.9688
Epoch 4 [2/172] - loss: 0.1297
Epoch 4 [3/172] - loss: 0.0598
Epoch 4 [4/172] - loss: 0.0719
Epoch 4 [5/172] - loss: 0.0466
Epoch 4 [6/172] - loss: 0.0715
Epoch 4 [7/172] - loss: 0.0724
Epoch 4 [8/172] - loss: 0.0726
Epoch 4 [9/172] - loss: 0.0760
Epoch 4 [10/172] - loss: 0.1204, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0346
Epoch 4 [12/172] - loss: 0.1375
Epoch 4 [13/172] - loss: 0.3101
Epoch 4 [14/172] - loss: 0.0955
Epoch 4 [15/172] - loss: 0.0579
Epoch 4 [16/172] - loss: 0.1164
Epoch 4 [17/172] - loss: 0.0475
Epoch 4 [18/172] - loss: 0.0363
Epoch 4 [19/172] - loss: 0.1011
Epoch 4 [20/172] - loss: 0.1862, acc: 0.9062
Epoch 4 [21/172] - loss: 0.1585
Epoch 4 [22/172] - loss: 0.0459
Epoch 4 [23/172] - loss: 0.0985
Epoch 4 [24/172] - loss: 0.0405
Epoch 4 [25/172] - loss: 0.0532
Epoch 4 [26/172] - loss: 0.2852
Epoch 4 [27/172] - loss: 0.0331
Epoch 4 [28/172] - loss: 0.2284
Epoch 4 [29/172] - loss: 0.0395
Epoch 4 [30/172] - loss: 0.0835, acc: 0.9375
Epoch 4 [31/172] - loss: 0.2034
Epoch 4 [32/172] - loss: 0.0426
Epoch 4 [33/172] - loss: 0.0500
Epoch 4 [34/172] - loss: 0.0520
Epoch 4 [35/172] - loss: 0.2286
Epoch 4 [36/172] - loss: 0.0569
Epoch 4 [37/172] - loss: 0.0239
Epoch 4 [38/172] - loss: 0.0537
Epoch 4 [39/172] - loss: 0.1145
Epoch 4 [40/172] - loss: 0.3493, acc: 0.8125
Epoch 4 [41/172] - loss: 0.0564
Epoch 4 [42/172] - loss: 0.0365
Epoch 4 [43/172] - loss: 0.1011
Epoch 4 [44/172] - loss: 0.0530
Epoch 4 [45/172] - loss: 0.0315
Epoch 4 [46/172] - loss: 0.0553
Epoch 4 [47/172] - loss: 0.0730
Epoch 4 [48/172] - loss: 0.1018
Epoch 4 [49/172] - loss: 0.0543
Epoch 4 [50/172] - loss: 0.0361, acc: 1.0000
Epoch 4 [51/172] - loss: 0.0986
Epoch 4 [52/172] - loss: 0.1401
Epoch 4 [53/172] - loss: 0.0296
Epoch 4 [54/172] - loss: 0.0861
Epoch 4 [55/172] - loss: 0.1911
Epoch 4 [56/172] - loss: 0.0567
Epoch 4 [57/172] - loss: 0.0377
Epoch 4 [58/172] - loss: 0.0446
Epoch 4 [59/172] - loss: 0.0395
Epoch 4 [60/172] - loss: 0.0544, acc: 0.9688
Epoch 4 [61/172] - loss: 0.1671
Epoch 4 [62/172] - loss: 0.0661
Epoch 4 [63/172] - loss: 0.0606
Epoch 4 [64/172] - loss: 0.0402
Epoch 4 [65/172] - loss: 0.2632
Epoch 4 [66/172] - loss: 0.0435
Epoch 4 [67/172] - loss: 0.0960
Epoch 4 [68/172] - loss: 0.0390
Epoch 4 [69/172] - loss: 0.0509
Epoch 4 [70/172] - loss: 0.0334, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0611
Epoch 4 [72/172] - loss: 0.0462
Epoch 4 [73/172] - loss: 0.0703
Epoch 4 [74/172] - loss: 0.0932
Epoch 4 [75/172] - loss: 0.0768
Epoch 4 [76/172] - loss: 0.0903
Epoch 4 [77/172] - loss: 0.0553
Epoch 4 [78/172] - loss: 0.0512
Epoch 4 [79/172] - loss: 0.0486
Epoch 4 [80/172] - loss: 0.0643, acc: 0.9688
Epoch 4 [81/172] - loss: 0.1138
Epoch 4 [82/172] - loss: 0.0494
Epoch 4 [83/172] - loss: 0.0312
Epoch 4 [84/172] - loss: 0.0247

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3833, log_difficulty=0.3244, weight=2.6222
neutral: count=5865.0, difficulty=0.3189, log_difficulty=0.2768, weight=2.3841
negative: count=6629.0, difficulty=0.3810, log_difficulty=0.3228, weight=2.6140

当前batch的pt分布：
positive: min=0.5174, max=0.9662, mean=0.8028
neutral: min=0.8944, max=0.9662, mean=0.9439
negative: min=0.6944, max=0.9632, mean=0.8995

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1620
焦点损失: 0.0091
边界损失: 0.2182
总损失: 0.0433
Epoch 4 [85/172] - loss: 0.0433
Epoch 4 [86/172] - loss: 0.1130
Epoch 4 [87/172] - loss: 0.0969
Epoch 4 [88/172] - loss: 0.0651
Epoch 4 [89/172] - loss: 0.0310
Epoch 4 [90/172] - loss: 0.0287, acc: 1.0000
Epoch 4 [91/172] - loss: 0.0835
Epoch 4 [92/172] - loss: 0.1676
Epoch 4 [93/172] - loss: 0.0282
Epoch 4 [94/172] - loss: 0.0526
Epoch 4 [95/172] - loss: 0.0705
Epoch 4 [96/172] - loss: 0.0448
Epoch 4 [97/172] - loss: 0.0463
Epoch 4 [98/172] - loss: 0.0370
Epoch 4 [99/172] - loss: 0.0453
Epoch 4 [100/172] - loss: 0.0588, acc: 0.9375
Epoch 4 [101/172] - loss: 0.1069
Epoch 4 [102/172] - loss: 0.1246
Epoch 4 [103/172] - loss: 0.0688
Epoch 4 [104/172] - loss: 0.0606
Epoch 4 [105/172] - loss: 0.0871
Epoch 4 [106/172] - loss: 0.0431
Epoch 4 [107/172] - loss: 0.0342
Epoch 4 [108/172] - loss: 0.0846
Epoch 4 [109/172] - loss: 0.0747
Epoch 4 [110/172] - loss: 0.2007, acc: 0.9062
Epoch 4 [111/172] - loss: 0.0278
Epoch 4 [112/172] - loss: 0.0362
Epoch 4 [113/172] - loss: 0.0459
Epoch 4 [114/172] - loss: 0.1881
Epoch 4 [115/172] - loss: 0.0405
Epoch 4 [116/172] - loss: 0.0817
Epoch 4 [117/172] - loss: 0.0292
Epoch 4 [118/172] - loss: 0.0637
Epoch 4 [119/172] - loss: 0.0370
Epoch 4 [120/172] - loss: 0.0731, acc: 0.9688
Epoch 4 [121/172] - loss: 0.0408
Epoch 4 [122/172] - loss: 0.1586
Epoch 4 [123/172] - loss: 0.0654
Epoch 4 [124/172] - loss: 0.0853
Epoch 4 [125/172] - loss: 0.0735
Epoch 4 [126/172] - loss: 0.2332
Epoch 4 [127/172] - loss: 0.1296
Epoch 4 [128/172] - loss: 0.0296
Epoch 4 [129/172] - loss: 0.0228
Epoch 4 [130/172] - loss: 0.0642, acc: 0.9688
Epoch 4 [131/172] - loss: 0.0231
Epoch 4 [132/172] - loss: 0.0558
Epoch 4 [133/172] - loss: 0.0616
Epoch 4 [134/172] - loss: 0.0703
Epoch 4 [135/172] - loss: 0.0429
Epoch 4 [136/172] - loss: 0.1103
Epoch 4 [137/172] - loss: 0.0479
Epoch 4 [138/172] - loss: 0.0403
Epoch 4 [139/172] - loss: 0.0427
Epoch 4 [140/172] - loss: 0.0881, acc: 0.9688
Epoch 4 [141/172] - loss: 0.0293
Epoch 4 [142/172] - loss: 0.0551
Epoch 4 [143/172] - loss: 0.0893
Epoch 4 [144/172] - loss: 0.0458
Epoch 4 [145/172] - loss: 0.0818
Epoch 4 [146/172] - loss: 0.0670
Epoch 4 [147/172] - loss: 0.1195
Epoch 4 [148/172] - loss: 0.0705
Epoch 4 [149/172] - loss: 0.0711
Epoch 4 [150/172] - loss: 0.1006, acc: 0.9375
Epoch 4 [151/172] - loss: 0.3415
Epoch 4 [152/172] - loss: 0.0334
Epoch 4 [153/172] - loss: 0.0284
Epoch 4 [154/172] - loss: 0.0571
Epoch 4 [155/172] - loss: 0.1168
Epoch 4 [156/172] - loss: 0.0581
Epoch 4 [157/172] - loss: 0.2525
Epoch 4 [158/172] - loss: 0.0458
Epoch 4 [159/172] - loss: 0.0381
Epoch 4 [160/172] - loss: 0.0268, acc: 1.0000
Epoch 4 [161/172] - loss: 0.2603
Epoch 4 [162/172] - loss: 0.0315
Epoch 4 [163/172] - loss: 0.0625
Epoch 4 [164/172] - loss: 0.0386
Epoch 4 [165/172] - loss: 0.1727
Epoch 4 [166/172] - loss: 0.0904
Epoch 4 [167/172] - loss: 0.0513
Epoch 4 [168/172] - loss: 0.0597
Epoch 4 [169/172] - loss: 0.1247
Epoch 4 [170/172] - loss: 0.0776, acc: 0.9375
Epoch 4 [171/172] - loss: 0.1345
Epoch 4 [172/172] - loss: 0.0342

类别准确率:
positive: 0.8373 (391/467)
neutral: 0.1687 (14/83)
negative: 0.6880 (172/250)

Epoch 4/10
Train Loss: 0.0938, Train Acc: 0.9556
Val Loss: 0.7129, Val Acc: 0.7212
Epoch 5 [1/172] - loss: 0.0465, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0453
Epoch 5 [3/172] - loss: 0.0931
Epoch 5 [4/172] - loss: 0.0589
Epoch 5 [5/172] - loss: 0.0588
Epoch 5 [6/172] - loss: 0.0439
Epoch 5 [7/172] - loss: 0.0805
Epoch 5 [8/172] - loss: 0.1321
Epoch 5 [9/172] - loss: 0.1252
Epoch 5 [10/172] - loss: 0.0486, acc: 0.9688
Epoch 5 [11/172] - loss: 0.0632
Epoch 5 [12/172] - loss: 0.0278

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.3502, log_difficulty=0.3002, weight=2.5011
neutral: count=6845.0, difficulty=0.2911, log_difficulty=0.2555, weight=2.2775
negative: count=7694.0, difficulty=0.3521, log_difficulty=0.3017, weight=2.5083

当前batch的pt分布：
positive: min=0.3013, max=0.9549, mean=0.8539
neutral: min=0.8289, max=0.9932, mean=0.9537
negative: min=0.7662, max=0.9650, mean=0.8796

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1383
焦点损失: 0.0170
边界损失: 0.1951
总损失: 0.0578
Epoch 5 [13/172] - loss: 0.0578
Epoch 5 [14/172] - loss: 0.1144
Epoch 5 [15/172] - loss: 0.0309
Epoch 5 [16/172] - loss: 0.0620
Epoch 5 [17/172] - loss: 0.0410
Epoch 5 [18/172] - loss: 0.0288
Epoch 5 [19/172] - loss: 0.0751
Epoch 5 [20/172] - loss: 0.0351, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1348
Epoch 5 [22/172] - loss: 0.1135
Epoch 5 [23/172] - loss: 0.1018
Epoch 5 [24/172] - loss: 0.0327
Epoch 5 [25/172] - loss: 0.0212
Epoch 5 [26/172] - loss: 0.0675
Epoch 5 [27/172] - loss: 0.0324
Epoch 5 [28/172] - loss: 0.0262
Epoch 5 [29/172] - loss: 0.0523
Epoch 5 [30/172] - loss: 0.0431, acc: 0.9688
Epoch 5 [31/172] - loss: 0.0229
Epoch 5 [32/172] - loss: 0.0564
Epoch 5 [33/172] - loss: 0.0290
Epoch 5 [34/172] - loss: 0.0267
Epoch 5 [35/172] - loss: 0.0385
Epoch 5 [36/172] - loss: 0.0464
Epoch 5 [37/172] - loss: 0.0635
Epoch 5 [38/172] - loss: 0.0280
Epoch 5 [39/172] - loss: 0.3293
Epoch 5 [40/172] - loss: 0.1571, acc: 0.9062
Epoch 5 [41/172] - loss: 0.0462
Epoch 5 [42/172] - loss: 0.0483
Epoch 5 [43/172] - loss: 0.0799
Epoch 5 [44/172] - loss: 0.0808
Epoch 5 [45/172] - loss: 0.0257
Epoch 5 [46/172] - loss: 0.0948
Epoch 5 [47/172] - loss: 0.0288
Epoch 5 [48/172] - loss: 0.0370
Epoch 5 [49/172] - loss: 0.0403
Epoch 5 [50/172] - loss: 0.0886, acc: 0.9375
Epoch 5 [51/172] - loss: 0.1282
Epoch 5 [52/172] - loss: 0.0332
Epoch 5 [53/172] - loss: 0.1150
Epoch 5 [54/172] - loss: 0.0307
Epoch 5 [55/172] - loss: 0.0466
Epoch 5 [56/172] - loss: 0.0589
Epoch 5 [57/172] - loss: 0.0308
Epoch 5 [58/172] - loss: 0.0268
Epoch 5 [59/172] - loss: 0.0978
Epoch 5 [60/172] - loss: 0.0358, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0567
Epoch 5 [62/172] - loss: 0.0319
Epoch 5 [63/172] - loss: 0.0996
Epoch 5 [64/172] - loss: 0.0498
Epoch 5 [65/172] - loss: 0.0446
Epoch 5 [66/172] - loss: 0.0364
Epoch 5 [67/172] - loss: 0.0296
Epoch 5 [68/172] - loss: 0.0394
Epoch 5 [69/172] - loss: 0.0707
Epoch 5 [70/172] - loss: 0.0347, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0429
Epoch 5 [72/172] - loss: 0.0428
Epoch 5 [73/172] - loss: 0.0883
Epoch 5 [74/172] - loss: 0.1285
Epoch 5 [75/172] - loss: 0.0281
Epoch 5 [76/172] - loss: 0.0342
Epoch 5 [77/172] - loss: 0.0506
Epoch 5 [78/172] - loss: 0.0892
Epoch 5 [79/172] - loss: 0.0472
Epoch 5 [80/172] - loss: 0.0842, acc: 0.9375
Epoch 5 [81/172] - loss: 0.1240
Epoch 5 [82/172] - loss: 0.0828
Epoch 5 [83/172] - loss: 0.0285
Epoch 5 [84/172] - loss: 0.0247
Epoch 5 [85/172] - loss: 0.2039
Epoch 5 [86/172] - loss: 0.0342
Epoch 5 [87/172] - loss: 0.0599
Epoch 5 [88/172] - loss: 0.1258
Epoch 5 [89/172] - loss: 0.0206
Epoch 5 [90/172] - loss: 0.0332, acc: 1.0000
Epoch 5 [91/172] - loss: 0.0660
Epoch 5 [92/172] - loss: 0.0207
Epoch 5 [93/172] - loss: 0.0249
Epoch 5 [94/172] - loss: 0.0385
Epoch 5 [95/172] - loss: 0.0463
Epoch 5 [96/172] - loss: 0.0276
Epoch 5 [97/172] - loss: 0.0653
Epoch 5 [98/172] - loss: 0.0314
Epoch 5 [99/172] - loss: 0.1820
Epoch 5 [100/172] - loss: 0.0459, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0764
Epoch 5 [102/172] - loss: 0.0875
Epoch 5 [103/172] - loss: 0.0386
Epoch 5 [104/172] - loss: 0.1591
Epoch 5 [105/172] - loss: 0.2502
Epoch 5 [106/172] - loss: 0.0286
Epoch 5 [107/172] - loss: 0.0341
Epoch 5 [108/172] - loss: 0.2743
Epoch 5 [109/172] - loss: 0.0483
Epoch 5 [110/172] - loss: 0.0387, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0524
Epoch 5 [112/172] - loss: 0.0324

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.3231, log_difficulty=0.2800, weight=2.3999
neutral: count=7825.0, difficulty=0.2681, log_difficulty=0.2375, weight=2.1877
negative: count=8780.0, difficulty=0.3277, log_difficulty=0.2834, weight=2.4172

当前batch的pt分布：
positive: min=0.1029, max=0.9727, mean=0.7232
neutral: min=0.7084, max=0.9887, mean=0.8922
negative: min=0.8041, max=0.9802, mean=0.9263

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8125
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2706
焦点损失: 0.0835
边界损失: 0.2347
总损失: 0.2036
Epoch 5 [113/172] - loss: 0.2036
Epoch 5 [114/172] - loss: 0.0558
Epoch 5 [115/172] - loss: 0.0479
Epoch 5 [116/172] - loss: 0.0281
Epoch 5 [117/172] - loss: 0.0215
Epoch 5 [118/172] - loss: 0.0311
Epoch 5 [119/172] - loss: 0.0397
Epoch 5 [120/172] - loss: 0.0319, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0508
Epoch 5 [122/172] - loss: 0.0368
Epoch 5 [123/172] - loss: 0.0363
Epoch 5 [124/172] - loss: 0.0516
Epoch 5 [125/172] - loss: 0.0307
Epoch 5 [126/172] - loss: 0.0689
Epoch 5 [127/172] - loss: 0.0374
Epoch 5 [128/172] - loss: 0.0253
Epoch 5 [129/172] - loss: 0.1128
Epoch 5 [130/172] - loss: 0.0272, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0393
Epoch 5 [132/172] - loss: 0.1054
Epoch 5 [133/172] - loss: 0.2034
Epoch 5 [134/172] - loss: 0.2332
Epoch 5 [135/172] - loss: 0.0206
Epoch 5 [136/172] - loss: 0.0275
Epoch 5 [137/172] - loss: 0.0662
Epoch 5 [138/172] - loss: 0.0429
Epoch 5 [139/172] - loss: 0.2497
Epoch 5 [140/172] - loss: 0.0575, acc: 1.0000
Epoch 5 [141/172] - loss: 0.0351
Epoch 5 [142/172] - loss: 0.0334
Epoch 5 [143/172] - loss: 0.0341
Epoch 5 [144/172] - loss: 0.0292
Epoch 5 [145/172] - loss: 0.0358
Epoch 5 [146/172] - loss: 0.0278
Epoch 5 [147/172] - loss: 0.1170
Epoch 5 [148/172] - loss: 0.0239
Epoch 5 [149/172] - loss: 0.0319
Epoch 5 [150/172] - loss: 0.1968, acc: 0.9375
Epoch 5 [151/172] - loss: 0.0359
Epoch 5 [152/172] - loss: 0.0252
Epoch 5 [153/172] - loss: 0.0229
Epoch 5 [154/172] - loss: 0.0307
Epoch 5 [155/172] - loss: 0.0574
Epoch 5 [156/172] - loss: 0.0342
Epoch 5 [157/172] - loss: 0.0618
Epoch 5 [158/172] - loss: 0.0266
Epoch 5 [159/172] - loss: 0.0385
Epoch 5 [160/172] - loss: 0.0277, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0268
Epoch 5 [162/172] - loss: 0.0468
Epoch 5 [163/172] - loss: 0.1381
Epoch 5 [164/172] - loss: 0.0567
Epoch 5 [165/172] - loss: 0.3180
Epoch 5 [166/172] - loss: 0.1725
Epoch 5 [167/172] - loss: 0.0989
Epoch 5 [168/172] - loss: 0.0313
Epoch 5 [169/172] - loss: 0.0264
Epoch 5 [170/172] - loss: 0.0373, acc: 0.9688
Epoch 5 [171/172] - loss: 0.0404
Epoch 5 [172/172] - loss: 0.0369

类别准确率:
positive: 0.9229 (431/467)
neutral: 0.3253 (27/83)
negative: 0.4920 (123/250)

Epoch 5/10
Train Loss: 0.0740, Train Acc: 0.9758
Val Loss: 0.7331, Val Acc: 0.7262
Epoch 6 [1/172] - loss: 0.0636, acc: 1.0000
Epoch 6 [2/172] - loss: 0.0341
Epoch 6 [3/172] - loss: 0.0290
Epoch 6 [4/172] - loss: 0.0360
Epoch 6 [5/172] - loss: 0.1771
Epoch 6 [6/172] - loss: 0.0291
Epoch 6 [7/172] - loss: 0.0520
Epoch 6 [8/172] - loss: 0.0366
Epoch 6 [9/172] - loss: 0.0204
Epoch 6 [10/172] - loss: 0.0385, acc: 0.9688
Epoch 6 [11/172] - loss: 0.0225
Epoch 6 [12/172] - loss: 0.0327
Epoch 6 [13/172] - loss: 0.1804
Epoch 6 [14/172] - loss: 0.0209
Epoch 6 [15/172] - loss: 0.0253
Epoch 6 [16/172] - loss: 0.0627
Epoch 6 [17/172] - loss: 0.0299
Epoch 6 [18/172] - loss: 0.0228
Epoch 6 [19/172] - loss: 0.0343
Epoch 6 [20/172] - loss: 0.0190, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0237
Epoch 6 [22/172] - loss: 0.0349
Epoch 6 [23/172] - loss: 0.0258
Epoch 6 [24/172] - loss: 0.0387
Epoch 6 [25/172] - loss: 0.1549
Epoch 6 [26/172] - loss: 0.0478
Epoch 6 [27/172] - loss: 0.1046
Epoch 6 [28/172] - loss: 0.0250
Epoch 6 [29/172] - loss: 0.0277
Epoch 6 [30/172] - loss: 0.0352, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0276
Epoch 6 [32/172] - loss: 0.0348
Epoch 6 [33/172] - loss: 0.0247
Epoch 6 [34/172] - loss: 0.0240
Epoch 6 [35/172] - loss: 0.0240
Epoch 6 [36/172] - loss: 0.0235
Epoch 6 [37/172] - loss: 0.0569
Epoch 6 [38/172] - loss: 0.0378
Epoch 6 [39/172] - loss: 0.0550
Epoch 6 [40/172] - loss: 0.1159, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.3013, log_difficulty=0.2633, weight=2.3167
neutral: count=8815.0, difficulty=0.2494, log_difficulty=0.2226, weight=2.1132
negative: count=9870.0, difficulty=0.3070, log_difficulty=0.2677, weight=2.3387

当前batch的pt分布：
positive: min=0.2490, max=0.9900, mean=0.8568
neutral: min=0.5991, max=0.9859, mean=0.9132
negative: min=0.7705, max=0.9574, mean=0.8851

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1465
焦点损失: 0.0269
边界损失: 0.1948
总损失: 0.0752
Epoch 6 [41/172] - loss: 0.0752
Epoch 6 [42/172] - loss: 0.0242
Epoch 6 [43/172] - loss: 0.1658
Epoch 6 [44/172] - loss: 0.0270
Epoch 6 [45/172] - loss: 0.0633
Epoch 6 [46/172] - loss: 0.0397
Epoch 6 [47/172] - loss: 0.0299
Epoch 6 [48/172] - loss: 0.0198
Epoch 6 [49/172] - loss: 0.0374
Epoch 6 [50/172] - loss: 0.1371, acc: 0.9062
Epoch 6 [51/172] - loss: 0.0890
Epoch 6 [52/172] - loss: 0.3251
Epoch 6 [53/172] - loss: 0.0420
Epoch 6 [54/172] - loss: 0.2157
Epoch 6 [55/172] - loss: 0.0340
Epoch 6 [56/172] - loss: 0.0394
Epoch 6 [57/172] - loss: 0.0214
Epoch 6 [58/172] - loss: 0.0293
Epoch 6 [59/172] - loss: 0.0976
Epoch 6 [60/172] - loss: 0.0383, acc: 1.0000
Epoch 6 [61/172] - loss: 0.0476
Epoch 6 [62/172] - loss: 0.0420
Epoch 6 [63/172] - loss: 0.0357
Epoch 6 [64/172] - loss: 0.0965
Epoch 6 [65/172] - loss: 0.1452
Epoch 6 [66/172] - loss: 0.0812
Epoch 6 [67/172] - loss: 0.0390
Epoch 6 [68/172] - loss: 0.1475
Epoch 6 [69/172] - loss: 0.0819
Epoch 6 [70/172] - loss: 0.0398, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0294
Epoch 6 [72/172] - loss: 0.0568
Epoch 6 [73/172] - loss: 0.0911
Epoch 6 [74/172] - loss: 0.0215
Epoch 6 [75/172] - loss: 0.0361
Epoch 6 [76/172] - loss: 0.0450
Epoch 6 [77/172] - loss: 0.0520
Epoch 6 [78/172] - loss: 0.1279
Epoch 6 [79/172] - loss: 0.0555
Epoch 6 [80/172] - loss: 0.0249, acc: 1.0000
Epoch 6 [81/172] - loss: 0.0379
Epoch 6 [82/172] - loss: 0.0978
Epoch 6 [83/172] - loss: 0.0305
Epoch 6 [84/172] - loss: 0.0426
Epoch 6 [85/172] - loss: 0.0455
Epoch 6 [86/172] - loss: 0.0626
Epoch 6 [87/172] - loss: 0.0616
Epoch 6 [88/172] - loss: 0.0765
Epoch 6 [89/172] - loss: 0.0764
Epoch 6 [90/172] - loss: 0.0207, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0351
Epoch 6 [92/172] - loss: 0.0318
Epoch 6 [93/172] - loss: 0.0222
Epoch 6 [94/172] - loss: 0.0667
Epoch 6 [95/172] - loss: 0.0186
Epoch 6 [96/172] - loss: 0.0200
Epoch 6 [97/172] - loss: 0.0484
Epoch 6 [98/172] - loss: 0.0281
Epoch 6 [99/172] - loss: 0.0261
Epoch 6 [100/172] - loss: 0.0661, acc: 0.9688
Epoch 6 [101/172] - loss: 0.0371
Epoch 6 [102/172] - loss: 0.0224
Epoch 6 [103/172] - loss: 0.0354
Epoch 6 [104/172] - loss: 0.2666
Epoch 6 [105/172] - loss: 0.0214
Epoch 6 [106/172] - loss: 0.0616
Epoch 6 [107/172] - loss: 0.0278
Epoch 6 [108/172] - loss: 0.0243
Epoch 6 [109/172] - loss: 0.1154
Epoch 6 [110/172] - loss: 0.0305, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0913
Epoch 6 [112/172] - loss: 0.0563
Epoch 6 [113/172] - loss: 0.0542
Epoch 6 [114/172] - loss: 0.0274
Epoch 6 [115/172] - loss: 0.0470
Epoch 6 [116/172] - loss: 0.1349
Epoch 6 [117/172] - loss: 0.0493
Epoch 6 [118/172] - loss: 0.0246
Epoch 6 [119/172] - loss: 0.2099
Epoch 6 [120/172] - loss: 0.0964, acc: 0.9062
Epoch 6 [121/172] - loss: 0.0812
Epoch 6 [122/172] - loss: 0.0660
Epoch 6 [123/172] - loss: 0.0416
Epoch 6 [124/172] - loss: 0.0249
Epoch 6 [125/172] - loss: 0.0308
Epoch 6 [126/172] - loss: 0.0623
Epoch 6 [127/172] - loss: 0.0749
Epoch 6 [128/172] - loss: 0.0396
Epoch 6 [129/172] - loss: 0.0364
Epoch 6 [130/172] - loss: 0.1406, acc: 0.9688
Epoch 6 [131/172] - loss: 0.0549
Epoch 6 [132/172] - loss: 0.0851
Epoch 6 [133/172] - loss: 0.0259
Epoch 6 [134/172] - loss: 0.0282
Epoch 6 [135/172] - loss: 0.0285
Epoch 6 [136/172] - loss: 0.0230
Epoch 6 [137/172] - loss: 0.0445
Epoch 6 [138/172] - loss: 0.0218
Epoch 6 [139/172] - loss: 0.0379
Epoch 6 [140/172] - loss: 0.0432, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2833, log_difficulty=0.2494, weight=2.2471
neutral: count=9796.0, difficulty=0.2352, log_difficulty=0.2113, weight=2.0563
negative: count=10972.0, difficulty=0.2906, log_difficulty=0.2551, weight=2.2757

当前batch的pt分布：
positive: min=0.8632, max=0.9970, mean=0.9400
neutral: min=0.7234, max=0.9926, mean=0.9056
negative: min=0.5999, max=0.9706, mean=0.8011

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1438
焦点损失: 0.0063
边界损失: 0.2143
总损失: 0.0342
Epoch 6 [141/172] - loss: 0.0342
Epoch 6 [142/172] - loss: 0.0236
Epoch 6 [143/172] - loss: 0.0261
Epoch 6 [144/172] - loss: 0.0315
Epoch 6 [145/172] - loss: 0.0264
Epoch 6 [146/172] - loss: 0.0288
Epoch 6 [147/172] - loss: 0.0354
Epoch 6 [148/172] - loss: 0.0514
Epoch 6 [149/172] - loss: 0.0219
Epoch 6 [150/172] - loss: 0.0362, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0521
Epoch 6 [152/172] - loss: 0.0320
Epoch 6 [153/172] - loss: 0.0497
Epoch 6 [154/172] - loss: 0.0236
Epoch 6 [155/172] - loss: 0.0723
Epoch 6 [156/172] - loss: 0.0343
Epoch 6 [157/172] - loss: 0.0835
Epoch 6 [158/172] - loss: 0.0282
Epoch 6 [159/172] - loss: 0.0472
Epoch 6 [160/172] - loss: 0.0359, acc: 1.0000
Epoch 6 [161/172] - loss: 0.0393
Epoch 6 [162/172] - loss: 0.0897
Epoch 6 [163/172] - loss: 0.0291
Epoch 6 [164/172] - loss: 0.0513
Epoch 6 [165/172] - loss: 0.4642
Epoch 6 [166/172] - loss: 0.0286
Epoch 6 [167/172] - loss: 0.0223
Epoch 6 [168/172] - loss: 0.0297
Epoch 6 [169/172] - loss: 0.0559
Epoch 6 [170/172] - loss: 0.0195, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0365
Epoch 6 [172/172] - loss: 0.0238

类别准确率:
positive: 0.7901 (369/467)
neutral: 0.3494 (29/83)
negative: 0.6440 (161/250)

Epoch 6/10
Train Loss: 0.0678, Train Acc: 0.9798
Val Loss: 0.7662, Val Acc: 0.6987
Epoch 7 [1/172] - loss: 0.0240, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0311
Epoch 7 [3/172] - loss: 0.0273
Epoch 7 [4/172] - loss: 0.0323
Epoch 7 [5/172] - loss: 0.0261
Epoch 7 [6/172] - loss: 0.0277
Epoch 7 [7/172] - loss: 0.0205
Epoch 7 [8/172] - loss: 0.0622
Epoch 7 [9/172] - loss: 0.0304
Epoch 7 [10/172] - loss: 0.0298, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0231
Epoch 7 [12/172] - loss: 0.0327
Epoch 7 [13/172] - loss: 0.0204
Epoch 7 [14/172] - loss: 0.0195
Epoch 7 [15/172] - loss: 0.0628
Epoch 7 [16/172] - loss: 0.0301
Epoch 7 [17/172] - loss: 0.0442
Epoch 7 [18/172] - loss: 0.0307
Epoch 7 [19/172] - loss: 0.0215
Epoch 7 [20/172] - loss: 0.0202, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0362
Epoch 7 [22/172] - loss: 0.0250
Epoch 7 [23/172] - loss: 0.0223
Epoch 7 [24/172] - loss: 0.0356
Epoch 7 [25/172] - loss: 0.0426
Epoch 7 [26/172] - loss: 0.0532
Epoch 7 [27/172] - loss: 0.0649
Epoch 7 [28/172] - loss: 0.0388
Epoch 7 [29/172] - loss: 0.0597
Epoch 7 [30/172] - loss: 0.1264, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0210
Epoch 7 [32/172] - loss: 0.0185
Epoch 7 [33/172] - loss: 0.0316
Epoch 7 [34/172] - loss: 0.0273
Epoch 7 [35/172] - loss: 0.0220
Epoch 7 [36/172] - loss: 0.1091
Epoch 7 [37/172] - loss: 0.0544
Epoch 7 [38/172] - loss: 0.0181
Epoch 7 [39/172] - loss: 0.0207
Epoch 7 [40/172] - loss: 0.0199, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0261
Epoch 7 [42/172] - loss: 0.0201
Epoch 7 [43/172] - loss: 0.0219
Epoch 7 [44/172] - loss: 0.0232
Epoch 7 [45/172] - loss: 0.1108
Epoch 7 [46/172] - loss: 0.2015
Epoch 7 [47/172] - loss: 0.0500
Epoch 7 [48/172] - loss: 0.0191
Epoch 7 [49/172] - loss: 0.0220
Epoch 7 [50/172] - loss: 0.0179, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1113
Epoch 7 [52/172] - loss: 0.0206
Epoch 7 [53/172] - loss: 0.0222
Epoch 7 [54/172] - loss: 0.0333
Epoch 7 [55/172] - loss: 0.0192
Epoch 7 [56/172] - loss: 0.0374
Epoch 7 [57/172] - loss: 0.0410
Epoch 7 [58/172] - loss: 0.0273
Epoch 7 [59/172] - loss: 0.0776
Epoch 7 [60/172] - loss: 0.0336, acc: 1.0000
Epoch 7 [61/172] - loss: 0.0277
Epoch 7 [62/172] - loss: 0.0292
Epoch 7 [63/172] - loss: 0.0644
Epoch 7 [64/172] - loss: 0.0248
Epoch 7 [65/172] - loss: 0.0514
Epoch 7 [66/172] - loss: 0.0376
Epoch 7 [67/172] - loss: 0.0220
Epoch 7 [68/172] - loss: 0.0702

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.2670, log_difficulty=0.2367, weight=2.1834
neutral: count=10756.0, difficulty=0.2217, log_difficulty=0.2002, weight=2.0012
negative: count=12072.0, difficulty=0.2740, log_difficulty=0.2422, weight=2.2108

当前batch的pt分布：
positive: min=0.8767, max=0.9920, mean=0.9551
neutral: min=0.9066, max=0.9902, mean=0.9618
negative: min=0.5800, max=0.9782, mean=0.8677

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0894
焦点损失: 0.0032
边界损失: 0.1806
总损失: 0.0244
Epoch 7 [69/172] - loss: 0.0244
Epoch 7 [70/172] - loss: 0.0213, acc: 1.0000
Epoch 7 [71/172] - loss: 0.0286
Epoch 7 [72/172] - loss: 0.0342
Epoch 7 [73/172] - loss: 0.0570
Epoch 7 [74/172] - loss: 0.0191
Epoch 7 [75/172] - loss: 0.0222
Epoch 7 [76/172] - loss: 0.0368
Epoch 7 [77/172] - loss: 0.0441
Epoch 7 [78/172] - loss: 0.0207
Epoch 7 [79/172] - loss: 0.0348
Epoch 7 [80/172] - loss: 0.0269, acc: 1.0000
Epoch 7 [81/172] - loss: 0.0321
Epoch 7 [82/172] - loss: 0.0205
Epoch 7 [83/172] - loss: 0.4069
Epoch 7 [84/172] - loss: 0.0199
Epoch 7 [85/172] - loss: 0.0242
Epoch 7 [86/172] - loss: 0.0184
Epoch 7 [87/172] - loss: 0.0188
Epoch 7 [88/172] - loss: 0.0201
Epoch 7 [89/172] - loss: 0.0246
Epoch 7 [90/172] - loss: 0.1418, acc: 0.9375
Epoch 7 [91/172] - loss: 0.0219
Epoch 7 [92/172] - loss: 0.0220
Epoch 7 [93/172] - loss: 0.0368
Epoch 7 [94/172] - loss: 0.0174
Epoch 7 [95/172] - loss: 0.0225
Epoch 7 [96/172] - loss: 0.0205
Epoch 7 [97/172] - loss: 0.0256
Epoch 7 [98/172] - loss: 0.0594
Epoch 7 [99/172] - loss: 0.0181
Epoch 7 [100/172] - loss: 0.0297, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0266
Epoch 7 [102/172] - loss: 0.0170
Epoch 7 [103/172] - loss: 0.0187
Epoch 7 [104/172] - loss: 0.0309
Epoch 7 [105/172] - loss: 0.0465
Epoch 7 [106/172] - loss: 0.0460
Epoch 7 [107/172] - loss: 0.0185
Epoch 7 [108/172] - loss: 0.0178
Epoch 7 [109/172] - loss: 0.0397
Epoch 7 [110/172] - loss: 0.0336, acc: 1.0000
Epoch 7 [111/172] - loss: 0.0195
Epoch 7 [112/172] - loss: 0.0332
Epoch 7 [113/172] - loss: 0.0248
Epoch 7 [114/172] - loss: 0.0185
Epoch 7 [115/172] - loss: 0.0186
Epoch 7 [116/172] - loss: 0.1941
Epoch 7 [117/172] - loss: 0.0421
Epoch 7 [118/172] - loss: 0.0276
Epoch 7 [119/172] - loss: 0.0203
Epoch 7 [120/172] - loss: 0.0179, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0350
Epoch 7 [122/172] - loss: 0.0193
Epoch 7 [123/172] - loss: 0.0309
Epoch 7 [124/172] - loss: 0.0545
Epoch 7 [125/172] - loss: 0.0213
Epoch 7 [126/172] - loss: 0.0400
Epoch 7 [127/172] - loss: 0.0217
Epoch 7 [128/172] - loss: 0.0266
Epoch 7 [129/172] - loss: 0.0269
Epoch 7 [130/172] - loss: 0.1223, acc: 0.9688
Epoch 7 [131/172] - loss: 0.1586
Epoch 7 [132/172] - loss: 0.1162
Epoch 7 [133/172] - loss: 0.0205
Epoch 7 [134/172] - loss: 0.0200
Epoch 7 [135/172] - loss: 0.0309
Epoch 7 [136/172] - loss: 0.0234
Epoch 7 [137/172] - loss: 0.0346
Epoch 7 [138/172] - loss: 0.0208
Epoch 7 [139/172] - loss: 0.0513
Epoch 7 [140/172] - loss: 0.0424, acc: 0.9688
Epoch 7 [141/172] - loss: 0.0697
Epoch 7 [142/172] - loss: 0.0452
Epoch 7 [143/172] - loss: 0.0696
Epoch 7 [144/172] - loss: 0.0992
Epoch 7 [145/172] - loss: 0.0712
Epoch 7 [146/172] - loss: 0.1707
Epoch 7 [147/172] - loss: 0.1605
Epoch 7 [148/172] - loss: 0.0493
Epoch 7 [149/172] - loss: 0.0189
Epoch 7 [150/172] - loss: 0.0244, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1446
Epoch 7 [152/172] - loss: 0.0222
Epoch 7 [153/172] - loss: 0.0180
Epoch 7 [154/172] - loss: 0.0476
Epoch 7 [155/172] - loss: 0.0207
Epoch 7 [156/172] - loss: 0.1144
Epoch 7 [157/172] - loss: 0.0230
Epoch 7 [158/172] - loss: 0.0743
Epoch 7 [159/172] - loss: 0.0232
Epoch 7 [160/172] - loss: 0.0304, acc: 1.0000
Epoch 7 [161/172] - loss: 0.0212
Epoch 7 [162/172] - loss: 0.0484
Epoch 7 [163/172] - loss: 0.0635
Epoch 7 [164/172] - loss: 0.3451
Epoch 7 [165/172] - loss: 0.1608
Epoch 7 [166/172] - loss: 0.0722
Epoch 7 [167/172] - loss: 0.1082
Epoch 7 [168/172] - loss: 0.0653

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.2524, log_difficulty=0.2250, weight=2.1251
neutral: count=11731.0, difficulty=0.2105, log_difficulty=0.1910, weight=1.9552
negative: count=13173.0, difficulty=0.2602, log_difficulty=0.2313, weight=2.1563

当前batch的pt分布：
positive: min=0.7410, max=0.9893, mean=0.9323
neutral: min=0.8387, max=0.9960, mean=0.9407
negative: min=0.7442, max=0.9904, mean=0.8935

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0863
焦点损失: 0.0017
边界损失: 0.1801
总损失: 0.0213
Epoch 7 [169/172] - loss: 0.0213
Epoch 7 [170/172] - loss: 0.0563, acc: 0.9688
Epoch 7 [171/172] - loss: 0.0549
Epoch 7 [172/172] - loss: 0.0271

类别准确率:
positive: 0.8608 (402/467)
neutral: 0.3373 (28/83)
negative: 0.5520 (138/250)

Epoch 7/10
Train Loss: 0.0747, Train Acc: 0.9737
Val Loss: 0.7766, Val Acc: 0.7100
Epoch 8 [1/172] - loss: 0.0215, acc: 1.0000
Epoch 8 [2/172] - loss: 0.0401
Epoch 8 [3/172] - loss: 0.0323
Epoch 8 [4/172] - loss: 0.0242
Epoch 8 [5/172] - loss: 0.0484
Epoch 8 [6/172] - loss: 0.0511
Epoch 8 [7/172] - loss: 0.0260
Epoch 8 [8/172] - loss: 0.0211
Epoch 8 [9/172] - loss: 0.1145
Epoch 8 [10/172] - loss: 0.0449, acc: 0.9688
Epoch 8 [11/172] - loss: 0.0354
Epoch 8 [12/172] - loss: 0.0588
Epoch 8 [13/172] - loss: 0.0199
Epoch 8 [14/172] - loss: 0.0271
Epoch 8 [15/172] - loss: 0.0343
Epoch 8 [16/172] - loss: 0.0206
Epoch 8 [17/172] - loss: 0.0239
Epoch 8 [18/172] - loss: 0.0218
Epoch 8 [19/172] - loss: 0.0303
Epoch 8 [20/172] - loss: 0.0177, acc: 1.0000
Epoch 8 [21/172] - loss: 0.0254
Epoch 8 [22/172] - loss: 0.0256
Epoch 8 [23/172] - loss: 0.0278
Epoch 8 [24/172] - loss: 0.0199
Epoch 8 [25/172] - loss: 0.0358
Epoch 8 [26/172] - loss: 0.0232
Epoch 8 [27/172] - loss: 0.1216
Epoch 8 [28/172] - loss: 0.0408
Epoch 8 [29/172] - loss: 0.0206
Epoch 8 [30/172] - loss: 0.0187, acc: 1.0000
Epoch 8 [31/172] - loss: 0.0191
Epoch 8 [32/172] - loss: 0.0231
Epoch 8 [33/172] - loss: 0.0186
Epoch 8 [34/172] - loss: 0.0231
Epoch 8 [35/172] - loss: 0.0221
Epoch 8 [36/172] - loss: 0.0249
Epoch 8 [37/172] - loss: 0.0341
Epoch 8 [38/172] - loss: 0.0295
Epoch 8 [39/172] - loss: 0.0206
Epoch 8 [40/172] - loss: 0.0204, acc: 1.0000
Epoch 8 [41/172] - loss: 0.0235
Epoch 8 [42/172] - loss: 0.0349
Epoch 8 [43/172] - loss: 0.0225
Epoch 8 [44/172] - loss: 0.0754
Epoch 8 [45/172] - loss: 0.0228
Epoch 8 [46/172] - loss: 0.0273
Epoch 8 [47/172] - loss: 0.0228
Epoch 8 [48/172] - loss: 0.0648
Epoch 8 [49/172] - loss: 0.0201
Epoch 8 [50/172] - loss: 0.0245, acc: 1.0000
Epoch 8 [51/172] - loss: 0.0345
Epoch 8 [52/172] - loss: 0.0207
Epoch 8 [53/172] - loss: 0.0241
Epoch 8 [54/172] - loss: 0.0341
Epoch 8 [55/172] - loss: 0.0225
Epoch 8 [56/172] - loss: 0.0226
Epoch 8 [57/172] - loss: 0.0280
Epoch 8 [58/172] - loss: 0.0193
Epoch 8 [59/172] - loss: 0.0217
Epoch 8 [60/172] - loss: 0.0239, acc: 1.0000
Epoch 8 [61/172] - loss: 0.0228
Epoch 8 [62/172] - loss: 0.0170
Epoch 8 [63/172] - loss: 0.0191
Epoch 8 [64/172] - loss: 0.0211
Epoch 8 [65/172] - loss: 0.0177
Epoch 8 [66/172] - loss: 0.0256
Epoch 8 [67/172] - loss: 0.0257
Epoch 8 [68/172] - loss: 0.0186
Epoch 8 [69/172] - loss: 0.0188
Epoch 8 [70/172] - loss: 0.0190, acc: 1.0000
Epoch 8 [71/172] - loss: 0.0598
Epoch 8 [72/172] - loss: 0.0182
Epoch 8 [73/172] - loss: 0.0272
Epoch 8 [74/172] - loss: 0.0466
Epoch 8 [75/172] - loss: 0.0177
Epoch 8 [76/172] - loss: 0.1381
Epoch 8 [77/172] - loss: 0.0199
Epoch 8 [78/172] - loss: 0.0502
Epoch 8 [79/172] - loss: 0.0268
Epoch 8 [80/172] - loss: 0.0340, acc: 1.0000
Epoch 8 [81/172] - loss: 0.0201
Epoch 8 [82/172] - loss: 0.0206
Epoch 8 [83/172] - loss: 0.0185
Epoch 8 [84/172] - loss: 0.0199
Epoch 8 [85/172] - loss: 0.0265
Epoch 8 [86/172] - loss: 0.0195
Epoch 8 [87/172] - loss: 0.0487
Epoch 8 [88/172] - loss: 0.0291
Epoch 8 [89/172] - loss: 0.0219
Epoch 8 [90/172] - loss: 0.0183, acc: 1.0000
Epoch 8 [91/172] - loss: 0.0662
Epoch 8 [92/172] - loss: 0.0486
Epoch 8 [93/172] - loss: 0.0209
Epoch 8 [94/172] - loss: 0.0286
Epoch 8 [95/172] - loss: 0.0199
Epoch 8 [96/172] - loss: 0.0199

=== 第 1301 次迭代调试信息 ===
当前类别统计：
positive: count=14487.0, difficulty=0.2400, log_difficulty=0.2151, weight=2.0754
neutral: count=12738.0, difficulty=0.2000, log_difficulty=0.1823, weight=1.9117
negative: count=14288.0, difficulty=0.2475, log_difficulty=0.2211, weight=2.1056

当前batch的pt分布：
positive: min=0.8400, max=0.9865, mean=0.9315
neutral: min=0.0923, max=0.9903, mean=0.8000
negative: min=0.9400, max=0.9954, mean=0.9768

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 0.8667
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1820
焦点损失: 0.0725
边界损失: 0.1931
总损失: 0.1440
Epoch 8 [97/172] - loss: 0.1440
Epoch 8 [98/172] - loss: 0.0298
Epoch 8 [99/172] - loss: 0.0191
Epoch 8 [100/172] - loss: 0.0363, acc: 0.9688
Epoch 8 [101/172] - loss: 0.0381
Epoch 8 [102/172] - loss: 0.0725
Epoch 8 [103/172] - loss: 0.0727
Epoch 8 [104/172] - loss: 0.0262
Epoch 8 [105/172] - loss: 0.0342
Epoch 8 [106/172] - loss: 0.0227
Epoch 8 [107/172] - loss: 0.0444
Epoch 8 [108/172] - loss: 0.0235
Epoch 8 [109/172] - loss: 0.0964
Epoch 8 [110/172] - loss: 0.0258, acc: 1.0000
Epoch 8 [111/172] - loss: 0.0755
Epoch 8 [112/172] - loss: 0.1350
Epoch 8 [113/172] - loss: 0.0210
Epoch 8 [114/172] - loss: 0.0196
Epoch 8 [115/172] - loss: 0.0368
Epoch 8 [116/172] - loss: 0.0645
Epoch 8 [117/172] - loss: 0.0189
Epoch 8 [118/172] - loss: 0.0191
Epoch 8 [119/172] - loss: 0.0186
Epoch 8 [120/172] - loss: 0.0367, acc: 0.9688
Epoch 8 [121/172] - loss: 0.0451
Epoch 8 [122/172] - loss: 0.0181
Epoch 8 [123/172] - loss: 0.0263
Epoch 8 [124/172] - loss: 0.0198
Epoch 8 [125/172] - loss: 0.0296
Epoch 8 [126/172] - loss: 0.0260
Epoch 8 [127/172] - loss: 0.0435
Epoch 8 [128/172] - loss: 0.0917
Epoch 8 [129/172] - loss: 0.0543
Epoch 8 [130/172] - loss: 0.0229, acc: 1.0000
Epoch 8 [131/172] - loss: 0.0465
Epoch 8 [132/172] - loss: 0.0212
Epoch 8 [133/172] - loss: 0.0298
Epoch 8 [134/172] - loss: 0.0233
Epoch 8 [135/172] - loss: 0.0185
Epoch 8 [136/172] - loss: 0.0363
Epoch 8 [137/172] - loss: 0.0225
Epoch 8 [138/172] - loss: 0.0797
Epoch 8 [139/172] - loss: 0.0432
Epoch 8 [140/172] - loss: 0.0181, acc: 1.0000
Epoch 8 [141/172] - loss: 0.0174
Epoch 8 [142/172] - loss: 0.0298
Epoch 8 [143/172] - loss: 0.0332
Epoch 8 [144/172] - loss: 0.0529
Epoch 8 [145/172] - loss: 0.0632
Epoch 8 [146/172] - loss: 0.0181
Epoch 8 [147/172] - loss: 0.0265
Epoch 8 [148/172] - loss: 0.0253
Epoch 8 [149/172] - loss: 0.0210
Epoch 8 [150/172] - loss: 0.0327, acc: 1.0000
Epoch 8 [151/172] - loss: 0.0278
Epoch 8 [152/172] - loss: 0.0373
Epoch 8 [153/172] - loss: 0.0222
Epoch 8 [154/172] - loss: 0.1585
Epoch 8 [155/172] - loss: 0.0168
Epoch 8 [156/172] - loss: 0.0204
Epoch 8 [157/172] - loss: 0.0274
Epoch 8 [158/172] - loss: 0.0267
Epoch 8 [159/172] - loss: 0.0243
Epoch 8 [160/172] - loss: 0.0264, acc: 1.0000
Epoch 8 [161/172] - loss: 0.0202
Epoch 8 [162/172] - loss: 0.0301
Epoch 8 [163/172] - loss: 0.0206
Epoch 8 [164/172] - loss: 0.0262
Epoch 8 [165/172] - loss: 0.0169
Epoch 8 [166/172] - loss: 0.0186
Epoch 8 [167/172] - loss: 0.0177
Epoch 8 [168/172] - loss: 0.0188
Epoch 8 [169/172] - loss: 0.0268
Epoch 8 [170/172] - loss: 0.0208, acc: 1.0000
Epoch 8 [171/172] - loss: 0.0481
Epoch 8 [172/172] - loss: 0.0206

类别准确率:
positive: 0.8415 (393/467)
neutral: 0.2530 (21/83)
negative: 0.6080 (152/250)

Epoch 8/10
Train Loss: 0.0244, Train Acc: 0.9980
Val Loss: 0.7834, Val Acc: 0.7075
Early stopping triggered!
Best validation accuracy: 0.7262

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_131940-ipoi0kbd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.35_Multimodal_iterations_20250118_131939
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/ipoi0kbd
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  train_acc ▂▁▃▃▄▄▄▇▅▆▆██████▇█▇▇█▇█████████████████
wandb: train_loss █▇▆▅▇▄▃▄▃▃▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1374
wandb:  train_acc 1
wandb: train_loss 0.02081
wandb: 
wandb: 🚀 View run loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.35_Multimodal_iterations_20250118_131939 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/ipoi0kbd
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_131940-ipoi0kbd/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_133143-otcok8wq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.35_Multimodal_epochs_20250118_133143
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/otcok8wq
wandb: uploading history steps 0-0, summary; updating run config; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▄▅▆▇█
wandb:  train_acc ▁▅▇▇██▇█
wandb: train_loss █▄▂▂▂▁▂▁
wandb:    val_acc ▂▁▆▇█▃▅▄
wandb:   val_loss ▃▃▁▃▄▇██
wandb: 
wandb: Run summary:
wandb:      epoch 8
wandb:  train_acc 0.99798
wandb: train_loss 0.02439
wandb:    val_acc 0.7075
wandb:   val_loss 0.78335
wandb: 
wandb: 🚀 View run loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.35_Multimodal_epochs_20250118_133143 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/otcok8wq
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_133143-otcok8wq/logs

