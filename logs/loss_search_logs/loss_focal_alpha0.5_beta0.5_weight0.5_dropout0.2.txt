=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 0.5 --dropout 0.2 --name loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.2 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.2
text_dim: 128
image_dim: 256
dropout: 0.2
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6689, log_difficulty=0.5121, weight=3.5607
neutral: count=7.0, difficulty=0.6678, log_difficulty=0.5115, weight=3.5576
negative: count=13.0, difficulty=0.6249, log_difficulty=0.4854, weight=3.4271

当前batch的pt分布：
positive: min=0.1974, max=0.4144, mean=0.3311
neutral: min=0.1984, max=0.4062, mean=0.3322
negative: min=0.1551, max=0.8516, mean=0.3751

当前batch准确率：
整体准确率: 0.4375
positive 准确率: 0.4167
neutral 准确率: 0.2857
negative 准确率: 0.5385

损失分量：
基础交叉熵: 1.0942
焦点损失: 0.3552
边界损失: 0.8589
总损失: 1.0523
Epoch 1 [1/172] - loss: 1.0523, acc: 0.4375
Epoch 1 [2/172] - loss: 1.0689
Epoch 1 [3/172] - loss: 1.1090
Epoch 1 [4/172] - loss: 0.9514
Epoch 1 [5/172] - loss: 0.9868
Epoch 1 [6/172] - loss: 1.3763
Epoch 1 [7/172] - loss: 0.9427
Epoch 1 [8/172] - loss: 1.1193
Epoch 1 [9/172] - loss: 1.1068
Epoch 1 [10/172] - loss: 1.3342, acc: 0.2500
Epoch 1 [11/172] - loss: 0.9082
Epoch 1 [12/172] - loss: 1.0541
Epoch 1 [13/172] - loss: 0.8977
Epoch 1 [14/172] - loss: 1.1661
Epoch 1 [15/172] - loss: 0.9263
Epoch 1 [16/172] - loss: 0.8180
Epoch 1 [17/172] - loss: 1.0752
Epoch 1 [18/172] - loss: 0.7700
Epoch 1 [19/172] - loss: 1.1148
Epoch 1 [20/172] - loss: 1.0020, acc: 0.5312
Epoch 1 [21/172] - loss: 0.9244
Epoch 1 [22/172] - loss: 0.8892
Epoch 1 [23/172] - loss: 1.0843
Epoch 1 [24/172] - loss: 1.0032
Epoch 1 [25/172] - loss: 0.9471
Epoch 1 [26/172] - loss: 0.9550
Epoch 1 [27/172] - loss: 0.7780
Epoch 1 [28/172] - loss: 0.7434
Epoch 1 [29/172] - loss: 0.7926
Epoch 1 [30/172] - loss: 0.7224, acc: 0.5938
Epoch 1 [31/172] - loss: 0.9724
Epoch 1 [32/172] - loss: 0.8536
Epoch 1 [33/172] - loss: 0.7747
Epoch 1 [34/172] - loss: 0.8358
Epoch 1 [35/172] - loss: 1.0165
Epoch 1 [36/172] - loss: 0.6318
Epoch 1 [37/172] - loss: 0.8320
Epoch 1 [38/172] - loss: 0.7544
Epoch 1 [39/172] - loss: 0.6719
Epoch 1 [40/172] - loss: 0.6435, acc: 0.6562
Epoch 1 [41/172] - loss: 0.8942
Epoch 1 [42/172] - loss: 0.5689
Epoch 1 [43/172] - loss: 1.0426
Epoch 1 [44/172] - loss: 0.9281
Epoch 1 [45/172] - loss: 0.9090
Epoch 1 [46/172] - loss: 0.7184
Epoch 1 [47/172] - loss: 0.7961
Epoch 1 [48/172] - loss: 0.7267
Epoch 1 [49/172] - loss: 0.9249
Epoch 1 [50/172] - loss: 0.6757, acc: 0.6562
Epoch 1 [51/172] - loss: 0.8778
Epoch 1 [52/172] - loss: 0.7929
Epoch 1 [53/172] - loss: 0.8068
Epoch 1 [54/172] - loss: 0.7600
Epoch 1 [55/172] - loss: 0.6769
Epoch 1 [56/172] - loss: 0.4912
Epoch 1 [57/172] - loss: 0.6949
Epoch 1 [58/172] - loss: 0.4129
Epoch 1 [59/172] - loss: 0.9212
Epoch 1 [60/172] - loss: 0.4697, acc: 0.8438
Epoch 1 [61/172] - loss: 0.8149
Epoch 1 [62/172] - loss: 0.6646
Epoch 1 [63/172] - loss: 0.7740
Epoch 1 [64/172] - loss: 0.5213
Epoch 1 [65/172] - loss: 0.7090
Epoch 1 [66/172] - loss: 0.6991
Epoch 1 [67/172] - loss: 0.7543
Epoch 1 [68/172] - loss: 0.8931
Epoch 1 [69/172] - loss: 0.7132
Epoch 1 [70/172] - loss: 0.6660, acc: 0.7812
Epoch 1 [71/172] - loss: 0.6231
Epoch 1 [72/172] - loss: 0.6496
Epoch 1 [73/172] - loss: 0.6503
Epoch 1 [74/172] - loss: 0.6111
Epoch 1 [75/172] - loss: 0.3373
Epoch 1 [76/172] - loss: 0.5067
Epoch 1 [77/172] - loss: 0.6572
Epoch 1 [78/172] - loss: 0.6321
Epoch 1 [79/172] - loss: 0.6681
Epoch 1 [80/172] - loss: 0.4718, acc: 0.8125
Epoch 1 [81/172] - loss: 0.5864
Epoch 1 [82/172] - loss: 0.9531
Epoch 1 [83/172] - loss: 0.4850
Epoch 1 [84/172] - loss: 0.5890
Epoch 1 [85/172] - loss: 0.5261
Epoch 1 [86/172] - loss: 0.8081
Epoch 1 [87/172] - loss: 0.5530
Epoch 1 [88/172] - loss: 0.9402
Epoch 1 [89/172] - loss: 0.8793
Epoch 1 [90/172] - loss: 0.6749, acc: 0.6250
Epoch 1 [91/172] - loss: 0.6992
Epoch 1 [92/172] - loss: 0.5427
Epoch 1 [93/172] - loss: 0.6086
Epoch 1 [94/172] - loss: 0.4206
Epoch 1 [95/172] - loss: 0.5699
Epoch 1 [96/172] - loss: 0.5414
Epoch 1 [97/172] - loss: 0.6615
Epoch 1 [98/172] - loss: 0.4797
Epoch 1 [99/172] - loss: 0.6882
Epoch 1 [100/172] - loss: 0.6442, acc: 0.6562

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5407, log_difficulty=0.4323, weight=3.1613
neutral: count=983.0, difficulty=0.5300, log_difficulty=0.4252, weight=3.1262
negative: count=1119.0, difficulty=0.5342, log_difficulty=0.4280, weight=3.1399

当前batch的pt分布：
positive: min=0.0766, max=0.8651, mean=0.4949
neutral: min=0.4980, max=0.9601, mean=0.7516
negative: min=0.0342, max=0.8634, mean=0.4690

当前batch准确率：
整体准确率: 0.6562
positive 准确率: 0.5833
neutral 准确率: 1.0000
negative 准确率: 0.6250

损失分量：
基础交叉熵: 0.8404
焦点损失: 0.3422
边界损失: 0.4508
总损失: 0.7640
Epoch 1 [101/172] - loss: 0.7640
Epoch 1 [102/172] - loss: 0.4780
Epoch 1 [103/172] - loss: 0.5372
Epoch 1 [104/172] - loss: 0.4967
Epoch 1 [105/172] - loss: 0.6224
Epoch 1 [106/172] - loss: 0.7756
Epoch 1 [107/172] - loss: 0.4203
Epoch 1 [108/172] - loss: 1.0136
Epoch 1 [109/172] - loss: 0.6648
Epoch 1 [110/172] - loss: 0.7190, acc: 0.6875
Epoch 1 [111/172] - loss: 0.6146
Epoch 1 [112/172] - loss: 0.4380
Epoch 1 [113/172] - loss: 0.4755
Epoch 1 [114/172] - loss: 0.5186
Epoch 1 [115/172] - loss: 0.6547
Epoch 1 [116/172] - loss: 0.5956
Epoch 1 [117/172] - loss: 0.4169
Epoch 1 [118/172] - loss: 0.3835
Epoch 1 [119/172] - loss: 0.6103
Epoch 1 [120/172] - loss: 0.3295, acc: 0.8750
Epoch 1 [121/172] - loss: 0.3624
Epoch 1 [122/172] - loss: 0.6139
Epoch 1 [123/172] - loss: 0.3050
Epoch 1 [124/172] - loss: 0.3891
Epoch 1 [125/172] - loss: 0.5732
Epoch 1 [126/172] - loss: 0.8231
Epoch 1 [127/172] - loss: 0.4111
Epoch 1 [128/172] - loss: 0.4267
Epoch 1 [129/172] - loss: 0.6365
Epoch 1 [130/172] - loss: 0.4347, acc: 0.7500
Epoch 1 [131/172] - loss: 0.3895
Epoch 1 [132/172] - loss: 0.4650
Epoch 1 [133/172] - loss: 0.5050
Epoch 1 [134/172] - loss: 0.5094
Epoch 1 [135/172] - loss: 0.4974
Epoch 1 [136/172] - loss: 0.4866
Epoch 1 [137/172] - loss: 0.7224
Epoch 1 [138/172] - loss: 0.4272
Epoch 1 [139/172] - loss: 0.3030
Epoch 1 [140/172] - loss: 0.4719, acc: 0.8125
Epoch 1 [141/172] - loss: 0.5118
Epoch 1 [142/172] - loss: 0.4805
Epoch 1 [143/172] - loss: 0.4035
Epoch 1 [144/172] - loss: 0.4352
Epoch 1 [145/172] - loss: 0.4607
Epoch 1 [146/172] - loss: 0.6155
Epoch 1 [147/172] - loss: 0.5655
Epoch 1 [148/172] - loss: 0.3600
Epoch 1 [149/172] - loss: 0.2968
Epoch 1 [150/172] - loss: 0.5123, acc: 0.6875
Epoch 1 [151/172] - loss: 0.6044
Epoch 1 [152/172] - loss: 0.3939
Epoch 1 [153/172] - loss: 0.4998
Epoch 1 [154/172] - loss: 0.3638
Epoch 1 [155/172] - loss: 0.4851
Epoch 1 [156/172] - loss: 0.7006
Epoch 1 [157/172] - loss: 0.4868
Epoch 1 [158/172] - loss: 0.3510
Epoch 1 [159/172] - loss: 0.5773
Epoch 1 [160/172] - loss: 0.4187, acc: 0.8125
Epoch 1 [161/172] - loss: 0.3127
Epoch 1 [162/172] - loss: 0.5032
Epoch 1 [163/172] - loss: 0.4357
Epoch 1 [164/172] - loss: 0.6274
Epoch 1 [165/172] - loss: 0.4693
Epoch 1 [166/172] - loss: 0.3421
Epoch 1 [167/172] - loss: 0.3591
Epoch 1 [168/172] - loss: 0.4368
Epoch 1 [169/172] - loss: 0.4480
Epoch 1 [170/172] - loss: 0.3485, acc: 0.8438
Epoch 1 [171/172] - loss: 0.2794
Epoch 1 [172/172] - loss: 0.6320

类别准确率:
positive: 0.5118 (239/467)
neutral: 0.4096 (34/83)
negative: 0.9000 (225/250)

Epoch 1/10
Train Loss: 0.4392, Train Acc: 0.7939
Val Loss: 0.8135, Val Acc: 0.6225
Epoch 2 [1/172] - loss: 0.3389, acc: 0.8438
Epoch 2 [2/172] - loss: 0.2826
Epoch 2 [3/172] - loss: 0.3163
Epoch 2 [4/172] - loss: 0.3898
Epoch 2 [5/172] - loss: 0.4034
Epoch 2 [6/172] - loss: 0.4086
Epoch 2 [7/172] - loss: 0.4102
Epoch 2 [8/172] - loss: 0.2564
Epoch 2 [9/172] - loss: 0.2873
Epoch 2 [10/172] - loss: 0.3260, acc: 0.9688
Epoch 2 [11/172] - loss: 0.1899
Epoch 2 [12/172] - loss: 0.2335
Epoch 2 [13/172] - loss: 0.3959
Epoch 2 [14/172] - loss: 0.2586
Epoch 2 [15/172] - loss: 0.3513
Epoch 2 [16/172] - loss: 0.2749
Epoch 2 [17/172] - loss: 0.2903
Epoch 2 [18/172] - loss: 0.4049
Epoch 2 [19/172] - loss: 0.2943
Epoch 2 [20/172] - loss: 0.2488, acc: 0.9062
Epoch 2 [21/172] - loss: 0.2825
Epoch 2 [22/172] - loss: 0.3635
Epoch 2 [23/172] - loss: 0.2071
Epoch 2 [24/172] - loss: 0.6277
Epoch 2 [25/172] - loss: 0.4304
Epoch 2 [26/172] - loss: 0.2036
Epoch 2 [27/172] - loss: 0.2029
Epoch 2 [28/172] - loss: 0.2405

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4632, log_difficulty=0.3806, weight=2.9032
neutral: count=1952.0, difficulty=0.4181, log_difficulty=0.3493, weight=2.7464
negative: count=2216.0, difficulty=0.4586, log_difficulty=0.3775, weight=2.8875

当前batch的pt分布：
positive: min=0.5940, max=0.9160, mean=0.7843
neutral: min=0.5039, max=0.9828, mean=0.7600
negative: min=0.3193, max=0.9550, mean=0.7123

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.3256
焦点损失: 0.0432
边界损失: 0.3091
总损失: 0.2162
Epoch 2 [29/172] - loss: 0.2162
Epoch 2 [30/172] - loss: 0.3050, acc: 0.9062
Epoch 2 [31/172] - loss: 0.3162
Epoch 2 [32/172] - loss: 0.1933
Epoch 2 [33/172] - loss: 0.2280
Epoch 2 [34/172] - loss: 0.2510
Epoch 2 [35/172] - loss: 0.1994
Epoch 2 [36/172] - loss: 0.3395
Epoch 2 [37/172] - loss: 0.3065
Epoch 2 [38/172] - loss: 0.2299
Epoch 2 [39/172] - loss: 0.4168
Epoch 2 [40/172] - loss: 0.3737, acc: 0.7188
Epoch 2 [41/172] - loss: 0.1991
Epoch 2 [42/172] - loss: 0.1566
Epoch 2 [43/172] - loss: 0.1991
Epoch 2 [44/172] - loss: 0.5609
Epoch 2 [45/172] - loss: 0.1674
Epoch 2 [46/172] - loss: 0.2178
Epoch 2 [47/172] - loss: 0.2721
Epoch 2 [48/172] - loss: 0.3109
Epoch 2 [49/172] - loss: 0.1841
Epoch 2 [50/172] - loss: 0.4162, acc: 0.8125
Epoch 2 [51/172] - loss: 0.2565
Epoch 2 [52/172] - loss: 0.2174
Epoch 2 [53/172] - loss: 0.1501
Epoch 2 [54/172] - loss: 0.2639
Epoch 2 [55/172] - loss: 0.2643
Epoch 2 [56/172] - loss: 0.2708
Epoch 2 [57/172] - loss: 0.1679
Epoch 2 [58/172] - loss: 0.2636
Epoch 2 [59/172] - loss: 0.4102
Epoch 2 [60/172] - loss: 0.1748, acc: 0.9688
Epoch 2 [61/172] - loss: 0.1167
Epoch 2 [62/172] - loss: 0.1441
Epoch 2 [63/172] - loss: 0.2142
Epoch 2 [64/172] - loss: 0.2560
Epoch 2 [65/172] - loss: 0.2699
Epoch 2 [66/172] - loss: 0.2005
Epoch 2 [67/172] - loss: 0.1503
Epoch 2 [68/172] - loss: 0.3132
Epoch 2 [69/172] - loss: 0.1424
Epoch 2 [70/172] - loss: 0.3222, acc: 0.8750
Epoch 2 [71/172] - loss: 0.3057
Epoch 2 [72/172] - loss: 0.3769
Epoch 2 [73/172] - loss: 0.2848
Epoch 2 [74/172] - loss: 0.2657
Epoch 2 [75/172] - loss: 0.1589
Epoch 2 [76/172] - loss: 0.3785
Epoch 2 [77/172] - loss: 0.3084
Epoch 2 [78/172] - loss: 0.1787
Epoch 2 [79/172] - loss: 0.2244
Epoch 2 [80/172] - loss: 0.1801, acc: 0.9375
Epoch 2 [81/172] - loss: 0.1694
Epoch 2 [82/172] - loss: 0.2165
Epoch 2 [83/172] - loss: 0.2128
Epoch 2 [84/172] - loss: 0.2750
Epoch 2 [85/172] - loss: 0.2219
Epoch 2 [86/172] - loss: 0.2732
Epoch 2 [87/172] - loss: 0.4308
Epoch 2 [88/172] - loss: 0.3084
Epoch 2 [89/172] - loss: 0.1615
Epoch 2 [90/172] - loss: 0.2692, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1648
Epoch 2 [92/172] - loss: 0.3800
Epoch 2 [93/172] - loss: 0.2355
Epoch 2 [94/172] - loss: 0.2006
Epoch 2 [95/172] - loss: 0.3622
Epoch 2 [96/172] - loss: 0.1669
Epoch 2 [97/172] - loss: 0.2003
Epoch 2 [98/172] - loss: 0.1573
Epoch 2 [99/172] - loss: 0.1647
Epoch 2 [100/172] - loss: 0.1369, acc: 0.9688
Epoch 2 [101/172] - loss: 0.1785
Epoch 2 [102/172] - loss: 0.1423
Epoch 2 [103/172] - loss: 0.2184
Epoch 2 [104/172] - loss: 0.2141
Epoch 2 [105/172] - loss: 0.1649
Epoch 2 [106/172] - loss: 0.1623
Epoch 2 [107/172] - loss: 0.2443
Epoch 2 [108/172] - loss: 0.3593
Epoch 2 [109/172] - loss: 0.1458
Epoch 2 [110/172] - loss: 0.1963, acc: 0.9375
Epoch 2 [111/172] - loss: 0.1523
Epoch 2 [112/172] - loss: 0.1509
Epoch 2 [113/172] - loss: 0.1208
Epoch 2 [114/172] - loss: 0.1637
Epoch 2 [115/172] - loss: 0.3309
Epoch 2 [116/172] - loss: 0.2918
Epoch 2 [117/172] - loss: 0.2533
Epoch 2 [118/172] - loss: 0.1586
Epoch 2 [119/172] - loss: 0.1686
Epoch 2 [120/172] - loss: 0.1337, acc: 1.0000
Epoch 2 [121/172] - loss: 0.1344
Epoch 2 [122/172] - loss: 0.3519
Epoch 2 [123/172] - loss: 0.2284
Epoch 2 [124/172] - loss: 0.3192
Epoch 2 [125/172] - loss: 0.2179
Epoch 2 [126/172] - loss: 0.1482
Epoch 2 [127/172] - loss: 0.1434
Epoch 2 [128/172] - loss: 0.1911

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3932, log_difficulty=0.3316, weight=2.6582
neutral: count=2949.0, difficulty=0.3271, log_difficulty=0.2830, weight=2.4151
negative: count=3294.0, difficulty=0.3857, log_difficulty=0.3262, weight=2.6310

当前batch的pt分布：
positive: min=0.5187, max=0.9915, mean=0.8320
neutral: min=0.3583, max=0.9923, mean=0.8314
negative: min=0.2333, max=0.9775, mean=0.7228

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 1.0000
neutral 准确率: 0.9091
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.2783
焦点损失: 0.0582
边界损失: 0.2514
总损失: 0.2010
Epoch 2 [129/172] - loss: 0.2010
Epoch 2 [130/172] - loss: 0.2510, acc: 0.8438
Epoch 2 [131/172] - loss: 0.1773
Epoch 2 [132/172] - loss: 0.2123
Epoch 2 [133/172] - loss: 0.2622
Epoch 2 [134/172] - loss: 0.2770
Epoch 2 [135/172] - loss: 0.4227
Epoch 2 [136/172] - loss: 0.1481
Epoch 2 [137/172] - loss: 0.1431
Epoch 2 [138/172] - loss: 0.1730
Epoch 2 [139/172] - loss: 0.2028
Epoch 2 [140/172] - loss: 0.2069, acc: 0.9062
Epoch 2 [141/172] - loss: 0.2010
Epoch 2 [142/172] - loss: 0.2829
Epoch 2 [143/172] - loss: 0.2609
Epoch 2 [144/172] - loss: 0.2714
Epoch 2 [145/172] - loss: 0.6595
Epoch 2 [146/172] - loss: 0.1838
Epoch 2 [147/172] - loss: 0.1502
Epoch 2 [148/172] - loss: 0.3163
Epoch 2 [149/172] - loss: 0.2747
Epoch 2 [150/172] - loss: 0.3249, acc: 0.8750
Epoch 2 [151/172] - loss: 0.1650
Epoch 2 [152/172] - loss: 0.1493
Epoch 2 [153/172] - loss: 0.2669
Epoch 2 [154/172] - loss: 0.1642
Epoch 2 [155/172] - loss: 0.3807
Epoch 2 [156/172] - loss: 0.1892
Epoch 2 [157/172] - loss: 0.1081
Epoch 2 [158/172] - loss: 0.2415
Epoch 2 [159/172] - loss: 0.2633
Epoch 2 [160/172] - loss: 0.1951, acc: 0.9375
Epoch 2 [161/172] - loss: 0.2389
Epoch 2 [162/172] - loss: 0.1339
Epoch 2 [163/172] - loss: 0.2053
Epoch 2 [164/172] - loss: 0.1747
Epoch 2 [165/172] - loss: 0.2605
Epoch 2 [166/172] - loss: 0.2624
Epoch 2 [167/172] - loss: 0.2002
Epoch 2 [168/172] - loss: 0.1436
Epoch 2 [169/172] - loss: 0.1637
Epoch 2 [170/172] - loss: 0.1867, acc: 0.9062
Epoch 2 [171/172] - loss: 0.4461
Epoch 2 [172/172] - loss: 0.2597

类别准确率:
positive: 0.8630 (403/467)
neutral: 0.3133 (26/83)
negative: 0.6200 (155/250)

Epoch 2/10
Train Loss: 0.2177, Train Acc: 0.9111
Val Loss: 0.6456, Val Acc: 0.7300
Epoch 3 [1/172] - loss: 0.1685, acc: 0.9688
Epoch 3 [2/172] - loss: 0.2411
Epoch 3 [3/172] - loss: 0.1071
Epoch 3 [4/172] - loss: 0.1681
Epoch 3 [5/172] - loss: 0.1667
Epoch 3 [6/172] - loss: 0.1471
Epoch 3 [7/172] - loss: 0.1534
Epoch 3 [8/172] - loss: 0.1258
Epoch 3 [9/172] - loss: 0.1269
Epoch 3 [10/172] - loss: 0.1278, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1154
Epoch 3 [12/172] - loss: 0.0971
Epoch 3 [13/172] - loss: 0.1504
Epoch 3 [14/172] - loss: 0.1169
Epoch 3 [15/172] - loss: 0.1054
Epoch 3 [16/172] - loss: 0.3379
Epoch 3 [17/172] - loss: 0.1254
Epoch 3 [18/172] - loss: 0.1489
Epoch 3 [19/172] - loss: 0.1114
Epoch 3 [20/172] - loss: 0.1409, acc: 0.9062
Epoch 3 [21/172] - loss: 0.1175
Epoch 3 [22/172] - loss: 0.2116
Epoch 3 [23/172] - loss: 0.1345
Epoch 3 [24/172] - loss: 0.1535
Epoch 3 [25/172] - loss: 0.0987
Epoch 3 [26/172] - loss: 0.1280
Epoch 3 [27/172] - loss: 0.1534
Epoch 3 [28/172] - loss: 0.0930
Epoch 3 [29/172] - loss: 0.2535
Epoch 3 [30/172] - loss: 0.1874, acc: 0.9375
Epoch 3 [31/172] - loss: 0.1157
Epoch 3 [32/172] - loss: 0.1228
Epoch 3 [33/172] - loss: 0.1039
Epoch 3 [34/172] - loss: 0.1640
Epoch 3 [35/172] - loss: 0.2635
Epoch 3 [36/172] - loss: 0.0974
Epoch 3 [37/172] - loss: 0.2043
Epoch 3 [38/172] - loss: 0.1082
Epoch 3 [39/172] - loss: 0.0965
Epoch 3 [40/172] - loss: 0.1646, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1142
Epoch 3 [42/172] - loss: 0.1440
Epoch 3 [43/172] - loss: 0.2142
Epoch 3 [44/172] - loss: 0.0956
Epoch 3 [45/172] - loss: 0.1005
Epoch 3 [46/172] - loss: 0.1216
Epoch 3 [47/172] - loss: 0.0974
Epoch 3 [48/172] - loss: 0.1240
Epoch 3 [49/172] - loss: 0.0870
Epoch 3 [50/172] - loss: 0.1375, acc: 0.9688
Epoch 3 [51/172] - loss: 0.2529
Epoch 3 [52/172] - loss: 0.2517
Epoch 3 [53/172] - loss: 0.1056
Epoch 3 [54/172] - loss: 0.2170
Epoch 3 [55/172] - loss: 0.0981
Epoch 3 [56/172] - loss: 0.1192

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3390, log_difficulty=0.2919, weight=2.4597
neutral: count=3923.0, difficulty=0.2754, log_difficulty=0.2433, weight=2.2164
negative: count=4382.0, difficulty=0.3341, log_difficulty=0.2882, weight=2.4411

当前batch的pt分布：
positive: min=0.5114, max=0.9883, mean=0.8500
neutral: min=0.0039, max=0.9810, mean=0.7444
negative: min=0.9270, max=0.9928, mean=0.9683

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 1.0000
neutral 准确率: 0.8125
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3919
焦点损失: 0.2375
边界损失: 0.2171
总损失: 0.3724
Epoch 3 [57/172] - loss: 0.3724
Epoch 3 [58/172] - loss: 0.1042
Epoch 3 [59/172] - loss: 0.1294
Epoch 3 [60/172] - loss: 0.1628, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1029
Epoch 3 [62/172] - loss: 0.0996
Epoch 3 [63/172] - loss: 0.1034
Epoch 3 [64/172] - loss: 0.1041
Epoch 3 [65/172] - loss: 0.1379
Epoch 3 [66/172] - loss: 0.1263
Epoch 3 [67/172] - loss: 0.1168
Epoch 3 [68/172] - loss: 0.0979
Epoch 3 [69/172] - loss: 0.2416
Epoch 3 [70/172] - loss: 0.1051, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1343
Epoch 3 [72/172] - loss: 0.2020
Epoch 3 [73/172] - loss: 0.0919
Epoch 3 [74/172] - loss: 0.1250
Epoch 3 [75/172] - loss: 0.1087
Epoch 3 [76/172] - loss: 0.1234
Epoch 3 [77/172] - loss: 0.0998
Epoch 3 [78/172] - loss: 0.2673
Epoch 3 [79/172] - loss: 0.1487
Epoch 3 [80/172] - loss: 0.1606, acc: 0.9375
Epoch 3 [81/172] - loss: 0.1021
Epoch 3 [82/172] - loss: 0.1279
Epoch 3 [83/172] - loss: 0.0911
Epoch 3 [84/172] - loss: 0.0909
Epoch 3 [85/172] - loss: 0.1053
Epoch 3 [86/172] - loss: 0.0820
Epoch 3 [87/172] - loss: 0.1444
Epoch 3 [88/172] - loss: 0.1081
Epoch 3 [89/172] - loss: 0.0929
Epoch 3 [90/172] - loss: 0.0898, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1579
Epoch 3 [92/172] - loss: 0.0952
Epoch 3 [93/172] - loss: 0.1672
Epoch 3 [94/172] - loss: 0.1186
Epoch 3 [95/172] - loss: 0.0872
Epoch 3 [96/172] - loss: 0.1256
Epoch 3 [97/172] - loss: 0.0865
Epoch 3 [98/172] - loss: 0.0981
Epoch 3 [99/172] - loss: 0.0909
Epoch 3 [100/172] - loss: 0.1791, acc: 0.9688
Epoch 3 [101/172] - loss: 0.2159
Epoch 3 [102/172] - loss: 0.0799
Epoch 3 [103/172] - loss: 0.1171
Epoch 3 [104/172] - loss: 0.1126
Epoch 3 [105/172] - loss: 0.0935
Epoch 3 [106/172] - loss: 0.1598
Epoch 3 [107/172] - loss: 0.0847
Epoch 3 [108/172] - loss: 0.1069
Epoch 3 [109/172] - loss: 0.0876
Epoch 3 [110/172] - loss: 0.0945, acc: 1.0000
Epoch 3 [111/172] - loss: 0.1218
Epoch 3 [112/172] - loss: 0.1083
Epoch 3 [113/172] - loss: 0.1979
Epoch 3 [114/172] - loss: 0.0995
Epoch 3 [115/172] - loss: 0.1144
Epoch 3 [116/172] - loss: 0.1658
Epoch 3 [117/172] - loss: 0.1009
Epoch 3 [118/172] - loss: 0.1045
Epoch 3 [119/172] - loss: 0.1173
Epoch 3 [120/172] - loss: 0.2033, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1447
Epoch 3 [122/172] - loss: 0.1233
Epoch 3 [123/172] - loss: 0.0933
Epoch 3 [124/172] - loss: 0.0941
Epoch 3 [125/172] - loss: 0.1230
Epoch 3 [126/172] - loss: 0.2817
Epoch 3 [127/172] - loss: 0.1381
Epoch 3 [128/172] - loss: 0.1103
Epoch 3 [129/172] - loss: 0.0892
Epoch 3 [130/172] - loss: 0.0885, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1035
Epoch 3 [132/172] - loss: 0.0797
Epoch 3 [133/172] - loss: 0.1330
Epoch 3 [134/172] - loss: 0.0869
Epoch 3 [135/172] - loss: 0.1421
Epoch 3 [136/172] - loss: 0.1352
Epoch 3 [137/172] - loss: 0.0897
Epoch 3 [138/172] - loss: 0.0927
Epoch 3 [139/172] - loss: 0.0931
Epoch 3 [140/172] - loss: 0.1339, acc: 0.9688
Epoch 3 [141/172] - loss: 0.2510
Epoch 3 [142/172] - loss: 0.1024
Epoch 3 [143/172] - loss: 0.1569
Epoch 3 [144/172] - loss: 0.1681
Epoch 3 [145/172] - loss: 0.1171
Epoch 3 [146/172] - loss: 0.1038
Epoch 3 [147/172] - loss: 0.1088
Epoch 3 [148/172] - loss: 0.0943
Epoch 3 [149/172] - loss: 0.1195
Epoch 3 [150/172] - loss: 0.2207, acc: 0.9375
Epoch 3 [151/172] - loss: 0.3227
Epoch 3 [152/172] - loss: 0.1430
Epoch 3 [153/172] - loss: 0.0884
Epoch 3 [154/172] - loss: 0.2488
Epoch 3 [155/172] - loss: 0.1064
Epoch 3 [156/172] - loss: 0.1067

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2954, log_difficulty=0.2588, weight=2.2942
neutral: count=4903.0, difficulty=0.2352, log_difficulty=0.2112, weight=2.0560
negative: count=5500.0, difficulty=0.2892, log_difficulty=0.2540, weight=2.2701

当前batch的pt分布：
positive: min=0.6375, max=0.9973, mean=0.8870
neutral: min=0.8919, max=0.9939, mean=0.9543
negative: min=0.4706, max=0.9886, mean=0.8717

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1121
焦点损失: 0.0102
边界损失: 0.1916
总损失: 0.1075
Epoch 3 [157/172] - loss: 0.1075
Epoch 3 [158/172] - loss: 0.1821
Epoch 3 [159/172] - loss: 0.0882
Epoch 3 [160/172] - loss: 0.2367, acc: 0.9375
Epoch 3 [161/172] - loss: 0.3296
Epoch 3 [162/172] - loss: 0.1322
Epoch 3 [163/172] - loss: 0.1060
Epoch 3 [164/172] - loss: 0.0858
Epoch 3 [165/172] - loss: 0.0835
Epoch 3 [166/172] - loss: 0.0970
Epoch 3 [167/172] - loss: 0.1565
Epoch 3 [168/172] - loss: 0.0866
Epoch 3 [169/172] - loss: 0.1087
Epoch 3 [170/172] - loss: 0.1214, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1031
Epoch 3 [172/172] - loss: 0.0870

类别准确率:
positive: 0.8994 (420/467)
neutral: 0.1687 (14/83)
negative: 0.5800 (145/250)

Epoch 3/10
Train Loss: 0.1320, Train Acc: 0.9737
Val Loss: 0.7869, Val Acc: 0.7238
Epoch 4 [1/172] - loss: 0.1002, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1049
Epoch 4 [3/172] - loss: 0.0968
Epoch 4 [4/172] - loss: 0.0937
Epoch 4 [5/172] - loss: 0.0939
Epoch 4 [6/172] - loss: 0.0848
Epoch 4 [7/172] - loss: 0.0914
Epoch 4 [8/172] - loss: 0.0812
Epoch 4 [9/172] - loss: 0.1597
Epoch 4 [10/172] - loss: 0.2011, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0815
Epoch 4 [12/172] - loss: 0.0828
Epoch 4 [13/172] - loss: 0.1151
Epoch 4 [14/172] - loss: 0.0993
Epoch 4 [15/172] - loss: 0.0835
Epoch 4 [16/172] - loss: 0.0860
Epoch 4 [17/172] - loss: 0.0884
Epoch 4 [18/172] - loss: 0.0900
Epoch 4 [19/172] - loss: 0.0911
Epoch 4 [20/172] - loss: 0.0853, acc: 1.0000
Epoch 4 [21/172] - loss: 0.2024
Epoch 4 [22/172] - loss: 0.0910
Epoch 4 [23/172] - loss: 0.1444
Epoch 4 [24/172] - loss: 0.0790
Epoch 4 [25/172] - loss: 0.0797
Epoch 4 [26/172] - loss: 0.2796
Epoch 4 [27/172] - loss: 0.0780
Epoch 4 [28/172] - loss: 0.1205
Epoch 4 [29/172] - loss: 0.1078
Epoch 4 [30/172] - loss: 0.1709, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1177
Epoch 4 [32/172] - loss: 0.1042
Epoch 4 [33/172] - loss: 0.1203
Epoch 4 [34/172] - loss: 0.0832
Epoch 4 [35/172] - loss: 0.0929
Epoch 4 [36/172] - loss: 0.0925
Epoch 4 [37/172] - loss: 0.0774
Epoch 4 [38/172] - loss: 0.0872
Epoch 4 [39/172] - loss: 0.2791
Epoch 4 [40/172] - loss: 0.1599, acc: 0.9062
Epoch 4 [41/172] - loss: 0.0861
Epoch 4 [42/172] - loss: 0.1293
Epoch 4 [43/172] - loss: 0.1656
Epoch 4 [44/172] - loss: 0.1023
Epoch 4 [45/172] - loss: 0.0799
Epoch 4 [46/172] - loss: 0.0820
Epoch 4 [47/172] - loss: 0.0924
Epoch 4 [48/172] - loss: 0.0860
Epoch 4 [49/172] - loss: 0.0824
Epoch 4 [50/172] - loss: 0.1695, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0943
Epoch 4 [52/172] - loss: 0.1499
Epoch 4 [53/172] - loss: 0.0868
Epoch 4 [54/172] - loss: 0.1273
Epoch 4 [55/172] - loss: 0.2599
Epoch 4 [56/172] - loss: 0.0893
Epoch 4 [57/172] - loss: 0.0801
Epoch 4 [58/172] - loss: 0.1167
Epoch 4 [59/172] - loss: 0.0805
Epoch 4 [60/172] - loss: 0.0809, acc: 1.0000
Epoch 4 [61/172] - loss: 0.0929
Epoch 4 [62/172] - loss: 0.1547
Epoch 4 [63/172] - loss: 0.0876
Epoch 4 [64/172] - loss: 0.1204
Epoch 4 [65/172] - loss: 0.1147
Epoch 4 [66/172] - loss: 0.0824
Epoch 4 [67/172] - loss: 0.1024
Epoch 4 [68/172] - loss: 0.0932
Epoch 4 [69/172] - loss: 0.1215
Epoch 4 [70/172] - loss: 0.1023, acc: 0.9688
Epoch 4 [71/172] - loss: 0.0797
Epoch 4 [72/172] - loss: 0.1061
Epoch 4 [73/172] - loss: 0.0967
Epoch 4 [74/172] - loss: 0.2040
Epoch 4 [75/172] - loss: 0.1160
Epoch 4 [76/172] - loss: 0.0790
Epoch 4 [77/172] - loss: 0.0882
Epoch 4 [78/172] - loss: 0.1733
Epoch 4 [79/172] - loss: 0.0818
Epoch 4 [80/172] - loss: 0.0971, acc: 0.9688
Epoch 4 [81/172] - loss: 0.0957
Epoch 4 [82/172] - loss: 0.0824
Epoch 4 [83/172] - loss: 0.0846
Epoch 4 [84/172] - loss: 0.0808

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2606, log_difficulty=0.2316, weight=2.1579
neutral: count=5865.0, difficulty=0.2072, log_difficulty=0.1883, weight=1.9413
negative: count=6629.0, difficulty=0.2556, log_difficulty=0.2276, weight=2.1381

当前batch的pt分布：
positive: min=0.7614, max=0.9899, mean=0.9009
neutral: min=0.5489, max=0.9991, mean=0.9300
negative: min=0.6176, max=0.9992, mean=0.9402

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0937
焦点损失: 0.0065
边界损失: 0.1799
总损失: 0.0965
Epoch 4 [85/172] - loss: 0.0965
Epoch 4 [86/172] - loss: 0.1004
Epoch 4 [87/172] - loss: 0.0912
Epoch 4 [88/172] - loss: 0.1353
Epoch 4 [89/172] - loss: 0.0853
Epoch 4 [90/172] - loss: 0.0783, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1734
Epoch 4 [92/172] - loss: 0.1487
Epoch 4 [93/172] - loss: 0.0760
Epoch 4 [94/172] - loss: 0.0806
Epoch 4 [95/172] - loss: 0.1555
Epoch 4 [96/172] - loss: 0.0983
Epoch 4 [97/172] - loss: 0.0800
Epoch 4 [98/172] - loss: 0.0812
Epoch 4 [99/172] - loss: 0.1068
Epoch 4 [100/172] - loss: 0.1068, acc: 0.9688
Epoch 4 [101/172] - loss: 0.0903
Epoch 4 [102/172] - loss: 0.1232
Epoch 4 [103/172] - loss: 0.0871
Epoch 4 [104/172] - loss: 0.0789
Epoch 4 [105/172] - loss: 0.1335
Epoch 4 [106/172] - loss: 0.0779
Epoch 4 [107/172] - loss: 0.1160
Epoch 4 [108/172] - loss: 0.1237
Epoch 4 [109/172] - loss: 0.0805
Epoch 4 [110/172] - loss: 0.2638, acc: 0.9062
Epoch 4 [111/172] - loss: 0.0777
Epoch 4 [112/172] - loss: 0.0829
Epoch 4 [113/172] - loss: 0.0822
Epoch 4 [114/172] - loss: 0.0938
Epoch 4 [115/172] - loss: 0.0945
Epoch 4 [116/172] - loss: 0.1054
Epoch 4 [117/172] - loss: 0.0807
Epoch 4 [118/172] - loss: 0.0961
Epoch 4 [119/172] - loss: 0.0849
Epoch 4 [120/172] - loss: 0.0878, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1496
Epoch 4 [122/172] - loss: 0.1184
Epoch 4 [123/172] - loss: 0.0787
Epoch 4 [124/172] - loss: 0.0801
Epoch 4 [125/172] - loss: 0.0942
Epoch 4 [126/172] - loss: 0.1237
Epoch 4 [127/172] - loss: 0.1414
Epoch 4 [128/172] - loss: 0.0939
Epoch 4 [129/172] - loss: 0.0748
Epoch 4 [130/172] - loss: 0.0753, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1320
Epoch 4 [132/172] - loss: 0.0769
Epoch 4 [133/172] - loss: 0.0927
Epoch 4 [134/172] - loss: 0.0794
Epoch 4 [135/172] - loss: 0.0912
Epoch 4 [136/172] - loss: 0.1228
Epoch 4 [137/172] - loss: 0.0960
Epoch 4 [138/172] - loss: 0.1370
Epoch 4 [139/172] - loss: 0.1735
Epoch 4 [140/172] - loss: 0.1237, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1329
Epoch 4 [142/172] - loss: 0.0970
Epoch 4 [143/172] - loss: 0.0854
Epoch 4 [144/172] - loss: 0.0816
Epoch 4 [145/172] - loss: 0.3219
Epoch 4 [146/172] - loss: 0.0816
Epoch 4 [147/172] - loss: 0.1111
Epoch 4 [148/172] - loss: 0.0843
Epoch 4 [149/172] - loss: 0.0836
Epoch 4 [150/172] - loss: 0.1150, acc: 0.9688
Epoch 4 [151/172] - loss: 0.2077
Epoch 4 [152/172] - loss: 0.0839
Epoch 4 [153/172] - loss: 0.0824
Epoch 4 [154/172] - loss: 0.2802
Epoch 4 [155/172] - loss: 0.0912
Epoch 4 [156/172] - loss: 0.0991
Epoch 4 [157/172] - loss: 0.2015
Epoch 4 [158/172] - loss: 0.0843
Epoch 4 [159/172] - loss: 0.1091
Epoch 4 [160/172] - loss: 0.1120, acc: 0.9688
Epoch 4 [161/172] - loss: 0.0938
Epoch 4 [162/172] - loss: 0.1070
Epoch 4 [163/172] - loss: 0.0939
Epoch 4 [164/172] - loss: 0.0904
Epoch 4 [165/172] - loss: 0.1885
Epoch 4 [166/172] - loss: 0.1411
Epoch 4 [167/172] - loss: 0.1011
Epoch 4 [168/172] - loss: 0.1105
Epoch 4 [169/172] - loss: 0.1691
Epoch 4 [170/172] - loss: 0.2286, acc: 0.9062
Epoch 4 [171/172] - loss: 0.1189
Epoch 4 [172/172] - loss: 0.1570

类别准确率:
positive: 0.9315 (435/467)
neutral: 0.2771 (23/83)
negative: 0.4240 (106/250)

Epoch 4/10
Train Loss: 0.1317, Train Acc: 0.9596
Val Loss: 0.8504, Val Acc: 0.7050
Epoch 5 [1/172] - loss: 0.0887, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0924
Epoch 5 [3/172] - loss: 0.0806
Epoch 5 [4/172] - loss: 0.1075
Epoch 5 [5/172] - loss: 0.0944
Epoch 5 [6/172] - loss: 0.1306
Epoch 5 [7/172] - loss: 0.0888
Epoch 5 [8/172] - loss: 0.0894
Epoch 5 [9/172] - loss: 0.1044
Epoch 5 [10/172] - loss: 0.0857, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1032
Epoch 5 [12/172] - loss: 0.0822

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2342, log_difficulty=0.2104, weight=2.0521
neutral: count=6845.0, difficulty=0.1864, log_difficulty=0.1709, weight=1.8545
negative: count=7694.0, difficulty=0.2318, log_difficulty=0.2085, weight=2.0423

当前batch的pt分布：
positive: min=0.0652, max=0.9937, mean=0.8672
neutral: min=0.9343, max=0.9973, mean=0.9862
negative: min=0.7789, max=0.9970, mean=0.9267

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1464
焦点损失: 0.0749
边界损失: 0.1668
总损失: 0.1602
Epoch 5 [13/172] - loss: 0.1602
Epoch 5 [14/172] - loss: 0.1077
Epoch 5 [15/172] - loss: 0.0921
Epoch 5 [16/172] - loss: 0.0783
Epoch 5 [17/172] - loss: 0.1475
Epoch 5 [18/172] - loss: 0.0789
Epoch 5 [19/172] - loss: 0.0904
Epoch 5 [20/172] - loss: 0.1077, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1522
Epoch 5 [22/172] - loss: 0.1382
Epoch 5 [23/172] - loss: 0.0879
Epoch 5 [24/172] - loss: 0.0946
Epoch 5 [25/172] - loss: 0.0879
Epoch 5 [26/172] - loss: 0.0967
Epoch 5 [27/172] - loss: 0.0786
Epoch 5 [28/172] - loss: 0.0826
Epoch 5 [29/172] - loss: 0.0794
Epoch 5 [30/172] - loss: 0.0776, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0913
Epoch 5 [32/172] - loss: 0.0793
Epoch 5 [33/172] - loss: 0.0798
Epoch 5 [34/172] - loss: 0.0823
Epoch 5 [35/172] - loss: 0.0795
Epoch 5 [36/172] - loss: 0.0796
Epoch 5 [37/172] - loss: 0.0823
Epoch 5 [38/172] - loss: 0.0779
Epoch 5 [39/172] - loss: 0.0972
Epoch 5 [40/172] - loss: 0.0873, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0828
Epoch 5 [42/172] - loss: 0.0918
Epoch 5 [43/172] - loss: 0.1905
Epoch 5 [44/172] - loss: 0.1189
Epoch 5 [45/172] - loss: 0.0777
Epoch 5 [46/172] - loss: 0.0882
Epoch 5 [47/172] - loss: 0.0852
Epoch 5 [48/172] - loss: 0.1081
Epoch 5 [49/172] - loss: 0.0929
Epoch 5 [50/172] - loss: 0.1112, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0797
Epoch 5 [52/172] - loss: 0.0790
Epoch 5 [53/172] - loss: 0.1014
Epoch 5 [54/172] - loss: 0.0832
Epoch 5 [55/172] - loss: 0.0822
Epoch 5 [56/172] - loss: 0.1347
Epoch 5 [57/172] - loss: 0.0752
Epoch 5 [58/172] - loss: 0.1010
Epoch 5 [59/172] - loss: 0.1958
Epoch 5 [60/172] - loss: 0.1572, acc: 0.9688
Epoch 5 [61/172] - loss: 0.0890
Epoch 5 [62/172] - loss: 0.0850
Epoch 5 [63/172] - loss: 0.1379
Epoch 5 [64/172] - loss: 0.0905
Epoch 5 [65/172] - loss: 0.0782
Epoch 5 [66/172] - loss: 0.0762
Epoch 5 [67/172] - loss: 0.0769
Epoch 5 [68/172] - loss: 0.1099
Epoch 5 [69/172] - loss: 0.0816
Epoch 5 [70/172] - loss: 0.1138, acc: 0.9688
Epoch 5 [71/172] - loss: 0.1015
Epoch 5 [72/172] - loss: 0.0948
Epoch 5 [73/172] - loss: 0.0904
Epoch 5 [74/172] - loss: 0.1016
Epoch 5 [75/172] - loss: 0.0886
Epoch 5 [76/172] - loss: 0.0776
Epoch 5 [77/172] - loss: 0.0828
Epoch 5 [78/172] - loss: 0.1203
Epoch 5 [79/172] - loss: 0.0793
Epoch 5 [80/172] - loss: 0.0789, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1145
Epoch 5 [82/172] - loss: 0.1189
Epoch 5 [83/172] - loss: 0.1625
Epoch 5 [84/172] - loss: 0.0762
Epoch 5 [85/172] - loss: 0.1618
Epoch 5 [86/172] - loss: 0.0850
Epoch 5 [87/172] - loss: 0.1099
Epoch 5 [88/172] - loss: 0.1115
Epoch 5 [89/172] - loss: 0.0821
Epoch 5 [90/172] - loss: 0.0991, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0783
Epoch 5 [92/172] - loss: 0.0871
Epoch 5 [93/172] - loss: 0.0817
Epoch 5 [94/172] - loss: 0.0760
Epoch 5 [95/172] - loss: 0.0821
Epoch 5 [96/172] - loss: 0.0864
Epoch 5 [97/172] - loss: 0.0958
Epoch 5 [98/172] - loss: 0.0811
Epoch 5 [99/172] - loss: 0.1978
Epoch 5 [100/172] - loss: 0.0935, acc: 0.9688
Epoch 5 [101/172] - loss: 0.0851
Epoch 5 [102/172] - loss: 0.0894
Epoch 5 [103/172] - loss: 0.1461
Epoch 5 [104/172] - loss: 0.1616
Epoch 5 [105/172] - loss: 0.1785
Epoch 5 [106/172] - loss: 0.1133
Epoch 5 [107/172] - loss: 0.0885
Epoch 5 [108/172] - loss: 0.0846
Epoch 5 [109/172] - loss: 0.0763
Epoch 5 [110/172] - loss: 0.0800, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0907
Epoch 5 [112/172] - loss: 0.0765

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2123, log_difficulty=0.1925, weight=1.9627
neutral: count=7825.0, difficulty=0.1701, log_difficulty=0.1571, weight=1.7855
negative: count=8780.0, difficulty=0.2119, log_difficulty=0.1922, weight=1.9609

当前batch的pt分布：
positive: min=0.3659, max=0.9869, mean=0.8659
neutral: min=0.8785, max=0.9871, mean=0.9575
negative: min=0.9915, max=0.9995, mean=0.9969

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1064
焦点损失: 0.0229
边界损失: 0.1750
总损失: 0.1099
Epoch 5 [113/172] - loss: 0.1099
Epoch 5 [114/172] - loss: 0.0926
Epoch 5 [115/172] - loss: 0.1102
Epoch 5 [116/172] - loss: 0.0825
Epoch 5 [117/172] - loss: 0.0786
Epoch 5 [118/172] - loss: 0.0934
Epoch 5 [119/172] - loss: 0.0816
Epoch 5 [120/172] - loss: 0.0795, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0859
Epoch 5 [122/172] - loss: 0.0787
Epoch 5 [123/172] - loss: 0.0863
Epoch 5 [124/172] - loss: 0.0754
Epoch 5 [125/172] - loss: 0.0777
Epoch 5 [126/172] - loss: 0.0778
Epoch 5 [127/172] - loss: 0.0801
Epoch 5 [128/172] - loss: 0.0782
Epoch 5 [129/172] - loss: 0.1315
Epoch 5 [130/172] - loss: 0.0772, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0927
Epoch 5 [132/172] - loss: 0.1244
Epoch 5 [133/172] - loss: 0.1226
Epoch 5 [134/172] - loss: 0.1219
Epoch 5 [135/172] - loss: 0.0761
Epoch 5 [136/172] - loss: 0.0842
Epoch 5 [137/172] - loss: 0.0926
Epoch 5 [138/172] - loss: 0.1177
Epoch 5 [139/172] - loss: 0.1445
Epoch 5 [140/172] - loss: 0.0871, acc: 1.0000
Epoch 5 [141/172] - loss: 0.0801
Epoch 5 [142/172] - loss: 0.0860
Epoch 5 [143/172] - loss: 0.0766
Epoch 5 [144/172] - loss: 0.0772
Epoch 5 [145/172] - loss: 0.0831
Epoch 5 [146/172] - loss: 0.0788
Epoch 5 [147/172] - loss: 0.1161
Epoch 5 [148/172] - loss: 0.0738
Epoch 5 [149/172] - loss: 0.0779
Epoch 5 [150/172] - loss: 0.1118, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0751
Epoch 5 [152/172] - loss: 0.0749
Epoch 5 [153/172] - loss: 0.0767
Epoch 5 [154/172] - loss: 0.0895
Epoch 5 [155/172] - loss: 0.1169
Epoch 5 [156/172] - loss: 0.0855
Epoch 5 [157/172] - loss: 0.0879
Epoch 5 [158/172] - loss: 0.0799
Epoch 5 [159/172] - loss: 0.0750
Epoch 5 [160/172] - loss: 0.0800, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0778
Epoch 5 [162/172] - loss: 0.0852
Epoch 5 [163/172] - loss: 0.0980
Epoch 5 [164/172] - loss: 0.0750
Epoch 5 [165/172] - loss: 0.1588
Epoch 5 [166/172] - loss: 0.0907
Epoch 5 [167/172] - loss: 0.0892
Epoch 5 [168/172] - loss: 0.0762
Epoch 5 [169/172] - loss: 0.0747
Epoch 5 [170/172] - loss: 0.0777, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0827
Epoch 5 [172/172] - loss: 0.1057

类别准确率:
positive: 0.8501 (397/467)
neutral: 0.3133 (26/83)
negative: 0.6240 (156/250)

Epoch 5/10
Train Loss: 0.0884, Train Acc: 0.9939
Val Loss: 0.8326, Val Acc: 0.7238
Early stopping triggered!
Best validation accuracy: 0.7300

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_071546-k968wmdx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.2_Multimodal_iterations_20250118_071545
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/k968wmdx
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇██
wandb:  train_acc ▁▅▆▆▅▅▆▆▇▇▇▇▇█▇█▇▇████▇█████████████████
wandb: train_loss █▄▆▅▃▄▃▃▃▄▂▁▂▂▂▁▂▁▂▁▁▁▂▂▂▂▁▁▁▁▁▁▂▁▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 858
wandb:  train_acc 1
wandb: train_loss 0.07767
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.2_Multimodal_iterations_20250118_071545 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/k968wmdx
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_071546-k968wmdx/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_072312-vvmk5fp4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.2_Multimodal_epochs_20250118_072312
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/vvmk5fp4
wandb: uploading history steps 0-0, summary; updating run config; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▃▅▆█
wandb:  train_acc ▁▅▇▇█
wandb: train_loss █▄▂▂▁
wandb:    val_acc ▁██▆█
wandb:   val_loss ▇▁▆█▇
wandb: 
wandb: Run summary:
wandb:      epoch 5
wandb:  train_acc 0.99394
wandb: train_loss 0.08841
wandb:    val_acc 0.72375
wandb:   val_loss 0.8326
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.2_Multimodal_epochs_20250118_072312 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/vvmk5fp4
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_072312-vvmk5fp4/logs

