=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 1.5 --dropout 0.15 --name loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.15 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.15
text_dim: 128
image_dim: 256
dropout: 0.15
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6909, log_difficulty=0.5252, weight=3.6262
neutral: count=7.0, difficulty=0.6809, log_difficulty=0.5193, weight=3.5967
negative: count=13.0, difficulty=0.6520, log_difficulty=0.5020, weight=3.5098

当前batch的pt分布：
positive: min=0.1995, max=0.4276, mean=0.3091
neutral: min=0.1578, max=0.4254, mean=0.3191
negative: min=0.1770, max=0.6418, mean=0.3480

当前batch准确率：
整体准确率: 0.3125
positive 准确率: 0.2500
neutral 准确率: 0.4286
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1593
焦点损失: 0.4032
边界损失: 0.8065
总损失: 1.1239
Epoch 1 [1/172] - loss: 1.1239, acc: 0.3125
Epoch 1 [2/172] - loss: 1.0363
Epoch 1 [3/172] - loss: 1.0555
Epoch 1 [4/172] - loss: 1.2045
Epoch 1 [5/172] - loss: 1.2676
Epoch 1 [6/172] - loss: 1.1628
Epoch 1 [7/172] - loss: 1.1082
Epoch 1 [8/172] - loss: 1.0854
Epoch 1 [9/172] - loss: 0.9538
Epoch 1 [10/172] - loss: 0.9831, acc: 0.4688
Epoch 1 [11/172] - loss: 0.9740
Epoch 1 [12/172] - loss: 0.9423
Epoch 1 [13/172] - loss: 0.9527
Epoch 1 [14/172] - loss: 1.1751
Epoch 1 [15/172] - loss: 1.0831
Epoch 1 [16/172] - loss: 0.9036
Epoch 1 [17/172] - loss: 0.9429
Epoch 1 [18/172] - loss: 0.9756
Epoch 1 [19/172] - loss: 0.9839
Epoch 1 [20/172] - loss: 0.9471, acc: 0.3750
Epoch 1 [21/172] - loss: 1.0022
Epoch 1 [22/172] - loss: 0.8306
Epoch 1 [23/172] - loss: 1.0266
Epoch 1 [24/172] - loss: 1.2641
Epoch 1 [25/172] - loss: 0.6850
Epoch 1 [26/172] - loss: 1.0209
Epoch 1 [27/172] - loss: 0.8851
Epoch 1 [28/172] - loss: 0.8093
Epoch 1 [29/172] - loss: 0.8703
Epoch 1 [30/172] - loss: 0.9653, acc: 0.5625
Epoch 1 [31/172] - loss: 0.9340
Epoch 1 [32/172] - loss: 0.7527
Epoch 1 [33/172] - loss: 0.7720
Epoch 1 [34/172] - loss: 0.8667
Epoch 1 [35/172] - loss: 0.8765
Epoch 1 [36/172] - loss: 0.6878
Epoch 1 [37/172] - loss: 0.8569
Epoch 1 [38/172] - loss: 0.8381
Epoch 1 [39/172] - loss: 0.6348
Epoch 1 [40/172] - loss: 0.7545, acc: 0.5938
Epoch 1 [41/172] - loss: 0.7354
Epoch 1 [42/172] - loss: 0.5918
Epoch 1 [43/172] - loss: 0.9179
Epoch 1 [44/172] - loss: 1.0601
Epoch 1 [45/172] - loss: 0.9516
Epoch 1 [46/172] - loss: 0.7443
Epoch 1 [47/172] - loss: 0.8352
Epoch 1 [48/172] - loss: 0.7674
Epoch 1 [49/172] - loss: 0.8807
Epoch 1 [50/172] - loss: 0.7412, acc: 0.5625
Epoch 1 [51/172] - loss: 0.8523
Epoch 1 [52/172] - loss: 1.0677
Epoch 1 [53/172] - loss: 0.6817
Epoch 1 [54/172] - loss: 0.9139
Epoch 1 [55/172] - loss: 0.6685
Epoch 1 [56/172] - loss: 0.6963
Epoch 1 [57/172] - loss: 0.9562
Epoch 1 [58/172] - loss: 0.5878
Epoch 1 [59/172] - loss: 0.7745
Epoch 1 [60/172] - loss: 0.6059, acc: 0.7188
Epoch 1 [61/172] - loss: 0.6504
Epoch 1 [62/172] - loss: 0.7044
Epoch 1 [63/172] - loss: 0.7916
Epoch 1 [64/172] - loss: 0.5824
Epoch 1 [65/172] - loss: 0.7460
Epoch 1 [66/172] - loss: 0.8393
Epoch 1 [67/172] - loss: 0.7030
Epoch 1 [68/172] - loss: 0.8753
Epoch 1 [69/172] - loss: 0.6263
Epoch 1 [70/172] - loss: 0.6648, acc: 0.7812
Epoch 1 [71/172] - loss: 0.5010
Epoch 1 [72/172] - loss: 0.5942
Epoch 1 [73/172] - loss: 0.6499
Epoch 1 [74/172] - loss: 0.8289
Epoch 1 [75/172] - loss: 0.4262
Epoch 1 [76/172] - loss: 0.5835
Epoch 1 [77/172] - loss: 0.6385
Epoch 1 [78/172] - loss: 0.6150
Epoch 1 [79/172] - loss: 0.8449
Epoch 1 [80/172] - loss: 0.7009, acc: 0.7188
Epoch 1 [81/172] - loss: 0.5520
Epoch 1 [82/172] - loss: 1.0962
Epoch 1 [83/172] - loss: 0.6545
Epoch 1 [84/172] - loss: 0.4085
Epoch 1 [85/172] - loss: 0.5518
Epoch 1 [86/172] - loss: 0.8858
Epoch 1 [87/172] - loss: 0.7005
Epoch 1 [88/172] - loss: 0.8246
Epoch 1 [89/172] - loss: 0.7591
Epoch 1 [90/172] - loss: 0.7163, acc: 0.7188
Epoch 1 [91/172] - loss: 0.5169
Epoch 1 [92/172] - loss: 0.6365
Epoch 1 [93/172] - loss: 0.4854
Epoch 1 [94/172] - loss: 0.4744
Epoch 1 [95/172] - loss: 0.5840
Epoch 1 [96/172] - loss: 0.7109
Epoch 1 [97/172] - loss: 0.4602
Epoch 1 [98/172] - loss: 0.5123
Epoch 1 [99/172] - loss: 0.7558
Epoch 1 [100/172] - loss: 0.6782, acc: 0.6562

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5526, log_difficulty=0.4399, weight=3.1995
neutral: count=983.0, difficulty=0.5354, log_difficulty=0.4288, weight=3.1440
negative: count=1119.0, difficulty=0.5419, log_difficulty=0.4330, weight=3.1650

当前batch的pt分布：
positive: min=0.1317, max=0.7980, mean=0.3685
neutral: min=0.5158, max=0.9646, mean=0.7479
negative: min=0.1243, max=0.6850, mean=0.4015

当前batch准确率：
整体准确率: 0.4688
positive 准确率: 0.3333
neutral 准确率: 1.0000
negative 准确率: 0.4375

损失分量：
基础交叉熵: 0.9864
焦点损失: 0.3978
边界损失: 0.5366
总损失: 0.9014
Epoch 1 [101/172] - loss: 0.9014
Epoch 1 [102/172] - loss: 0.5036
Epoch 1 [103/172] - loss: 0.4788
Epoch 1 [104/172] - loss: 0.6477
Epoch 1 [105/172] - loss: 0.6515
Epoch 1 [106/172] - loss: 0.8186
Epoch 1 [107/172] - loss: 0.6183
Epoch 1 [108/172] - loss: 0.8027
Epoch 1 [109/172] - loss: 0.7581
Epoch 1 [110/172] - loss: 0.6557, acc: 0.5938
Epoch 1 [111/172] - loss: 0.6162
Epoch 1 [112/172] - loss: 0.5403
Epoch 1 [113/172] - loss: 0.4257
Epoch 1 [114/172] - loss: 0.4036
Epoch 1 [115/172] - loss: 0.5620
Epoch 1 [116/172] - loss: 0.5983
Epoch 1 [117/172] - loss: 0.4869
Epoch 1 [118/172] - loss: 0.3942
Epoch 1 [119/172] - loss: 0.5234
Epoch 1 [120/172] - loss: 0.4404, acc: 0.8438
Epoch 1 [121/172] - loss: 0.4031
Epoch 1 [122/172] - loss: 0.6124
Epoch 1 [123/172] - loss: 0.3487
Epoch 1 [124/172] - loss: 0.5294
Epoch 1 [125/172] - loss: 0.4583
Epoch 1 [126/172] - loss: 0.5804
Epoch 1 [127/172] - loss: 0.5413
Epoch 1 [128/172] - loss: 0.4885
Epoch 1 [129/172] - loss: 0.6703
Epoch 1 [130/172] - loss: 0.4340, acc: 0.7812
Epoch 1 [131/172] - loss: 0.2469
Epoch 1 [132/172] - loss: 0.7572
Epoch 1 [133/172] - loss: 0.5324
Epoch 1 [134/172] - loss: 0.3919
Epoch 1 [135/172] - loss: 0.6332
Epoch 1 [136/172] - loss: 0.5128
Epoch 1 [137/172] - loss: 0.6776
Epoch 1 [138/172] - loss: 0.3079
Epoch 1 [139/172] - loss: 0.3215
Epoch 1 [140/172] - loss: 0.4488, acc: 0.7188
Epoch 1 [141/172] - loss: 0.3915
Epoch 1 [142/172] - loss: 0.4997
Epoch 1 [143/172] - loss: 0.3696
Epoch 1 [144/172] - loss: 0.3433
Epoch 1 [145/172] - loss: 0.5804
Epoch 1 [146/172] - loss: 0.5889
Epoch 1 [147/172] - loss: 0.5906
Epoch 1 [148/172] - loss: 0.4706
Epoch 1 [149/172] - loss: 0.2770
Epoch 1 [150/172] - loss: 0.6902, acc: 0.6875
Epoch 1 [151/172] - loss: 0.6994
Epoch 1 [152/172] - loss: 0.4699
Epoch 1 [153/172] - loss: 0.4665
Epoch 1 [154/172] - loss: 0.3373
Epoch 1 [155/172] - loss: 0.4360
Epoch 1 [156/172] - loss: 0.5894
Epoch 1 [157/172] - loss: 0.3690
Epoch 1 [158/172] - loss: 0.3162
Epoch 1 [159/172] - loss: 0.6009
Epoch 1 [160/172] - loss: 0.5022, acc: 0.8125
Epoch 1 [161/172] - loss: 0.4315
Epoch 1 [162/172] - loss: 0.3506
Epoch 1 [163/172] - loss: 0.5614
Epoch 1 [164/172] - loss: 0.6283
Epoch 1 [165/172] - loss: 0.4752
Epoch 1 [166/172] - loss: 0.4621
Epoch 1 [167/172] - loss: 0.3727
Epoch 1 [168/172] - loss: 0.4550
Epoch 1 [169/172] - loss: 0.4861
Epoch 1 [170/172] - loss: 0.4230, acc: 0.8125
Epoch 1 [171/172] - loss: 0.2628
Epoch 1 [172/172] - loss: 0.4736

类别准确率:
positive: 0.6081 (284/467)
neutral: 0.4578 (38/83)
negative: 0.8280 (207/250)

Epoch 1/10
Train Loss: 0.4482, Train Acc: 0.8000
Val Loss: 0.7616, Val Acc: 0.6613
Epoch 2 [1/172] - loss: 0.3652, acc: 0.9062
Epoch 2 [2/172] - loss: 0.2423
Epoch 2 [3/172] - loss: 0.2797
Epoch 2 [4/172] - loss: 0.4093
Epoch 2 [5/172] - loss: 0.5004
Epoch 2 [6/172] - loss: 0.4254
Epoch 2 [7/172] - loss: 0.2987
Epoch 2 [8/172] - loss: 0.2808
Epoch 2 [9/172] - loss: 0.3096
Epoch 2 [10/172] - loss: 0.3683, acc: 0.9375
Epoch 2 [11/172] - loss: 0.2912
Epoch 2 [12/172] - loss: 0.2547
Epoch 2 [13/172] - loss: 0.5154
Epoch 2 [14/172] - loss: 0.2896
Epoch 2 [15/172] - loss: 0.4665
Epoch 2 [16/172] - loss: 0.4104
Epoch 2 [17/172] - loss: 0.3310
Epoch 2 [18/172] - loss: 0.4202
Epoch 2 [19/172] - loss: 0.2660
Epoch 2 [20/172] - loss: 0.3166, acc: 0.8438
Epoch 2 [21/172] - loss: 0.2702
Epoch 2 [22/172] - loss: 0.2870
Epoch 2 [23/172] - loss: 0.1951
Epoch 2 [24/172] - loss: 0.6164
Epoch 2 [25/172] - loss: 0.3331
Epoch 2 [26/172] - loss: 0.1695
Epoch 2 [27/172] - loss: 0.2962
Epoch 2 [28/172] - loss: 0.3837

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4830, log_difficulty=0.3941, weight=2.9703
neutral: count=1952.0, difficulty=0.4126, log_difficulty=0.3454, weight=2.7271
negative: count=2216.0, difficulty=0.4717, log_difficulty=0.3864, weight=2.9320

当前batch的pt分布：
positive: min=0.4670, max=0.9437, mean=0.7176
neutral: min=0.3584, max=0.9624, mean=0.8207
negative: min=0.1421, max=0.8778, mean=0.6900

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 0.9091
negative 准确率: 0.9167

损失分量：
基础交叉熵: 0.3516
焦点损失: 0.0718
边界损失: 0.3068
总损失: 0.2576
Epoch 2 [29/172] - loss: 0.2576
Epoch 2 [30/172] - loss: 0.2797, acc: 0.9062
Epoch 2 [31/172] - loss: 0.2434
Epoch 2 [32/172] - loss: 0.2030
Epoch 2 [33/172] - loss: 0.2895
Epoch 2 [34/172] - loss: 0.2275
Epoch 2 [35/172] - loss: 0.2232
Epoch 2 [36/172] - loss: 0.3997
Epoch 2 [37/172] - loss: 0.2107
Epoch 2 [38/172] - loss: 0.2833
Epoch 2 [39/172] - loss: 0.3439
Epoch 2 [40/172] - loss: 0.2920, acc: 0.8750
Epoch 2 [41/172] - loss: 0.2635
Epoch 2 [42/172] - loss: 0.1658
Epoch 2 [43/172] - loss: 0.1781
Epoch 2 [44/172] - loss: 0.2955
Epoch 2 [45/172] - loss: 0.1809
Epoch 2 [46/172] - loss: 0.3363
Epoch 2 [47/172] - loss: 0.4485
Epoch 2 [48/172] - loss: 0.3127
Epoch 2 [49/172] - loss: 0.3581
Epoch 2 [50/172] - loss: 0.4115, acc: 0.7188
Epoch 2 [51/172] - loss: 0.3236
Epoch 2 [52/172] - loss: 0.2243
Epoch 2 [53/172] - loss: 0.2498
Epoch 2 [54/172] - loss: 0.3459
Epoch 2 [55/172] - loss: 0.3144
Epoch 2 [56/172] - loss: 0.2625
Epoch 2 [57/172] - loss: 0.2755
Epoch 2 [58/172] - loss: 0.2477
Epoch 2 [59/172] - loss: 0.4393
Epoch 2 [60/172] - loss: 0.2414, acc: 0.8750
Epoch 2 [61/172] - loss: 0.1586
Epoch 2 [62/172] - loss: 0.1733
Epoch 2 [63/172] - loss: 0.2412
Epoch 2 [64/172] - loss: 0.3511
Epoch 2 [65/172] - loss: 0.3636
Epoch 2 [66/172] - loss: 0.3174
Epoch 2 [67/172] - loss: 0.1728
Epoch 2 [68/172] - loss: 0.3162
Epoch 2 [69/172] - loss: 0.1833
Epoch 2 [70/172] - loss: 0.4140, acc: 0.8438
Epoch 2 [71/172] - loss: 0.2418
Epoch 2 [72/172] - loss: 0.2211
Epoch 2 [73/172] - loss: 0.2527
Epoch 2 [74/172] - loss: 0.2175
Epoch 2 [75/172] - loss: 0.2182
Epoch 2 [76/172] - loss: 0.2245
Epoch 2 [77/172] - loss: 0.3556
Epoch 2 [78/172] - loss: 0.2625
Epoch 2 [79/172] - loss: 0.2766
Epoch 2 [80/172] - loss: 0.2284, acc: 0.9688
Epoch 2 [81/172] - loss: 0.2417
Epoch 2 [82/172] - loss: 0.1588
Epoch 2 [83/172] - loss: 0.2614
Epoch 2 [84/172] - loss: 0.3025
Epoch 2 [85/172] - loss: 0.2251
Epoch 2 [86/172] - loss: 0.2840
Epoch 2 [87/172] - loss: 0.6956
Epoch 2 [88/172] - loss: 0.1855
Epoch 2 [89/172] - loss: 0.1433
Epoch 2 [90/172] - loss: 0.2347, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1985
Epoch 2 [92/172] - loss: 0.2214
Epoch 2 [93/172] - loss: 0.2433
Epoch 2 [94/172] - loss: 0.3691
Epoch 2 [95/172] - loss: 0.3610
Epoch 2 [96/172] - loss: 0.2003
Epoch 2 [97/172] - loss: 0.2485
Epoch 2 [98/172] - loss: 0.1789
Epoch 2 [99/172] - loss: 0.2042
Epoch 2 [100/172] - loss: 0.2071, acc: 0.8750
Epoch 2 [101/172] - loss: 0.1973
Epoch 2 [102/172] - loss: 0.1604
Epoch 2 [103/172] - loss: 0.3130
Epoch 2 [104/172] - loss: 0.2201
Epoch 2 [105/172] - loss: 0.2031
Epoch 2 [106/172] - loss: 0.1966
Epoch 2 [107/172] - loss: 0.1719
Epoch 2 [108/172] - loss: 0.4173
Epoch 2 [109/172] - loss: 0.2002
Epoch 2 [110/172] - loss: 0.2235, acc: 0.8750
Epoch 2 [111/172] - loss: 0.1700
Epoch 2 [112/172] - loss: 0.1871
Epoch 2 [113/172] - loss: 0.2653
Epoch 2 [114/172] - loss: 0.2639
Epoch 2 [115/172] - loss: 0.2833
Epoch 2 [116/172] - loss: 0.2559
Epoch 2 [117/172] - loss: 0.4540
Epoch 2 [118/172] - loss: 0.1859
Epoch 2 [119/172] - loss: 0.1667
Epoch 2 [120/172] - loss: 0.2265, acc: 0.9062
Epoch 2 [121/172] - loss: 0.2498
Epoch 2 [122/172] - loss: 0.5686
Epoch 2 [123/172] - loss: 0.3079
Epoch 2 [124/172] - loss: 0.2681
Epoch 2 [125/172] - loss: 0.2171
Epoch 2 [126/172] - loss: 0.2043
Epoch 2 [127/172] - loss: 0.1672
Epoch 2 [128/172] - loss: 0.2339

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4128, log_difficulty=0.3455, weight=2.7277
neutral: count=2949.0, difficulty=0.3261, log_difficulty=0.2822, weight=2.4111
negative: count=3294.0, difficulty=0.4055, log_difficulty=0.3404, weight=2.7019

当前batch的pt分布：
positive: min=0.4663, max=0.9842, mean=0.8294
neutral: min=0.6706, max=0.9874, mean=0.8570
negative: min=0.3710, max=0.9685, mean=0.7793

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.2221
焦点损失: 0.0253
边界损失: 0.2496
总损失: 0.1588
Epoch 2 [129/172] - loss: 0.1588
Epoch 2 [130/172] - loss: 0.2002, acc: 0.8750
Epoch 2 [131/172] - loss: 0.2580
Epoch 2 [132/172] - loss: 0.3039
Epoch 2 [133/172] - loss: 0.2086
Epoch 2 [134/172] - loss: 0.3097
Epoch 2 [135/172] - loss: 0.3778
Epoch 2 [136/172] - loss: 0.1991
Epoch 2 [137/172] - loss: 0.1390
Epoch 2 [138/172] - loss: 0.2157
Epoch 2 [139/172] - loss: 0.1963
Epoch 2 [140/172] - loss: 0.3494, acc: 0.8438
Epoch 2 [141/172] - loss: 0.2033
Epoch 2 [142/172] - loss: 0.3292
Epoch 2 [143/172] - loss: 0.1926
Epoch 2 [144/172] - loss: 0.1682
Epoch 2 [145/172] - loss: 0.6701
Epoch 2 [146/172] - loss: 0.1847
Epoch 2 [147/172] - loss: 0.2588
Epoch 2 [148/172] - loss: 0.2243
Epoch 2 [149/172] - loss: 0.2033
Epoch 2 [150/172] - loss: 0.1630, acc: 0.9688
Epoch 2 [151/172] - loss: 0.1983
Epoch 2 [152/172] - loss: 0.2590
Epoch 2 [153/172] - loss: 0.1775
Epoch 2 [154/172] - loss: 0.2040
Epoch 2 [155/172] - loss: 0.2166
Epoch 2 [156/172] - loss: 0.2397
Epoch 2 [157/172] - loss: 0.1359
Epoch 2 [158/172] - loss: 0.2434
Epoch 2 [159/172] - loss: 0.2743
Epoch 2 [160/172] - loss: 0.2679, acc: 0.9062
Epoch 2 [161/172] - loss: 0.1525
Epoch 2 [162/172] - loss: 0.1977
Epoch 2 [163/172] - loss: 0.3836
Epoch 2 [164/172] - loss: 0.2176
Epoch 2 [165/172] - loss: 0.2639
Epoch 2 [166/172] - loss: 0.3506
Epoch 2 [167/172] - loss: 0.2810
Epoch 2 [168/172] - loss: 0.1616
Epoch 2 [169/172] - loss: 0.1478
Epoch 2 [170/172] - loss: 0.1797, acc: 0.9688
Epoch 2 [171/172] - loss: 0.3050
Epoch 2 [172/172] - loss: 0.4043

类别准确率:
positive: 0.8351 (390/467)
neutral: 0.2048 (17/83)
negative: 0.6960 (174/250)

Epoch 2/10
Train Loss: 0.2479, Train Acc: 0.9172
Val Loss: 0.6775, Val Acc: 0.7262
Epoch 3 [1/172] - loss: 0.2129, acc: 0.9375
Epoch 3 [2/172] - loss: 0.3365
Epoch 3 [3/172] - loss: 0.1336
Epoch 3 [4/172] - loss: 0.1530
Epoch 3 [5/172] - loss: 0.1703
Epoch 3 [6/172] - loss: 0.1588
Epoch 3 [7/172] - loss: 0.1321
Epoch 3 [8/172] - loss: 0.1632
Epoch 3 [9/172] - loss: 0.1576
Epoch 3 [10/172] - loss: 0.1580, acc: 0.9375
Epoch 3 [11/172] - loss: 0.1275
Epoch 3 [12/172] - loss: 0.0970
Epoch 3 [13/172] - loss: 0.1177
Epoch 3 [14/172] - loss: 0.1498
Epoch 3 [15/172] - loss: 0.1262
Epoch 3 [16/172] - loss: 0.2450
Epoch 3 [17/172] - loss: 0.1726
Epoch 3 [18/172] - loss: 0.1892
Epoch 3 [19/172] - loss: 0.1456
Epoch 3 [20/172] - loss: 0.1355, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1679
Epoch 3 [22/172] - loss: 0.2046
Epoch 3 [23/172] - loss: 0.1223
Epoch 3 [24/172] - loss: 0.1837
Epoch 3 [25/172] - loss: 0.1219
Epoch 3 [26/172] - loss: 0.2130
Epoch 3 [27/172] - loss: 0.1147
Epoch 3 [28/172] - loss: 0.1245
Epoch 3 [29/172] - loss: 0.1199
Epoch 3 [30/172] - loss: 0.1449, acc: 0.9688
Epoch 3 [31/172] - loss: 0.1070
Epoch 3 [32/172] - loss: 0.1388
Epoch 3 [33/172] - loss: 0.1593
Epoch 3 [34/172] - loss: 0.1321
Epoch 3 [35/172] - loss: 0.1527
Epoch 3 [36/172] - loss: 0.1177
Epoch 3 [37/172] - loss: 0.1279
Epoch 3 [38/172] - loss: 0.0993
Epoch 3 [39/172] - loss: 0.1169
Epoch 3 [40/172] - loss: 0.1188, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1220
Epoch 3 [42/172] - loss: 0.1177
Epoch 3 [43/172] - loss: 0.1446
Epoch 3 [44/172] - loss: 0.1122
Epoch 3 [45/172] - loss: 0.1209
Epoch 3 [46/172] - loss: 0.1755
Epoch 3 [47/172] - loss: 0.0955
Epoch 3 [48/172] - loss: 0.1391
Epoch 3 [49/172] - loss: 0.1600
Epoch 3 [50/172] - loss: 0.0902, acc: 1.0000
Epoch 3 [51/172] - loss: 0.1646
Epoch 3 [52/172] - loss: 0.2487
Epoch 3 [53/172] - loss: 0.1652
Epoch 3 [54/172] - loss: 0.1050
Epoch 3 [55/172] - loss: 0.1605
Epoch 3 [56/172] - loss: 0.1733

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3575, log_difficulty=0.3057, weight=2.5283
neutral: count=3923.0, difficulty=0.2757, log_difficulty=0.2435, weight=2.2173
negative: count=4382.0, difficulty=0.3522, log_difficulty=0.3018, weight=2.5088

当前batch的pt分布：
positive: min=0.5352, max=0.9885, mean=0.8654
neutral: min=0.0054, max=0.9740, mean=0.7853
negative: min=0.9587, max=0.9925, mean=0.9775

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3228
焦点损失: 0.1876
边界损失: 0.2090
总损失: 0.3132
Epoch 3 [57/172] - loss: 0.3132
Epoch 3 [58/172] - loss: 0.1726
Epoch 3 [59/172] - loss: 0.1040
Epoch 3 [60/172] - loss: 0.1113, acc: 1.0000
Epoch 3 [61/172] - loss: 0.1288
Epoch 3 [62/172] - loss: 0.1184
Epoch 3 [63/172] - loss: 0.1251
Epoch 3 [64/172] - loss: 0.1335
Epoch 3 [65/172] - loss: 0.1236
Epoch 3 [66/172] - loss: 0.2435
Epoch 3 [67/172] - loss: 0.1364
Epoch 3 [68/172] - loss: 0.1047
Epoch 3 [69/172] - loss: 0.1868
Epoch 3 [70/172] - loss: 0.1530, acc: 0.9688
Epoch 3 [71/172] - loss: 0.1128
Epoch 3 [72/172] - loss: 0.1518
Epoch 3 [73/172] - loss: 0.1063
Epoch 3 [74/172] - loss: 0.1373
Epoch 3 [75/172] - loss: 0.1465
Epoch 3 [76/172] - loss: 0.0854
Epoch 3 [77/172] - loss: 0.1107
Epoch 3 [78/172] - loss: 0.2568
Epoch 3 [79/172] - loss: 0.1338
Epoch 3 [80/172] - loss: 0.2252, acc: 0.9375
Epoch 3 [81/172] - loss: 0.1698
Epoch 3 [82/172] - loss: 0.1352
Epoch 3 [83/172] - loss: 0.0913
Epoch 3 [84/172] - loss: 0.0949
Epoch 3 [85/172] - loss: 0.1173
Epoch 3 [86/172] - loss: 0.1096
Epoch 3 [87/172] - loss: 0.1521
Epoch 3 [88/172] - loss: 0.1527
Epoch 3 [89/172] - loss: 0.0882
Epoch 3 [90/172] - loss: 0.0929, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1424
Epoch 3 [92/172] - loss: 0.1759
Epoch 3 [93/172] - loss: 0.1637
Epoch 3 [94/172] - loss: 0.1453
Epoch 3 [95/172] - loss: 0.0961
Epoch 3 [96/172] - loss: 0.1882
Epoch 3 [97/172] - loss: 0.1334
Epoch 3 [98/172] - loss: 0.1431
Epoch 3 [99/172] - loss: 0.1223
Epoch 3 [100/172] - loss: 0.2636, acc: 0.9062
Epoch 3 [101/172] - loss: 0.2693
Epoch 3 [102/172] - loss: 0.0991
Epoch 3 [103/172] - loss: 0.1749
Epoch 3 [104/172] - loss: 0.1185
Epoch 3 [105/172] - loss: 0.0893
Epoch 3 [106/172] - loss: 0.2056
Epoch 3 [107/172] - loss: 0.0867
Epoch 3 [108/172] - loss: 0.1241
Epoch 3 [109/172] - loss: 0.1130
Epoch 3 [110/172] - loss: 0.1595, acc: 0.9375
Epoch 3 [111/172] - loss: 0.1278
Epoch 3 [112/172] - loss: 0.0907
Epoch 3 [113/172] - loss: 0.1037
Epoch 3 [114/172] - loss: 0.1741
Epoch 3 [115/172] - loss: 0.0925
Epoch 3 [116/172] - loss: 0.1139
Epoch 3 [117/172] - loss: 0.2285
Epoch 3 [118/172] - loss: 0.1093
Epoch 3 [119/172] - loss: 0.1230
Epoch 3 [120/172] - loss: 0.2488, acc: 0.9062
Epoch 3 [121/172] - loss: 0.2331
Epoch 3 [122/172] - loss: 0.1296
Epoch 3 [123/172] - loss: 0.1546
Epoch 3 [124/172] - loss: 0.1285
Epoch 3 [125/172] - loss: 0.1256
Epoch 3 [126/172] - loss: 0.2737
Epoch 3 [127/172] - loss: 0.1384
Epoch 3 [128/172] - loss: 0.1096
Epoch 3 [129/172] - loss: 0.1068
Epoch 3 [130/172] - loss: 0.1324, acc: 0.9688
Epoch 3 [131/172] - loss: 0.1067
Epoch 3 [132/172] - loss: 0.0973
Epoch 3 [133/172] - loss: 0.2130
Epoch 3 [134/172] - loss: 0.0902
Epoch 3 [135/172] - loss: 0.1171
Epoch 3 [136/172] - loss: 0.1168
Epoch 3 [137/172] - loss: 0.0916
Epoch 3 [138/172] - loss: 0.1277
Epoch 3 [139/172] - loss: 0.2208
Epoch 3 [140/172] - loss: 0.1547, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1896
Epoch 3 [142/172] - loss: 0.2509
Epoch 3 [143/172] - loss: 0.1021
Epoch 3 [144/172] - loss: 0.1999
Epoch 3 [145/172] - loss: 0.1632
Epoch 3 [146/172] - loss: 0.1146
Epoch 3 [147/172] - loss: 0.1008
Epoch 3 [148/172] - loss: 0.1243
Epoch 3 [149/172] - loss: 0.1356
Epoch 3 [150/172] - loss: 0.2659, acc: 0.9375
Epoch 3 [151/172] - loss: 0.1662
Epoch 3 [152/172] - loss: 0.2393
Epoch 3 [153/172] - loss: 0.1017
Epoch 3 [154/172] - loss: 0.1556
Epoch 3 [155/172] - loss: 0.0956
Epoch 3 [156/172] - loss: 0.2066

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3133, log_difficulty=0.2725, weight=2.3626
neutral: count=4903.0, difficulty=0.2357, log_difficulty=0.2116, weight=2.0581
negative: count=5500.0, difficulty=0.3094, log_difficulty=0.2696, weight=2.3480

当前batch的pt分布：
positive: min=0.6748, max=0.9908, mean=0.9003
neutral: min=0.8869, max=0.9965, mean=0.9550
negative: min=0.2969, max=0.9992, mean=0.7732

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8000

损失分量：
基础交叉熵: 0.1563
焦点损失: 0.0301
边界损失: 0.1942
总损失: 0.1324
Epoch 3 [157/172] - loss: 0.1324
Epoch 3 [158/172] - loss: 0.2998
Epoch 3 [159/172] - loss: 0.2414
Epoch 3 [160/172] - loss: 0.3076, acc: 0.8750
Epoch 3 [161/172] - loss: 0.2330
Epoch 3 [162/172] - loss: 0.1551
Epoch 3 [163/172] - loss: 0.2230
Epoch 3 [164/172] - loss: 0.1007
Epoch 3 [165/172] - loss: 0.0980
Epoch 3 [166/172] - loss: 0.1335
Epoch 3 [167/172] - loss: 0.1330
Epoch 3 [168/172] - loss: 0.1069
Epoch 3 [169/172] - loss: 0.1004
Epoch 3 [170/172] - loss: 0.1867, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1339
Epoch 3 [172/172] - loss: 0.1333

类别准确率:
positive: 0.6981 (326/467)
neutral: 0.2530 (21/83)
negative: 0.7880 (197/250)

Epoch 3/10
Train Loss: 0.1699, Train Acc: 0.9475
Val Loss: 0.8193, Val Acc: 0.6800
Epoch 4 [1/172] - loss: 0.1485, acc: 0.9688
Epoch 4 [2/172] - loss: 0.2092
Epoch 4 [3/172] - loss: 0.1168
Epoch 4 [4/172] - loss: 0.1128
Epoch 4 [5/172] - loss: 0.0996
Epoch 4 [6/172] - loss: 0.1114
Epoch 4 [7/172] - loss: 0.1208
Epoch 4 [8/172] - loss: 0.0898
Epoch 4 [9/172] - loss: 0.1168
Epoch 4 [10/172] - loss: 0.1038, acc: 1.0000
Epoch 4 [11/172] - loss: 0.1333
Epoch 4 [12/172] - loss: 0.1062
Epoch 4 [13/172] - loss: 0.1116
Epoch 4 [14/172] - loss: 0.0993
Epoch 4 [15/172] - loss: 0.0886
Epoch 4 [16/172] - loss: 0.0998
Epoch 4 [17/172] - loss: 0.0883
Epoch 4 [18/172] - loss: 0.1376
Epoch 4 [19/172] - loss: 0.1039
Epoch 4 [20/172] - loss: 0.1106, acc: 0.9688
Epoch 4 [21/172] - loss: 0.1605
Epoch 4 [22/172] - loss: 0.0963
Epoch 4 [23/172] - loss: 0.1109
Epoch 4 [24/172] - loss: 0.0846
Epoch 4 [25/172] - loss: 0.0917
Epoch 4 [26/172] - loss: 0.1787
Epoch 4 [27/172] - loss: 0.0900
Epoch 4 [28/172] - loss: 0.1168
Epoch 4 [29/172] - loss: 0.0961
Epoch 4 [30/172] - loss: 0.1833, acc: 0.9375
Epoch 4 [31/172] - loss: 0.1174
Epoch 4 [32/172] - loss: 0.0828
Epoch 4 [33/172] - loss: 0.0869
Epoch 4 [34/172] - loss: 0.0788
Epoch 4 [35/172] - loss: 0.1036
Epoch 4 [36/172] - loss: 0.0858
Epoch 4 [37/172] - loss: 0.0980
Epoch 4 [38/172] - loss: 0.1027
Epoch 4 [39/172] - loss: 0.1670
Epoch 4 [40/172] - loss: 0.1890, acc: 0.9062
Epoch 4 [41/172] - loss: 0.0899
Epoch 4 [42/172] - loss: 0.1016
Epoch 4 [43/172] - loss: 0.1003
Epoch 4 [44/172] - loss: 0.0921
Epoch 4 [45/172] - loss: 0.0976
Epoch 4 [46/172] - loss: 0.0782
Epoch 4 [47/172] - loss: 0.0863
Epoch 4 [48/172] - loss: 0.0944
Epoch 4 [49/172] - loss: 0.1261
Epoch 4 [50/172] - loss: 0.1045, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0846
Epoch 4 [52/172] - loss: 0.1120
Epoch 4 [53/172] - loss: 0.0772
Epoch 4 [54/172] - loss: 0.1226
Epoch 4 [55/172] - loss: 0.1737
Epoch 4 [56/172] - loss: 0.0872
Epoch 4 [57/172] - loss: 0.0765
Epoch 4 [58/172] - loss: 0.1005
Epoch 4 [59/172] - loss: 0.0763
Epoch 4 [60/172] - loss: 0.0805, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1108
Epoch 4 [62/172] - loss: 0.1393
Epoch 4 [63/172] - loss: 0.0838
Epoch 4 [64/172] - loss: 0.0788
Epoch 4 [65/172] - loss: 0.1042
Epoch 4 [66/172] - loss: 0.0873
Epoch 4 [67/172] - loss: 0.0839
Epoch 4 [68/172] - loss: 0.0860
Epoch 4 [69/172] - loss: 0.0995
Epoch 4 [70/172] - loss: 0.1349, acc: 0.9375
Epoch 4 [71/172] - loss: 0.1371
Epoch 4 [72/172] - loss: 0.0899
Epoch 4 [73/172] - loss: 0.0953
Epoch 4 [74/172] - loss: 0.2738
Epoch 4 [75/172] - loss: 0.0867
Epoch 4 [76/172] - loss: 0.1241
Epoch 4 [77/172] - loss: 0.0920
Epoch 4 [78/172] - loss: 0.1077
Epoch 4 [79/172] - loss: 0.0815
Epoch 4 [80/172] - loss: 0.1074, acc: 0.9688
Epoch 4 [81/172] - loss: 0.2014
Epoch 4 [82/172] - loss: 0.0972
Epoch 4 [83/172] - loss: 0.0829
Epoch 4 [84/172] - loss: 0.0939

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2793, log_difficulty=0.2463, weight=2.2316
neutral: count=5865.0, difficulty=0.2068, log_difficulty=0.1880, weight=1.9399
negative: count=6629.0, difficulty=0.2754, log_difficulty=0.2433, weight=2.2163

当前batch的pt分布：
positive: min=0.1118, max=0.9947, mean=0.8137
neutral: min=0.9902, max=0.9983, mean=0.9951
negative: min=0.8028, max=0.9961, mean=0.9359

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1682
焦点损失: 0.0614
边界损失: 0.1856
总损失: 0.1613
Epoch 4 [85/172] - loss: 0.1613
Epoch 4 [86/172] - loss: 0.1156
Epoch 4 [87/172] - loss: 0.0999
Epoch 4 [88/172] - loss: 0.0879
Epoch 4 [89/172] - loss: 0.0952
Epoch 4 [90/172] - loss: 0.0864, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1939
Epoch 4 [92/172] - loss: 0.2383
Epoch 4 [93/172] - loss: 0.0849
Epoch 4 [94/172] - loss: 0.0794
Epoch 4 [95/172] - loss: 0.1143
Epoch 4 [96/172] - loss: 0.1076
Epoch 4 [97/172] - loss: 0.0944
Epoch 4 [98/172] - loss: 0.0898
Epoch 4 [99/172] - loss: 0.1085
Epoch 4 [100/172] - loss: 0.0807, acc: 1.0000
Epoch 4 [101/172] - loss: 0.0949
Epoch 4 [102/172] - loss: 0.1013
Epoch 4 [103/172] - loss: 0.0857
Epoch 4 [104/172] - loss: 0.0791
Epoch 4 [105/172] - loss: 0.1158
Epoch 4 [106/172] - loss: 0.0775
Epoch 4 [107/172] - loss: 0.0912
Epoch 4 [108/172] - loss: 0.1014
Epoch 4 [109/172] - loss: 0.0977
Epoch 4 [110/172] - loss: 0.2768, acc: 0.8750
Epoch 4 [111/172] - loss: 0.0825
Epoch 4 [112/172] - loss: 0.0760
Epoch 4 [113/172] - loss: 0.0810
Epoch 4 [114/172] - loss: 0.1102
Epoch 4 [115/172] - loss: 0.0950
Epoch 4 [116/172] - loss: 0.0892
Epoch 4 [117/172] - loss: 0.0992
Epoch 4 [118/172] - loss: 0.0849
Epoch 4 [119/172] - loss: 0.0887
Epoch 4 [120/172] - loss: 0.0856, acc: 1.0000
Epoch 4 [121/172] - loss: 0.0887
Epoch 4 [122/172] - loss: 0.1585
Epoch 4 [123/172] - loss: 0.0776
Epoch 4 [124/172] - loss: 0.0748
Epoch 4 [125/172] - loss: 0.0903
Epoch 4 [126/172] - loss: 0.2678
Epoch 4 [127/172] - loss: 0.1632
Epoch 4 [128/172] - loss: 0.0773
Epoch 4 [129/172] - loss: 0.0797
Epoch 4 [130/172] - loss: 0.0910, acc: 0.9688
Epoch 4 [131/172] - loss: 0.1093
Epoch 4 [132/172] - loss: 0.1599
Epoch 4 [133/172] - loss: 0.0778
Epoch 4 [134/172] - loss: 0.0810
Epoch 4 [135/172] - loss: 0.0863
Epoch 4 [136/172] - loss: 0.1403
Epoch 4 [137/172] - loss: 0.0845
Epoch 4 [138/172] - loss: 0.0781
Epoch 4 [139/172] - loss: 0.0808
Epoch 4 [140/172] - loss: 0.1029, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1803
Epoch 4 [142/172] - loss: 0.0984
Epoch 4 [143/172] - loss: 0.0920
Epoch 4 [144/172] - loss: 0.0937
Epoch 4 [145/172] - loss: 0.1981
Epoch 4 [146/172] - loss: 0.1275
Epoch 4 [147/172] - loss: 0.0892
Epoch 4 [148/172] - loss: 0.1100
Epoch 4 [149/172] - loss: 0.0904
Epoch 4 [150/172] - loss: 0.1882, acc: 0.9375
Epoch 4 [151/172] - loss: 0.1810
Epoch 4 [152/172] - loss: 0.0787
Epoch 4 [153/172] - loss: 0.0771
Epoch 4 [154/172] - loss: 0.1493
Epoch 4 [155/172] - loss: 0.0926
Epoch 4 [156/172] - loss: 0.0914
Epoch 4 [157/172] - loss: 0.2375
Epoch 4 [158/172] - loss: 0.0754
Epoch 4 [159/172] - loss: 0.1752
Epoch 4 [160/172] - loss: 0.0934, acc: 0.9688
Epoch 4 [161/172] - loss: 0.1079
Epoch 4 [162/172] - loss: 0.1020
Epoch 4 [163/172] - loss: 0.0936
Epoch 4 [164/172] - loss: 0.0870
Epoch 4 [165/172] - loss: 0.2038
Epoch 4 [166/172] - loss: 0.1080
Epoch 4 [167/172] - loss: 0.1201
Epoch 4 [168/172] - loss: 0.0918
Epoch 4 [169/172] - loss: 0.1396
Epoch 4 [170/172] - loss: 0.1147, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1014
Epoch 4 [172/172] - loss: 0.0828

类别准确率:
positive: 0.8137 (380/467)
neutral: 0.2892 (24/83)
negative: 0.6840 (171/250)

Epoch 4/10
Train Loss: 0.1209, Train Acc: 0.9697
Val Loss: 0.7654, Val Acc: 0.7188
Epoch 5 [1/172] - loss: 0.0840, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1646
Epoch 5 [3/172] - loss: 0.0980
Epoch 5 [4/172] - loss: 0.0949
Epoch 5 [5/172] - loss: 0.0847
Epoch 5 [6/172] - loss: 0.1002
Epoch 5 [7/172] - loss: 0.0859
Epoch 5 [8/172] - loss: 0.0955
Epoch 5 [9/172] - loss: 0.1076
Epoch 5 [10/172] - loss: 0.0813, acc: 1.0000
Epoch 5 [11/172] - loss: 0.0966
Epoch 5 [12/172] - loss: 0.0834

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2502, log_difficulty=0.2233, weight=2.1164
neutral: count=6845.0, difficulty=0.1844, log_difficulty=0.1692, weight=1.8462
negative: count=7694.0, difficulty=0.2485, log_difficulty=0.2219, weight=2.1095

当前batch的pt分布：
positive: min=0.1359, max=0.9906, mean=0.8950
neutral: min=0.9885, max=0.9991, mean=0.9938
negative: min=0.6906, max=0.9969, mean=0.9259

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1115
焦点损失: 0.0465
边界损失: 0.1620
总损失: 0.1302
Epoch 5 [13/172] - loss: 0.1302
Epoch 5 [14/172] - loss: 0.1676
Epoch 5 [15/172] - loss: 0.0858
Epoch 5 [16/172] - loss: 0.0809
Epoch 5 [17/172] - loss: 0.0928
Epoch 5 [18/172] - loss: 0.0833
Epoch 5 [19/172] - loss: 0.1592
Epoch 5 [20/172] - loss: 0.1002, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1195
Epoch 5 [22/172] - loss: 0.1507
Epoch 5 [23/172] - loss: 0.0927
Epoch 5 [24/172] - loss: 0.0780
Epoch 5 [25/172] - loss: 0.0843
Epoch 5 [26/172] - loss: 0.0947
Epoch 5 [27/172] - loss: 0.0804
Epoch 5 [28/172] - loss: 0.0774
Epoch 5 [29/172] - loss: 0.0851
Epoch 5 [30/172] - loss: 0.0888, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0861
Epoch 5 [32/172] - loss: 0.0839
Epoch 5 [33/172] - loss: 0.0813
Epoch 5 [34/172] - loss: 0.1218
Epoch 5 [35/172] - loss: 0.0858
Epoch 5 [36/172] - loss: 0.0808
Epoch 5 [37/172] - loss: 0.0815
Epoch 5 [38/172] - loss: 0.0773
Epoch 5 [39/172] - loss: 0.1057
Epoch 5 [40/172] - loss: 0.0861, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0809
Epoch 5 [42/172] - loss: 0.0915
Epoch 5 [43/172] - loss: 0.1921
Epoch 5 [44/172] - loss: 0.0846
Epoch 5 [45/172] - loss: 0.0762
Epoch 5 [46/172] - loss: 0.0966
Epoch 5 [47/172] - loss: 0.0854
Epoch 5 [48/172] - loss: 0.0943
Epoch 5 [49/172] - loss: 0.0798
Epoch 5 [50/172] - loss: 0.0898, acc: 1.0000
Epoch 5 [51/172] - loss: 0.0925
Epoch 5 [52/172] - loss: 0.0776
Epoch 5 [53/172] - loss: 0.1152
Epoch 5 [54/172] - loss: 0.0962
Epoch 5 [55/172] - loss: 0.1144
Epoch 5 [56/172] - loss: 0.0874
Epoch 5 [57/172] - loss: 0.0820
Epoch 5 [58/172] - loss: 0.1689
Epoch 5 [59/172] - loss: 0.1261
Epoch 5 [60/172] - loss: 0.0792, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0822
Epoch 5 [62/172] - loss: 0.0766
Epoch 5 [63/172] - loss: 0.1150
Epoch 5 [64/172] - loss: 0.0806
Epoch 5 [65/172] - loss: 0.0822
Epoch 5 [66/172] - loss: 0.0774
Epoch 5 [67/172] - loss: 0.0755
Epoch 5 [68/172] - loss: 0.0824
Epoch 5 [69/172] - loss: 0.0779
Epoch 5 [70/172] - loss: 0.0847, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1071
Epoch 5 [72/172] - loss: 0.0952
Epoch 5 [73/172] - loss: 0.0800
Epoch 5 [74/172] - loss: 0.0893
Epoch 5 [75/172] - loss: 0.0754
Epoch 5 [76/172] - loss: 0.0761
Epoch 5 [77/172] - loss: 0.0782
Epoch 5 [78/172] - loss: 0.0885
Epoch 5 [79/172] - loss: 0.0852
Epoch 5 [80/172] - loss: 0.0853, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1035
Epoch 5 [82/172] - loss: 0.1044
Epoch 5 [83/172] - loss: 0.0804
Epoch 5 [84/172] - loss: 0.0781
Epoch 5 [85/172] - loss: 0.1071
Epoch 5 [86/172] - loss: 0.0794
Epoch 5 [87/172] - loss: 0.0920
Epoch 5 [88/172] - loss: 0.0952
Epoch 5 [89/172] - loss: 0.0773
Epoch 5 [90/172] - loss: 0.0964, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0766
Epoch 5 [92/172] - loss: 0.0775
Epoch 5 [93/172] - loss: 0.0798
Epoch 5 [94/172] - loss: 0.0782
Epoch 5 [95/172] - loss: 0.0925
Epoch 5 [96/172] - loss: 0.0781
Epoch 5 [97/172] - loss: 0.0904
Epoch 5 [98/172] - loss: 0.0780
Epoch 5 [99/172] - loss: 0.1981
Epoch 5 [100/172] - loss: 0.0854, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0915
Epoch 5 [102/172] - loss: 0.0820
Epoch 5 [103/172] - loss: 0.0838
Epoch 5 [104/172] - loss: 0.1025
Epoch 5 [105/172] - loss: 0.1614
Epoch 5 [106/172] - loss: 0.0774
Epoch 5 [107/172] - loss: 0.0854
Epoch 5 [108/172] - loss: 0.1425
Epoch 5 [109/172] - loss: 0.0760
Epoch 5 [110/172] - loss: 0.0797, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0820
Epoch 5 [112/172] - loss: 0.0743

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2255, log_difficulty=0.2033, weight=2.0167
neutral: count=7825.0, difficulty=0.1668, log_difficulty=0.1543, weight=1.7713
negative: count=8780.0, difficulty=0.2267, log_difficulty=0.2044, weight=2.0218

当前batch的pt分布：
positive: min=0.2323, max=0.9888, mean=0.8787
neutral: min=0.9176, max=0.9973, mean=0.9654
negative: min=0.9614, max=0.9994, mean=0.9848

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0999
焦点损失: 0.0270
边界损失: 0.1668
总损失: 0.1106
Epoch 5 [113/172] - loss: 0.1106
Epoch 5 [114/172] - loss: 0.0859
Epoch 5 [115/172] - loss: 0.0855
Epoch 5 [116/172] - loss: 0.0797
Epoch 5 [117/172] - loss: 0.0778
Epoch 5 [118/172] - loss: 0.0771
Epoch 5 [119/172] - loss: 0.0769
Epoch 5 [120/172] - loss: 0.2413, acc: 0.9688
Epoch 5 [121/172] - loss: 0.0823
Epoch 5 [122/172] - loss: 0.0814
Epoch 5 [123/172] - loss: 0.0806
Epoch 5 [124/172] - loss: 0.0757
Epoch 5 [125/172] - loss: 0.0784
Epoch 5 [126/172] - loss: 0.0782
Epoch 5 [127/172] - loss: 0.0797
Epoch 5 [128/172] - loss: 0.0797
Epoch 5 [129/172] - loss: 0.1327
Epoch 5 [130/172] - loss: 0.0776, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0796
Epoch 5 [132/172] - loss: 0.1108
Epoch 5 [133/172] - loss: 0.0955
Epoch 5 [134/172] - loss: 0.1086
Epoch 5 [135/172] - loss: 0.0774
Epoch 5 [136/172] - loss: 0.0806
Epoch 5 [137/172] - loss: 0.0811
Epoch 5 [138/172] - loss: 0.1065
Epoch 5 [139/172] - loss: 0.3348
Epoch 5 [140/172] - loss: 0.0803, acc: 1.0000
Epoch 5 [141/172] - loss: 0.0817
Epoch 5 [142/172] - loss: 0.0780
Epoch 5 [143/172] - loss: 0.0790
Epoch 5 [144/172] - loss: 0.0815
Epoch 5 [145/172] - loss: 0.0826
Epoch 5 [146/172] - loss: 0.0751
Epoch 5 [147/172] - loss: 0.0849
Epoch 5 [148/172] - loss: 0.0758
Epoch 5 [149/172] - loss: 0.1075
Epoch 5 [150/172] - loss: 0.1311, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0759
Epoch 5 [152/172] - loss: 0.0767
Epoch 5 [153/172] - loss: 0.0752
Epoch 5 [154/172] - loss: 0.0780
Epoch 5 [155/172] - loss: 0.1828
Epoch 5 [156/172] - loss: 0.0877
Epoch 5 [157/172] - loss: 0.0793
Epoch 5 [158/172] - loss: 0.0858
Epoch 5 [159/172] - loss: 0.0753
Epoch 5 [160/172] - loss: 0.0772, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0758
Epoch 5 [162/172] - loss: 0.0943
Epoch 5 [163/172] - loss: 0.1462
Epoch 5 [164/172] - loss: 0.0759
Epoch 5 [165/172] - loss: 0.1336
Epoch 5 [166/172] - loss: 0.0864
Epoch 5 [167/172] - loss: 0.0920
Epoch 5 [168/172] - loss: 0.0799
Epoch 5 [169/172] - loss: 0.0771
Epoch 5 [170/172] - loss: 0.0759, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0915
Epoch 5 [172/172] - loss: 0.0822

类别准确率:
positive: 0.8651 (404/467)
neutral: 0.3133 (26/83)
negative: 0.6040 (151/250)

Epoch 5/10
Train Loss: 0.0893, Train Acc: 0.9899
Val Loss: 0.8132, Val Acc: 0.7262
Early stopping triggered!
Best validation accuracy: 0.7262

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_085708-c094cd11
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.15_Multimodal_iterations_20250118_085707
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/c094cd11
wandb: uploading wandb-summary.json; uploading history steps 87-89, summary, console lines 1086-1112; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇███
wandb:  train_acc ▁▂▄▅▄▅▄▆▆▇██▇▇██▇▇▇█▆█▇███▇█████████████
wandb: train_loss █▆▅▆▆▆▄▄▄▃▃▃▂▂▂▂▂▁▂▁▁▂▃▃▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 858
wandb:  train_acc 1
wandb: train_loss 0.07593
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.15_Multimodal_iterations_20250118_085707 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/c094cd11
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_085708-c094cd11/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_090428-julpe528
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.15_Multimodal_epochs_20250118_090428
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/julpe528
wandb: uploading requirements.txt; uploading history steps 0-0, summary; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▃▅▆█
wandb:  train_acc ▁▅▆▇█
wandb: train_loss █▄▃▂▁
wandb:    val_acc ▁█▃▇█
wandb:   val_loss ▅▁█▅█
wandb: 
wandb: Run summary:
wandb:      epoch 5
wandb:  train_acc 0.9899
wandb: train_loss 0.08927
wandb:    val_acc 0.72625
wandb:   val_loss 0.81321
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.15_Multimodal_epochs_20250118_090428 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/julpe528
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_090428-julpe528/logs

