=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 0.5 --dropout 0.15 --name loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.15 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.15
text_dim: 128
image_dim: 256
dropout: 0.15
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6737, log_difficulty=0.5150, weight=3.5752
neutral: count=7.0, difficulty=0.6206, log_difficulty=0.4828, weight=3.4141
negative: count=13.0, difficulty=0.6524, log_difficulty=0.5022, weight=3.5112

当前batch的pt分布：
positive: min=0.2604, max=0.4301, mean=0.3263
neutral: min=0.2392, max=0.5233, mean=0.3794
negative: min=0.0430, max=0.6273, mean=0.3476

当前batch准确率：
整体准确率: 0.5000
positive 准确率: 0.4167
neutral 准确率: 0.5714
negative 准确率: 0.5385

损失分量：
基础交叉熵: 1.1317
焦点损失: 0.4064
边界损失: 0.7702
总损失: 0.9349
Epoch 1 [1/172] - loss: 0.9349, acc: 0.5000
Epoch 1 [2/172] - loss: 0.9122
Epoch 1 [3/172] - loss: 0.9177
Epoch 1 [4/172] - loss: 0.9083
Epoch 1 [5/172] - loss: 0.8772
Epoch 1 [6/172] - loss: 0.9884
Epoch 1 [7/172] - loss: 0.9544
Epoch 1 [8/172] - loss: 0.9666
Epoch 1 [9/172] - loss: 0.7805
Epoch 1 [10/172] - loss: 0.9622, acc: 0.2500
Epoch 1 [11/172] - loss: 0.9512
Epoch 1 [12/172] - loss: 0.9105
Epoch 1 [13/172] - loss: 0.8099
Epoch 1 [14/172] - loss: 0.9272
Epoch 1 [15/172] - loss: 0.8352
Epoch 1 [16/172] - loss: 0.7603
Epoch 1 [17/172] - loss: 0.8103
Epoch 1 [18/172] - loss: 0.7610
Epoch 1 [19/172] - loss: 0.8303
Epoch 1 [20/172] - loss: 0.9207, acc: 0.4062
Epoch 1 [21/172] - loss: 0.6849
Epoch 1 [22/172] - loss: 0.8069
Epoch 1 [23/172] - loss: 0.7671
Epoch 1 [24/172] - loss: 0.8512
Epoch 1 [25/172] - loss: 0.6496
Epoch 1 [26/172] - loss: 0.8477
Epoch 1 [27/172] - loss: 0.7941
Epoch 1 [28/172] - loss: 0.7471
Epoch 1 [29/172] - loss: 0.6140
Epoch 1 [30/172] - loss: 0.6134, acc: 0.5938
Epoch 1 [31/172] - loss: 0.8322
Epoch 1 [32/172] - loss: 0.6691
Epoch 1 [33/172] - loss: 0.6364
Epoch 1 [34/172] - loss: 0.7142
Epoch 1 [35/172] - loss: 0.8278
Epoch 1 [36/172] - loss: 0.5299
Epoch 1 [37/172] - loss: 0.6749
Epoch 1 [38/172] - loss: 0.8008
Epoch 1 [39/172] - loss: 0.4848
Epoch 1 [40/172] - loss: 0.7188, acc: 0.5312
Epoch 1 [41/172] - loss: 0.6886
Epoch 1 [42/172] - loss: 0.5420
Epoch 1 [43/172] - loss: 0.6756
Epoch 1 [44/172] - loss: 0.7661
Epoch 1 [45/172] - loss: 0.7539
Epoch 1 [46/172] - loss: 0.6487
Epoch 1 [47/172] - loss: 0.7065
Epoch 1 [48/172] - loss: 0.6859
Epoch 1 [49/172] - loss: 0.6216
Epoch 1 [50/172] - loss: 0.6318, acc: 0.5938
Epoch 1 [51/172] - loss: 0.7395
Epoch 1 [52/172] - loss: 0.7251
Epoch 1 [53/172] - loss: 0.7993
Epoch 1 [54/172] - loss: 0.6614
Epoch 1 [55/172] - loss: 0.5461
Epoch 1 [56/172] - loss: 0.5616
Epoch 1 [57/172] - loss: 0.9068
Epoch 1 [58/172] - loss: 0.4517
Epoch 1 [59/172] - loss: 0.6917
Epoch 1 [60/172] - loss: 0.5540, acc: 0.6562
Epoch 1 [61/172] - loss: 0.7189
Epoch 1 [62/172] - loss: 0.5896
Epoch 1 [63/172] - loss: 0.6038
Epoch 1 [64/172] - loss: 0.5059
Epoch 1 [65/172] - loss: 0.7100
Epoch 1 [66/172] - loss: 0.5699
Epoch 1 [67/172] - loss: 0.5390
Epoch 1 [68/172] - loss: 0.7271
Epoch 1 [69/172] - loss: 0.6503
Epoch 1 [70/172] - loss: 0.6260, acc: 0.6562
Epoch 1 [71/172] - loss: 0.4511
Epoch 1 [72/172] - loss: 0.5629
Epoch 1 [73/172] - loss: 0.5267
Epoch 1 [74/172] - loss: 0.6961
Epoch 1 [75/172] - loss: 0.3533
Epoch 1 [76/172] - loss: 0.5081
Epoch 1 [77/172] - loss: 0.4686
Epoch 1 [78/172] - loss: 0.4041
Epoch 1 [79/172] - loss: 0.4913
Epoch 1 [80/172] - loss: 0.3436, acc: 0.8125
Epoch 1 [81/172] - loss: 0.4545
Epoch 1 [82/172] - loss: 0.7051
Epoch 1 [83/172] - loss: 0.5362
Epoch 1 [84/172] - loss: 0.5061
Epoch 1 [85/172] - loss: 0.4645
Epoch 1 [86/172] - loss: 0.7549
Epoch 1 [87/172] - loss: 0.4810
Epoch 1 [88/172] - loss: 0.7575
Epoch 1 [89/172] - loss: 0.8396
Epoch 1 [90/172] - loss: 0.6822, acc: 0.5625
Epoch 1 [91/172] - loss: 0.4830
Epoch 1 [92/172] - loss: 0.5258
Epoch 1 [93/172] - loss: 0.4717
Epoch 1 [94/172] - loss: 0.3347
Epoch 1 [95/172] - loss: 0.4455
Epoch 1 [96/172] - loss: 0.5238
Epoch 1 [97/172] - loss: 0.5049
Epoch 1 [98/172] - loss: 0.4392
Epoch 1 [99/172] - loss: 0.5834
Epoch 1 [100/172] - loss: 0.5181, acc: 0.7188

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5228, log_difficulty=0.4206, weight=3.1028
neutral: count=983.0, difficulty=0.5088, log_difficulty=0.4113, weight=3.0566
negative: count=1119.0, difficulty=0.5120, log_difficulty=0.4134, weight=3.0672

当前batch的pt分布：
positive: min=0.0556, max=0.9271, mean=0.5087
neutral: min=0.6138, max=0.9982, mean=0.8135
negative: min=0.0811, max=0.8493, mean=0.4553

当前batch准确率：
整体准确率: 0.6250
positive 准确率: 0.5833
neutral 准确率: 1.0000
negative 准确率: 0.5625

损失分量：
基础交叉熵: 0.8643
焦点损失: 0.3948
边界损失: 0.4227
总损失: 0.6214
Epoch 1 [101/172] - loss: 0.6214
Epoch 1 [102/172] - loss: 0.4414
Epoch 1 [103/172] - loss: 0.5352
Epoch 1 [104/172] - loss: 0.3513
Epoch 1 [105/172] - loss: 0.4547
Epoch 1 [106/172] - loss: 0.6760
Epoch 1 [107/172] - loss: 0.4529
Epoch 1 [108/172] - loss: 0.6312
Epoch 1 [109/172] - loss: 0.4814
Epoch 1 [110/172] - loss: 0.4424, acc: 0.8125
Epoch 1 [111/172] - loss: 0.4570
Epoch 1 [112/172] - loss: 0.4473
Epoch 1 [113/172] - loss: 0.3130
Epoch 1 [114/172] - loss: 0.4306
Epoch 1 [115/172] - loss: 0.4491
Epoch 1 [116/172] - loss: 0.5188
Epoch 1 [117/172] - loss: 0.4318
Epoch 1 [118/172] - loss: 0.3256
Epoch 1 [119/172] - loss: 0.3956
Epoch 1 [120/172] - loss: 0.3873, acc: 0.7500
Epoch 1 [121/172] - loss: 0.4242
Epoch 1 [122/172] - loss: 0.4937
Epoch 1 [123/172] - loss: 0.3086
Epoch 1 [124/172] - loss: 0.4508
Epoch 1 [125/172] - loss: 0.3479
Epoch 1 [126/172] - loss: 0.5274
Epoch 1 [127/172] - loss: 0.4031
Epoch 1 [128/172] - loss: 0.3661
Epoch 1 [129/172] - loss: 0.5060
Epoch 1 [130/172] - loss: 0.3696, acc: 0.7500
Epoch 1 [131/172] - loss: 0.3461
Epoch 1 [132/172] - loss: 0.4917
Epoch 1 [133/172] - loss: 0.4962
Epoch 1 [134/172] - loss: 0.3688
Epoch 1 [135/172] - loss: 0.4122
Epoch 1 [136/172] - loss: 0.3696
Epoch 1 [137/172] - loss: 0.5202
Epoch 1 [138/172] - loss: 0.3307
Epoch 1 [139/172] - loss: 0.2795
Epoch 1 [140/172] - loss: 0.3066, acc: 0.8125
Epoch 1 [141/172] - loss: 0.2850
Epoch 1 [142/172] - loss: 0.4103
Epoch 1 [143/172] - loss: 0.4216
Epoch 1 [144/172] - loss: 0.2105
Epoch 1 [145/172] - loss: 0.4134
Epoch 1 [146/172] - loss: 0.5151
Epoch 1 [147/172] - loss: 0.5920
Epoch 1 [148/172] - loss: 0.4267
Epoch 1 [149/172] - loss: 0.2210
Epoch 1 [150/172] - loss: 0.5629, acc: 0.5938
Epoch 1 [151/172] - loss: 0.5191
Epoch 1 [152/172] - loss: 0.3426
Epoch 1 [153/172] - loss: 0.3387
Epoch 1 [154/172] - loss: 0.3205
Epoch 1 [155/172] - loss: 0.4623
Epoch 1 [156/172] - loss: 0.5725
Epoch 1 [157/172] - loss: 0.3864
Epoch 1 [158/172] - loss: 0.4027
Epoch 1 [159/172] - loss: 0.5171
Epoch 1 [160/172] - loss: 0.3689, acc: 0.7500
Epoch 1 [161/172] - loss: 0.2642
Epoch 1 [162/172] - loss: 0.2730
Epoch 1 [163/172] - loss: 0.3645
Epoch 1 [164/172] - loss: 0.4812
Epoch 1 [165/172] - loss: 0.2858
Epoch 1 [166/172] - loss: 0.3700
Epoch 1 [167/172] - loss: 0.3826
Epoch 1 [168/172] - loss: 0.5076
Epoch 1 [169/172] - loss: 0.4028
Epoch 1 [170/172] - loss: 0.3811, acc: 0.7812
Epoch 1 [171/172] - loss: 0.2759
Epoch 1 [172/172] - loss: 0.3834

类别准确率:
positive: 0.5675 (265/467)
neutral: 0.6265 (52/83)
negative: 0.7240 (181/250)

Epoch 1/10
Train Loss: 0.3780, Train Acc: 0.7960
Val Loss: 0.9171, Val Acc: 0.6225
Epoch 2 [1/172] - loss: 0.2762, acc: 0.9375
Epoch 2 [2/172] - loss: 0.2494
Epoch 2 [3/172] - loss: 0.2713
Epoch 2 [4/172] - loss: 0.3978
Epoch 2 [5/172] - loss: 0.3419
Epoch 2 [6/172] - loss: 0.3433
Epoch 2 [7/172] - loss: 0.3945
Epoch 2 [8/172] - loss: 0.2243
Epoch 2 [9/172] - loss: 0.2757
Epoch 2 [10/172] - loss: 0.3578, acc: 0.8125
Epoch 2 [11/172] - loss: 0.2658
Epoch 2 [12/172] - loss: 0.2398
Epoch 2 [13/172] - loss: 0.3471
Epoch 2 [14/172] - loss: 0.2961
Epoch 2 [15/172] - loss: 0.3011
Epoch 2 [16/172] - loss: 0.3014
Epoch 2 [17/172] - loss: 0.3115
Epoch 2 [18/172] - loss: 0.3429
Epoch 2 [19/172] - loss: 0.2778
Epoch 2 [20/172] - loss: 0.2272, acc: 0.9375
Epoch 2 [21/172] - loss: 0.2718
Epoch 2 [22/172] - loss: 0.2194
Epoch 2 [23/172] - loss: 0.2245
Epoch 2 [24/172] - loss: 0.4139
Epoch 2 [25/172] - loss: 0.3486
Epoch 2 [26/172] - loss: 0.2267
Epoch 2 [27/172] - loss: 0.2061
Epoch 2 [28/172] - loss: 0.2730

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4336, log_difficulty=0.3602, weight=2.8010
neutral: count=1952.0, difficulty=0.3743, log_difficulty=0.3180, weight=2.5899
negative: count=2216.0, difficulty=0.4219, log_difficulty=0.3520, weight=2.7600

当前batch的pt分布：
positive: min=0.3094, max=0.9845, mean=0.8242
neutral: min=0.6253, max=0.9745, mean=0.8998
negative: min=0.0189, max=0.9905, mean=0.7423

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8889
neutral 准确率: 1.0000
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.3299
焦点损失: 0.1682
边界损失: 0.2079
总损失: 0.2721
Epoch 2 [29/172] - loss: 0.2721
Epoch 2 [30/172] - loss: 0.2570, acc: 0.9375
Epoch 2 [31/172] - loss: 0.2149
Epoch 2 [32/172] - loss: 0.2577
Epoch 2 [33/172] - loss: 0.2442
Epoch 2 [34/172] - loss: 0.2566
Epoch 2 [35/172] - loss: 0.1986
Epoch 2 [36/172] - loss: 0.3297
Epoch 2 [37/172] - loss: 0.1826
Epoch 2 [38/172] - loss: 0.2799
Epoch 2 [39/172] - loss: 0.3067
Epoch 2 [40/172] - loss: 0.3700, acc: 0.8125
Epoch 2 [41/172] - loss: 0.1801
Epoch 2 [42/172] - loss: 0.1772
Epoch 2 [43/172] - loss: 0.1679
Epoch 2 [44/172] - loss: 0.3274
Epoch 2 [45/172] - loss: 0.1680
Epoch 2 [46/172] - loss: 0.2177
Epoch 2 [47/172] - loss: 0.3159
Epoch 2 [48/172] - loss: 0.3177
Epoch 2 [49/172] - loss: 0.2603
Epoch 2 [50/172] - loss: 0.3256, acc: 0.7812
Epoch 2 [51/172] - loss: 0.3152
Epoch 2 [52/172] - loss: 0.1937
Epoch 2 [53/172] - loss: 0.1811
Epoch 2 [54/172] - loss: 0.1988
Epoch 2 [55/172] - loss: 0.3619
Epoch 2 [56/172] - loss: 0.2149
Epoch 2 [57/172] - loss: 0.1886
Epoch 2 [58/172] - loss: 0.3032
Epoch 2 [59/172] - loss: 0.3315
Epoch 2 [60/172] - loss: 0.2345, acc: 0.8750
Epoch 2 [61/172] - loss: 0.1508
Epoch 2 [62/172] - loss: 0.1542
Epoch 2 [63/172] - loss: 0.2481
Epoch 2 [64/172] - loss: 0.2447
Epoch 2 [65/172] - loss: 0.1861
Epoch 2 [66/172] - loss: 0.2411
Epoch 2 [67/172] - loss: 0.1800
Epoch 2 [68/172] - loss: 0.2753
Epoch 2 [69/172] - loss: 0.1882
Epoch 2 [70/172] - loss: 0.3562, acc: 0.7812
Epoch 2 [71/172] - loss: 0.2562
Epoch 2 [72/172] - loss: 0.2634
Epoch 2 [73/172] - loss: 0.2584
Epoch 2 [74/172] - loss: 0.2242
Epoch 2 [75/172] - loss: 0.1983
Epoch 2 [76/172] - loss: 0.2503
Epoch 2 [77/172] - loss: 0.2642
Epoch 2 [78/172] - loss: 0.2490
Epoch 2 [79/172] - loss: 0.2433
Epoch 2 [80/172] - loss: 0.1485, acc: 1.0000
Epoch 2 [81/172] - loss: 0.2355
Epoch 2 [82/172] - loss: 0.2008
Epoch 2 [83/172] - loss: 0.1951
Epoch 2 [84/172] - loss: 0.2121
Epoch 2 [85/172] - loss: 0.2359
Epoch 2 [86/172] - loss: 0.2755
Epoch 2 [87/172] - loss: 0.4809
Epoch 2 [88/172] - loss: 0.2069
Epoch 2 [89/172] - loss: 0.2015
Epoch 2 [90/172] - loss: 0.2771, acc: 0.8438
Epoch 2 [91/172] - loss: 0.1380
Epoch 2 [92/172] - loss: 0.2935
Epoch 2 [93/172] - loss: 0.2605
Epoch 2 [94/172] - loss: 0.2298
Epoch 2 [95/172] - loss: 0.3326
Epoch 2 [96/172] - loss: 0.2056
Epoch 2 [97/172] - loss: 0.1903
Epoch 2 [98/172] - loss: 0.1646
Epoch 2 [99/172] - loss: 0.1664
Epoch 2 [100/172] - loss: 0.2300, acc: 0.9375
Epoch 2 [101/172] - loss: 0.1632
Epoch 2 [102/172] - loss: 0.1802
Epoch 2 [103/172] - loss: 0.2399
Epoch 2 [104/172] - loss: 0.2283
Epoch 2 [105/172] - loss: 0.2412
Epoch 2 [106/172] - loss: 0.2312
Epoch 2 [107/172] - loss: 0.2249
Epoch 2 [108/172] - loss: 0.3205
Epoch 2 [109/172] - loss: 0.2093
Epoch 2 [110/172] - loss: 0.1879, acc: 0.9375
Epoch 2 [111/172] - loss: 0.1798
Epoch 2 [112/172] - loss: 0.1799
Epoch 2 [113/172] - loss: 0.1642
Epoch 2 [114/172] - loss: 0.2197
Epoch 2 [115/172] - loss: 0.2409
Epoch 2 [116/172] - loss: 0.2130
Epoch 2 [117/172] - loss: 0.2978
Epoch 2 [118/172] - loss: 0.1898
Epoch 2 [119/172] - loss: 0.2140
Epoch 2 [120/172] - loss: 0.1795, acc: 0.9688
Epoch 2 [121/172] - loss: 0.2142
Epoch 2 [122/172] - loss: 0.3333
Epoch 2 [123/172] - loss: 0.2392
Epoch 2 [124/172] - loss: 0.2067
Epoch 2 [125/172] - loss: 0.1571
Epoch 2 [126/172] - loss: 0.2217
Epoch 2 [127/172] - loss: 0.1850
Epoch 2 [128/172] - loss: 0.2252

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3632, log_difficulty=0.3098, weight=2.5492
neutral: count=2949.0, difficulty=0.2844, log_difficulty=0.2503, weight=2.2513
negative: count=3294.0, difficulty=0.3511, log_difficulty=0.3009, weight=2.5046

当前batch的pt分布：
positive: min=0.2144, max=0.9969, mean=0.8299
neutral: min=0.7960, max=0.9934, mean=0.9238
negative: min=0.1613, max=0.9984, mean=0.7612

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.2395
焦点损失: 0.0791
边界损失: 0.2079
总损失: 0.2058
Epoch 2 [129/172] - loss: 0.2058
Epoch 2 [130/172] - loss: 0.2029, acc: 0.9375
Epoch 2 [131/172] - loss: 0.2284
Epoch 2 [132/172] - loss: 0.1905
Epoch 2 [133/172] - loss: 0.2914
Epoch 2 [134/172] - loss: 0.2317
Epoch 2 [135/172] - loss: 0.2828
Epoch 2 [136/172] - loss: 0.2392
Epoch 2 [137/172] - loss: 0.1358
Epoch 2 [138/172] - loss: 0.1769
Epoch 2 [139/172] - loss: 0.2007
Epoch 2 [140/172] - loss: 0.2146, acc: 0.9375
Epoch 2 [141/172] - loss: 0.1645
Epoch 2 [142/172] - loss: 0.1962
Epoch 2 [143/172] - loss: 0.2726
Epoch 2 [144/172] - loss: 0.1536
Epoch 2 [145/172] - loss: 0.3229
Epoch 2 [146/172] - loss: 0.1535
Epoch 2 [147/172] - loss: 0.2089
Epoch 2 [148/172] - loss: 0.1722
Epoch 2 [149/172] - loss: 0.2029
Epoch 2 [150/172] - loss: 0.1688, acc: 0.9688
Epoch 2 [151/172] - loss: 0.2161
Epoch 2 [152/172] - loss: 0.2257
Epoch 2 [153/172] - loss: 0.1758
Epoch 2 [154/172] - loss: 0.1776
Epoch 2 [155/172] - loss: 0.2565
Epoch 2 [156/172] - loss: 0.1651
Epoch 2 [157/172] - loss: 0.1446
Epoch 2 [158/172] - loss: 0.2078
Epoch 2 [159/172] - loss: 0.1948
Epoch 2 [160/172] - loss: 0.1537, acc: 0.9688
Epoch 2 [161/172] - loss: 0.1632
Epoch 2 [162/172] - loss: 0.1756
Epoch 2 [163/172] - loss: 0.2938
Epoch 2 [164/172] - loss: 0.1630
Epoch 2 [165/172] - loss: 0.2387
Epoch 2 [166/172] - loss: 0.2987
Epoch 2 [167/172] - loss: 0.2678
Epoch 2 [168/172] - loss: 0.1456
Epoch 2 [169/172] - loss: 0.1335
Epoch 2 [170/172] - loss: 0.1767, acc: 0.9688
Epoch 2 [171/172] - loss: 0.2874
Epoch 2 [172/172] - loss: 0.4448

类别准确率:
positive: 0.9208 (430/467)
neutral: 0.2771 (23/83)
negative: 0.4360 (109/250)

Epoch 2/10
Train Loss: 0.2181, Train Acc: 0.9374
Val Loss: 0.7949, Val Acc: 0.7025
Epoch 3 [1/172] - loss: 0.1546, acc: 1.0000
Epoch 3 [2/172] - loss: 0.2169
Epoch 3 [3/172] - loss: 0.1476
Epoch 3 [4/172] - loss: 0.1314
Epoch 3 [5/172] - loss: 0.1508
Epoch 3 [6/172] - loss: 0.1525
Epoch 3 [7/172] - loss: 0.1307
Epoch 3 [8/172] - loss: 0.1379
Epoch 3 [9/172] - loss: 0.1528
Epoch 3 [10/172] - loss: 0.1390, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1310
Epoch 3 [12/172] - loss: 0.1487
Epoch 3 [13/172] - loss: 0.1548
Epoch 3 [14/172] - loss: 0.1375
Epoch 3 [15/172] - loss: 0.1677
Epoch 3 [16/172] - loss: 0.2047
Epoch 3 [17/172] - loss: 0.1617
Epoch 3 [18/172] - loss: 0.2362
Epoch 3 [19/172] - loss: 0.1586
Epoch 3 [20/172] - loss: 0.1237, acc: 1.0000
Epoch 3 [21/172] - loss: 0.2057
Epoch 3 [22/172] - loss: 0.2442
Epoch 3 [23/172] - loss: 0.1626
Epoch 3 [24/172] - loss: 0.1826
Epoch 3 [25/172] - loss: 0.1700
Epoch 3 [26/172] - loss: 0.1391
Epoch 3 [27/172] - loss: 0.1393
Epoch 3 [28/172] - loss: 0.1578
Epoch 3 [29/172] - loss: 0.1803
Epoch 3 [30/172] - loss: 0.2068, acc: 0.8750
Epoch 3 [31/172] - loss: 0.1348
Epoch 3 [32/172] - loss: 0.1479
Epoch 3 [33/172] - loss: 0.1424
Epoch 3 [34/172] - loss: 0.1556
Epoch 3 [35/172] - loss: 0.1618
Epoch 3 [36/172] - loss: 0.1436
Epoch 3 [37/172] - loss: 0.1783
Epoch 3 [38/172] - loss: 0.1349
Epoch 3 [39/172] - loss: 0.1265
Epoch 3 [40/172] - loss: 0.1739, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1389
Epoch 3 [42/172] - loss: 0.1576
Epoch 3 [43/172] - loss: 0.1193
Epoch 3 [44/172] - loss: 0.1205
Epoch 3 [45/172] - loss: 0.1550
Epoch 3 [46/172] - loss: 0.1470
Epoch 3 [47/172] - loss: 0.1161
Epoch 3 [48/172] - loss: 0.1654
Epoch 3 [49/172] - loss: 0.1143
Epoch 3 [50/172] - loss: 0.1278, acc: 1.0000
Epoch 3 [51/172] - loss: 0.1695
Epoch 3 [52/172] - loss: 0.1908
Epoch 3 [53/172] - loss: 0.1512
Epoch 3 [54/172] - loss: 0.1542
Epoch 3 [55/172] - loss: 0.1514
Epoch 3 [56/172] - loss: 0.1517

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3056, log_difficulty=0.2667, weight=2.3333
neutral: count=3923.0, difficulty=0.2346, log_difficulty=0.2108, weight=2.0539
negative: count=4382.0, difficulty=0.2949, log_difficulty=0.2584, weight=2.2920

当前batch的pt分布：
positive: min=0.0823, max=0.9957, mean=0.7480
neutral: min=0.0021, max=0.9976, mean=0.8085
negative: min=0.9889, max=0.9970, mean=0.9931

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.7273
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.4810
焦点损失: 0.3575
边界损失: 0.1808
总损失: 0.3288
Epoch 3 [57/172] - loss: 0.3288
Epoch 3 [58/172] - loss: 0.1246
Epoch 3 [59/172] - loss: 0.2309
Epoch 3 [60/172] - loss: 0.1350, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1313
Epoch 3 [62/172] - loss: 0.1587
Epoch 3 [63/172] - loss: 0.1552
Epoch 3 [64/172] - loss: 0.1351
Epoch 3 [65/172] - loss: 0.1433
Epoch 3 [66/172] - loss: 0.1480
Epoch 3 [67/172] - loss: 0.1211
Epoch 3 [68/172] - loss: 0.1444
Epoch 3 [69/172] - loss: 0.2302
Epoch 3 [70/172] - loss: 0.1213, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1347
Epoch 3 [72/172] - loss: 0.1579
Epoch 3 [73/172] - loss: 0.1322
Epoch 3 [74/172] - loss: 0.1596
Epoch 3 [75/172] - loss: 0.1297
Epoch 3 [76/172] - loss: 0.1258
Epoch 3 [77/172] - loss: 0.1683
Epoch 3 [78/172] - loss: 0.2147
Epoch 3 [79/172] - loss: 0.1309
Epoch 3 [80/172] - loss: 0.1842, acc: 0.9062
Epoch 3 [81/172] - loss: 0.1363
Epoch 3 [82/172] - loss: 0.1618
Epoch 3 [83/172] - loss: 0.1213
Epoch 3 [84/172] - loss: 0.1488
Epoch 3 [85/172] - loss: 0.1366
Epoch 3 [86/172] - loss: 0.1235
Epoch 3 [87/172] - loss: 0.1951
Epoch 3 [88/172] - loss: 0.1405
Epoch 3 [89/172] - loss: 0.1150
Epoch 3 [90/172] - loss: 0.1324, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1465
Epoch 3 [92/172] - loss: 0.1748
Epoch 3 [93/172] - loss: 0.2048
Epoch 3 [94/172] - loss: 0.1457
Epoch 3 [95/172] - loss: 0.1200
Epoch 3 [96/172] - loss: 0.1252
Epoch 3 [97/172] - loss: 0.1262
Epoch 3 [98/172] - loss: 0.1284
Epoch 3 [99/172] - loss: 0.1706
Epoch 3 [100/172] - loss: 0.2476, acc: 0.9062
Epoch 3 [101/172] - loss: 0.1914
Epoch 3 [102/172] - loss: 0.1175
Epoch 3 [103/172] - loss: 0.1493
Epoch 3 [104/172] - loss: 0.1268
Epoch 3 [105/172] - loss: 0.1299
Epoch 3 [106/172] - loss: 0.1273
Epoch 3 [107/172] - loss: 0.1199
Epoch 3 [108/172] - loss: 0.1249
Epoch 3 [109/172] - loss: 0.1209
Epoch 3 [110/172] - loss: 0.1351, acc: 1.0000
Epoch 3 [111/172] - loss: 0.1578
Epoch 3 [112/172] - loss: 0.1231
Epoch 3 [113/172] - loss: 0.1285
Epoch 3 [114/172] - loss: 0.1304
Epoch 3 [115/172] - loss: 0.1566
Epoch 3 [116/172] - loss: 0.1258
Epoch 3 [117/172] - loss: 0.1331
Epoch 3 [118/172] - loss: 0.1398
Epoch 3 [119/172] - loss: 0.1585
Epoch 3 [120/172] - loss: 0.1929, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1410
Epoch 3 [122/172] - loss: 0.1170
Epoch 3 [123/172] - loss: 0.1344
Epoch 3 [124/172] - loss: 0.1381
Epoch 3 [125/172] - loss: 0.1279
Epoch 3 [126/172] - loss: 0.2200
Epoch 3 [127/172] - loss: 0.1375
Epoch 3 [128/172] - loss: 0.1138
Epoch 3 [129/172] - loss: 0.1588
Epoch 3 [130/172] - loss: 0.1352, acc: 0.9688
Epoch 3 [131/172] - loss: 0.1437
Epoch 3 [132/172] - loss: 0.1163
Epoch 3 [133/172] - loss: 0.1162
Epoch 3 [134/172] - loss: 0.1096
Epoch 3 [135/172] - loss: 0.1193
Epoch 3 [136/172] - loss: 0.1242
Epoch 3 [137/172] - loss: 0.1125
Epoch 3 [138/172] - loss: 0.1334
Epoch 3 [139/172] - loss: 0.1215
Epoch 3 [140/172] - loss: 0.1298, acc: 1.0000
Epoch 3 [141/172] - loss: 0.1743
Epoch 3 [142/172] - loss: 0.1964
Epoch 3 [143/172] - loss: 0.1512
Epoch 3 [144/172] - loss: 0.2657
Epoch 3 [145/172] - loss: 0.1287
Epoch 3 [146/172] - loss: 0.1389
Epoch 3 [147/172] - loss: 0.1307
Epoch 3 [148/172] - loss: 0.1379
Epoch 3 [149/172] - loss: 0.1629
Epoch 3 [150/172] - loss: 0.1700, acc: 0.8750
Epoch 3 [151/172] - loss: 0.1971
Epoch 3 [152/172] - loss: 0.2182
Epoch 3 [153/172] - loss: 0.1213
Epoch 3 [154/172] - loss: 0.1948
Epoch 3 [155/172] - loss: 0.1160
Epoch 3 [156/172] - loss: 0.1327

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2616, log_difficulty=0.2324, weight=2.1620
neutral: count=4903.0, difficulty=0.1984, log_difficulty=0.1810, weight=1.9050
negative: count=5500.0, difficulty=0.2522, log_difficulty=0.2249, weight=2.1247

当前batch的pt分布：
positive: min=0.6961, max=0.9951, mean=0.9414
neutral: min=0.7455, max=0.9988, mean=0.9556
negative: min=0.7189, max=0.9992, mean=0.9449

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0582
焦点损失: 0.0022
边界损失: 0.1643
总损失: 0.1244
Epoch 3 [157/172] - loss: 0.1244
Epoch 3 [158/172] - loss: 0.1470
Epoch 3 [159/172] - loss: 0.1938
Epoch 3 [160/172] - loss: 0.2038, acc: 0.9375
Epoch 3 [161/172] - loss: 0.1612
Epoch 3 [162/172] - loss: 0.1494
Epoch 3 [163/172] - loss: 0.1700
Epoch 3 [164/172] - loss: 0.1166
Epoch 3 [165/172] - loss: 0.1215
Epoch 3 [166/172] - loss: 0.1257
Epoch 3 [167/172] - loss: 0.1304
Epoch 3 [168/172] - loss: 0.1749
Epoch 3 [169/172] - loss: 0.1265
Epoch 3 [170/172] - loss: 0.1389, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1344
Epoch 3 [172/172] - loss: 0.1096

类别准确率:
positive: 0.8244 (385/467)
neutral: 0.3614 (30/83)
negative: 0.6080 (152/250)

Epoch 3/10
Train Loss: 0.1455, Train Acc: 0.9697
Val Loss: 0.9019, Val Acc: 0.7087
Epoch 4 [1/172] - loss: 0.1116, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1763
Epoch 4 [3/172] - loss: 0.1331
Epoch 4 [4/172] - loss: 0.1184
Epoch 4 [5/172] - loss: 0.1397
Epoch 4 [6/172] - loss: 0.1182
Epoch 4 [7/172] - loss: 0.1355
Epoch 4 [8/172] - loss: 0.1223
Epoch 4 [9/172] - loss: 0.1572
Epoch 4 [10/172] - loss: 0.1762, acc: 0.9688
Epoch 4 [11/172] - loss: 0.1100
Epoch 4 [12/172] - loss: 0.1460
Epoch 4 [13/172] - loss: 0.1678
Epoch 4 [14/172] - loss: 0.1366
Epoch 4 [15/172] - loss: 0.1187
Epoch 4 [16/172] - loss: 0.1108
Epoch 4 [17/172] - loss: 0.1164
Epoch 4 [18/172] - loss: 0.1174
Epoch 4 [19/172] - loss: 0.1128
Epoch 4 [20/172] - loss: 0.1284, acc: 0.9688
Epoch 4 [21/172] - loss: 0.1474
Epoch 4 [22/172] - loss: 0.1101
Epoch 4 [23/172] - loss: 0.1402
Epoch 4 [24/172] - loss: 0.1751
Epoch 4 [25/172] - loss: 0.1098
Epoch 4 [26/172] - loss: 0.1648
Epoch 4 [27/172] - loss: 0.1096
Epoch 4 [28/172] - loss: 0.1416
Epoch 4 [29/172] - loss: 0.1117
Epoch 4 [30/172] - loss: 0.1577, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1838
Epoch 4 [32/172] - loss: 0.1160
Epoch 4 [33/172] - loss: 0.1137
Epoch 4 [34/172] - loss: 0.1105
Epoch 4 [35/172] - loss: 0.1703
Epoch 4 [36/172] - loss: 0.1291
Epoch 4 [37/172] - loss: 0.1061
Epoch 4 [38/172] - loss: 0.1083
Epoch 4 [39/172] - loss: 0.1565
Epoch 4 [40/172] - loss: 0.1649, acc: 0.9375
Epoch 4 [41/172] - loss: 0.1103
Epoch 4 [42/172] - loss: 0.1332
Epoch 4 [43/172] - loss: 0.1246
Epoch 4 [44/172] - loss: 0.1157
Epoch 4 [45/172] - loss: 0.1194
Epoch 4 [46/172] - loss: 0.1239
Epoch 4 [47/172] - loss: 0.1152
Epoch 4 [48/172] - loss: 0.1087
Epoch 4 [49/172] - loss: 0.1185
Epoch 4 [50/172] - loss: 0.1571, acc: 0.9688
Epoch 4 [51/172] - loss: 0.1133
Epoch 4 [52/172] - loss: 0.1609
Epoch 4 [53/172] - loss: 0.1107
Epoch 4 [54/172] - loss: 0.1218
Epoch 4 [55/172] - loss: 0.1902
Epoch 4 [56/172] - loss: 0.1195
Epoch 4 [57/172] - loss: 0.1104
Epoch 4 [58/172] - loss: 0.1107
Epoch 4 [59/172] - loss: 0.1083
Epoch 4 [60/172] - loss: 0.1118, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1135
Epoch 4 [62/172] - loss: 0.1571
Epoch 4 [63/172] - loss: 0.1124
Epoch 4 [64/172] - loss: 0.1091
Epoch 4 [65/172] - loss: 0.1248
Epoch 4 [66/172] - loss: 0.1088
Epoch 4 [67/172] - loss: 0.1168
Epoch 4 [68/172] - loss: 0.1093
Epoch 4 [69/172] - loss: 0.1499
Epoch 4 [70/172] - loss: 0.1087, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1108
Epoch 4 [72/172] - loss: 0.1129
Epoch 4 [73/172] - loss: 0.1090
Epoch 4 [74/172] - loss: 0.2331
Epoch 4 [75/172] - loss: 0.1125
Epoch 4 [76/172] - loss: 0.1102
Epoch 4 [77/172] - loss: 0.1224
Epoch 4 [78/172] - loss: 0.1154
Epoch 4 [79/172] - loss: 0.1109
Epoch 4 [80/172] - loss: 0.1211, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1440
Epoch 4 [82/172] - loss: 0.1177
Epoch 4 [83/172] - loss: 0.1116
Epoch 4 [84/172] - loss: 0.1138

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2284, log_difficulty=0.2057, weight=2.0285
neutral: count=5865.0, difficulty=0.1727, log_difficulty=0.1593, weight=1.7964
negative: count=6629.0, difficulty=0.2188, log_difficulty=0.1979, weight=1.9895

当前batch的pt分布：
positive: min=0.5764, max=0.9932, mean=0.9113
neutral: min=0.9698, max=0.9995, mean=0.9934
negative: min=0.8332, max=0.9990, mean=0.9701

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0628
焦点损失: 0.0053
边界损失: 0.1626
总损失: 0.1247
Epoch 4 [85/172] - loss: 0.1247
Epoch 4 [86/172] - loss: 0.1579
Epoch 4 [87/172] - loss: 0.1473
Epoch 4 [88/172] - loss: 0.1112
Epoch 4 [89/172] - loss: 0.1220
Epoch 4 [90/172] - loss: 0.1145, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1192
Epoch 4 [92/172] - loss: 0.1701
Epoch 4 [93/172] - loss: 0.1075
Epoch 4 [94/172] - loss: 0.1076
Epoch 4 [95/172] - loss: 0.1246
Epoch 4 [96/172] - loss: 0.1159
Epoch 4 [97/172] - loss: 0.1096
Epoch 4 [98/172] - loss: 0.1089
Epoch 4 [99/172] - loss: 0.1269
Epoch 4 [100/172] - loss: 0.1114, acc: 1.0000
Epoch 4 [101/172] - loss: 0.1518
Epoch 4 [102/172] - loss: 0.1266
Epoch 4 [103/172] - loss: 0.1109
Epoch 4 [104/172] - loss: 0.1137
Epoch 4 [105/172] - loss: 0.1409
Epoch 4 [106/172] - loss: 0.1146
Epoch 4 [107/172] - loss: 0.1085
Epoch 4 [108/172] - loss: 0.1362
Epoch 4 [109/172] - loss: 0.1525
Epoch 4 [110/172] - loss: 0.2192, acc: 0.8438
Epoch 4 [111/172] - loss: 0.1148
Epoch 4 [112/172] - loss: 0.1093
Epoch 4 [113/172] - loss: 0.1111
Epoch 4 [114/172] - loss: 0.1146
Epoch 4 [115/172] - loss: 0.1172
Epoch 4 [116/172] - loss: 0.1256
Epoch 4 [117/172] - loss: 0.1129
Epoch 4 [118/172] - loss: 0.1665
Epoch 4 [119/172] - loss: 0.1116
Epoch 4 [120/172] - loss: 0.1642, acc: 0.9688
Epoch 4 [121/172] - loss: 0.1275
Epoch 4 [122/172] - loss: 0.2096
Epoch 4 [123/172] - loss: 0.1078
Epoch 4 [124/172] - loss: 0.1071
Epoch 4 [125/172] - loss: 0.1220
Epoch 4 [126/172] - loss: 0.2098
Epoch 4 [127/172] - loss: 0.1229
Epoch 4 [128/172] - loss: 0.1116
Epoch 4 [129/172] - loss: 0.1064
Epoch 4 [130/172] - loss: 0.1090, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1089
Epoch 4 [132/172] - loss: 0.1084
Epoch 4 [133/172] - loss: 0.1498
Epoch 4 [134/172] - loss: 0.1091
Epoch 4 [135/172] - loss: 0.1142
Epoch 4 [136/172] - loss: 0.1596
Epoch 4 [137/172] - loss: 0.1228
Epoch 4 [138/172] - loss: 0.1113
Epoch 4 [139/172] - loss: 0.1152
Epoch 4 [140/172] - loss: 0.1263, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1435
Epoch 4 [142/172] - loss: 0.1275
Epoch 4 [143/172] - loss: 0.1257
Epoch 4 [144/172] - loss: 0.1167
Epoch 4 [145/172] - loss: 0.1399
Epoch 4 [146/172] - loss: 0.1137
Epoch 4 [147/172] - loss: 0.1166
Epoch 4 [148/172] - loss: 0.1180
Epoch 4 [149/172] - loss: 0.1096
Epoch 4 [150/172] - loss: 0.1418, acc: 0.9688
Epoch 4 [151/172] - loss: 0.1701
Epoch 4 [152/172] - loss: 0.1101
Epoch 4 [153/172] - loss: 0.1180
Epoch 4 [154/172] - loss: 0.1586
Epoch 4 [155/172] - loss: 0.1103
Epoch 4 [156/172] - loss: 0.1134
Epoch 4 [157/172] - loss: 0.1721
Epoch 4 [158/172] - loss: 0.1075
Epoch 4 [159/172] - loss: 0.1114
Epoch 4 [160/172] - loss: 0.1074, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1226
Epoch 4 [162/172] - loss: 0.1097
Epoch 4 [163/172] - loss: 0.1132
Epoch 4 [164/172] - loss: 0.1154
Epoch 4 [165/172] - loss: 0.1795
Epoch 4 [166/172] - loss: 0.1104
Epoch 4 [167/172] - loss: 0.1421
Epoch 4 [168/172] - loss: 0.1083
Epoch 4 [169/172] - loss: 0.1536
Epoch 4 [170/172] - loss: 0.1236, acc: 1.0000
Epoch 4 [171/172] - loss: 0.1132
Epoch 4 [172/172] - loss: 0.1169

类别准确率:
positive: 0.8630 (403/467)
neutral: 0.2410 (20/83)
negative: 0.6240 (156/250)

Epoch 4/10
Train Loss: 0.1254, Train Acc: 0.9899
Val Loss: 0.9035, Val Acc: 0.7238
Epoch 5 [1/172] - loss: 0.1085, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1213
Epoch 5 [3/172] - loss: 0.1060
Epoch 5 [4/172] - loss: 0.1211
Epoch 5 [5/172] - loss: 0.1092
Epoch 5 [6/172] - loss: 0.1218
Epoch 5 [7/172] - loss: 0.1132
Epoch 5 [8/172] - loss: 0.1200
Epoch 5 [9/172] - loss: 0.1302
Epoch 5 [10/172] - loss: 0.1074, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1119
Epoch 5 [12/172] - loss: 0.1112

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2023, log_difficulty=0.1843, weight=1.9213
neutral: count=6845.0, difficulty=0.1526, log_difficulty=0.1421, weight=1.7103
negative: count=7694.0, difficulty=0.1946, log_difficulty=0.1778, weight=1.8890

当前batch的pt分布：
positive: min=0.3149, max=0.9974, mean=0.9212
neutral: min=0.9919, max=0.9999, mean=0.9968
negative: min=0.9776, max=0.9988, mean=0.9876

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0546
焦点损失: 0.0167
边界损失: 0.1500
总损失: 0.1205
Epoch 5 [13/172] - loss: 0.1205
Epoch 5 [14/172] - loss: 0.1343
Epoch 5 [15/172] - loss: 0.1076
Epoch 5 [16/172] - loss: 0.1085
Epoch 5 [17/172] - loss: 0.1216
Epoch 5 [18/172] - loss: 0.1080
Epoch 5 [19/172] - loss: 0.1362
Epoch 5 [20/172] - loss: 0.1188, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1628
Epoch 5 [22/172] - loss: 0.1811
Epoch 5 [23/172] - loss: 0.1071
Epoch 5 [24/172] - loss: 0.1115
Epoch 5 [25/172] - loss: 0.1057
Epoch 5 [26/172] - loss: 0.1234
Epoch 5 [27/172] - loss: 0.1087
Epoch 5 [28/172] - loss: 0.1053
Epoch 5 [29/172] - loss: 0.1059
Epoch 5 [30/172] - loss: 0.1091, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1195
Epoch 5 [32/172] - loss: 0.1070
Epoch 5 [33/172] - loss: 0.1111
Epoch 5 [34/172] - loss: 0.1198
Epoch 5 [35/172] - loss: 0.1070
Epoch 5 [36/172] - loss: 0.1068
Epoch 5 [37/172] - loss: 0.1167
Epoch 5 [38/172] - loss: 0.1067
Epoch 5 [39/172] - loss: 0.1989
Epoch 5 [40/172] - loss: 0.1101, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1121
Epoch 5 [42/172] - loss: 0.1195
Epoch 5 [43/172] - loss: 0.1736
Epoch 5 [44/172] - loss: 0.1255
Epoch 5 [45/172] - loss: 0.1082
Epoch 5 [46/172] - loss: 0.1373
Epoch 5 [47/172] - loss: 0.1070
Epoch 5 [48/172] - loss: 0.1192
Epoch 5 [49/172] - loss: 0.1094
Epoch 5 [50/172] - loss: 0.1110, acc: 1.0000
Epoch 5 [51/172] - loss: 0.1149
Epoch 5 [52/172] - loss: 0.1080
Epoch 5 [53/172] - loss: 0.1141
Epoch 5 [54/172] - loss: 0.1114
Epoch 5 [55/172] - loss: 0.1157
Epoch 5 [56/172] - loss: 0.1083
Epoch 5 [57/172] - loss: 0.1111
Epoch 5 [58/172] - loss: 0.1105
Epoch 5 [59/172] - loss: 0.1255
Epoch 5 [60/172] - loss: 0.1104, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1163
Epoch 5 [62/172] - loss: 0.1168
Epoch 5 [63/172] - loss: 0.1227
Epoch 5 [64/172] - loss: 0.1451
Epoch 5 [65/172] - loss: 0.1202
Epoch 5 [66/172] - loss: 0.1058
Epoch 5 [67/172] - loss: 0.1058
Epoch 5 [68/172] - loss: 0.1088
Epoch 5 [69/172] - loss: 0.1208
Epoch 5 [70/172] - loss: 0.1297, acc: 0.9688
Epoch 5 [71/172] - loss: 0.1079
Epoch 5 [72/172] - loss: 0.1183
Epoch 5 [73/172] - loss: 0.1741
Epoch 5 [74/172] - loss: 0.1140
Epoch 5 [75/172] - loss: 0.1089
Epoch 5 [76/172] - loss: 0.1099
Epoch 5 [77/172] - loss: 0.1113
Epoch 5 [78/172] - loss: 0.1371
Epoch 5 [79/172] - loss: 0.1177
Epoch 5 [80/172] - loss: 0.1111, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1785
Epoch 5 [82/172] - loss: 0.1284
Epoch 5 [83/172] - loss: 0.1090
Epoch 5 [84/172] - loss: 0.1119
Epoch 5 [85/172] - loss: 0.1518
Epoch 5 [86/172] - loss: 0.1126
Epoch 5 [87/172] - loss: 0.1223
Epoch 5 [88/172] - loss: 0.1418
Epoch 5 [89/172] - loss: 0.1083
Epoch 5 [90/172] - loss: 0.1766, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1175
Epoch 5 [92/172] - loss: 0.1058
Epoch 5 [93/172] - loss: 0.1148
Epoch 5 [94/172] - loss: 0.1080
Epoch 5 [95/172] - loss: 0.1130
Epoch 5 [96/172] - loss: 0.1281
Epoch 5 [97/172] - loss: 0.1651
Epoch 5 [98/172] - loss: 0.1092
Epoch 5 [99/172] - loss: 0.1639
Epoch 5 [100/172] - loss: 0.1121, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1117
Epoch 5 [102/172] - loss: 0.1178
Epoch 5 [103/172] - loss: 0.1106
Epoch 5 [104/172] - loss: 0.1761
Epoch 5 [105/172] - loss: 0.1962
Epoch 5 [106/172] - loss: 0.1078
Epoch 5 [107/172] - loss: 0.1192
Epoch 5 [108/172] - loss: 0.1492
Epoch 5 [109/172] - loss: 0.1058
Epoch 5 [110/172] - loss: 0.1108, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1264
Epoch 5 [112/172] - loss: 0.1060

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.1811, log_difficulty=0.1664, weight=1.8321
neutral: count=7825.0, difficulty=0.1369, log_difficulty=0.1283, weight=1.6417
negative: count=8780.0, difficulty=0.1759, log_difficulty=0.1620, weight=1.8101

当前batch的pt分布：
positive: min=0.6871, max=0.9949, mean=0.9432
neutral: min=0.7282, max=0.9996, mean=0.9455
negative: min=0.9957, max=1.0000, mean=0.9987

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0521
焦点损失: 0.0024
边界损失: 0.1605
总损失: 0.1214
Epoch 5 [113/172] - loss: 0.1214
Epoch 5 [114/172] - loss: 0.1153
Epoch 5 [115/172] - loss: 0.1098
Epoch 5 [116/172] - loss: 0.1066
Epoch 5 [117/172] - loss: 0.1100
Epoch 5 [118/172] - loss: 0.1086
Epoch 5 [119/172] - loss: 0.1144
Epoch 5 [120/172] - loss: 0.1416, acc: 0.9688
Epoch 5 [121/172] - loss: 0.1091
Epoch 5 [122/172] - loss: 0.1137
Epoch 5 [123/172] - loss: 0.1084
Epoch 5 [124/172] - loss: 0.1106
Epoch 5 [125/172] - loss: 0.1085
Epoch 5 [126/172] - loss: 0.1063
Epoch 5 [127/172] - loss: 0.1115
Epoch 5 [128/172] - loss: 0.1084
Epoch 5 [129/172] - loss: 0.1574
Epoch 5 [130/172] - loss: 0.1062, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1328
Epoch 5 [132/172] - loss: 0.1321
Epoch 5 [133/172] - loss: 0.1667
Epoch 5 [134/172] - loss: 0.1171
Epoch 5 [135/172] - loss: 0.1124
Epoch 5 [136/172] - loss: 0.1204
Epoch 5 [137/172] - loss: 0.1319
Epoch 5 [138/172] - loss: 0.1466
Epoch 5 [139/172] - loss: 0.1938
Epoch 5 [140/172] - loss: 0.1259, acc: 0.9688
Epoch 5 [141/172] - loss: 0.1149
Epoch 5 [142/172] - loss: 0.1083
Epoch 5 [143/172] - loss: 0.1133
Epoch 5 [144/172] - loss: 0.1086
Epoch 5 [145/172] - loss: 0.1333
Epoch 5 [146/172] - loss: 0.1092
Epoch 5 [147/172] - loss: 0.1191
Epoch 5 [148/172] - loss: 0.1062
Epoch 5 [149/172] - loss: 0.1081
Epoch 5 [150/172] - loss: 0.1642, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1101
Epoch 5 [152/172] - loss: 0.1064
Epoch 5 [153/172] - loss: 0.1067
Epoch 5 [154/172] - loss: 0.1104
Epoch 5 [155/172] - loss: 0.1164
Epoch 5 [156/172] - loss: 0.1133
Epoch 5 [157/172] - loss: 0.1098
Epoch 5 [158/172] - loss: 0.1075
Epoch 5 [159/172] - loss: 0.1111
Epoch 5 [160/172] - loss: 0.1073, acc: 1.0000
Epoch 5 [161/172] - loss: 0.1052
Epoch 5 [162/172] - loss: 0.1150
Epoch 5 [163/172] - loss: 0.1544
Epoch 5 [164/172] - loss: 0.1072
Epoch 5 [165/172] - loss: 0.1653
Epoch 5 [166/172] - loss: 0.1203
Epoch 5 [167/172] - loss: 0.1129
Epoch 5 [168/172] - loss: 0.1059
Epoch 5 [169/172] - loss: 0.1161
Epoch 5 [170/172] - loss: 0.1156, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1095
Epoch 5 [172/172] - loss: 0.1173

类别准确率:
positive: 0.8672 (405/467)
neutral: 0.3253 (27/83)
negative: 0.5280 (132/250)

Epoch 5/10
Train Loss: 0.1175, Train Acc: 0.9960
Val Loss: 1.1052, Val Acc: 0.7050
Epoch 6 [1/172] - loss: 0.1270, acc: 1.0000
Epoch 6 [2/172] - loss: 0.1359
Epoch 6 [3/172] - loss: 0.1050
Epoch 6 [4/172] - loss: 0.1073
Epoch 6 [5/172] - loss: 0.1862
Epoch 6 [6/172] - loss: 0.1084
Epoch 6 [7/172] - loss: 0.1272
Epoch 6 [8/172] - loss: 0.1158
Epoch 6 [9/172] - loss: 0.1068
Epoch 6 [10/172] - loss: 0.1054, acc: 1.0000
Epoch 6 [11/172] - loss: 0.1054
Epoch 6 [12/172] - loss: 0.1047
Epoch 6 [13/172] - loss: 0.1125
Epoch 6 [14/172] - loss: 0.1048
Epoch 6 [15/172] - loss: 0.1055
Epoch 6 [16/172] - loss: 0.1428
Epoch 6 [17/172] - loss: 0.1124
Epoch 6 [18/172] - loss: 0.1231
Epoch 6 [19/172] - loss: 0.1093
Epoch 6 [20/172] - loss: 0.1138, acc: 1.0000
Epoch 6 [21/172] - loss: 0.1084
Epoch 6 [22/172] - loss: 0.1061
Epoch 6 [23/172] - loss: 0.1070
Epoch 6 [24/172] - loss: 0.1061
Epoch 6 [25/172] - loss: 0.1052
Epoch 6 [26/172] - loss: 0.1100
Epoch 6 [27/172] - loss: 0.1214
Epoch 6 [28/172] - loss: 0.1423
Epoch 6 [29/172] - loss: 0.1066
Epoch 6 [30/172] - loss: 0.1064, acc: 1.0000
Epoch 6 [31/172] - loss: 0.1064
Epoch 6 [32/172] - loss: 0.1045
Epoch 6 [33/172] - loss: 0.1055
Epoch 6 [34/172] - loss: 0.1055
Epoch 6 [35/172] - loss: 0.1053
Epoch 6 [36/172] - loss: 0.1056
Epoch 6 [37/172] - loss: 0.1067
Epoch 6 [38/172] - loss: 0.1155
Epoch 6 [39/172] - loss: 0.1072
Epoch 6 [40/172] - loss: 0.1541, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1649, log_difficulty=0.1526, weight=1.7632
neutral: count=8815.0, difficulty=0.1246, log_difficulty=0.1174, weight=1.5869
negative: count=9870.0, difficulty=0.1594, log_difficulty=0.1479, weight=1.7395

当前batch的pt分布：
positive: min=0.0363, max=0.9992, mean=0.9063
neutral: min=0.9822, max=0.9986, mean=0.9933
negative: min=0.9362, max=0.9986, mean=0.9855

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1129
焦点损失: 0.0964
边界损失: 0.1402
总损失: 0.1476
Epoch 6 [41/172] - loss: 0.1476
Epoch 6 [42/172] - loss: 0.1609
Epoch 6 [43/172] - loss: 0.1173
Epoch 6 [44/172] - loss: 0.1044
Epoch 6 [45/172] - loss: 0.1441
Epoch 6 [46/172] - loss: 0.1096
Epoch 6 [47/172] - loss: 0.1143
Epoch 6 [48/172] - loss: 0.1305
Epoch 6 [49/172] - loss: 0.1129
Epoch 6 [50/172] - loss: 0.1401, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1376
Epoch 6 [52/172] - loss: 0.1161
Epoch 6 [53/172] - loss: 0.1152
Epoch 6 [54/172] - loss: 0.1846
Epoch 6 [55/172] - loss: 0.1093
Epoch 6 [56/172] - loss: 0.1089
Epoch 6 [57/172] - loss: 0.1075
Epoch 6 [58/172] - loss: 0.1116
Epoch 6 [59/172] - loss: 0.1246
Epoch 6 [60/172] - loss: 0.1139, acc: 1.0000
Epoch 6 [61/172] - loss: 0.1156
Epoch 6 [62/172] - loss: 0.1172
Epoch 6 [63/172] - loss: 0.1133
Epoch 6 [64/172] - loss: 0.1774
Epoch 6 [65/172] - loss: 0.1420
Epoch 6 [66/172] - loss: 0.1078
Epoch 6 [67/172] - loss: 0.1090
Epoch 6 [68/172] - loss: 0.1317
Epoch 6 [69/172] - loss: 0.1494
Epoch 6 [70/172] - loss: 0.1059, acc: 1.0000
Epoch 6 [71/172] - loss: 0.1168
Epoch 6 [72/172] - loss: 0.1207
Epoch 6 [73/172] - loss: 0.1173
Epoch 6 [74/172] - loss: 0.1059
Epoch 6 [75/172] - loss: 0.1204
Epoch 6 [76/172] - loss: 0.1094
Epoch 6 [77/172] - loss: 0.1324
Epoch 6 [78/172] - loss: 0.1495
Epoch 6 [79/172] - loss: 0.1130
Epoch 6 [80/172] - loss: 0.1200, acc: 0.9688
Epoch 6 [81/172] - loss: 0.1143
Epoch 6 [82/172] - loss: 0.1180
Epoch 6 [83/172] - loss: 0.1101
Epoch 6 [84/172] - loss: 0.1061
Epoch 6 [85/172] - loss: 0.1391
Epoch 6 [86/172] - loss: 0.1390
Epoch 6 [87/172] - loss: 0.1167
Epoch 6 [88/172] - loss: 0.1437
Epoch 6 [89/172] - loss: 0.1113
Epoch 6 [90/172] - loss: 0.1113, acc: 1.0000
Epoch 6 [91/172] - loss: 0.1052
Epoch 6 [92/172] - loss: 0.1316
Epoch 6 [93/172] - loss: 0.1055
Epoch 6 [94/172] - loss: 0.1165
Epoch 6 [95/172] - loss: 0.1142
Epoch 6 [96/172] - loss: 0.1068
Epoch 6 [97/172] - loss: 0.1279
Epoch 6 [98/172] - loss: 0.1169
Epoch 6 [99/172] - loss: 0.1058
Epoch 6 [100/172] - loss: 0.1069, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1218
Epoch 6 [102/172] - loss: 0.1088
Epoch 6 [103/172] - loss: 0.1122
Epoch 6 [104/172] - loss: 0.1344
Epoch 6 [105/172] - loss: 0.1105
Epoch 6 [106/172] - loss: 0.1131
Epoch 6 [107/172] - loss: 0.1099
Epoch 6 [108/172] - loss: 0.1077
Epoch 6 [109/172] - loss: 0.1728
Epoch 6 [110/172] - loss: 0.1087, acc: 1.0000
Epoch 6 [111/172] - loss: 0.1187
Epoch 6 [112/172] - loss: 0.1072
Epoch 6 [113/172] - loss: 0.1211
Epoch 6 [114/172] - loss: 0.1058
Epoch 6 [115/172] - loss: 0.1153
Epoch 6 [116/172] - loss: 0.2381
Epoch 6 [117/172] - loss: 0.1175
Epoch 6 [118/172] - loss: 0.1062
Epoch 6 [119/172] - loss: 0.1637
Epoch 6 [120/172] - loss: 0.1111, acc: 1.0000
Epoch 6 [121/172] - loss: 0.1135
Epoch 6 [122/172] - loss: 0.1313
Epoch 6 [123/172] - loss: 0.1214
Epoch 6 [124/172] - loss: 0.1116
Epoch 6 [125/172] - loss: 0.1574
Epoch 6 [126/172] - loss: 0.1569
Epoch 6 [127/172] - loss: 0.1329
Epoch 6 [128/172] - loss: 0.1147
Epoch 6 [129/172] - loss: 0.1098
Epoch 6 [130/172] - loss: 0.1533, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1451
Epoch 6 [132/172] - loss: 0.1417
Epoch 6 [133/172] - loss: 0.1159
Epoch 6 [134/172] - loss: 0.1142
Epoch 6 [135/172] - loss: 0.1123
Epoch 6 [136/172] - loss: 0.1082
Epoch 6 [137/172] - loss: 0.1076
Epoch 6 [138/172] - loss: 0.1163
Epoch 6 [139/172] - loss: 0.1087
Epoch 6 [140/172] - loss: 0.1121, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1523, log_difficulty=0.1417, weight=1.7086
neutral: count=9796.0, difficulty=0.1148, log_difficulty=0.1087, weight=1.5433
negative: count=10972.0, difficulty=0.1479, log_difficulty=0.1379, weight=1.6897

当前batch的pt分布：
positive: min=0.9888, max=0.9996, mean=0.9961
neutral: min=0.9789, max=0.9984, mean=0.9939
negative: min=0.9470, max=0.9969, mean=0.9851

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0092
焦点损失: 0.0000
边界损失: 0.1395
总损失: 0.1046
Epoch 6 [141/172] - loss: 0.1046
Epoch 6 [142/172] - loss: 0.1187
Epoch 6 [143/172] - loss: 0.1095
Epoch 6 [144/172] - loss: 0.1158
Epoch 6 [145/172] - loss: 0.1081
Epoch 6 [146/172] - loss: 0.1086
Epoch 6 [147/172] - loss: 0.1104
Epoch 6 [148/172] - loss: 0.1156
Epoch 6 [149/172] - loss: 0.1173
Epoch 6 [150/172] - loss: 0.1045, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1071
Epoch 6 [152/172] - loss: 0.1130
Epoch 6 [153/172] - loss: 0.1087
Epoch 6 [154/172] - loss: 0.1053
Epoch 6 [155/172] - loss: 0.1287
Epoch 6 [156/172] - loss: 0.1420
Epoch 6 [157/172] - loss: 0.1056
Epoch 6 [158/172] - loss: 0.1105
Epoch 6 [159/172] - loss: 0.1610
Epoch 6 [160/172] - loss: 0.1707, acc: 0.9688
Epoch 6 [161/172] - loss: 0.1180
Epoch 6 [162/172] - loss: 0.1194
Epoch 6 [163/172] - loss: 0.1230
Epoch 6 [164/172] - loss: 0.1399
Epoch 6 [165/172] - loss: 0.2174
Epoch 6 [166/172] - loss: 0.1141
Epoch 6 [167/172] - loss: 0.1097
Epoch 6 [168/172] - loss: 0.1415
Epoch 6 [169/172] - loss: 0.1531
Epoch 6 [170/172] - loss: 0.1069, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1091
Epoch 6 [172/172] - loss: 0.1146

类别准确率:
positive: 0.9507 (444/467)
neutral: 0.2169 (18/83)
negative: 0.4200 (105/250)

Epoch 6/10
Train Loss: 0.1322, Train Acc: 0.9818
Val Loss: 1.1508, Val Acc: 0.7087
Epoch 7 [1/172] - loss: 0.1180, acc: 1.0000
Epoch 7 [2/172] - loss: 0.1052
Epoch 7 [3/172] - loss: 0.1071
Epoch 7 [4/172] - loss: 0.1145
Epoch 7 [5/172] - loss: 0.1109
Epoch 7 [6/172] - loss: 0.1107
Epoch 7 [7/172] - loss: 0.1118
Epoch 7 [8/172] - loss: 0.1445
Epoch 7 [9/172] - loss: 0.1237
Epoch 7 [10/172] - loss: 0.1059, acc: 1.0000
Epoch 7 [11/172] - loss: 0.1153
Epoch 7 [12/172] - loss: 0.1285
Epoch 7 [13/172] - loss: 0.1099
Epoch 7 [14/172] - loss: 0.1075
Epoch 7 [15/172] - loss: 0.1142
Epoch 7 [16/172] - loss: 0.1191
Epoch 7 [17/172] - loss: 0.1484
Epoch 7 [18/172] - loss: 0.1108
Epoch 7 [19/172] - loss: 0.1091
Epoch 7 [20/172] - loss: 0.1054, acc: 1.0000
Epoch 7 [21/172] - loss: 0.1182
Epoch 7 [22/172] - loss: 0.1098
Epoch 7 [23/172] - loss: 0.1072
Epoch 7 [24/172] - loss: 0.1106
Epoch 7 [25/172] - loss: 0.1224
Epoch 7 [26/172] - loss: 0.1398
Epoch 7 [27/172] - loss: 0.1192
Epoch 7 [28/172] - loss: 0.1422
Epoch 7 [29/172] - loss: 0.1206
Epoch 7 [30/172] - loss: 0.1581, acc: 0.9688
Epoch 7 [31/172] - loss: 0.1066
Epoch 7 [32/172] - loss: 0.1055
Epoch 7 [33/172] - loss: 0.1185
Epoch 7 [34/172] - loss: 0.1083
Epoch 7 [35/172] - loss: 0.1042
Epoch 7 [36/172] - loss: 0.1692
Epoch 7 [37/172] - loss: 0.1156
Epoch 7 [38/172] - loss: 0.1087
Epoch 7 [39/172] - loss: 0.1063
Epoch 7 [40/172] - loss: 0.1040, acc: 1.0000
Epoch 7 [41/172] - loss: 0.1124
Epoch 7 [42/172] - loss: 0.1063
Epoch 7 [43/172] - loss: 0.1054
Epoch 7 [44/172] - loss: 0.1145
Epoch 7 [45/172] - loss: 0.1080
Epoch 7 [46/172] - loss: 0.1877
Epoch 7 [47/172] - loss: 0.1460
Epoch 7 [48/172] - loss: 0.1063
Epoch 7 [49/172] - loss: 0.1077
Epoch 7 [50/172] - loss: 0.1052, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1612
Epoch 7 [52/172] - loss: 0.1080
Epoch 7 [53/172] - loss: 0.1063
Epoch 7 [54/172] - loss: 0.1092
Epoch 7 [55/172] - loss: 0.1103
Epoch 7 [56/172] - loss: 0.1059
Epoch 7 [57/172] - loss: 0.1334
Epoch 7 [58/172] - loss: 0.1145
Epoch 7 [59/172] - loss: 0.1061
Epoch 7 [60/172] - loss: 0.1202, acc: 0.9688
Epoch 7 [61/172] - loss: 0.1102
Epoch 7 [62/172] - loss: 0.1141
Epoch 7 [63/172] - loss: 0.1791
Epoch 7 [64/172] - loss: 0.1309
Epoch 7 [65/172] - loss: 0.1223
Epoch 7 [66/172] - loss: 0.1147
Epoch 7 [67/172] - loss: 0.1134
Epoch 7 [68/172] - loss: 0.1078

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1413, log_difficulty=0.1322, weight=1.6608
neutral: count=10756.0, difficulty=0.1068, log_difficulty=0.1014, weight=1.5072
negative: count=12072.0, difficulty=0.1378, log_difficulty=0.1291, weight=1.6453

当前batch的pt分布：
positive: min=0.9876, max=0.9995, mean=0.9959
neutral: min=0.9803, max=0.9995, mean=0.9957
negative: min=0.8700, max=0.9996, mean=0.9672

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0173
焦点损失: 0.0001
边界损失: 0.1431
总损失: 0.1074
Epoch 7 [69/172] - loss: 0.1074
Epoch 7 [70/172] - loss: 0.1066, acc: 1.0000
Epoch 7 [71/172] - loss: 0.1079
Epoch 7 [72/172] - loss: 0.1260
Epoch 7 [73/172] - loss: 0.1101
Epoch 7 [74/172] - loss: 0.1046
Epoch 7 [75/172] - loss: 0.1048
Epoch 7 [76/172] - loss: 0.1145
Epoch 7 [77/172] - loss: 0.1074
Epoch 7 [78/172] - loss: 0.1051
Epoch 7 [79/172] - loss: 0.1257
Epoch 7 [80/172] - loss: 0.1388, acc: 0.9688
Epoch 7 [81/172] - loss: 0.1051
Epoch 7 [82/172] - loss: 0.1049
Epoch 7 [83/172] - loss: 0.1187
Epoch 7 [84/172] - loss: 0.1629
Epoch 7 [85/172] - loss: 0.1081
Epoch 7 [86/172] - loss: 0.1065
Epoch 7 [87/172] - loss: 0.1111
Epoch 7 [88/172] - loss: 0.1049
Epoch 7 [89/172] - loss: 0.1064
Epoch 7 [90/172] - loss: 0.1066, acc: 1.0000
Epoch 7 [91/172] - loss: 0.1132
Epoch 7 [92/172] - loss: 0.1243
Epoch 7 [93/172] - loss: 0.1419
Epoch 7 [94/172] - loss: 0.1072
Epoch 7 [95/172] - loss: 0.1049
Epoch 7 [96/172] - loss: 0.1082
Epoch 7 [97/172] - loss: 0.1162
Epoch 7 [98/172] - loss: 0.1291
Epoch 7 [99/172] - loss: 0.1061
Epoch 7 [100/172] - loss: 0.1037, acc: 1.0000
Epoch 7 [101/172] - loss: 0.1117
Epoch 7 [102/172] - loss: 0.1063
Epoch 7 [103/172] - loss: 0.1107
Epoch 7 [104/172] - loss: 0.1094
Epoch 7 [105/172] - loss: 0.1118
Epoch 7 [106/172] - loss: 0.1556
Epoch 7 [107/172] - loss: 0.1055
Epoch 7 [108/172] - loss: 0.1049
Epoch 7 [109/172] - loss: 0.1126
Epoch 7 [110/172] - loss: 0.1355, acc: 0.9688
Epoch 7 [111/172] - loss: 0.1082
Epoch 7 [112/172] - loss: 0.1125
Epoch 7 [113/172] - loss: 0.1058
Epoch 7 [114/172] - loss: 0.1044
Epoch 7 [115/172] - loss: 0.1042
Epoch 7 [116/172] - loss: 0.1180
Epoch 7 [117/172] - loss: 0.1192
Epoch 7 [118/172] - loss: 0.1142
Epoch 7 [119/172] - loss: 0.1075
Epoch 7 [120/172] - loss: 0.1055, acc: 1.0000
Epoch 7 [121/172] - loss: 0.1089
Epoch 7 [122/172] - loss: 0.1044
Epoch 7 [123/172] - loss: 0.1110
Epoch 7 [124/172] - loss: 0.1137
Epoch 7 [125/172] - loss: 0.1050
Epoch 7 [126/172] - loss: 0.1040
Epoch 7 [127/172] - loss: 0.1086
Epoch 7 [128/172] - loss: 0.1053
Epoch 7 [129/172] - loss: 0.1065
Epoch 7 [130/172] - loss: 0.1077, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1317
Epoch 7 [132/172] - loss: 0.1529
Epoch 7 [133/172] - loss: 0.1042
Epoch 7 [134/172] - loss: 0.1094
Epoch 7 [135/172] - loss: 0.1096
Epoch 7 [136/172] - loss: 0.1114
Epoch 7 [137/172] - loss: 0.1160
Epoch 7 [138/172] - loss: 0.1040
Epoch 7 [139/172] - loss: 0.1304
Epoch 7 [140/172] - loss: 0.1095, acc: 1.0000
Epoch 7 [141/172] - loss: 0.1209
Epoch 7 [142/172] - loss: 0.1075
Epoch 7 [143/172] - loss: 0.1501
Epoch 7 [144/172] - loss: 0.1092
Epoch 7 [145/172] - loss: 0.1148
Epoch 7 [146/172] - loss: 0.1314
Epoch 7 [147/172] - loss: 0.1179
Epoch 7 [148/172] - loss: 0.1096
Epoch 7 [149/172] - loss: 0.1059
Epoch 7 [150/172] - loss: 0.1070, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1308
Epoch 7 [152/172] - loss: 0.1038
Epoch 7 [153/172] - loss: 0.1043
Epoch 7 [154/172] - loss: 0.1128
Epoch 7 [155/172] - loss: 0.1045
Epoch 7 [156/172] - loss: 0.1323
Epoch 7 [157/172] - loss: 0.1071
Epoch 7 [158/172] - loss: 0.1129
Epoch 7 [159/172] - loss: 0.1046
Epoch 7 [160/172] - loss: 0.1077, acc: 1.0000
Epoch 7 [161/172] - loss: 0.1155
Epoch 7 [162/172] - loss: 0.1170
Epoch 7 [163/172] - loss: 0.1092
Epoch 7 [164/172] - loss: 0.1165
Epoch 7 [165/172] - loss: 0.1216
Epoch 7 [166/172] - loss: 0.1067
Epoch 7 [167/172] - loss: 0.1095
Epoch 7 [168/172] - loss: 0.1050

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1316, log_difficulty=0.1236, weight=1.6182
neutral: count=11731.0, difficulty=0.0998, log_difficulty=0.0952, weight=1.4758
negative: count=13173.0, difficulty=0.1281, log_difficulty=0.1205, weight=1.6027

当前batch的pt分布：
positive: min=0.9800, max=0.9987, mean=0.9939
neutral: min=0.9831, max=0.9991, mean=0.9960
negative: min=0.9314, max=0.9990, mean=0.9846

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0091
焦点损失: 0.0000
边界损失: 0.1394
总损失: 0.1045
Epoch 7 [169/172] - loss: 0.1045
Epoch 7 [170/172] - loss: 0.1348, acc: 0.9375
Epoch 7 [171/172] - loss: 0.1060
Epoch 7 [172/172] - loss: 0.1035

类别准确率:
positive: 0.8908 (416/467)
neutral: 0.2892 (24/83)
negative: 0.5840 (146/250)

Epoch 7/10
Train Loss: 0.1114, Train Acc: 0.9899
Val Loss: 1.0651, Val Acc: 0.7325
Epoch 8 [1/172] - loss: 0.1108, acc: 1.0000
Epoch 8 [2/172] - loss: 0.1136
Epoch 8 [3/172] - loss: 0.1055
Epoch 8 [4/172] - loss: 0.1037
Epoch 8 [5/172] - loss: 0.1044
Epoch 8 [6/172] - loss: 0.1307
Epoch 8 [7/172] - loss: 0.1098
Epoch 8 [8/172] - loss: 0.1041
Epoch 8 [9/172] - loss: 0.1133
Epoch 8 [10/172] - loss: 0.1291, acc: 0.9688
Epoch 8 [11/172] - loss: 0.1080
Epoch 8 [12/172] - loss: 0.1109
Epoch 8 [13/172] - loss: 0.1041
Epoch 8 [14/172] - loss: 0.1050
Epoch 8 [15/172] - loss: 0.1130
Epoch 8 [16/172] - loss: 0.1078
Epoch 8 [17/172] - loss: 0.1056
Epoch 8 [18/172] - loss: 0.1039
Epoch 8 [19/172] - loss: 0.1087
Epoch 8 [20/172] - loss: 0.1044, acc: 1.0000
Epoch 8 [21/172] - loss: 0.1064
Epoch 8 [22/172] - loss: 0.1219
Epoch 8 [23/172] - loss: 0.1104
Epoch 8 [24/172] - loss: 0.1100
Epoch 8 [25/172] - loss: 0.1104
Epoch 8 [26/172] - loss: 0.1114
Epoch 8 [27/172] - loss: 0.1215
Epoch 8 [28/172] - loss: 0.1200
Epoch 8 [29/172] - loss: 0.1053
Epoch 8 [30/172] - loss: 0.1047, acc: 1.0000
Epoch 8 [31/172] - loss: 0.1048
Epoch 8 [32/172] - loss: 0.1042
Epoch 8 [33/172] - loss: 0.1049
Epoch 8 [34/172] - loss: 0.1120
Epoch 8 [35/172] - loss: 0.1078
Epoch 8 [36/172] - loss: 0.1053
Epoch 8 [37/172] - loss: 0.1113
Epoch 8 [38/172] - loss: 0.1181
Epoch 8 [39/172] - loss: 0.1082
Epoch 8 [40/172] - loss: 0.1057, acc: 1.0000
Epoch 8 [41/172] - loss: 0.1053
Epoch 8 [42/172] - loss: 0.1203
Epoch 8 [43/172] - loss: 0.1048
Epoch 8 [44/172] - loss: 0.1052
Epoch 8 [45/172] - loss: 0.1057
Epoch 8 [46/172] - loss: 0.1054
Epoch 8 [47/172] - loss: 0.1044
Epoch 8 [48/172] - loss: 0.1164
Epoch 8 [49/172] - loss: 0.1036
Epoch 8 [50/172] - loss: 0.1202, acc: 0.9688
Epoch 8 [51/172] - loss: 0.1052
Epoch 8 [52/172] - loss: 0.1040
Epoch 8 [53/172] - loss: 0.1075
Epoch 8 [54/172] - loss: 0.1135
Epoch 8 [55/172] - loss: 0.1052
Epoch 8 [56/172] - loss: 0.1056
Epoch 8 [57/172] - loss: 0.1040
Epoch 8 [58/172] - loss: 0.1064
Epoch 8 [59/172] - loss: 0.1051
Epoch 8 [60/172] - loss: 0.1054, acc: 1.0000
Epoch 8 [61/172] - loss: 0.1298
Epoch 8 [62/172] - loss: 0.1038
Epoch 8 [63/172] - loss: 0.1037
Epoch 8 [64/172] - loss: 0.1043
Epoch 8 [65/172] - loss: 0.1043
Epoch 8 [66/172] - loss: 0.1191
Epoch 8 [67/172] - loss: 0.1063
Epoch 8 [68/172] - loss: 0.1035
Epoch 8 [69/172] - loss: 0.1038
Epoch 8 [70/172] - loss: 0.1043, acc: 1.0000
Epoch 8 [71/172] - loss: 0.1485
Epoch 8 [72/172] - loss: 0.1043
Epoch 8 [73/172] - loss: 0.1163
Epoch 8 [74/172] - loss: 0.1402
Epoch 8 [75/172] - loss: 0.1042
Epoch 8 [76/172] - loss: 0.1349
Epoch 8 [77/172] - loss: 0.1037
Epoch 8 [78/172] - loss: 0.1239
Epoch 8 [79/172] - loss: 0.1096
Epoch 8 [80/172] - loss: 0.1094, acc: 1.0000
Epoch 8 [81/172] - loss: 0.1074
Epoch 8 [82/172] - loss: 0.1041
Epoch 8 [83/172] - loss: 0.1038
Epoch 8 [84/172] - loss: 0.1082
Epoch 8 [85/172] - loss: 0.1049
Epoch 8 [86/172] - loss: 0.1046
Epoch 8 [87/172] - loss: 0.1037
Epoch 8 [88/172] - loss: 0.1279
Epoch 8 [89/172] - loss: 0.1045
Epoch 8 [90/172] - loss: 0.1068, acc: 1.0000
Epoch 8 [91/172] - loss: 0.1330
Epoch 8 [92/172] - loss: 0.1140
Epoch 8 [93/172] - loss: 0.1035
Epoch 8 [94/172] - loss: 0.1107
Epoch 8 [95/172] - loss: 0.1072
Epoch 8 [96/172] - loss: 0.1047

=== 第 1301 次迭代调试信息 ===
当前类别统计：
positive: count=14487.0, difficulty=0.1233, log_difficulty=0.1163, weight=1.5813
neutral: count=12738.0, difficulty=0.0936, log_difficulty=0.0894, weight=1.4472
negative: count=14288.0, difficulty=0.1196, log_difficulty=0.1129, weight=1.5647

当前batch的pt分布：
positive: min=0.9877, max=0.9995, mean=0.9957
neutral: min=0.0341, max=0.9978, mean=0.8939
negative: min=0.9976, max=0.9999, mean=0.9989

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9333
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1291
焦点损失: 0.1010
边界损失: 0.1468
总损失: 0.1466
Epoch 8 [97/172] - loss: 0.1466
Epoch 8 [98/172] - loss: 0.1067
Epoch 8 [99/172] - loss: 0.1052
Epoch 8 [100/172] - loss: 0.1094, acc: 1.0000
Epoch 8 [101/172] - loss: 0.1037
Epoch 8 [102/172] - loss: 0.1250
Epoch 8 [103/172] - loss: 0.1206
Epoch 8 [104/172] - loss: 0.1104
Epoch 8 [105/172] - loss: 0.1052
Epoch 8 [106/172] - loss: 0.1056
Epoch 8 [107/172] - loss: 0.1068
Epoch 8 [108/172] - loss: 0.1049
Epoch 8 [109/172] - loss: 0.1435
Epoch 8 [110/172] - loss: 0.1074, acc: 1.0000
Epoch 8 [111/172] - loss: 0.1648
Epoch 8 [112/172] - loss: 0.1182
Epoch 8 [113/172] - loss: 0.1042
Epoch 8 [114/172] - loss: 0.1067
Epoch 8 [115/172] - loss: 0.1042
Epoch 8 [116/172] - loss: 0.1035
Epoch 8 [117/172] - loss: 0.1048
Epoch 8 [118/172] - loss: 0.1042
Epoch 8 [119/172] - loss: 0.1039
Epoch 8 [120/172] - loss: 0.1056, acc: 1.0000
Epoch 8 [121/172] - loss: 0.1391
Epoch 8 [122/172] - loss: 0.1057
Epoch 8 [123/172] - loss: 0.1046
Epoch 8 [124/172] - loss: 0.1058
Epoch 8 [125/172] - loss: 0.1069
Epoch 8 [126/172] - loss: 0.1105
Epoch 8 [127/172] - loss: 0.1165
Epoch 8 [128/172] - loss: 0.1243
Epoch 8 [129/172] - loss: 0.1068
Epoch 8 [130/172] - loss: 0.1040, acc: 1.0000
Epoch 8 [131/172] - loss: 0.1074
Epoch 8 [132/172] - loss: 0.1037
Epoch 8 [133/172] - loss: 0.1075
Epoch 8 [134/172] - loss: 0.1048
Epoch 8 [135/172] - loss: 0.1036
Epoch 8 [136/172] - loss: 0.1081
Epoch 8 [137/172] - loss: 0.1050
Epoch 8 [138/172] - loss: 0.1199
Epoch 8 [139/172] - loss: 0.1064
Epoch 8 [140/172] - loss: 0.1036, acc: 1.0000
Epoch 8 [141/172] - loss: 0.1047
Epoch 8 [142/172] - loss: 0.1055
Epoch 8 [143/172] - loss: 0.1080
Epoch 8 [144/172] - loss: 0.1093
Epoch 8 [145/172] - loss: 0.1047
Epoch 8 [146/172] - loss: 0.1030
Epoch 8 [147/172] - loss: 0.1046
Epoch 8 [148/172] - loss: 0.1147
Epoch 8 [149/172] - loss: 0.1095
Epoch 8 [150/172] - loss: 0.1051, acc: 1.0000
Epoch 8 [151/172] - loss: 0.1164
Epoch 8 [152/172] - loss: 0.1193
Epoch 8 [153/172] - loss: 0.1080
Epoch 8 [154/172] - loss: 0.1168
Epoch 8 [155/172] - loss: 0.1079
Epoch 8 [156/172] - loss: 0.1052
Epoch 8 [157/172] - loss: 0.1050
Epoch 8 [158/172] - loss: 0.1072
Epoch 8 [159/172] - loss: 0.1123
Epoch 8 [160/172] - loss: 0.1061, acc: 1.0000
Epoch 8 [161/172] - loss: 0.1061
Epoch 8 [162/172] - loss: 0.1082
Epoch 8 [163/172] - loss: 0.1061
Epoch 8 [164/172] - loss: 0.1056
Epoch 8 [165/172] - loss: 0.1054
Epoch 8 [166/172] - loss: 0.1146
Epoch 8 [167/172] - loss: 0.1037
Epoch 8 [168/172] - loss: 0.1048
Epoch 8 [169/172] - loss: 0.1057
Epoch 8 [170/172] - loss: 0.1066, acc: 1.0000
Epoch 8 [171/172] - loss: 0.1155
Epoch 8 [172/172] - loss: 0.1049

类别准确率:
positive: 0.9036 (422/467)
neutral: 0.2651 (22/83)
negative: 0.5520 (138/250)

Epoch 8/10
Train Loss: 0.1074, Train Acc: 0.9980
Val Loss: 1.1355, Val Acc: 0.7275
Epoch 9 [1/172] - loss: 0.1163, acc: 1.0000
Epoch 9 [2/172] - loss: 0.1064
Epoch 9 [3/172] - loss: 0.1055
Epoch 9 [4/172] - loss: 0.1050
Epoch 9 [5/172] - loss: 0.1140
Epoch 9 [6/172] - loss: 0.1075
Epoch 9 [7/172] - loss: 0.1062
Epoch 9 [8/172] - loss: 0.1204
Epoch 9 [9/172] - loss: 0.1034
Epoch 9 [10/172] - loss: 0.1047, acc: 1.0000
Epoch 9 [11/172] - loss: 0.1127
Epoch 9 [12/172] - loss: 0.1128
Epoch 9 [13/172] - loss: 0.1081
Epoch 9 [14/172] - loss: 0.1063
Epoch 9 [15/172] - loss: 0.1079
Epoch 9 [16/172] - loss: 0.1121
Epoch 9 [17/172] - loss: 0.1056
Epoch 9 [18/172] - loss: 0.1035
Epoch 9 [19/172] - loss: 0.1140
Epoch 9 [20/172] - loss: 0.1059, acc: 1.0000
Epoch 9 [21/172] - loss: 0.1034
Epoch 9 [22/172] - loss: 0.1076
Epoch 9 [23/172] - loss: 0.1035
Epoch 9 [24/172] - loss: 0.1033

=== 第 1401 次迭代调试信息 ===
当前类别统计：
positive: count=15648.0, difficulty=0.1156, log_difficulty=0.1094, weight=1.5471
neutral: count=13691.0, difficulty=0.0880, log_difficulty=0.0844, weight=1.4218
negative: count=15357.0, difficulty=0.1123, log_difficulty=0.1065, weight=1.5324

当前batch的pt分布：
positive: min=0.9873, max=0.9994, mean=0.9952
neutral: min=0.9853, max=0.9990, mean=0.9940
negative: min=0.9812, max=0.9981, mean=0.9946

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0054
焦点损失: 0.0000
边界损失: 0.1378
总损失: 0.1033
Epoch 9 [25/172] - loss: 0.1033
Epoch 9 [26/172] - loss: 0.1054
Epoch 9 [27/172] - loss: 0.1056
Epoch 9 [28/172] - loss: 0.1211
Epoch 9 [29/172] - loss: 0.1048
Epoch 9 [30/172] - loss: 0.1059, acc: 1.0000
Epoch 9 [31/172] - loss: 0.1097
Epoch 9 [32/172] - loss: 0.1054
Epoch 9 [33/172] - loss: 0.1479
Epoch 9 [34/172] - loss: 0.1208
Epoch 9 [35/172] - loss: 0.1034
Epoch 9 [36/172] - loss: 0.1047
Epoch 9 [37/172] - loss: 0.1074
Epoch 9 [38/172] - loss: 0.1267
Epoch 9 [39/172] - loss: 0.1048
Epoch 9 [40/172] - loss: 0.1037, acc: 1.0000
Epoch 9 [41/172] - loss: 0.1039
Epoch 9 [42/172] - loss: 0.1040
Epoch 9 [43/172] - loss: 0.1040
Epoch 9 [44/172] - loss: 0.1059
Epoch 9 [45/172] - loss: 0.1118
Epoch 9 [46/172] - loss: 0.1074
Epoch 9 [47/172] - loss: 0.1035
Epoch 9 [48/172] - loss: 0.1063
Epoch 9 [49/172] - loss: 0.1200
Epoch 9 [50/172] - loss: 0.1032, acc: 1.0000
Epoch 9 [51/172] - loss: 0.1041
Epoch 9 [52/172] - loss: 0.1063
Epoch 9 [53/172] - loss: 0.1041
Epoch 9 [54/172] - loss: 0.1171
Epoch 9 [55/172] - loss: 0.1082
Epoch 9 [56/172] - loss: 0.1036
Epoch 9 [57/172] - loss: 0.1057
Epoch 9 [58/172] - loss: 0.1039
Epoch 9 [59/172] - loss: 0.1215
Epoch 9 [60/172] - loss: 0.1051, acc: 1.0000
Epoch 9 [61/172] - loss: 0.1136
Epoch 9 [62/172] - loss: 0.1037
Epoch 9 [63/172] - loss: 0.1307
Epoch 9 [64/172] - loss: 0.1058
Epoch 9 [65/172] - loss: 0.1037
Epoch 9 [66/172] - loss: 0.1085
Epoch 9 [67/172] - loss: 0.1233
Epoch 9 [68/172] - loss: 0.1040
Epoch 9 [69/172] - loss: 0.1043
Epoch 9 [70/172] - loss: 0.1054, acc: 1.0000
Epoch 9 [71/172] - loss: 0.1056
Epoch 9 [72/172] - loss: 0.1258
Epoch 9 [73/172] - loss: 0.1041
Epoch 9 [74/172] - loss: 0.1042
Epoch 9 [75/172] - loss: 0.1041
Epoch 9 [76/172] - loss: 0.1049
Epoch 9 [77/172] - loss: 0.1042
Epoch 9 [78/172] - loss: 0.1145
Epoch 9 [79/172] - loss: 0.1377
Epoch 9 [80/172] - loss: 0.1179, acc: 0.9688
Epoch 9 [81/172] - loss: 0.1064
Epoch 9 [82/172] - loss: 0.1657
Epoch 9 [83/172] - loss: 0.1039
Epoch 9 [84/172] - loss: 0.1055
Epoch 9 [85/172] - loss: 0.1079
Epoch 9 [86/172] - loss: 0.1075
Epoch 9 [87/172] - loss: 0.1178
Epoch 9 [88/172] - loss: 0.1040
Epoch 9 [89/172] - loss: 0.1163
Epoch 9 [90/172] - loss: 0.1040, acc: 1.0000
Epoch 9 [91/172] - loss: 0.1209
Epoch 9 [92/172] - loss: 0.1056
Epoch 9 [93/172] - loss: 0.1051
Epoch 9 [94/172] - loss: 0.1034
Epoch 9 [95/172] - loss: 0.1049
Epoch 9 [96/172] - loss: 0.1072
Epoch 9 [97/172] - loss: 0.1037
Epoch 9 [98/172] - loss: 0.1190
Epoch 9 [99/172] - loss: 0.1054
Epoch 9 [100/172] - loss: 0.1041, acc: 1.0000
Epoch 9 [101/172] - loss: 0.1034
Epoch 9 [102/172] - loss: 0.1047
Epoch 9 [103/172] - loss: 0.1098
Epoch 9 [104/172] - loss: 0.1158
Epoch 9 [105/172] - loss: 0.1058
Epoch 9 [106/172] - loss: 0.1082
Epoch 9 [107/172] - loss: 0.1136
Epoch 9 [108/172] - loss: 0.1078
Epoch 9 [109/172] - loss: 0.1383
Epoch 9 [110/172] - loss: 0.1043, acc: 1.0000
Epoch 9 [111/172] - loss: 0.1057
Epoch 9 [112/172] - loss: 0.1039
Epoch 9 [113/172] - loss: 0.1045
Epoch 9 [114/172] - loss: 0.1033
Epoch 9 [115/172] - loss: 0.1039
Epoch 9 [116/172] - loss: 0.1052
Epoch 9 [117/172] - loss: 0.1063
Epoch 9 [118/172] - loss: 0.1553
Epoch 9 [119/172] - loss: 0.1056
Epoch 9 [120/172] - loss: 0.1110, acc: 1.0000
Epoch 9 [121/172] - loss: 0.1039
Epoch 9 [122/172] - loss: 0.1398
Epoch 9 [123/172] - loss: 0.1037
Epoch 9 [124/172] - loss: 0.1059

=== 第 1501 次迭代调试信息 ===
当前类别统计：
positive: count=16764.0, difficulty=0.1091, log_difficulty=0.1036, weight=1.5178
neutral: count=14673.0, difficulty=0.0832, log_difficulty=0.0799, weight=1.3994
negative: count=16459.0, difficulty=0.1061, log_difficulty=0.1008, weight=1.5041

当前batch的pt分布：
positive: min=0.9181, max=0.9969, mean=0.9733
neutral: min=0.9855, max=0.9987, mean=0.9954
negative: min=0.9990, max=0.9999, mean=0.9996

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0152
焦点损失: 0.0001
边界损失: 0.1423
总损失: 0.1067
Epoch 9 [125/172] - loss: 0.1067
Epoch 9 [126/172] - loss: 0.1056
Epoch 9 [127/172] - loss: 0.1041
Epoch 9 [128/172] - loss: 0.1058
Epoch 9 [129/172] - loss: 0.1094
Epoch 9 [130/172] - loss: 0.1215, acc: 0.9688
Epoch 9 [131/172] - loss: 0.1048
Epoch 9 [132/172] - loss: 0.1240
Epoch 9 [133/172] - loss: 0.1082
Epoch 9 [134/172] - loss: 0.1066
Epoch 9 [135/172] - loss: 0.1056
Epoch 9 [136/172] - loss: 0.1139
Epoch 9 [137/172] - loss: 0.1071
Epoch 9 [138/172] - loss: 0.1083
Epoch 9 [139/172] - loss: 0.1334
Epoch 9 [140/172] - loss: 0.1040, acc: 1.0000
Epoch 9 [141/172] - loss: 0.1062
Epoch 9 [142/172] - loss: 0.1042
Epoch 9 [143/172] - loss: 0.1294
Epoch 9 [144/172] - loss: 0.1042
Epoch 9 [145/172] - loss: 0.1193
Epoch 9 [146/172] - loss: 0.1034
Epoch 9 [147/172] - loss: 0.1140
Epoch 9 [148/172] - loss: 0.1040
Epoch 9 [149/172] - loss: 0.1048
Epoch 9 [150/172] - loss: 0.1043, acc: 1.0000
Epoch 9 [151/172] - loss: 0.1050
Epoch 9 [152/172] - loss: 0.1063
Epoch 9 [153/172] - loss: 0.1110
Epoch 9 [154/172] - loss: 0.1050
Epoch 9 [155/172] - loss: 0.1044
Epoch 9 [156/172] - loss: 0.1064
Epoch 9 [157/172] - loss: 0.1039
Epoch 9 [158/172] - loss: 0.1061
Epoch 9 [159/172] - loss: 0.1039
Epoch 9 [160/172] - loss: 0.1037, acc: 1.0000
Epoch 9 [161/172] - loss: 0.1039
Epoch 9 [162/172] - loss: 0.1177
Epoch 9 [163/172] - loss: 0.1075
Epoch 9 [164/172] - loss: 0.1051
Epoch 9 [165/172] - loss: 0.1037
Epoch 9 [166/172] - loss: 0.1040
Epoch 9 [167/172] - loss: 0.1087
Epoch 9 [168/172] - loss: 0.1033
Epoch 9 [169/172] - loss: 0.1067
Epoch 9 [170/172] - loss: 0.1066, acc: 1.0000
Epoch 9 [171/172] - loss: 0.1170
Epoch 9 [172/172] - loss: 0.1050

类别准确率:
positive: 0.8544 (399/467)
neutral: 0.3253 (27/83)
negative: 0.6040 (151/250)

Epoch 9/10
Train Loss: 0.1067, Train Acc: 0.9960
Val Loss: 1.0535, Val Acc: 0.7212
Epoch 10 [1/172] - loss: 0.1055, acc: 1.0000
Epoch 10 [2/172] - loss: 0.1269
Epoch 10 [3/172] - loss: 0.1038
Epoch 10 [4/172] - loss: 0.1188
Epoch 10 [5/172] - loss: 0.1055
Epoch 10 [6/172] - loss: 0.1123
Epoch 10 [7/172] - loss: 0.1054
Epoch 10 [8/172] - loss: 0.1052
Epoch 10 [9/172] - loss: 0.1087
Epoch 10 [10/172] - loss: 0.1207, acc: 0.9688
Epoch 10 [11/172] - loss: 0.1039
Epoch 10 [12/172] - loss: 0.1055
Epoch 10 [13/172] - loss: 0.1066
Epoch 10 [14/172] - loss: 0.1398
Epoch 10 [15/172] - loss: 0.1036
Epoch 10 [16/172] - loss: 0.1113
Epoch 10 [17/172] - loss: 0.1049
Epoch 10 [18/172] - loss: 0.1057
Epoch 10 [19/172] - loss: 0.1058
Epoch 10 [20/172] - loss: 0.1039, acc: 1.0000
Epoch 10 [21/172] - loss: 0.1059
Epoch 10 [22/172] - loss: 0.1038
Epoch 10 [23/172] - loss: 0.1056
Epoch 10 [24/172] - loss: 0.1319
Epoch 10 [25/172] - loss: 0.1037
Epoch 10 [26/172] - loss: 0.1036
Epoch 10 [27/172] - loss: 0.1035
Epoch 10 [28/172] - loss: 0.1081
Epoch 10 [29/172] - loss: 0.1039
Epoch 10 [30/172] - loss: 0.1042, acc: 1.0000
Epoch 10 [31/172] - loss: 0.1123
Epoch 10 [32/172] - loss: 0.1042
Epoch 10 [33/172] - loss: 0.1036
Epoch 10 [34/172] - loss: 0.1047
Epoch 10 [35/172] - loss: 0.1113
Epoch 10 [36/172] - loss: 0.1779
Epoch 10 [37/172] - loss: 0.1147
Epoch 10 [38/172] - loss: 0.1083
Epoch 10 [39/172] - loss: 0.1071
Epoch 10 [40/172] - loss: 0.1034, acc: 1.0000
Epoch 10 [41/172] - loss: 0.1045
Epoch 10 [42/172] - loss: 0.1048
Epoch 10 [43/172] - loss: 0.1044
Epoch 10 [44/172] - loss: 0.1299
Epoch 10 [45/172] - loss: 0.1036
Epoch 10 [46/172] - loss: 0.1043
Epoch 10 [47/172] - loss: 0.1035
Epoch 10 [48/172] - loss: 0.1131
Epoch 10 [49/172] - loss: 0.1037
Epoch 10 [50/172] - loss: 0.1036, acc: 1.0000
Epoch 10 [51/172] - loss: 0.1058
Epoch 10 [52/172] - loss: 0.1093

=== 第 1601 次迭代调试信息 ===
当前类别统计：
positive: count=17907.0, difficulty=0.1032, log_difficulty=0.0982, weight=1.4911
neutral: count=15634.0, difficulty=0.0788, log_difficulty=0.0758, weight=1.3792
negative: count=17538.0, difficulty=0.1008, log_difficulty=0.0961, weight=1.4803

当前batch的pt分布：
positive: min=0.9916, max=0.9997, mean=0.9963
neutral: min=0.8432, max=0.9988, mean=0.9815
negative: min=0.9911, max=0.9991, mean=0.9945

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0098
焦点损失: 0.0002
边界损失: 0.1398
总损失: 0.1049
Epoch 10 [53/172] - loss: 0.1049
Epoch 10 [54/172] - loss: 0.1191
Epoch 10 [55/172] - loss: 0.1043
Epoch 10 [56/172] - loss: 0.1034
Epoch 10 [57/172] - loss: 0.1039
Epoch 10 [58/172] - loss: 0.1112
Epoch 10 [59/172] - loss: 0.1036
Epoch 10 [60/172] - loss: 0.1039, acc: 1.0000
Epoch 10 [61/172] - loss: 0.1082
Epoch 10 [62/172] - loss: 0.1074
Epoch 10 [63/172] - loss: 0.1127
Epoch 10 [64/172] - loss: 0.1046
Epoch 10 [65/172] - loss: 0.1357
Epoch 10 [66/172] - loss: 0.1129
Epoch 10 [67/172] - loss: 0.1048
Epoch 10 [68/172] - loss: 0.1062
Epoch 10 [69/172] - loss: 0.1039
Epoch 10 [70/172] - loss: 0.1056, acc: 1.0000
Epoch 10 [71/172] - loss: 0.1065
Epoch 10 [72/172] - loss: 0.1039
Epoch 10 [73/172] - loss: 0.1041
Epoch 10 [74/172] - loss: 0.1044
Epoch 10 [75/172] - loss: 0.1100
Epoch 10 [76/172] - loss: 0.1037
Epoch 10 [77/172] - loss: 0.1048
Epoch 10 [78/172] - loss: 0.1084
Epoch 10 [79/172] - loss: 0.1056
Epoch 10 [80/172] - loss: 0.1043, acc: 1.0000
Epoch 10 [81/172] - loss: 0.1040
Epoch 10 [82/172] - loss: 0.1046
Epoch 10 [83/172] - loss: 0.1177
Epoch 10 [84/172] - loss: 0.1057
Epoch 10 [85/172] - loss: 0.1036
Epoch 10 [86/172] - loss: 0.1090
Epoch 10 [87/172] - loss: 0.1037
Epoch 10 [88/172] - loss: 0.1091
Epoch 10 [89/172] - loss: 0.1041
Epoch 10 [90/172] - loss: 0.1289, acc: 0.9375
Epoch 10 [91/172] - loss: 0.1049
Epoch 10 [92/172] - loss: 0.1042
Epoch 10 [93/172] - loss: 0.1037
Epoch 10 [94/172] - loss: 0.1044
Epoch 10 [95/172] - loss: 0.1044
Epoch 10 [96/172] - loss: 0.1078
Epoch 10 [97/172] - loss: 0.1059
Epoch 10 [98/172] - loss: 0.1151
Epoch 10 [99/172] - loss: 0.1039
Epoch 10 [100/172] - loss: 0.1061, acc: 1.0000
Epoch 10 [101/172] - loss: 0.1045
Epoch 10 [102/172] - loss: 0.1044
Epoch 10 [103/172] - loss: 0.1035
Epoch 10 [104/172] - loss: 0.1223
Epoch 10 [105/172] - loss: 0.1046
Epoch 10 [106/172] - loss: 0.1204
Epoch 10 [107/172] - loss: 0.1034
Epoch 10 [108/172] - loss: 0.1045
Epoch 10 [109/172] - loss: 0.1034
Epoch 10 [110/172] - loss: 0.1128, acc: 1.0000
Epoch 10 [111/172] - loss: 0.1063
Epoch 10 [112/172] - loss: 0.1040
Epoch 10 [113/172] - loss: 0.1064
Epoch 10 [114/172] - loss: 0.1063
Epoch 10 [115/172] - loss: 0.1087
Epoch 10 [116/172] - loss: 0.1067
Epoch 10 [117/172] - loss: 0.1036
Epoch 10 [118/172] - loss: 0.1047
Epoch 10 [119/172] - loss: 0.1137
Epoch 10 [120/172] - loss: 0.1511, acc: 0.9688
Epoch 10 [121/172] - loss: 0.1124
Epoch 10 [122/172] - loss: 0.1101
Epoch 10 [123/172] - loss: 0.1101
Epoch 10 [124/172] - loss: 0.1043
Epoch 10 [125/172] - loss: 0.1038
Epoch 10 [126/172] - loss: 0.1053
Epoch 10 [127/172] - loss: 0.1056
Epoch 10 [128/172] - loss: 0.1126
Epoch 10 [129/172] - loss: 0.1038
Epoch 10 [130/172] - loss: 0.1128, acc: 1.0000
Epoch 10 [131/172] - loss: 0.1046
Epoch 10 [132/172] - loss: 0.1137
Epoch 10 [133/172] - loss: 0.1070
Epoch 10 [134/172] - loss: 0.1044
Epoch 10 [135/172] - loss: 0.1083
Epoch 10 [136/172] - loss: 0.1071
Epoch 10 [137/172] - loss: 0.1064
Epoch 10 [138/172] - loss: 0.1043
Epoch 10 [139/172] - loss: 0.1065
Epoch 10 [140/172] - loss: 0.1038, acc: 1.0000
Epoch 10 [141/172] - loss: 0.1057
Epoch 10 [142/172] - loss: 0.1080
Epoch 10 [143/172] - loss: 0.1059
Epoch 10 [144/172] - loss: 0.1351
Epoch 10 [145/172] - loss: 0.1055
Epoch 10 [146/172] - loss: 0.1070
Epoch 10 [147/172] - loss: 0.1033
Epoch 10 [148/172] - loss: 0.1438
Epoch 10 [149/172] - loss: 0.1102
Epoch 10 [150/172] - loss: 0.1039, acc: 1.0000
Epoch 10 [151/172] - loss: 0.1050
Epoch 10 [152/172] - loss: 0.1035

=== 第 1701 次迭代调试信息 ===
当前类别统计：
positive: count=19021.0, difficulty=0.0981, log_difficulty=0.0936, weight=1.4680
neutral: count=16607.0, difficulty=0.0749, log_difficulty=0.0723, weight=1.3613
negative: count=18651.0, difficulty=0.0958, log_difficulty=0.0914, weight=1.4572

当前batch的pt分布：
positive: min=0.9689, max=0.9977, mean=0.9898
neutral: min=0.8812, max=0.9995, mean=0.9836
negative: min=0.9944, max=0.9994, mean=0.9965

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0101
焦点损失: 0.0001
边界损失: 0.1398
总损失: 0.1049
Epoch 10 [153/172] - loss: 0.1049
Epoch 10 [154/172] - loss: 0.1137
Epoch 10 [155/172] - loss: 0.1040
Epoch 10 [156/172] - loss: 0.1045
Epoch 10 [157/172] - loss: 0.1051
Epoch 10 [158/172] - loss: 0.1147
Epoch 10 [159/172] - loss: 0.1047
Epoch 10 [160/172] - loss: 0.1037, acc: 1.0000
Epoch 10 [161/172] - loss: 0.1053
Epoch 10 [162/172] - loss: 0.1032
Epoch 10 [163/172] - loss: 0.1154
Epoch 10 [164/172] - loss: 0.1039
Epoch 10 [165/172] - loss: 0.1065
Epoch 10 [166/172] - loss: 0.1046
Epoch 10 [167/172] - loss: 0.1082
Epoch 10 [168/172] - loss: 0.1036
Epoch 10 [169/172] - loss: 0.1035
Epoch 10 [170/172] - loss: 0.1081, acc: 1.0000
Epoch 10 [171/172] - loss: 0.1049
Epoch 10 [172/172] - loss: 0.1101

类别准确率:
positive: 0.8758 (409/467)
neutral: 0.2530 (21/83)
negative: 0.5920 (148/250)

Epoch 10/10
Train Loss: 0.1066, Train Acc: 0.9960
Val Loss: 1.1348, Val Acc: 0.7225
Early stopping triggered!
Best validation accuracy: 0.7325

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_042754-4p36ok63
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.15_Multimodal_iterations_20250118_042752
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/4p36ok63
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇████
wandb:  train_acc ▁▆▆▆▇████▇█▇████████████████████████████
wandb: train_loss ██▅▆▄▃▃▂▃▁▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1718
wandb:  train_acc 1
wandb: train_loss 0.10813
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.15_Multimodal_iterations_20250118_042752 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/4p36ok63
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_042754-4p36ok63/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_044242-7cfu4wcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.15_Multimodal_epochs_20250118_044242
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/7cfu4wcx
wandb: uploading history steps 0-0, summary; updating run config; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▃▄▅▆▆▇█
wandb:  train_acc ▁▆▇██▇████
wandb: train_loss █▄▂▁▁▂▁▁▁▁
wandb:    val_acc ▁▆▆▇▆▆██▇▇
wandb:   val_loss ▃▁▃▃▇█▆█▆█
wandb: 
wandb: Run summary:
wandb:      epoch 10
wandb:  train_acc 0.99596
wandb: train_loss 0.10659
wandb:    val_acc 0.7225
wandb:   val_loss 1.13476
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.15_Multimodal_epochs_20250118_044242 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/7cfu4wcx
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_044242-7cfu4wcx/logs

