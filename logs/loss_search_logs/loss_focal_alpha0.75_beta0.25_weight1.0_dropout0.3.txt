=== 命令 ===
python main.py --loss_type focal --alpha 0.75 --beta 0.25 --neural_init_weight 1.0 --dropout 0.3 --name loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.3 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.3
text_dim: 128
image_dim: 256
dropout: 0.3
loss_type: focal
alpha: 0.75
beta: 0.25
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6850, log_difficulty=0.5218, weight=3.6089
neutral: count=7.0, difficulty=0.7134, log_difficulty=0.5385, weight=3.6924
negative: count=13.0, difficulty=0.6645, log_difficulty=0.5095, weight=3.5476

当前batch的pt分布：
positive: min=0.1487, max=0.5737, mean=0.3150
neutral: min=0.1913, max=0.4014, mean=0.2866
negative: min=0.1633, max=0.5204, mean=0.3355

当前batch准确率：
整体准确率: 0.2500
positive 准确率: 0.2500
neutral 准确率: 0.1429
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1969
焦点损失: 0.4368
边界损失: 0.7251
总损失: 1.3632
Epoch 1 [1/172] - loss: 1.3632, acc: 0.2500
Epoch 1 [2/172] - loss: 1.1836
Epoch 1 [3/172] - loss: 1.1196
Epoch 1 [4/172] - loss: 1.4980
Epoch 1 [5/172] - loss: 1.0784
Epoch 1 [6/172] - loss: 1.3075
Epoch 1 [7/172] - loss: 1.4709
Epoch 1 [8/172] - loss: 1.3333
Epoch 1 [9/172] - loss: 1.3261
Epoch 1 [10/172] - loss: 1.2561, acc: 0.3438
Epoch 1 [11/172] - loss: 1.6110
Epoch 1 [12/172] - loss: 1.2530
Epoch 1 [13/172] - loss: 1.0437
Epoch 1 [14/172] - loss: 1.2941
Epoch 1 [15/172] - loss: 1.1997
Epoch 1 [16/172] - loss: 1.2976
Epoch 1 [17/172] - loss: 1.5235
Epoch 1 [18/172] - loss: 1.1632
Epoch 1 [19/172] - loss: 1.2220
Epoch 1 [20/172] - loss: 0.9962, acc: 0.4688
Epoch 1 [21/172] - loss: 1.2546
Epoch 1 [22/172] - loss: 0.8694
Epoch 1 [23/172] - loss: 1.1359
Epoch 1 [24/172] - loss: 1.0113
Epoch 1 [25/172] - loss: 0.9946
Epoch 1 [26/172] - loss: 0.9974
Epoch 1 [27/172] - loss: 1.4006
Epoch 1 [28/172] - loss: 0.9372
Epoch 1 [29/172] - loss: 0.9334
Epoch 1 [30/172] - loss: 0.7841, acc: 0.5000
Epoch 1 [31/172] - loss: 1.1066
Epoch 1 [32/172] - loss: 1.0618
Epoch 1 [33/172] - loss: 1.1846
Epoch 1 [34/172] - loss: 1.1662
Epoch 1 [35/172] - loss: 1.0402
Epoch 1 [36/172] - loss: 0.8865
Epoch 1 [37/172] - loss: 0.8964
Epoch 1 [38/172] - loss: 0.9596
Epoch 1 [39/172] - loss: 0.8357
Epoch 1 [40/172] - loss: 1.3055, acc: 0.3750
Epoch 1 [41/172] - loss: 0.9663
Epoch 1 [42/172] - loss: 0.8856
Epoch 1 [43/172] - loss: 1.1223
Epoch 1 [44/172] - loss: 1.4150
Epoch 1 [45/172] - loss: 1.3056
Epoch 1 [46/172] - loss: 1.0092
Epoch 1 [47/172] - loss: 1.0619
Epoch 1 [48/172] - loss: 1.0043
Epoch 1 [49/172] - loss: 0.9029
Epoch 1 [50/172] - loss: 1.1113, acc: 0.5625
Epoch 1 [51/172] - loss: 0.9831
Epoch 1 [52/172] - loss: 1.0585
Epoch 1 [53/172] - loss: 1.0986
Epoch 1 [54/172] - loss: 1.1320
Epoch 1 [55/172] - loss: 0.7180
Epoch 1 [56/172] - loss: 0.9151
Epoch 1 [57/172] - loss: 1.1749
Epoch 1 [58/172] - loss: 0.9863
Epoch 1 [59/172] - loss: 0.8660
Epoch 1 [60/172] - loss: 0.6840, acc: 0.6562
Epoch 1 [61/172] - loss: 0.8277
Epoch 1 [62/172] - loss: 0.5820
Epoch 1 [63/172] - loss: 0.8179
Epoch 1 [64/172] - loss: 0.7745
Epoch 1 [65/172] - loss: 0.9704
Epoch 1 [66/172] - loss: 1.1074
Epoch 1 [67/172] - loss: 0.7315
Epoch 1 [68/172] - loss: 0.9132
Epoch 1 [69/172] - loss: 0.9641
Epoch 1 [70/172] - loss: 0.6187, acc: 0.6875
Epoch 1 [71/172] - loss: 0.6508
Epoch 1 [72/172] - loss: 0.7209
Epoch 1 [73/172] - loss: 0.6604
Epoch 1 [74/172] - loss: 0.7818
Epoch 1 [75/172] - loss: 0.4317
Epoch 1 [76/172] - loss: 0.7010
Epoch 1 [77/172] - loss: 0.8396
Epoch 1 [78/172] - loss: 0.7766
Epoch 1 [79/172] - loss: 0.7855
Epoch 1 [80/172] - loss: 0.4827, acc: 0.7812
Epoch 1 [81/172] - loss: 0.8539
Epoch 1 [82/172] - loss: 0.9407
Epoch 1 [83/172] - loss: 1.0661
Epoch 1 [84/172] - loss: 0.5899
Epoch 1 [85/172] - loss: 0.8170
Epoch 1 [86/172] - loss: 0.9185
Epoch 1 [87/172] - loss: 0.8739
Epoch 1 [88/172] - loss: 0.8007
Epoch 1 [89/172] - loss: 0.8121
Epoch 1 [90/172] - loss: 0.6816, acc: 0.6250
Epoch 1 [91/172] - loss: 0.7375
Epoch 1 [92/172] - loss: 0.4856
Epoch 1 [93/172] - loss: 0.7347
Epoch 1 [94/172] - loss: 0.5558
Epoch 1 [95/172] - loss: 0.7749
Epoch 1 [96/172] - loss: 0.5248
Epoch 1 [97/172] - loss: 0.4300
Epoch 1 [98/172] - loss: 0.5420
Epoch 1 [99/172] - loss: 0.9397
Epoch 1 [100/172] - loss: 1.0333, acc: 0.6562

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5827, log_difficulty=0.4591, weight=3.2955
neutral: count=983.0, difficulty=0.5821, log_difficulty=0.4588, weight=3.2939
negative: count=1119.0, difficulty=0.5661, log_difficulty=0.4486, weight=3.2429

当前batch的pt分布：
positive: min=0.1752, max=0.8757, mean=0.4505
neutral: min=0.3672, max=0.8852, mean=0.7280
negative: min=0.1029, max=0.7340, mean=0.3907

当前batch准确率：
整体准确率: 0.5000
positive 准确率: 0.5833
neutral 准确率: 0.7500
negative 准确率: 0.3750

损失分量：
基础交叉熵: 0.9251
焦点损失: 0.3458
边界损失: 0.5301
总损失: 0.9788
Epoch 1 [101/172] - loss: 0.9788
Epoch 1 [102/172] - loss: 0.6741
Epoch 1 [103/172] - loss: 0.5882
Epoch 1 [104/172] - loss: 0.5164
Epoch 1 [105/172] - loss: 0.7863
Epoch 1 [106/172] - loss: 1.0338
Epoch 1 [107/172] - loss: 0.6015
Epoch 1 [108/172] - loss: 0.8920
Epoch 1 [109/172] - loss: 0.7645
Epoch 1 [110/172] - loss: 1.0517, acc: 0.6875
Epoch 1 [111/172] - loss: 0.5973
Epoch 1 [112/172] - loss: 0.5172
Epoch 1 [113/172] - loss: 0.5730
Epoch 1 [114/172] - loss: 0.6411
Epoch 1 [115/172] - loss: 0.4224
Epoch 1 [116/172] - loss: 0.6829
Epoch 1 [117/172] - loss: 0.9848
Epoch 1 [118/172] - loss: 0.5626
Epoch 1 [119/172] - loss: 0.4536
Epoch 1 [120/172] - loss: 0.5845, acc: 0.6875
Epoch 1 [121/172] - loss: 0.4848
Epoch 1 [122/172] - loss: 0.7295
Epoch 1 [123/172] - loss: 0.5940
Epoch 1 [124/172] - loss: 0.5509
Epoch 1 [125/172] - loss: 0.4063
Epoch 1 [126/172] - loss: 1.1821
Epoch 1 [127/172] - loss: 0.7012
Epoch 1 [128/172] - loss: 0.6542
Epoch 1 [129/172] - loss: 0.8060
Epoch 1 [130/172] - loss: 0.5641, acc: 0.6562
Epoch 1 [131/172] - loss: 0.3391
Epoch 1 [132/172] - loss: 0.4666
Epoch 1 [133/172] - loss: 0.6221
Epoch 1 [134/172] - loss: 0.7864
Epoch 1 [135/172] - loss: 0.4584
Epoch 1 [136/172] - loss: 0.4857
Epoch 1 [137/172] - loss: 0.6825
Epoch 1 [138/172] - loss: 0.4710
Epoch 1 [139/172] - loss: 0.4913
Epoch 1 [140/172] - loss: 0.5328, acc: 0.7500
Epoch 1 [141/172] - loss: 0.5660
Epoch 1 [142/172] - loss: 0.5385
Epoch 1 [143/172] - loss: 0.5991
Epoch 1 [144/172] - loss: 0.5418
Epoch 1 [145/172] - loss: 0.7390
Epoch 1 [146/172] - loss: 0.6950
Epoch 1 [147/172] - loss: 0.8390
Epoch 1 [148/172] - loss: 0.4974
Epoch 1 [149/172] - loss: 0.5355
Epoch 1 [150/172] - loss: 0.6480, acc: 0.6875
Epoch 1 [151/172] - loss: 0.6986
Epoch 1 [152/172] - loss: 0.5109
Epoch 1 [153/172] - loss: 0.6773
Epoch 1 [154/172] - loss: 0.4698
Epoch 1 [155/172] - loss: 0.5746
Epoch 1 [156/172] - loss: 0.7650
Epoch 1 [157/172] - loss: 0.8613
Epoch 1 [158/172] - loss: 0.4782
Epoch 1 [159/172] - loss: 0.7880
Epoch 1 [160/172] - loss: 0.6313, acc: 0.6250
Epoch 1 [161/172] - loss: 0.6585
Epoch 1 [162/172] - loss: 0.7001
Epoch 1 [163/172] - loss: 0.5899
Epoch 1 [164/172] - loss: 0.5701
Epoch 1 [165/172] - loss: 0.4239
Epoch 1 [166/172] - loss: 0.5017
Epoch 1 [167/172] - loss: 0.3402
Epoch 1 [168/172] - loss: 0.9069
Epoch 1 [169/172] - loss: 0.5812
Epoch 1 [170/172] - loss: 0.5462, acc: 0.8125
Epoch 1 [171/172] - loss: 0.5513
Epoch 1 [172/172] - loss: 1.0706

类别准确率:
positive: 0.5589 (261/467)
neutral: 0.8313 (69/83)
negative: 0.4520 (113/250)

Epoch 1/10
Train Loss: 0.6375, Train Acc: 0.7253
Val Loss: 0.9295, Val Acc: 0.5537
Epoch 2 [1/172] - loss: 0.6053, acc: 0.7188
Epoch 2 [2/172] - loss: 0.3691
Epoch 2 [3/172] - loss: 0.3114
Epoch 2 [4/172] - loss: 0.5609
Epoch 2 [5/172] - loss: 0.7532
Epoch 2 [6/172] - loss: 0.4407
Epoch 2 [7/172] - loss: 0.5198
Epoch 2 [8/172] - loss: 0.5637
Epoch 2 [9/172] - loss: 0.5391
Epoch 2 [10/172] - loss: 0.4247, acc: 0.8438
Epoch 2 [11/172] - loss: 0.3406
Epoch 2 [12/172] - loss: 0.4435
Epoch 2 [13/172] - loss: 0.4158
Epoch 2 [14/172] - loss: 0.4216
Epoch 2 [15/172] - loss: 0.4598
Epoch 2 [16/172] - loss: 0.4845
Epoch 2 [17/172] - loss: 0.5466
Epoch 2 [18/172] - loss: 0.4750
Epoch 2 [19/172] - loss: 0.3089
Epoch 2 [20/172] - loss: 0.7650, acc: 0.7188
Epoch 2 [21/172] - loss: 0.2842
Epoch 2 [22/172] - loss: 0.3024
Epoch 2 [23/172] - loss: 0.2663
Epoch 2 [24/172] - loss: 0.5843
Epoch 2 [25/172] - loss: 0.5029
Epoch 2 [26/172] - loss: 0.4433
Epoch 2 [27/172] - loss: 0.3355
Epoch 2 [28/172] - loss: 0.4255

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5295, log_difficulty=0.4250, weight=3.1248
neutral: count=1952.0, difficulty=0.4850, log_difficulty=0.3954, weight=2.9770
negative: count=2216.0, difficulty=0.5127, log_difficulty=0.4139, weight=3.0696

当前batch的pt分布：
positive: min=0.2550, max=0.8693, mean=0.5951
neutral: min=0.2008, max=0.9416, mean=0.6482
negative: min=0.1940, max=0.9180, mean=0.6282

当前batch准确率：
整体准确率: 0.8125
positive 准确率: 0.7778
neutral 准确率: 0.8182
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.5462
焦点损失: 0.1360
边界损失: 0.4061
总损失: 0.4128
Epoch 2 [29/172] - loss: 0.4128
Epoch 2 [30/172] - loss: 0.2412, acc: 0.9062
Epoch 2 [31/172] - loss: 0.4515
Epoch 2 [32/172] - loss: 0.2995
Epoch 2 [33/172] - loss: 0.3298
Epoch 2 [34/172] - loss: 0.3645
Epoch 2 [35/172] - loss: 0.2450
Epoch 2 [36/172] - loss: 0.3597
Epoch 2 [37/172] - loss: 0.2389
Epoch 2 [38/172] - loss: 0.3688
Epoch 2 [39/172] - loss: 0.7117
Epoch 2 [40/172] - loss: 0.4825, acc: 0.7812
Epoch 2 [41/172] - loss: 0.2637
Epoch 2 [42/172] - loss: 0.2200
Epoch 2 [43/172] - loss: 0.2486
Epoch 2 [44/172] - loss: 0.5780
Epoch 2 [45/172] - loss: 0.1962
Epoch 2 [46/172] - loss: 0.2201
Epoch 2 [47/172] - loss: 0.5317
Epoch 2 [48/172] - loss: 0.3940
Epoch 2 [49/172] - loss: 0.4728
Epoch 2 [50/172] - loss: 0.2368, acc: 0.9062
Epoch 2 [51/172] - loss: 0.5174
Epoch 2 [52/172] - loss: 0.2795
Epoch 2 [53/172] - loss: 0.2849
Epoch 2 [54/172] - loss: 0.2518
Epoch 2 [55/172] - loss: 0.4832
Epoch 2 [56/172] - loss: 0.3439
Epoch 2 [57/172] - loss: 0.2713
Epoch 2 [58/172] - loss: 0.3744
Epoch 2 [59/172] - loss: 0.2848
Epoch 2 [60/172] - loss: 0.2683, acc: 0.8750
Epoch 2 [61/172] - loss: 0.1861
Epoch 2 [62/172] - loss: 0.2757
Epoch 2 [63/172] - loss: 0.3991
Epoch 2 [64/172] - loss: 0.2713
Epoch 2 [65/172] - loss: 0.2788
Epoch 2 [66/172] - loss: 0.2263
Epoch 2 [67/172] - loss: 0.3223
Epoch 2 [68/172] - loss: 0.4757
Epoch 2 [69/172] - loss: 0.2509
Epoch 2 [70/172] - loss: 0.4613, acc: 0.8125
Epoch 2 [71/172] - loss: 0.4465
Epoch 2 [72/172] - loss: 0.4809
Epoch 2 [73/172] - loss: 0.4077
Epoch 2 [74/172] - loss: 0.2132
Epoch 2 [75/172] - loss: 0.2028
Epoch 2 [76/172] - loss: 0.2724
Epoch 2 [77/172] - loss: 0.2264
Epoch 2 [78/172] - loss: 0.2413
Epoch 2 [79/172] - loss: 0.3110
Epoch 2 [80/172] - loss: 0.2371, acc: 0.8750
Epoch 2 [81/172] - loss: 0.4046
Epoch 2 [82/172] - loss: 0.1902
Epoch 2 [83/172] - loss: 0.2724
Epoch 2 [84/172] - loss: 0.3591
Epoch 2 [85/172] - loss: 0.2501
Epoch 2 [86/172] - loss: 0.2388
Epoch 2 [87/172] - loss: 0.6661
Epoch 2 [88/172] - loss: 0.1963
Epoch 2 [89/172] - loss: 0.1876
Epoch 2 [90/172] - loss: 0.4003, acc: 0.8438
Epoch 2 [91/172] - loss: 0.1577
Epoch 2 [92/172] - loss: 0.3245
Epoch 2 [93/172] - loss: 0.1664
Epoch 2 [94/172] - loss: 0.2242
Epoch 2 [95/172] - loss: 0.3961
Epoch 2 [96/172] - loss: 0.1593
Epoch 2 [97/172] - loss: 0.1844
Epoch 2 [98/172] - loss: 0.2079
Epoch 2 [99/172] - loss: 0.2290
Epoch 2 [100/172] - loss: 0.1429, acc: 0.9375
Epoch 2 [101/172] - loss: 0.2500
Epoch 2 [102/172] - loss: 0.1659
Epoch 2 [103/172] - loss: 0.2414
Epoch 2 [104/172] - loss: 0.3788
Epoch 2 [105/172] - loss: 0.1929
Epoch 2 [106/172] - loss: 0.1736
Epoch 2 [107/172] - loss: 0.1729
Epoch 2 [108/172] - loss: 0.3650
Epoch 2 [109/172] - loss: 0.2379
Epoch 2 [110/172] - loss: 0.4566, acc: 0.8750
Epoch 2 [111/172] - loss: 0.2347
Epoch 2 [112/172] - loss: 0.1390
Epoch 2 [113/172] - loss: 0.1611
Epoch 2 [114/172] - loss: 0.1790
Epoch 2 [115/172] - loss: 0.3087
Epoch 2 [116/172] - loss: 0.2679
Epoch 2 [117/172] - loss: 0.5947
Epoch 2 [118/172] - loss: 0.1556
Epoch 2 [119/172] - loss: 0.1401
Epoch 2 [120/172] - loss: 0.2131, acc: 0.9375
Epoch 2 [121/172] - loss: 0.2432
Epoch 2 [122/172] - loss: 0.5275
Epoch 2 [123/172] - loss: 0.1978
Epoch 2 [124/172] - loss: 0.1462
Epoch 2 [125/172] - loss: 0.2729
Epoch 2 [126/172] - loss: 0.1357
Epoch 2 [127/172] - loss: 0.1755
Epoch 2 [128/172] - loss: 0.3336

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4703, log_difficulty=0.3854, weight=2.9272
neutral: count=2949.0, difficulty=0.3938, log_difficulty=0.3321, weight=2.6603
negative: count=3294.0, difficulty=0.4536, log_difficulty=0.3740, weight=2.8702

当前batch的pt分布：
positive: min=0.3841, max=0.9351, mean=0.7443
neutral: min=0.2722, max=0.9868, mean=0.7892
negative: min=0.1521, max=0.9026, mean=0.6751

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.9000
neutral 准确率: 0.9091
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.3714
焦点损失: 0.0870
边界损失: 0.3007
总损失: 0.2593
Epoch 2 [129/172] - loss: 0.2593
Epoch 2 [130/172] - loss: 0.2025, acc: 0.8125
Epoch 2 [131/172] - loss: 0.1303
Epoch 2 [132/172] - loss: 0.3185
Epoch 2 [133/172] - loss: 0.2505
Epoch 2 [134/172] - loss: 0.1725
Epoch 2 [135/172] - loss: 0.4907
Epoch 2 [136/172] - loss: 0.2229
Epoch 2 [137/172] - loss: 0.1576
Epoch 2 [138/172] - loss: 0.2678
Epoch 2 [139/172] - loss: 0.2319
Epoch 2 [140/172] - loss: 0.5587, acc: 0.8438
Epoch 2 [141/172] - loss: 0.2968
Epoch 2 [142/172] - loss: 0.3084
Epoch 2 [143/172] - loss: 0.2157
Epoch 2 [144/172] - loss: 0.1808
Epoch 2 [145/172] - loss: 0.6214
Epoch 2 [146/172] - loss: 0.1837
Epoch 2 [147/172] - loss: 0.2223
Epoch 2 [148/172] - loss: 0.2552
Epoch 2 [149/172] - loss: 0.1769
Epoch 2 [150/172] - loss: 0.2690, acc: 0.8750
Epoch 2 [151/172] - loss: 0.3743
Epoch 2 [152/172] - loss: 0.2056
Epoch 2 [153/172] - loss: 0.2891
Epoch 2 [154/172] - loss: 0.2178
Epoch 2 [155/172] - loss: 0.2748
Epoch 2 [156/172] - loss: 0.3622
Epoch 2 [157/172] - loss: 0.2230
Epoch 2 [158/172] - loss: 0.3266
Epoch 2 [159/172] - loss: 0.4085
Epoch 2 [160/172] - loss: 0.1758, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1766
Epoch 2 [162/172] - loss: 0.1909
Epoch 2 [163/172] - loss: 0.3236
Epoch 2 [164/172] - loss: 0.2798
Epoch 2 [165/172] - loss: 0.3282
Epoch 2 [166/172] - loss: 0.4192
Epoch 2 [167/172] - loss: 0.2300
Epoch 2 [168/172] - loss: 0.1224
Epoch 2 [169/172] - loss: 0.1301
Epoch 2 [170/172] - loss: 0.1888, acc: 0.9062
Epoch 2 [171/172] - loss: 0.2388
Epoch 2 [172/172] - loss: 0.2571

类别准确率:
positive: 0.8480 (396/467)
neutral: 0.3012 (25/83)
negative: 0.5640 (141/250)

Epoch 2/10
Train Loss: 0.2512, Train Acc: 0.8949
Val Loss: 0.7202, Val Acc: 0.7025
Epoch 3 [1/172] - loss: 0.2417, acc: 0.8438
Epoch 3 [2/172] - loss: 0.1218
Epoch 3 [3/172] - loss: 0.1012
Epoch 3 [4/172] - loss: 0.1497
Epoch 3 [5/172] - loss: 0.1453
Epoch 3 [6/172] - loss: 0.1238
Epoch 3 [7/172] - loss: 0.1499
Epoch 3 [8/172] - loss: 0.1360
Epoch 3 [9/172] - loss: 0.1453
Epoch 3 [10/172] - loss: 0.1089, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1208
Epoch 3 [12/172] - loss: 0.0986
Epoch 3 [13/172] - loss: 0.1704
Epoch 3 [14/172] - loss: 0.1236
Epoch 3 [15/172] - loss: 0.0739
Epoch 3 [16/172] - loss: 0.3424
Epoch 3 [17/172] - loss: 0.2874
Epoch 3 [18/172] - loss: 0.1901
Epoch 3 [19/172] - loss: 0.1068
Epoch 3 [20/172] - loss: 0.1224, acc: 0.9688
Epoch 3 [21/172] - loss: 0.0690
Epoch 3 [22/172] - loss: 0.3288
Epoch 3 [23/172] - loss: 0.0816
Epoch 3 [24/172] - loss: 0.1770
Epoch 3 [25/172] - loss: 0.2307
Epoch 3 [26/172] - loss: 0.2272
Epoch 3 [27/172] - loss: 0.1209
Epoch 3 [28/172] - loss: 0.0777
Epoch 3 [29/172] - loss: 0.1998
Epoch 3 [30/172] - loss: 0.1402, acc: 0.9688
Epoch 3 [31/172] - loss: 0.0783
Epoch 3 [32/172] - loss: 0.1005
Epoch 3 [33/172] - loss: 0.1857
Epoch 3 [34/172] - loss: 0.1342
Epoch 3 [35/172] - loss: 0.2328
Epoch 3 [36/172] - loss: 0.1102
Epoch 3 [37/172] - loss: 0.2887
Epoch 3 [38/172] - loss: 0.1032
Epoch 3 [39/172] - loss: 0.1014
Epoch 3 [40/172] - loss: 0.1016, acc: 1.0000
Epoch 3 [41/172] - loss: 0.2125
Epoch 3 [42/172] - loss: 0.1486
Epoch 3 [43/172] - loss: 0.0723
Epoch 3 [44/172] - loss: 0.1078
Epoch 3 [45/172] - loss: 0.1149
Epoch 3 [46/172] - loss: 0.0945
Epoch 3 [47/172] - loss: 0.1270
Epoch 3 [48/172] - loss: 0.1059
Epoch 3 [49/172] - loss: 0.2066
Epoch 3 [50/172] - loss: 0.1066, acc: 0.9688
Epoch 3 [51/172] - loss: 0.1136
Epoch 3 [52/172] - loss: 0.2025
Epoch 3 [53/172] - loss: 0.2661
Epoch 3 [54/172] - loss: 0.1919
Epoch 3 [55/172] - loss: 0.1078
Epoch 3 [56/172] - loss: 0.0855

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.4168, log_difficulty=0.3484, weight=2.7420
neutral: count=3923.0, difficulty=0.3396, log_difficulty=0.2923, weight=2.4617
negative: count=4382.0, difficulty=0.4054, log_difficulty=0.3403, weight=2.7014

当前batch的pt分布：
positive: min=0.3440, max=0.9918, mean=0.6936
neutral: min=0.0159, max=0.9513, mean=0.7160
negative: min=0.5657, max=0.9808, mean=0.8763

当前batch准确率：
整体准确率: 0.7812
positive 准确率: 0.6364
neutral 准确率: 0.8125
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.5179
焦点损失: 0.2827
边界损失: 0.2685
总损失: 0.5960
Epoch 3 [57/172] - loss: 0.5960
Epoch 3 [58/172] - loss: 0.0995
Epoch 3 [59/172] - loss: 0.1571
Epoch 3 [60/172] - loss: 0.1241, acc: 0.9062
Epoch 3 [61/172] - loss: 0.1775
Epoch 3 [62/172] - loss: 0.1111
Epoch 3 [63/172] - loss: 0.0832
Epoch 3 [64/172] - loss: 0.1155
Epoch 3 [65/172] - loss: 0.0998
Epoch 3 [66/172] - loss: 0.1017
Epoch 3 [67/172] - loss: 0.1426
Epoch 3 [68/172] - loss: 0.0895
Epoch 3 [69/172] - loss: 0.2459
Epoch 3 [70/172] - loss: 0.1086, acc: 0.9062
Epoch 3 [71/172] - loss: 0.1833
Epoch 3 [72/172] - loss: 0.2922
Epoch 3 [73/172] - loss: 0.1070
Epoch 3 [74/172] - loss: 0.1122
Epoch 3 [75/172] - loss: 0.1741
Epoch 3 [76/172] - loss: 0.1872
Epoch 3 [77/172] - loss: 0.0839
Epoch 3 [78/172] - loss: 0.3316
Epoch 3 [79/172] - loss: 0.2285
Epoch 3 [80/172] - loss: 0.2005, acc: 0.8750
Epoch 3 [81/172] - loss: 0.0955
Epoch 3 [82/172] - loss: 0.1225
Epoch 3 [83/172] - loss: 0.1194
Epoch 3 [84/172] - loss: 0.1526
Epoch 3 [85/172] - loss: 0.1288
Epoch 3 [86/172] - loss: 0.0723
Epoch 3 [87/172] - loss: 0.1291
Epoch 3 [88/172] - loss: 0.1353
Epoch 3 [89/172] - loss: 0.2059
Epoch 3 [90/172] - loss: 0.1317, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1038
Epoch 3 [92/172] - loss: 0.1337
Epoch 3 [93/172] - loss: 0.1703
Epoch 3 [94/172] - loss: 0.2360
Epoch 3 [95/172] - loss: 0.0761
Epoch 3 [96/172] - loss: 0.1510
Epoch 3 [97/172] - loss: 0.0937
Epoch 3 [98/172] - loss: 0.0852
Epoch 3 [99/172] - loss: 0.0919
Epoch 3 [100/172] - loss: 0.2514, acc: 0.9062
Epoch 3 [101/172] - loss: 0.2746
Epoch 3 [102/172] - loss: 0.0622
Epoch 3 [103/172] - loss: 0.1787
Epoch 3 [104/172] - loss: 0.1303
Epoch 3 [105/172] - loss: 0.1145
Epoch 3 [106/172] - loss: 0.2112
Epoch 3 [107/172] - loss: 0.0860
Epoch 3 [108/172] - loss: 0.1288
Epoch 3 [109/172] - loss: 0.1745
Epoch 3 [110/172] - loss: 0.4067, acc: 0.8750
Epoch 3 [111/172] - loss: 0.1741
Epoch 3 [112/172] - loss: 0.1205
Epoch 3 [113/172] - loss: 0.0966
Epoch 3 [114/172] - loss: 0.1922
Epoch 3 [115/172] - loss: 0.3113
Epoch 3 [116/172] - loss: 0.1510
Epoch 3 [117/172] - loss: 0.1890
Epoch 3 [118/172] - loss: 0.2189
Epoch 3 [119/172] - loss: 0.0675
Epoch 3 [120/172] - loss: 0.0933, acc: 0.9375
Epoch 3 [121/172] - loss: 0.1294
Epoch 3 [122/172] - loss: 0.1224
Epoch 3 [123/172] - loss: 0.1336
Epoch 3 [124/172] - loss: 0.1064
Epoch 3 [125/172] - loss: 0.1344
Epoch 3 [126/172] - loss: 0.4446
Epoch 3 [127/172] - loss: 0.1372
Epoch 3 [128/172] - loss: 0.0796
Epoch 3 [129/172] - loss: 0.1348
Epoch 3 [130/172] - loss: 0.1755, acc: 0.9062
Epoch 3 [131/172] - loss: 0.2592
Epoch 3 [132/172] - loss: 0.0646
Epoch 3 [133/172] - loss: 0.1698
Epoch 3 [134/172] - loss: 0.0802
Epoch 3 [135/172] - loss: 0.0792
Epoch 3 [136/172] - loss: 0.2062
Epoch 3 [137/172] - loss: 0.1158
Epoch 3 [138/172] - loss: 0.2803
Epoch 3 [139/172] - loss: 0.1517
Epoch 3 [140/172] - loss: 0.1440, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1698
Epoch 3 [142/172] - loss: 0.2365
Epoch 3 [143/172] - loss: 0.1174
Epoch 3 [144/172] - loss: 0.1345
Epoch 3 [145/172] - loss: 0.1672
Epoch 3 [146/172] - loss: 0.1169
Epoch 3 [147/172] - loss: 0.1012
Epoch 3 [148/172] - loss: 0.1317
Epoch 3 [149/172] - loss: 0.1424
Epoch 3 [150/172] - loss: 0.1477, acc: 0.9375
Epoch 3 [151/172] - loss: 0.3832
Epoch 3 [152/172] - loss: 0.1760
Epoch 3 [153/172] - loss: 0.3414
Epoch 3 [154/172] - loss: 0.1650
Epoch 3 [155/172] - loss: 0.0653
Epoch 3 [156/172] - loss: 0.0765

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3736, log_difficulty=0.3174, weight=2.5872
neutral: count=4903.0, difficulty=0.3003, log_difficulty=0.2626, weight=2.3131
negative: count=5500.0, difficulty=0.3664, log_difficulty=0.3122, weight=2.5608

当前batch的pt分布：
positive: min=0.5706, max=0.9773, mean=0.8281
neutral: min=0.3436, max=0.9805, mean=0.8788
negative: min=0.5436, max=0.9758, mean=0.7672

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9091
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2135
焦点损失: 0.0239
边界损失: 0.2474
总损失: 0.1054
Epoch 3 [157/172] - loss: 0.1054
Epoch 3 [158/172] - loss: 0.3202
Epoch 3 [159/172] - loss: 0.1324
Epoch 3 [160/172] - loss: 0.1866, acc: 0.8438
Epoch 3 [161/172] - loss: 0.2755
Epoch 3 [162/172] - loss: 0.1412
Epoch 3 [163/172] - loss: 0.0844
Epoch 3 [164/172] - loss: 0.0528
Epoch 3 [165/172] - loss: 0.1258
Epoch 3 [166/172] - loss: 0.0634
Epoch 3 [167/172] - loss: 0.0935
Epoch 3 [168/172] - loss: 0.0688
Epoch 3 [169/172] - loss: 0.0651
Epoch 3 [170/172] - loss: 0.1235, acc: 0.9375
Epoch 3 [171/172] - loss: 0.0955
Epoch 3 [172/172] - loss: 0.1159

类别准确率:
positive: 0.8030 (375/467)
neutral: 0.2410 (20/83)
negative: 0.6400 (160/250)

Epoch 3/10
Train Loss: 0.1281, Train Acc: 0.9616
Val Loss: 0.7282, Val Acc: 0.6937
Epoch 4 [1/172] - loss: 0.1121, acc: 0.9688
Epoch 4 [2/172] - loss: 0.1604
Epoch 4 [3/172] - loss: 0.0620
Epoch 4 [4/172] - loss: 0.0979
Epoch 4 [5/172] - loss: 0.0833
Epoch 4 [6/172] - loss: 0.0695
Epoch 4 [7/172] - loss: 0.1703
Epoch 4 [8/172] - loss: 0.0586
Epoch 4 [9/172] - loss: 0.1961
Epoch 4 [10/172] - loss: 0.0643, acc: 1.0000
Epoch 4 [11/172] - loss: 0.0627
Epoch 4 [12/172] - loss: 0.1289
Epoch 4 [13/172] - loss: 0.1316
Epoch 4 [14/172] - loss: 0.1061
Epoch 4 [15/172] - loss: 0.0603
Epoch 4 [16/172] - loss: 0.0512
Epoch 4 [17/172] - loss: 0.1161
Epoch 4 [18/172] - loss: 0.0963
Epoch 4 [19/172] - loss: 0.0821
Epoch 4 [20/172] - loss: 0.0800, acc: 0.9688
Epoch 4 [21/172] - loss: 0.2025
Epoch 4 [22/172] - loss: 0.0795
Epoch 4 [23/172] - loss: 0.0910
Epoch 4 [24/172] - loss: 0.1642
Epoch 4 [25/172] - loss: 0.0715
Epoch 4 [26/172] - loss: 0.0854
Epoch 4 [27/172] - loss: 0.0576
Epoch 4 [28/172] - loss: 0.0847
Epoch 4 [29/172] - loss: 0.0671
Epoch 4 [30/172] - loss: 0.2514, acc: 0.9062
Epoch 4 [31/172] - loss: 0.0773
Epoch 4 [32/172] - loss: 0.2278
Epoch 4 [33/172] - loss: 0.0649
Epoch 4 [34/172] - loss: 0.0507
Epoch 4 [35/172] - loss: 0.0663
Epoch 4 [36/172] - loss: 0.0926
Epoch 4 [37/172] - loss: 0.0475
Epoch 4 [38/172] - loss: 0.0651
Epoch 4 [39/172] - loss: 0.2497
Epoch 4 [40/172] - loss: 0.2612, acc: 0.9062
Epoch 4 [41/172] - loss: 0.1023
Epoch 4 [42/172] - loss: 0.0957
Epoch 4 [43/172] - loss: 0.2540
Epoch 4 [44/172] - loss: 0.0802
Epoch 4 [45/172] - loss: 0.0666
Epoch 4 [46/172] - loss: 0.0654
Epoch 4 [47/172] - loss: 0.0722
Epoch 4 [48/172] - loss: 0.1100
Epoch 4 [49/172] - loss: 0.0525
Epoch 4 [50/172] - loss: 0.2017, acc: 0.9062
Epoch 4 [51/172] - loss: 0.0751
Epoch 4 [52/172] - loss: 0.0652
Epoch 4 [53/172] - loss: 0.0536
Epoch 4 [54/172] - loss: 0.1144
Epoch 4 [55/172] - loss: 0.2188
Epoch 4 [56/172] - loss: 0.1031
Epoch 4 [57/172] - loss: 0.0584
Epoch 4 [58/172] - loss: 0.0965
Epoch 4 [59/172] - loss: 0.0507
Epoch 4 [60/172] - loss: 0.0663, acc: 0.9688
Epoch 4 [61/172] - loss: 0.0667
Epoch 4 [62/172] - loss: 0.1025
Epoch 4 [63/172] - loss: 0.0679
Epoch 4 [64/172] - loss: 0.0624
Epoch 4 [65/172] - loss: 0.0876
Epoch 4 [66/172] - loss: 0.0599
Epoch 4 [67/172] - loss: 0.0862
Epoch 4 [68/172] - loss: 0.0827
Epoch 4 [69/172] - loss: 0.0866
Epoch 4 [70/172] - loss: 0.0882, acc: 0.9375
Epoch 4 [71/172] - loss: 0.0863
Epoch 4 [72/172] - loss: 0.0512
Epoch 4 [73/172] - loss: 0.0684
Epoch 4 [74/172] - loss: 0.2476
Epoch 4 [75/172] - loss: 0.0629
Epoch 4 [76/172] - loss: 0.0577
Epoch 4 [77/172] - loss: 0.0909
Epoch 4 [78/172] - loss: 0.1182
Epoch 4 [79/172] - loss: 0.0580
Epoch 4 [80/172] - loss: 0.1509, acc: 0.9062
Epoch 4 [81/172] - loss: 0.2393
Epoch 4 [82/172] - loss: 0.0573
Epoch 4 [83/172] - loss: 0.1137
Epoch 4 [84/172] - loss: 0.0581

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3366, log_difficulty=0.2901, weight=2.4505
neutral: count=5865.0, difficulty=0.2679, log_difficulty=0.2374, weight=2.1869
negative: count=6629.0, difficulty=0.3319, log_difficulty=0.2866, weight=2.4330

当前batch的pt分布：
positive: min=0.3877, max=0.9605, mean=0.8104
neutral: min=0.8052, max=0.9945, mean=0.9518
negative: min=0.7428, max=0.9732, mean=0.9134

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1520
焦点损失: 0.0125
边界损失: 0.2084
总损失: 0.0750
Epoch 4 [85/172] - loss: 0.0750
Epoch 4 [86/172] - loss: 0.1082
Epoch 4 [87/172] - loss: 0.0686
Epoch 4 [88/172] - loss: 0.0664
Epoch 4 [89/172] - loss: 0.0971
Epoch 4 [90/172] - loss: 0.0792, acc: 0.9688
Epoch 4 [91/172] - loss: 0.1341
Epoch 4 [92/172] - loss: 0.2281
Epoch 4 [93/172] - loss: 0.0511
Epoch 4 [94/172] - loss: 0.0524
Epoch 4 [95/172] - loss: 0.1353
Epoch 4 [96/172] - loss: 0.0712
Epoch 4 [97/172] - loss: 0.0595
Epoch 4 [98/172] - loss: 0.0863
Epoch 4 [99/172] - loss: 0.0970
Epoch 4 [100/172] - loss: 0.1338, acc: 0.9062
Epoch 4 [101/172] - loss: 0.0915
Epoch 4 [102/172] - loss: 0.1779
Epoch 4 [103/172] - loss: 0.0653
Epoch 4 [104/172] - loss: 0.0594
Epoch 4 [105/172] - loss: 0.0817
Epoch 4 [106/172] - loss: 0.0535
Epoch 4 [107/172] - loss: 0.0588
Epoch 4 [108/172] - loss: 0.1214
Epoch 4 [109/172] - loss: 0.0605
Epoch 4 [110/172] - loss: 0.5451, acc: 0.8750
Epoch 4 [111/172] - loss: 0.0556
Epoch 4 [112/172] - loss: 0.0539
Epoch 4 [113/172] - loss: 0.0565
Epoch 4 [114/172] - loss: 0.0532
Epoch 4 [115/172] - loss: 0.1377
Epoch 4 [116/172] - loss: 0.0573
Epoch 4 [117/172] - loss: 0.0660
Epoch 4 [118/172] - loss: 0.0573
Epoch 4 [119/172] - loss: 0.0541
Epoch 4 [120/172] - loss: 0.0896, acc: 0.9375
Epoch 4 [121/172] - loss: 0.0771
Epoch 4 [122/172] - loss: 0.1517
Epoch 4 [123/172] - loss: 0.0644
Epoch 4 [124/172] - loss: 0.0887
Epoch 4 [125/172] - loss: 0.0999
Epoch 4 [126/172] - loss: 0.2025
Epoch 4 [127/172] - loss: 0.1029
Epoch 4 [128/172] - loss: 0.1111
Epoch 4 [129/172] - loss: 0.1096
Epoch 4 [130/172] - loss: 0.0702, acc: 0.9688
Epoch 4 [131/172] - loss: 0.0824
Epoch 4 [132/172] - loss: 0.0683
Epoch 4 [133/172] - loss: 0.0951
Epoch 4 [134/172] - loss: 0.0664
Epoch 4 [135/172] - loss: 0.1020
Epoch 4 [136/172] - loss: 0.1214
Epoch 4 [137/172] - loss: 0.0705
Epoch 4 [138/172] - loss: 0.0603
Epoch 4 [139/172] - loss: 0.0654
Epoch 4 [140/172] - loss: 0.0834, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1204
Epoch 4 [142/172] - loss: 0.0717
Epoch 4 [143/172] - loss: 0.0507
Epoch 4 [144/172] - loss: 0.0901
Epoch 4 [145/172] - loss: 0.2474
Epoch 4 [146/172] - loss: 0.0611
Epoch 4 [147/172] - loss: 0.0824
Epoch 4 [148/172] - loss: 0.0817
Epoch 4 [149/172] - loss: 0.1086
Epoch 4 [150/172] - loss: 0.1030, acc: 0.9688
Epoch 4 [151/172] - loss: 0.1258
Epoch 4 [152/172] - loss: 0.1334
Epoch 4 [153/172] - loss: 0.0564
Epoch 4 [154/172] - loss: 0.2324
Epoch 4 [155/172] - loss: 0.0662
Epoch 4 [156/172] - loss: 0.0589
Epoch 4 [157/172] - loss: 0.2377
Epoch 4 [158/172] - loss: 0.0450
Epoch 4 [159/172] - loss: 0.0639
Epoch 4 [160/172] - loss: 0.1696, acc: 0.9062
Epoch 4 [161/172] - loss: 0.1413
Epoch 4 [162/172] - loss: 0.0717
Epoch 4 [163/172] - loss: 0.0778
Epoch 4 [164/172] - loss: 0.0586
Epoch 4 [165/172] - loss: 0.0689
Epoch 4 [166/172] - loss: 0.0550
Epoch 4 [167/172] - loss: 0.0683
Epoch 4 [168/172] - loss: 0.0498
Epoch 4 [169/172] - loss: 0.2132
Epoch 4 [170/172] - loss: 0.1535, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0907
Epoch 4 [172/172] - loss: 0.0669

类别准确率:
positive: 0.8672 (405/467)
neutral: 0.3253 (27/83)
negative: 0.5600 (140/250)

Epoch 4/10
Train Loss: 0.1020, Train Acc: 0.9677
Val Loss: 0.7468, Val Acc: 0.7150
Epoch 5 [1/172] - loss: 0.0435, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1074
Epoch 5 [3/172] - loss: 0.0659
Epoch 5 [4/172] - loss: 0.0737
Epoch 5 [5/172] - loss: 0.0554
Epoch 5 [6/172] - loss: 0.0782
Epoch 5 [7/172] - loss: 0.0509
Epoch 5 [8/172] - loss: 0.0697
Epoch 5 [9/172] - loss: 0.1274
Epoch 5 [10/172] - loss: 0.0588, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1025
Epoch 5 [12/172] - loss: 0.0541

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.3081, log_difficulty=0.2685, weight=2.3427
neutral: count=6845.0, difficulty=0.2418, log_difficulty=0.2166, weight=2.0830
negative: count=7694.0, difficulty=0.3059, log_difficulty=0.2669, weight=2.3346

当前batch的pt分布：
positive: min=0.5143, max=0.9738, mean=0.8079
neutral: min=0.9220, max=0.9921, mean=0.9602
negative: min=0.6915, max=0.9886, mean=0.8946

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1531
焦点损失: 0.0130
边界损失: 0.2176
总损失: 0.0772
Epoch 5 [13/172] - loss: 0.0772
Epoch 5 [14/172] - loss: 0.1071
Epoch 5 [15/172] - loss: 0.0452
Epoch 5 [16/172] - loss: 0.0546
Epoch 5 [17/172] - loss: 0.1188
Epoch 5 [18/172] - loss: 0.0462
Epoch 5 [19/172] - loss: 0.1022
Epoch 5 [20/172] - loss: 0.1347, acc: 0.9688
Epoch 5 [21/172] - loss: 0.0928
Epoch 5 [22/172] - loss: 0.1678
Epoch 5 [23/172] - loss: 0.1076
Epoch 5 [24/172] - loss: 0.1939
Epoch 5 [25/172] - loss: 0.0529
Epoch 5 [26/172] - loss: 0.1301
Epoch 5 [27/172] - loss: 0.0676
Epoch 5 [28/172] - loss: 0.0597
Epoch 5 [29/172] - loss: 0.0546
Epoch 5 [30/172] - loss: 0.0635, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0616
Epoch 5 [32/172] - loss: 0.0499
Epoch 5 [33/172] - loss: 0.0567
Epoch 5 [34/172] - loss: 0.0653
Epoch 5 [35/172] - loss: 0.0650
Epoch 5 [36/172] - loss: 0.0467
Epoch 5 [37/172] - loss: 0.0545
Epoch 5 [38/172] - loss: 0.0462
Epoch 5 [39/172] - loss: 0.2233
Epoch 5 [40/172] - loss: 0.0622, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0552
Epoch 5 [42/172] - loss: 0.1153
Epoch 5 [43/172] - loss: 0.1361
Epoch 5 [44/172] - loss: 0.0778
Epoch 5 [45/172] - loss: 0.0497
Epoch 5 [46/172] - loss: 0.1069
Epoch 5 [47/172] - loss: 0.0463
Epoch 5 [48/172] - loss: 0.0693
Epoch 5 [49/172] - loss: 0.0520
Epoch 5 [50/172] - loss: 0.0791, acc: 0.9688
Epoch 5 [51/172] - loss: 0.1097
Epoch 5 [52/172] - loss: 0.0578
Epoch 5 [53/172] - loss: 0.1165
Epoch 5 [54/172] - loss: 0.0581
Epoch 5 [55/172] - loss: 0.0601
Epoch 5 [56/172] - loss: 0.0585
Epoch 5 [57/172] - loss: 0.0469
Epoch 5 [58/172] - loss: 0.0491
Epoch 5 [59/172] - loss: 0.1151
Epoch 5 [60/172] - loss: 0.0571, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0566
Epoch 5 [62/172] - loss: 0.0615
Epoch 5 [63/172] - loss: 0.1318
Epoch 5 [64/172] - loss: 0.0639
Epoch 5 [65/172] - loss: 0.0502
Epoch 5 [66/172] - loss: 0.0448
Epoch 5 [67/172] - loss: 0.0451
Epoch 5 [68/172] - loss: 0.0531
Epoch 5 [69/172] - loss: 0.0773
Epoch 5 [70/172] - loss: 0.0547, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0581
Epoch 5 [72/172] - loss: 0.1032
Epoch 5 [73/172] - loss: 0.0497
Epoch 5 [74/172] - loss: 0.2405
Epoch 5 [75/172] - loss: 0.0456
Epoch 5 [76/172] - loss: 0.0456
Epoch 5 [77/172] - loss: 0.0673
Epoch 5 [78/172] - loss: 0.0782
Epoch 5 [79/172] - loss: 0.0671
Epoch 5 [80/172] - loss: 0.0470, acc: 1.0000
Epoch 5 [81/172] - loss: 0.0638
Epoch 5 [82/172] - loss: 0.0969
Epoch 5 [83/172] - loss: 0.0558
Epoch 5 [84/172] - loss: 0.0461
Epoch 5 [85/172] - loss: 0.2069
Epoch 5 [86/172] - loss: 0.0823
Epoch 5 [87/172] - loss: 0.0559
Epoch 5 [88/172] - loss: 0.1142
Epoch 5 [89/172] - loss: 0.0478
Epoch 5 [90/172] - loss: 0.1768, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0598
Epoch 5 [92/172] - loss: 0.0426
Epoch 5 [93/172] - loss: 0.0503
Epoch 5 [94/172] - loss: 0.0666
Epoch 5 [95/172] - loss: 0.0770
Epoch 5 [96/172] - loss: 0.0479
Epoch 5 [97/172] - loss: 0.0761
Epoch 5 [98/172] - loss: 0.0929
Epoch 5 [99/172] - loss: 0.0766
Epoch 5 [100/172] - loss: 0.0651, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0522
Epoch 5 [102/172] - loss: 0.0918
Epoch 5 [103/172] - loss: 0.0521
Epoch 5 [104/172] - loss: 0.1241
Epoch 5 [105/172] - loss: 0.2372
Epoch 5 [106/172] - loss: 0.0627
Epoch 5 [107/172] - loss: 0.0626
Epoch 5 [108/172] - loss: 0.2033
Epoch 5 [109/172] - loss: 0.0423
Epoch 5 [110/172] - loss: 0.1389, acc: 0.9375
Epoch 5 [111/172] - loss: 0.0756
Epoch 5 [112/172] - loss: 0.0452

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2831, log_difficulty=0.2493, weight=2.2464
neutral: count=7825.0, difficulty=0.2211, log_difficulty=0.1997, weight=1.9987
negative: count=8780.0, difficulty=0.2830, log_difficulty=0.2492, weight=2.2459

当前batch的pt分布：
positive: min=0.3008, max=0.9973, mean=0.7625
neutral: min=0.7774, max=0.9598, mean=0.9005
negative: min=0.9805, max=0.9950, mean=0.9876

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8125
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2086
焦点损失: 0.0485
边界损失: 0.2140
总损失: 0.1350
Epoch 5 [113/172] - loss: 0.1350
Epoch 5 [114/172] - loss: 0.2473
Epoch 5 [115/172] - loss: 0.0510
Epoch 5 [116/172] - loss: 0.0480
Epoch 5 [117/172] - loss: 0.0589
Epoch 5 [118/172] - loss: 0.0498
Epoch 5 [119/172] - loss: 0.0458
Epoch 5 [120/172] - loss: 0.0571, acc: 0.9688
Epoch 5 [121/172] - loss: 0.0993
Epoch 5 [122/172] - loss: 0.0463
Epoch 5 [123/172] - loss: 0.0887
Epoch 5 [124/172] - loss: 0.0435
Epoch 5 [125/172] - loss: 0.0670
Epoch 5 [126/172] - loss: 0.0428
Epoch 5 [127/172] - loss: 0.0704
Epoch 5 [128/172] - loss: 0.0457
Epoch 5 [129/172] - loss: 0.1037
Epoch 5 [130/172] - loss: 0.0522, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0740
Epoch 5 [132/172] - loss: 0.1882
Epoch 5 [133/172] - loss: 0.0823
Epoch 5 [134/172] - loss: 0.0853
Epoch 5 [135/172] - loss: 0.0737
Epoch 5 [136/172] - loss: 0.0508
Epoch 5 [137/172] - loss: 0.0710
Epoch 5 [138/172] - loss: 0.0788
Epoch 5 [139/172] - loss: 0.2200
Epoch 5 [140/172] - loss: 0.0714, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0449
Epoch 5 [142/172] - loss: 0.0523
Epoch 5 [143/172] - loss: 0.0702
Epoch 5 [144/172] - loss: 0.0484
Epoch 5 [145/172] - loss: 0.1549
Epoch 5 [146/172] - loss: 0.0455
Epoch 5 [147/172] - loss: 0.0747
Epoch 5 [148/172] - loss: 0.0470
Epoch 5 [149/172] - loss: 0.0613
Epoch 5 [150/172] - loss: 0.1292, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0528
Epoch 5 [152/172] - loss: 0.0439
Epoch 5 [153/172] - loss: 0.0473
Epoch 5 [154/172] - loss: 0.0453
Epoch 5 [155/172] - loss: 0.0455
Epoch 5 [156/172] - loss: 0.1208
Epoch 5 [157/172] - loss: 0.0499
Epoch 5 [158/172] - loss: 0.0506
Epoch 5 [159/172] - loss: 0.0436
Epoch 5 [160/172] - loss: 0.0488, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0417
Epoch 5 [162/172] - loss: 0.0712
Epoch 5 [163/172] - loss: 0.0824
Epoch 5 [164/172] - loss: 0.0414
Epoch 5 [165/172] - loss: 0.1412
Epoch 5 [166/172] - loss: 0.0666
Epoch 5 [167/172] - loss: 0.0596
Epoch 5 [168/172] - loss: 0.0432
Epoch 5 [169/172] - loss: 0.0502
Epoch 5 [170/172] - loss: 0.0541, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0713
Epoch 5 [172/172] - loss: 0.0831

类别准确率:
positive: 0.7859 (367/467)
neutral: 0.3976 (33/83)
negative: 0.6880 (172/250)

Epoch 5/10
Train Loss: 0.0624, Train Acc: 0.9939
Val Loss: 0.8280, Val Acc: 0.7150
Epoch 6 [1/172] - loss: 0.1175, acc: 0.9375
Epoch 6 [2/172] - loss: 0.0838
Epoch 6 [3/172] - loss: 0.0404
Epoch 6 [4/172] - loss: 0.0527
Epoch 6 [5/172] - loss: 0.1160
Epoch 6 [6/172] - loss: 0.0432
Epoch 6 [7/172] - loss: 0.0707
Epoch 6 [8/172] - loss: 0.0879
Epoch 6 [9/172] - loss: 0.0528
Epoch 6 [10/172] - loss: 0.0426, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0390
Epoch 6 [12/172] - loss: 0.0434
Epoch 6 [13/172] - loss: 0.0525
Epoch 6 [14/172] - loss: 0.0502
Epoch 6 [15/172] - loss: 0.0563
Epoch 6 [16/172] - loss: 0.1270
Epoch 6 [17/172] - loss: 0.0593
Epoch 6 [18/172] - loss: 0.0456
Epoch 6 [19/172] - loss: 0.0432
Epoch 6 [20/172] - loss: 0.0414, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0586
Epoch 6 [22/172] - loss: 0.0425
Epoch 6 [23/172] - loss: 0.0492
Epoch 6 [24/172] - loss: 0.0456
Epoch 6 [25/172] - loss: 0.0426
Epoch 6 [26/172] - loss: 0.0625
Epoch 6 [27/172] - loss: 0.0559
Epoch 6 [28/172] - loss: 0.0656
Epoch 6 [29/172] - loss: 0.0578
Epoch 6 [30/172] - loss: 0.0486, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0473
Epoch 6 [32/172] - loss: 0.0439
Epoch 6 [33/172] - loss: 0.0482
Epoch 6 [34/172] - loss: 0.0433
Epoch 6 [35/172] - loss: 0.0463
Epoch 6 [36/172] - loss: 0.0443
Epoch 6 [37/172] - loss: 0.0439
Epoch 6 [38/172] - loss: 0.0493
Epoch 6 [39/172] - loss: 0.0487
Epoch 6 [40/172] - loss: 0.0531, acc: 1.0000

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2616, log_difficulty=0.2324, weight=2.1619
neutral: count=8815.0, difficulty=0.2053, log_difficulty=0.1868, weight=1.9338
negative: count=9870.0, difficulty=0.2614, log_difficulty=0.2322, weight=2.1610

当前batch的pt分布：
positive: min=0.5032, max=0.9943, mean=0.9093
neutral: min=0.8880, max=0.9961, mean=0.9572
negative: min=0.8294, max=0.9710, mean=0.9234

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0805
焦点损失: 0.0056
边界损失: 0.1754
总损失: 0.0530
Epoch 6 [41/172] - loss: 0.0530
Epoch 6 [42/172] - loss: 0.0458
Epoch 6 [43/172] - loss: 0.1560
Epoch 6 [44/172] - loss: 0.0403
Epoch 6 [45/172] - loss: 0.0784
Epoch 6 [46/172] - loss: 0.0654
Epoch 6 [47/172] - loss: 0.0474
Epoch 6 [48/172] - loss: 0.0515
Epoch 6 [49/172] - loss: 0.0616
Epoch 6 [50/172] - loss: 0.0884, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0569
Epoch 6 [52/172] - loss: 0.0529
Epoch 6 [53/172] - loss: 0.0457
Epoch 6 [54/172] - loss: 0.0847
Epoch 6 [55/172] - loss: 0.0600
Epoch 6 [56/172] - loss: 0.0894
Epoch 6 [57/172] - loss: 0.0416
Epoch 6 [58/172] - loss: 0.0405
Epoch 6 [59/172] - loss: 0.1299
Epoch 6 [60/172] - loss: 0.0616, acc: 0.9688
Epoch 6 [61/172] - loss: 0.0445
Epoch 6 [62/172] - loss: 0.0458
Epoch 6 [63/172] - loss: 0.0433
Epoch 6 [64/172] - loss: 0.1698
Epoch 6 [65/172] - loss: 0.0680
Epoch 6 [66/172] - loss: 0.0516
Epoch 6 [67/172] - loss: 0.0447
Epoch 6 [68/172] - loss: 0.1488
Epoch 6 [69/172] - loss: 0.1162
Epoch 6 [70/172] - loss: 0.0425, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0509
Epoch 6 [72/172] - loss: 0.0455
Epoch 6 [73/172] - loss: 0.0733
Epoch 6 [74/172] - loss: 0.0418
Epoch 6 [75/172] - loss: 0.0513
Epoch 6 [76/172] - loss: 0.0536
Epoch 6 [77/172] - loss: 0.0541
Epoch 6 [78/172] - loss: 0.0624
Epoch 6 [79/172] - loss: 0.0414
Epoch 6 [80/172] - loss: 0.0419, acc: 1.0000
Epoch 6 [81/172] - loss: 0.0722
Epoch 6 [82/172] - loss: 0.0460
Epoch 6 [83/172] - loss: 0.0474
Epoch 6 [84/172] - loss: 0.0440
Epoch 6 [85/172] - loss: 0.1081
Epoch 6 [86/172] - loss: 0.0897
Epoch 6 [87/172] - loss: 0.0587
Epoch 6 [88/172] - loss: 0.1205
Epoch 6 [89/172] - loss: 0.0439
Epoch 6 [90/172] - loss: 0.0417, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0613
Epoch 6 [92/172] - loss: 0.0903
Epoch 6 [93/172] - loss: 0.0593
Epoch 6 [94/172] - loss: 0.1118
Epoch 6 [95/172] - loss: 0.0820
Epoch 6 [96/172] - loss: 0.0728
Epoch 6 [97/172] - loss: 0.0604
Epoch 6 [98/172] - loss: 0.0601
Epoch 6 [99/172] - loss: 0.0571
Epoch 6 [100/172] - loss: 0.1396, acc: 0.9688
Epoch 6 [101/172] - loss: 0.0689
Epoch 6 [102/172] - loss: 0.0432
Epoch 6 [103/172] - loss: 0.0486
Epoch 6 [104/172] - loss: 0.0973
Epoch 6 [105/172] - loss: 0.1053
Epoch 6 [106/172] - loss: 0.0550
Epoch 6 [107/172] - loss: 0.0783
Epoch 6 [108/172] - loss: 0.0446
Epoch 6 [109/172] - loss: 0.2075
Epoch 6 [110/172] - loss: 0.0623, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0519
Epoch 6 [112/172] - loss: 0.0777
Epoch 6 [113/172] - loss: 0.2586
Epoch 6 [114/172] - loss: 0.0539
Epoch 6 [115/172] - loss: 0.0906
Epoch 6 [116/172] - loss: 0.2294
Epoch 6 [117/172] - loss: 0.0686
Epoch 6 [118/172] - loss: 0.0523
Epoch 6 [119/172] - loss: 0.1663
Epoch 6 [120/172] - loss: 0.0502, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0499
Epoch 6 [122/172] - loss: 0.1019
Epoch 6 [123/172] - loss: 0.0568
Epoch 6 [124/172] - loss: 0.0695
Epoch 6 [125/172] - loss: 0.0988
Epoch 6 [126/172] - loss: 0.1822
Epoch 6 [127/172] - loss: 0.0743
Epoch 6 [128/172] - loss: 0.0646
Epoch 6 [129/172] - loss: 0.1001
Epoch 6 [130/172] - loss: 0.0910, acc: 0.9688
Epoch 6 [131/172] - loss: 0.0600
Epoch 6 [132/172] - loss: 0.0858
Epoch 6 [133/172] - loss: 0.0578
Epoch 6 [134/172] - loss: 0.0935
Epoch 6 [135/172] - loss: 0.0934
Epoch 6 [136/172] - loss: 0.0438
Epoch 6 [137/172] - loss: 0.0552
Epoch 6 [138/172] - loss: 0.0616
Epoch 6 [139/172] - loss: 0.0415
Epoch 6 [140/172] - loss: 0.0592, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2448, log_difficulty=0.2190, weight=2.0949
neutral: count=9796.0, difficulty=0.1923, log_difficulty=0.1759, weight=1.8795
negative: count=10972.0, difficulty=0.2444, log_difficulty=0.2187, weight=2.0933

当前batch的pt分布：
positive: min=0.8234, max=0.9920, mean=0.9490
neutral: min=0.8628, max=0.9930, mean=0.9589
negative: min=0.2185, max=0.9851, mean=0.8639

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9231

损失分量：
基础交叉熵: 0.1092
焦点损失: 0.0288
边界损失: 0.1718
总损失: 0.0881
Epoch 6 [141/172] - loss: 0.0881
Epoch 6 [142/172] - loss: 0.0418
Epoch 6 [143/172] - loss: 0.0642
Epoch 6 [144/172] - loss: 0.0457
Epoch 6 [145/172] - loss: 0.0476
Epoch 6 [146/172] - loss: 0.0532
Epoch 6 [147/172] - loss: 0.0457
Epoch 6 [148/172] - loss: 0.0602
Epoch 6 [149/172] - loss: 0.0464
Epoch 6 [150/172] - loss: 0.0439, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0804
Epoch 6 [152/172] - loss: 0.1026
Epoch 6 [153/172] - loss: 0.1467
Epoch 6 [154/172] - loss: 0.0462
Epoch 6 [155/172] - loss: 0.0829
Epoch 6 [156/172] - loss: 0.0679
Epoch 6 [157/172] - loss: 0.0470
Epoch 6 [158/172] - loss: 0.0506
Epoch 6 [159/172] - loss: 0.0598
Epoch 6 [160/172] - loss: 0.2628, acc: 0.9375
Epoch 6 [161/172] - loss: 0.0477
Epoch 6 [162/172] - loss: 0.0534
Epoch 6 [163/172] - loss: 0.0512
Epoch 6 [164/172] - loss: 0.0799
Epoch 6 [165/172] - loss: 0.2511
Epoch 6 [166/172] - loss: 0.1103
Epoch 6 [167/172] - loss: 0.0468
Epoch 6 [168/172] - loss: 0.1093
Epoch 6 [169/172] - loss: 0.0951
Epoch 6 [170/172] - loss: 0.0440, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0413
Epoch 6 [172/172] - loss: 0.0480

类别准确率:
positive: 0.9186 (429/467)
neutral: 0.1687 (14/83)
negative: 0.4000 (100/250)

Epoch 6/10
Train Loss: 0.0874, Train Acc: 0.9737
Val Loss: 1.0274, Val Acc: 0.6787
Epoch 7 [1/172] - loss: 0.0455, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0477
Epoch 7 [3/172] - loss: 0.0421
Epoch 7 [4/172] - loss: 0.0478
Epoch 7 [5/172] - loss: 0.0403
Epoch 7 [6/172] - loss: 0.0425
Epoch 7 [7/172] - loss: 0.1266
Epoch 7 [8/172] - loss: 0.0901
Epoch 7 [9/172] - loss: 0.0404
Epoch 7 [10/172] - loss: 0.0431, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0467
Epoch 7 [12/172] - loss: 0.0796
Epoch 7 [13/172] - loss: 0.0451
Epoch 7 [14/172] - loss: 0.0521
Epoch 7 [15/172] - loss: 0.0625
Epoch 7 [16/172] - loss: 0.0718
Epoch 7 [17/172] - loss: 0.1010
Epoch 7 [18/172] - loss: 0.0452
Epoch 7 [19/172] - loss: 0.0460
Epoch 7 [20/172] - loss: 0.0479, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0514
Epoch 7 [22/172] - loss: 0.0802
Epoch 7 [23/172] - loss: 0.0446
Epoch 7 [24/172] - loss: 0.0420
Epoch 7 [25/172] - loss: 0.0444
Epoch 7 [26/172] - loss: 0.0712
Epoch 7 [27/172] - loss: 0.0445
Epoch 7 [28/172] - loss: 0.0619
Epoch 7 [29/172] - loss: 0.0751
Epoch 7 [30/172] - loss: 0.1038, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0774
Epoch 7 [32/172] - loss: 0.0429
Epoch 7 [33/172] - loss: 0.0467
Epoch 7 [34/172] - loss: 0.0431
Epoch 7 [35/172] - loss: 0.0666
Epoch 7 [36/172] - loss: 0.1795
Epoch 7 [37/172] - loss: 0.0438
Epoch 7 [38/172] - loss: 0.0405
Epoch 7 [39/172] - loss: 0.0440
Epoch 7 [40/172] - loss: 0.0488, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0493
Epoch 7 [42/172] - loss: 0.0418
Epoch 7 [43/172] - loss: 0.0460
Epoch 7 [44/172] - loss: 0.0665
Epoch 7 [45/172] - loss: 0.2101
Epoch 7 [46/172] - loss: 0.0759
Epoch 7 [47/172] - loss: 0.0545
Epoch 7 [48/172] - loss: 0.0415
Epoch 7 [49/172] - loss: 0.0410
Epoch 7 [50/172] - loss: 0.0441, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1382
Epoch 7 [52/172] - loss: 0.0599
Epoch 7 [53/172] - loss: 0.0407
Epoch 7 [54/172] - loss: 0.0497
Epoch 7 [55/172] - loss: 0.0472
Epoch 7 [56/172] - loss: 0.0470
Epoch 7 [57/172] - loss: 0.1009
Epoch 7 [58/172] - loss: 0.0573
Epoch 7 [59/172] - loss: 0.0395
Epoch 7 [60/172] - loss: 0.0566, acc: 1.0000
Epoch 7 [61/172] - loss: 0.0507
Epoch 7 [62/172] - loss: 0.0471
Epoch 7 [63/172] - loss: 0.1196
Epoch 7 [64/172] - loss: 0.0463
Epoch 7 [65/172] - loss: 0.0658
Epoch 7 [66/172] - loss: 0.0454
Epoch 7 [67/172] - loss: 0.0505
Epoch 7 [68/172] - loss: 0.1159

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.2299, log_difficulty=0.2070, weight=2.0348
neutral: count=10756.0, difficulty=0.1813, log_difficulty=0.1666, weight=1.8329
negative: count=12072.0, difficulty=0.2297, log_difficulty=0.2068, weight=2.0340

当前batch的pt分布：
positive: min=0.7459, max=0.9985, mean=0.9375
neutral: min=0.6072, max=0.9908, mean=0.9210
negative: min=0.3433, max=0.9697, mean=0.8904

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9286

损失分量：
基础交叉熵: 0.1068
焦点损失: 0.0170
边界损失: 0.1787
总损失: 0.0702
Epoch 7 [69/172] - loss: 0.0702
Epoch 7 [70/172] - loss: 0.0511, acc: 1.0000
Epoch 7 [71/172] - loss: 0.0550
Epoch 7 [72/172] - loss: 0.0684
Epoch 7 [73/172] - loss: 0.0487
Epoch 7 [74/172] - loss: 0.0414
Epoch 7 [75/172] - loss: 0.0401
Epoch 7 [76/172] - loss: 0.0455
Epoch 7 [77/172] - loss: 0.0437
Epoch 7 [78/172] - loss: 0.0431
Epoch 7 [79/172] - loss: 0.0497
Epoch 7 [80/172] - loss: 0.0576, acc: 0.9688
Epoch 7 [81/172] - loss: 0.0423
Epoch 7 [82/172] - loss: 0.0423
Epoch 7 [83/172] - loss: 0.0497
Epoch 7 [84/172] - loss: 0.0413
Epoch 7 [85/172] - loss: 0.0465
Epoch 7 [86/172] - loss: 0.0432
Epoch 7 [87/172] - loss: 0.0450
Epoch 7 [88/172] - loss: 0.0452
Epoch 7 [89/172] - loss: 0.0660
Epoch 7 [90/172] - loss: 0.0441, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0446
Epoch 7 [92/172] - loss: 0.0503
Epoch 7 [93/172] - loss: 0.1161
Epoch 7 [94/172] - loss: 0.0432
Epoch 7 [95/172] - loss: 0.0423
Epoch 7 [96/172] - loss: 0.0442
Epoch 7 [97/172] - loss: 0.0937
Epoch 7 [98/172] - loss: 0.0648
Epoch 7 [99/172] - loss: 0.0529
Epoch 7 [100/172] - loss: 0.0410, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0420
Epoch 7 [102/172] - loss: 0.0424
Epoch 7 [103/172] - loss: 0.0419
Epoch 7 [104/172] - loss: 0.1949
Epoch 7 [105/172] - loss: 0.0468
Epoch 7 [106/172] - loss: 0.0717
Epoch 7 [107/172] - loss: 0.0448
Epoch 7 [108/172] - loss: 0.0417
Epoch 7 [109/172] - loss: 0.0528
Epoch 7 [110/172] - loss: 0.0906, acc: 0.9688
Epoch 7 [111/172] - loss: 0.0442
Epoch 7 [112/172] - loss: 0.0640
Epoch 7 [113/172] - loss: 0.0409
Epoch 7 [114/172] - loss: 0.0541
Epoch 7 [115/172] - loss: 0.0441
Epoch 7 [116/172] - loss: 0.0776
Epoch 7 [117/172] - loss: 0.0505
Epoch 7 [118/172] - loss: 0.0512
Epoch 7 [119/172] - loss: 0.0541
Epoch 7 [120/172] - loss: 0.0429, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0547
Epoch 7 [122/172] - loss: 0.0453
Epoch 7 [123/172] - loss: 0.0401
Epoch 7 [124/172] - loss: 0.0547
Epoch 7 [125/172] - loss: 0.0430
Epoch 7 [126/172] - loss: 0.0451
Epoch 7 [127/172] - loss: 0.0515
Epoch 7 [128/172] - loss: 0.0511
Epoch 7 [129/172] - loss: 0.0439
Epoch 7 [130/172] - loss: 0.0428, acc: 1.0000
Epoch 7 [131/172] - loss: 0.0556
Epoch 7 [132/172] - loss: 0.1992
Epoch 7 [133/172] - loss: 0.0410
Epoch 7 [134/172] - loss: 0.0710
Epoch 7 [135/172] - loss: 0.0456
Epoch 7 [136/172] - loss: 0.0406
Epoch 7 [137/172] - loss: 0.0944
Epoch 7 [138/172] - loss: 0.0441
Epoch 7 [139/172] - loss: 0.0905
Epoch 7 [140/172] - loss: 0.0522, acc: 1.0000
Epoch 7 [141/172] - loss: 0.0638
Epoch 7 [142/172] - loss: 0.0412
Epoch 7 [143/172] - loss: 0.0601
Epoch 7 [144/172] - loss: 0.0437
Epoch 7 [145/172] - loss: 0.0459
Epoch 7 [146/172] - loss: 0.0582
Epoch 7 [147/172] - loss: 0.0500
Epoch 7 [148/172] - loss: 0.0480
Epoch 7 [149/172] - loss: 0.0425
Epoch 7 [150/172] - loss: 0.0524, acc: 1.0000
Epoch 7 [151/172] - loss: 0.0903
Epoch 7 [152/172] - loss: 0.0382
Epoch 7 [153/172] - loss: 0.0391
Epoch 7 [154/172] - loss: 0.0513
Epoch 7 [155/172] - loss: 0.0438
Epoch 7 [156/172] - loss: 0.0733
Epoch 7 [157/172] - loss: 0.0491
Epoch 7 [158/172] - loss: 0.0432
Epoch 7 [159/172] - loss: 0.0428
Epoch 7 [160/172] - loss: 0.0394, acc: 1.0000
Epoch 7 [161/172] - loss: 0.0431
Epoch 7 [162/172] - loss: 0.0432
Epoch 7 [163/172] - loss: 0.0463
Epoch 7 [164/172] - loss: 0.0515
Epoch 7 [165/172] - loss: 0.0575
Epoch 7 [166/172] - loss: 0.0427
Epoch 7 [167/172] - loss: 0.0715
Epoch 7 [168/172] - loss: 0.0539

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.2164, log_difficulty=0.1959, weight=1.9795
neutral: count=11731.0, difficulty=0.1717, log_difficulty=0.1585, weight=1.7923
negative: count=13173.0, difficulty=0.2165, log_difficulty=0.1960, weight=1.9800

当前batch的pt分布：
positive: min=0.8911, max=0.9926, mean=0.9589
neutral: min=0.8516, max=0.9938, mean=0.9553
negative: min=0.8819, max=0.9872, mean=0.9453

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0491
焦点损失: 0.0003
边界损失: 0.1595
总损失: 0.0403
Epoch 7 [169/172] - loss: 0.0403
Epoch 7 [170/172] - loss: 0.0480, acc: 1.0000
Epoch 7 [171/172] - loss: 0.0420
Epoch 7 [172/172] - loss: 0.0424

类别准确率:
positive: 0.8544 (399/467)
neutral: 0.1928 (16/83)
negative: 0.5800 (145/250)

Epoch 7/10
Train Loss: 0.0473, Train Acc: 0.9980
Val Loss: 0.9198, Val Acc: 0.7000
Early stopping triggered!
Best validation accuracy: 0.7150

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_111722-j7zqp84p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.3_Multimodal_iterations_20250118_111721
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/j7zqp84p
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████
wandb:  train_acc ▁▁▅▃▄▆▄▆▆▇███▇▆█▇▆██▇▇▆█████████████████
wandb: train_loss █▅▆▅▅▅▅▆▂▄▄▂▂▃▂▂▂▁▂▁▂▁▃▂▁▁▂▂▁▂▁▁▁▃▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 1
wandb: train_loss 0.04796
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.3_Multimodal_iterations_20250118_111721 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/j7zqp84p
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_111722-j7zqp84p/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_112815-pzdi3j3c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.3_Multimodal_epochs_20250118_112815
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/pzdi3j3c
wandb: uploading history steps 0-0, summary; updating run config; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▅▇▇█▇█
wandb: train_loss █▃▂▂▁▁▁
wandb:    val_acc ▁▇▇██▆▇
wandb:   val_loss ▆▁▁▂▃█▆
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.99798
wandb: train_loss 0.0473
wandb:    val_acc 0.7
wandb:   val_loss 0.91982
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.3_Multimodal_epochs_20250118_112815 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/pzdi3j3c
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_112815-pzdi3j3c/logs

