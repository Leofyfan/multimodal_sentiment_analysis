=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 0.5 --dropout 0.25 --name loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.25 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.25
text_dim: 128
image_dim: 256
dropout: 0.25
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6942, log_difficulty=0.5272, weight=3.6360
neutral: count=7.0, difficulty=0.7003, log_difficulty=0.5308, weight=3.6541
negative: count=13.0, difficulty=0.6688, log_difficulty=0.5121, weight=3.5607

当前batch的pt分布：
positive: min=0.1709, max=0.5028, mean=0.3058
neutral: min=0.1817, max=0.3830, mean=0.2997
negative: min=0.2239, max=0.4313, mean=0.3312

当前batch准确率：
整体准确率: 0.1875
positive 准确率: 0.1667
neutral 准确率: 0.1429
negative 准确率: 0.2308

损失分量：
基础交叉熵: 1.1930
焦点损失: 0.4243
边界损失: 0.7717
总损失: 1.1527
Epoch 1 [1/172] - loss: 1.1527, acc: 0.1875
Epoch 1 [2/172] - loss: 1.0115
Epoch 1 [3/172] - loss: 1.0709
Epoch 1 [4/172] - loss: 1.1411
Epoch 1 [5/172] - loss: 1.1929
Epoch 1 [6/172] - loss: 1.2370
Epoch 1 [7/172] - loss: 1.2993
Epoch 1 [8/172] - loss: 1.0237
Epoch 1 [9/172] - loss: 0.8617
Epoch 1 [10/172] - loss: 1.0708, acc: 0.3750
Epoch 1 [11/172] - loss: 1.1213
Epoch 1 [12/172] - loss: 0.9685
Epoch 1 [13/172] - loss: 0.8259
Epoch 1 [14/172] - loss: 1.0928
Epoch 1 [15/172] - loss: 1.0855
Epoch 1 [16/172] - loss: 0.9773
Epoch 1 [17/172] - loss: 1.1002
Epoch 1 [18/172] - loss: 1.0779
Epoch 1 [19/172] - loss: 1.1342
Epoch 1 [20/172] - loss: 1.0854, acc: 0.3750
Epoch 1 [21/172] - loss: 0.9031
Epoch 1 [22/172] - loss: 0.9348
Epoch 1 [23/172] - loss: 0.9509
Epoch 1 [24/172] - loss: 1.0304
Epoch 1 [25/172] - loss: 0.8693
Epoch 1 [26/172] - loss: 0.9971
Epoch 1 [27/172] - loss: 1.1263
Epoch 1 [28/172] - loss: 0.6863
Epoch 1 [29/172] - loss: 0.8001
Epoch 1 [30/172] - loss: 0.7568, acc: 0.6250
Epoch 1 [31/172] - loss: 0.8771
Epoch 1 [32/172] - loss: 0.7596
Epoch 1 [33/172] - loss: 1.0242
Epoch 1 [34/172] - loss: 0.6756
Epoch 1 [35/172] - loss: 0.7859
Epoch 1 [36/172] - loss: 0.6125
Epoch 1 [37/172] - loss: 0.7398
Epoch 1 [38/172] - loss: 0.8243
Epoch 1 [39/172] - loss: 0.6578
Epoch 1 [40/172] - loss: 0.8798, acc: 0.4062
Epoch 1 [41/172] - loss: 0.7997
Epoch 1 [42/172] - loss: 0.6939
Epoch 1 [43/172] - loss: 1.0330
Epoch 1 [44/172] - loss: 0.7586
Epoch 1 [45/172] - loss: 1.0154
Epoch 1 [46/172] - loss: 0.6385
Epoch 1 [47/172] - loss: 0.8918
Epoch 1 [48/172] - loss: 0.8608
Epoch 1 [49/172] - loss: 1.0721
Epoch 1 [50/172] - loss: 0.7333, acc: 0.6250
Epoch 1 [51/172] - loss: 0.7916
Epoch 1 [52/172] - loss: 0.7513
Epoch 1 [53/172] - loss: 0.7522
Epoch 1 [54/172] - loss: 0.9282
Epoch 1 [55/172] - loss: 0.7969
Epoch 1 [56/172] - loss: 0.7157
Epoch 1 [57/172] - loss: 0.8738
Epoch 1 [58/172] - loss: 0.6079
Epoch 1 [59/172] - loss: 0.7931
Epoch 1 [60/172] - loss: 0.6511, acc: 0.6875
Epoch 1 [61/172] - loss: 0.7261
Epoch 1 [62/172] - loss: 0.8414
Epoch 1 [63/172] - loss: 0.6859
Epoch 1 [64/172] - loss: 0.5916
Epoch 1 [65/172] - loss: 0.7533
Epoch 1 [66/172] - loss: 0.8866
Epoch 1 [67/172] - loss: 0.7133
Epoch 1 [68/172] - loss: 0.9769
Epoch 1 [69/172] - loss: 0.7066
Epoch 1 [70/172] - loss: 0.5263, acc: 0.7812
Epoch 1 [71/172] - loss: 0.5247
Epoch 1 [72/172] - loss: 0.6320
Epoch 1 [73/172] - loss: 0.5610
Epoch 1 [74/172] - loss: 0.6743
Epoch 1 [75/172] - loss: 0.5068
Epoch 1 [76/172] - loss: 0.6534
Epoch 1 [77/172] - loss: 0.5016
Epoch 1 [78/172] - loss: 0.6014
Epoch 1 [79/172] - loss: 0.7128
Epoch 1 [80/172] - loss: 0.3478, acc: 0.8750
Epoch 1 [81/172] - loss: 0.7018
Epoch 1 [82/172] - loss: 0.7352
Epoch 1 [83/172] - loss: 0.8559
Epoch 1 [84/172] - loss: 0.7267
Epoch 1 [85/172] - loss: 0.5629
Epoch 1 [86/172] - loss: 0.6953
Epoch 1 [87/172] - loss: 0.7044
Epoch 1 [88/172] - loss: 1.0549
Epoch 1 [89/172] - loss: 1.2132
Epoch 1 [90/172] - loss: 0.6285, acc: 0.6562
Epoch 1 [91/172] - loss: 0.6274
Epoch 1 [92/172] - loss: 0.7711
Epoch 1 [93/172] - loss: 0.6327
Epoch 1 [94/172] - loss: 0.4549
Epoch 1 [95/172] - loss: 0.4844
Epoch 1 [96/172] - loss: 0.5600
Epoch 1 [97/172] - loss: 0.5148
Epoch 1 [98/172] - loss: 0.6068
Epoch 1 [99/172] - loss: 0.6666
Epoch 1 [100/172] - loss: 0.5301, acc: 0.6875

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5607, log_difficulty=0.4452, weight=3.2258
neutral: count=983.0, difficulty=0.5307, log_difficulty=0.4257, weight=3.1285
negative: count=1119.0, difficulty=0.5383, log_difficulty=0.4307, weight=3.1535

当前batch的pt分布：
positive: min=0.0650, max=0.8755, mean=0.3904
neutral: min=0.4644, max=0.9590, mean=0.7260
negative: min=0.0771, max=0.5745, mean=0.4249

当前batch准确率：
整体准确率: 0.5938
positive 准确率: 0.4167
neutral 准确率: 1.0000
negative 准确率: 0.6250

损失分量：
基础交叉熵: 0.9632
焦点损失: 0.3959
边界损失: 0.5268
总损失: 0.8960
Epoch 1 [101/172] - loss: 0.8960
Epoch 1 [102/172] - loss: 0.7156
Epoch 1 [103/172] - loss: 0.6035
Epoch 1 [104/172] - loss: 0.4824
Epoch 1 [105/172] - loss: 0.7657
Epoch 1 [106/172] - loss: 0.7771
Epoch 1 [107/172] - loss: 0.5115
Epoch 1 [108/172] - loss: 0.6507
Epoch 1 [109/172] - loss: 0.5824
Epoch 1 [110/172] - loss: 0.7302, acc: 0.6250
Epoch 1 [111/172] - loss: 0.8082
Epoch 1 [112/172] - loss: 0.4840
Epoch 1 [113/172] - loss: 0.3866
Epoch 1 [114/172] - loss: 0.7241
Epoch 1 [115/172] - loss: 0.5393
Epoch 1 [116/172] - loss: 0.7885
Epoch 1 [117/172] - loss: 0.4981
Epoch 1 [118/172] - loss: 0.5455
Epoch 1 [119/172] - loss: 0.4629
Epoch 1 [120/172] - loss: 0.4768, acc: 0.8125
Epoch 1 [121/172] - loss: 0.4540
Epoch 1 [122/172] - loss: 0.6754
Epoch 1 [123/172] - loss: 0.4236
Epoch 1 [124/172] - loss: 0.4083
Epoch 1 [125/172] - loss: 0.3645
Epoch 1 [126/172] - loss: 0.7071
Epoch 1 [127/172] - loss: 0.4815
Epoch 1 [128/172] - loss: 0.4114
Epoch 1 [129/172] - loss: 0.5626
Epoch 1 [130/172] - loss: 0.4173, acc: 0.7500
Epoch 1 [131/172] - loss: 0.3494
Epoch 1 [132/172] - loss: 0.4412
Epoch 1 [133/172] - loss: 0.5392
Epoch 1 [134/172] - loss: 0.4468
Epoch 1 [135/172] - loss: 0.4362
Epoch 1 [136/172] - loss: 0.5709
Epoch 1 [137/172] - loss: 0.4468
Epoch 1 [138/172] - loss: 0.4721
Epoch 1 [139/172] - loss: 0.3263
Epoch 1 [140/172] - loss: 0.4124, acc: 0.7812
Epoch 1 [141/172] - loss: 0.4201
Epoch 1 [142/172] - loss: 0.4456
Epoch 1 [143/172] - loss: 0.5622
Epoch 1 [144/172] - loss: 0.2683
Epoch 1 [145/172] - loss: 0.5662
Epoch 1 [146/172] - loss: 0.8292
Epoch 1 [147/172] - loss: 0.7679
Epoch 1 [148/172] - loss: 0.5137
Epoch 1 [149/172] - loss: 0.4544
Epoch 1 [150/172] - loss: 0.4698, acc: 0.7500
Epoch 1 [151/172] - loss: 0.4687
Epoch 1 [152/172] - loss: 0.4595
Epoch 1 [153/172] - loss: 0.3432
Epoch 1 [154/172] - loss: 0.4152
Epoch 1 [155/172] - loss: 0.5893
Epoch 1 [156/172] - loss: 0.7262
Epoch 1 [157/172] - loss: 0.5894
Epoch 1 [158/172] - loss: 0.3397
Epoch 1 [159/172] - loss: 0.6068
Epoch 1 [160/172] - loss: 0.4560, acc: 0.7500
Epoch 1 [161/172] - loss: 0.3891
Epoch 1 [162/172] - loss: 0.4617
Epoch 1 [163/172] - loss: 0.4520
Epoch 1 [164/172] - loss: 0.4663
Epoch 1 [165/172] - loss: 0.3891
Epoch 1 [166/172] - loss: 0.4343
Epoch 1 [167/172] - loss: 0.3863
Epoch 1 [168/172] - loss: 0.5045
Epoch 1 [169/172] - loss: 0.4528
Epoch 1 [170/172] - loss: 0.4322, acc: 0.7500
Epoch 1 [171/172] - loss: 0.3590
Epoch 1 [172/172] - loss: 0.5979

类别准确率:
positive: 0.7323 (342/467)
neutral: 0.4578 (38/83)
negative: 0.7480 (187/250)

Epoch 1/10
Train Loss: 0.4573, Train Acc: 0.7838
Val Loss: 0.7105, Val Acc: 0.7087
Epoch 2 [1/172] - loss: 0.2623, acc: 0.8750
Epoch 2 [2/172] - loss: 0.2637
Epoch 2 [3/172] - loss: 0.2646
Epoch 2 [4/172] - loss: 0.2858
Epoch 2 [5/172] - loss: 0.5090
Epoch 2 [6/172] - loss: 0.3995
Epoch 2 [7/172] - loss: 0.4691
Epoch 2 [8/172] - loss: 0.5426
Epoch 2 [9/172] - loss: 0.2495
Epoch 2 [10/172] - loss: 0.4620, acc: 0.8125
Epoch 2 [11/172] - loss: 0.2574
Epoch 2 [12/172] - loss: 0.2431
Epoch 2 [13/172] - loss: 0.4534
Epoch 2 [14/172] - loss: 0.4529
Epoch 2 [15/172] - loss: 0.3492
Epoch 2 [16/172] - loss: 0.3494
Epoch 2 [17/172] - loss: 0.3791
Epoch 2 [18/172] - loss: 0.6154
Epoch 2 [19/172] - loss: 0.3644
Epoch 2 [20/172] - loss: 0.3540, acc: 0.8750
Epoch 2 [21/172] - loss: 0.3180
Epoch 2 [22/172] - loss: 0.3840
Epoch 2 [23/172] - loss: 0.1925
Epoch 2 [24/172] - loss: 0.7846
Epoch 2 [25/172] - loss: 0.4305
Epoch 2 [26/172] - loss: 0.2068
Epoch 2 [27/172] - loss: 0.2220
Epoch 2 [28/172] - loss: 0.2614

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4886, log_difficulty=0.3978, weight=2.9892
neutral: count=1952.0, difficulty=0.4156, log_difficulty=0.3476, weight=2.7379
negative: count=2216.0, difficulty=0.4644, log_difficulty=0.3814, weight=2.9072

当前batch的pt分布：
positive: min=0.3700, max=0.9446, mean=0.7504
neutral: min=0.5656, max=0.9585, mean=0.8271
negative: min=0.2417, max=0.8939, mean=0.6399

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.8889
neutral 准确率: 1.0000
negative 准确率: 0.6667

损失分量：
基础交叉熵: 0.3598
焦点损失: 0.0679
边界损失: 0.3067
总损失: 0.2522
Epoch 2 [29/172] - loss: 0.2522
Epoch 2 [30/172] - loss: 0.2860, acc: 0.9062
Epoch 2 [31/172] - loss: 0.3852
Epoch 2 [32/172] - loss: 0.2935
Epoch 2 [33/172] - loss: 0.3610
Epoch 2 [34/172] - loss: 0.2558
Epoch 2 [35/172] - loss: 0.1949
Epoch 2 [36/172] - loss: 0.3997
Epoch 2 [37/172] - loss: 0.2359
Epoch 2 [38/172] - loss: 0.3034
Epoch 2 [39/172] - loss: 0.4400
Epoch 2 [40/172] - loss: 0.4614, acc: 0.7188
Epoch 2 [41/172] - loss: 0.3220
Epoch 2 [42/172] - loss: 0.1688
Epoch 2 [43/172] - loss: 0.1528
Epoch 2 [44/172] - loss: 0.5834
Epoch 2 [45/172] - loss: 0.3295
Epoch 2 [46/172] - loss: 0.2922
Epoch 2 [47/172] - loss: 0.3451
Epoch 2 [48/172] - loss: 0.3220
Epoch 2 [49/172] - loss: 0.2154
Epoch 2 [50/172] - loss: 0.3384, acc: 0.7500
Epoch 2 [51/172] - loss: 0.3767
Epoch 2 [52/172] - loss: 0.2005
Epoch 2 [53/172] - loss: 0.4053
Epoch 2 [54/172] - loss: 0.1836
Epoch 2 [55/172] - loss: 0.2174
Epoch 2 [56/172] - loss: 0.2572
Epoch 2 [57/172] - loss: 0.2019
Epoch 2 [58/172] - loss: 0.2042
Epoch 2 [59/172] - loss: 0.4818
Epoch 2 [60/172] - loss: 0.4190, acc: 0.7812
Epoch 2 [61/172] - loss: 0.1621
Epoch 2 [62/172] - loss: 0.1856
Epoch 2 [63/172] - loss: 0.2724
Epoch 2 [64/172] - loss: 0.3267
Epoch 2 [65/172] - loss: 0.1959
Epoch 2 [66/172] - loss: 0.2115
Epoch 2 [67/172] - loss: 0.2367
Epoch 2 [68/172] - loss: 0.3268
Epoch 2 [69/172] - loss: 0.1921
Epoch 2 [70/172] - loss: 0.2252, acc: 0.9062
Epoch 2 [71/172] - loss: 0.3154
Epoch 2 [72/172] - loss: 0.3533
Epoch 2 [73/172] - loss: 0.4131
Epoch 2 [74/172] - loss: 0.2742
Epoch 2 [75/172] - loss: 0.2636
Epoch 2 [76/172] - loss: 0.2514
Epoch 2 [77/172] - loss: 0.2439
Epoch 2 [78/172] - loss: 0.3659
Epoch 2 [79/172] - loss: 0.3125
Epoch 2 [80/172] - loss: 0.1872, acc: 0.9375
Epoch 2 [81/172] - loss: 0.2645
Epoch 2 [82/172] - loss: 0.2431
Epoch 2 [83/172] - loss: 0.1634
Epoch 2 [84/172] - loss: 0.3467
Epoch 2 [85/172] - loss: 0.2427
Epoch 2 [86/172] - loss: 0.2288
Epoch 2 [87/172] - loss: 0.4381
Epoch 2 [88/172] - loss: 0.1875
Epoch 2 [89/172] - loss: 0.1954
Epoch 2 [90/172] - loss: 0.2237, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1727
Epoch 2 [92/172] - loss: 0.4202
Epoch 2 [93/172] - loss: 0.2637
Epoch 2 [94/172] - loss: 0.2574
Epoch 2 [95/172] - loss: 0.1990
Epoch 2 [96/172] - loss: 0.1793
Epoch 2 [97/172] - loss: 0.1319
Epoch 2 [98/172] - loss: 0.2346
Epoch 2 [99/172] - loss: 0.1431
Epoch 2 [100/172] - loss: 0.2440, acc: 0.8438
Epoch 2 [101/172] - loss: 0.1832
Epoch 2 [102/172] - loss: 0.1867
Epoch 2 [103/172] - loss: 0.2572
Epoch 2 [104/172] - loss: 0.2837
Epoch 2 [105/172] - loss: 0.2110
Epoch 2 [106/172] - loss: 0.2085
Epoch 2 [107/172] - loss: 0.2160
Epoch 2 [108/172] - loss: 0.4919
Epoch 2 [109/172] - loss: 0.2356
Epoch 2 [110/172] - loss: 0.2803, acc: 0.8438
Epoch 2 [111/172] - loss: 0.2704
Epoch 2 [112/172] - loss: 0.1662
Epoch 2 [113/172] - loss: 0.1670
Epoch 2 [114/172] - loss: 0.2430
Epoch 2 [115/172] - loss: 0.2379
Epoch 2 [116/172] - loss: 0.2394
Epoch 2 [117/172] - loss: 0.4450
Epoch 2 [118/172] - loss: 0.1520
Epoch 2 [119/172] - loss: 0.3449
Epoch 2 [120/172] - loss: 0.3573, acc: 0.8438
Epoch 2 [121/172] - loss: 0.2556
Epoch 2 [122/172] - loss: 0.5002
Epoch 2 [123/172] - loss: 0.2947
Epoch 2 [124/172] - loss: 0.1992
Epoch 2 [125/172] - loss: 0.2709
Epoch 2 [126/172] - loss: 0.1729
Epoch 2 [127/172] - loss: 0.2186
Epoch 2 [128/172] - loss: 0.3301

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4247, log_difficulty=0.3539, weight=2.7697
neutral: count=2949.0, difficulty=0.3271, log_difficulty=0.2830, weight=2.4151
negative: count=3294.0, difficulty=0.4000, log_difficulty=0.3365, weight=2.6825

当前batch的pt分布：
positive: min=0.4830, max=0.9832, mean=0.7960
neutral: min=0.5115, max=0.9932, mean=0.8891
negative: min=0.0736, max=0.9570, mean=0.7069

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.3256
焦点损失: 0.1336
边界损失: 0.2329
总损失: 0.2954
Epoch 2 [129/172] - loss: 0.2954
Epoch 2 [130/172] - loss: 0.2436, acc: 0.8438
Epoch 2 [131/172] - loss: 0.1373
Epoch 2 [132/172] - loss: 0.3265
Epoch 2 [133/172] - loss: 0.2210
Epoch 2 [134/172] - loss: 0.2823
Epoch 2 [135/172] - loss: 0.2844
Epoch 2 [136/172] - loss: 0.2766
Epoch 2 [137/172] - loss: 0.1447
Epoch 2 [138/172] - loss: 0.1792
Epoch 2 [139/172] - loss: 0.1996
Epoch 2 [140/172] - loss: 0.2031, acc: 0.9062
Epoch 2 [141/172] - loss: 0.1894
Epoch 2 [142/172] - loss: 0.2904
Epoch 2 [143/172] - loss: 0.2454
Epoch 2 [144/172] - loss: 0.2036
Epoch 2 [145/172] - loss: 0.3757
Epoch 2 [146/172] - loss: 0.1500
Epoch 2 [147/172] - loss: 0.2175
Epoch 2 [148/172] - loss: 0.1874
Epoch 2 [149/172] - loss: 0.2687
Epoch 2 [150/172] - loss: 0.1538, acc: 0.9688
Epoch 2 [151/172] - loss: 0.2423
Epoch 2 [152/172] - loss: 0.1830
Epoch 2 [153/172] - loss: 0.1867
Epoch 2 [154/172] - loss: 0.1620
Epoch 2 [155/172] - loss: 0.2104
Epoch 2 [156/172] - loss: 0.1484
Epoch 2 [157/172] - loss: 0.1569
Epoch 2 [158/172] - loss: 0.2015
Epoch 2 [159/172] - loss: 0.1494
Epoch 2 [160/172] - loss: 0.1414, acc: 0.9688
Epoch 2 [161/172] - loss: 0.1605
Epoch 2 [162/172] - loss: 0.1347
Epoch 2 [163/172] - loss: 0.4350
Epoch 2 [164/172] - loss: 0.2087
Epoch 2 [165/172] - loss: 0.2829
Epoch 2 [166/172] - loss: 0.2167
Epoch 2 [167/172] - loss: 0.2861
Epoch 2 [168/172] - loss: 0.1715
Epoch 2 [169/172] - loss: 0.1234
Epoch 2 [170/172] - loss: 0.2760, acc: 0.9062
Epoch 2 [171/172] - loss: 0.2951
Epoch 2 [172/172] - loss: 0.9745

类别准确率:
positive: 0.8180 (382/467)
neutral: 0.4940 (41/83)
negative: 0.5320 (133/250)

Epoch 2/10
Train Loss: 0.2634, Train Acc: 0.9192
Val Loss: 0.7844, Val Acc: 0.6950
Epoch 3 [1/172] - loss: 0.2901, acc: 0.9062
Epoch 3 [2/172] - loss: 0.1195
Epoch 3 [3/172] - loss: 0.0966
Epoch 3 [4/172] - loss: 0.1080
Epoch 3 [5/172] - loss: 0.2783
Epoch 3 [6/172] - loss: 0.1635
Epoch 3 [7/172] - loss: 0.1352
Epoch 3 [8/172] - loss: 0.1695
Epoch 3 [9/172] - loss: 0.1778
Epoch 3 [10/172] - loss: 0.1400, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1287
Epoch 3 [12/172] - loss: 0.1271
Epoch 3 [13/172] - loss: 0.1454
Epoch 3 [14/172] - loss: 0.1164
Epoch 3 [15/172] - loss: 0.1343
Epoch 3 [16/172] - loss: 0.3605
Epoch 3 [17/172] - loss: 0.1706
Epoch 3 [18/172] - loss: 0.1442
Epoch 3 [19/172] - loss: 0.1919
Epoch 3 [20/172] - loss: 0.1440, acc: 0.9375
Epoch 3 [21/172] - loss: 0.1093
Epoch 3 [22/172] - loss: 0.2808
Epoch 3 [23/172] - loss: 0.1267
Epoch 3 [24/172] - loss: 0.2035
Epoch 3 [25/172] - loss: 0.1005
Epoch 3 [26/172] - loss: 0.1564
Epoch 3 [27/172] - loss: 0.1339
Epoch 3 [28/172] - loss: 0.1057
Epoch 3 [29/172] - loss: 0.1666
Epoch 3 [30/172] - loss: 0.1383, acc: 0.9688
Epoch 3 [31/172] - loss: 0.1042
Epoch 3 [32/172] - loss: 0.1787
Epoch 3 [33/172] - loss: 0.0988
Epoch 3 [34/172] - loss: 0.1782
Epoch 3 [35/172] - loss: 0.1454
Epoch 3 [36/172] - loss: 0.1273
Epoch 3 [37/172] - loss: 0.1448
Epoch 3 [38/172] - loss: 0.1967
Epoch 3 [39/172] - loss: 0.1013
Epoch 3 [40/172] - loss: 0.2044, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1234
Epoch 3 [42/172] - loss: 0.1933
Epoch 3 [43/172] - loss: 0.1066
Epoch 3 [44/172] - loss: 0.1641
Epoch 3 [45/172] - loss: 0.2130
Epoch 3 [46/172] - loss: 0.1218
Epoch 3 [47/172] - loss: 0.1057
Epoch 3 [48/172] - loss: 0.1291
Epoch 3 [49/172] - loss: 0.0930
Epoch 3 [50/172] - loss: 0.1423, acc: 0.9688
Epoch 3 [51/172] - loss: 0.2004
Epoch 3 [52/172] - loss: 0.1526
Epoch 3 [53/172] - loss: 0.1200
Epoch 3 [54/172] - loss: 0.1583
Epoch 3 [55/172] - loss: 0.1533
Epoch 3 [56/172] - loss: 0.1150

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3651, log_difficulty=0.3112, weight=2.5561
neutral: count=3923.0, difficulty=0.2763, log_difficulty=0.2439, weight=2.2197
negative: count=4382.0, difficulty=0.3475, log_difficulty=0.2983, weight=2.4914

当前batch的pt分布：
positive: min=0.2421, max=0.9915, mean=0.8535
neutral: min=0.0337, max=0.9770, mean=0.7848
negative: min=0.8596, max=0.9885, mean=0.9565

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9091
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2778
焦点损失: 0.1284
边界损失: 0.2068
总损失: 0.2500
Epoch 3 [57/172] - loss: 0.2500
Epoch 3 [58/172] - loss: 0.1745
Epoch 3 [59/172] - loss: 0.1312
Epoch 3 [60/172] - loss: 0.1368, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1487
Epoch 3 [62/172] - loss: 0.1040
Epoch 3 [63/172] - loss: 0.1079
Epoch 3 [64/172] - loss: 0.1417
Epoch 3 [65/172] - loss: 0.1089
Epoch 3 [66/172] - loss: 0.2656
Epoch 3 [67/172] - loss: 0.1765
Epoch 3 [68/172] - loss: 0.1183
Epoch 3 [69/172] - loss: 0.1718
Epoch 3 [70/172] - loss: 0.1243, acc: 0.9688
Epoch 3 [71/172] - loss: 0.1082
Epoch 3 [72/172] - loss: 0.2253
Epoch 3 [73/172] - loss: 0.1292
Epoch 3 [74/172] - loss: 0.2045
Epoch 3 [75/172] - loss: 0.1236
Epoch 3 [76/172] - loss: 0.1202
Epoch 3 [77/172] - loss: 0.1080
Epoch 3 [78/172] - loss: 0.2063
Epoch 3 [79/172] - loss: 0.1416
Epoch 3 [80/172] - loss: 0.1839, acc: 0.9062
Epoch 3 [81/172] - loss: 0.1359
Epoch 3 [82/172] - loss: 0.1164
Epoch 3 [83/172] - loss: 0.1185
Epoch 3 [84/172] - loss: 0.0895
Epoch 3 [85/172] - loss: 0.1070
Epoch 3 [86/172] - loss: 0.1274
Epoch 3 [87/172] - loss: 0.1270
Epoch 3 [88/172] - loss: 0.2238
Epoch 3 [89/172] - loss: 0.1103
Epoch 3 [90/172] - loss: 0.1256, acc: 0.9375
Epoch 3 [91/172] - loss: 0.1196
Epoch 3 [92/172] - loss: 0.1761
Epoch 3 [93/172] - loss: 0.1584
Epoch 3 [94/172] - loss: 0.1130
Epoch 3 [95/172] - loss: 0.0983
Epoch 3 [96/172] - loss: 0.1534
Epoch 3 [97/172] - loss: 0.1030
Epoch 3 [98/172] - loss: 0.1139
Epoch 3 [99/172] - loss: 0.0931
Epoch 3 [100/172] - loss: 0.0975, acc: 1.0000
Epoch 3 [101/172] - loss: 0.1811
Epoch 3 [102/172] - loss: 0.0840
Epoch 3 [103/172] - loss: 0.2071
Epoch 3 [104/172] - loss: 0.1211
Epoch 3 [105/172] - loss: 0.2287
Epoch 3 [106/172] - loss: 0.1659
Epoch 3 [107/172] - loss: 0.0915
Epoch 3 [108/172] - loss: 0.1129
Epoch 3 [109/172] - loss: 0.1059
Epoch 3 [110/172] - loss: 0.2700, acc: 0.9375
Epoch 3 [111/172] - loss: 0.1036
Epoch 3 [112/172] - loss: 0.1208
Epoch 3 [113/172] - loss: 0.0936
Epoch 3 [114/172] - loss: 0.1186
Epoch 3 [115/172] - loss: 0.1851
Epoch 3 [116/172] - loss: 0.0991
Epoch 3 [117/172] - loss: 0.1137
Epoch 3 [118/172] - loss: 0.0944
Epoch 3 [119/172] - loss: 0.0875
Epoch 3 [120/172] - loss: 0.1845, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1689
Epoch 3 [122/172] - loss: 0.1121
Epoch 3 [123/172] - loss: 0.1536
Epoch 3 [124/172] - loss: 0.1221
Epoch 3 [125/172] - loss: 0.2406
Epoch 3 [126/172] - loss: 0.3732
Epoch 3 [127/172] - loss: 0.2087
Epoch 3 [128/172] - loss: 0.1120
Epoch 3 [129/172] - loss: 0.1009
Epoch 3 [130/172] - loss: 0.0909, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1749
Epoch 3 [132/172] - loss: 0.0905
Epoch 3 [133/172] - loss: 0.0994
Epoch 3 [134/172] - loss: 0.1146
Epoch 3 [135/172] - loss: 0.0985
Epoch 3 [136/172] - loss: 0.1144
Epoch 3 [137/172] - loss: 0.1118
Epoch 3 [138/172] - loss: 0.1155
Epoch 3 [139/172] - loss: 0.1092
Epoch 3 [140/172] - loss: 0.1574, acc: 0.9062
Epoch 3 [141/172] - loss: 0.1370
Epoch 3 [142/172] - loss: 0.2314
Epoch 3 [143/172] - loss: 0.1093
Epoch 3 [144/172] - loss: 0.2246
Epoch 3 [145/172] - loss: 0.1410
Epoch 3 [146/172] - loss: 0.1002
Epoch 3 [147/172] - loss: 0.1161
Epoch 3 [148/172] - loss: 0.1122
Epoch 3 [149/172] - loss: 0.1913
Epoch 3 [150/172] - loss: 0.1431, acc: 0.9688
Epoch 3 [151/172] - loss: 0.2935
Epoch 3 [152/172] - loss: 0.1121
Epoch 3 [153/172] - loss: 0.2772
Epoch 3 [154/172] - loss: 0.2481
Epoch 3 [155/172] - loss: 0.0951
Epoch 3 [156/172] - loss: 0.1463

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3171, log_difficulty=0.2754, weight=2.3772
neutral: count=4903.0, difficulty=0.2374, log_difficulty=0.2130, weight=2.0651
negative: count=5500.0, difficulty=0.3056, log_difficulty=0.2667, weight=2.3334

当前batch的pt分布：
positive: min=0.5049, max=0.9923, mean=0.8844
neutral: min=0.5275, max=0.9927, mean=0.9253
negative: min=0.3322, max=0.9872, mean=0.8469

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1443
焦点损失: 0.0240
边界损失: 0.1980
总损失: 0.1266
Epoch 3 [157/172] - loss: 0.1266
Epoch 3 [158/172] - loss: 0.2933
Epoch 3 [159/172] - loss: 0.1021
Epoch 3 [160/172] - loss: 0.1759, acc: 0.9375
Epoch 3 [161/172] - loss: 0.2879
Epoch 3 [162/172] - loss: 0.1103
Epoch 3 [163/172] - loss: 0.1254
Epoch 3 [164/172] - loss: 0.1341
Epoch 3 [165/172] - loss: 0.1229
Epoch 3 [166/172] - loss: 0.2933
Epoch 3 [167/172] - loss: 0.1778
Epoch 3 [168/172] - loss: 0.1022
Epoch 3 [169/172] - loss: 0.1363
Epoch 3 [170/172] - loss: 0.1349, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1394
Epoch 3 [172/172] - loss: 0.2445

类别准确率:
positive: 0.8351 (390/467)
neutral: 0.3253 (27/83)
negative: 0.6280 (157/250)

Epoch 3/10
Train Loss: 0.1692, Train Acc: 0.9495
Val Loss: 0.7255, Val Acc: 0.7175
Epoch 4 [1/172] - loss: 0.0880, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1425
Epoch 4 [3/172] - loss: 0.1068
Epoch 4 [4/172] - loss: 0.1000
Epoch 4 [5/172] - loss: 0.1138
Epoch 4 [6/172] - loss: 0.1258
Epoch 4 [7/172] - loss: 0.0974
Epoch 4 [8/172] - loss: 0.1845
Epoch 4 [9/172] - loss: 0.1316
Epoch 4 [10/172] - loss: 0.1347, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0823
Epoch 4 [12/172] - loss: 0.1364
Epoch 4 [13/172] - loss: 0.1520
Epoch 4 [14/172] - loss: 0.1495
Epoch 4 [15/172] - loss: 0.0998
Epoch 4 [16/172] - loss: 0.0956
Epoch 4 [17/172] - loss: 0.1071
Epoch 4 [18/172] - loss: 0.1156
Epoch 4 [19/172] - loss: 0.0935
Epoch 4 [20/172] - loss: 0.1248, acc: 0.9375
Epoch 4 [21/172] - loss: 0.1693
Epoch 4 [22/172] - loss: 0.0860
Epoch 4 [23/172] - loss: 0.1382
Epoch 4 [24/172] - loss: 0.0886
Epoch 4 [25/172] - loss: 0.0848
Epoch 4 [26/172] - loss: 0.1178
Epoch 4 [27/172] - loss: 0.1514
Epoch 4 [28/172] - loss: 0.1683
Epoch 4 [29/172] - loss: 0.0872
Epoch 4 [30/172] - loss: 0.1648, acc: 0.9375
Epoch 4 [31/172] - loss: 0.1032
Epoch 4 [32/172] - loss: 0.0840
Epoch 4 [33/172] - loss: 0.1130
Epoch 4 [34/172] - loss: 0.0995
Epoch 4 [35/172] - loss: 0.0925
Epoch 4 [36/172] - loss: 0.0941
Epoch 4 [37/172] - loss: 0.1128
Epoch 4 [38/172] - loss: 0.0914
Epoch 4 [39/172] - loss: 0.1466
Epoch 4 [40/172] - loss: 0.2196, acc: 0.8750
Epoch 4 [41/172] - loss: 0.0872
Epoch 4 [42/172] - loss: 0.1656
Epoch 4 [43/172] - loss: 0.2459
Epoch 4 [44/172] - loss: 0.0983
Epoch 4 [45/172] - loss: 0.0941
Epoch 4 [46/172] - loss: 0.0982
Epoch 4 [47/172] - loss: 0.0869
Epoch 4 [48/172] - loss: 0.0964
Epoch 4 [49/172] - loss: 0.0878
Epoch 4 [50/172] - loss: 0.0928, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0877
Epoch 4 [52/172] - loss: 0.1292
Epoch 4 [53/172] - loss: 0.0856
Epoch 4 [54/172] - loss: 0.1135
Epoch 4 [55/172] - loss: 0.1381
Epoch 4 [56/172] - loss: 0.0865
Epoch 4 [57/172] - loss: 0.0830
Epoch 4 [58/172] - loss: 0.0862
Epoch 4 [59/172] - loss: 0.0846
Epoch 4 [60/172] - loss: 0.0911, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1469
Epoch 4 [62/172] - loss: 0.1345
Epoch 4 [63/172] - loss: 0.0889
Epoch 4 [64/172] - loss: 0.0799
Epoch 4 [65/172] - loss: 0.0932
Epoch 4 [66/172] - loss: 0.0911
Epoch 4 [67/172] - loss: 0.1221
Epoch 4 [68/172] - loss: 0.0983
Epoch 4 [69/172] - loss: 0.0883
Epoch 4 [70/172] - loss: 0.1045, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0870
Epoch 4 [72/172] - loss: 0.0896
Epoch 4 [73/172] - loss: 0.0863
Epoch 4 [74/172] - loss: 0.2394
Epoch 4 [75/172] - loss: 0.0936
Epoch 4 [76/172] - loss: 0.0766
Epoch 4 [77/172] - loss: 0.0997
Epoch 4 [78/172] - loss: 0.0922
Epoch 4 [79/172] - loss: 0.0969
Epoch 4 [80/172] - loss: 0.0793, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1023
Epoch 4 [82/172] - loss: 0.1201
Epoch 4 [83/172] - loss: 0.1899
Epoch 4 [84/172] - loss: 0.0858

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2811, log_difficulty=0.2477, weight=2.2386
neutral: count=5865.0, difficulty=0.2102, log_difficulty=0.1908, weight=1.9538
negative: count=6629.0, difficulty=0.2713, log_difficulty=0.2400, weight=2.2001

当前batch的pt分布：
positive: min=0.4717, max=0.9924, mean=0.8296
neutral: min=0.9800, max=0.9961, mean=0.9892
negative: min=0.6959, max=0.9910, mean=0.9403

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1252
焦点损失: 0.0121
边界损失: 0.1950
总损失: 0.1110
Epoch 4 [85/172] - loss: 0.1110
Epoch 4 [86/172] - loss: 0.1203
Epoch 4 [87/172] - loss: 0.0872
Epoch 4 [88/172] - loss: 0.1189
Epoch 4 [89/172] - loss: 0.0776
Epoch 4 [90/172] - loss: 0.0965, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1934
Epoch 4 [92/172] - loss: 0.2021
Epoch 4 [93/172] - loss: 0.0787
Epoch 4 [94/172] - loss: 0.0812
Epoch 4 [95/172] - loss: 0.0926
Epoch 4 [96/172] - loss: 0.1201
Epoch 4 [97/172] - loss: 0.1008
Epoch 4 [98/172] - loss: 0.0818
Epoch 4 [99/172] - loss: 0.0969
Epoch 4 [100/172] - loss: 0.1458, acc: 0.9375
Epoch 4 [101/172] - loss: 0.0875
Epoch 4 [102/172] - loss: 0.1399
Epoch 4 [103/172] - loss: 0.1402
Epoch 4 [104/172] - loss: 0.0934
Epoch 4 [105/172] - loss: 0.0878
Epoch 4 [106/172] - loss: 0.0836
Epoch 4 [107/172] - loss: 0.0820
Epoch 4 [108/172] - loss: 0.1249
Epoch 4 [109/172] - loss: 0.0840
Epoch 4 [110/172] - loss: 0.3506, acc: 0.8750
Epoch 4 [111/172] - loss: 0.0823
Epoch 4 [112/172] - loss: 0.0838
Epoch 4 [113/172] - loss: 0.0852
Epoch 4 [114/172] - loss: 0.1068
Epoch 4 [115/172] - loss: 0.1067
Epoch 4 [116/172] - loss: 0.0888
Epoch 4 [117/172] - loss: 0.0913
Epoch 4 [118/172] - loss: 0.1032
Epoch 4 [119/172] - loss: 0.0838
Epoch 4 [120/172] - loss: 0.0859, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1098
Epoch 4 [122/172] - loss: 0.2333
Epoch 4 [123/172] - loss: 0.0981
Epoch 4 [124/172] - loss: 0.0854
Epoch 4 [125/172] - loss: 0.1474
Epoch 4 [126/172] - loss: 0.1912
Epoch 4 [127/172] - loss: 0.1874
Epoch 4 [128/172] - loss: 0.1197
Epoch 4 [129/172] - loss: 0.0829
Epoch 4 [130/172] - loss: 0.0838, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0967
Epoch 4 [132/172] - loss: 0.0782
Epoch 4 [133/172] - loss: 0.0805
Epoch 4 [134/172] - loss: 0.0880
Epoch 4 [135/172] - loss: 0.1176
Epoch 4 [136/172] - loss: 0.1627
Epoch 4 [137/172] - loss: 0.1268
Epoch 4 [138/172] - loss: 0.1005
Epoch 4 [139/172] - loss: 0.1375
Epoch 4 [140/172] - loss: 0.1076, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1361
Epoch 4 [142/172] - loss: 0.0867
Epoch 4 [143/172] - loss: 0.0973
Epoch 4 [144/172] - loss: 0.0956
Epoch 4 [145/172] - loss: 0.2055
Epoch 4 [146/172] - loss: 0.0815
Epoch 4 [147/172] - loss: 0.1196
Epoch 4 [148/172] - loss: 0.0907
Epoch 4 [149/172] - loss: 0.1050
Epoch 4 [150/172] - loss: 0.1228, acc: 0.9688
Epoch 4 [151/172] - loss: 0.1473
Epoch 4 [152/172] - loss: 0.0881
Epoch 4 [153/172] - loss: 0.0802
Epoch 4 [154/172] - loss: 0.0994
Epoch 4 [155/172] - loss: 0.1143
Epoch 4 [156/172] - loss: 0.0936
Epoch 4 [157/172] - loss: 0.2761
Epoch 4 [158/172] - loss: 0.0822
Epoch 4 [159/172] - loss: 0.0811
Epoch 4 [160/172] - loss: 0.0842, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1285
Epoch 4 [162/172] - loss: 0.1248
Epoch 4 [163/172] - loss: 0.0951
Epoch 4 [164/172] - loss: 0.2004
Epoch 4 [165/172] - loss: 0.2005
Epoch 4 [166/172] - loss: 0.1147
Epoch 4 [167/172] - loss: 0.1135
Epoch 4 [168/172] - loss: 0.1331
Epoch 4 [169/172] - loss: 0.2033
Epoch 4 [170/172] - loss: 0.1198, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0926
Epoch 4 [172/172] - loss: 0.1289

类别准确率:
positive: 0.7794 (364/467)
neutral: 0.2289 (19/83)
negative: 0.7600 (190/250)

Epoch 4/10
Train Loss: 0.1362, Train Acc: 0.9657
Val Loss: 0.7991, Val Acc: 0.7163
Epoch 5 [1/172] - loss: 0.0952, acc: 0.9688
Epoch 5 [2/172] - loss: 0.1019
Epoch 5 [3/172] - loss: 0.0772
Epoch 5 [4/172] - loss: 0.1255
Epoch 5 [5/172] - loss: 0.0751
Epoch 5 [6/172] - loss: 0.0965
Epoch 5 [7/172] - loss: 0.0810
Epoch 5 [8/172] - loss: 0.0971
Epoch 5 [9/172] - loss: 0.1188
Epoch 5 [10/172] - loss: 0.0922, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1678
Epoch 5 [12/172] - loss: 0.0779

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2528, log_difficulty=0.2254, weight=2.1271
neutral: count=6845.0, difficulty=0.1892, log_difficulty=0.1733, weight=1.8666
negative: count=7694.0, difficulty=0.2453, log_difficulty=0.2194, weight=2.0969

当前batch的pt分布：
positive: min=0.1831, max=0.9979, mean=0.8658
neutral: min=0.9838, max=0.9993, mean=0.9921
negative: min=0.8198, max=0.9845, mean=0.9424

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8571
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1170
焦点损失: 0.0408
边界损失: 0.1677
总损失: 0.1273
Epoch 5 [13/172] - loss: 0.1273
Epoch 5 [14/172] - loss: 0.1987
Epoch 5 [15/172] - loss: 0.0787
Epoch 5 [16/172] - loss: 0.0830
Epoch 5 [17/172] - loss: 0.1214
Epoch 5 [18/172] - loss: 0.0804
Epoch 5 [19/172] - loss: 0.1107
Epoch 5 [20/172] - loss: 0.0915, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1678
Epoch 5 [22/172] - loss: 0.1582
Epoch 5 [23/172] - loss: 0.1589
Epoch 5 [24/172] - loss: 0.1116
Epoch 5 [25/172] - loss: 0.0798
Epoch 5 [26/172] - loss: 0.0826
Epoch 5 [27/172] - loss: 0.0810
Epoch 5 [28/172] - loss: 0.0785
Epoch 5 [29/172] - loss: 0.0809
Epoch 5 [30/172] - loss: 0.0920, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0963
Epoch 5 [32/172] - loss: 0.0937
Epoch 5 [33/172] - loss: 0.0869
Epoch 5 [34/172] - loss: 0.0792
Epoch 5 [35/172] - loss: 0.0825
Epoch 5 [36/172] - loss: 0.0951
Epoch 5 [37/172] - loss: 0.1002
Epoch 5 [38/172] - loss: 0.1139
Epoch 5 [39/172] - loss: 0.2361
Epoch 5 [40/172] - loss: 0.1007, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0868
Epoch 5 [42/172] - loss: 0.0918
Epoch 5 [43/172] - loss: 0.1626
Epoch 5 [44/172] - loss: 0.1761
Epoch 5 [45/172] - loss: 0.0784
Epoch 5 [46/172] - loss: 0.1445
Epoch 5 [47/172] - loss: 0.0774
Epoch 5 [48/172] - loss: 0.0929
Epoch 5 [49/172] - loss: 0.0874
Epoch 5 [50/172] - loss: 0.0857, acc: 1.0000
Epoch 5 [51/172] - loss: 0.0881
Epoch 5 [52/172] - loss: 0.0827
Epoch 5 [53/172] - loss: 0.0897
Epoch 5 [54/172] - loss: 0.0959
Epoch 5 [55/172] - loss: 0.1079
Epoch 5 [56/172] - loss: 0.0819
Epoch 5 [57/172] - loss: 0.0847
Epoch 5 [58/172] - loss: 0.0933
Epoch 5 [59/172] - loss: 0.0926
Epoch 5 [60/172] - loss: 0.0823, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0790
Epoch 5 [62/172] - loss: 0.0769
Epoch 5 [63/172] - loss: 0.1209
Epoch 5 [64/172] - loss: 0.0835
Epoch 5 [65/172] - loss: 0.0950
Epoch 5 [66/172] - loss: 0.0745
Epoch 5 [67/172] - loss: 0.0776
Epoch 5 [68/172] - loss: 0.0890
Epoch 5 [69/172] - loss: 0.0810
Epoch 5 [70/172] - loss: 0.0793, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0873
Epoch 5 [72/172] - loss: 0.0819
Epoch 5 [73/172] - loss: 0.0801
Epoch 5 [74/172] - loss: 0.1113
Epoch 5 [75/172] - loss: 0.0973
Epoch 5 [76/172] - loss: 0.0784
Epoch 5 [77/172] - loss: 0.0791
Epoch 5 [78/172] - loss: 0.1223
Epoch 5 [79/172] - loss: 0.0771
Epoch 5 [80/172] - loss: 0.0777, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1253
Epoch 5 [82/172] - loss: 0.1012
Epoch 5 [83/172] - loss: 0.0766
Epoch 5 [84/172] - loss: 0.0765
Epoch 5 [85/172] - loss: 0.2369
Epoch 5 [86/172] - loss: 0.1721
Epoch 5 [87/172] - loss: 0.0939
Epoch 5 [88/172] - loss: 0.1484
Epoch 5 [89/172] - loss: 0.0777
Epoch 5 [90/172] - loss: 0.1087, acc: 0.9375
Epoch 5 [91/172] - loss: 0.0825
Epoch 5 [92/172] - loss: 0.0958
Epoch 5 [93/172] - loss: 0.0761
Epoch 5 [94/172] - loss: 0.0759
Epoch 5 [95/172] - loss: 0.0809
Epoch 5 [96/172] - loss: 0.0917
Epoch 5 [97/172] - loss: 0.1246
Epoch 5 [98/172] - loss: 0.0821
Epoch 5 [99/172] - loss: 0.1695
Epoch 5 [100/172] - loss: 0.1033, acc: 0.9688
Epoch 5 [101/172] - loss: 0.0820
Epoch 5 [102/172] - loss: 0.0854
Epoch 5 [103/172] - loss: 0.0955
Epoch 5 [104/172] - loss: 0.1404
Epoch 5 [105/172] - loss: 0.2303
Epoch 5 [106/172] - loss: 0.0828
Epoch 5 [107/172] - loss: 0.0781
Epoch 5 [108/172] - loss: 0.0904
Epoch 5 [109/172] - loss: 0.0771
Epoch 5 [110/172] - loss: 0.0775, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0788
Epoch 5 [112/172] - loss: 0.0832

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2290, log_difficulty=0.2062, weight=2.0309
neutral: count=7825.0, difficulty=0.1720, log_difficulty=0.1587, weight=1.7934
negative: count=8780.0, difficulty=0.2239, log_difficulty=0.2021, weight=2.0104

当前batch的pt分布：
positive: min=0.2704, max=0.9817, mean=0.9090
neutral: min=0.8869, max=0.9942, mean=0.9566
negative: min=0.9806, max=0.9993, mean=0.9937

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0807
焦点损失: 0.0211
边界损失: 0.1596
总损失: 0.1012
Epoch 5 [113/172] - loss: 0.1012
Epoch 5 [114/172] - loss: 0.1043
Epoch 5 [115/172] - loss: 0.0945
Epoch 5 [116/172] - loss: 0.0935
Epoch 5 [117/172] - loss: 0.1452
Epoch 5 [118/172] - loss: 0.0739
Epoch 5 [119/172] - loss: 0.0745
Epoch 5 [120/172] - loss: 0.1968, acc: 0.9688
Epoch 5 [121/172] - loss: 0.0810
Epoch 5 [122/172] - loss: 0.1011
Epoch 5 [123/172] - loss: 0.0889
Epoch 5 [124/172] - loss: 0.0767
Epoch 5 [125/172] - loss: 0.0744
Epoch 5 [126/172] - loss: 0.0762
Epoch 5 [127/172] - loss: 0.0823
Epoch 5 [128/172] - loss: 0.0776
Epoch 5 [129/172] - loss: 0.1950
Epoch 5 [130/172] - loss: 0.0739, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0777
Epoch 5 [132/172] - loss: 0.1565
Epoch 5 [133/172] - loss: 0.1426
Epoch 5 [134/172] - loss: 0.1662
Epoch 5 [135/172] - loss: 0.0757
Epoch 5 [136/172] - loss: 0.0922
Epoch 5 [137/172] - loss: 0.0893
Epoch 5 [138/172] - loss: 0.1684
Epoch 5 [139/172] - loss: 0.2071
Epoch 5 [140/172] - loss: 0.1295, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0859
Epoch 5 [142/172] - loss: 0.0861
Epoch 5 [143/172] - loss: 0.0763
Epoch 5 [144/172] - loss: 0.0757
Epoch 5 [145/172] - loss: 0.0977
Epoch 5 [146/172] - loss: 0.0807
Epoch 5 [147/172] - loss: 0.1228
Epoch 5 [148/172] - loss: 0.0797
Epoch 5 [149/172] - loss: 0.0761
Epoch 5 [150/172] - loss: 0.2063, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0783
Epoch 5 [152/172] - loss: 0.0767
Epoch 5 [153/172] - loss: 0.1150
Epoch 5 [154/172] - loss: 0.1133
Epoch 5 [155/172] - loss: 0.0768
Epoch 5 [156/172] - loss: 0.0838
Epoch 5 [157/172] - loss: 0.0817
Epoch 5 [158/172] - loss: 0.0773
Epoch 5 [159/172] - loss: 0.0990
Epoch 5 [160/172] - loss: 0.0794, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0758
Epoch 5 [162/172] - loss: 0.0951
Epoch 5 [163/172] - loss: 0.1483
Epoch 5 [164/172] - loss: 0.0764
Epoch 5 [165/172] - loss: 0.1398
Epoch 5 [166/172] - loss: 0.0962
Epoch 5 [167/172] - loss: 0.1063
Epoch 5 [168/172] - loss: 0.0749
Epoch 5 [169/172] - loss: 0.0919
Epoch 5 [170/172] - loss: 0.0839, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0772
Epoch 5 [172/172] - loss: 0.0883

类别准确率:
positive: 0.8351 (390/467)
neutral: 0.2892 (24/83)
negative: 0.6800 (170/250)

Epoch 5/10
Train Loss: 0.0932, Train Acc: 0.9859
Val Loss: 0.8164, Val Acc: 0.7300
Epoch 6 [1/172] - loss: 0.1027, acc: 0.9688
Epoch 6 [2/172] - loss: 0.0866
Epoch 6 [3/172] - loss: 0.0788
Epoch 6 [4/172] - loss: 0.0762
Epoch 6 [5/172] - loss: 0.1261
Epoch 6 [6/172] - loss: 0.0778
Epoch 6 [7/172] - loss: 0.0769
Epoch 6 [8/172] - loss: 0.0925
Epoch 6 [9/172] - loss: 0.0764
Epoch 6 [10/172] - loss: 0.0787, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0769
Epoch 6 [12/172] - loss: 0.0745
Epoch 6 [13/172] - loss: 0.0808
Epoch 6 [14/172] - loss: 0.0743
Epoch 6 [15/172] - loss: 0.0775
Epoch 6 [16/172] - loss: 0.2113
Epoch 6 [17/172] - loss: 0.0766
Epoch 6 [18/172] - loss: 0.0760
Epoch 6 [19/172] - loss: 0.0786
Epoch 6 [20/172] - loss: 0.1142, acc: 0.9688
Epoch 6 [21/172] - loss: 0.0860
Epoch 6 [22/172] - loss: 0.0871
Epoch 6 [23/172] - loss: 0.0870
Epoch 6 [24/172] - loss: 0.0769
Epoch 6 [25/172] - loss: 0.0900
Epoch 6 [26/172] - loss: 0.0820
Epoch 6 [27/172] - loss: 0.1009
Epoch 6 [28/172] - loss: 0.0804
Epoch 6 [29/172] - loss: 0.0987
Epoch 6 [30/172] - loss: 0.0734, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0740
Epoch 6 [32/172] - loss: 0.0776
Epoch 6 [33/172] - loss: 0.0750
Epoch 6 [34/172] - loss: 0.0852
Epoch 6 [35/172] - loss: 0.0767
Epoch 6 [36/172] - loss: 0.0826
Epoch 6 [37/172] - loss: 0.0768
Epoch 6 [38/172] - loss: 0.0776
Epoch 6 [39/172] - loss: 0.1294
Epoch 6 [40/172] - loss: 0.0997, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2100, log_difficulty=0.1906, weight=1.9531
neutral: count=8815.0, difficulty=0.1582, log_difficulty=0.1468, weight=1.7342
negative: count=9870.0, difficulty=0.2047, log_difficulty=0.1863, weight=1.9313

当前batch的pt分布：
positive: min=0.1879, max=0.9988, mean=0.8610
neutral: min=0.9494, max=0.9959, mean=0.9799
negative: min=0.8114, max=0.9972, mean=0.9492

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8182
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1078
焦点损失: 0.0420
边界损失: 0.1634
总损失: 0.1227
Epoch 6 [41/172] - loss: 0.1227
Epoch 6 [42/172] - loss: 0.0767
Epoch 6 [43/172] - loss: 0.1551
Epoch 6 [44/172] - loss: 0.0745
Epoch 6 [45/172] - loss: 0.0827
Epoch 6 [46/172] - loss: 0.0815
Epoch 6 [47/172] - loss: 0.0787
Epoch 6 [48/172] - loss: 0.1777
Epoch 6 [49/172] - loss: 0.0785
Epoch 6 [50/172] - loss: 0.1676, acc: 0.9688
Epoch 6 [51/172] - loss: 0.2069
Epoch 6 [52/172] - loss: 0.1094
Epoch 6 [53/172] - loss: 0.0739
Epoch 6 [54/172] - loss: 0.2097
Epoch 6 [55/172] - loss: 0.1153
Epoch 6 [56/172] - loss: 0.0816
Epoch 6 [57/172] - loss: 0.0801
Epoch 6 [58/172] - loss: 0.0928
Epoch 6 [59/172] - loss: 0.0914
Epoch 6 [60/172] - loss: 0.1989, acc: 0.9375
Epoch 6 [61/172] - loss: 0.0783
Epoch 6 [62/172] - loss: 0.0896
Epoch 6 [63/172] - loss: 0.0887
Epoch 6 [64/172] - loss: 0.2131
Epoch 6 [65/172] - loss: 0.0868
Epoch 6 [66/172] - loss: 0.0895
Epoch 6 [67/172] - loss: 0.0777
Epoch 6 [68/172] - loss: 0.1546
Epoch 6 [69/172] - loss: 0.0964
Epoch 6 [70/172] - loss: 0.0860, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0799
Epoch 6 [72/172] - loss: 0.0863
Epoch 6 [73/172] - loss: 0.0919
Epoch 6 [74/172] - loss: 0.0754
Epoch 6 [75/172] - loss: 0.1164
Epoch 6 [76/172] - loss: 0.0774
Epoch 6 [77/172] - loss: 0.0940
Epoch 6 [78/172] - loss: 0.1084
Epoch 6 [79/172] - loss: 0.0732
Epoch 6 [80/172] - loss: 0.1024, acc: 0.9688
Epoch 6 [81/172] - loss: 0.0854
Epoch 6 [82/172] - loss: 0.1269
Epoch 6 [83/172] - loss: 0.0746
Epoch 6 [84/172] - loss: 0.1064
Epoch 6 [85/172] - loss: 0.0908
Epoch 6 [86/172] - loss: 0.0958
Epoch 6 [87/172] - loss: 0.0982
Epoch 6 [88/172] - loss: 0.0912
Epoch 6 [89/172] - loss: 0.0768
Epoch 6 [90/172] - loss: 0.0748, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0726
Epoch 6 [92/172] - loss: 0.0747
Epoch 6 [93/172] - loss: 0.0970
Epoch 6 [94/172] - loss: 0.1477
Epoch 6 [95/172] - loss: 0.1402
Epoch 6 [96/172] - loss: 0.0782
Epoch 6 [97/172] - loss: 0.0879
Epoch 6 [98/172] - loss: 0.0911
Epoch 6 [99/172] - loss: 0.0725
Epoch 6 [100/172] - loss: 0.0771, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1434
Epoch 6 [102/172] - loss: 0.0852
Epoch 6 [103/172] - loss: 0.0769
Epoch 6 [104/172] - loss: 0.1187
Epoch 6 [105/172] - loss: 0.0954
Epoch 6 [106/172] - loss: 0.0871
Epoch 6 [107/172] - loss: 0.0825
Epoch 6 [108/172] - loss: 0.0743
Epoch 6 [109/172] - loss: 0.1514
Epoch 6 [110/172] - loss: 0.0791, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0750
Epoch 6 [112/172] - loss: 0.0752
Epoch 6 [113/172] - loss: 0.0789
Epoch 6 [114/172] - loss: 0.0731
Epoch 6 [115/172] - loss: 0.1121
Epoch 6 [116/172] - loss: 0.1969
Epoch 6 [117/172] - loss: 0.0783
Epoch 6 [118/172] - loss: 0.0786
Epoch 6 [119/172] - loss: 0.1570
Epoch 6 [120/172] - loss: 0.0998, acc: 0.9688
Epoch 6 [121/172] - loss: 0.0804
Epoch 6 [122/172] - loss: 0.1147
Epoch 6 [123/172] - loss: 0.1007
Epoch 6 [124/172] - loss: 0.0741
Epoch 6 [125/172] - loss: 0.0849
Epoch 6 [126/172] - loss: 0.1067
Epoch 6 [127/172] - loss: 0.1444
Epoch 6 [128/172] - loss: 0.1360
Epoch 6 [129/172] - loss: 0.0792
Epoch 6 [130/172] - loss: 0.1370, acc: 0.9688
Epoch 6 [131/172] - loss: 0.0989
Epoch 6 [132/172] - loss: 0.1713
Epoch 6 [133/172] - loss: 0.1060
Epoch 6 [134/172] - loss: 0.1316
Epoch 6 [135/172] - loss: 0.0913
Epoch 6 [136/172] - loss: 0.0793
Epoch 6 [137/172] - loss: 0.0825
Epoch 6 [138/172] - loss: 0.1578
Epoch 6 [139/172] - loss: 0.0952
Epoch 6 [140/172] - loss: 0.1129, acc: 0.9375

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1948, log_difficulty=0.1780, weight=1.8898
neutral: count=9796.0, difficulty=0.1470, log_difficulty=0.1372, weight=1.6860
negative: count=10972.0, difficulty=0.1906, log_difficulty=0.1745, weight=1.8724

当前batch的pt分布：
positive: min=0.9549, max=0.9981, mean=0.9793
neutral: min=0.9551, max=0.9979, mean=0.9787
negative: min=0.4510, max=0.9975, mean=0.8896

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9231

损失分量：
基础交叉熵: 0.0679
焦点损失: 0.0084
边界损失: 0.1651
总损失: 0.0904
Epoch 6 [141/172] - loss: 0.0904
Epoch 6 [142/172] - loss: 0.0782
Epoch 6 [143/172] - loss: 0.0836
Epoch 6 [144/172] - loss: 0.0794
Epoch 6 [145/172] - loss: 0.0834
Epoch 6 [146/172] - loss: 0.0906
Epoch 6 [147/172] - loss: 0.0800
Epoch 6 [148/172] - loss: 0.0999
Epoch 6 [149/172] - loss: 0.1010
Epoch 6 [150/172] - loss: 0.0817, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1557
Epoch 6 [152/172] - loss: 0.0947
Epoch 6 [153/172] - loss: 0.1014
Epoch 6 [154/172] - loss: 0.0809
Epoch 6 [155/172] - loss: 0.1379
Epoch 6 [156/172] - loss: 0.1257
Epoch 6 [157/172] - loss: 0.0791
Epoch 6 [158/172] - loss: 0.1202
Epoch 6 [159/172] - loss: 0.0799
Epoch 6 [160/172] - loss: 0.1172, acc: 0.9688
Epoch 6 [161/172] - loss: 0.0782
Epoch 6 [162/172] - loss: 0.0855
Epoch 6 [163/172] - loss: 0.0795
Epoch 6 [164/172] - loss: 0.0898
Epoch 6 [165/172] - loss: 0.2313
Epoch 6 [166/172] - loss: 0.0851
Epoch 6 [167/172] - loss: 0.0766
Epoch 6 [168/172] - loss: 0.0873
Epoch 6 [169/172] - loss: 0.0845
Epoch 6 [170/172] - loss: 0.1126, acc: 0.9688
Epoch 6 [171/172] - loss: 0.0853
Epoch 6 [172/172] - loss: 0.1019

类别准确率:
positive: 0.8887 (415/467)
neutral: 0.2048 (17/83)
negative: 0.5480 (137/250)

Epoch 6/10
Train Loss: 0.0996, Train Acc: 0.9859
Val Loss: 0.9602, Val Acc: 0.7113
Epoch 7 [1/172] - loss: 0.0760, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0733
Epoch 7 [3/172] - loss: 0.0727
Epoch 7 [4/172] - loss: 0.0862
Epoch 7 [5/172] - loss: 0.0747
Epoch 7 [6/172] - loss: 0.0902
Epoch 7 [7/172] - loss: 0.0792
Epoch 7 [8/172] - loss: 0.1060
Epoch 7 [9/172] - loss: 0.0774
Epoch 7 [10/172] - loss: 0.0738, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0797
Epoch 7 [12/172] - loss: 0.1426
Epoch 7 [13/172] - loss: 0.0843
Epoch 7 [14/172] - loss: 0.0876
Epoch 7 [15/172] - loss: 0.1070
Epoch 7 [16/172] - loss: 0.0828
Epoch 7 [17/172] - loss: 0.1836
Epoch 7 [18/172] - loss: 0.0836
Epoch 7 [19/172] - loss: 0.0801
Epoch 7 [20/172] - loss: 0.1298, acc: 0.9688
Epoch 7 [21/172] - loss: 0.0951
Epoch 7 [22/172] - loss: 0.0813
Epoch 7 [23/172] - loss: 0.0789
Epoch 7 [24/172] - loss: 0.0831
Epoch 7 [25/172] - loss: 0.0738
Epoch 7 [26/172] - loss: 0.0870
Epoch 7 [27/172] - loss: 0.1637
Epoch 7 [28/172] - loss: 0.1011
Epoch 7 [29/172] - loss: 0.1157
Epoch 7 [30/172] - loss: 0.1462, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0938
Epoch 7 [32/172] - loss: 0.0765
Epoch 7 [33/172] - loss: 0.1837
Epoch 7 [34/172] - loss: 0.0763
Epoch 7 [35/172] - loss: 0.0792
Epoch 7 [36/172] - loss: 0.1762
Epoch 7 [37/172] - loss: 0.0855
Epoch 7 [38/172] - loss: 0.0746
Epoch 7 [39/172] - loss: 0.0848
Epoch 7 [40/172] - loss: 0.0786, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0764
Epoch 7 [42/172] - loss: 0.0803
Epoch 7 [43/172] - loss: 0.0792
Epoch 7 [44/172] - loss: 0.0815
Epoch 7 [45/172] - loss: 0.0893
Epoch 7 [46/172] - loss: 0.1030
Epoch 7 [47/172] - loss: 0.1343
Epoch 7 [48/172] - loss: 0.0954
Epoch 7 [49/172] - loss: 0.0783
Epoch 7 [50/172] - loss: 0.0860, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1202
Epoch 7 [52/172] - loss: 0.0958
Epoch 7 [53/172] - loss: 0.0787
Epoch 7 [54/172] - loss: 0.0927
Epoch 7 [55/172] - loss: 0.0807
Epoch 7 [56/172] - loss: 0.0773
Epoch 7 [57/172] - loss: 0.0745
Epoch 7 [58/172] - loss: 0.0995
Epoch 7 [59/172] - loss: 0.0767
Epoch 7 [60/172] - loss: 0.0888, acc: 1.0000
Epoch 7 [61/172] - loss: 0.0884
Epoch 7 [62/172] - loss: 0.0801
Epoch 7 [63/172] - loss: 0.1374
Epoch 7 [64/172] - loss: 0.0780
Epoch 7 [65/172] - loss: 0.0975
Epoch 7 [66/172] - loss: 0.0767
Epoch 7 [67/172] - loss: 0.0850
Epoch 7 [68/172] - loss: 0.1183

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1822, log_difficulty=0.1674, weight=1.8370
neutral: count=10756.0, difficulty=0.1378, log_difficulty=0.1291, weight=1.6455
negative: count=12072.0, difficulty=0.1791, log_difficulty=0.1647, weight=1.8237

当前batch的pt分布：
positive: min=0.9607, max=0.9998, mean=0.9836
neutral: min=0.9476, max=1.0000, mean=0.9798
negative: min=0.8065, max=0.9985, mean=0.9322

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0418
焦点损失: 0.0005
边界损失: 0.1553
总损失: 0.0781
Epoch 7 [69/172] - loss: 0.0781
Epoch 7 [70/172] - loss: 0.0805, acc: 1.0000
Epoch 7 [71/172] - loss: 0.1033
Epoch 7 [72/172] - loss: 0.0916
Epoch 7 [73/172] - loss: 0.0901
Epoch 7 [74/172] - loss: 0.0770
Epoch 7 [75/172] - loss: 0.0799
Epoch 7 [76/172] - loss: 0.2293
Epoch 7 [77/172] - loss: 0.1135
Epoch 7 [78/172] - loss: 0.1111
Epoch 7 [79/172] - loss: 0.0811
Epoch 7 [80/172] - loss: 0.0856, acc: 1.0000
Epoch 7 [81/172] - loss: 0.0745
Epoch 7 [82/172] - loss: 0.0828
Epoch 7 [83/172] - loss: 0.1567
Epoch 7 [84/172] - loss: 0.0735
Epoch 7 [85/172] - loss: 0.0803
Epoch 7 [86/172] - loss: 0.0781
Epoch 7 [87/172] - loss: 0.0745
Epoch 7 [88/172] - loss: 0.0781
Epoch 7 [89/172] - loss: 0.0751
Epoch 7 [90/172] - loss: 0.0860, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0758
Epoch 7 [92/172] - loss: 0.0767
Epoch 7 [93/172] - loss: 0.0908
Epoch 7 [94/172] - loss: 0.0725
Epoch 7 [95/172] - loss: 0.0733
Epoch 7 [96/172] - loss: 0.0796
Epoch 7 [97/172] - loss: 0.0783
Epoch 7 [98/172] - loss: 0.0921
Epoch 7 [99/172] - loss: 0.0754
Epoch 7 [100/172] - loss: 0.0716, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0732
Epoch 7 [102/172] - loss: 0.0743
Epoch 7 [103/172] - loss: 0.0789
Epoch 7 [104/172] - loss: 0.0756
Epoch 7 [105/172] - loss: 0.0924
Epoch 7 [106/172] - loss: 0.1031
Epoch 7 [107/172] - loss: 0.0720
Epoch 7 [108/172] - loss: 0.0727
Epoch 7 [109/172] - loss: 0.1823
Epoch 7 [110/172] - loss: 0.0955, acc: 0.9688
Epoch 7 [111/172] - loss: 0.1915
Epoch 7 [112/172] - loss: 0.0798
Epoch 7 [113/172] - loss: 0.1160
Epoch 7 [114/172] - loss: 0.0755
Epoch 7 [115/172] - loss: 0.0757
Epoch 7 [116/172] - loss: 0.1377
Epoch 7 [117/172] - loss: 0.1075
Epoch 7 [118/172] - loss: 0.0785
Epoch 7 [119/172] - loss: 0.2524
Epoch 7 [120/172] - loss: 0.0787, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0942
Epoch 7 [122/172] - loss: 0.0818
Epoch 7 [123/172] - loss: 0.0758
Epoch 7 [124/172] - loss: 0.1511
Epoch 7 [125/172] - loss: 0.1713
Epoch 7 [126/172] - loss: 0.0878
Epoch 7 [127/172] - loss: 0.1091
Epoch 7 [128/172] - loss: 0.0837
Epoch 7 [129/172] - loss: 0.1009
Epoch 7 [130/172] - loss: 0.0820, acc: 1.0000
Epoch 7 [131/172] - loss: 0.0873
Epoch 7 [132/172] - loss: 0.1908
Epoch 7 [133/172] - loss: 0.0759
Epoch 7 [134/172] - loss: 0.2042
Epoch 7 [135/172] - loss: 0.1078
Epoch 7 [136/172] - loss: 0.0791
Epoch 7 [137/172] - loss: 0.1235
Epoch 7 [138/172] - loss: 0.0875
Epoch 7 [139/172] - loss: 0.2559
Epoch 7 [140/172] - loss: 0.1269, acc: 0.9688
Epoch 7 [141/172] - loss: 0.2386
Epoch 7 [142/172] - loss: 0.0857
Epoch 7 [143/172] - loss: 0.0835
Epoch 7 [144/172] - loss: 0.0784
Epoch 7 [145/172] - loss: 0.1262
Epoch 7 [146/172] - loss: 0.1135
Epoch 7 [147/172] - loss: 0.1046
Epoch 7 [148/172] - loss: 0.0956
Epoch 7 [149/172] - loss: 0.0749
Epoch 7 [150/172] - loss: 0.1055, acc: 0.9688
Epoch 7 [151/172] - loss: 0.1442
Epoch 7 [152/172] - loss: 0.0740
Epoch 7 [153/172] - loss: 0.0778
Epoch 7 [154/172] - loss: 0.0887
Epoch 7 [155/172] - loss: 0.0800
Epoch 7 [156/172] - loss: 0.1338
Epoch 7 [157/172] - loss: 0.1074
Epoch 7 [158/172] - loss: 0.0792
Epoch 7 [159/172] - loss: 0.0892
Epoch 7 [160/172] - loss: 0.2692, acc: 0.9062
Epoch 7 [161/172] - loss: 0.1044
Epoch 7 [162/172] - loss: 0.1160
Epoch 7 [163/172] - loss: 0.1726
Epoch 7 [164/172] - loss: 0.1522
Epoch 7 [165/172] - loss: 0.1610
Epoch 7 [166/172] - loss: 0.0744
Epoch 7 [167/172] - loss: 0.0886
Epoch 7 [168/172] - loss: 0.0842

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1718, log_difficulty=0.1586, weight=1.7929
neutral: count=11731.0, difficulty=0.1309, log_difficulty=0.1230, weight=1.6150
negative: count=13173.0, difficulty=0.1691, log_difficulty=0.1562, weight=1.7810

当前batch的pt分布：
positive: min=0.9083, max=0.9991, mean=0.9804
neutral: min=0.7127, max=0.9978, mean=0.9610
negative: min=0.7440, max=0.9984, mean=0.9262

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0503
焦点损失: 0.0025
边界损失: 0.1585
总损失: 0.0814
Epoch 7 [169/172] - loss: 0.0814
Epoch 7 [170/172] - loss: 0.3153, acc: 0.9375
Epoch 7 [171/172] - loss: 0.0817
Epoch 7 [172/172] - loss: 0.0768

类别准确率:
positive: 0.9079 (424/467)
neutral: 0.3133 (26/83)
negative: 0.4200 (105/250)

Epoch 7/10
Train Loss: 0.1284, Train Acc: 0.9697
Val Loss: 0.9731, Val Acc: 0.6937
Epoch 8 [1/172] - loss: 0.0937, acc: 0.9688
Epoch 8 [2/172] - loss: 0.0878
Epoch 8 [3/172] - loss: 0.1391
Epoch 8 [4/172] - loss: 0.0862
Epoch 8 [5/172] - loss: 0.0750
Epoch 8 [6/172] - loss: 0.0997
Epoch 8 [7/172] - loss: 0.1089
Epoch 8 [8/172] - loss: 0.0799
Epoch 8 [9/172] - loss: 0.1105
Epoch 8 [10/172] - loss: 0.0994, acc: 0.9688
Epoch 8 [11/172] - loss: 0.0827
Epoch 8 [12/172] - loss: 0.1336
Epoch 8 [13/172] - loss: 0.0767
Epoch 8 [14/172] - loss: 0.0786
Epoch 8 [15/172] - loss: 0.0931
Epoch 8 [16/172] - loss: 0.0864
Epoch 8 [17/172] - loss: 0.0794
Epoch 8 [18/172] - loss: 0.0719
Epoch 8 [19/172] - loss: 0.0968
Epoch 8 [20/172] - loss: 0.0758, acc: 1.0000
Epoch 8 [21/172] - loss: 0.0785
Epoch 8 [22/172] - loss: 0.0859
Epoch 8 [23/172] - loss: 0.0767
Epoch 8 [24/172] - loss: 0.0809
Epoch 8 [25/172] - loss: 0.0759
Epoch 8 [26/172] - loss: 0.0769
Epoch 8 [27/172] - loss: 0.0997
Epoch 8 [28/172] - loss: 0.0843
Epoch 8 [29/172] - loss: 0.0777
Epoch 8 [30/172] - loss: 0.0742, acc: 1.0000
Epoch 8 [31/172] - loss: 0.0899
Epoch 8 [32/172] - loss: 0.0741
Epoch 8 [33/172] - loss: 0.0769
Epoch 8 [34/172] - loss: 0.1019
Epoch 8 [35/172] - loss: 0.0852
Epoch 8 [36/172] - loss: 0.0801
Epoch 8 [37/172] - loss: 0.0778
Epoch 8 [38/172] - loss: 0.1330
Epoch 8 [39/172] - loss: 0.0841
Epoch 8 [40/172] - loss: 0.0842, acc: 1.0000
Epoch 8 [41/172] - loss: 0.1400
Epoch 8 [42/172] - loss: 0.0839
Epoch 8 [43/172] - loss: 0.0743
Epoch 8 [44/172] - loss: 0.0780
Epoch 8 [45/172] - loss: 0.0857
Epoch 8 [46/172] - loss: 0.0802
Epoch 8 [47/172] - loss: 0.0742
Epoch 8 [48/172] - loss: 0.1118
Epoch 8 [49/172] - loss: 0.0746
Epoch 8 [50/172] - loss: 0.0750, acc: 1.0000
Epoch 8 [51/172] - loss: 0.0775
Epoch 8 [52/172] - loss: 0.0792
Epoch 8 [53/172] - loss: 0.0877
Epoch 8 [54/172] - loss: 0.0975
Epoch 8 [55/172] - loss: 0.0768
Epoch 8 [56/172] - loss: 0.0827
Epoch 8 [57/172] - loss: 0.0748
Epoch 8 [58/172] - loss: 0.0816
Epoch 8 [59/172] - loss: 0.0739
Epoch 8 [60/172] - loss: 0.0754, acc: 1.0000
Epoch 8 [61/172] - loss: 0.0774
Epoch 8 [62/172] - loss: 0.0784
Epoch 8 [63/172] - loss: 0.0764
Epoch 8 [64/172] - loss: 0.0728
Epoch 8 [65/172] - loss: 0.0744
Epoch 8 [66/172] - loss: 0.1249
Epoch 8 [67/172] - loss: 0.0746
Epoch 8 [68/172] - loss: 0.0736
Epoch 8 [69/172] - loss: 0.0798
Epoch 8 [70/172] - loss: 0.0753, acc: 1.0000
Epoch 8 [71/172] - loss: 0.0771
Epoch 8 [72/172] - loss: 0.0734
Epoch 8 [73/172] - loss: 0.0927
Epoch 8 [74/172] - loss: 0.0908
Epoch 8 [75/172] - loss: 0.0748
Epoch 8 [76/172] - loss: 0.1643
Epoch 8 [77/172] - loss: 0.0712
Epoch 8 [78/172] - loss: 0.1121
Epoch 8 [79/172] - loss: 0.0841
Epoch 8 [80/172] - loss: 0.1348, acc: 0.9688
Epoch 8 [81/172] - loss: 0.0746
Epoch 8 [82/172] - loss: 0.0772
Epoch 8 [83/172] - loss: 0.0755
Epoch 8 [84/172] - loss: 0.0786
Epoch 8 [85/172] - loss: 0.0760
Epoch 8 [86/172] - loss: 0.0754
Epoch 8 [87/172] - loss: 0.0822
Epoch 8 [88/172] - loss: 0.0928
Epoch 8 [89/172] - loss: 0.0812
Epoch 8 [90/172] - loss: 0.0738, acc: 1.0000
Epoch 8 [91/172] - loss: 0.1359
Epoch 8 [92/172] - loss: 0.0926
Epoch 8 [93/172] - loss: 0.0885
Epoch 8 [94/172] - loss: 0.0774
Epoch 8 [95/172] - loss: 0.0755
Epoch 8 [96/172] - loss: 0.0728

=== 第 1301 次迭代调试信息 ===
当前类别统计：
positive: count=14487.0, difficulty=0.1621, log_difficulty=0.1502, weight=1.7511
neutral: count=12738.0, difficulty=0.1237, log_difficulty=0.1166, weight=1.5830
negative: count=14288.0, difficulty=0.1601, log_difficulty=0.1485, weight=1.7426

当前batch的pt分布：
positive: min=0.8882, max=0.9991, mean=0.9724
neutral: min=0.0347, max=0.9976, mean=0.8808
negative: min=0.9604, max=0.9996, mean=0.9879

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9333
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1451
焦点损失: 0.1002
边界损失: 0.1554
总损失: 0.1570
Epoch 8 [97/172] - loss: 0.1570
Epoch 8 [98/172] - loss: 0.0796
Epoch 8 [99/172] - loss: 0.0744
Epoch 8 [100/172] - loss: 0.0770, acc: 1.0000
Epoch 8 [101/172] - loss: 0.0834
Epoch 8 [102/172] - loss: 0.0976
Epoch 8 [103/172] - loss: 0.1058
Epoch 8 [104/172] - loss: 0.0947
Epoch 8 [105/172] - loss: 0.0740
Epoch 8 [106/172] - loss: 0.0842
Epoch 8 [107/172] - loss: 0.0840
Epoch 8 [108/172] - loss: 0.0756
Epoch 8 [109/172] - loss: 0.0742
Epoch 8 [110/172] - loss: 0.0861, acc: 1.0000
Epoch 8 [111/172] - loss: 0.1098
Epoch 8 [112/172] - loss: 0.1016
Epoch 8 [113/172] - loss: 0.0727
Epoch 8 [114/172] - loss: 0.0727
Epoch 8 [115/172] - loss: 0.0752
Epoch 8 [116/172] - loss: 0.0714
Epoch 8 [117/172] - loss: 0.0796
Epoch 8 [118/172] - loss: 0.0754
Epoch 8 [119/172] - loss: 0.0734
Epoch 8 [120/172] - loss: 0.0771, acc: 1.0000
Epoch 8 [121/172] - loss: 0.1532
Epoch 8 [122/172] - loss: 0.0725
Epoch 8 [123/172] - loss: 0.0767
Epoch 8 [124/172] - loss: 0.0736
Epoch 8 [125/172] - loss: 0.0883
Epoch 8 [126/172] - loss: 0.0747
Epoch 8 [127/172] - loss: 0.0999
Epoch 8 [128/172] - loss: 0.1214
Epoch 8 [129/172] - loss: 0.0728
Epoch 8 [130/172] - loss: 0.0883, acc: 0.9688
Epoch 8 [131/172] - loss: 0.0902
Epoch 8 [132/172] - loss: 0.0804
Epoch 8 [133/172] - loss: 0.0801
Epoch 8 [134/172] - loss: 0.0764
Epoch 8 [135/172] - loss: 0.0782
Epoch 8 [136/172] - loss: 0.0765
Epoch 8 [137/172] - loss: 0.1071
Epoch 8 [138/172] - loss: 0.1626
Epoch 8 [139/172] - loss: 0.1265
Epoch 8 [140/172] - loss: 0.0714, acc: 1.0000
Epoch 8 [141/172] - loss: 0.0748
Epoch 8 [142/172] - loss: 0.0763
Epoch 8 [143/172] - loss: 0.0747
Epoch 8 [144/172] - loss: 0.0810
Epoch 8 [145/172] - loss: 0.0740
Epoch 8 [146/172] - loss: 0.0724
Epoch 8 [147/172] - loss: 0.0779
Epoch 8 [148/172] - loss: 0.0893
Epoch 8 [149/172] - loss: 0.0749
Epoch 8 [150/172] - loss: 0.0754, acc: 1.0000
Epoch 8 [151/172] - loss: 0.0867
Epoch 8 [152/172] - loss: 0.0836
Epoch 8 [153/172] - loss: 0.0786
Epoch 8 [154/172] - loss: 0.1134
Epoch 8 [155/172] - loss: 0.0735
Epoch 8 [156/172] - loss: 0.0748
Epoch 8 [157/172] - loss: 0.0825
Epoch 8 [158/172] - loss: 0.0872
Epoch 8 [159/172] - loss: 0.0841
Epoch 8 [160/172] - loss: 0.0739, acc: 1.0000
Epoch 8 [161/172] - loss: 0.0756
Epoch 8 [162/172] - loss: 0.0779
Epoch 8 [163/172] - loss: 0.1638
Epoch 8 [164/172] - loss: 0.0945
Epoch 8 [165/172] - loss: 0.0748
Epoch 8 [166/172] - loss: 0.0749
Epoch 8 [167/172] - loss: 0.0741
Epoch 8 [168/172] - loss: 0.0745
Epoch 8 [169/172] - loss: 0.0762
Epoch 8 [170/172] - loss: 0.0821, acc: 1.0000
Epoch 8 [171/172] - loss: 0.0838
Epoch 8 [172/172] - loss: 0.0767

类别准确率:
positive: 0.8630 (403/467)
neutral: 0.3133 (26/83)
negative: 0.5960 (149/250)

Epoch 8/10
Train Loss: 0.0848, Train Acc: 0.9960
Val Loss: 0.8688, Val Acc: 0.7225
Early stopping triggered!
Best validation accuracy: 0.7300

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_072326-doxvw3ce
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.25_Multimodal_iterations_20250118_072324
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/doxvw3ce
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇███
wandb:  train_acc ▁▃▂▂▄▆▂▇▅▆▆██▇▇█▇▅█████▇▇█▇▇▇▇▇█▇██▆▇▇██
wandb: train_loss █▅▅▃▅▅▃▂▄▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1374
wandb:  train_acc 1
wandb: train_loss 0.0821
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.25_Multimodal_iterations_20250118_072324 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/doxvw3ce
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_072326-doxvw3ce/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_073509-rsqei29n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.25_Multimodal_epochs_20250118_073509
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/rsqei29n
wandb: uploading history steps 0-0, summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▄▅▆▇█
wandb:  train_acc ▁▅▆▇██▇█
wandb: train_loss █▄▃▂▁▁▂▁
wandb:    val_acc ▄▁▆▅█▄▁▇
wandb:   val_loss ▁▃▁▃▄██▅
wandb: 
wandb: Run summary:
wandb:      epoch 8
wandb:  train_acc 0.99596
wandb: train_loss 0.0848
wandb:    val_acc 0.7225
wandb:   val_loss 0.86878
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.25_Multimodal_epochs_20250118_073509 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/rsqei29n
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_073509-rsqei29n/logs

