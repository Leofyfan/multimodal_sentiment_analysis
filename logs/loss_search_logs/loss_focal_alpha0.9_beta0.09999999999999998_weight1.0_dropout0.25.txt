=== 命令 ===
python main.py --loss_type focal --alpha 0.9 --beta 0.09999999999999998 --neural_init_weight 1.0 --dropout 0.25 --name loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.25 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.25
text_dim: 128
image_dim: 256
dropout: 0.25
loss_type: focal
alpha: 0.9
beta: 0.09999999999999998
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6935, log_difficulty=0.5268, weight=3.6340
neutral: count=7.0, difficulty=0.7044, log_difficulty=0.5332, weight=3.6660
negative: count=13.0, difficulty=0.6749, log_difficulty=0.5157, weight=3.5787

当前batch的pt分布：
positive: min=0.1767, max=0.5034, mean=0.3065
neutral: min=0.1717, max=0.3788, mean=0.2956
negative: min=0.2272, max=0.4208, mean=0.3251

当前batch准确率：
整体准确率: 0.2188
positive 准确率: 0.1667
neutral 准确率: 0.1429
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.2028
焦点损失: 0.4317
边界损失: 0.7684
总损失: 1.4841
Epoch 1 [1/172] - loss: 1.4841, acc: 0.2188
Epoch 1 [2/172] - loss: 1.4013
Epoch 1 [3/172] - loss: 1.2406
Epoch 1 [4/172] - loss: 1.2657
Epoch 1 [5/172] - loss: 1.5383
Epoch 1 [6/172] - loss: 1.5489
Epoch 1 [7/172] - loss: 1.4808
Epoch 1 [8/172] - loss: 2.1173
Epoch 1 [9/172] - loss: 1.4444
Epoch 1 [10/172] - loss: 1.4395, acc: 0.3438
Epoch 1 [11/172] - loss: 1.4288
Epoch 1 [12/172] - loss: 1.4065
Epoch 1 [13/172] - loss: 1.3870
Epoch 1 [14/172] - loss: 1.6745
Epoch 1 [15/172] - loss: 1.3695
Epoch 1 [16/172] - loss: 1.2888
Epoch 1 [17/172] - loss: 1.6474
Epoch 1 [18/172] - loss: 1.2223
Epoch 1 [19/172] - loss: 1.1710
Epoch 1 [20/172] - loss: 1.3963, acc: 0.3125
Epoch 1 [21/172] - loss: 1.0236
Epoch 1 [22/172] - loss: 0.9265
Epoch 1 [23/172] - loss: 1.2419
Epoch 1 [24/172] - loss: 1.6467
Epoch 1 [25/172] - loss: 1.0166
Epoch 1 [26/172] - loss: 1.3587
Epoch 1 [27/172] - loss: 1.3294
Epoch 1 [28/172] - loss: 1.1631
Epoch 1 [29/172] - loss: 0.9022
Epoch 1 [30/172] - loss: 0.9665, acc: 0.5000
Epoch 1 [31/172] - loss: 1.4190
Epoch 1 [32/172] - loss: 0.8932
Epoch 1 [33/172] - loss: 1.1072
Epoch 1 [34/172] - loss: 0.9361
Epoch 1 [35/172] - loss: 1.1708
Epoch 1 [36/172] - loss: 0.9615
Epoch 1 [37/172] - loss: 0.9464
Epoch 1 [38/172] - loss: 1.0121
Epoch 1 [39/172] - loss: 0.8500
Epoch 1 [40/172] - loss: 1.0768, acc: 0.5938
Epoch 1 [41/172] - loss: 0.9668
Epoch 1 [42/172] - loss: 0.9698
Epoch 1 [43/172] - loss: 1.1065
Epoch 1 [44/172] - loss: 1.2335
Epoch 1 [45/172] - loss: 1.0121
Epoch 1 [46/172] - loss: 0.8091
Epoch 1 [47/172] - loss: 0.8337
Epoch 1 [48/172] - loss: 0.9470
Epoch 1 [49/172] - loss: 0.8583
Epoch 1 [50/172] - loss: 1.0732, acc: 0.4375
Epoch 1 [51/172] - loss: 0.8885
Epoch 1 [52/172] - loss: 1.0485
Epoch 1 [53/172] - loss: 0.9057
Epoch 1 [54/172] - loss: 0.8520
Epoch 1 [55/172] - loss: 0.6738
Epoch 1 [56/172] - loss: 1.2558
Epoch 1 [57/172] - loss: 1.1793
Epoch 1 [58/172] - loss: 0.6971
Epoch 1 [59/172] - loss: 1.2521
Epoch 1 [60/172] - loss: 0.6224, acc: 0.7812
Epoch 1 [61/172] - loss: 1.1127
Epoch 1 [62/172] - loss: 0.7908
Epoch 1 [63/172] - loss: 0.7531
Epoch 1 [64/172] - loss: 0.6385
Epoch 1 [65/172] - loss: 1.3736
Epoch 1 [66/172] - loss: 0.9611
Epoch 1 [67/172] - loss: 1.0447
Epoch 1 [68/172] - loss: 0.8118
Epoch 1 [69/172] - loss: 1.0889
Epoch 1 [70/172] - loss: 0.8366, acc: 0.5938
Epoch 1 [71/172] - loss: 0.6427
Epoch 1 [72/172] - loss: 0.8241
Epoch 1 [73/172] - loss: 0.6250
Epoch 1 [74/172] - loss: 0.7281
Epoch 1 [75/172] - loss: 0.5546
Epoch 1 [76/172] - loss: 0.8790
Epoch 1 [77/172] - loss: 0.8045
Epoch 1 [78/172] - loss: 0.7896
Epoch 1 [79/172] - loss: 0.8281
Epoch 1 [80/172] - loss: 0.4548, acc: 0.8438
Epoch 1 [81/172] - loss: 0.7070
Epoch 1 [82/172] - loss: 0.7933
Epoch 1 [83/172] - loss: 0.8340
Epoch 1 [84/172] - loss: 0.8969
Epoch 1 [85/172] - loss: 0.9134
Epoch 1 [86/172] - loss: 0.6438
Epoch 1 [87/172] - loss: 0.8280
Epoch 1 [88/172] - loss: 0.9277
Epoch 1 [89/172] - loss: 1.0916
Epoch 1 [90/172] - loss: 1.0252, acc: 0.6562
Epoch 1 [91/172] - loss: 0.6478
Epoch 1 [92/172] - loss: 0.7730
Epoch 1 [93/172] - loss: 0.7341
Epoch 1 [94/172] - loss: 0.5128
Epoch 1 [95/172] - loss: 0.7647
Epoch 1 [96/172] - loss: 0.6204
Epoch 1 [97/172] - loss: 0.6787
Epoch 1 [98/172] - loss: 0.5489
Epoch 1 [99/172] - loss: 0.8419
Epoch 1 [100/172] - loss: 1.0206, acc: 0.6250

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5824, log_difficulty=0.4590, weight=3.2948
neutral: count=983.0, difficulty=0.5831, log_difficulty=0.4594, weight=3.2968
negative: count=1119.0, difficulty=0.5878, log_difficulty=0.4623, weight=3.3117

当前batch的pt分布：
positive: min=0.1145, max=0.5965, mean=0.3802
neutral: min=0.3565, max=0.9538, mean=0.6928
negative: min=0.1856, max=0.7550, mean=0.4148

当前batch准确率：
整体准确率: 0.5625
positive 准确率: 0.5833
neutral 准确率: 1.0000
negative 准确率: 0.4375

损失分量：
基础交叉熵: 0.9450
焦点损失: 0.3342
边界损失: 0.5727
总损失: 1.0509
Epoch 1 [101/172] - loss: 1.0509
Epoch 1 [102/172] - loss: 0.6966
Epoch 1 [103/172] - loss: 0.8858
Epoch 1 [104/172] - loss: 0.5521
Epoch 1 [105/172] - loss: 0.9562
Epoch 1 [106/172] - loss: 1.2446
Epoch 1 [107/172] - loss: 0.6667
Epoch 1 [108/172] - loss: 0.8782
Epoch 1 [109/172] - loss: 0.8738
Epoch 1 [110/172] - loss: 0.8539, acc: 0.5938
Epoch 1 [111/172] - loss: 0.8092
Epoch 1 [112/172] - loss: 0.6252
Epoch 1 [113/172] - loss: 0.3577
Epoch 1 [114/172] - loss: 0.7036
Epoch 1 [115/172] - loss: 0.7023
Epoch 1 [116/172] - loss: 0.5530
Epoch 1 [117/172] - loss: 0.6341
Epoch 1 [118/172] - loss: 0.5354
Epoch 1 [119/172] - loss: 0.4971
Epoch 1 [120/172] - loss: 0.5051, acc: 0.8125
Epoch 1 [121/172] - loss: 0.5205
Epoch 1 [122/172] - loss: 0.7325
Epoch 1 [123/172] - loss: 0.5011
Epoch 1 [124/172] - loss: 0.5183
Epoch 1 [125/172] - loss: 0.4943
Epoch 1 [126/172] - loss: 0.8843
Epoch 1 [127/172] - loss: 0.4245
Epoch 1 [128/172] - loss: 0.4953
Epoch 1 [129/172] - loss: 1.0320
Epoch 1 [130/172] - loss: 0.6785, acc: 0.7500
Epoch 1 [131/172] - loss: 0.2861
Epoch 1 [132/172] - loss: 0.5612
Epoch 1 [133/172] - loss: 0.5115
Epoch 1 [134/172] - loss: 0.6048
Epoch 1 [135/172] - loss: 0.9423
Epoch 1 [136/172] - loss: 0.6078
Epoch 1 [137/172] - loss: 0.6681
Epoch 1 [138/172] - loss: 0.4655
Epoch 1 [139/172] - loss: 0.4529
Epoch 1 [140/172] - loss: 0.7252, acc: 0.7188
Epoch 1 [141/172] - loss: 0.6435
Epoch 1 [142/172] - loss: 0.6291
Epoch 1 [143/172] - loss: 0.5272
Epoch 1 [144/172] - loss: 0.3149
Epoch 1 [145/172] - loss: 0.7203
Epoch 1 [146/172] - loss: 0.6677
Epoch 1 [147/172] - loss: 0.5827
Epoch 1 [148/172] - loss: 0.4221
Epoch 1 [149/172] - loss: 0.2192
Epoch 1 [150/172] - loss: 0.5428, acc: 0.6250
Epoch 1 [151/172] - loss: 0.6313
Epoch 1 [152/172] - loss: 0.5773
Epoch 1 [153/172] - loss: 0.4157
Epoch 1 [154/172] - loss: 0.4698
Epoch 1 [155/172] - loss: 0.4967
Epoch 1 [156/172] - loss: 0.8536
Epoch 1 [157/172] - loss: 0.4707
Epoch 1 [158/172] - loss: 0.4008
Epoch 1 [159/172] - loss: 0.4920
Epoch 1 [160/172] - loss: 0.5380, acc: 0.7188
Epoch 1 [161/172] - loss: 0.3313
Epoch 1 [162/172] - loss: 0.3276
Epoch 1 [163/172] - loss: 0.4171
Epoch 1 [164/172] - loss: 0.6938
Epoch 1 [165/172] - loss: 0.3545
Epoch 1 [166/172] - loss: 0.6107
Epoch 1 [167/172] - loss: 0.3727
Epoch 1 [168/172] - loss: 0.4136
Epoch 1 [169/172] - loss: 0.5599
Epoch 1 [170/172] - loss: 0.2111, acc: 0.9375
Epoch 1 [171/172] - loss: 0.4842
Epoch 1 [172/172] - loss: 0.4060

类别准确率:
positive: 0.7473 (349/467)
neutral: 0.4819 (40/83)
negative: 0.6160 (154/250)

Epoch 1/10
Train Loss: 0.4428, Train Acc: 0.7758
Val Loss: 0.7170, Val Acc: 0.6787
Epoch 2 [1/172] - loss: 0.5996, acc: 0.7500
Epoch 2 [2/172] - loss: 0.1815
Epoch 2 [3/172] - loss: 0.2749
Epoch 2 [4/172] - loss: 0.5861
Epoch 2 [5/172] - loss: 0.7101
Epoch 2 [6/172] - loss: 0.4681
Epoch 2 [7/172] - loss: 0.4432
Epoch 2 [8/172] - loss: 0.5502
Epoch 2 [9/172] - loss: 0.4921
Epoch 2 [10/172] - loss: 0.3393, acc: 0.8438
Epoch 2 [11/172] - loss: 0.4102
Epoch 2 [12/172] - loss: 0.3004
Epoch 2 [13/172] - loss: 0.5724
Epoch 2 [14/172] - loss: 0.4327
Epoch 2 [15/172] - loss: 0.3340
Epoch 2 [16/172] - loss: 0.4409
Epoch 2 [17/172] - loss: 0.5173
Epoch 2 [18/172] - loss: 0.3753
Epoch 2 [19/172] - loss: 0.2565
Epoch 2 [20/172] - loss: 0.4498, acc: 0.8125
Epoch 2 [21/172] - loss: 0.4133
Epoch 2 [22/172] - loss: 0.3495
Epoch 2 [23/172] - loss: 0.2475
Epoch 2 [24/172] - loss: 0.7759
Epoch 2 [25/172] - loss: 0.3168
Epoch 2 [26/172] - loss: 0.1749
Epoch 2 [27/172] - loss: 0.4787
Epoch 2 [28/172] - loss: 0.2432

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5274, log_difficulty=0.4236, weight=3.1178
neutral: count=1952.0, difficulty=0.4879, log_difficulty=0.3974, weight=2.9868
negative: count=2216.0, difficulty=0.5256, log_difficulty=0.4224, weight=3.1120

当前batch的pt分布：
positive: min=0.3976, max=0.9159, mean=0.6953
neutral: min=0.3197, max=0.8271, mean=0.6802
negative: min=0.2544, max=0.8741, mean=0.6273

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.8889
neutral 准确率: 0.9091
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.4564
焦点损失: 0.0792
边界损失: 0.3860
总损失: 0.2583
Epoch 2 [29/172] - loss: 0.2583
Epoch 2 [30/172] - loss: 0.2670, acc: 0.9062
Epoch 2 [31/172] - loss: 0.2291
Epoch 2 [32/172] - loss: 0.3366
Epoch 2 [33/172] - loss: 0.2824
Epoch 2 [34/172] - loss: 0.4714
Epoch 2 [35/172] - loss: 0.2766
Epoch 2 [36/172] - loss: 0.4834
Epoch 2 [37/172] - loss: 0.2959
Epoch 2 [38/172] - loss: 0.3342
Epoch 2 [39/172] - loss: 0.7038
Epoch 2 [40/172] - loss: 0.5117, acc: 0.7188
Epoch 2 [41/172] - loss: 0.4579
Epoch 2 [42/172] - loss: 0.1166
Epoch 2 [43/172] - loss: 0.3732
Epoch 2 [44/172] - loss: 0.5968
Epoch 2 [45/172] - loss: 0.3341
Epoch 2 [46/172] - loss: 0.2817
Epoch 2 [47/172] - loss: 0.2593
Epoch 2 [48/172] - loss: 0.3574
Epoch 2 [49/172] - loss: 0.2525
Epoch 2 [50/172] - loss: 0.4387, acc: 0.6875
Epoch 2 [51/172] - loss: 0.3781
Epoch 2 [52/172] - loss: 0.3604
Epoch 2 [53/172] - loss: 0.2960
Epoch 2 [54/172] - loss: 0.3408
Epoch 2 [55/172] - loss: 0.3966
Epoch 2 [56/172] - loss: 0.2084
Epoch 2 [57/172] - loss: 0.2721
Epoch 2 [58/172] - loss: 0.2794
Epoch 2 [59/172] - loss: 0.4541
Epoch 2 [60/172] - loss: 0.2356, acc: 0.8438
Epoch 2 [61/172] - loss: 0.1972
Epoch 2 [62/172] - loss: 0.2910
Epoch 2 [63/172] - loss: 0.3280
Epoch 2 [64/172] - loss: 0.3995
Epoch 2 [65/172] - loss: 0.3113
Epoch 2 [66/172] - loss: 0.3156
Epoch 2 [67/172] - loss: 0.1987
Epoch 2 [68/172] - loss: 0.2281
Epoch 2 [69/172] - loss: 0.1209
Epoch 2 [70/172] - loss: 0.5680, acc: 0.8125
Epoch 2 [71/172] - loss: 0.3977
Epoch 2 [72/172] - loss: 0.3600
Epoch 2 [73/172] - loss: 0.4001
Epoch 2 [74/172] - loss: 0.1581
Epoch 2 [75/172] - loss: 0.2827
Epoch 2 [76/172] - loss: 0.3553
Epoch 2 [77/172] - loss: 0.4838
Epoch 2 [78/172] - loss: 0.2615
Epoch 2 [79/172] - loss: 0.2346
Epoch 2 [80/172] - loss: 0.1928, acc: 0.8750
Epoch 2 [81/172] - loss: 0.2818
Epoch 2 [82/172] - loss: 0.3725
Epoch 2 [83/172] - loss: 0.2754
Epoch 2 [84/172] - loss: 0.3142
Epoch 2 [85/172] - loss: 0.2464
Epoch 2 [86/172] - loss: 0.2501
Epoch 2 [87/172] - loss: 0.6589
Epoch 2 [88/172] - loss: 0.2755
Epoch 2 [89/172] - loss: 0.1861
Epoch 2 [90/172] - loss: 0.3088, acc: 0.8438
Epoch 2 [91/172] - loss: 0.1732
Epoch 2 [92/172] - loss: 0.2470
Epoch 2 [93/172] - loss: 0.1772
Epoch 2 [94/172] - loss: 0.2691
Epoch 2 [95/172] - loss: 0.5235
Epoch 2 [96/172] - loss: 0.2154
Epoch 2 [97/172] - loss: 0.2811
Epoch 2 [98/172] - loss: 0.2113
Epoch 2 [99/172] - loss: 0.1426
Epoch 2 [100/172] - loss: 0.1651, acc: 0.9062
Epoch 2 [101/172] - loss: 0.1538
Epoch 2 [102/172] - loss: 0.1280
Epoch 2 [103/172] - loss: 0.3960
Epoch 2 [104/172] - loss: 0.2866
Epoch 2 [105/172] - loss: 0.1171
Epoch 2 [106/172] - loss: 0.2475
Epoch 2 [107/172] - loss: 0.1682
Epoch 2 [108/172] - loss: 0.5242
Epoch 2 [109/172] - loss: 0.1305
Epoch 2 [110/172] - loss: 0.2437, acc: 0.9062
Epoch 2 [111/172] - loss: 0.3686
Epoch 2 [112/172] - loss: 0.1493
Epoch 2 [113/172] - loss: 0.1126
Epoch 2 [114/172] - loss: 0.1700
Epoch 2 [115/172] - loss: 0.3544
Epoch 2 [116/172] - loss: 0.3722
Epoch 2 [117/172] - loss: 0.5251
Epoch 2 [118/172] - loss: 0.0743
Epoch 2 [119/172] - loss: 0.1616
Epoch 2 [120/172] - loss: 0.1755, acc: 0.9375
Epoch 2 [121/172] - loss: 0.1437
Epoch 2 [122/172] - loss: 0.6334
Epoch 2 [123/172] - loss: 0.2685
Epoch 2 [124/172] - loss: 0.2230
Epoch 2 [125/172] - loss: 0.2249
Epoch 2 [126/172] - loss: 0.1926
Epoch 2 [127/172] - loss: 0.1140
Epoch 2 [128/172] - loss: 0.2203

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4740, log_difficulty=0.3880, weight=2.9400
neutral: count=2949.0, difficulty=0.4074, log_difficulty=0.3417, weight=2.7087
negative: count=3294.0, difficulty=0.4729, log_difficulty=0.3872, weight=2.9360

当前batch的pt分布：
positive: min=0.3430, max=0.9307, mean=0.6958
neutral: min=0.5160, max=0.9556, mean=0.7804
negative: min=0.2203, max=0.9371, mean=0.6947

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.3633
焦点损失: 0.0577
边界损失: 0.3360
总损失: 0.1848
Epoch 2 [129/172] - loss: 0.1848
Epoch 2 [130/172] - loss: 0.1537, acc: 0.9375
Epoch 2 [131/172] - loss: 0.2413
Epoch 2 [132/172] - loss: 0.2590
Epoch 2 [133/172] - loss: 0.2873
Epoch 2 [134/172] - loss: 0.2781
Epoch 2 [135/172] - loss: 0.5545
Epoch 2 [136/172] - loss: 0.2918
Epoch 2 [137/172] - loss: 0.1515
Epoch 2 [138/172] - loss: 0.2140
Epoch 2 [139/172] - loss: 0.1828
Epoch 2 [140/172] - loss: 0.1360, acc: 0.9375
Epoch 2 [141/172] - loss: 0.1184
Epoch 2 [142/172] - loss: 0.3049
Epoch 2 [143/172] - loss: 0.2224
Epoch 2 [144/172] - loss: 0.1829
Epoch 2 [145/172] - loss: 0.5915
Epoch 2 [146/172] - loss: 0.1297
Epoch 2 [147/172] - loss: 0.1214
Epoch 2 [148/172] - loss: 0.2333
Epoch 2 [149/172] - loss: 0.4891
Epoch 2 [150/172] - loss: 0.2207, acc: 0.9375
Epoch 2 [151/172] - loss: 0.3005
Epoch 2 [152/172] - loss: 0.2500
Epoch 2 [153/172] - loss: 0.1315
Epoch 2 [154/172] - loss: 0.1710
Epoch 2 [155/172] - loss: 0.2952
Epoch 2 [156/172] - loss: 0.1047
Epoch 2 [157/172] - loss: 0.1002
Epoch 2 [158/172] - loss: 0.0979
Epoch 2 [159/172] - loss: 0.2468
Epoch 2 [160/172] - loss: 0.1007, acc: 0.9688
Epoch 2 [161/172] - loss: 0.1344
Epoch 2 [162/172] - loss: 0.1840
Epoch 2 [163/172] - loss: 0.4215
Epoch 2 [164/172] - loss: 0.2350
Epoch 2 [165/172] - loss: 0.2641
Epoch 2 [166/172] - loss: 0.3906
Epoch 2 [167/172] - loss: 0.3230
Epoch 2 [168/172] - loss: 0.1487
Epoch 2 [169/172] - loss: 0.1132
Epoch 2 [170/172] - loss: 0.1621, acc: 0.8750
Epoch 2 [171/172] - loss: 0.4822
Epoch 2 [172/172] - loss: 0.8766

类别准确率:
positive: 0.8522 (398/467)
neutral: 0.4337 (36/83)
negative: 0.4960 (124/250)

Epoch 2/10
Train Loss: 0.2676, Train Acc: 0.8909
Val Loss: 0.7121, Val Acc: 0.6975
Epoch 3 [1/172] - loss: 0.1510, acc: 0.9062
Epoch 3 [2/172] - loss: 0.1493
Epoch 3 [3/172] - loss: 0.0741
Epoch 3 [4/172] - loss: 0.1733
Epoch 3 [5/172] - loss: 0.1323
Epoch 3 [6/172] - loss: 0.0852
Epoch 3 [7/172] - loss: 0.1123
Epoch 3 [8/172] - loss: 0.1170
Epoch 3 [9/172] - loss: 0.0728
Epoch 3 [10/172] - loss: 0.0998, acc: 0.9375
Epoch 3 [11/172] - loss: 0.0541
Epoch 3 [12/172] - loss: 0.1281
Epoch 3 [13/172] - loss: 0.0502
Epoch 3 [14/172] - loss: 0.0771
Epoch 3 [15/172] - loss: 0.0686
Epoch 3 [16/172] - loss: 0.1905
Epoch 3 [17/172] - loss: 0.1052
Epoch 3 [18/172] - loss: 0.1832
Epoch 3 [19/172] - loss: 0.1080
Epoch 3 [20/172] - loss: 0.0713, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1512
Epoch 3 [22/172] - loss: 0.1384
Epoch 3 [23/172] - loss: 0.1607
Epoch 3 [24/172] - loss: 0.1483
Epoch 3 [25/172] - loss: 0.0869
Epoch 3 [26/172] - loss: 0.1296
Epoch 3 [27/172] - loss: 0.1495
Epoch 3 [28/172] - loss: 0.0753
Epoch 3 [29/172] - loss: 0.2243
Epoch 3 [30/172] - loss: 0.1027, acc: 0.9375
Epoch 3 [31/172] - loss: 0.0670
Epoch 3 [32/172] - loss: 0.0722
Epoch 3 [33/172] - loss: 0.0931
Epoch 3 [34/172] - loss: 0.1439
Epoch 3 [35/172] - loss: 0.1080
Epoch 3 [36/172] - loss: 0.0945
Epoch 3 [37/172] - loss: 0.0944
Epoch 3 [38/172] - loss: 0.0933
Epoch 3 [39/172] - loss: 0.0356
Epoch 3 [40/172] - loss: 0.1649, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1684
Epoch 3 [42/172] - loss: 0.1375
Epoch 3 [43/172] - loss: 0.0761
Epoch 3 [44/172] - loss: 0.2322
Epoch 3 [45/172] - loss: 0.3089
Epoch 3 [46/172] - loss: 0.1074
Epoch 3 [47/172] - loss: 0.0606
Epoch 3 [48/172] - loss: 0.1016
Epoch 3 [49/172] - loss: 0.0988
Epoch 3 [50/172] - loss: 0.0594, acc: 1.0000
Epoch 3 [51/172] - loss: 0.2092
Epoch 3 [52/172] - loss: 0.1657
Epoch 3 [53/172] - loss: 0.1061
Epoch 3 [54/172] - loss: 0.1020
Epoch 3 [55/172] - loss: 0.0843
Epoch 3 [56/172] - loss: 0.1034

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.4284, log_difficulty=0.3566, weight=2.7829
neutral: count=3923.0, difficulty=0.3542, log_difficulty=0.3032, weight=2.5161
negative: count=4382.0, difficulty=0.4235, log_difficulty=0.3531, weight=2.7654

当前batch的pt分布：
positive: min=0.4309, max=0.9225, mean=0.7525
neutral: min=0.0508, max=0.9409, mean=0.7065
negative: min=0.7727, max=0.9866, mean=0.8925

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3643
焦点损失: 0.1098
边界损失: 0.2924
总损失: 0.2812
Epoch 3 [57/172] - loss: 0.2812
Epoch 3 [58/172] - loss: 0.1253
Epoch 3 [59/172] - loss: 0.0836
Epoch 3 [60/172] - loss: 0.2198, acc: 0.9062
Epoch 3 [61/172] - loss: 0.0999
Epoch 3 [62/172] - loss: 0.1316
Epoch 3 [63/172] - loss: 0.1505
Epoch 3 [64/172] - loss: 0.1204
Epoch 3 [65/172] - loss: 0.1119
Epoch 3 [66/172] - loss: 0.1806
Epoch 3 [67/172] - loss: 0.1534
Epoch 3 [68/172] - loss: 0.0574
Epoch 3 [69/172] - loss: 0.2159
Epoch 3 [70/172] - loss: 0.0888, acc: 0.9688
Epoch 3 [71/172] - loss: 0.1703
Epoch 3 [72/172] - loss: 0.1934
Epoch 3 [73/172] - loss: 0.0606
Epoch 3 [74/172] - loss: 0.1784
Epoch 3 [75/172] - loss: 0.1259
Epoch 3 [76/172] - loss: 0.1282
Epoch 3 [77/172] - loss: 0.1416
Epoch 3 [78/172] - loss: 0.0836
Epoch 3 [79/172] - loss: 0.0571
Epoch 3 [80/172] - loss: 0.1049, acc: 0.9375
Epoch 3 [81/172] - loss: 0.0624
Epoch 3 [82/172] - loss: 0.1513
Epoch 3 [83/172] - loss: 0.0564
Epoch 3 [84/172] - loss: 0.0649
Epoch 3 [85/172] - loss: 0.0946
Epoch 3 [86/172] - loss: 0.0638
Epoch 3 [87/172] - loss: 0.4624
Epoch 3 [88/172] - loss: 0.1346
Epoch 3 [89/172] - loss: 0.0426
Epoch 3 [90/172] - loss: 0.0701, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1272
Epoch 3 [92/172] - loss: 0.0659
Epoch 3 [93/172] - loss: 0.2769
Epoch 3 [94/172] - loss: 0.1752
Epoch 3 [95/172] - loss: 0.0480
Epoch 3 [96/172] - loss: 0.1395
Epoch 3 [97/172] - loss: 0.1260
Epoch 3 [98/172] - loss: 0.0833
Epoch 3 [99/172] - loss: 0.0740
Epoch 3 [100/172] - loss: 0.0868, acc: 0.9375
Epoch 3 [101/172] - loss: 0.0820
Epoch 3 [102/172] - loss: 0.1034
Epoch 3 [103/172] - loss: 0.1408
Epoch 3 [104/172] - loss: 0.0500
Epoch 3 [105/172] - loss: 0.0865
Epoch 3 [106/172] - loss: 0.1062
Epoch 3 [107/172] - loss: 0.0796
Epoch 3 [108/172] - loss: 0.1604
Epoch 3 [109/172] - loss: 0.0781
Epoch 3 [110/172] - loss: 0.2344, acc: 0.8750
Epoch 3 [111/172] - loss: 0.0788
Epoch 3 [112/172] - loss: 0.1354
Epoch 3 [113/172] - loss: 0.0682
Epoch 3 [114/172] - loss: 0.1305
Epoch 3 [115/172] - loss: 0.1288
Epoch 3 [116/172] - loss: 0.0712
Epoch 3 [117/172] - loss: 0.0439
Epoch 3 [118/172] - loss: 0.1158
Epoch 3 [119/172] - loss: 0.0851
Epoch 3 [120/172] - loss: 0.1379, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1692
Epoch 3 [122/172] - loss: 0.0615
Epoch 3 [123/172] - loss: 0.1357
Epoch 3 [124/172] - loss: 0.1116
Epoch 3 [125/172] - loss: 0.1437
Epoch 3 [126/172] - loss: 0.5857
Epoch 3 [127/172] - loss: 0.1158
Epoch 3 [128/172] - loss: 0.0531
Epoch 3 [129/172] - loss: 0.0844
Epoch 3 [130/172] - loss: 0.0523, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1462
Epoch 3 [132/172] - loss: 0.0471
Epoch 3 [133/172] - loss: 0.0724
Epoch 3 [134/172] - loss: 0.1246
Epoch 3 [135/172] - loss: 0.0381
Epoch 3 [136/172] - loss: 0.1506
Epoch 3 [137/172] - loss: 0.0585
Epoch 3 [138/172] - loss: 0.1304
Epoch 3 [139/172] - loss: 0.0913
Epoch 3 [140/172] - loss: 0.0893, acc: 1.0000
Epoch 3 [141/172] - loss: 0.1101
Epoch 3 [142/172] - loss: 0.1253
Epoch 3 [143/172] - loss: 0.0613
Epoch 3 [144/172] - loss: 0.2167
Epoch 3 [145/172] - loss: 0.1033
Epoch 3 [146/172] - loss: 0.1308
Epoch 3 [147/172] - loss: 0.0944
Epoch 3 [148/172] - loss: 0.0617
Epoch 3 [149/172] - loss: 0.0885
Epoch 3 [150/172] - loss: 0.1901, acc: 0.9062
Epoch 3 [151/172] - loss: 0.3090
Epoch 3 [152/172] - loss: 0.1324
Epoch 3 [153/172] - loss: 0.0524
Epoch 3 [154/172] - loss: 0.1458
Epoch 3 [155/172] - loss: 0.0497
Epoch 3 [156/172] - loss: 0.0983

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3892, log_difficulty=0.3287, weight=2.6437
neutral: count=4903.0, difficulty=0.3135, log_difficulty=0.2727, weight=2.3636
negative: count=5500.0, difficulty=0.3847, log_difficulty=0.3255, weight=2.6276

当前batch的pt分布：
positive: min=0.6426, max=0.9171, mean=0.7864
neutral: min=0.6277, max=0.9757, mean=0.8737
negative: min=0.5447, max=0.9713, mean=0.7913

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2115
焦点损失: 0.0103
边界损失: 0.2620
总损失: 0.0502
Epoch 3 [157/172] - loss: 0.0502
Epoch 3 [158/172] - loss: 0.1804
Epoch 3 [159/172] - loss: 0.0531
Epoch 3 [160/172] - loss: 0.1714, acc: 0.8125
Epoch 3 [161/172] - loss: 0.1759
Epoch 3 [162/172] - loss: 0.0735
Epoch 3 [163/172] - loss: 0.0822
Epoch 3 [164/172] - loss: 0.0642
Epoch 3 [165/172] - loss: 0.0627
Epoch 3 [166/172] - loss: 0.0890
Epoch 3 [167/172] - loss: 0.0490
Epoch 3 [168/172] - loss: 0.0440
Epoch 3 [169/172] - loss: 0.0535
Epoch 3 [170/172] - loss: 0.0968, acc: 0.9688
Epoch 3 [171/172] - loss: 0.0930
Epoch 3 [172/172] - loss: 0.0618

类别准确率:
positive: 0.8672 (405/467)
neutral: 0.2169 (18/83)
negative: 0.6200 (155/250)

Epoch 3/10
Train Loss: 0.0876, Train Acc: 0.9657
Val Loss: 0.6812, Val Acc: 0.7225
Epoch 4 [1/172] - loss: 0.0501, acc: 1.0000
Epoch 4 [2/172] - loss: 0.0910
Epoch 4 [3/172] - loss: 0.0455
Epoch 4 [4/172] - loss: 0.0409
Epoch 4 [5/172] - loss: 0.0535
Epoch 4 [6/172] - loss: 0.0281
Epoch 4 [7/172] - loss: 0.0550
Epoch 4 [8/172] - loss: 0.0273
Epoch 4 [9/172] - loss: 0.1138
Epoch 4 [10/172] - loss: 0.0562, acc: 1.0000
Epoch 4 [11/172] - loss: 0.0299
Epoch 4 [12/172] - loss: 0.0740
Epoch 4 [13/172] - loss: 0.0831
Epoch 4 [14/172] - loss: 0.0661
Epoch 4 [15/172] - loss: 0.0323
Epoch 4 [16/172] - loss: 0.0380
Epoch 4 [17/172] - loss: 0.0277
Epoch 4 [18/172] - loss: 0.0593
Epoch 4 [19/172] - loss: 0.0372
Epoch 4 [20/172] - loss: 0.0446, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1476
Epoch 4 [22/172] - loss: 0.0260
Epoch 4 [23/172] - loss: 0.0416
Epoch 4 [24/172] - loss: 0.0676
Epoch 4 [25/172] - loss: 0.0224
Epoch 4 [26/172] - loss: 0.2479
Epoch 4 [27/172] - loss: 0.0259
Epoch 4 [28/172] - loss: 0.0827
Epoch 4 [29/172] - loss: 0.0871
Epoch 4 [30/172] - loss: 0.0618, acc: 0.9688
Epoch 4 [31/172] - loss: 0.0960
Epoch 4 [32/172] - loss: 0.0253
Epoch 4 [33/172] - loss: 0.0576
Epoch 4 [34/172] - loss: 0.1448
Epoch 4 [35/172] - loss: 0.0686
Epoch 4 [36/172] - loss: 0.0521
Epoch 4 [37/172] - loss: 0.0492
Epoch 4 [38/172] - loss: 0.0245
Epoch 4 [39/172] - loss: 0.0955
Epoch 4 [40/172] - loss: 0.1648, acc: 0.9688
Epoch 4 [41/172] - loss: 0.0347
Epoch 4 [42/172] - loss: 0.3083
Epoch 4 [43/172] - loss: 0.0521
Epoch 4 [44/172] - loss: 0.0517
Epoch 4 [45/172] - loss: 0.0257
Epoch 4 [46/172] - loss: 0.0382
Epoch 4 [47/172] - loss: 0.0461
Epoch 4 [48/172] - loss: 0.0368
Epoch 4 [49/172] - loss: 0.0414
Epoch 4 [50/172] - loss: 0.0970, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0255
Epoch 4 [52/172] - loss: 0.0559
Epoch 4 [53/172] - loss: 0.0221
Epoch 4 [54/172] - loss: 0.0801
Epoch 4 [55/172] - loss: 0.1937
Epoch 4 [56/172] - loss: 0.0588
Epoch 4 [57/172] - loss: 0.0329
Epoch 4 [58/172] - loss: 0.0305
Epoch 4 [59/172] - loss: 0.0678
Epoch 4 [60/172] - loss: 0.0472, acc: 0.9688
Epoch 4 [61/172] - loss: 0.0731
Epoch 4 [62/172] - loss: 0.0446
Epoch 4 [63/172] - loss: 0.0390
Epoch 4 [64/172] - loss: 0.0454
Epoch 4 [65/172] - loss: 0.0755
Epoch 4 [66/172] - loss: 0.0347
Epoch 4 [67/172] - loss: 0.0425
Epoch 4 [68/172] - loss: 0.0273
Epoch 4 [69/172] - loss: 0.0390
Epoch 4 [70/172] - loss: 0.0360, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0443
Epoch 4 [72/172] - loss: 0.0332
Epoch 4 [73/172] - loss: 0.0365
Epoch 4 [74/172] - loss: 0.0805
Epoch 4 [75/172] - loss: 0.0519
Epoch 4 [76/172] - loss: 0.0259
Epoch 4 [77/172] - loss: 0.0592
Epoch 4 [78/172] - loss: 0.0473
Epoch 4 [79/172] - loss: 0.0463
Epoch 4 [80/172] - loss: 0.0256, acc: 1.0000
Epoch 4 [81/172] - loss: 0.0938
Epoch 4 [82/172] - loss: 0.0356
Epoch 4 [83/172] - loss: 0.0314
Epoch 4 [84/172] - loss: 0.0296

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3535, log_difficulty=0.3027, weight=2.5134
neutral: count=5865.0, difficulty=0.2807, log_difficulty=0.2474, weight=2.2372
negative: count=6629.0, difficulty=0.3479, log_difficulty=0.2986, weight=2.4929

当前batch的pt分布：
positive: min=0.3653, max=0.9495, mean=0.7987
neutral: min=0.9232, max=0.9868, mean=0.9716
negative: min=0.7878, max=0.9724, mean=0.9116

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1578
焦点损失: 0.0154
边界损失: 0.2103
总损失: 0.0558
Epoch 4 [85/172] - loss: 0.0558
Epoch 4 [86/172] - loss: 0.0752
Epoch 4 [87/172] - loss: 0.1067
Epoch 4 [88/172] - loss: 0.0232
Epoch 4 [89/172] - loss: 0.0233
Epoch 4 [90/172] - loss: 0.0273, acc: 1.0000
Epoch 4 [91/172] - loss: 0.2349
Epoch 4 [92/172] - loss: 0.0946
Epoch 4 [93/172] - loss: 0.0483
Epoch 4 [94/172] - loss: 0.0520
Epoch 4 [95/172] - loss: 0.0602
Epoch 4 [96/172] - loss: 0.0411
Epoch 4 [97/172] - loss: 0.0756
Epoch 4 [98/172] - loss: 0.0935
Epoch 4 [99/172] - loss: 0.0447
Epoch 4 [100/172] - loss: 0.0557, acc: 1.0000
Epoch 4 [101/172] - loss: 0.0668
Epoch 4 [102/172] - loss: 0.0314
Epoch 4 [103/172] - loss: 0.0492
Epoch 4 [104/172] - loss: 0.0238
Epoch 4 [105/172] - loss: 0.0692
Epoch 4 [106/172] - loss: 0.0574
Epoch 4 [107/172] - loss: 0.0791
Epoch 4 [108/172] - loss: 0.0612
Epoch 4 [109/172] - loss: 0.0272
Epoch 4 [110/172] - loss: 0.3185, acc: 0.8438
Epoch 4 [111/172] - loss: 0.0307
Epoch 4 [112/172] - loss: 0.0472
Epoch 4 [113/172] - loss: 0.0451
Epoch 4 [114/172] - loss: 0.0593
Epoch 4 [115/172] - loss: 0.0907
Epoch 4 [116/172] - loss: 0.1173
Epoch 4 [117/172] - loss: 0.0225
Epoch 4 [118/172] - loss: 0.0948
Epoch 4 [119/172] - loss: 0.0240
Epoch 4 [120/172] - loss: 0.1250, acc: 0.9688
Epoch 4 [121/172] - loss: 0.0344
Epoch 4 [122/172] - loss: 0.1582
Epoch 4 [123/172] - loss: 0.0221
Epoch 4 [124/172] - loss: 0.0284
Epoch 4 [125/172] - loss: 0.1571
Epoch 4 [126/172] - loss: 0.2551
Epoch 4 [127/172] - loss: 0.0950
Epoch 4 [128/172] - loss: 0.0365
Epoch 4 [129/172] - loss: 0.0256
Epoch 4 [130/172] - loss: 0.0322, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0239
Epoch 4 [132/172] - loss: 0.0253
Epoch 4 [133/172] - loss: 0.0868
Epoch 4 [134/172] - loss: 0.0452
Epoch 4 [135/172] - loss: 0.0416
Epoch 4 [136/172] - loss: 0.1957
Epoch 4 [137/172] - loss: 0.0758
Epoch 4 [138/172] - loss: 0.0603
Epoch 4 [139/172] - loss: 0.0869
Epoch 4 [140/172] - loss: 0.0510, acc: 1.0000
Epoch 4 [141/172] - loss: 0.1435
Epoch 4 [142/172] - loss: 0.0473
Epoch 4 [143/172] - loss: 0.0376
Epoch 4 [144/172] - loss: 0.1280
Epoch 4 [145/172] - loss: 0.1704
Epoch 4 [146/172] - loss: 0.0512
Epoch 4 [147/172] - loss: 0.1001
Epoch 4 [148/172] - loss: 0.0457
Epoch 4 [149/172] - loss: 0.0287
Epoch 4 [150/172] - loss: 0.2279, acc: 0.9375
Epoch 4 [151/172] - loss: 0.0980
Epoch 4 [152/172] - loss: 0.0219
Epoch 4 [153/172] - loss: 0.0438
Epoch 4 [154/172] - loss: 0.0931
Epoch 4 [155/172] - loss: 0.0342
Epoch 4 [156/172] - loss: 0.0520
Epoch 4 [157/172] - loss: 0.2554
Epoch 4 [158/172] - loss: 0.0347
Epoch 4 [159/172] - loss: 0.1344
Epoch 4 [160/172] - loss: 0.1181, acc: 0.9375
Epoch 4 [161/172] - loss: 0.0427
Epoch 4 [162/172] - loss: 0.0385
Epoch 4 [163/172] - loss: 0.0597
Epoch 4 [164/172] - loss: 0.0404
Epoch 4 [165/172] - loss: 0.0865
Epoch 4 [166/172] - loss: 0.0802
Epoch 4 [167/172] - loss: 0.0851
Epoch 4 [168/172] - loss: 0.0402
Epoch 4 [169/172] - loss: 0.2162
Epoch 4 [170/172] - loss: 0.0771, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0579
Epoch 4 [172/172] - loss: 0.0301

类别准确率:
positive: 0.8972 (419/467)
neutral: 0.2892 (24/83)
negative: 0.5280 (132/250)

Epoch 4/10
Train Loss: 0.0873, Train Acc: 0.9657
Val Loss: 0.7114, Val Acc: 0.7188
Epoch 5 [1/172] - loss: 0.0291, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0481
Epoch 5 [3/172] - loss: 0.0234
Epoch 5 [4/172] - loss: 0.0908
Epoch 5 [5/172] - loss: 0.0359
Epoch 5 [6/172] - loss: 0.0676
Epoch 5 [7/172] - loss: 0.0430
Epoch 5 [8/172] - loss: 0.0319
Epoch 5 [9/172] - loss: 0.0805
Epoch 5 [10/172] - loss: 0.0352, acc: 1.0000
Epoch 5 [11/172] - loss: 0.0510
Epoch 5 [12/172] - loss: 0.0249

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.3242, log_difficulty=0.2808, weight=2.4042
neutral: count=6845.0, difficulty=0.2573, log_difficulty=0.2289, weight=2.1447
negative: count=7694.0, difficulty=0.3208, log_difficulty=0.2782, weight=2.3911

当前batch的pt分布：
positive: min=0.4468, max=0.9676, mean=0.8152
neutral: min=0.9138, max=0.9924, mean=0.9604
negative: min=0.7827, max=0.9701, mean=0.8824

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1508
焦点损失: 0.0107
边界损失: 0.2157
总损失: 0.0446
Epoch 5 [13/172] - loss: 0.0446
Epoch 5 [14/172] - loss: 0.0521
Epoch 5 [15/172] - loss: 0.0213
Epoch 5 [16/172] - loss: 0.0343
Epoch 5 [17/172] - loss: 0.0431
Epoch 5 [18/172] - loss: 0.0208
Epoch 5 [19/172] - loss: 0.0419
Epoch 5 [20/172] - loss: 0.0662, acc: 0.9375
Epoch 5 [21/172] - loss: 0.1321
Epoch 5 [22/172] - loss: 0.2262
Epoch 5 [23/172] - loss: 0.0412
Epoch 5 [24/172] - loss: 0.0342
Epoch 5 [25/172] - loss: 0.0263
Epoch 5 [26/172] - loss: 0.1410
Epoch 5 [27/172] - loss: 0.0574
Epoch 5 [28/172] - loss: 0.0291
Epoch 5 [29/172] - loss: 0.0323
Epoch 5 [30/172] - loss: 0.0333, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0537
Epoch 5 [32/172] - loss: 0.0217
Epoch 5 [33/172] - loss: 0.0342
Epoch 5 [34/172] - loss: 0.0230
Epoch 5 [35/172] - loss: 0.0222
Epoch 5 [36/172] - loss: 0.0251
Epoch 5 [37/172] - loss: 0.0237
Epoch 5 [38/172] - loss: 0.0398
Epoch 5 [39/172] - loss: 0.0809
Epoch 5 [40/172] - loss: 0.0340, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0703
Epoch 5 [42/172] - loss: 0.0326
Epoch 5 [43/172] - loss: 0.0939
Epoch 5 [44/172] - loss: 0.0329
Epoch 5 [45/172] - loss: 0.0202
Epoch 5 [46/172] - loss: 0.0790
Epoch 5 [47/172] - loss: 0.0335
Epoch 5 [48/172] - loss: 0.0353
Epoch 5 [49/172] - loss: 0.0228
Epoch 5 [50/172] - loss: 0.0363, acc: 1.0000
Epoch 5 [51/172] - loss: 0.0383
Epoch 5 [52/172] - loss: 0.0255
Epoch 5 [53/172] - loss: 0.0637
Epoch 5 [54/172] - loss: 0.1526
Epoch 5 [55/172] - loss: 0.0316
Epoch 5 [56/172] - loss: 0.0338
Epoch 5 [57/172] - loss: 0.0215
Epoch 5 [58/172] - loss: 0.0185
Epoch 5 [59/172] - loss: 0.0663
Epoch 5 [60/172] - loss: 0.0476, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0424
Epoch 5 [62/172] - loss: 0.0301
Epoch 5 [63/172] - loss: 0.1210
Epoch 5 [64/172] - loss: 0.0223
Epoch 5 [65/172] - loss: 0.0271
Epoch 5 [66/172] - loss: 0.0349
Epoch 5 [67/172] - loss: 0.0211
Epoch 5 [68/172] - loss: 0.0280
Epoch 5 [69/172] - loss: 0.0954
Epoch 5 [70/172] - loss: 0.0669, acc: 0.9688
Epoch 5 [71/172] - loss: 0.0386
Epoch 5 [72/172] - loss: 0.0331
Epoch 5 [73/172] - loss: 0.0807
Epoch 5 [74/172] - loss: 0.0809
Epoch 5 [75/172] - loss: 0.0226
Epoch 5 [76/172] - loss: 0.0689
Epoch 5 [77/172] - loss: 0.0599
Epoch 5 [78/172] - loss: 0.0235
Epoch 5 [79/172] - loss: 0.0294
Epoch 5 [80/172] - loss: 0.0267, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1468
Epoch 5 [82/172] - loss: 0.0391
Epoch 5 [83/172] - loss: 0.0228
Epoch 5 [84/172] - loss: 0.0245
Epoch 5 [85/172] - loss: 0.0638
Epoch 5 [86/172] - loss: 0.0551
Epoch 5 [87/172] - loss: 0.0903
Epoch 5 [88/172] - loss: 0.1801
Epoch 5 [89/172] - loss: 0.0335
Epoch 5 [90/172] - loss: 0.1204, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0234
Epoch 5 [92/172] - loss: 0.0257
Epoch 5 [93/172] - loss: 0.0299
Epoch 5 [94/172] - loss: 0.0396
Epoch 5 [95/172] - loss: 0.0689
Epoch 5 [96/172] - loss: 0.0332
Epoch 5 [97/172] - loss: 0.0900
Epoch 5 [98/172] - loss: 0.1803
Epoch 5 [99/172] - loss: 0.0824
Epoch 5 [100/172] - loss: 0.0673, acc: 0.9375
Epoch 5 [101/172] - loss: 0.0333
Epoch 5 [102/172] - loss: 0.0359
Epoch 5 [103/172] - loss: 0.0526
Epoch 5 [104/172] - loss: 0.1971
Epoch 5 [105/172] - loss: 0.1576
Epoch 5 [106/172] - loss: 0.0368
Epoch 5 [107/172] - loss: 0.0750
Epoch 5 [108/172] - loss: 0.1057
Epoch 5 [109/172] - loss: 0.0226
Epoch 5 [110/172] - loss: 0.0703, acc: 0.9688
Epoch 5 [111/172] - loss: 0.0441
Epoch 5 [112/172] - loss: 0.0339

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2999, log_difficulty=0.2623, weight=2.3114
neutral: count=7825.0, difficulty=0.2378, log_difficulty=0.2133, weight=2.0667
negative: count=8780.0, difficulty=0.2973, log_difficulty=0.2603, weight=2.3013

当前batch的pt分布：
positive: min=0.4287, max=0.9323, mean=0.7732
neutral: min=0.7455, max=0.9911, mean=0.8988
negative: min=0.9549, max=0.9936, mean=0.9823

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1828
焦点损失: 0.0199
边界损失: 0.2304
总损失: 0.0643
Epoch 5 [113/172] - loss: 0.0643
Epoch 5 [114/172] - loss: 0.1155
Epoch 5 [115/172] - loss: 0.0247
Epoch 5 [116/172] - loss: 0.0254
Epoch 5 [117/172] - loss: 0.0346
Epoch 5 [118/172] - loss: 0.0479
Epoch 5 [119/172] - loss: 0.0351
Epoch 5 [120/172] - loss: 0.0464, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0460
Epoch 5 [122/172] - loss: 0.0252
Epoch 5 [123/172] - loss: 0.0649
Epoch 5 [124/172] - loss: 0.0345
Epoch 5 [125/172] - loss: 0.0269
Epoch 5 [126/172] - loss: 0.0273
Epoch 5 [127/172] - loss: 0.0473
Epoch 5 [128/172] - loss: 0.0694
Epoch 5 [129/172] - loss: 0.1231
Epoch 5 [130/172] - loss: 0.0205, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0542
Epoch 5 [132/172] - loss: 0.1333
Epoch 5 [133/172] - loss: 0.1240
Epoch 5 [134/172] - loss: 0.0913
Epoch 5 [135/172] - loss: 0.0244
Epoch 5 [136/172] - loss: 0.0366
Epoch 5 [137/172] - loss: 0.0380
Epoch 5 [138/172] - loss: 0.0425
Epoch 5 [139/172] - loss: 0.1947
Epoch 5 [140/172] - loss: 0.0360, acc: 1.0000
Epoch 5 [141/172] - loss: 0.0333
Epoch 5 [142/172] - loss: 0.0213
Epoch 5 [143/172] - loss: 0.0352
Epoch 5 [144/172] - loss: 0.0541
Epoch 5 [145/172] - loss: 0.0324
Epoch 5 [146/172] - loss: 0.0698
Epoch 5 [147/172] - loss: 0.1202
Epoch 5 [148/172] - loss: 0.0203
Epoch 5 [149/172] - loss: 0.0211
Epoch 5 [150/172] - loss: 0.1173, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0337
Epoch 5 [152/172] - loss: 0.0203
Epoch 5 [153/172] - loss: 0.0249
Epoch 5 [154/172] - loss: 0.0277
Epoch 5 [155/172] - loss: 0.0604
Epoch 5 [156/172] - loss: 0.0424
Epoch 5 [157/172] - loss: 0.0291
Epoch 5 [158/172] - loss: 0.0315
Epoch 5 [159/172] - loss: 0.0256
Epoch 5 [160/172] - loss: 0.0719, acc: 0.9688
Epoch 5 [161/172] - loss: 0.0329
Epoch 5 [162/172] - loss: 0.0288
Epoch 5 [163/172] - loss: 0.0685
Epoch 5 [164/172] - loss: 0.0256
Epoch 5 [165/172] - loss: 0.0567
Epoch 5 [166/172] - loss: 0.0389
Epoch 5 [167/172] - loss: 0.1123
Epoch 5 [168/172] - loss: 0.0259
Epoch 5 [169/172] - loss: 0.0236
Epoch 5 [170/172] - loss: 0.2024, acc: 0.9375
Epoch 5 [171/172] - loss: 0.0715
Epoch 5 [172/172] - loss: 0.0625

类别准确率:
positive: 0.8779 (410/467)
neutral: 0.3253 (27/83)
negative: 0.4960 (124/250)

Epoch 5/10
Train Loss: 0.0567, Train Acc: 0.9778
Val Loss: 0.7292, Val Acc: 0.7013
Epoch 6 [1/172] - loss: 0.0495, acc: 1.0000
Epoch 6 [2/172] - loss: 0.0421
Epoch 6 [3/172] - loss: 0.0206
Epoch 6 [4/172] - loss: 0.0366
Epoch 6 [5/172] - loss: 0.0856
Epoch 6 [6/172] - loss: 0.0260
Epoch 6 [7/172] - loss: 0.0424
Epoch 6 [8/172] - loss: 0.0237
Epoch 6 [9/172] - loss: 0.0300
Epoch 6 [10/172] - loss: 0.0315, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0341
Epoch 6 [12/172] - loss: 0.0247
Epoch 6 [13/172] - loss: 0.0296
Epoch 6 [14/172] - loss: 0.0218
Epoch 6 [15/172] - loss: 0.0364
Epoch 6 [16/172] - loss: 0.1157
Epoch 6 [17/172] - loss: 0.0268
Epoch 6 [18/172] - loss: 0.0456
Epoch 6 [19/172] - loss: 0.0390
Epoch 6 [20/172] - loss: 0.0238, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0475
Epoch 6 [22/172] - loss: 0.0364
Epoch 6 [23/172] - loss: 0.0290
Epoch 6 [24/172] - loss: 0.0304
Epoch 6 [25/172] - loss: 0.0469
Epoch 6 [26/172] - loss: 0.0347
Epoch 6 [27/172] - loss: 0.0406
Epoch 6 [28/172] - loss: 0.0671
Epoch 6 [29/172] - loss: 0.0247
Epoch 6 [30/172] - loss: 0.0226, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0297
Epoch 6 [32/172] - loss: 0.0224
Epoch 6 [33/172] - loss: 0.0284
Epoch 6 [34/172] - loss: 0.0362
Epoch 6 [35/172] - loss: 0.0229
Epoch 6 [36/172] - loss: 0.0212
Epoch 6 [37/172] - loss: 0.0635
Epoch 6 [38/172] - loss: 0.0236
Epoch 6 [39/172] - loss: 0.0329
Epoch 6 [40/172] - loss: 0.0950, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2815, log_difficulty=0.2481, weight=2.2403
neutral: count=8815.0, difficulty=0.2219, log_difficulty=0.2004, weight=2.0020
negative: count=9870.0, difficulty=0.2772, log_difficulty=0.2447, weight=2.2235

当前batch的pt分布：
positive: min=0.3947, max=0.9922, mean=0.8485
neutral: min=0.9164, max=0.9838, mean=0.9555
negative: min=0.7774, max=0.9711, mean=0.9116

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1123
焦点损失: 0.0108
边界损失: 0.1873
总损失: 0.0404
Epoch 6 [41/172] - loss: 0.0404
Epoch 6 [42/172] - loss: 0.0268
Epoch 6 [43/172] - loss: 0.0336
Epoch 6 [44/172] - loss: 0.0417
Epoch 6 [45/172] - loss: 0.0937
Epoch 6 [46/172] - loss: 0.0347
Epoch 6 [47/172] - loss: 0.0198
Epoch 6 [48/172] - loss: 0.0229
Epoch 6 [49/172] - loss: 0.0273
Epoch 6 [50/172] - loss: 0.0766, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0384
Epoch 6 [52/172] - loss: 0.0503
Epoch 6 [53/172] - loss: 0.0215
Epoch 6 [54/172] - loss: 0.2210
Epoch 6 [55/172] - loss: 0.0374
Epoch 6 [56/172] - loss: 0.0246
Epoch 6 [57/172] - loss: 0.0225
Epoch 6 [58/172] - loss: 0.0248
Epoch 6 [59/172] - loss: 0.0351
Epoch 6 [60/172] - loss: 0.0861, acc: 0.9375
Epoch 6 [61/172] - loss: 0.0372
Epoch 6 [62/172] - loss: 0.0306
Epoch 6 [63/172] - loss: 0.0228
Epoch 6 [64/172] - loss: 0.0831
Epoch 6 [65/172] - loss: 0.0552
Epoch 6 [66/172] - loss: 0.0315
Epoch 6 [67/172] - loss: 0.0213
Epoch 6 [68/172] - loss: 0.0340
Epoch 6 [69/172] - loss: 0.1610
Epoch 6 [70/172] - loss: 0.0291, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0217
Epoch 6 [72/172] - loss: 0.0705
Epoch 6 [73/172] - loss: 0.0301
Epoch 6 [74/172] - loss: 0.0203
Epoch 6 [75/172] - loss: 0.0577
Epoch 6 [76/172] - loss: 0.0224
Epoch 6 [77/172] - loss: 0.0330
Epoch 6 [78/172] - loss: 0.0355
Epoch 6 [79/172] - loss: 0.0280
Epoch 6 [80/172] - loss: 0.0344, acc: 0.9688
Epoch 6 [81/172] - loss: 0.0409
Epoch 6 [82/172] - loss: 0.0402
Epoch 6 [83/172] - loss: 0.0194
Epoch 6 [84/172] - loss: 0.0202
Epoch 6 [85/172] - loss: 0.0706
Epoch 6 [86/172] - loss: 0.0245
Epoch 6 [87/172] - loss: 0.0746
Epoch 6 [88/172] - loss: 0.0473
Epoch 6 [89/172] - loss: 0.0248
Epoch 6 [90/172] - loss: 0.0221, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0241
Epoch 6 [92/172] - loss: 0.0220
Epoch 6 [93/172] - loss: 0.0203
Epoch 6 [94/172] - loss: 0.0341
Epoch 6 [95/172] - loss: 0.0259
Epoch 6 [96/172] - loss: 0.0202
Epoch 6 [97/172] - loss: 0.0344
Epoch 6 [98/172] - loss: 0.0262
Epoch 6 [99/172] - loss: 0.0244
Epoch 6 [100/172] - loss: 0.0222, acc: 1.0000
Epoch 6 [101/172] - loss: 0.0681
Epoch 6 [102/172] - loss: 0.0373
Epoch 6 [103/172] - loss: 0.0361
Epoch 6 [104/172] - loss: 0.0449
Epoch 6 [105/172] - loss: 0.0223
Epoch 6 [106/172] - loss: 0.0577
Epoch 6 [107/172] - loss: 0.0261
Epoch 6 [108/172] - loss: 0.0233
Epoch 6 [109/172] - loss: 0.0688
Epoch 6 [110/172] - loss: 0.0323, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0208
Epoch 6 [112/172] - loss: 0.0263
Epoch 6 [113/172] - loss: 0.0278
Epoch 6 [114/172] - loss: 0.0250
Epoch 6 [115/172] - loss: 0.0502
Epoch 6 [116/172] - loss: 0.0636
Epoch 6 [117/172] - loss: 0.0438
Epoch 6 [118/172] - loss: 0.0247
Epoch 6 [119/172] - loss: 0.0705
Epoch 6 [120/172] - loss: 0.0201, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0320
Epoch 6 [122/172] - loss: 0.0314
Epoch 6 [123/172] - loss: 0.0228
Epoch 6 [124/172] - loss: 0.0533
Epoch 6 [125/172] - loss: 0.0472
Epoch 6 [126/172] - loss: 0.0218
Epoch 6 [127/172] - loss: 0.1561
Epoch 6 [128/172] - loss: 0.0380
Epoch 6 [129/172] - loss: 0.0257
Epoch 6 [130/172] - loss: 0.1505, acc: 0.9688
Epoch 6 [131/172] - loss: 0.0756
Epoch 6 [132/172] - loss: 0.0245
Epoch 6 [133/172] - loss: 0.0749
Epoch 6 [134/172] - loss: 0.0205
Epoch 6 [135/172] - loss: 0.0256
Epoch 6 [136/172] - loss: 0.0210
Epoch 6 [137/172] - loss: 0.0199
Epoch 6 [138/172] - loss: 0.0233
Epoch 6 [139/172] - loss: 0.0222
Epoch 6 [140/172] - loss: 0.0236, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2650, log_difficulty=0.2350, weight=2.1752
neutral: count=9796.0, difficulty=0.2085, log_difficulty=0.1894, weight=1.9470
negative: count=10972.0, difficulty=0.2599, log_difficulty=0.2310, weight=2.1551

当前batch的pt分布：
positive: min=0.7870, max=0.9877, mean=0.9385
neutral: min=0.8585, max=0.9891, mean=0.9469
negative: min=0.7196, max=0.9488, mean=0.8861

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0861
焦点损失: 0.0016
边界损失: 0.1798
总损失: 0.0211
Epoch 6 [141/172] - loss: 0.0211
Epoch 6 [142/172] - loss: 0.0214
Epoch 6 [143/172] - loss: 0.0325
Epoch 6 [144/172] - loss: 0.0216
Epoch 6 [145/172] - loss: 0.0200
Epoch 6 [146/172] - loss: 0.0195
Epoch 6 [147/172] - loss: 0.0224
Epoch 6 [148/172] - loss: 0.0267
Epoch 6 [149/172] - loss: 0.0229
Epoch 6 [150/172] - loss: 0.0183, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0263
Epoch 6 [152/172] - loss: 0.0333
Epoch 6 [153/172] - loss: 0.0215
Epoch 6 [154/172] - loss: 0.0189
Epoch 6 [155/172] - loss: 0.0785
Epoch 6 [156/172] - loss: 0.1242
Epoch 6 [157/172] - loss: 0.0251
Epoch 6 [158/172] - loss: 0.0340
Epoch 6 [159/172] - loss: 0.0198
Epoch 6 [160/172] - loss: 0.0811, acc: 0.9375
Epoch 6 [161/172] - loss: 0.0245
Epoch 6 [162/172] - loss: 0.0174
Epoch 6 [163/172] - loss: 0.0274
Epoch 6 [164/172] - loss: 0.0521
Epoch 6 [165/172] - loss: 0.1742
Epoch 6 [166/172] - loss: 0.0218
Epoch 6 [167/172] - loss: 0.0223
Epoch 6 [168/172] - loss: 0.0205
Epoch 6 [169/172] - loss: 0.0760
Epoch 6 [170/172] - loss: 0.0185, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0237
Epoch 6 [172/172] - loss: 0.0209

类别准确率:
positive: 0.8373 (391/467)
neutral: 0.2651 (22/83)
negative: 0.6520 (163/250)

Epoch 6/10
Train Loss: 0.0412, Train Acc: 0.9879
Val Loss: 0.7074, Val Acc: 0.7200
Early stopping triggered!
Best validation accuracy: 0.7225

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_135543-9ik3nvct
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.25_Multimodal_iterations_20250118_135541
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/9ik3nvct
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇█████
wandb:  train_acc ▁▄▅▄▅▅▅▇▆▇▇▇█▇▇██▇████▇██▇██████████████
wandb: train_loss ██▆▆▆▅▃▅▃▄▃▂▃▄▂▂▂▁▁▁▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1030
wandb:  train_acc 1
wandb: train_loss 0.01849
wandb: 
wandb: 🚀 View run loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.25_Multimodal_iterations_20250118_135541 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/9ik3nvct
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_135543-9ik3nvct/logs
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_140456-dvngrf9n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.25_Multimodal_epochs_20250118_140456
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/dvngrf9n
wandb: uploading summary; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▄▅▇█
wandb:  train_acc ▁▅▇▇██
wandb: train_loss █▅▂▂▁▁
wandb:    val_acc ▁▄█▇▅█
wandb:   val_loss ▆▅▁▅█▅
wandb: 
wandb: Run summary:
wandb:      epoch 6
wandb:  train_acc 0.98788
wandb: train_loss 0.04121
wandb:    val_acc 0.72
wandb:   val_loss 0.70744
wandb: 
wandb: 🚀 View run loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.25_Multimodal_epochs_20250118_140456 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/dvngrf9n
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_140456-dvngrf9n/logs

