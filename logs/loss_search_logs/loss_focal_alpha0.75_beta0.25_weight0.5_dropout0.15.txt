=== 命令 ===
python main.py --loss_type focal --alpha 0.75 --beta 0.25 --neural_init_weight 0.5 --dropout 0.15 --name loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.15 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.15
text_dim: 128
image_dim: 256
dropout: 0.15
loss_type: focal
alpha: 0.75
beta: 0.25
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6909, log_difficulty=0.5253, weight=3.6264
neutral: count=7.0, difficulty=0.6823, log_difficulty=0.5202, weight=3.6009
negative: count=13.0, difficulty=0.6535, log_difficulty=0.5029, weight=3.5145

当前batch的pt分布：
positive: min=0.1960, max=0.4305, mean=0.3091
neutral: min=0.1628, max=0.4184, mean=0.3177
negative: min=0.1778, max=0.6393, mean=0.3465

当前batch准确率：
整体准确率: 0.3125
positive 准确率: 0.2500
neutral 准确率: 0.4286
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1615
焦点损失: 0.4041
边界损失: 0.8048
总损失: 1.2856
Epoch 1 [1/172] - loss: 1.2856, acc: 0.3125
Epoch 1 [2/172] - loss: 1.1960
Epoch 1 [3/172] - loss: 1.2136
Epoch 1 [4/172] - loss: 1.0674
Epoch 1 [5/172] - loss: 1.3596
Epoch 1 [6/172] - loss: 1.1470
Epoch 1 [7/172] - loss: 1.2507
Epoch 1 [8/172] - loss: 1.2683
Epoch 1 [9/172] - loss: 1.0690
Epoch 1 [10/172] - loss: 1.1988, acc: 0.4062
Epoch 1 [11/172] - loss: 1.0182
Epoch 1 [12/172] - loss: 1.2687
Epoch 1 [13/172] - loss: 0.9278
Epoch 1 [14/172] - loss: 1.3103
Epoch 1 [15/172] - loss: 1.0336
Epoch 1 [16/172] - loss: 0.9998
Epoch 1 [17/172] - loss: 1.0282
Epoch 1 [18/172] - loss: 1.0729
Epoch 1 [19/172] - loss: 1.0141
Epoch 1 [20/172] - loss: 0.9966, acc: 0.5625
Epoch 1 [21/172] - loss: 1.1397
Epoch 1 [22/172] - loss: 1.0211
Epoch 1 [23/172] - loss: 1.4312
Epoch 1 [24/172] - loss: 1.2745
Epoch 1 [25/172] - loss: 1.0101
Epoch 1 [26/172] - loss: 1.2278
Epoch 1 [27/172] - loss: 1.0571
Epoch 1 [28/172] - loss: 0.9562
Epoch 1 [29/172] - loss: 1.0207
Epoch 1 [30/172] - loss: 1.0941, acc: 0.4688
Epoch 1 [31/172] - loss: 0.9629
Epoch 1 [32/172] - loss: 0.8034
Epoch 1 [33/172] - loss: 0.6887
Epoch 1 [34/172] - loss: 0.6735
Epoch 1 [35/172] - loss: 0.8980
Epoch 1 [36/172] - loss: 0.7221
Epoch 1 [37/172] - loss: 0.9080
Epoch 1 [38/172] - loss: 0.8579
Epoch 1 [39/172] - loss: 0.7196
Epoch 1 [40/172] - loss: 0.9791, acc: 0.5000
Epoch 1 [41/172] - loss: 1.0504
Epoch 1 [42/172] - loss: 0.8549
Epoch 1 [43/172] - loss: 1.2741
Epoch 1 [44/172] - loss: 1.1108
Epoch 1 [45/172] - loss: 1.0089
Epoch 1 [46/172] - loss: 0.9326
Epoch 1 [47/172] - loss: 0.8855
Epoch 1 [48/172] - loss: 1.0353
Epoch 1 [49/172] - loss: 0.7526
Epoch 1 [50/172] - loss: 0.7532, acc: 0.6875
Epoch 1 [51/172] - loss: 1.2141
Epoch 1 [52/172] - loss: 0.8221
Epoch 1 [53/172] - loss: 1.0288
Epoch 1 [54/172] - loss: 0.7797
Epoch 1 [55/172] - loss: 0.8899
Epoch 1 [56/172] - loss: 0.8455
Epoch 1 [57/172] - loss: 1.0965
Epoch 1 [58/172] - loss: 0.6081
Epoch 1 [59/172] - loss: 0.8843
Epoch 1 [60/172] - loss: 0.7431, acc: 0.6562
Epoch 1 [61/172] - loss: 0.9946
Epoch 1 [62/172] - loss: 0.7835
Epoch 1 [63/172] - loss: 0.7105
Epoch 1 [64/172] - loss: 0.5662
Epoch 1 [65/172] - loss: 0.8016
Epoch 1 [66/172] - loss: 0.8986
Epoch 1 [67/172] - loss: 0.7639
Epoch 1 [68/172] - loss: 1.0090
Epoch 1 [69/172] - loss: 0.8646
Epoch 1 [70/172] - loss: 0.6728, acc: 0.6875
Epoch 1 [71/172] - loss: 0.7631
Epoch 1 [72/172] - loss: 0.7230
Epoch 1 [73/172] - loss: 0.8129
Epoch 1 [74/172] - loss: 0.8117
Epoch 1 [75/172] - loss: 0.5173
Epoch 1 [76/172] - loss: 0.5730
Epoch 1 [77/172] - loss: 0.7354
Epoch 1 [78/172] - loss: 0.5941
Epoch 1 [79/172] - loss: 0.8515
Epoch 1 [80/172] - loss: 0.5400, acc: 0.7188
Epoch 1 [81/172] - loss: 0.5874
Epoch 1 [82/172] - loss: 1.2305
Epoch 1 [83/172] - loss: 1.0420
Epoch 1 [84/172] - loss: 0.4852
Epoch 1 [85/172] - loss: 0.5700
Epoch 1 [86/172] - loss: 0.9804
Epoch 1 [87/172] - loss: 0.6358
Epoch 1 [88/172] - loss: 1.0489
Epoch 1 [89/172] - loss: 1.0182
Epoch 1 [90/172] - loss: 0.7771, acc: 0.5625
Epoch 1 [91/172] - loss: 0.5074
Epoch 1 [92/172] - loss: 0.6057
Epoch 1 [93/172] - loss: 0.6724
Epoch 1 [94/172] - loss: 0.4657
Epoch 1 [95/172] - loss: 0.7470
Epoch 1 [96/172] - loss: 0.9765
Epoch 1 [97/172] - loss: 0.6229
Epoch 1 [98/172] - loss: 0.5057
Epoch 1 [99/172] - loss: 0.9057
Epoch 1 [100/172] - loss: 0.7696, acc: 0.6250

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5692, log_difficulty=0.4506, weight=3.2529
neutral: count=983.0, difficulty=0.5573, log_difficulty=0.4430, weight=3.2148
negative: count=1119.0, difficulty=0.5675, log_difficulty=0.4495, weight=3.2473

当前batch的pt分布：
positive: min=0.1742, max=0.7223, mean=0.4658
neutral: min=0.4610, max=0.9333, mean=0.6239
negative: min=0.1608, max=0.6149, mean=0.4074

当前batch准确率：
整体准确率: 0.6250
positive 准确率: 0.5833
neutral 准确率: 1.0000
negative 准确率: 0.5625

损失分量：
基础交叉熵: 0.8671
焦点损失: 0.2641
边界损失: 0.5539
总损失: 0.7820
Epoch 1 [101/172] - loss: 0.7820
Epoch 1 [102/172] - loss: 0.6776
Epoch 1 [103/172] - loss: 0.6791
Epoch 1 [104/172] - loss: 0.3921
Epoch 1 [105/172] - loss: 0.8388
Epoch 1 [106/172] - loss: 0.9973
Epoch 1 [107/172] - loss: 0.5876
Epoch 1 [108/172] - loss: 0.7888
Epoch 1 [109/172] - loss: 0.4483
Epoch 1 [110/172] - loss: 0.7341, acc: 0.7188
Epoch 1 [111/172] - loss: 0.5047
Epoch 1 [112/172] - loss: 0.6795
Epoch 1 [113/172] - loss: 0.4091
Epoch 1 [114/172] - loss: 0.5768
Epoch 1 [115/172] - loss: 0.6859
Epoch 1 [116/172] - loss: 0.7282
Epoch 1 [117/172] - loss: 0.4479
Epoch 1 [118/172] - loss: 0.4444
Epoch 1 [119/172] - loss: 0.4334
Epoch 1 [120/172] - loss: 0.3231, acc: 0.9062
Epoch 1 [121/172] - loss: 0.4146
Epoch 1 [122/172] - loss: 0.6886
Epoch 1 [123/172] - loss: 0.3635
Epoch 1 [124/172] - loss: 0.4903
Epoch 1 [125/172] - loss: 0.5024
Epoch 1 [126/172] - loss: 0.8229
Epoch 1 [127/172] - loss: 0.4288
Epoch 1 [128/172] - loss: 0.4788
Epoch 1 [129/172] - loss: 0.6795
Epoch 1 [130/172] - loss: 0.7794, acc: 0.6250
Epoch 1 [131/172] - loss: 0.4000
Epoch 1 [132/172] - loss: 0.5261
Epoch 1 [133/172] - loss: 0.5111
Epoch 1 [134/172] - loss: 0.4236
Epoch 1 [135/172] - loss: 0.5215
Epoch 1 [136/172] - loss: 0.5178
Epoch 1 [137/172] - loss: 0.5678
Epoch 1 [138/172] - loss: 0.4615
Epoch 1 [139/172] - loss: 0.2915
Epoch 1 [140/172] - loss: 0.4209, acc: 0.7188
Epoch 1 [141/172] - loss: 0.2560
Epoch 1 [142/172] - loss: 0.5245
Epoch 1 [143/172] - loss: 0.4717
Epoch 1 [144/172] - loss: 0.3614
Epoch 1 [145/172] - loss: 0.3008
Epoch 1 [146/172] - loss: 0.5972
Epoch 1 [147/172] - loss: 0.5414
Epoch 1 [148/172] - loss: 0.4728
Epoch 1 [149/172] - loss: 0.3796
Epoch 1 [150/172] - loss: 0.6602, acc: 0.6875
Epoch 1 [151/172] - loss: 0.7108
Epoch 1 [152/172] - loss: 0.4258
Epoch 1 [153/172] - loss: 0.5009
Epoch 1 [154/172] - loss: 0.3636
Epoch 1 [155/172] - loss: 0.5882
Epoch 1 [156/172] - loss: 0.6875
Epoch 1 [157/172] - loss: 0.4622
Epoch 1 [158/172] - loss: 0.3363
Epoch 1 [159/172] - loss: 0.5711
Epoch 1 [160/172] - loss: 0.5003, acc: 0.8750
Epoch 1 [161/172] - loss: 0.2891
Epoch 1 [162/172] - loss: 0.4119
Epoch 1 [163/172] - loss: 0.3750
Epoch 1 [164/172] - loss: 0.6391
Epoch 1 [165/172] - loss: 0.2733
Epoch 1 [166/172] - loss: 0.4380
Epoch 1 [167/172] - loss: 0.5724
Epoch 1 [168/172] - loss: 0.3994
Epoch 1 [169/172] - loss: 0.4092
Epoch 1 [170/172] - loss: 0.3413, acc: 0.8750
Epoch 1 [171/172] - loss: 0.3458
Epoch 1 [172/172] - loss: 0.3372

类别准确率:
positive: 0.6617 (309/467)
neutral: 0.4940 (41/83)
negative: 0.7920 (198/250)

Epoch 1/10
Train Loss: 0.4189, Train Acc: 0.8061
Val Loss: 0.7432, Val Acc: 0.6850
Epoch 2 [1/172] - loss: 0.3249, acc: 0.8750
Epoch 2 [2/172] - loss: 0.2513
Epoch 2 [3/172] - loss: 0.2738
Epoch 2 [4/172] - loss: 0.5791
Epoch 2 [5/172] - loss: 0.5316
Epoch 2 [6/172] - loss: 0.4610
Epoch 2 [7/172] - loss: 0.4378
Epoch 2 [8/172] - loss: 0.2529
Epoch 2 [9/172] - loss: 0.3365
Epoch 2 [10/172] - loss: 0.2870, acc: 0.9062
Epoch 2 [11/172] - loss: 0.2440
Epoch 2 [12/172] - loss: 0.2413
Epoch 2 [13/172] - loss: 0.3075
Epoch 2 [14/172] - loss: 0.2184
Epoch 2 [15/172] - loss: 0.4948
Epoch 2 [16/172] - loss: 0.4015
Epoch 2 [17/172] - loss: 0.3502
Epoch 2 [18/172] - loss: 0.5341
Epoch 2 [19/172] - loss: 0.2525
Epoch 2 [20/172] - loss: 0.2322, acc: 0.9062
Epoch 2 [21/172] - loss: 0.2941
Epoch 2 [22/172] - loss: 0.2597
Epoch 2 [23/172] - loss: 0.1845
Epoch 2 [24/172] - loss: 0.5601
Epoch 2 [25/172] - loss: 0.3431
Epoch 2 [26/172] - loss: 0.1720
Epoch 2 [27/172] - loss: 0.3351
Epoch 2 [28/172] - loss: 0.2000

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5009, log_difficulty=0.4061, weight=3.0303
neutral: count=1952.0, difficulty=0.4482, log_difficulty=0.3703, weight=2.8515
negative: count=2216.0, difficulty=0.4971, log_difficulty=0.4035, weight=3.0175

当前batch的pt分布：
positive: min=0.3090, max=0.8921, mean=0.6869
neutral: min=0.4147, max=0.9593, mean=0.6999
negative: min=0.0750, max=0.9205, mean=0.5860

当前batch准确率：
整体准确率: 0.8125
positive 准确率: 0.8889
neutral 准确率: 0.9091
negative 准确率: 0.6667

损失分量：
基础交叉熵: 0.5167
焦点损失: 0.1465
边界损失: 0.3589
总损失: 0.4194
Epoch 2 [29/172] - loss: 0.4194
Epoch 2 [30/172] - loss: 0.3362, acc: 0.7812
Epoch 2 [31/172] - loss: 0.3080
Epoch 2 [32/172] - loss: 0.1982
Epoch 2 [33/172] - loss: 0.1953
Epoch 2 [34/172] - loss: 0.2952
Epoch 2 [35/172] - loss: 0.1691
Epoch 2 [36/172] - loss: 0.5337
Epoch 2 [37/172] - loss: 0.2258
Epoch 2 [38/172] - loss: 0.3166
Epoch 2 [39/172] - loss: 0.4377
Epoch 2 [40/172] - loss: 0.4314, acc: 0.6562
Epoch 2 [41/172] - loss: 0.3308
Epoch 2 [42/172] - loss: 0.1918
Epoch 2 [43/172] - loss: 0.1737
Epoch 2 [44/172] - loss: 0.3159
Epoch 2 [45/172] - loss: 0.2695
Epoch 2 [46/172] - loss: 0.2069
Epoch 2 [47/172] - loss: 0.4761
Epoch 2 [48/172] - loss: 0.3592
Epoch 2 [49/172] - loss: 0.3671
Epoch 2 [50/172] - loss: 0.2980, acc: 0.8438
Epoch 2 [51/172] - loss: 0.2981
Epoch 2 [52/172] - loss: 0.2946
Epoch 2 [53/172] - loss: 0.1762
Epoch 2 [54/172] - loss: 0.2269
Epoch 2 [55/172] - loss: 0.3742
Epoch 2 [56/172] - loss: 0.2141
Epoch 2 [57/172] - loss: 0.1348
Epoch 2 [58/172] - loss: 0.2999
Epoch 2 [59/172] - loss: 0.4182
Epoch 2 [60/172] - loss: 0.2275, acc: 0.8750
Epoch 2 [61/172] - loss: 0.1860
Epoch 2 [62/172] - loss: 0.1511
Epoch 2 [63/172] - loss: 0.2150
Epoch 2 [64/172] - loss: 0.2835
Epoch 2 [65/172] - loss: 0.2070
Epoch 2 [66/172] - loss: 0.1658
Epoch 2 [67/172] - loss: 0.0939
Epoch 2 [68/172] - loss: 0.3030
Epoch 2 [69/172] - loss: 0.1849
Epoch 2 [70/172] - loss: 0.4043, acc: 0.9062
Epoch 2 [71/172] - loss: 0.2413
Epoch 2 [72/172] - loss: 0.2533
Epoch 2 [73/172] - loss: 0.2038
Epoch 2 [74/172] - loss: 0.1898
Epoch 2 [75/172] - loss: 0.1490
Epoch 2 [76/172] - loss: 0.1911
Epoch 2 [77/172] - loss: 0.2203
Epoch 2 [78/172] - loss: 0.2582
Epoch 2 [79/172] - loss: 0.1579
Epoch 2 [80/172] - loss: 0.1899, acc: 0.9375
Epoch 2 [81/172] - loss: 0.1709
Epoch 2 [82/172] - loss: 0.1488
Epoch 2 [83/172] - loss: 0.2066
Epoch 2 [84/172] - loss: 0.1755
Epoch 2 [85/172] - loss: 0.3178
Epoch 2 [86/172] - loss: 0.2235
Epoch 2 [87/172] - loss: 0.6530
Epoch 2 [88/172] - loss: 0.2017
Epoch 2 [89/172] - loss: 0.1295
Epoch 2 [90/172] - loss: 0.2435, acc: 0.8438
Epoch 2 [91/172] - loss: 0.1497
Epoch 2 [92/172] - loss: 0.3101
Epoch 2 [93/172] - loss: 0.1973
Epoch 2 [94/172] - loss: 0.1658
Epoch 2 [95/172] - loss: 0.4695
Epoch 2 [96/172] - loss: 0.1212
Epoch 2 [97/172] - loss: 0.1989
Epoch 2 [98/172] - loss: 0.1674
Epoch 2 [99/172] - loss: 0.0920
Epoch 2 [100/172] - loss: 0.2035, acc: 0.8438
Epoch 2 [101/172] - loss: 0.1395
Epoch 2 [102/172] - loss: 0.2189
Epoch 2 [103/172] - loss: 0.1493
Epoch 2 [104/172] - loss: 0.2573
Epoch 2 [105/172] - loss: 0.1387
Epoch 2 [106/172] - loss: 0.1913
Epoch 2 [107/172] - loss: 0.1877
Epoch 2 [108/172] - loss: 0.4982
Epoch 2 [109/172] - loss: 0.1358
Epoch 2 [110/172] - loss: 0.1910, acc: 0.8750
Epoch 2 [111/172] - loss: 0.1834
Epoch 2 [112/172] - loss: 0.1679
Epoch 2 [113/172] - loss: 0.0836
Epoch 2 [114/172] - loss: 0.1518
Epoch 2 [115/172] - loss: 0.3066
Epoch 2 [116/172] - loss: 0.1846
Epoch 2 [117/172] - loss: 0.2817
Epoch 2 [118/172] - loss: 0.0820
Epoch 2 [119/172] - loss: 0.1479
Epoch 2 [120/172] - loss: 0.1633, acc: 0.9688
Epoch 2 [121/172] - loss: 0.0967
Epoch 2 [122/172] - loss: 0.4997
Epoch 2 [123/172] - loss: 0.1998
Epoch 2 [124/172] - loss: 0.3251
Epoch 2 [125/172] - loss: 0.2418
Epoch 2 [126/172] - loss: 0.1617
Epoch 2 [127/172] - loss: 0.1460
Epoch 2 [128/172] - loss: 0.2881

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4385, log_difficulty=0.3636, weight=2.8181
neutral: count=2949.0, difficulty=0.3601, log_difficulty=0.3076, weight=2.5379
negative: count=3294.0, difficulty=0.4337, log_difficulty=0.3602, weight=2.8012

当前batch的pt分布：
positive: min=0.3731, max=0.9318, mean=0.7666
neutral: min=0.6926, max=0.9672, mean=0.8878
negative: min=0.1914, max=0.9589, mean=0.7348

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8000
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.2704
焦点损失: 0.0523
边界损失: 0.2583
总损失: 0.1746
Epoch 2 [129/172] - loss: 0.1746
Epoch 2 [130/172] - loss: 0.2220, acc: 0.9062
Epoch 2 [131/172] - loss: 0.2743
Epoch 2 [132/172] - loss: 0.2996
Epoch 2 [133/172] - loss: 0.1472
Epoch 2 [134/172] - loss: 0.2364
Epoch 2 [135/172] - loss: 0.4225
Epoch 2 [136/172] - loss: 0.1353
Epoch 2 [137/172] - loss: 0.1658
Epoch 2 [138/172] - loss: 0.2673
Epoch 2 [139/172] - loss: 0.2406
Epoch 2 [140/172] - loss: 0.2406, acc: 0.8750
Epoch 2 [141/172] - loss: 0.1586
Epoch 2 [142/172] - loss: 0.2348
Epoch 2 [143/172] - loss: 0.1456
Epoch 2 [144/172] - loss: 0.1504
Epoch 2 [145/172] - loss: 0.4871
Epoch 2 [146/172] - loss: 0.1573
Epoch 2 [147/172] - loss: 0.2617
Epoch 2 [148/172] - loss: 0.2393
Epoch 2 [149/172] - loss: 0.1511
Epoch 2 [150/172] - loss: 0.2694, acc: 0.9062
Epoch 2 [151/172] - loss: 0.4146
Epoch 2 [152/172] - loss: 0.1396
Epoch 2 [153/172] - loss: 0.1917
Epoch 2 [154/172] - loss: 0.1387
Epoch 2 [155/172] - loss: 0.2619
Epoch 2 [156/172] - loss: 0.1954
Epoch 2 [157/172] - loss: 0.2353
Epoch 2 [158/172] - loss: 0.2218
Epoch 2 [159/172] - loss: 0.1913
Epoch 2 [160/172] - loss: 0.1382, acc: 0.9062
Epoch 2 [161/172] - loss: 0.1452
Epoch 2 [162/172] - loss: 0.1123
Epoch 2 [163/172] - loss: 0.4486
Epoch 2 [164/172] - loss: 0.1784
Epoch 2 [165/172] - loss: 0.1924
Epoch 2 [166/172] - loss: 0.3683
Epoch 2 [167/172] - loss: 0.2786
Epoch 2 [168/172] - loss: 0.1664
Epoch 2 [169/172] - loss: 0.1776
Epoch 2 [170/172] - loss: 0.1973, acc: 0.8438
Epoch 2 [171/172] - loss: 0.2005
Epoch 2 [172/172] - loss: 0.3563

类别准确率:
positive: 0.8244 (385/467)
neutral: 0.3855 (32/83)
negative: 0.5800 (145/250)

Epoch 2/10
Train Loss: 0.2255, Train Acc: 0.9091
Val Loss: 0.6918, Val Acc: 0.7025
Epoch 3 [1/172] - loss: 0.1311, acc: 1.0000
Epoch 3 [2/172] - loss: 0.2106
Epoch 3 [3/172] - loss: 0.0951
Epoch 3 [4/172] - loss: 0.2247
Epoch 3 [5/172] - loss: 0.1487
Epoch 3 [6/172] - loss: 0.1126
Epoch 3 [7/172] - loss: 0.0828
Epoch 3 [8/172] - loss: 0.1954
Epoch 3 [9/172] - loss: 0.1541
Epoch 3 [10/172] - loss: 0.0873, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1013
Epoch 3 [12/172] - loss: 0.0624
Epoch 3 [13/172] - loss: 0.1070
Epoch 3 [14/172] - loss: 0.0906
Epoch 3 [15/172] - loss: 0.1047
Epoch 3 [16/172] - loss: 0.2957
Epoch 3 [17/172] - loss: 0.1786
Epoch 3 [18/172] - loss: 0.1907
Epoch 3 [19/172] - loss: 0.0817
Epoch 3 [20/172] - loss: 0.1032, acc: 0.9375
Epoch 3 [21/172] - loss: 0.1002
Epoch 3 [22/172] - loss: 0.1677
Epoch 3 [23/172] - loss: 0.1170
Epoch 3 [24/172] - loss: 0.1465
Epoch 3 [25/172] - loss: 0.1191
Epoch 3 [26/172] - loss: 0.1159
Epoch 3 [27/172] - loss: 0.0787
Epoch 3 [28/172] - loss: 0.0581
Epoch 3 [29/172] - loss: 0.1710
Epoch 3 [30/172] - loss: 0.1469, acc: 0.9375
Epoch 3 [31/172] - loss: 0.0724
Epoch 3 [32/172] - loss: 0.1255
Epoch 3 [33/172] - loss: 0.0687
Epoch 3 [34/172] - loss: 0.1214
Epoch 3 [35/172] - loss: 0.0903
Epoch 3 [36/172] - loss: 0.0889
Epoch 3 [37/172] - loss: 0.1645
Epoch 3 [38/172] - loss: 0.0806
Epoch 3 [39/172] - loss: 0.0920
Epoch 3 [40/172] - loss: 0.1022, acc: 0.9688
Epoch 3 [41/172] - loss: 0.0747
Epoch 3 [42/172] - loss: 0.0818
Epoch 3 [43/172] - loss: 0.1433
Epoch 3 [44/172] - loss: 0.0745
Epoch 3 [45/172] - loss: 0.1142
Epoch 3 [46/172] - loss: 0.0965
Epoch 3 [47/172] - loss: 0.1061
Epoch 3 [48/172] - loss: 0.2299
Epoch 3 [49/172] - loss: 0.0649
Epoch 3 [50/172] - loss: 0.1227, acc: 0.9688
Epoch 3 [51/172] - loss: 0.1099
Epoch 3 [52/172] - loss: 0.2161
Epoch 3 [53/172] - loss: 0.1436
Epoch 3 [54/172] - loss: 0.1964
Epoch 3 [55/172] - loss: 0.1087
Epoch 3 [56/172] - loss: 0.0592

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3882, log_difficulty=0.3280, weight=2.6401
neutral: count=3923.0, difficulty=0.3088, log_difficulty=0.2691, weight=2.3454
negative: count=4382.0, difficulty=0.3853, log_difficulty=0.3259, weight=2.6294

当前batch的pt分布：
positive: min=0.3620, max=0.9864, mean=0.7541
neutral: min=0.0129, max=0.9291, mean=0.7216
negative: min=0.9309, max=0.9854, mean=0.9511

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8182
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3891
焦点损失: 0.1656
边界损失: 0.2639
总损失: 0.3618
Epoch 3 [57/172] - loss: 0.3618
Epoch 3 [58/172] - loss: 0.1245
Epoch 3 [59/172] - loss: 0.0908
Epoch 3 [60/172] - loss: 0.0972, acc: 0.9688
Epoch 3 [61/172] - loss: 0.0807
Epoch 3 [62/172] - loss: 0.1108
Epoch 3 [63/172] - loss: 0.0858
Epoch 3 [64/172] - loss: 0.1311
Epoch 3 [65/172] - loss: 0.0994
Epoch 3 [66/172] - loss: 0.0907
Epoch 3 [67/172] - loss: 0.1186
Epoch 3 [68/172] - loss: 0.0894
Epoch 3 [69/172] - loss: 0.1212
Epoch 3 [70/172] - loss: 0.0667, acc: 0.9688
Epoch 3 [71/172] - loss: 0.1318
Epoch 3 [72/172] - loss: 0.2694
Epoch 3 [73/172] - loss: 0.0791
Epoch 3 [74/172] - loss: 0.0883
Epoch 3 [75/172] - loss: 0.0852
Epoch 3 [76/172] - loss: 0.2542
Epoch 3 [77/172] - loss: 0.0858
Epoch 3 [78/172] - loss: 0.2499
Epoch 3 [79/172] - loss: 0.0585
Epoch 3 [80/172] - loss: 0.1230, acc: 0.9062
Epoch 3 [81/172] - loss: 0.1410
Epoch 3 [82/172] - loss: 0.0996
Epoch 3 [83/172] - loss: 0.1275
Epoch 3 [84/172] - loss: 0.0723
Epoch 3 [85/172] - loss: 0.0908
Epoch 3 [86/172] - loss: 0.0832
Epoch 3 [87/172] - loss: 0.1094
Epoch 3 [88/172] - loss: 0.1125
Epoch 3 [89/172] - loss: 0.0684
Epoch 3 [90/172] - loss: 0.0936, acc: 0.9688
Epoch 3 [91/172] - loss: 0.0803
Epoch 3 [92/172] - loss: 0.1156
Epoch 3 [93/172] - loss: 0.1906
Epoch 3 [94/172] - loss: 0.1768
Epoch 3 [95/172] - loss: 0.0674
Epoch 3 [96/172] - loss: 0.0895
Epoch 3 [97/172] - loss: 0.2858
Epoch 3 [98/172] - loss: 0.1106
Epoch 3 [99/172] - loss: 0.0800
Epoch 3 [100/172] - loss: 0.1881, acc: 0.9688
Epoch 3 [101/172] - loss: 0.2249
Epoch 3 [102/172] - loss: 0.0812
Epoch 3 [103/172] - loss: 0.1361
Epoch 3 [104/172] - loss: 0.1154
Epoch 3 [105/172] - loss: 0.1297
Epoch 3 [106/172] - loss: 0.0580
Epoch 3 [107/172] - loss: 0.0707
Epoch 3 [108/172] - loss: 0.0620
Epoch 3 [109/172] - loss: 0.0620
Epoch 3 [110/172] - loss: 0.1038, acc: 0.9375
Epoch 3 [111/172] - loss: 0.1223
Epoch 3 [112/172] - loss: 0.0625
Epoch 3 [113/172] - loss: 0.0588
Epoch 3 [114/172] - loss: 0.0738
Epoch 3 [115/172] - loss: 0.1578
Epoch 3 [116/172] - loss: 0.0861
Epoch 3 [117/172] - loss: 0.1045
Epoch 3 [118/172] - loss: 0.0902
Epoch 3 [119/172] - loss: 0.0766
Epoch 3 [120/172] - loss: 0.1599, acc: 0.9375
Epoch 3 [121/172] - loss: 0.2434
Epoch 3 [122/172] - loss: 0.1169
Epoch 3 [123/172] - loss: 0.1048
Epoch 3 [124/172] - loss: 0.0965
Epoch 3 [125/172] - loss: 0.0618
Epoch 3 [126/172] - loss: 0.2576
Epoch 3 [127/172] - loss: 0.0968
Epoch 3 [128/172] - loss: 0.0731
Epoch 3 [129/172] - loss: 0.1165
Epoch 3 [130/172] - loss: 0.1357, acc: 0.9375
Epoch 3 [131/172] - loss: 0.1149
Epoch 3 [132/172] - loss: 0.0481
Epoch 3 [133/172] - loss: 0.0861
Epoch 3 [134/172] - loss: 0.0732
Epoch 3 [135/172] - loss: 0.0535
Epoch 3 [136/172] - loss: 0.0670
Epoch 3 [137/172] - loss: 0.0701
Epoch 3 [138/172] - loss: 0.0892
Epoch 3 [139/172] - loss: 0.0834
Epoch 3 [140/172] - loss: 0.1429, acc: 0.9375
Epoch 3 [141/172] - loss: 0.1479
Epoch 3 [142/172] - loss: 0.2122
Epoch 3 [143/172] - loss: 0.0578
Epoch 3 [144/172] - loss: 0.1498
Epoch 3 [145/172] - loss: 0.1475
Epoch 3 [146/172] - loss: 0.1020
Epoch 3 [147/172] - loss: 0.0763
Epoch 3 [148/172] - loss: 0.0956
Epoch 3 [149/172] - loss: 0.0740
Epoch 3 [150/172] - loss: 0.1507, acc: 0.9062
Epoch 3 [151/172] - loss: 0.2450
Epoch 3 [152/172] - loss: 0.1356
Epoch 3 [153/172] - loss: 0.0823
Epoch 3 [154/172] - loss: 0.3139
Epoch 3 [155/172] - loss: 0.0847
Epoch 3 [156/172] - loss: 0.1547

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3452, log_difficulty=0.2966, weight=2.4829
neutral: count=4903.0, difficulty=0.2700, log_difficulty=0.2390, weight=2.1952
negative: count=5500.0, difficulty=0.3438, log_difficulty=0.2955, weight=2.4774

当前batch的pt分布：
positive: min=0.6043, max=0.9708, mean=0.8343
neutral: min=0.7015, max=0.9749, mean=0.9085
negative: min=0.3701, max=0.9940, mean=0.7751

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1935
焦点损失: 0.0205
边界损失: 0.2372
总损失: 0.0971
Epoch 3 [157/172] - loss: 0.0971
Epoch 3 [158/172] - loss: 0.1663
Epoch 3 [159/172] - loss: 0.1637
Epoch 3 [160/172] - loss: 0.2836, acc: 0.8750
Epoch 3 [161/172] - loss: 0.2040
Epoch 3 [162/172] - loss: 0.3271
Epoch 3 [163/172] - loss: 0.1087
Epoch 3 [164/172] - loss: 0.0533
Epoch 3 [165/172] - loss: 0.0803
Epoch 3 [166/172] - loss: 0.0850
Epoch 3 [167/172] - loss: 0.1234
Epoch 3 [168/172] - loss: 0.0901
Epoch 3 [169/172] - loss: 0.0544
Epoch 3 [170/172] - loss: 0.1214, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1222
Epoch 3 [172/172] - loss: 0.0546

类别准确率:
positive: 0.8672 (405/467)
neutral: 0.2410 (20/83)
negative: 0.6040 (151/250)

Epoch 3/10
Train Loss: 0.1334, Train Acc: 0.9455
Val Loss: 0.6984, Val Acc: 0.7200
Epoch 4 [1/172] - loss: 0.0591, acc: 1.0000
Epoch 4 [2/172] - loss: 0.0594
Epoch 4 [3/172] - loss: 0.0664
Epoch 4 [4/172] - loss: 0.0792
Epoch 4 [5/172] - loss: 0.0694
Epoch 4 [6/172] - loss: 0.0646
Epoch 4 [7/172] - loss: 0.0677
Epoch 4 [8/172] - loss: 0.0560
Epoch 4 [9/172] - loss: 0.1653
Epoch 4 [10/172] - loss: 0.0722, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0548
Epoch 4 [12/172] - loss: 0.0564
Epoch 4 [13/172] - loss: 0.0746
Epoch 4 [14/172] - loss: 0.1315
Epoch 4 [15/172] - loss: 0.0617
Epoch 4 [16/172] - loss: 0.0661
Epoch 4 [17/172] - loss: 0.0622
Epoch 4 [18/172] - loss: 0.1074
Epoch 4 [19/172] - loss: 0.0563
Epoch 4 [20/172] - loss: 0.0657, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1601
Epoch 4 [22/172] - loss: 0.0499
Epoch 4 [23/172] - loss: 0.0925
Epoch 4 [24/172] - loss: 0.0764
Epoch 4 [25/172] - loss: 0.0667
Epoch 4 [26/172] - loss: 0.3514
Epoch 4 [27/172] - loss: 0.0497
Epoch 4 [28/172] - loss: 0.0885
Epoch 4 [29/172] - loss: 0.0799
Epoch 4 [30/172] - loss: 0.1058, acc: 0.9375
Epoch 4 [31/172] - loss: 0.0954
Epoch 4 [32/172] - loss: 0.0572
Epoch 4 [33/172] - loss: 0.0994
Epoch 4 [34/172] - loss: 0.0979
Epoch 4 [35/172] - loss: 0.0631
Epoch 4 [36/172] - loss: 0.0512
Epoch 4 [37/172] - loss: 0.0470
Epoch 4 [38/172] - loss: 0.0529
Epoch 4 [39/172] - loss: 0.1641
Epoch 4 [40/172] - loss: 0.1444, acc: 0.9375
Epoch 4 [41/172] - loss: 0.0700
Epoch 4 [42/172] - loss: 0.1025
Epoch 4 [43/172] - loss: 0.1538
Epoch 4 [44/172] - loss: 0.0878
Epoch 4 [45/172] - loss: 0.0671
Epoch 4 [46/172] - loss: 0.0740
Epoch 4 [47/172] - loss: 0.0723
Epoch 4 [48/172] - loss: 0.0654
Epoch 4 [49/172] - loss: 0.0628
Epoch 4 [50/172] - loss: 0.1375, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0473
Epoch 4 [52/172] - loss: 0.0984
Epoch 4 [53/172] - loss: 0.0540
Epoch 4 [54/172] - loss: 0.0883
Epoch 4 [55/172] - loss: 0.1423
Epoch 4 [56/172] - loss: 0.0522
Epoch 4 [57/172] - loss: 0.0554
Epoch 4 [58/172] - loss: 0.0713
Epoch 4 [59/172] - loss: 0.0468
Epoch 4 [60/172] - loss: 0.0567, acc: 1.0000
Epoch 4 [61/172] - loss: 0.0725
Epoch 4 [62/172] - loss: 0.1620
Epoch 4 [63/172] - loss: 0.0642
Epoch 4 [64/172] - loss: 0.1167
Epoch 4 [65/172] - loss: 0.0844
Epoch 4 [66/172] - loss: 0.0548
Epoch 4 [67/172] - loss: 0.0639
Epoch 4 [68/172] - loss: 0.0436
Epoch 4 [69/172] - loss: 0.0686
Epoch 4 [70/172] - loss: 0.0621, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0576
Epoch 4 [72/172] - loss: 0.0520
Epoch 4 [73/172] - loss: 0.0518
Epoch 4 [74/172] - loss: 0.2659
Epoch 4 [75/172] - loss: 0.0524
Epoch 4 [76/172] - loss: 0.0438
Epoch 4 [77/172] - loss: 0.0666
Epoch 4 [78/172] - loss: 0.0572
Epoch 4 [79/172] - loss: 0.0583
Epoch 4 [80/172] - loss: 0.0747, acc: 0.9688
Epoch 4 [81/172] - loss: 0.0672
Epoch 4 [82/172] - loss: 0.0542
Epoch 4 [83/172] - loss: 0.0448
Epoch 4 [84/172] - loss: 0.0454

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3119, log_difficulty=0.2715, weight=2.3574
neutral: count=5865.0, difficulty=0.2400, log_difficulty=0.2151, weight=2.0755
negative: count=6629.0, difficulty=0.3090, log_difficulty=0.2692, weight=2.3462

当前batch的pt分布：
positive: min=0.2642, max=0.9813, mean=0.7837
neutral: min=0.8202, max=0.9990, mean=0.9544
negative: min=0.8158, max=0.9732, mean=0.9374

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1791
焦点损失: 0.0391
边界损失: 0.2004
总损失: 0.1192
Epoch 4 [85/172] - loss: 0.1192
Epoch 4 [86/172] - loss: 0.1175
Epoch 4 [87/172] - loss: 0.0504
Epoch 4 [88/172] - loss: 0.0492
Epoch 4 [89/172] - loss: 0.0664
Epoch 4 [90/172] - loss: 0.0461, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1616
Epoch 4 [92/172] - loss: 0.2252
Epoch 4 [93/172] - loss: 0.0513
Epoch 4 [94/172] - loss: 0.0629
Epoch 4 [95/172] - loss: 0.0870
Epoch 4 [96/172] - loss: 0.0584
Epoch 4 [97/172] - loss: 0.0706
Epoch 4 [98/172] - loss: 0.1574
Epoch 4 [99/172] - loss: 0.0565
Epoch 4 [100/172] - loss: 0.0506, acc: 1.0000
Epoch 4 [101/172] - loss: 0.0681
Epoch 4 [102/172] - loss: 0.0811
Epoch 4 [103/172] - loss: 0.0760
Epoch 4 [104/172] - loss: 0.0613
Epoch 4 [105/172] - loss: 0.1082
Epoch 4 [106/172] - loss: 0.0517
Epoch 4 [107/172] - loss: 0.0542
Epoch 4 [108/172] - loss: 0.1246
Epoch 4 [109/172] - loss: 0.0517
Epoch 4 [110/172] - loss: 0.1263, acc: 0.9062
Epoch 4 [111/172] - loss: 0.0436
Epoch 4 [112/172] - loss: 0.0445
Epoch 4 [113/172] - loss: 0.0550
Epoch 4 [114/172] - loss: 0.0630
Epoch 4 [115/172] - loss: 0.0996
Epoch 4 [116/172] - loss: 0.0532
Epoch 4 [117/172] - loss: 0.0674
Epoch 4 [118/172] - loss: 0.1585
Epoch 4 [119/172] - loss: 0.0738
Epoch 4 [120/172] - loss: 0.0589, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1556
Epoch 4 [122/172] - loss: 0.1339
Epoch 4 [123/172] - loss: 0.0491
Epoch 4 [124/172] - loss: 0.0542
Epoch 4 [125/172] - loss: 0.0769
Epoch 4 [126/172] - loss: 0.1225
Epoch 4 [127/172] - loss: 0.0962
Epoch 4 [128/172] - loss: 0.0453
Epoch 4 [129/172] - loss: 0.0460
Epoch 4 [130/172] - loss: 0.0427, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1109
Epoch 4 [132/172] - loss: 0.0460
Epoch 4 [133/172] - loss: 0.0859
Epoch 4 [134/172] - loss: 0.0579
Epoch 4 [135/172] - loss: 0.0690
Epoch 4 [136/172] - loss: 0.0967
Epoch 4 [137/172] - loss: 0.0460
Epoch 4 [138/172] - loss: 0.0509
Epoch 4 [139/172] - loss: 0.0835
Epoch 4 [140/172] - loss: 0.0490, acc: 1.0000
Epoch 4 [141/172] - loss: 0.0989
Epoch 4 [142/172] - loss: 0.0622
Epoch 4 [143/172] - loss: 0.0627
Epoch 4 [144/172] - loss: 0.0521
Epoch 4 [145/172] - loss: 0.0956
Epoch 4 [146/172] - loss: 0.1124
Epoch 4 [147/172] - loss: 0.0537
Epoch 4 [148/172] - loss: 0.0576
Epoch 4 [149/172] - loss: 0.0488
Epoch 4 [150/172] - loss: 0.0941, acc: 0.9688
Epoch 4 [151/172] - loss: 0.0999
Epoch 4 [152/172] - loss: 0.0448
Epoch 4 [153/172] - loss: 0.0446
Epoch 4 [154/172] - loss: 0.1637
Epoch 4 [155/172] - loss: 0.0588
Epoch 4 [156/172] - loss: 0.0802
Epoch 4 [157/172] - loss: 0.0837
Epoch 4 [158/172] - loss: 0.0561
Epoch 4 [159/172] - loss: 0.0513
Epoch 4 [160/172] - loss: 0.0520, acc: 1.0000
Epoch 4 [161/172] - loss: 0.0504
Epoch 4 [162/172] - loss: 0.0621
Epoch 4 [163/172] - loss: 0.0639
Epoch 4 [164/172] - loss: 0.0774
Epoch 4 [165/172] - loss: 0.1050
Epoch 4 [166/172] - loss: 0.0776
Epoch 4 [167/172] - loss: 0.0609
Epoch 4 [168/172] - loss: 0.0483
Epoch 4 [169/172] - loss: 0.0938
Epoch 4 [170/172] - loss: 0.1535, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0551
Epoch 4 [172/172] - loss: 0.0573

类别准确率:
positive: 0.9379 (438/467)
neutral: 0.2289 (19/83)
negative: 0.4320 (108/250)

Epoch 4/10
Train Loss: 0.0718, Train Acc: 0.9838
Val Loss: 0.8414, Val Acc: 0.7063
Epoch 5 [1/172] - loss: 0.0430, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0657
Epoch 5 [3/172] - loss: 0.0446
Epoch 5 [4/172] - loss: 0.0544
Epoch 5 [5/172] - loss: 0.0450
Epoch 5 [6/172] - loss: 0.0651
Epoch 5 [7/172] - loss: 0.0462
Epoch 5 [8/172] - loss: 0.0675
Epoch 5 [9/172] - loss: 0.0857
Epoch 5 [10/172] - loss: 0.0565, acc: 0.9688
Epoch 5 [11/172] - loss: 0.0633
Epoch 5 [12/172] - loss: 0.0425

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2833, log_difficulty=0.2494, weight=2.2471
neutral: count=6845.0, difficulty=0.2164, log_difficulty=0.1959, weight=1.9796
negative: count=7694.0, difficulty=0.2810, log_difficulty=0.2477, weight=2.2383

当前batch的pt分布：
positive: min=0.2926, max=0.9720, mean=0.8425
neutral: min=0.9164, max=0.9958, mean=0.9748
negative: min=0.8194, max=0.9907, mean=0.9325

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1215
焦点损失: 0.0204
边界损失: 0.1832
总损失: 0.0802
Epoch 5 [13/172] - loss: 0.0802
Epoch 5 [14/172] - loss: 0.0858
Epoch 5 [15/172] - loss: 0.0431
Epoch 5 [16/172] - loss: 0.0505
Epoch 5 [17/172] - loss: 0.0530
Epoch 5 [18/172] - loss: 0.0421
Epoch 5 [19/172] - loss: 0.0783
Epoch 5 [20/172] - loss: 0.0765, acc: 0.9375
Epoch 5 [21/172] - loss: 0.1442
Epoch 5 [22/172] - loss: 0.1869
Epoch 5 [23/172] - loss: 0.0427
Epoch 5 [24/172] - loss: 0.0917
Epoch 5 [25/172] - loss: 0.0418
Epoch 5 [26/172] - loss: 0.0875
Epoch 5 [27/172] - loss: 0.0421
Epoch 5 [28/172] - loss: 0.0514
Epoch 5 [29/172] - loss: 0.0459
Epoch 5 [30/172] - loss: 0.0487, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1052
Epoch 5 [32/172] - loss: 0.0438
Epoch 5 [33/172] - loss: 0.0499
Epoch 5 [34/172] - loss: 0.0429
Epoch 5 [35/172] - loss: 0.0708
Epoch 5 [36/172] - loss: 0.0432
Epoch 5 [37/172] - loss: 0.0471
Epoch 5 [38/172] - loss: 0.0435
Epoch 5 [39/172] - loss: 0.2449
Epoch 5 [40/172] - loss: 0.0550, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0477
Epoch 5 [42/172] - loss: 0.0497
Epoch 5 [43/172] - loss: 0.1337
Epoch 5 [44/172] - loss: 0.1397
Epoch 5 [45/172] - loss: 0.0424
Epoch 5 [46/172] - loss: 0.1341
Epoch 5 [47/172] - loss: 0.0483
Epoch 5 [48/172] - loss: 0.0555
Epoch 5 [49/172] - loss: 0.0455
Epoch 5 [50/172] - loss: 0.0761, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0626
Epoch 5 [52/172] - loss: 0.0535
Epoch 5 [53/172] - loss: 0.0832
Epoch 5 [54/172] - loss: 0.0714
Epoch 5 [55/172] - loss: 0.0723
Epoch 5 [56/172] - loss: 0.0593
Epoch 5 [57/172] - loss: 0.0669
Epoch 5 [58/172] - loss: 0.0517
Epoch 5 [59/172] - loss: 0.1299
Epoch 5 [60/172] - loss: 0.0694, acc: 0.9688
Epoch 5 [61/172] - loss: 0.0539
Epoch 5 [62/172] - loss: 0.0562
Epoch 5 [63/172] - loss: 0.0969
Epoch 5 [64/172] - loss: 0.0604
Epoch 5 [65/172] - loss: 0.0756
Epoch 5 [66/172] - loss: 0.0467
Epoch 5 [67/172] - loss: 0.0501
Epoch 5 [68/172] - loss: 0.0866
Epoch 5 [69/172] - loss: 0.0532
Epoch 5 [70/172] - loss: 0.0566, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0541
Epoch 5 [72/172] - loss: 0.0613
Epoch 5 [73/172] - loss: 0.0444
Epoch 5 [74/172] - loss: 0.0697
Epoch 5 [75/172] - loss: 0.0489
Epoch 5 [76/172] - loss: 0.0450
Epoch 5 [77/172] - loss: 0.0458
Epoch 5 [78/172] - loss: 0.0611
Epoch 5 [79/172] - loss: 0.0458
Epoch 5 [80/172] - loss: 0.0537, acc: 1.0000
Epoch 5 [81/172] - loss: 0.0880
Epoch 5 [82/172] - loss: 0.1458
Epoch 5 [83/172] - loss: 0.0490
Epoch 5 [84/172] - loss: 0.0461
Epoch 5 [85/172] - loss: 0.1443
Epoch 5 [86/172] - loss: 0.0472
Epoch 5 [87/172] - loss: 0.0459
Epoch 5 [88/172] - loss: 0.1365
Epoch 5 [89/172] - loss: 0.0431
Epoch 5 [90/172] - loss: 0.2472, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0521
Epoch 5 [92/172] - loss: 0.0664
Epoch 5 [93/172] - loss: 0.0486
Epoch 5 [94/172] - loss: 0.0775
Epoch 5 [95/172] - loss: 0.0526
Epoch 5 [96/172] - loss: 0.0571
Epoch 5 [97/172] - loss: 0.0850
Epoch 5 [98/172] - loss: 0.0544
Epoch 5 [99/172] - loss: 0.0906
Epoch 5 [100/172] - loss: 0.0480, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0606
Epoch 5 [102/172] - loss: 0.0654
Epoch 5 [103/172] - loss: 0.0502
Epoch 5 [104/172] - loss: 0.0727
Epoch 5 [105/172] - loss: 0.2021
Epoch 5 [106/172] - loss: 0.0559
Epoch 5 [107/172] - loss: 0.0516
Epoch 5 [108/172] - loss: 0.1410
Epoch 5 [109/172] - loss: 0.0422
Epoch 5 [110/172] - loss: 0.0464, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0533
Epoch 5 [112/172] - loss: 0.0459

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2599, log_difficulty=0.2310, weight=2.1550
neutral: count=7825.0, difficulty=0.1975, log_difficulty=0.1802, weight=1.9010
negative: count=8780.0, difficulty=0.2589, log_difficulty=0.2303, weight=2.1514

当前batch的pt分布：
positive: min=0.2696, max=0.9548, mean=0.7750
neutral: min=0.5186, max=0.9953, mean=0.9222
negative: min=0.9785, max=0.9944, mean=0.9886

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1841
焦点损失: 0.0374
边界损失: 0.2149
总损失: 0.1132
Epoch 5 [113/172] - loss: 0.1132
Epoch 5 [114/172] - loss: 0.0863
Epoch 5 [115/172] - loss: 0.0474
Epoch 5 [116/172] - loss: 0.0411
Epoch 5 [117/172] - loss: 0.0538
Epoch 5 [118/172] - loss: 0.0452
Epoch 5 [119/172] - loss: 0.0425
Epoch 5 [120/172] - loss: 0.0499, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0561
Epoch 5 [122/172] - loss: 0.0454
Epoch 5 [123/172] - loss: 0.0491
Epoch 5 [124/172] - loss: 0.0439
Epoch 5 [125/172] - loss: 0.0440
Epoch 5 [126/172] - loss: 0.0448
Epoch 5 [127/172] - loss: 0.1169
Epoch 5 [128/172] - loss: 0.0441
Epoch 5 [129/172] - loss: 0.1569
Epoch 5 [130/172] - loss: 0.0409, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0526
Epoch 5 [132/172] - loss: 0.1552
Epoch 5 [133/172] - loss: 0.1026
Epoch 5 [134/172] - loss: 0.0891
Epoch 5 [135/172] - loss: 0.0438
Epoch 5 [136/172] - loss: 0.0431
Epoch 5 [137/172] - loss: 0.1046
Epoch 5 [138/172] - loss: 0.0840
Epoch 5 [139/172] - loss: 0.3053
Epoch 5 [140/172] - loss: 0.1038, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0449
Epoch 5 [142/172] - loss: 0.0541
Epoch 5 [143/172] - loss: 0.0438
Epoch 5 [144/172] - loss: 0.0439
Epoch 5 [145/172] - loss: 0.0643
Epoch 5 [146/172] - loss: 0.0539
Epoch 5 [147/172] - loss: 0.0605
Epoch 5 [148/172] - loss: 0.0737
Epoch 5 [149/172] - loss: 0.0433
Epoch 5 [150/172] - loss: 0.0703, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0485
Epoch 5 [152/172] - loss: 0.0438
Epoch 5 [153/172] - loss: 0.0961
Epoch 5 [154/172] - loss: 0.0580
Epoch 5 [155/172] - loss: 0.0490
Epoch 5 [156/172] - loss: 0.0518
Epoch 5 [157/172] - loss: 0.0591
Epoch 5 [158/172] - loss: 0.0485
Epoch 5 [159/172] - loss: 0.0467
Epoch 5 [160/172] - loss: 0.0508, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0453
Epoch 5 [162/172] - loss: 0.0585
Epoch 5 [163/172] - loss: 0.0679
Epoch 5 [164/172] - loss: 0.0409
Epoch 5 [165/172] - loss: 0.0812
Epoch 5 [166/172] - loss: 0.0496
Epoch 5 [167/172] - loss: 0.0655
Epoch 5 [168/172] - loss: 0.0412
Epoch 5 [169/172] - loss: 0.0442
Epoch 5 [170/172] - loss: 0.0466, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0611
Epoch 5 [172/172] - loss: 0.0451

类别准确率:
positive: 0.8929 (417/467)
neutral: 0.2892 (24/83)
negative: 0.4920 (123/250)

Epoch 5/10
Train Loss: 0.0533, Train Acc: 0.9939
Val Loss: 0.8216, Val Acc: 0.7050
Epoch 6 [1/172] - loss: 0.0643, acc: 0.9688
Epoch 6 [2/172] - loss: 0.0551
Epoch 6 [3/172] - loss: 0.0446
Epoch 6 [4/172] - loss: 0.0421
Epoch 6 [5/172] - loss: 0.0647
Epoch 6 [6/172] - loss: 0.0444
Epoch 6 [7/172] - loss: 0.0470
Epoch 6 [8/172] - loss: 0.0442
Epoch 6 [9/172] - loss: 0.0443
Epoch 6 [10/172] - loss: 0.0409, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0406
Epoch 6 [12/172] - loss: 0.0424
Epoch 6 [13/172] - loss: 0.0513
Epoch 6 [14/172] - loss: 0.0404
Epoch 6 [15/172] - loss: 0.0402
Epoch 6 [16/172] - loss: 0.1086
Epoch 6 [17/172] - loss: 0.0462
Epoch 6 [18/172] - loss: 0.0443
Epoch 6 [19/172] - loss: 0.0432
Epoch 6 [20/172] - loss: 0.0428, acc: 1.0000
Epoch 6 [21/172] - loss: 0.1151
Epoch 6 [22/172] - loss: 0.0426
Epoch 6 [23/172] - loss: 0.0419
Epoch 6 [24/172] - loss: 0.0416
Epoch 6 [25/172] - loss: 0.0867
Epoch 6 [26/172] - loss: 0.0674
Epoch 6 [27/172] - loss: 0.0808
Epoch 6 [28/172] - loss: 0.0433
Epoch 6 [29/172] - loss: 0.0412
Epoch 6 [30/172] - loss: 0.0529, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0419
Epoch 6 [32/172] - loss: 0.0392
Epoch 6 [33/172] - loss: 0.0424
Epoch 6 [34/172] - loss: 0.0410
Epoch 6 [35/172] - loss: 0.0408
Epoch 6 [36/172] - loss: 0.0455
Epoch 6 [37/172] - loss: 0.0519
Epoch 6 [38/172] - loss: 0.0443
Epoch 6 [39/172] - loss: 0.0409
Epoch 6 [40/172] - loss: 0.0742, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2400, log_difficulty=0.2151, weight=2.0755
neutral: count=8815.0, difficulty=0.1825, log_difficulty=0.1676, weight=1.8381
negative: count=9870.0, difficulty=0.2391, log_difficulty=0.2144, weight=2.0719

当前batch的pt分布：
positive: min=0.2363, max=0.9925, mean=0.8841
neutral: min=0.9016, max=0.9974, mean=0.9704
negative: min=0.7573, max=0.9878, mean=0.9315

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0970
焦点损失: 0.0261
边界损失: 0.1657
总损失: 0.0821
Epoch 6 [41/172] - loss: 0.0821
Epoch 6 [42/172] - loss: 0.0422
Epoch 6 [43/172] - loss: 0.0509
Epoch 6 [44/172] - loss: 0.0406
Epoch 6 [45/172] - loss: 0.0838
Epoch 6 [46/172] - loss: 0.0558
Epoch 6 [47/172] - loss: 0.0467
Epoch 6 [48/172] - loss: 0.0446
Epoch 6 [49/172] - loss: 0.0490
Epoch 6 [50/172] - loss: 0.0536, acc: 1.0000
Epoch 6 [51/172] - loss: 0.0578
Epoch 6 [52/172] - loss: 0.0649
Epoch 6 [53/172] - loss: 0.0398
Epoch 6 [54/172] - loss: 0.0608
Epoch 6 [55/172] - loss: 0.0455
Epoch 6 [56/172] - loss: 0.0441
Epoch 6 [57/172] - loss: 0.0459
Epoch 6 [58/172] - loss: 0.0404
Epoch 6 [59/172] - loss: 0.0418
Epoch 6 [60/172] - loss: 0.0664, acc: 0.9688
Epoch 6 [61/172] - loss: 0.0728
Epoch 6 [62/172] - loss: 0.0427
Epoch 6 [63/172] - loss: 0.0423
Epoch 6 [64/172] - loss: 0.0586
Epoch 6 [65/172] - loss: 0.0484
Epoch 6 [66/172] - loss: 0.0489
Epoch 6 [67/172] - loss: 0.0447
Epoch 6 [68/172] - loss: 0.1007
Epoch 6 [69/172] - loss: 0.0530
Epoch 6 [70/172] - loss: 0.0425, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0549
Epoch 6 [72/172] - loss: 0.0653
Epoch 6 [73/172] - loss: 0.0827
Epoch 6 [74/172] - loss: 0.0461
Epoch 6 [75/172] - loss: 0.0445
Epoch 6 [76/172] - loss: 0.0450
Epoch 6 [77/172] - loss: 0.0471
Epoch 6 [78/172] - loss: 0.0479
Epoch 6 [79/172] - loss: 0.0392
Epoch 6 [80/172] - loss: 0.0451, acc: 1.0000
Epoch 6 [81/172] - loss: 0.0645
Epoch 6 [82/172] - loss: 0.0454
Epoch 6 [83/172] - loss: 0.0395
Epoch 6 [84/172] - loss: 0.0401
Epoch 6 [85/172] - loss: 0.1108
Epoch 6 [86/172] - loss: 0.0549
Epoch 6 [87/172] - loss: 0.0477
Epoch 6 [88/172] - loss: 0.0567
Epoch 6 [89/172] - loss: 0.0427
Epoch 6 [90/172] - loss: 0.0442, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0414
Epoch 6 [92/172] - loss: 0.0583
Epoch 6 [93/172] - loss: 0.0509
Epoch 6 [94/172] - loss: 0.0838
Epoch 6 [95/172] - loss: 0.0668
Epoch 6 [96/172] - loss: 0.0399
Epoch 6 [97/172] - loss: 0.0442
Epoch 6 [98/172] - loss: 0.0429
Epoch 6 [99/172] - loss: 0.0401
Epoch 6 [100/172] - loss: 0.0446, acc: 1.0000
Epoch 6 [101/172] - loss: 0.0505
Epoch 6 [102/172] - loss: 0.0425
Epoch 6 [103/172] - loss: 0.0800
Epoch 6 [104/172] - loss: 0.0654
Epoch 6 [105/172] - loss: 0.0408
Epoch 6 [106/172] - loss: 0.0480
Epoch 6 [107/172] - loss: 0.0448
Epoch 6 [108/172] - loss: 0.0398
Epoch 6 [109/172] - loss: 0.0998
Epoch 6 [110/172] - loss: 0.0950, acc: 0.9688
Epoch 6 [111/172] - loss: 0.0421
Epoch 6 [112/172] - loss: 0.0434
Epoch 6 [113/172] - loss: 0.0515
Epoch 6 [114/172] - loss: 0.0417
Epoch 6 [115/172] - loss: 0.0537
Epoch 6 [116/172] - loss: 0.1699
Epoch 6 [117/172] - loss: 0.0577
Epoch 6 [118/172] - loss: 0.0399
Epoch 6 [119/172] - loss: 0.0559
Epoch 6 [120/172] - loss: 0.0576, acc: 0.9688
Epoch 6 [121/172] - loss: 0.0426
Epoch 6 [122/172] - loss: 0.0892
Epoch 6 [123/172] - loss: 0.0393
Epoch 6 [124/172] - loss: 0.0429
Epoch 6 [125/172] - loss: 0.0919
Epoch 6 [126/172] - loss: 0.0920
Epoch 6 [127/172] - loss: 0.0910
Epoch 6 [128/172] - loss: 0.0767
Epoch 6 [129/172] - loss: 0.0441
Epoch 6 [130/172] - loss: 0.0767, acc: 0.9688
Epoch 6 [131/172] - loss: 0.0810
Epoch 6 [132/172] - loss: 0.1149
Epoch 6 [133/172] - loss: 0.0387
Epoch 6 [134/172] - loss: 0.0422
Epoch 6 [135/172] - loss: 0.0395
Epoch 6 [136/172] - loss: 0.0398
Epoch 6 [137/172] - loss: 0.0398
Epoch 6 [138/172] - loss: 0.0507
Epoch 6 [139/172] - loss: 0.0412
Epoch 6 [140/172] - loss: 0.0484, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2229, log_difficulty=0.2012, weight=2.0059
neutral: count=9796.0, difficulty=0.1697, log_difficulty=0.1567, weight=1.7835
negative: count=10972.0, difficulty=0.2227, log_difficulty=0.2010, weight=2.0052

当前batch的pt分布：
positive: min=0.9432, max=0.9869, mean=0.9722
neutral: min=0.9081, max=0.9956, mean=0.9712
negative: min=0.6449, max=0.9966, mean=0.9170

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0546
焦点损失: 0.0018
边界损失: 0.1622
总损失: 0.0432
Epoch 6 [141/172] - loss: 0.0432
Epoch 6 [142/172] - loss: 0.0422
Epoch 6 [143/172] - loss: 0.0542
Epoch 6 [144/172] - loss: 0.0430
Epoch 6 [145/172] - loss: 0.0423
Epoch 6 [146/172] - loss: 0.0411
Epoch 6 [147/172] - loss: 0.0433
Epoch 6 [148/172] - loss: 0.0477
Epoch 6 [149/172] - loss: 0.0411
Epoch 6 [150/172] - loss: 0.0397, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0420
Epoch 6 [152/172] - loss: 0.0491
Epoch 6 [153/172] - loss: 0.0516
Epoch 6 [154/172] - loss: 0.0396
Epoch 6 [155/172] - loss: 0.0754
Epoch 6 [156/172] - loss: 0.0823
Epoch 6 [157/172] - loss: 0.0405
Epoch 6 [158/172] - loss: 0.0464
Epoch 6 [159/172] - loss: 0.0425
Epoch 6 [160/172] - loss: 0.0574, acc: 1.0000
Epoch 6 [161/172] - loss: 0.0515
Epoch 6 [162/172] - loss: 0.0397
Epoch 6 [163/172] - loss: 0.0569
Epoch 6 [164/172] - loss: 0.1335
Epoch 6 [165/172] - loss: 0.1005
Epoch 6 [166/172] - loss: 0.0426
Epoch 6 [167/172] - loss: 0.0396
Epoch 6 [168/172] - loss: 0.0416
Epoch 6 [169/172] - loss: 0.0693
Epoch 6 [170/172] - loss: 0.0385, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0471
Epoch 6 [172/172] - loss: 0.0418

类别准确率:
positive: 0.8565 (400/467)
neutral: 0.2289 (19/83)
negative: 0.6120 (153/250)

Epoch 6/10
Train Loss: 0.0556, Train Acc: 0.9879
Val Loss: 0.7838, Val Acc: 0.7150
Early stopping triggered!
Best validation accuracy: 0.7200

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_094458-z7z77670
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.15_Multimodal_iterations_20250118_094457
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/z7z77670
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██
wandb:  train_acc ▁▂▃▃▅▄▅▇▇▇▇▆▆▇▇▇▇█▇▇▇████▇██████████████
wandb: train_loss ███▄▃▅▃▃▂▃▃▂▂▁▂▂▂▃▁▁▂▂▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1030
wandb:  train_acc 1
wandb: train_loss 0.03853
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.15_Multimodal_iterations_20250118_094457 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/z7z77670
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_094458-z7z77670/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_095435-dkwozhl0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.15_Multimodal_epochs_20250118_095435
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/dkwozhl0
wandb: uploading history steps 0-0, summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▄▅▇█
wandb:  train_acc ▁▅▆███
wandb: train_loss █▄▃▁▁▁
wandb:    val_acc ▁▄█▅▅▇
wandb:   val_loss ▃▁▁█▇▅
wandb: 
wandb: Run summary:
wandb:      epoch 6
wandb:  train_acc 0.98788
wandb: train_loss 0.0556
wandb:    val_acc 0.715
wandb:   val_loss 0.78384
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.15_Multimodal_epochs_20250118_095435 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/dkwozhl0
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_095435-dkwozhl0/logs

