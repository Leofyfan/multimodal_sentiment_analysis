=== 命令 ===
python main.py --loss_type focal --alpha 0.9 --beta 0.09999999999999998 --neural_init_weight 1.0 --dropout 0.35 --name loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.35 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.35
text_dim: 128
image_dim: 256
dropout: 0.35
loss_type: focal
alpha: 0.9
beta: 0.09999999999999998
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6843, log_difficulty=0.5214, weight=3.6068
neutral: count=7.0, difficulty=0.7128, log_difficulty=0.5381, weight=3.6907
negative: count=13.0, difficulty=0.6676, log_difficulty=0.5114, weight=3.5569

当前batch的pt分布：
positive: min=0.1670, max=0.5508, mean=0.3157
neutral: min=0.1504, max=0.3874, mean=0.2872
negative: min=0.0804, max=0.5301, mean=0.3324

当前batch准确率：
整体准确率: 0.2812
positive 准确率: 0.2500
neutral 准确率: 0.1429
negative 准确率: 0.3846

损失分量：
基础交叉熵: 1.2121
焦点损失: 0.4579
边界损失: 0.7658
总损失: 1.5632
Epoch 1 [1/172] - loss: 1.5632, acc: 0.2812
Epoch 1 [2/172] - loss: 1.0827
Epoch 1 [3/172] - loss: 1.3623
Epoch 1 [4/172] - loss: 1.2068
Epoch 1 [5/172] - loss: 1.3921
Epoch 1 [6/172] - loss: 1.5661
Epoch 1 [7/172] - loss: 1.3586
Epoch 1 [8/172] - loss: 1.5471
Epoch 1 [9/172] - loss: 1.2359
Epoch 1 [10/172] - loss: 2.2186, acc: 0.1875
Epoch 1 [11/172] - loss: 1.3295
Epoch 1 [12/172] - loss: 1.2129
Epoch 1 [13/172] - loss: 1.1930
Epoch 1 [14/172] - loss: 1.3919
Epoch 1 [15/172] - loss: 1.2888
Epoch 1 [16/172] - loss: 1.2862
Epoch 1 [17/172] - loss: 1.3334
Epoch 1 [18/172] - loss: 1.1365
Epoch 1 [19/172] - loss: 1.1317
Epoch 1 [20/172] - loss: 1.2715, acc: 0.4062
Epoch 1 [21/172] - loss: 1.0079
Epoch 1 [22/172] - loss: 1.0046
Epoch 1 [23/172] - loss: 1.3444
Epoch 1 [24/172] - loss: 1.2492
Epoch 1 [25/172] - loss: 1.0996
Epoch 1 [26/172] - loss: 1.9381
Epoch 1 [27/172] - loss: 1.0864
Epoch 1 [28/172] - loss: 0.9802
Epoch 1 [29/172] - loss: 1.1006
Epoch 1 [30/172] - loss: 1.2104, acc: 0.6250
Epoch 1 [31/172] - loss: 1.1601
Epoch 1 [32/172] - loss: 0.9388
Epoch 1 [33/172] - loss: 1.1486
Epoch 1 [34/172] - loss: 0.9756
Epoch 1 [35/172] - loss: 1.3056
Epoch 1 [36/172] - loss: 1.2091
Epoch 1 [37/172] - loss: 1.0444
Epoch 1 [38/172] - loss: 0.9859
Epoch 1 [39/172] - loss: 0.9787
Epoch 1 [40/172] - loss: 1.0012, acc: 0.5938
Epoch 1 [41/172] - loss: 1.1504
Epoch 1 [42/172] - loss: 0.8060
Epoch 1 [43/172] - loss: 1.0095
Epoch 1 [44/172] - loss: 1.5701
Epoch 1 [45/172] - loss: 1.3165
Epoch 1 [46/172] - loss: 1.1744
Epoch 1 [47/172] - loss: 0.9759
Epoch 1 [48/172] - loss: 1.0166
Epoch 1 [49/172] - loss: 1.3371
Epoch 1 [50/172] - loss: 0.9237, acc: 0.5938
Epoch 1 [51/172] - loss: 0.9239
Epoch 1 [52/172] - loss: 1.4591
Epoch 1 [53/172] - loss: 0.9900
Epoch 1 [54/172] - loss: 0.8970
Epoch 1 [55/172] - loss: 1.0555
Epoch 1 [56/172] - loss: 0.7732
Epoch 1 [57/172] - loss: 1.5206
Epoch 1 [58/172] - loss: 0.8057
Epoch 1 [59/172] - loss: 1.4081
Epoch 1 [60/172] - loss: 0.7459, acc: 0.6250
Epoch 1 [61/172] - loss: 1.0341
Epoch 1 [62/172] - loss: 0.7609
Epoch 1 [63/172] - loss: 0.9444
Epoch 1 [64/172] - loss: 0.5932
Epoch 1 [65/172] - loss: 1.0666
Epoch 1 [66/172] - loss: 1.2316
Epoch 1 [67/172] - loss: 0.9921
Epoch 1 [68/172] - loss: 1.4043
Epoch 1 [69/172] - loss: 1.0751
Epoch 1 [70/172] - loss: 0.7586, acc: 0.6250
Epoch 1 [71/172] - loss: 1.1276
Epoch 1 [72/172] - loss: 0.6716
Epoch 1 [73/172] - loss: 0.8227
Epoch 1 [74/172] - loss: 1.3414
Epoch 1 [75/172] - loss: 0.4646
Epoch 1 [76/172] - loss: 1.0018
Epoch 1 [77/172] - loss: 0.6523
Epoch 1 [78/172] - loss: 0.7950
Epoch 1 [79/172] - loss: 1.1517
Epoch 1 [80/172] - loss: 0.7590, acc: 0.6562
Epoch 1 [81/172] - loss: 0.8165
Epoch 1 [82/172] - loss: 1.2131
Epoch 1 [83/172] - loss: 0.7936
Epoch 1 [84/172] - loss: 0.8998
Epoch 1 [85/172] - loss: 1.1103
Epoch 1 [86/172] - loss: 0.9718
Epoch 1 [87/172] - loss: 0.7377
Epoch 1 [88/172] - loss: 1.3580
Epoch 1 [89/172] - loss: 1.3216
Epoch 1 [90/172] - loss: 1.3551, acc: 0.4688
Epoch 1 [91/172] - loss: 0.6424
Epoch 1 [92/172] - loss: 0.8628
Epoch 1 [93/172] - loss: 0.7818
Epoch 1 [94/172] - loss: 0.6342
Epoch 1 [95/172] - loss: 1.1108
Epoch 1 [96/172] - loss: 0.8418
Epoch 1 [97/172] - loss: 0.8242
Epoch 1 [98/172] - loss: 0.8268
Epoch 1 [99/172] - loss: 0.9916
Epoch 1 [100/172] - loss: 1.2196, acc: 0.5312

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5976, log_difficulty=0.4685, weight=3.3424
neutral: count=983.0, difficulty=0.6037, log_difficulty=0.4723, weight=3.3614
negative: count=1119.0, difficulty=0.5804, log_difficulty=0.4577, weight=3.2883

当前batch的pt分布：
positive: min=0.1452, max=0.5912, mean=0.3808
neutral: min=0.0937, max=0.7622, mean=0.4769
negative: min=0.1137, max=0.6466, mean=0.3605

当前batch准确率：
整体准确率: 0.3750
positive 准确率: 0.2500
neutral 准确率: 0.7500
negative 准确率: 0.3750

损失分量：
基础交叉熵: 1.0589
焦点损失: 0.3946
边界损失: 0.6734
总损失: 1.2456
Epoch 1 [101/172] - loss: 1.2456
Epoch 1 [102/172] - loss: 0.9028
Epoch 1 [103/172] - loss: 0.8742
Epoch 1 [104/172] - loss: 0.6784
Epoch 1 [105/172] - loss: 1.0278
Epoch 1 [106/172] - loss: 1.3361
Epoch 1 [107/172] - loss: 0.6036
Epoch 1 [108/172] - loss: 1.3607
Epoch 1 [109/172] - loss: 0.8931
Epoch 1 [110/172] - loss: 0.8665, acc: 0.5000
Epoch 1 [111/172] - loss: 0.8539
Epoch 1 [112/172] - loss: 0.7515
Epoch 1 [113/172] - loss: 0.6861
Epoch 1 [114/172] - loss: 0.9077
Epoch 1 [115/172] - loss: 0.6720
Epoch 1 [116/172] - loss: 1.0033
Epoch 1 [117/172] - loss: 1.0080
Epoch 1 [118/172] - loss: 0.6308
Epoch 1 [119/172] - loss: 0.9042
Epoch 1 [120/172] - loss: 0.7338, acc: 0.7500
Epoch 1 [121/172] - loss: 0.5780
Epoch 1 [122/172] - loss: 1.3075
Epoch 1 [123/172] - loss: 0.7216
Epoch 1 [124/172] - loss: 0.8465
Epoch 1 [125/172] - loss: 0.5565
Epoch 1 [126/172] - loss: 0.8911
Epoch 1 [127/172] - loss: 0.8038
Epoch 1 [128/172] - loss: 0.7878
Epoch 1 [129/172] - loss: 0.8578
Epoch 1 [130/172] - loss: 0.6349, acc: 0.6562
Epoch 1 [131/172] - loss: 0.5326
Epoch 1 [132/172] - loss: 0.9486
Epoch 1 [133/172] - loss: 0.7670
Epoch 1 [134/172] - loss: 0.7612
Epoch 1 [135/172] - loss: 0.8116
Epoch 1 [136/172] - loss: 0.4468
Epoch 1 [137/172] - loss: 0.8100
Epoch 1 [138/172] - loss: 0.6924
Epoch 1 [139/172] - loss: 0.4954
Epoch 1 [140/172] - loss: 0.9478, acc: 0.6562
Epoch 1 [141/172] - loss: 0.6940
Epoch 1 [142/172] - loss: 0.8898
Epoch 1 [143/172] - loss: 0.7219
Epoch 1 [144/172] - loss: 0.4590
Epoch 1 [145/172] - loss: 0.7258
Epoch 1 [146/172] - loss: 0.6212
Epoch 1 [147/172] - loss: 0.9347
Epoch 1 [148/172] - loss: 0.5903
Epoch 1 [149/172] - loss: 0.5843
Epoch 1 [150/172] - loss: 0.8565, acc: 0.5312
Epoch 1 [151/172] - loss: 0.7285
Epoch 1 [152/172] - loss: 0.9783
Epoch 1 [153/172] - loss: 0.8556
Epoch 1 [154/172] - loss: 0.7147
Epoch 1 [155/172] - loss: 0.8207
Epoch 1 [156/172] - loss: 1.1384
Epoch 1 [157/172] - loss: 0.9517
Epoch 1 [158/172] - loss: 0.7256
Epoch 1 [159/172] - loss: 0.6674
Epoch 1 [160/172] - loss: 0.4161, acc: 0.7812
Epoch 1 [161/172] - loss: 0.5409
Epoch 1 [162/172] - loss: 0.6249
Epoch 1 [163/172] - loss: 0.7035
Epoch 1 [164/172] - loss: 0.5886
Epoch 1 [165/172] - loss: 0.5504
Epoch 1 [166/172] - loss: 0.6953
Epoch 1 [167/172] - loss: 0.6733
Epoch 1 [168/172] - loss: 0.6797
Epoch 1 [169/172] - loss: 0.7208
Epoch 1 [170/172] - loss: 0.4813, acc: 0.7188
Epoch 1 [171/172] - loss: 0.4626
Epoch 1 [172/172] - loss: 0.9366

类别准确率:
positive: 0.5696 (266/467)
neutral: 0.6506 (54/83)
negative: 0.4800 (120/250)

Epoch 1/10
Train Loss: 0.6512, Train Acc: 0.6929
Val Loss: 0.8746, Val Acc: 0.5500
Epoch 2 [1/172] - loss: 0.5566, acc: 0.8750
Epoch 2 [2/172] - loss: 0.5394
Epoch 2 [3/172] - loss: 0.3922
Epoch 2 [4/172] - loss: 0.7019
Epoch 2 [5/172] - loss: 0.7476
Epoch 2 [6/172] - loss: 0.5120
Epoch 2 [7/172] - loss: 0.5628
Epoch 2 [8/172] - loss: 0.4983
Epoch 2 [9/172] - loss: 0.4468
Epoch 2 [10/172] - loss: 0.4779, acc: 0.8125
Epoch 2 [11/172] - loss: 0.3907
Epoch 2 [12/172] - loss: 0.4489
Epoch 2 [13/172] - loss: 0.5351
Epoch 2 [14/172] - loss: 0.6445
Epoch 2 [15/172] - loss: 0.6091
Epoch 2 [16/172] - loss: 0.3681
Epoch 2 [17/172] - loss: 0.7214
Epoch 2 [18/172] - loss: 0.8204
Epoch 2 [19/172] - loss: 0.3702
Epoch 2 [20/172] - loss: 0.3477, acc: 0.7188
Epoch 2 [21/172] - loss: 0.5104
Epoch 2 [22/172] - loss: 0.4585
Epoch 2 [23/172] - loss: 0.5128
Epoch 2 [24/172] - loss: 1.0569
Epoch 2 [25/172] - loss: 0.5153
Epoch 2 [26/172] - loss: 0.4055
Epoch 2 [27/172] - loss: 0.3774
Epoch 2 [28/172] - loss: 0.2852

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5534, log_difficulty=0.4405, weight=3.2023
neutral: count=1952.0, difficulty=0.5242, log_difficulty=0.4214, weight=3.1072
negative: count=2216.0, difficulty=0.5353, log_difficulty=0.4287, weight=3.1436

当前batch的pt分布：
positive: min=0.4005, max=0.9021, mean=0.5874
neutral: min=0.1418, max=0.9155, mean=0.6060
negative: min=0.1215, max=0.9175, mean=0.5641

当前batch准确率：
整体准确率: 0.6875
positive 准确率: 0.7778
neutral 准确率: 0.7273
negative 准确率: 0.5833

损失分量：
基础交叉熵: 0.6373
焦点损失: 0.1844
边界损失: 0.4392
总损失: 0.5650
Epoch 2 [29/172] - loss: 0.5650
Epoch 2 [30/172] - loss: 0.3434, acc: 0.8438
Epoch 2 [31/172] - loss: 0.5563
Epoch 2 [32/172] - loss: 0.3437
Epoch 2 [33/172] - loss: 0.4662
Epoch 2 [34/172] - loss: 0.4342
Epoch 2 [35/172] - loss: 0.3869
Epoch 2 [36/172] - loss: 0.7561
Epoch 2 [37/172] - loss: 0.3835
Epoch 2 [38/172] - loss: 0.2884
Epoch 2 [39/172] - loss: 0.7072
Epoch 2 [40/172] - loss: 0.7196, acc: 0.7188
Epoch 2 [41/172] - loss: 0.4872
Epoch 2 [42/172] - loss: 0.3350
Epoch 2 [43/172] - loss: 0.3666
Epoch 2 [44/172] - loss: 0.5485
Epoch 2 [45/172] - loss: 0.3823
Epoch 2 [46/172] - loss: 0.3712
Epoch 2 [47/172] - loss: 0.4226
Epoch 2 [48/172] - loss: 0.5519
Epoch 2 [49/172] - loss: 0.4783
Epoch 2 [50/172] - loss: 0.3598, acc: 0.8125
Epoch 2 [51/172] - loss: 0.4185
Epoch 2 [52/172] - loss: 0.4768
Epoch 2 [53/172] - loss: 0.4362
Epoch 2 [54/172] - loss: 0.3991
Epoch 2 [55/172] - loss: 0.3994
Epoch 2 [56/172] - loss: 0.2807
Epoch 2 [57/172] - loss: 0.2297
Epoch 2 [58/172] - loss: 0.3106
Epoch 2 [59/172] - loss: 0.6020
Epoch 2 [60/172] - loss: 0.3195, acc: 0.7812
Epoch 2 [61/172] - loss: 0.1501
Epoch 2 [62/172] - loss: 0.1743
Epoch 2 [63/172] - loss: 0.4106
Epoch 2 [64/172] - loss: 0.3265
Epoch 2 [65/172] - loss: 0.2647
Epoch 2 [66/172] - loss: 0.4173
Epoch 2 [67/172] - loss: 0.2459
Epoch 2 [68/172] - loss: 0.3887
Epoch 2 [69/172] - loss: 0.2463
Epoch 2 [70/172] - loss: 0.6498, acc: 0.7188
Epoch 2 [71/172] - loss: 0.9223
Epoch 2 [72/172] - loss: 0.4294
Epoch 2 [73/172] - loss: 0.4036
Epoch 2 [74/172] - loss: 0.2091
Epoch 2 [75/172] - loss: 0.2161
Epoch 2 [76/172] - loss: 0.4037
Epoch 2 [77/172] - loss: 0.2524
Epoch 2 [78/172] - loss: 0.3444
Epoch 2 [79/172] - loss: 0.3588
Epoch 2 [80/172] - loss: 0.2288, acc: 0.8438
Epoch 2 [81/172] - loss: 0.2346
Epoch 2 [82/172] - loss: 0.3487
Epoch 2 [83/172] - loss: 0.4298
Epoch 2 [84/172] - loss: 0.3049
Epoch 2 [85/172] - loss: 0.4166
Epoch 2 [86/172] - loss: 0.3467
Epoch 2 [87/172] - loss: 0.7498
Epoch 2 [88/172] - loss: 0.5293
Epoch 2 [89/172] - loss: 0.4171
Epoch 2 [90/172] - loss: 0.2508, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1829
Epoch 2 [92/172] - loss: 0.4302
Epoch 2 [93/172] - loss: 0.3100
Epoch 2 [94/172] - loss: 0.4746
Epoch 2 [95/172] - loss: 0.5209
Epoch 2 [96/172] - loss: 0.3031
Epoch 2 [97/172] - loss: 0.2172
Epoch 2 [98/172] - loss: 0.1975
Epoch 2 [99/172] - loss: 0.1798
Epoch 2 [100/172] - loss: 0.2353, acc: 0.8750
Epoch 2 [101/172] - loss: 0.2325
Epoch 2 [102/172] - loss: 0.1871
Epoch 2 [103/172] - loss: 0.3417
Epoch 2 [104/172] - loss: 0.3928
Epoch 2 [105/172] - loss: 0.2466
Epoch 2 [106/172] - loss: 0.2434
Epoch 2 [107/172] - loss: 0.2120
Epoch 2 [108/172] - loss: 0.5154
Epoch 2 [109/172] - loss: 0.2452
Epoch 2 [110/172] - loss: 0.3228, acc: 0.7500
Epoch 2 [111/172] - loss: 0.3407
Epoch 2 [112/172] - loss: 0.2799
Epoch 2 [113/172] - loss: 0.2171
Epoch 2 [114/172] - loss: 0.3695
Epoch 2 [115/172] - loss: 0.3775
Epoch 2 [116/172] - loss: 0.2477
Epoch 2 [117/172] - loss: 0.4860
Epoch 2 [118/172] - loss: 0.2408
Epoch 2 [119/172] - loss: 0.2328
Epoch 2 [120/172] - loss: 0.2579, acc: 0.8438
Epoch 2 [121/172] - loss: 0.1556
Epoch 2 [122/172] - loss: 0.5450
Epoch 2 [123/172] - loss: 0.3818
Epoch 2 [124/172] - loss: 0.2886
Epoch 2 [125/172] - loss: 0.1780
Epoch 2 [126/172] - loss: 0.1305
Epoch 2 [127/172] - loss: 0.2765
Epoch 2 [128/172] - loss: 0.3387

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.5062, log_difficulty=0.4096, weight=3.0481
neutral: count=2949.0, difficulty=0.4380, log_difficulty=0.3633, weight=2.8163
negative: count=3294.0, difficulty=0.4880, log_difficulty=0.3974, weight=2.9871

当前batch的pt分布：
positive: min=0.4458, max=0.8390, mean=0.6609
neutral: min=0.1694, max=0.9438, mean=0.7191
negative: min=0.0463, max=0.9021, mean=0.5824

当前batch准确率：
整体准确率: 0.7812
positive 准确率: 0.9000
neutral 准确率: 0.8182
negative 准确率: 0.6364

损失分量：
基础交叉熵: 0.5300
焦点损失: 0.1651
边界损失: 0.3853
总损失: 0.4766
Epoch 2 [129/172] - loss: 0.4766
Epoch 2 [130/172] - loss: 0.2002, acc: 0.9062
Epoch 2 [131/172] - loss: 0.1787
Epoch 2 [132/172] - loss: 0.3554
Epoch 2 [133/172] - loss: 0.1907
Epoch 2 [134/172] - loss: 0.1191
Epoch 2 [135/172] - loss: 0.3934
Epoch 2 [136/172] - loss: 0.3996
Epoch 2 [137/172] - loss: 0.1796
Epoch 2 [138/172] - loss: 0.1602
Epoch 2 [139/172] - loss: 0.3073
Epoch 2 [140/172] - loss: 0.2876, acc: 0.8750
Epoch 2 [141/172] - loss: 0.2902
Epoch 2 [142/172] - loss: 0.3181
Epoch 2 [143/172] - loss: 0.2116
Epoch 2 [144/172] - loss: 0.2935
Epoch 2 [145/172] - loss: 0.6392
Epoch 2 [146/172] - loss: 0.1696
Epoch 2 [147/172] - loss: 0.1381
Epoch 2 [148/172] - loss: 0.3429
Epoch 2 [149/172] - loss: 0.3919
Epoch 2 [150/172] - loss: 0.4047, acc: 0.8438
Epoch 2 [151/172] - loss: 0.2302
Epoch 2 [152/172] - loss: 0.2388
Epoch 2 [153/172] - loss: 0.3276
Epoch 2 [154/172] - loss: 0.3021
Epoch 2 [155/172] - loss: 0.1498
Epoch 2 [156/172] - loss: 0.2554
Epoch 2 [157/172] - loss: 0.2046
Epoch 2 [158/172] - loss: 0.2756
Epoch 2 [159/172] - loss: 0.2746
Epoch 2 [160/172] - loss: 0.2390, acc: 0.9062
Epoch 2 [161/172] - loss: 0.1998
Epoch 2 [162/172] - loss: 0.1302
Epoch 2 [163/172] - loss: 0.2542
Epoch 2 [164/172] - loss: 0.3661
Epoch 2 [165/172] - loss: 0.4400
Epoch 2 [166/172] - loss: 0.4791
Epoch 2 [167/172] - loss: 0.2772
Epoch 2 [168/172] - loss: 0.1913
Epoch 2 [169/172] - loss: 0.1695
Epoch 2 [170/172] - loss: 0.2024, acc: 0.8438
Epoch 2 [171/172] - loss: 0.3369
Epoch 2 [172/172] - loss: 0.5419

类别准确率:
positive: 0.8266 (386/467)
neutral: 0.3614 (30/83)
negative: 0.6760 (169/250)

Epoch 2/10
Train Loss: 0.2864, Train Acc: 0.8545
Val Loss: 0.6714, Val Acc: 0.7312
Epoch 3 [1/172] - loss: 0.2103, acc: 0.9062
Epoch 3 [2/172] - loss: 0.1093
Epoch 3 [3/172] - loss: 0.0658
Epoch 3 [4/172] - loss: 0.1919
Epoch 3 [5/172] - loss: 0.2683
Epoch 3 [6/172] - loss: 0.1972
Epoch 3 [7/172] - loss: 0.1440
Epoch 3 [8/172] - loss: 0.3025
Epoch 3 [9/172] - loss: 0.1026
Epoch 3 [10/172] - loss: 0.0848, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1197
Epoch 3 [12/172] - loss: 0.0761
Epoch 3 [13/172] - loss: 0.0808
Epoch 3 [14/172] - loss: 0.0729
Epoch 3 [15/172] - loss: 0.1689
Epoch 3 [16/172] - loss: 0.4017
Epoch 3 [17/172] - loss: 0.2355
Epoch 3 [18/172] - loss: 0.2390
Epoch 3 [19/172] - loss: 0.2758
Epoch 3 [20/172] - loss: 0.0732, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1126
Epoch 3 [22/172] - loss: 0.3134
Epoch 3 [23/172] - loss: 0.0947
Epoch 3 [24/172] - loss: 0.1440
Epoch 3 [25/172] - loss: 0.1594
Epoch 3 [26/172] - loss: 0.1022
Epoch 3 [27/172] - loss: 0.2163
Epoch 3 [28/172] - loss: 0.1135
Epoch 3 [29/172] - loss: 0.3482
Epoch 3 [30/172] - loss: 0.3875, acc: 0.7500
Epoch 3 [31/172] - loss: 0.1256
Epoch 3 [32/172] - loss: 0.2051
Epoch 3 [33/172] - loss: 0.0825
Epoch 3 [34/172] - loss: 0.1662
Epoch 3 [35/172] - loss: 0.1620
Epoch 3 [36/172] - loss: 0.0703
Epoch 3 [37/172] - loss: 0.1507
Epoch 3 [38/172] - loss: 0.1586
Epoch 3 [39/172] - loss: 0.1042
Epoch 3 [40/172] - loss: 0.1892, acc: 0.9062
Epoch 3 [41/172] - loss: 0.1225
Epoch 3 [42/172] - loss: 0.2594
Epoch 3 [43/172] - loss: 0.1742
Epoch 3 [44/172] - loss: 0.0850
Epoch 3 [45/172] - loss: 0.3914
Epoch 3 [46/172] - loss: 0.2983
Epoch 3 [47/172] - loss: 0.2066
Epoch 3 [48/172] - loss: 0.1368
Epoch 3 [49/172] - loss: 0.0949
Epoch 3 [50/172] - loss: 0.0746, acc: 1.0000
Epoch 3 [51/172] - loss: 0.2121
Epoch 3 [52/172] - loss: 0.4161
Epoch 3 [53/172] - loss: 0.0591
Epoch 3 [54/172] - loss: 0.1588
Epoch 3 [55/172] - loss: 0.1459
Epoch 3 [56/172] - loss: 0.1223

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.4587, log_difficulty=0.3775, weight=2.8877
neutral: count=3923.0, difficulty=0.3835, log_difficulty=0.3246, weight=2.6232
negative: count=4382.0, difficulty=0.4451, log_difficulty=0.3681, weight=2.8407

当前batch的pt分布：
positive: min=0.2561, max=0.9866, mean=0.7237
neutral: min=0.0449, max=0.8793, mean=0.6847
negative: min=0.7407, max=0.8863, mean=0.8281

当前batch准确率：
整体准确率: 0.8125
positive 准确率: 0.7273
neutral 准确率: 0.8125
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.4603
焦点损失: 0.1926
边界损失: 0.2841
总损失: 0.4926
Epoch 3 [57/172] - loss: 0.4926
Epoch 3 [58/172] - loss: 0.0619
Epoch 3 [59/172] - loss: 0.1198
Epoch 3 [60/172] - loss: 0.1032, acc: 0.9062
Epoch 3 [61/172] - loss: 0.1816
Epoch 3 [62/172] - loss: 0.2035
Epoch 3 [63/172] - loss: 0.0692
Epoch 3 [64/172] - loss: 0.1948
Epoch 3 [65/172] - loss: 0.1751
Epoch 3 [66/172] - loss: 0.1230
Epoch 3 [67/172] - loss: 0.2084
Epoch 3 [68/172] - loss: 0.0537
Epoch 3 [69/172] - loss: 0.2307
Epoch 3 [70/172] - loss: 0.0850, acc: 0.9375
Epoch 3 [71/172] - loss: 0.1106
Epoch 3 [72/172] - loss: 0.2229
Epoch 3 [73/172] - loss: 0.1198
Epoch 3 [74/172] - loss: 0.2830
Epoch 3 [75/172] - loss: 0.0744
Epoch 3 [76/172] - loss: 0.0561
Epoch 3 [77/172] - loss: 0.1351
Epoch 3 [78/172] - loss: 0.2315
Epoch 3 [79/172] - loss: 0.1579
Epoch 3 [80/172] - loss: 0.1437, acc: 0.9062
Epoch 3 [81/172] - loss: 0.0983
Epoch 3 [82/172] - loss: 0.1796
Epoch 3 [83/172] - loss: 0.0671
Epoch 3 [84/172] - loss: 0.1916
Epoch 3 [85/172] - loss: 0.0997
Epoch 3 [86/172] - loss: 0.0889
Epoch 3 [87/172] - loss: 0.1209
Epoch 3 [88/172] - loss: 0.1137
Epoch 3 [89/172] - loss: 0.0957
Epoch 3 [90/172] - loss: 0.1161, acc: 0.9062
Epoch 3 [91/172] - loss: 0.2324
Epoch 3 [92/172] - loss: 0.1623
Epoch 3 [93/172] - loss: 0.1932
Epoch 3 [94/172] - loss: 0.1390
Epoch 3 [95/172] - loss: 0.0542
Epoch 3 [96/172] - loss: 0.0924
Epoch 3 [97/172] - loss: 0.1209
Epoch 3 [98/172] - loss: 0.1247
Epoch 3 [99/172] - loss: 0.0589
Epoch 3 [100/172] - loss: 0.0918, acc: 0.9688
Epoch 3 [101/172] - loss: 0.1455
Epoch 3 [102/172] - loss: 0.0483
Epoch 3 [103/172] - loss: 0.1828
Epoch 3 [104/172] - loss: 0.1335
Epoch 3 [105/172] - loss: 0.0595
Epoch 3 [106/172] - loss: 0.1795
Epoch 3 [107/172] - loss: 0.0922
Epoch 3 [108/172] - loss: 0.3099
Epoch 3 [109/172] - loss: 0.0631
Epoch 3 [110/172] - loss: 0.2163, acc: 0.8750
Epoch 3 [111/172] - loss: 0.2415
Epoch 3 [112/172] - loss: 0.0615
Epoch 3 [113/172] - loss: 0.0969
Epoch 3 [114/172] - loss: 0.1223
Epoch 3 [115/172] - loss: 0.1070
Epoch 3 [116/172] - loss: 0.1404
Epoch 3 [117/172] - loss: 0.2601
Epoch 3 [118/172] - loss: 0.1639
Epoch 3 [119/172] - loss: 0.2391
Epoch 3 [120/172] - loss: 0.1913, acc: 0.9062
Epoch 3 [121/172] - loss: 0.4136
Epoch 3 [122/172] - loss: 0.1872
Epoch 3 [123/172] - loss: 0.0942
Epoch 3 [124/172] - loss: 0.2237
Epoch 3 [125/172] - loss: 0.0967
Epoch 3 [126/172] - loss: 0.3301
Epoch 3 [127/172] - loss: 0.2563
Epoch 3 [128/172] - loss: 0.0592
Epoch 3 [129/172] - loss: 0.1062
Epoch 3 [130/172] - loss: 0.1115, acc: 0.9375
Epoch 3 [131/172] - loss: 0.1228
Epoch 3 [132/172] - loss: 0.0678
Epoch 3 [133/172] - loss: 0.1054
Epoch 3 [134/172] - loss: 0.0821
Epoch 3 [135/172] - loss: 0.0949
Epoch 3 [136/172] - loss: 0.1605
Epoch 3 [137/172] - loss: 0.1993
Epoch 3 [138/172] - loss: 0.0921
Epoch 3 [139/172] - loss: 0.1130
Epoch 3 [140/172] - loss: 0.0933, acc: 0.9375
Epoch 3 [141/172] - loss: 0.1762
Epoch 3 [142/172] - loss: 0.1739
Epoch 3 [143/172] - loss: 0.0693
Epoch 3 [144/172] - loss: 0.1157
Epoch 3 [145/172] - loss: 0.1756
Epoch 3 [146/172] - loss: 0.0961
Epoch 3 [147/172] - loss: 0.2089
Epoch 3 [148/172] - loss: 0.2208
Epoch 3 [149/172] - loss: 0.1530
Epoch 3 [150/172] - loss: 0.1588, acc: 0.9062
Epoch 3 [151/172] - loss: 0.3403
Epoch 3 [152/172] - loss: 0.3181
Epoch 3 [153/172] - loss: 0.1044
Epoch 3 [154/172] - loss: 0.1028
Epoch 3 [155/172] - loss: 0.0524
Epoch 3 [156/172] - loss: 0.1288

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.4176, log_difficulty=0.3490, weight=2.7450
neutral: count=4903.0, difficulty=0.3404, log_difficulty=0.2929, weight=2.4647
negative: count=5500.0, difficulty=0.4096, log_difficulty=0.3433, weight=2.7167

当前batch的pt分布：
positive: min=0.4294, max=0.9445, mean=0.7392
neutral: min=0.4721, max=0.9860, mean=0.8546
negative: min=0.3311, max=0.9251, mean=0.7202

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 0.8000

损失分量：
基础交叉熵: 0.2910
焦点损失: 0.0392
边界损失: 0.2925
总损失: 0.1237
Epoch 3 [157/172] - loss: 0.1237
Epoch 3 [158/172] - loss: 0.2808
Epoch 3 [159/172] - loss: 0.1247
Epoch 3 [160/172] - loss: 0.1928, acc: 0.8125
Epoch 3 [161/172] - loss: 0.1746
Epoch 3 [162/172] - loss: 0.2237
Epoch 3 [163/172] - loss: 0.2720
Epoch 3 [164/172] - loss: 0.0713
Epoch 3 [165/172] - loss: 0.1199
Epoch 3 [166/172] - loss: 0.0931
Epoch 3 [167/172] - loss: 0.1088
Epoch 3 [168/172] - loss: 0.0448
Epoch 3 [169/172] - loss: 0.0648
Epoch 3 [170/172] - loss: 0.0937, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1318
Epoch 3 [172/172] - loss: 0.0851

类别准确率:
positive: 0.8158 (381/467)
neutral: 0.3494 (29/83)
negative: 0.6480 (162/250)

Epoch 3/10
Train Loss: 0.1378, Train Acc: 0.9212
Val Loss: 0.7066, Val Acc: 0.7150
Epoch 4 [1/172] - loss: 0.0459, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1314
Epoch 4 [3/172] - loss: 0.0527
Epoch 4 [4/172] - loss: 0.0582
Epoch 4 [5/172] - loss: 0.0640
Epoch 4 [6/172] - loss: 0.0339
Epoch 4 [7/172] - loss: 0.0499
Epoch 4 [8/172] - loss: 0.0411
Epoch 4 [9/172] - loss: 0.1968
Epoch 4 [10/172] - loss: 0.0390, acc: 1.0000
Epoch 4 [11/172] - loss: 0.0327
Epoch 4 [12/172] - loss: 0.1872
Epoch 4 [13/172] - loss: 0.0848
Epoch 4 [14/172] - loss: 0.1019
Epoch 4 [15/172] - loss: 0.0373
Epoch 4 [16/172] - loss: 0.0722
Epoch 4 [17/172] - loss: 0.0394
Epoch 4 [18/172] - loss: 0.3486
Epoch 4 [19/172] - loss: 0.0785
Epoch 4 [20/172] - loss: 0.0619, acc: 1.0000
Epoch 4 [21/172] - loss: 0.0423
Epoch 4 [22/172] - loss: 0.0312
Epoch 4 [23/172] - loss: 0.0734
Epoch 4 [24/172] - loss: 0.0350
Epoch 4 [25/172] - loss: 0.0443
Epoch 4 [26/172] - loss: 0.2587
Epoch 4 [27/172] - loss: 0.0435
Epoch 4 [28/172] - loss: 0.0632
Epoch 4 [29/172] - loss: 0.0724
Epoch 4 [30/172] - loss: 0.1471, acc: 0.9062
Epoch 4 [31/172] - loss: 0.0992
Epoch 4 [32/172] - loss: 0.1466
Epoch 4 [33/172] - loss: 0.1490
Epoch 4 [34/172] - loss: 0.0326
Epoch 4 [35/172] - loss: 0.0761
Epoch 4 [36/172] - loss: 0.0637
Epoch 4 [37/172] - loss: 0.0261
Epoch 4 [38/172] - loss: 0.0241
Epoch 4 [39/172] - loss: 0.0931
Epoch 4 [40/172] - loss: 0.2270, acc: 0.8438
Epoch 4 [41/172] - loss: 0.0474
Epoch 4 [42/172] - loss: 0.0522
Epoch 4 [43/172] - loss: 0.1355
Epoch 4 [44/172] - loss: 0.0714
Epoch 4 [45/172] - loss: 0.0870
Epoch 4 [46/172] - loss: 0.0460
Epoch 4 [47/172] - loss: 0.0758
Epoch 4 [48/172] - loss: 0.0797
Epoch 4 [49/172] - loss: 0.0456
Epoch 4 [50/172] - loss: 0.2311, acc: 0.9375
Epoch 4 [51/172] - loss: 0.0446
Epoch 4 [52/172] - loss: 0.0742
Epoch 4 [53/172] - loss: 0.0729
Epoch 4 [54/172] - loss: 0.0559
Epoch 4 [55/172] - loss: 0.1372
Epoch 4 [56/172] - loss: 0.0657
Epoch 4 [57/172] - loss: 0.0413
Epoch 4 [58/172] - loss: 0.0547
Epoch 4 [59/172] - loss: 0.0419
Epoch 4 [60/172] - loss: 0.0532, acc: 0.9688
Epoch 4 [61/172] - loss: 0.2666
Epoch 4 [62/172] - loss: 0.1439
Epoch 4 [63/172] - loss: 0.0870
Epoch 4 [64/172] - loss: 0.0961
Epoch 4 [65/172] - loss: 0.0556
Epoch 4 [66/172] - loss: 0.0376
Epoch 4 [67/172] - loss: 0.0552
Epoch 4 [68/172] - loss: 0.0424
Epoch 4 [69/172] - loss: 0.1732
Epoch 4 [70/172] - loss: 0.0893, acc: 0.9688
Epoch 4 [71/172] - loss: 0.0376
Epoch 4 [72/172] - loss: 0.0293
Epoch 4 [73/172] - loss: 0.1132
Epoch 4 [74/172] - loss: 0.1422
Epoch 4 [75/172] - loss: 0.0621
Epoch 4 [76/172] - loss: 0.0913
Epoch 4 [77/172] - loss: 0.0629
Epoch 4 [78/172] - loss: 0.0967
Epoch 4 [79/172] - loss: 0.0779
Epoch 4 [80/172] - loss: 0.0710, acc: 0.9688
Epoch 4 [81/172] - loss: 0.0776
Epoch 4 [82/172] - loss: 0.0662
Epoch 4 [83/172] - loss: 0.0536
Epoch 4 [84/172] - loss: 0.0314

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3819, log_difficulty=0.3235, weight=2.6173
neutral: count=5865.0, difficulty=0.3071, log_difficulty=0.2678, weight=2.3390
negative: count=6629.0, difficulty=0.3757, log_difficulty=0.3190, weight=2.5948

当前batch的pt分布：
positive: min=0.3078, max=0.9110, mean=0.7211
neutral: min=0.7240, max=0.9933, mean=0.9321
negative: min=0.5070, max=0.9518, mean=0.7881

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2762
焦点损失: 0.0422
边界损失: 0.2750
总损失: 0.1267
Epoch 4 [85/172] - loss: 0.1267
Epoch 4 [86/172] - loss: 0.1423
Epoch 4 [87/172] - loss: 0.1813
Epoch 4 [88/172] - loss: 0.0404
Epoch 4 [89/172] - loss: 0.0439
Epoch 4 [90/172] - loss: 0.0526, acc: 0.9688
Epoch 4 [91/172] - loss: 0.2310
Epoch 4 [92/172] - loss: 0.2202
Epoch 4 [93/172] - loss: 0.0386
Epoch 4 [94/172] - loss: 0.1380
Epoch 4 [95/172] - loss: 0.1675
Epoch 4 [96/172] - loss: 0.0508
Epoch 4 [97/172] - loss: 0.0482
Epoch 4 [98/172] - loss: 0.1505
Epoch 4 [99/172] - loss: 0.1112
Epoch 4 [100/172] - loss: 0.0471, acc: 1.0000
Epoch 4 [101/172] - loss: 0.1425
Epoch 4 [102/172] - loss: 0.2251
Epoch 4 [103/172] - loss: 0.1452
Epoch 4 [104/172] - loss: 0.0440
Epoch 4 [105/172] - loss: 0.2864
Epoch 4 [106/172] - loss: 0.0424
Epoch 4 [107/172] - loss: 0.0802
Epoch 4 [108/172] - loss: 0.0758
Epoch 4 [109/172] - loss: 0.0294
Epoch 4 [110/172] - loss: 0.3895, acc: 0.8750
Epoch 4 [111/172] - loss: 0.1173
Epoch 4 [112/172] - loss: 0.0345
Epoch 4 [113/172] - loss: 0.0342
Epoch 4 [114/172] - loss: 0.0689
Epoch 4 [115/172] - loss: 0.1166
Epoch 4 [116/172] - loss: 0.0465
Epoch 4 [117/172] - loss: 0.1078
Epoch 4 [118/172] - loss: 0.1123
Epoch 4 [119/172] - loss: 0.0453
Epoch 4 [120/172] - loss: 0.0524, acc: 0.9688
Epoch 4 [121/172] - loss: 0.1779
Epoch 4 [122/172] - loss: 0.3024
Epoch 4 [123/172] - loss: 0.1100
Epoch 4 [124/172] - loss: 0.0450
Epoch 4 [125/172] - loss: 0.0871
Epoch 4 [126/172] - loss: 0.2173
Epoch 4 [127/172] - loss: 0.1739
Epoch 4 [128/172] - loss: 0.0651
Epoch 4 [129/172] - loss: 0.0517
Epoch 4 [130/172] - loss: 0.0319, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0415
Epoch 4 [132/172] - loss: 0.0294
Epoch 4 [133/172] - loss: 0.1387
Epoch 4 [134/172] - loss: 0.0460
Epoch 4 [135/172] - loss: 0.1970
Epoch 4 [136/172] - loss: 0.2218
Epoch 4 [137/172] - loss: 0.0642
Epoch 4 [138/172] - loss: 0.0398
Epoch 4 [139/172] - loss: 0.0441
Epoch 4 [140/172] - loss: 0.0345, acc: 1.0000
Epoch 4 [141/172] - loss: 0.2821
Epoch 4 [142/172] - loss: 0.0946
Epoch 4 [143/172] - loss: 0.0294
Epoch 4 [144/172] - loss: 0.0988
Epoch 4 [145/172] - loss: 0.2749
Epoch 4 [146/172] - loss: 0.0519
Epoch 4 [147/172] - loss: 0.1717
Epoch 4 [148/172] - loss: 0.0552
Epoch 4 [149/172] - loss: 0.0830
Epoch 4 [150/172] - loss: 0.2170, acc: 0.8750
Epoch 4 [151/172] - loss: 0.3303
Epoch 4 [152/172] - loss: 0.0547
Epoch 4 [153/172] - loss: 0.0509
Epoch 4 [154/172] - loss: 0.3785
Epoch 4 [155/172] - loss: 0.0530
Epoch 4 [156/172] - loss: 0.1477
Epoch 4 [157/172] - loss: 0.3569
Epoch 4 [158/172] - loss: 0.0347
Epoch 4 [159/172] - loss: 0.0468
Epoch 4 [160/172] - loss: 0.1114, acc: 0.9375
Epoch 4 [161/172] - loss: 0.0618
Epoch 4 [162/172] - loss: 0.1075
Epoch 4 [163/172] - loss: 0.0856
Epoch 4 [164/172] - loss: 0.0651
Epoch 4 [165/172] - loss: 0.0924
Epoch 4 [166/172] - loss: 0.0874
Epoch 4 [167/172] - loss: 0.1624
Epoch 4 [168/172] - loss: 0.0557
Epoch 4 [169/172] - loss: 0.1411
Epoch 4 [170/172] - loss: 0.1695, acc: 0.9062
Epoch 4 [171/172] - loss: 0.2016
Epoch 4 [172/172] - loss: 0.0695

类别准确率:
positive: 0.8522 (398/467)
neutral: 0.3012 (25/83)
negative: 0.5680 (142/250)

Epoch 4/10
Train Loss: 0.1156, Train Acc: 0.9394
Val Loss: 0.6859, Val Acc: 0.7063
Epoch 5 [1/172] - loss: 0.0268, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1040
Epoch 5 [3/172] - loss: 0.0546
Epoch 5 [4/172] - loss: 0.0686
Epoch 5 [5/172] - loss: 0.0616
Epoch 5 [6/172] - loss: 0.0615
Epoch 5 [7/172] - loss: 0.0814
Epoch 5 [8/172] - loss: 0.0759
Epoch 5 [9/172] - loss: 0.1225
Epoch 5 [10/172] - loss: 0.0842, acc: 0.9688
Epoch 5 [11/172] - loss: 0.0737
Epoch 5 [12/172] - loss: 0.0364

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.3525, log_difficulty=0.3020, weight=2.5098
neutral: count=6845.0, difficulty=0.2824, log_difficulty=0.2487, weight=2.2435
negative: count=7694.0, difficulty=0.3531, log_difficulty=0.3024, weight=2.5121

当前batch的pt分布：
positive: min=0.2848, max=0.9558, mean=0.7654
neutral: min=0.7898, max=0.9997, mean=0.9328
negative: min=0.4818, max=0.9370, mean=0.8093

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2289
焦点损失: 0.0317
边界损失: 0.2482
总损失: 0.0964
Epoch 5 [13/172] - loss: 0.0964
Epoch 5 [14/172] - loss: 0.1133
Epoch 5 [15/172] - loss: 0.0425
Epoch 5 [16/172] - loss: 0.0323
Epoch 5 [17/172] - loss: 0.0427
Epoch 5 [18/172] - loss: 0.0547
Epoch 5 [19/172] - loss: 0.0783
Epoch 5 [20/172] - loss: 0.0742, acc: 0.9688
Epoch 5 [21/172] - loss: 0.0769
Epoch 5 [22/172] - loss: 0.1425
Epoch 5 [23/172] - loss: 0.0343
Epoch 5 [24/172] - loss: 0.0377
Epoch 5 [25/172] - loss: 0.0325
Epoch 5 [26/172] - loss: 0.0428
Epoch 5 [27/172] - loss: 0.0305
Epoch 5 [28/172] - loss: 0.0761
Epoch 5 [29/172] - loss: 0.0510
Epoch 5 [30/172] - loss: 0.0525, acc: 0.9688
Epoch 5 [31/172] - loss: 0.0434
Epoch 5 [32/172] - loss: 0.0441
Epoch 5 [33/172] - loss: 0.0496
Epoch 5 [34/172] - loss: 0.0424
Epoch 5 [35/172] - loss: 0.0293
Epoch 5 [36/172] - loss: 0.0392
Epoch 5 [37/172] - loss: 0.0442
Epoch 5 [38/172] - loss: 0.0597
Epoch 5 [39/172] - loss: 0.0817
Epoch 5 [40/172] - loss: 0.0328, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0702
Epoch 5 [42/172] - loss: 0.0806
Epoch 5 [43/172] - loss: 0.0743
Epoch 5 [44/172] - loss: 0.0397
Epoch 5 [45/172] - loss: 0.0276
Epoch 5 [46/172] - loss: 0.0650
Epoch 5 [47/172] - loss: 0.0471
Epoch 5 [48/172] - loss: 0.0519
Epoch 5 [49/172] - loss: 0.0639
Epoch 5 [50/172] - loss: 0.1439, acc: 0.9688
Epoch 5 [51/172] - loss: 0.1396
Epoch 5 [52/172] - loss: 0.0567
Epoch 5 [53/172] - loss: 0.0512
Epoch 5 [54/172] - loss: 0.0422
Epoch 5 [55/172] - loss: 0.0587
Epoch 5 [56/172] - loss: 0.0545
Epoch 5 [57/172] - loss: 0.0408
Epoch 5 [58/172] - loss: 0.0374
Epoch 5 [59/172] - loss: 0.0715
Epoch 5 [60/172] - loss: 0.0390, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0784
Epoch 5 [62/172] - loss: 0.0301
Epoch 5 [63/172] - loss: 0.1123
Epoch 5 [64/172] - loss: 0.0548
Epoch 5 [65/172] - loss: 0.0386
Epoch 5 [66/172] - loss: 0.0306
Epoch 5 [67/172] - loss: 0.0388
Epoch 5 [68/172] - loss: 0.0699
Epoch 5 [69/172] - loss: 0.1563
Epoch 5 [70/172] - loss: 0.0263, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0745
Epoch 5 [72/172] - loss: 0.0417
Epoch 5 [73/172] - loss: 0.0345
Epoch 5 [74/172] - loss: 0.0440
Epoch 5 [75/172] - loss: 0.0277
Epoch 5 [76/172] - loss: 0.0330
Epoch 5 [77/172] - loss: 0.0362
Epoch 5 [78/172] - loss: 0.0982
Epoch 5 [79/172] - loss: 0.0344
Epoch 5 [80/172] - loss: 0.0449, acc: 1.0000
Epoch 5 [81/172] - loss: 0.0946
Epoch 5 [82/172] - loss: 0.0908
Epoch 5 [83/172] - loss: 0.0306
Epoch 5 [84/172] - loss: 0.0269
Epoch 5 [85/172] - loss: 0.0798
Epoch 5 [86/172] - loss: 0.0425
Epoch 5 [87/172] - loss: 0.0844
Epoch 5 [88/172] - loss: 0.0668
Epoch 5 [89/172] - loss: 0.0308
Epoch 5 [90/172] - loss: 0.0800, acc: 0.9375
Epoch 5 [91/172] - loss: 0.0519
Epoch 5 [92/172] - loss: 0.0444
Epoch 5 [93/172] - loss: 0.0349
Epoch 5 [94/172] - loss: 0.0294
Epoch 5 [95/172] - loss: 0.0399
Epoch 5 [96/172] - loss: 0.0769
Epoch 5 [97/172] - loss: 0.0600
Epoch 5 [98/172] - loss: 0.0489
Epoch 5 [99/172] - loss: 0.0796
Epoch 5 [100/172] - loss: 0.0615, acc: 0.9688
Epoch 5 [101/172] - loss: 0.0569
Epoch 5 [102/172] - loss: 0.0331
Epoch 5 [103/172] - loss: 0.0826
Epoch 5 [104/172] - loss: 0.1751
Epoch 5 [105/172] - loss: 0.2723
Epoch 5 [106/172] - loss: 0.0403
Epoch 5 [107/172] - loss: 0.0966
Epoch 5 [108/172] - loss: 0.2806
Epoch 5 [109/172] - loss: 0.0224
Epoch 5 [110/172] - loss: 0.0358, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0510
Epoch 5 [112/172] - loss: 0.0426

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.3273, log_difficulty=0.2832, weight=2.4159
neutral: count=7825.0, difficulty=0.2621, log_difficulty=0.2328, weight=2.1639
negative: count=8780.0, difficulty=0.3317, log_difficulty=0.2865, weight=2.4324

当前batch的pt分布：
positive: min=0.1633, max=0.9300, mean=0.7526
neutral: min=0.7710, max=0.9571, mean=0.8968
negative: min=0.8840, max=0.9682, mean=0.9406

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2231
焦点损失: 0.0500
边界损失: 0.2295
总损失: 0.1315
Epoch 5 [113/172] - loss: 0.1315
Epoch 5 [114/172] - loss: 0.0417
Epoch 5 [115/172] - loss: 0.0841
Epoch 5 [116/172] - loss: 0.0257
Epoch 5 [117/172] - loss: 0.0382
Epoch 5 [118/172] - loss: 0.0265
Epoch 5 [119/172] - loss: 0.0278
Epoch 5 [120/172] - loss: 0.0450, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0676
Epoch 5 [122/172] - loss: 0.0451
Epoch 5 [123/172] - loss: 0.0428
Epoch 5 [124/172] - loss: 0.0228
Epoch 5 [125/172] - loss: 0.0246
Epoch 5 [126/172] - loss: 0.0364
Epoch 5 [127/172] - loss: 0.0608
Epoch 5 [128/172] - loss: 0.0337
Epoch 5 [129/172] - loss: 0.0948
Epoch 5 [130/172] - loss: 0.0263, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0295
Epoch 5 [132/172] - loss: 0.0721
Epoch 5 [133/172] - loss: 0.0920
Epoch 5 [134/172] - loss: 0.1000
Epoch 5 [135/172] - loss: 0.0242
Epoch 5 [136/172] - loss: 0.0297
Epoch 5 [137/172] - loss: 0.0566
Epoch 5 [138/172] - loss: 0.0518
Epoch 5 [139/172] - loss: 0.2689
Epoch 5 [140/172] - loss: 0.0469, acc: 1.0000
Epoch 5 [141/172] - loss: 0.0406
Epoch 5 [142/172] - loss: 0.0372
Epoch 5 [143/172] - loss: 0.0315
Epoch 5 [144/172] - loss: 0.0224
Epoch 5 [145/172] - loss: 0.0557
Epoch 5 [146/172] - loss: 0.0241
Epoch 5 [147/172] - loss: 0.0875
Epoch 5 [148/172] - loss: 0.0247
Epoch 5 [149/172] - loss: 0.0928
Epoch 5 [150/172] - loss: 0.0759, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0292
Epoch 5 [152/172] - loss: 0.0245
Epoch 5 [153/172] - loss: 0.0268
Epoch 5 [154/172] - loss: 0.0408
Epoch 5 [155/172] - loss: 0.1766
Epoch 5 [156/172] - loss: 0.0598
Epoch 5 [157/172] - loss: 0.0451
Epoch 5 [158/172] - loss: 0.0414
Epoch 5 [159/172] - loss: 0.0240
Epoch 5 [160/172] - loss: 0.0501, acc: 0.9688
Epoch 5 [161/172] - loss: 0.0273
Epoch 5 [162/172] - loss: 0.0525
Epoch 5 [163/172] - loss: 0.0678
Epoch 5 [164/172] - loss: 0.0308
Epoch 5 [165/172] - loss: 0.0652
Epoch 5 [166/172] - loss: 0.0417
Epoch 5 [167/172] - loss: 0.0406
Epoch 5 [168/172] - loss: 0.0195
Epoch 5 [169/172] - loss: 0.0247
Epoch 5 [170/172] - loss: 0.0298, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0301
Epoch 5 [172/172] - loss: 0.0406

类别准确率:
positive: 0.8351 (390/467)
neutral: 0.3253 (27/83)
negative: 0.6440 (161/250)

Epoch 5/10
Train Loss: 0.0395, Train Acc: 0.9919
Val Loss: 0.7079, Val Acc: 0.7225
Early stopping triggered!
Best validation accuracy: 0.7312

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_141608-dmnar3jj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.35_Multimodal_iterations_20250118_141607
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/dmnar3jj
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██
wandb:  train_acc ▁▄▄▄▄▂▂▅▂▅▅▆▅▅▆▇▆▆██▇▇▇█▇▇▇█▇█▇█████████
wandb: train_loss █▅▃▄▃▄▂▃▂▂▂▂▂▂▂▁▁▂▁▁▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 858
wandb:  train_acc 1
wandb: train_loss 0.02982
wandb: 
wandb: 🚀 View run loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.35_Multimodal_iterations_20250118_141607 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/dmnar3jj
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_141608-dmnar3jj/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_142351-zltb4z6y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.35_Multimodal_epochs_20250118_142351
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/zltb4z6y
wandb: uploading summary; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▃▅▆█
wandb:  train_acc ▁▅▆▇█
wandb: train_loss █▄▂▂▁
wandb:    val_acc ▁█▇▇█
wandb:   val_loss █▁▂▁▂
wandb: 
wandb: Run summary:
wandb:      epoch 5
wandb:  train_acc 0.99192
wandb: train_loss 0.03945
wandb:    val_acc 0.7225
wandb:   val_loss 0.70793
wandb: 
wandb: 🚀 View run loss_focal_alpha0.9_beta0.09999999999999998_weight1.0_dropout0.35_Multimodal_epochs_20250118_142351 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/zltb4z6y
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_142351-zltb4z6y/logs

