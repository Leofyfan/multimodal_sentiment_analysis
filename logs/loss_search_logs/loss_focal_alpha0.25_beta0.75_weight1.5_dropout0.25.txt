=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 1.5 --dropout 0.25 --name loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.25 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.25
text_dim: 128
image_dim: 256
dropout: 0.25
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6964, log_difficulty=0.5285, weight=3.6426
neutral: count=7.0, difficulty=0.6997, log_difficulty=0.5304, weight=3.6521
negative: count=13.0, difficulty=0.6735, log_difficulty=0.5149, weight=3.5746

当前batch的pt分布：
positive: min=0.1723, max=0.5005, mean=0.3036
neutral: min=0.1949, max=0.3834, mean=0.3003
negative: min=0.2275, max=0.4447, mean=0.3265

当前batch准确率：
整体准确率: 0.1562
positive 准确率: 0.1667
neutral 准确率: 0.1429
negative 准确率: 0.1538

损失分量：
基础交叉熵: 1.2008
焦点损失: 0.4298
边界损失: 0.7658
总损失: 0.9634
Epoch 1 [1/172] - loss: 0.9634, acc: 0.1562
Epoch 1 [2/172] - loss: 0.9558
Epoch 1 [3/172] - loss: 0.9381
Epoch 1 [4/172] - loss: 0.9638
Epoch 1 [5/172] - loss: 0.9893
Epoch 1 [6/172] - loss: 1.1116
Epoch 1 [7/172] - loss: 0.8827
Epoch 1 [8/172] - loss: 0.8512
Epoch 1 [9/172] - loss: 0.9863
Epoch 1 [10/172] - loss: 0.7724, acc: 0.5938
Epoch 1 [11/172] - loss: 1.0581
Epoch 1 [12/172] - loss: 0.8854
Epoch 1 [13/172] - loss: 0.8812
Epoch 1 [14/172] - loss: 0.8545
Epoch 1 [15/172] - loss: 0.9074
Epoch 1 [16/172] - loss: 0.8583
Epoch 1 [17/172] - loss: 0.8130
Epoch 1 [18/172] - loss: 0.9390
Epoch 1 [19/172] - loss: 0.7407
Epoch 1 [20/172] - loss: 0.9216, acc: 0.3438
Epoch 1 [21/172] - loss: 0.9433
Epoch 1 [22/172] - loss: 0.8044
Epoch 1 [23/172] - loss: 0.8641
Epoch 1 [24/172] - loss: 0.8307
Epoch 1 [25/172] - loss: 0.7769
Epoch 1 [26/172] - loss: 0.8752
Epoch 1 [27/172] - loss: 0.7917
Epoch 1 [28/172] - loss: 0.7606
Epoch 1 [29/172] - loss: 0.9755
Epoch 1 [30/172] - loss: 0.7883, acc: 0.4062
Epoch 1 [31/172] - loss: 0.8784
Epoch 1 [32/172] - loss: 0.7052
Epoch 1 [33/172] - loss: 0.7471
Epoch 1 [34/172] - loss: 0.6524
Epoch 1 [35/172] - loss: 0.8289
Epoch 1 [36/172] - loss: 0.6068
Epoch 1 [37/172] - loss: 0.6888
Epoch 1 [38/172] - loss: 0.6842
Epoch 1 [39/172] - loss: 0.5227
Epoch 1 [40/172] - loss: 0.7169, acc: 0.6250
Epoch 1 [41/172] - loss: 0.5602
Epoch 1 [42/172] - loss: 0.5383
Epoch 1 [43/172] - loss: 0.7302
Epoch 1 [44/172] - loss: 0.9636
Epoch 1 [45/172] - loss: 0.9459
Epoch 1 [46/172] - loss: 0.6047
Epoch 1 [47/172] - loss: 0.5896
Epoch 1 [48/172] - loss: 0.5429
Epoch 1 [49/172] - loss: 0.7368
Epoch 1 [50/172] - loss: 0.6185, acc: 0.5625
Epoch 1 [51/172] - loss: 0.7788
Epoch 1 [52/172] - loss: 0.6148
Epoch 1 [53/172] - loss: 0.6251
Epoch 1 [54/172] - loss: 0.8003
Epoch 1 [55/172] - loss: 0.5212
Epoch 1 [56/172] - loss: 0.4672
Epoch 1 [57/172] - loss: 0.8545
Epoch 1 [58/172] - loss: 0.5922
Epoch 1 [59/172] - loss: 0.7203
Epoch 1 [60/172] - loss: 0.5263, acc: 0.6875
Epoch 1 [61/172] - loss: 0.6310
Epoch 1 [62/172] - loss: 0.5384
Epoch 1 [63/172] - loss: 0.6011
Epoch 1 [64/172] - loss: 0.4714
Epoch 1 [65/172] - loss: 0.6248
Epoch 1 [66/172] - loss: 0.6151
Epoch 1 [67/172] - loss: 0.5222
Epoch 1 [68/172] - loss: 0.7520
Epoch 1 [69/172] - loss: 0.6493
Epoch 1 [70/172] - loss: 0.5600, acc: 0.7188
Epoch 1 [71/172] - loss: 0.5058
Epoch 1 [72/172] - loss: 0.4776
Epoch 1 [73/172] - loss: 0.6010
Epoch 1 [74/172] - loss: 0.5728
Epoch 1 [75/172] - loss: 0.4635
Epoch 1 [76/172] - loss: 0.5573
Epoch 1 [77/172] - loss: 0.4994
Epoch 1 [78/172] - loss: 0.7165
Epoch 1 [79/172] - loss: 0.5749
Epoch 1 [80/172] - loss: 0.3871, acc: 0.7812
Epoch 1 [81/172] - loss: 0.5733
Epoch 1 [82/172] - loss: 0.5663
Epoch 1 [83/172] - loss: 0.6168
Epoch 1 [84/172] - loss: 0.5876
Epoch 1 [85/172] - loss: 0.4831
Epoch 1 [86/172] - loss: 0.6766
Epoch 1 [87/172] - loss: 0.6198
Epoch 1 [88/172] - loss: 0.7636
Epoch 1 [89/172] - loss: 0.7572
Epoch 1 [90/172] - loss: 0.5802, acc: 0.6250
Epoch 1 [91/172] - loss: 0.6319
Epoch 1 [92/172] - loss: 0.5236
Epoch 1 [93/172] - loss: 0.5200
Epoch 1 [94/172] - loss: 0.3911
Epoch 1 [95/172] - loss: 0.4662
Epoch 1 [96/172] - loss: 0.5344
Epoch 1 [97/172] - loss: 0.4554
Epoch 1 [98/172] - loss: 0.5131
Epoch 1 [99/172] - loss: 0.6657
Epoch 1 [100/172] - loss: 0.5861, acc: 0.6875

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5567, log_difficulty=0.4426, weight=3.2129
neutral: count=983.0, difficulty=0.5059, log_difficulty=0.4094, weight=3.0469
negative: count=1119.0, difficulty=0.5125, log_difficulty=0.4138, weight=3.0689

当前batch的pt分布：
positive: min=0.1405, max=0.9811, mean=0.4782
neutral: min=0.5922, max=0.9929, mean=0.8218
negative: min=0.1448, max=0.8034, mean=0.4452

当前batch准确率：
整体准确率: 0.5625
positive 准确率: 0.4167
neutral 准确率: 1.0000
negative 准确率: 0.5625

损失分量：
基础交叉熵: 0.8588
焦点损失: 0.3540
边界损失: 0.4221
总损失: 0.5935
Epoch 1 [101/172] - loss: 0.5935
Epoch 1 [102/172] - loss: 0.5174
Epoch 1 [103/172] - loss: 0.5491
Epoch 1 [104/172] - loss: 0.3981
Epoch 1 [105/172] - loss: 0.5747
Epoch 1 [106/172] - loss: 0.5547
Epoch 1 [107/172] - loss: 0.4795
Epoch 1 [108/172] - loss: 0.5962
Epoch 1 [109/172] - loss: 0.4408
Epoch 1 [110/172] - loss: 0.4804, acc: 0.8125
Epoch 1 [111/172] - loss: 0.5695
Epoch 1 [112/172] - loss: 0.4128
Epoch 1 [113/172] - loss: 0.3134
Epoch 1 [114/172] - loss: 0.4360
Epoch 1 [115/172] - loss: 0.4639
Epoch 1 [116/172] - loss: 0.4104
Epoch 1 [117/172] - loss: 0.3912
Epoch 1 [118/172] - loss: 0.3472
Epoch 1 [119/172] - loss: 0.4290
Epoch 1 [120/172] - loss: 0.3178, acc: 0.8125
Epoch 1 [121/172] - loss: 0.3385
Epoch 1 [122/172] - loss: 0.6364
Epoch 1 [123/172] - loss: 0.4404
Epoch 1 [124/172] - loss: 0.3608
Epoch 1 [125/172] - loss: 0.3133
Epoch 1 [126/172] - loss: 0.5963
Epoch 1 [127/172] - loss: 0.4205
Epoch 1 [128/172] - loss: 0.3601
Epoch 1 [129/172] - loss: 0.5208
Epoch 1 [130/172] - loss: 0.3802, acc: 0.7500
Epoch 1 [131/172] - loss: 0.2829
Epoch 1 [132/172] - loss: 0.4088
Epoch 1 [133/172] - loss: 0.3999
Epoch 1 [134/172] - loss: 0.3748
Epoch 1 [135/172] - loss: 0.5240
Epoch 1 [136/172] - loss: 0.3180
Epoch 1 [137/172] - loss: 0.4583
Epoch 1 [138/172] - loss: 0.4486
Epoch 1 [139/172] - loss: 0.2874
Epoch 1 [140/172] - loss: 0.4211, acc: 0.7812
Epoch 1 [141/172] - loss: 0.3676
Epoch 1 [142/172] - loss: 0.4371
Epoch 1 [143/172] - loss: 0.4619
Epoch 1 [144/172] - loss: 0.3709
Epoch 1 [145/172] - loss: 0.3869
Epoch 1 [146/172] - loss: 0.3610
Epoch 1 [147/172] - loss: 0.6635
Epoch 1 [148/172] - loss: 0.3280
Epoch 1 [149/172] - loss: 0.3693
Epoch 1 [150/172] - loss: 0.4627, acc: 0.6562
Epoch 1 [151/172] - loss: 0.4176
Epoch 1 [152/172] - loss: 0.4209
Epoch 1 [153/172] - loss: 0.3309
Epoch 1 [154/172] - loss: 0.3473
Epoch 1 [155/172] - loss: 0.3669
Epoch 1 [156/172] - loss: 0.5401
Epoch 1 [157/172] - loss: 0.4304
Epoch 1 [158/172] - loss: 0.3870
Epoch 1 [159/172] - loss: 0.5649
Epoch 1 [160/172] - loss: 0.4055, acc: 0.7812
Epoch 1 [161/172] - loss: 0.3294
Epoch 1 [162/172] - loss: 0.3843
Epoch 1 [163/172] - loss: 0.3678
Epoch 1 [164/172] - loss: 0.3478
Epoch 1 [165/172] - loss: 0.3243
Epoch 1 [166/172] - loss: 0.3676
Epoch 1 [167/172] - loss: 0.3500
Epoch 1 [168/172] - loss: 0.3900
Epoch 1 [169/172] - loss: 0.3540
Epoch 1 [170/172] - loss: 0.3276, acc: 0.8438
Epoch 1 [171/172] - loss: 0.2377
Epoch 1 [172/172] - loss: 0.4394

类别准确率:
positive: 0.6574 (307/467)
neutral: 0.5542 (46/83)
negative: 0.7640 (191/250)

Epoch 1/10
Train Loss: 0.3755, Train Acc: 0.7919
Val Loss: 0.7402, Val Acc: 0.6800
Epoch 2 [1/172] - loss: 0.3014, acc: 0.8438
Epoch 2 [2/172] - loss: 0.2757
Epoch 2 [3/172] - loss: 0.2582
Epoch 2 [4/172] - loss: 0.3611
Epoch 2 [5/172] - loss: 0.4137
Epoch 2 [6/172] - loss: 0.3036
Epoch 2 [7/172] - loss: 0.3028
Epoch 2 [8/172] - loss: 0.3363
Epoch 2 [9/172] - loss: 0.2767
Epoch 2 [10/172] - loss: 0.2980, acc: 0.9062
Epoch 2 [11/172] - loss: 0.2440
Epoch 2 [12/172] - loss: 0.2610
Epoch 2 [13/172] - loss: 0.4253
Epoch 2 [14/172] - loss: 0.3075
Epoch 2 [15/172] - loss: 0.3537
Epoch 2 [16/172] - loss: 0.2967
Epoch 2 [17/172] - loss: 0.3952
Epoch 2 [18/172] - loss: 0.4000
Epoch 2 [19/172] - loss: 0.2363
Epoch 2 [20/172] - loss: 0.2248, acc: 0.9062
Epoch 2 [21/172] - loss: 0.2775
Epoch 2 [22/172] - loss: 0.2049
Epoch 2 [23/172] - loss: 0.2120
Epoch 2 [24/172] - loss: 0.3528
Epoch 2 [25/172] - loss: 0.2666
Epoch 2 [26/172] - loss: 0.2325
Epoch 2 [27/172] - loss: 0.2462
Epoch 2 [28/172] - loss: 0.2533

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4575, log_difficulty=0.3767, weight=2.8836
neutral: count=1952.0, difficulty=0.3710, log_difficulty=0.3155, weight=2.5777
negative: count=2216.0, difficulty=0.4232, log_difficulty=0.3529, weight=2.7647

当前batch的pt分布：
positive: min=0.3547, max=0.9678, mean=0.7455
neutral: min=0.3178, max=0.9911, mean=0.8019
negative: min=0.0259, max=0.9617, mean=0.7219

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.8889
neutral 准确率: 0.9091
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.3945
焦点损失: 0.1521
边界损失: 0.2627
总损失: 0.3018
Epoch 2 [29/172] - loss: 0.3018
Epoch 2 [30/172] - loss: 0.2658, acc: 0.9375
Epoch 2 [31/172] - loss: 0.2476
Epoch 2 [32/172] - loss: 0.1793
Epoch 2 [33/172] - loss: 0.2888
Epoch 2 [34/172] - loss: 0.2764
Epoch 2 [35/172] - loss: 0.2207
Epoch 2 [36/172] - loss: 0.3241
Epoch 2 [37/172] - loss: 0.2214
Epoch 2 [38/172] - loss: 0.2063
Epoch 2 [39/172] - loss: 0.3151
Epoch 2 [40/172] - loss: 0.3163, acc: 0.7812
Epoch 2 [41/172] - loss: 0.2879
Epoch 2 [42/172] - loss: 0.1849
Epoch 2 [43/172] - loss: 0.1592
Epoch 2 [44/172] - loss: 0.4252
Epoch 2 [45/172] - loss: 0.1765
Epoch 2 [46/172] - loss: 0.1773
Epoch 2 [47/172] - loss: 0.2947
Epoch 2 [48/172] - loss: 0.2262
Epoch 2 [49/172] - loss: 0.2455
Epoch 2 [50/172] - loss: 0.2732, acc: 0.8438
Epoch 2 [51/172] - loss: 0.3042
Epoch 2 [52/172] - loss: 0.1887
Epoch 2 [53/172] - loss: 0.2089
Epoch 2 [54/172] - loss: 0.1804
Epoch 2 [55/172] - loss: 0.2559
Epoch 2 [56/172] - loss: 0.2365
Epoch 2 [57/172] - loss: 0.2165
Epoch 2 [58/172] - loss: 0.2440
Epoch 2 [59/172] - loss: 0.3430
Epoch 2 [60/172] - loss: 0.2704, acc: 0.8750
Epoch 2 [61/172] - loss: 0.2309
Epoch 2 [62/172] - loss: 0.1765
Epoch 2 [63/172] - loss: 0.2135
Epoch 2 [64/172] - loss: 0.1978
Epoch 2 [65/172] - loss: 0.2816
Epoch 2 [66/172] - loss: 0.2640
Epoch 2 [67/172] - loss: 0.1817
Epoch 2 [68/172] - loss: 0.2843
Epoch 2 [69/172] - loss: 0.1886
Epoch 2 [70/172] - loss: 0.2448, acc: 0.8750
Epoch 2 [71/172] - loss: 0.2331
Epoch 2 [72/172] - loss: 0.2566
Epoch 2 [73/172] - loss: 0.2755
Epoch 2 [74/172] - loss: 0.2785
Epoch 2 [75/172] - loss: 0.2498
Epoch 2 [76/172] - loss: 0.2776
Epoch 2 [77/172] - loss: 0.3542
Epoch 2 [78/172] - loss: 0.3021
Epoch 2 [79/172] - loss: 0.2760
Epoch 2 [80/172] - loss: 0.1709, acc: 0.9375
Epoch 2 [81/172] - loss: 0.2409
Epoch 2 [82/172] - loss: 0.1640
Epoch 2 [83/172] - loss: 0.1943
Epoch 2 [84/172] - loss: 0.2526
Epoch 2 [85/172] - loss: 0.2152
Epoch 2 [86/172] - loss: 0.1980
Epoch 2 [87/172] - loss: 0.4611
Epoch 2 [88/172] - loss: 0.2321
Epoch 2 [89/172] - loss: 0.1905
Epoch 2 [90/172] - loss: 0.2825, acc: 0.7812
Epoch 2 [91/172] - loss: 0.1787
Epoch 2 [92/172] - loss: 0.3769
Epoch 2 [93/172] - loss: 0.2455
Epoch 2 [94/172] - loss: 0.2245
Epoch 2 [95/172] - loss: 0.2484
Epoch 2 [96/172] - loss: 0.1679
Epoch 2 [97/172] - loss: 0.2520
Epoch 2 [98/172] - loss: 0.1826
Epoch 2 [99/172] - loss: 0.1496
Epoch 2 [100/172] - loss: 0.2714, acc: 0.8438
Epoch 2 [101/172] - loss: 0.2203
Epoch 2 [102/172] - loss: 0.1945
Epoch 2 [103/172] - loss: 0.2877
Epoch 2 [104/172] - loss: 0.2677
Epoch 2 [105/172] - loss: 0.2218
Epoch 2 [106/172] - loss: 0.1844
Epoch 2 [107/172] - loss: 0.2047
Epoch 2 [108/172] - loss: 0.2539
Epoch 2 [109/172] - loss: 0.2649
Epoch 2 [110/172] - loss: 0.2215, acc: 0.8750
Epoch 2 [111/172] - loss: 0.1979
Epoch 2 [112/172] - loss: 0.1449
Epoch 2 [113/172] - loss: 0.1520
Epoch 2 [114/172] - loss: 0.2112
Epoch 2 [115/172] - loss: 0.2349
Epoch 2 [116/172] - loss: 0.2561
Epoch 2 [117/172] - loss: 0.4461
Epoch 2 [118/172] - loss: 0.1962
Epoch 2 [119/172] - loss: 0.1672
Epoch 2 [120/172] - loss: 0.1616, acc: 0.9375
Epoch 2 [121/172] - loss: 0.2594
Epoch 2 [122/172] - loss: 0.3177
Epoch 2 [123/172] - loss: 0.1841
Epoch 2 [124/172] - loss: 0.2086
Epoch 2 [125/172] - loss: 0.1588
Epoch 2 [126/172] - loss: 0.1898
Epoch 2 [127/172] - loss: 0.3319
Epoch 2 [128/172] - loss: 0.2189

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3813, log_difficulty=0.3230, weight=2.6151
neutral: count=2949.0, difficulty=0.2806, log_difficulty=0.2473, weight=2.2367
negative: count=3294.0, difficulty=0.3568, log_difficulty=0.3051, weight=2.5256

当前batch的pt分布：
positive: min=0.5715, max=0.9976, mean=0.8950
neutral: min=0.8421, max=0.9936, mean=0.9527
negative: min=0.0256, max=0.9899, mean=0.7688

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.2581
焦点损失: 0.1550
边界损失: 0.1794
总损失: 0.2325
Epoch 2 [129/172] - loss: 0.2325
Epoch 2 [130/172] - loss: 0.2408, acc: 0.8750
Epoch 2 [131/172] - loss: 0.1994
Epoch 2 [132/172] - loss: 0.1777
Epoch 2 [133/172] - loss: 0.2093
Epoch 2 [134/172] - loss: 0.2600
Epoch 2 [135/172] - loss: 0.2358
Epoch 2 [136/172] - loss: 0.2165
Epoch 2 [137/172] - loss: 0.1520
Epoch 2 [138/172] - loss: 0.2308
Epoch 2 [139/172] - loss: 0.1662
Epoch 2 [140/172] - loss: 0.2930, acc: 0.8125
Epoch 2 [141/172] - loss: 0.2209
Epoch 2 [142/172] - loss: 0.2407
Epoch 2 [143/172] - loss: 0.2254
Epoch 2 [144/172] - loss: 0.1729
Epoch 2 [145/172] - loss: 0.4466
Epoch 2 [146/172] - loss: 0.1842
Epoch 2 [147/172] - loss: 0.2453
Epoch 2 [148/172] - loss: 0.2222
Epoch 2 [149/172] - loss: 0.2509
Epoch 2 [150/172] - loss: 0.1494, acc: 1.0000
Epoch 2 [151/172] - loss: 0.2203
Epoch 2 [152/172] - loss: 0.1923
Epoch 2 [153/172] - loss: 0.2359
Epoch 2 [154/172] - loss: 0.1730
Epoch 2 [155/172] - loss: 0.2091
Epoch 2 [156/172] - loss: 0.2034
Epoch 2 [157/172] - loss: 0.1427
Epoch 2 [158/172] - loss: 0.2071
Epoch 2 [159/172] - loss: 0.1782
Epoch 2 [160/172] - loss: 0.1854, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1691
Epoch 2 [162/172] - loss: 0.1629
Epoch 2 [163/172] - loss: 0.2649
Epoch 2 [164/172] - loss: 0.1999
Epoch 2 [165/172] - loss: 0.2132
Epoch 2 [166/172] - loss: 0.3273
Epoch 2 [167/172] - loss: 0.2772
Epoch 2 [168/172] - loss: 0.1716
Epoch 2 [169/172] - loss: 0.1780
Epoch 2 [170/172] - loss: 0.2257, acc: 0.8750
Epoch 2 [171/172] - loss: 0.2915
Epoch 2 [172/172] - loss: 0.5516

类别准确率:
positive: 0.8308 (388/467)
neutral: 0.3133 (26/83)
negative: 0.6720 (168/250)

Epoch 2/10
Train Loss: 0.2342, Train Acc: 0.9253
Val Loss: 0.7222, Val Acc: 0.7275
Epoch 3 [1/172] - loss: 0.1408, acc: 1.0000
Epoch 3 [2/172] - loss: 0.1503
Epoch 3 [3/172] - loss: 0.1350
Epoch 3 [4/172] - loss: 0.1638
Epoch 3 [5/172] - loss: 0.1835
Epoch 3 [6/172] - loss: 0.1505
Epoch 3 [7/172] - loss: 0.1492
Epoch 3 [8/172] - loss: 0.1701
Epoch 3 [9/172] - loss: 0.1828
Epoch 3 [10/172] - loss: 0.1649, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1870
Epoch 3 [12/172] - loss: 0.1306
Epoch 3 [13/172] - loss: 0.1312
Epoch 3 [14/172] - loss: 0.1246
Epoch 3 [15/172] - loss: 0.1444
Epoch 3 [16/172] - loss: 0.2289
Epoch 3 [17/172] - loss: 0.1902
Epoch 3 [18/172] - loss: 0.1762
Epoch 3 [19/172] - loss: 0.1339
Epoch 3 [20/172] - loss: 0.1411, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1523
Epoch 3 [22/172] - loss: 0.1910
Epoch 3 [23/172] - loss: 0.1369
Epoch 3 [24/172] - loss: 0.1381
Epoch 3 [25/172] - loss: 0.1533
Epoch 3 [26/172] - loss: 0.1290
Epoch 3 [27/172] - loss: 0.1652
Epoch 3 [28/172] - loss: 0.1484
Epoch 3 [29/172] - loss: 0.1708
Epoch 3 [30/172] - loss: 0.2181, acc: 0.9062
Epoch 3 [31/172] - loss: 0.1510
Epoch 3 [32/172] - loss: 0.1497
Epoch 3 [33/172] - loss: 0.1617
Epoch 3 [34/172] - loss: 0.1704
Epoch 3 [35/172] - loss: 0.2343
Epoch 3 [36/172] - loss: 0.1366
Epoch 3 [37/172] - loss: 0.1960
Epoch 3 [38/172] - loss: 0.1186
Epoch 3 [39/172] - loss: 0.1376
Epoch 3 [40/172] - loss: 0.1601, acc: 1.0000
Epoch 3 [41/172] - loss: 0.1429
Epoch 3 [42/172] - loss: 0.1458
Epoch 3 [43/172] - loss: 0.1533
Epoch 3 [44/172] - loss: 0.1167
Epoch 3 [45/172] - loss: 0.1682
Epoch 3 [46/172] - loss: 0.1404
Epoch 3 [47/172] - loss: 0.1221
Epoch 3 [48/172] - loss: 0.1429
Epoch 3 [49/172] - loss: 0.1352
Epoch 3 [50/172] - loss: 0.1274, acc: 1.0000
Epoch 3 [51/172] - loss: 0.1679
Epoch 3 [52/172] - loss: 0.2094
Epoch 3 [53/172] - loss: 0.1445
Epoch 3 [54/172] - loss: 0.1635
Epoch 3 [55/172] - loss: 0.1350
Epoch 3 [56/172] - loss: 0.1286

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3204, log_difficulty=0.2779, weight=2.3896
neutral: count=3923.0, difficulty=0.2313, log_difficulty=0.2080, weight=2.0402
negative: count=4382.0, difficulty=0.3014, log_difficulty=0.2634, weight=2.3171

当前batch的pt分布：
positive: min=0.3080, max=0.9970, mean=0.8855
neutral: min=0.0041, max=0.9899, mean=0.8179
negative: min=0.9847, max=0.9981, mean=0.9944

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9091
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2991
焦点损失: 0.1921
边界损失: 0.1873
总损失: 0.2399
Epoch 3 [57/172] - loss: 0.2399
Epoch 3 [58/172] - loss: 0.1225
Epoch 3 [59/172] - loss: 0.1332
Epoch 3 [60/172] - loss: 0.1392, acc: 1.0000
Epoch 3 [61/172] - loss: 0.1296
Epoch 3 [62/172] - loss: 0.1340
Epoch 3 [63/172] - loss: 0.1380
Epoch 3 [64/172] - loss: 0.1732
Epoch 3 [65/172] - loss: 0.1274
Epoch 3 [66/172] - loss: 0.1827
Epoch 3 [67/172] - loss: 0.1584
Epoch 3 [68/172] - loss: 0.1232
Epoch 3 [69/172] - loss: 0.1843
Epoch 3 [70/172] - loss: 0.1149, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1296
Epoch 3 [72/172] - loss: 0.2119
Epoch 3 [73/172] - loss: 0.1207
Epoch 3 [74/172] - loss: 0.1443
Epoch 3 [75/172] - loss: 0.1476
Epoch 3 [76/172] - loss: 0.1274
Epoch 3 [77/172] - loss: 0.2058
Epoch 3 [78/172] - loss: 0.3112
Epoch 3 [79/172] - loss: 0.1248
Epoch 3 [80/172] - loss: 0.2266, acc: 0.9375
Epoch 3 [81/172] - loss: 0.1251
Epoch 3 [82/172] - loss: 0.1751
Epoch 3 [83/172] - loss: 0.1391
Epoch 3 [84/172] - loss: 0.1331
Epoch 3 [85/172] - loss: 0.1526
Epoch 3 [86/172] - loss: 0.1211
Epoch 3 [87/172] - loss: 0.2215
Epoch 3 [88/172] - loss: 0.1478
Epoch 3 [89/172] - loss: 0.1128
Epoch 3 [90/172] - loss: 0.1241, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1589
Epoch 3 [92/172] - loss: 0.1489
Epoch 3 [93/172] - loss: 0.1957
Epoch 3 [94/172] - loss: 0.1417
Epoch 3 [95/172] - loss: 0.1271
Epoch 3 [96/172] - loss: 0.1385
Epoch 3 [97/172] - loss: 0.1300
Epoch 3 [98/172] - loss: 0.1235
Epoch 3 [99/172] - loss: 0.1262
Epoch 3 [100/172] - loss: 0.1711, acc: 0.9375
Epoch 3 [101/172] - loss: 0.1577
Epoch 3 [102/172] - loss: 0.1253
Epoch 3 [103/172] - loss: 0.1904
Epoch 3 [104/172] - loss: 0.1392
Epoch 3 [105/172] - loss: 0.1233
Epoch 3 [106/172] - loss: 0.1394
Epoch 3 [107/172] - loss: 0.1271
Epoch 3 [108/172] - loss: 0.1342
Epoch 3 [109/172] - loss: 0.1117
Epoch 3 [110/172] - loss: 0.1711, acc: 0.9688
Epoch 3 [111/172] - loss: 0.1991
Epoch 3 [112/172] - loss: 0.1275
Epoch 3 [113/172] - loss: 0.1197
Epoch 3 [114/172] - loss: 0.1170
Epoch 3 [115/172] - loss: 0.1455
Epoch 3 [116/172] - loss: 0.1160
Epoch 3 [117/172] - loss: 0.1373
Epoch 3 [118/172] - loss: 0.1240
Epoch 3 [119/172] - loss: 0.1187
Epoch 3 [120/172] - loss: 0.1906, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1642
Epoch 3 [122/172] - loss: 0.1438
Epoch 3 [123/172] - loss: 0.1563
Epoch 3 [124/172] - loss: 0.1454
Epoch 3 [125/172] - loss: 0.1641
Epoch 3 [126/172] - loss: 0.2798
Epoch 3 [127/172] - loss: 0.1967
Epoch 3 [128/172] - loss: 0.1110
Epoch 3 [129/172] - loss: 0.1232
Epoch 3 [130/172] - loss: 0.1398, acc: 0.9375
Epoch 3 [131/172] - loss: 0.1653
Epoch 3 [132/172] - loss: 0.1145
Epoch 3 [133/172] - loss: 0.1195
Epoch 3 [134/172] - loss: 0.1137
Epoch 3 [135/172] - loss: 0.1543
Epoch 3 [136/172] - loss: 0.1336
Epoch 3 [137/172] - loss: 0.1259
Epoch 3 [138/172] - loss: 0.1462
Epoch 3 [139/172] - loss: 0.1867
Epoch 3 [140/172] - loss: 0.1351, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1679
Epoch 3 [142/172] - loss: 0.2641
Epoch 3 [143/172] - loss: 0.1282
Epoch 3 [144/172] - loss: 0.2305
Epoch 3 [145/172] - loss: 0.1324
Epoch 3 [146/172] - loss: 0.1513
Epoch 3 [147/172] - loss: 0.1556
Epoch 3 [148/172] - loss: 0.1641
Epoch 3 [149/172] - loss: 0.1375
Epoch 3 [150/172] - loss: 0.1736, acc: 0.9688
Epoch 3 [151/172] - loss: 0.2037
Epoch 3 [152/172] - loss: 0.1960
Epoch 3 [153/172] - loss: 0.1354
Epoch 3 [154/172] - loss: 0.2072
Epoch 3 [155/172] - loss: 0.1156
Epoch 3 [156/172] - loss: 0.1244

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2737, log_difficulty=0.2419, weight=2.2094
neutral: count=4903.0, difficulty=0.1951, log_difficulty=0.1782, weight=1.8911
negative: count=5500.0, difficulty=0.2582, log_difficulty=0.2297, weight=2.1485

当前batch的pt分布：
positive: min=0.5964, max=0.9993, mean=0.9166
neutral: min=0.9431, max=0.9972, mean=0.9757
negative: min=0.7597, max=0.9942, mean=0.9471

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0602
焦点损失: 0.0031
边界损失: 0.1648
总损失: 0.1252
Epoch 3 [157/172] - loss: 0.1252
Epoch 3 [158/172] - loss: 0.1558
Epoch 3 [159/172] - loss: 0.1223
Epoch 3 [160/172] - loss: 0.2469, acc: 0.8750
Epoch 3 [161/172] - loss: 0.1983
Epoch 3 [162/172] - loss: 0.1292
Epoch 3 [163/172] - loss: 0.1227
Epoch 3 [164/172] - loss: 0.1093
Epoch 3 [165/172] - loss: 0.1425
Epoch 3 [166/172] - loss: 0.1250
Epoch 3 [167/172] - loss: 0.1715
Epoch 3 [168/172] - loss: 0.1227
Epoch 3 [169/172] - loss: 0.1146
Epoch 3 [170/172] - loss: 0.2174, acc: 0.9062
Epoch 3 [171/172] - loss: 0.1163
Epoch 3 [172/172] - loss: 0.1313

类别准确率:
positive: 0.8887 (415/467)
neutral: 0.2530 (21/83)
negative: 0.6560 (164/250)

Epoch 3/10
Train Loss: 0.1469, Train Acc: 0.9737
Val Loss: 0.8287, Val Acc: 0.7500
Epoch 4 [1/172] - loss: 0.1164, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1128
Epoch 4 [3/172] - loss: 0.1335
Epoch 4 [4/172] - loss: 0.1185
Epoch 4 [5/172] - loss: 0.1337
Epoch 4 [6/172] - loss: 0.1110
Epoch 4 [7/172] - loss: 0.1134
Epoch 4 [8/172] - loss: 0.1084
Epoch 4 [9/172] - loss: 0.1636
Epoch 4 [10/172] - loss: 0.1179, acc: 1.0000
Epoch 4 [11/172] - loss: 0.1096
Epoch 4 [12/172] - loss: 0.1181
Epoch 4 [13/172] - loss: 0.1621
Epoch 4 [14/172] - loss: 0.1141
Epoch 4 [15/172] - loss: 0.1148
Epoch 4 [16/172] - loss: 0.1230
Epoch 4 [17/172] - loss: 0.1282
Epoch 4 [18/172] - loss: 0.1228
Epoch 4 [19/172] - loss: 0.1467
Epoch 4 [20/172] - loss: 0.1191, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1776
Epoch 4 [22/172] - loss: 0.1105
Epoch 4 [23/172] - loss: 0.1430
Epoch 4 [24/172] - loss: 0.1079
Epoch 4 [25/172] - loss: 0.1100
Epoch 4 [26/172] - loss: 0.2142
Epoch 4 [27/172] - loss: 0.1070
Epoch 4 [28/172] - loss: 0.1384
Epoch 4 [29/172] - loss: 0.1096
Epoch 4 [30/172] - loss: 0.1870, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1322
Epoch 4 [32/172] - loss: 0.1093
Epoch 4 [33/172] - loss: 0.1170
Epoch 4 [34/172] - loss: 0.1292
Epoch 4 [35/172] - loss: 0.1262
Epoch 4 [36/172] - loss: 0.1226
Epoch 4 [37/172] - loss: 0.1090
Epoch 4 [38/172] - loss: 0.1225
Epoch 4 [39/172] - loss: 0.1469
Epoch 4 [40/172] - loss: 0.1587, acc: 0.9375
Epoch 4 [41/172] - loss: 0.1130
Epoch 4 [42/172] - loss: 0.1316
Epoch 4 [43/172] - loss: 0.1280
Epoch 4 [44/172] - loss: 0.1396
Epoch 4 [45/172] - loss: 0.1108
Epoch 4 [46/172] - loss: 0.1097
Epoch 4 [47/172] - loss: 0.1262
Epoch 4 [48/172] - loss: 0.1369
Epoch 4 [49/172] - loss: 0.1355
Epoch 4 [50/172] - loss: 0.1237, acc: 0.9688
Epoch 4 [51/172] - loss: 0.1080
Epoch 4 [52/172] - loss: 0.1739
Epoch 4 [53/172] - loss: 0.1081
Epoch 4 [54/172] - loss: 0.1291
Epoch 4 [55/172] - loss: 0.1903
Epoch 4 [56/172] - loss: 0.1141
Epoch 4 [57/172] - loss: 0.1139
Epoch 4 [58/172] - loss: 0.1345
Epoch 4 [59/172] - loss: 0.1099
Epoch 4 [60/172] - loss: 0.1309, acc: 0.9688
Epoch 4 [61/172] - loss: 0.1455
Epoch 4 [62/172] - loss: 0.1310
Epoch 4 [63/172] - loss: 0.1195
Epoch 4 [64/172] - loss: 0.1180
Epoch 4 [65/172] - loss: 0.1570
Epoch 4 [66/172] - loss: 0.1084
Epoch 4 [67/172] - loss: 0.1262
Epoch 4 [68/172] - loss: 0.1345
Epoch 4 [69/172] - loss: 0.1173
Epoch 4 [70/172] - loss: 0.1146, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1099
Epoch 4 [72/172] - loss: 0.1149
Epoch 4 [73/172] - loss: 0.1099
Epoch 4 [74/172] - loss: 0.2213
Epoch 4 [75/172] - loss: 0.1305
Epoch 4 [76/172] - loss: 0.1089
Epoch 4 [77/172] - loss: 0.1251
Epoch 4 [78/172] - loss: 0.1590
Epoch 4 [79/172] - loss: 0.1132
Epoch 4 [80/172] - loss: 0.1106, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1683
Epoch 4 [82/172] - loss: 0.1146
Epoch 4 [83/172] - loss: 0.1247
Epoch 4 [84/172] - loss: 0.1166

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2380, log_difficulty=0.2135, weight=2.0673
neutral: count=5865.0, difficulty=0.1695, log_difficulty=0.1566, weight=1.7830
negative: count=6629.0, difficulty=0.2240, log_difficulty=0.2021, weight=2.0106

当前batch的pt分布：
positive: min=0.3605, max=0.9948, mean=0.8981
neutral: min=0.9501, max=0.9999, mean=0.9898
negative: min=0.9648, max=0.9984, mean=0.9880

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0715
焦点损失: 0.0133
边界损失: 0.1611
总损失: 0.1277
Epoch 4 [85/172] - loss: 0.1277
Epoch 4 [86/172] - loss: 0.1534
Epoch 4 [87/172] - loss: 0.1236
Epoch 4 [88/172] - loss: 0.1081
Epoch 4 [89/172] - loss: 0.1153
Epoch 4 [90/172] - loss: 0.1100, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1630
Epoch 4 [92/172] - loss: 0.1988
Epoch 4 [93/172] - loss: 0.1094
Epoch 4 [94/172] - loss: 0.1071
Epoch 4 [95/172] - loss: 0.1236
Epoch 4 [96/172] - loss: 0.1156
Epoch 4 [97/172] - loss: 0.1221
Epoch 4 [98/172] - loss: 0.1120
Epoch 4 [99/172] - loss: 0.1129
Epoch 4 [100/172] - loss: 0.1734, acc: 0.9375
Epoch 4 [101/172] - loss: 0.1609
Epoch 4 [102/172] - loss: 0.1356
Epoch 4 [103/172] - loss: 0.1318
Epoch 4 [104/172] - loss: 0.1120
Epoch 4 [105/172] - loss: 0.1575
Epoch 4 [106/172] - loss: 0.1160
Epoch 4 [107/172] - loss: 0.1083
Epoch 4 [108/172] - loss: 0.1308
Epoch 4 [109/172] - loss: 0.1264
Epoch 4 [110/172] - loss: 0.2268, acc: 0.9062
Epoch 4 [111/172] - loss: 0.1064
Epoch 4 [112/172] - loss: 0.1073
Epoch 4 [113/172] - loss: 0.1115
Epoch 4 [114/172] - loss: 0.1365
Epoch 4 [115/172] - loss: 0.1253
Epoch 4 [116/172] - loss: 0.1333
Epoch 4 [117/172] - loss: 0.1132
Epoch 4 [118/172] - loss: 0.1748
Epoch 4 [119/172] - loss: 0.1178
Epoch 4 [120/172] - loss: 0.1185, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1255
Epoch 4 [122/172] - loss: 0.1519
Epoch 4 [123/172] - loss: 0.1131
Epoch 4 [124/172] - loss: 0.1192
Epoch 4 [125/172] - loss: 0.1281
Epoch 4 [126/172] - loss: 0.1908
Epoch 4 [127/172] - loss: 0.1514
Epoch 4 [128/172] - loss: 0.1402
Epoch 4 [129/172] - loss: 0.1842
Epoch 4 [130/172] - loss: 0.1092, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1076
Epoch 4 [132/172] - loss: 0.1102
Epoch 4 [133/172] - loss: 0.1211
Epoch 4 [134/172] - loss: 0.1228
Epoch 4 [135/172] - loss: 0.1263
Epoch 4 [136/172] - loss: 0.1415
Epoch 4 [137/172] - loss: 0.1136
Epoch 4 [138/172] - loss: 0.1092
Epoch 4 [139/172] - loss: 0.1158
Epoch 4 [140/172] - loss: 0.1314, acc: 0.9375
Epoch 4 [141/172] - loss: 0.1368
Epoch 4 [142/172] - loss: 0.1362
Epoch 4 [143/172] - loss: 0.1125
Epoch 4 [144/172] - loss: 0.1151
Epoch 4 [145/172] - loss: 0.1495
Epoch 4 [146/172] - loss: 0.1510
Epoch 4 [147/172] - loss: 0.1148
Epoch 4 [148/172] - loss: 0.1222
Epoch 4 [149/172] - loss: 0.1130
Epoch 4 [150/172] - loss: 0.1215, acc: 1.0000
Epoch 4 [151/172] - loss: 0.2140
Epoch 4 [152/172] - loss: 0.1099
Epoch 4 [153/172] - loss: 0.1087
Epoch 4 [154/172] - loss: 0.1426
Epoch 4 [155/172] - loss: 0.1310
Epoch 4 [156/172] - loss: 0.1143
Epoch 4 [157/172] - loss: 0.2262
Epoch 4 [158/172] - loss: 0.1114
Epoch 4 [159/172] - loss: 0.1074
Epoch 4 [160/172] - loss: 0.1113, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1321
Epoch 4 [162/172] - loss: 0.1152
Epoch 4 [163/172] - loss: 0.1352
Epoch 4 [164/172] - loss: 0.1509
Epoch 4 [165/172] - loss: 0.1740
Epoch 4 [166/172] - loss: 0.1312
Epoch 4 [167/172] - loss: 0.1646
Epoch 4 [168/172] - loss: 0.1192
Epoch 4 [169/172] - loss: 0.1663
Epoch 4 [170/172] - loss: 0.1958, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1211
Epoch 4 [172/172] - loss: 0.1094

类别准确率:
positive: 0.8844 (413/467)
neutral: 0.2771 (23/83)
negative: 0.5440 (136/250)

Epoch 4/10
Train Loss: 0.1420, Train Acc: 0.9758
Val Loss: 0.8805, Val Acc: 0.7150
Epoch 5 [1/172] - loss: 0.1100, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1281
Epoch 5 [3/172] - loss: 0.1082
Epoch 5 [4/172] - loss: 0.1164
Epoch 5 [5/172] - loss: 0.1158
Epoch 5 [6/172] - loss: 0.1368
Epoch 5 [7/172] - loss: 0.1142
Epoch 5 [8/172] - loss: 0.1596
Epoch 5 [9/172] - loss: 0.1252
Epoch 5 [10/172] - loss: 0.1107, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1290
Epoch 5 [12/172] - loss: 0.1063

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2122, log_difficulty=0.1924, weight=1.9621
neutral: count=6845.0, difficulty=0.1504, log_difficulty=0.1401, weight=1.7004
negative: count=7694.0, difficulty=0.2002, log_difficulty=0.1825, weight=1.9123

当前batch的pt分布：
positive: min=0.1436, max=0.9984, mean=0.9094
neutral: min=0.9922, max=0.9996, mean=0.9978
negative: min=0.9567, max=0.9994, mean=0.9791

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0817
焦点损失: 0.0440
边界损失: 0.1479
总损失: 0.1325
Epoch 5 [13/172] - loss: 0.1325
Epoch 5 [14/172] - loss: 0.1368
Epoch 5 [15/172] - loss: 0.1095
Epoch 5 [16/172] - loss: 0.1070
Epoch 5 [17/172] - loss: 0.1833
Epoch 5 [18/172] - loss: 0.1136
Epoch 5 [19/172] - loss: 0.1143
Epoch 5 [20/172] - loss: 0.1689, acc: 0.9062
Epoch 5 [21/172] - loss: 0.2001
Epoch 5 [22/172] - loss: 0.1851
Epoch 5 [23/172] - loss: 0.1246
Epoch 5 [24/172] - loss: 0.1254
Epoch 5 [25/172] - loss: 0.1121
Epoch 5 [26/172] - loss: 0.2131
Epoch 5 [27/172] - loss: 0.1109
Epoch 5 [28/172] - loss: 0.1214
Epoch 5 [29/172] - loss: 0.1133
Epoch 5 [30/172] - loss: 0.1133, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1590
Epoch 5 [32/172] - loss: 0.1115
Epoch 5 [33/172] - loss: 0.1174
Epoch 5 [34/172] - loss: 0.1283
Epoch 5 [35/172] - loss: 0.1107
Epoch 5 [36/172] - loss: 0.1308
Epoch 5 [37/172] - loss: 0.1165
Epoch 5 [38/172] - loss: 0.1094
Epoch 5 [39/172] - loss: 0.1585
Epoch 5 [40/172] - loss: 0.1170, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1194
Epoch 5 [42/172] - loss: 0.1111
Epoch 5 [43/172] - loss: 0.1747
Epoch 5 [44/172] - loss: 0.1107
Epoch 5 [45/172] - loss: 0.1075
Epoch 5 [46/172] - loss: 0.1539
Epoch 5 [47/172] - loss: 0.1072
Epoch 5 [48/172] - loss: 0.1242
Epoch 5 [49/172] - loss: 0.1100
Epoch 5 [50/172] - loss: 0.1135, acc: 1.0000
Epoch 5 [51/172] - loss: 0.1142
Epoch 5 [52/172] - loss: 0.1204
Epoch 5 [53/172] - loss: 0.1298
Epoch 5 [54/172] - loss: 0.1185
Epoch 5 [55/172] - loss: 0.1119
Epoch 5 [56/172] - loss: 0.1113
Epoch 5 [57/172] - loss: 0.1119
Epoch 5 [58/172] - loss: 0.1187
Epoch 5 [59/172] - loss: 0.1398
Epoch 5 [60/172] - loss: 0.1077, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1163
Epoch 5 [62/172] - loss: 0.1141
Epoch 5 [63/172] - loss: 0.1411
Epoch 5 [64/172] - loss: 0.1094
Epoch 5 [65/172] - loss: 0.1150
Epoch 5 [66/172] - loss: 0.1103
Epoch 5 [67/172] - loss: 0.1128
Epoch 5 [68/172] - loss: 0.1101
Epoch 5 [69/172] - loss: 0.1118
Epoch 5 [70/172] - loss: 0.1086, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1270
Epoch 5 [72/172] - loss: 0.1106
Epoch 5 [73/172] - loss: 0.1139
Epoch 5 [74/172] - loss: 0.1449
Epoch 5 [75/172] - loss: 0.1067
Epoch 5 [76/172] - loss: 0.1070
Epoch 5 [77/172] - loss: 0.1156
Epoch 5 [78/172] - loss: 0.1299
Epoch 5 [79/172] - loss: 0.1066
Epoch 5 [80/172] - loss: 0.1119, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1340
Epoch 5 [82/172] - loss: 0.1354
Epoch 5 [83/172] - loss: 0.1102
Epoch 5 [84/172] - loss: 0.1094
Epoch 5 [85/172] - loss: 0.1491
Epoch 5 [86/172] - loss: 0.1183
Epoch 5 [87/172] - loss: 0.1173
Epoch 5 [88/172] - loss: 0.1555
Epoch 5 [89/172] - loss: 0.1075
Epoch 5 [90/172] - loss: 0.1129, acc: 1.0000
Epoch 5 [91/172] - loss: 0.1210
Epoch 5 [92/172] - loss: 0.1127
Epoch 5 [93/172] - loss: 0.1093
Epoch 5 [94/172] - loss: 0.1068
Epoch 5 [95/172] - loss: 0.1205
Epoch 5 [96/172] - loss: 0.1126
Epoch 5 [97/172] - loss: 0.1218
Epoch 5 [98/172] - loss: 0.1099
Epoch 5 [99/172] - loss: 0.1925
Epoch 5 [100/172] - loss: 0.1111, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1134
Epoch 5 [102/172] - loss: 0.1104
Epoch 5 [103/172] - loss: 0.1121
Epoch 5 [104/172] - loss: 0.1997
Epoch 5 [105/172] - loss: 0.2725
Epoch 5 [106/172] - loss: 0.1097
Epoch 5 [107/172] - loss: 0.1074
Epoch 5 [108/172] - loss: 0.1515
Epoch 5 [109/172] - loss: 0.1064
Epoch 5 [110/172] - loss: 0.1081, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1144
Epoch 5 [112/172] - loss: 0.1069

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.1904, log_difficulty=0.1743, weight=1.8714
neutral: count=7825.0, difficulty=0.1348, log_difficulty=0.1264, weight=1.6322
negative: count=8780.0, difficulty=0.1814, log_difficulty=0.1667, weight=1.8335

当前batch的pt分布：
positive: min=0.8112, max=0.9961, mean=0.9421
neutral: min=0.8862, max=0.9990, mean=0.9688
negative: min=0.9977, max=0.9999, mean=0.9992

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0418
焦点损失: 0.0005
边界损失: 0.1561
总损失: 0.1173
Epoch 5 [113/172] - loss: 0.1173
Epoch 5 [114/172] - loss: 0.1206
Epoch 5 [115/172] - loss: 0.1130
Epoch 5 [116/172] - loss: 0.1064
Epoch 5 [117/172] - loss: 0.1067
Epoch 5 [118/172] - loss: 0.1091
Epoch 5 [119/172] - loss: 0.1072
Epoch 5 [120/172] - loss: 0.1135, acc: 1.0000
Epoch 5 [121/172] - loss: 0.1841
Epoch 5 [122/172] - loss: 0.1214
Epoch 5 [123/172] - loss: 0.1078
Epoch 5 [124/172] - loss: 0.1139
Epoch 5 [125/172] - loss: 0.1057
Epoch 5 [126/172] - loss: 0.1068
Epoch 5 [127/172] - loss: 0.1109
Epoch 5 [128/172] - loss: 0.1122
Epoch 5 [129/172] - loss: 0.1750
Epoch 5 [130/172] - loss: 0.1083, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1138
Epoch 5 [132/172] - loss: 0.1427
Epoch 5 [133/172] - loss: 0.1180
Epoch 5 [134/172] - loss: 0.1591
Epoch 5 [135/172] - loss: 0.1095
Epoch 5 [136/172] - loss: 0.1092
Epoch 5 [137/172] - loss: 0.1128
Epoch 5 [138/172] - loss: 0.1514
Epoch 5 [139/172] - loss: 0.1889
Epoch 5 [140/172] - loss: 0.1250, acc: 0.9688
Epoch 5 [141/172] - loss: 0.1100
Epoch 5 [142/172] - loss: 0.1367
Epoch 5 [143/172] - loss: 0.1070
Epoch 5 [144/172] - loss: 0.1062
Epoch 5 [145/172] - loss: 0.1218
Epoch 5 [146/172] - loss: 0.1211
Epoch 5 [147/172] - loss: 0.1204
Epoch 5 [148/172] - loss: 0.1106
Epoch 5 [149/172] - loss: 0.1057
Epoch 5 [150/172] - loss: 0.1371, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1175
Epoch 5 [152/172] - loss: 0.1087
Epoch 5 [153/172] - loss: 0.1093
Epoch 5 [154/172] - loss: 0.1142
Epoch 5 [155/172] - loss: 0.1224
Epoch 5 [156/172] - loss: 0.1204
Epoch 5 [157/172] - loss: 0.1081
Epoch 5 [158/172] - loss: 0.1086
Epoch 5 [159/172] - loss: 0.1085
Epoch 5 [160/172] - loss: 0.1111, acc: 1.0000
Epoch 5 [161/172] - loss: 0.1081
Epoch 5 [162/172] - loss: 0.1583
Epoch 5 [163/172] - loss: 0.1681
Epoch 5 [164/172] - loss: 0.1079
Epoch 5 [165/172] - loss: 0.1426
Epoch 5 [166/172] - loss: 0.1165
Epoch 5 [167/172] - loss: 0.1187
Epoch 5 [168/172] - loss: 0.1068
Epoch 5 [169/172] - loss: 0.1077
Epoch 5 [170/172] - loss: 0.1079, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1164
Epoch 5 [172/172] - loss: 0.1135

类别准确率:
positive: 0.8951 (418/467)
neutral: 0.2289 (19/83)
negative: 0.5400 (135/250)

Epoch 5/10
Train Loss: 0.1193, Train Acc: 0.9919
Val Loss: 1.0071, Val Acc: 0.7150
Epoch 6 [1/172] - loss: 0.1267, acc: 0.9688
Epoch 6 [2/172] - loss: 0.1164
Epoch 6 [3/172] - loss: 0.1059
Epoch 6 [4/172] - loss: 0.1070
Epoch 6 [5/172] - loss: 0.1425
Epoch 6 [6/172] - loss: 0.1084
Epoch 6 [7/172] - loss: 0.1173
Epoch 6 [8/172] - loss: 0.1260
Epoch 6 [9/172] - loss: 0.1065
Epoch 6 [10/172] - loss: 0.1061, acc: 1.0000
Epoch 6 [11/172] - loss: 0.1057
Epoch 6 [12/172] - loss: 0.1064
Epoch 6 [13/172] - loss: 0.1115
Epoch 6 [14/172] - loss: 0.1057
Epoch 6 [15/172] - loss: 0.1068
Epoch 6 [16/172] - loss: 0.1778
Epoch 6 [17/172] - loss: 0.1094
Epoch 6 [18/172] - loss: 0.1084
Epoch 6 [19/172] - loss: 0.1098
Epoch 6 [20/172] - loss: 0.1058, acc: 1.0000
Epoch 6 [21/172] - loss: 0.1168
Epoch 6 [22/172] - loss: 0.1070
Epoch 6 [23/172] - loss: 0.1085
Epoch 6 [24/172] - loss: 0.1092
Epoch 6 [25/172] - loss: 0.1280
Epoch 6 [26/172] - loss: 0.1083
Epoch 6 [27/172] - loss: 0.1194
Epoch 6 [28/172] - loss: 0.1256
Epoch 6 [29/172] - loss: 0.1092
Epoch 6 [30/172] - loss: 0.1050, acc: 1.0000
Epoch 6 [31/172] - loss: 0.1144
Epoch 6 [32/172] - loss: 0.1063
Epoch 6 [33/172] - loss: 0.1066
Epoch 6 [34/172] - loss: 0.1074
Epoch 6 [35/172] - loss: 0.1058
Epoch 6 [36/172] - loss: 0.1082
Epoch 6 [37/172] - loss: 0.1083
Epoch 6 [38/172] - loss: 0.1077
Epoch 6 [39/172] - loss: 0.1078
Epoch 6 [40/172] - loss: 0.1899, acc: 0.9375

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1728, log_difficulty=0.1594, weight=1.7971
neutral: count=8815.0, difficulty=0.1229, log_difficulty=0.1159, weight=1.5794
negative: count=9870.0, difficulty=0.1648, log_difficulty=0.1526, weight=1.7628

当前batch的pt分布：
positive: min=0.0099, max=0.9994, mean=0.9042
neutral: min=0.9555, max=0.9990, mean=0.9881
negative: min=0.3093, max=0.9992, mean=0.8812

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.2123
焦点损失: 0.1651
边界损失: 0.1553
总损失: 0.1905
Epoch 6 [41/172] - loss: 0.1905
Epoch 6 [42/172] - loss: 0.1070
Epoch 6 [43/172] - loss: 0.1070
Epoch 6 [44/172] - loss: 0.1097
Epoch 6 [45/172] - loss: 0.1136
Epoch 6 [46/172] - loss: 0.1088
Epoch 6 [47/172] - loss: 0.1059
Epoch 6 [48/172] - loss: 0.1056
Epoch 6 [49/172] - loss: 0.1081
Epoch 6 [50/172] - loss: 0.1723, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1445
Epoch 6 [52/172] - loss: 0.1152
Epoch 6 [53/172] - loss: 0.1061
Epoch 6 [54/172] - loss: 0.1440
Epoch 6 [55/172] - loss: 0.1087
Epoch 6 [56/172] - loss: 0.1092
Epoch 6 [57/172] - loss: 0.1071
Epoch 6 [58/172] - loss: 0.1080
Epoch 6 [59/172] - loss: 0.1325
Epoch 6 [60/172] - loss: 0.1245, acc: 0.9688
Epoch 6 [61/172] - loss: 0.1083
Epoch 6 [62/172] - loss: 0.1260
Epoch 6 [63/172] - loss: 0.1067
Epoch 6 [64/172] - loss: 0.1482
Epoch 6 [65/172] - loss: 0.1113
Epoch 6 [66/172] - loss: 0.1086
Epoch 6 [67/172] - loss: 0.1062
Epoch 6 [68/172] - loss: 0.1381
Epoch 6 [69/172] - loss: 0.1143
Epoch 6 [70/172] - loss: 0.1050, acc: 1.0000
Epoch 6 [71/172] - loss: 0.1135
Epoch 6 [72/172] - loss: 0.1083
Epoch 6 [73/172] - loss: 0.1203
Epoch 6 [74/172] - loss: 0.1058
Epoch 6 [75/172] - loss: 0.1086
Epoch 6 [76/172] - loss: 0.1091
Epoch 6 [77/172] - loss: 0.1159
Epoch 6 [78/172] - loss: 0.1203
Epoch 6 [79/172] - loss: 0.1078
Epoch 6 [80/172] - loss: 0.1085, acc: 1.0000
Epoch 6 [81/172] - loss: 0.1282
Epoch 6 [82/172] - loss: 0.1091
Epoch 6 [83/172] - loss: 0.1062
Epoch 6 [84/172] - loss: 0.1070
Epoch 6 [85/172] - loss: 0.1171
Epoch 6 [86/172] - loss: 0.1217
Epoch 6 [87/172] - loss: 0.1099
Epoch 6 [88/172] - loss: 0.1279
Epoch 6 [89/172] - loss: 0.1162
Epoch 6 [90/172] - loss: 0.1055, acc: 1.0000
Epoch 6 [91/172] - loss: 0.1099
Epoch 6 [92/172] - loss: 0.1073
Epoch 6 [93/172] - loss: 0.1056
Epoch 6 [94/172] - loss: 0.1212
Epoch 6 [95/172] - loss: 0.1130
Epoch 6 [96/172] - loss: 0.1053
Epoch 6 [97/172] - loss: 0.1072
Epoch 6 [98/172] - loss: 0.1084
Epoch 6 [99/172] - loss: 0.1046
Epoch 6 [100/172] - loss: 0.1060, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1185
Epoch 6 [102/172] - loss: 0.1075
Epoch 6 [103/172] - loss: 0.1083
Epoch 6 [104/172] - loss: 0.1562
Epoch 6 [105/172] - loss: 0.1107
Epoch 6 [106/172] - loss: 0.1180
Epoch 6 [107/172] - loss: 0.1067
Epoch 6 [108/172] - loss: 0.1090
Epoch 6 [109/172] - loss: 0.1601
Epoch 6 [110/172] - loss: 0.1240, acc: 0.9688
Epoch 6 [111/172] - loss: 0.1162
Epoch 6 [112/172] - loss: 0.1133
Epoch 6 [113/172] - loss: 0.1084
Epoch 6 [114/172] - loss: 0.1050
Epoch 6 [115/172] - loss: 0.1547
Epoch 6 [116/172] - loss: 0.1330
Epoch 6 [117/172] - loss: 0.1060
Epoch 6 [118/172] - loss: 0.1057
Epoch 6 [119/172] - loss: 0.1388
Epoch 6 [120/172] - loss: 0.1102, acc: 1.0000
Epoch 6 [121/172] - loss: 0.1254
Epoch 6 [122/172] - loss: 0.1094
Epoch 6 [123/172] - loss: 0.1081
Epoch 6 [124/172] - loss: 0.1051
Epoch 6 [125/172] - loss: 0.1091
Epoch 6 [126/172] - loss: 0.1772
Epoch 6 [127/172] - loss: 0.1464
Epoch 6 [128/172] - loss: 0.1078
Epoch 6 [129/172] - loss: 0.1068
Epoch 6 [130/172] - loss: 0.1474, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1572
Epoch 6 [132/172] - loss: 0.1122
Epoch 6 [133/172] - loss: 0.1155
Epoch 6 [134/172] - loss: 0.1053
Epoch 6 [135/172] - loss: 0.1054
Epoch 6 [136/172] - loss: 0.1054
Epoch 6 [137/172] - loss: 0.1076
Epoch 6 [138/172] - loss: 0.1073
Epoch 6 [139/172] - loss: 0.1154
Epoch 6 [140/172] - loss: 0.1109, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1582, log_difficulty=0.1468, weight=1.7341
neutral: count=9796.0, difficulty=0.1133, log_difficulty=0.1073, weight=1.5364
negative: count=10972.0, difficulty=0.1514, log_difficulty=0.1410, weight=1.7048

当前batch的pt分布：
positive: min=0.9686, max=0.9997, mean=0.9948
neutral: min=0.9494, max=0.9986, mean=0.9901
negative: min=0.9634, max=0.9985, mean=0.9819

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0121
焦点损失: 0.0000
边界损失: 0.1408
总损失: 0.1056
Epoch 6 [141/172] - loss: 0.1056
Epoch 6 [142/172] - loss: 0.1053
Epoch 6 [143/172] - loss: 0.1097
Epoch 6 [144/172] - loss: 0.1092
Epoch 6 [145/172] - loss: 0.1061
Epoch 6 [146/172] - loss: 0.1075
Epoch 6 [147/172] - loss: 0.1083
Epoch 6 [148/172] - loss: 0.1085
Epoch 6 [149/172] - loss: 0.1081
Epoch 6 [150/172] - loss: 0.1049, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1070
Epoch 6 [152/172] - loss: 0.1139
Epoch 6 [153/172] - loss: 0.1062
Epoch 6 [154/172] - loss: 0.1064
Epoch 6 [155/172] - loss: 0.1243
Epoch 6 [156/172] - loss: 0.1528
Epoch 6 [157/172] - loss: 0.1150
Epoch 6 [158/172] - loss: 0.1118
Epoch 6 [159/172] - loss: 0.1093
Epoch 6 [160/172] - loss: 0.1322, acc: 0.9688
Epoch 6 [161/172] - loss: 0.1101
Epoch 6 [162/172] - loss: 0.1080
Epoch 6 [163/172] - loss: 0.1059
Epoch 6 [164/172] - loss: 0.1353
Epoch 6 [165/172] - loss: 0.2216
Epoch 6 [166/172] - loss: 0.1077
Epoch 6 [167/172] - loss: 0.1058
Epoch 6 [168/172] - loss: 0.1070
Epoch 6 [169/172] - loss: 0.1134
Epoch 6 [170/172] - loss: 0.1048, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1066
Epoch 6 [172/172] - loss: 0.1076

类别准确率:
positive: 0.8694 (406/467)
neutral: 0.2530 (21/83)
negative: 0.6400 (160/250)

Epoch 6/10
Train Loss: 0.1189, Train Acc: 0.9899
Val Loss: 0.9444, Val Acc: 0.7338
Early stopping triggered!
Best validation accuracy: 0.7500

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_063422-r691nw5p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.25_Multimodal_iterations_20250118_063420
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/r691nw5p
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███
wandb:  train_acc ▁▂▃▆▄▆▇▇▇▇▇█▇▇██▇█▇█▇███▇▇▇█▇███████▇███
wandb: train_loss █▇▄▇▃▄▂▃▂▃▂▁▁▂▁▁▃▂▁▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1030
wandb:  train_acc 1
wandb: train_loss 0.10477
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.25_Multimodal_iterations_20250118_063420 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/r691nw5p
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_063422-r691nw5p/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_064345-c7rmgwdz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.25_Multimodal_epochs_20250118_064345
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/c7rmgwdz
wandb: uploading summary; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▄▅▇█
wandb:  train_acc ▁▆▇▇██
wandb: train_loss █▄▂▂▁▁
wandb:    val_acc ▁▆█▄▄▆
wandb:   val_loss ▁▁▄▅█▆
wandb: 
wandb: Run summary:
wandb:      epoch 6
wandb:  train_acc 0.9899
wandb: train_loss 0.11888
wandb:    val_acc 0.73375
wandb:   val_loss 0.9444
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.25_Multimodal_epochs_20250118_064345 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/c7rmgwdz
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_064345-c7rmgwdz/logs

