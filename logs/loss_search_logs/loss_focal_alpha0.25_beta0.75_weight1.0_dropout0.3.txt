=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 1.0 --dropout 0.3 --name loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.3 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.3
text_dim: 128
image_dim: 256
dropout: 0.3
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6833, log_difficulty=0.5207, weight=3.6037
neutral: count=7.0, difficulty=0.7137, log_difficulty=0.5387, weight=3.6933
negative: count=13.0, difficulty=0.6629, log_difficulty=0.5086, weight=3.5428

当前batch的pt分布：
positive: min=0.1534, max=0.5755, mean=0.3167
neutral: min=0.1988, max=0.3974, mean=0.2863
negative: min=0.1640, max=0.5155, mean=0.3371

当前batch准确率：
整体准确率: 0.2500
positive 准确率: 0.2500
neutral 准确率: 0.1429
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1929
焦点损失: 0.4337
边界损失: 0.7301
总损失: 0.9383
Epoch 1 [1/172] - loss: 0.9383, acc: 0.2500
Epoch 1 [2/172] - loss: 0.9142
Epoch 1 [3/172] - loss: 0.9380
Epoch 1 [4/172] - loss: 0.9824
Epoch 1 [5/172] - loss: 0.9814
Epoch 1 [6/172] - loss: 0.9408
Epoch 1 [7/172] - loss: 0.9417
Epoch 1 [8/172] - loss: 0.9132
Epoch 1 [9/172] - loss: 0.9368
Epoch 1 [10/172] - loss: 0.8660, acc: 0.4375
Epoch 1 [11/172] - loss: 0.7946
Epoch 1 [12/172] - loss: 0.7886
Epoch 1 [13/172] - loss: 0.8247
Epoch 1 [14/172] - loss: 0.9252
Epoch 1 [15/172] - loss: 0.9251
Epoch 1 [16/172] - loss: 0.8759
Epoch 1 [17/172] - loss: 0.8065
Epoch 1 [18/172] - loss: 0.8372
Epoch 1 [19/172] - loss: 0.8462
Epoch 1 [20/172] - loss: 0.8600, acc: 0.3438
Epoch 1 [21/172] - loss: 0.7921
Epoch 1 [22/172] - loss: 0.7359
Epoch 1 [23/172] - loss: 0.8855
Epoch 1 [24/172] - loss: 0.8335
Epoch 1 [25/172] - loss: 0.8931
Epoch 1 [26/172] - loss: 0.9465
Epoch 1 [27/172] - loss: 0.8665
Epoch 1 [28/172] - loss: 0.8078
Epoch 1 [29/172] - loss: 0.9087
Epoch 1 [30/172] - loss: 0.7072, acc: 0.4688
Epoch 1 [31/172] - loss: 0.9279
Epoch 1 [32/172] - loss: 0.7294
Epoch 1 [33/172] - loss: 0.7206
Epoch 1 [34/172] - loss: 0.7073
Epoch 1 [35/172] - loss: 0.9406
Epoch 1 [36/172] - loss: 0.6264
Epoch 1 [37/172] - loss: 0.7570
Epoch 1 [38/172] - loss: 0.7538
Epoch 1 [39/172] - loss: 0.6393
Epoch 1 [40/172] - loss: 0.6879, acc: 0.5938
Epoch 1 [41/172] - loss: 0.6443
Epoch 1 [42/172] - loss: 0.5787
Epoch 1 [43/172] - loss: 0.7195
Epoch 1 [44/172] - loss: 0.7783
Epoch 1 [45/172] - loss: 0.8670
Epoch 1 [46/172] - loss: 0.6006
Epoch 1 [47/172] - loss: 0.6454
Epoch 1 [48/172] - loss: 0.6486
Epoch 1 [49/172] - loss: 0.7542
Epoch 1 [50/172] - loss: 0.6292, acc: 0.5000
Epoch 1 [51/172] - loss: 0.7199
Epoch 1 [52/172] - loss: 0.6680
Epoch 1 [53/172] - loss: 0.6452
Epoch 1 [54/172] - loss: 0.9024
Epoch 1 [55/172] - loss: 0.5449
Epoch 1 [56/172] - loss: 0.6469
Epoch 1 [57/172] - loss: 0.6795
Epoch 1 [58/172] - loss: 0.7180
Epoch 1 [59/172] - loss: 0.6131
Epoch 1 [60/172] - loss: 0.5743, acc: 0.6875
Epoch 1 [61/172] - loss: 0.6409
Epoch 1 [62/172] - loss: 0.5878
Epoch 1 [63/172] - loss: 0.5667
Epoch 1 [64/172] - loss: 0.5889
Epoch 1 [65/172] - loss: 0.6716
Epoch 1 [66/172] - loss: 0.6886
Epoch 1 [67/172] - loss: 0.6433
Epoch 1 [68/172] - loss: 0.7239
Epoch 1 [69/172] - loss: 0.7947
Epoch 1 [70/172] - loss: 0.5506, acc: 0.6250
Epoch 1 [71/172] - loss: 0.4355
Epoch 1 [72/172] - loss: 0.6108
Epoch 1 [73/172] - loss: 0.5708
Epoch 1 [74/172] - loss: 0.5838
Epoch 1 [75/172] - loss: 0.3652
Epoch 1 [76/172] - loss: 0.6025
Epoch 1 [77/172] - loss: 0.6767
Epoch 1 [78/172] - loss: 0.6584
Epoch 1 [79/172] - loss: 0.5308
Epoch 1 [80/172] - loss: 0.3821, acc: 0.8125
Epoch 1 [81/172] - loss: 0.4871
Epoch 1 [82/172] - loss: 0.8690
Epoch 1 [83/172] - loss: 0.6216
Epoch 1 [84/172] - loss: 0.5666
Epoch 1 [85/172] - loss: 0.5616
Epoch 1 [86/172] - loss: 0.6558
Epoch 1 [87/172] - loss: 0.5435
Epoch 1 [88/172] - loss: 0.7099
Epoch 1 [89/172] - loss: 0.7982
Epoch 1 [90/172] - loss: 0.5991, acc: 0.5000
Epoch 1 [91/172] - loss: 0.5212
Epoch 1 [92/172] - loss: 0.4632
Epoch 1 [93/172] - loss: 0.5256
Epoch 1 [94/172] - loss: 0.4077
Epoch 1 [95/172] - loss: 0.5634
Epoch 1 [96/172] - loss: 0.5056
Epoch 1 [97/172] - loss: 0.5067
Epoch 1 [98/172] - loss: 0.5666
Epoch 1 [99/172] - loss: 0.5848
Epoch 1 [100/172] - loss: 0.6223, acc: 0.6562

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5589, log_difficulty=0.4440, weight=3.2200
neutral: count=983.0, difficulty=0.5270, log_difficulty=0.4233, weight=3.1167
negative: count=1119.0, difficulty=0.5086, log_difficulty=0.4112, weight=3.0559

当前batch的pt分布：
positive: min=0.0578, max=0.9291, mean=0.4558
neutral: min=0.1898, max=0.9797, mean=0.7425
negative: min=0.0442, max=0.8634, mean=0.4586

当前batch准确率：
整体准确率: 0.5938
positive 准确率: 0.5833
neutral 准确率: 0.7500
negative 准确率: 0.5625

损失分量：
基础交叉熵: 0.9681
焦点损失: 0.4896
边界损失: 0.3985
总损失: 0.6821
Epoch 1 [101/172] - loss: 0.6821
Epoch 1 [102/172] - loss: 0.6154
Epoch 1 [103/172] - loss: 0.6202
Epoch 1 [104/172] - loss: 0.4221
Epoch 1 [105/172] - loss: 0.6046
Epoch 1 [106/172] - loss: 0.7473
Epoch 1 [107/172] - loss: 0.5503
Epoch 1 [108/172] - loss: 0.6011
Epoch 1 [109/172] - loss: 0.4835
Epoch 1 [110/172] - loss: 0.6390, acc: 0.5938
Epoch 1 [111/172] - loss: 0.5788
Epoch 1 [112/172] - loss: 0.3989
Epoch 1 [113/172] - loss: 0.4001
Epoch 1 [114/172] - loss: 0.4031
Epoch 1 [115/172] - loss: 0.5419
Epoch 1 [116/172] - loss: 0.4305
Epoch 1 [117/172] - loss: 0.6453
Epoch 1 [118/172] - loss: 0.3586
Epoch 1 [119/172] - loss: 0.5408
Epoch 1 [120/172] - loss: 0.4269, acc: 0.6562
Epoch 1 [121/172] - loss: 0.3482
Epoch 1 [122/172] - loss: 0.5688
Epoch 1 [123/172] - loss: 0.3894
Epoch 1 [124/172] - loss: 0.4659
Epoch 1 [125/172] - loss: 0.3786
Epoch 1 [126/172] - loss: 0.6440
Epoch 1 [127/172] - loss: 0.4457
Epoch 1 [128/172] - loss: 0.3325
Epoch 1 [129/172] - loss: 0.5036
Epoch 1 [130/172] - loss: 0.5463, acc: 0.6562
Epoch 1 [131/172] - loss: 0.2964
Epoch 1 [132/172] - loss: 0.5583
Epoch 1 [133/172] - loss: 0.6049
Epoch 1 [134/172] - loss: 0.3672
Epoch 1 [135/172] - loss: 0.4840
Epoch 1 [136/172] - loss: 0.4015
Epoch 1 [137/172] - loss: 0.4930
Epoch 1 [138/172] - loss: 0.3960
Epoch 1 [139/172] - loss: 0.3379
Epoch 1 [140/172] - loss: 0.4039, acc: 0.7188
Epoch 1 [141/172] - loss: 0.4722
Epoch 1 [142/172] - loss: 0.4996
Epoch 1 [143/172] - loss: 0.5303
Epoch 1 [144/172] - loss: 0.4131
Epoch 1 [145/172] - loss: 0.4794
Epoch 1 [146/172] - loss: 0.4909
Epoch 1 [147/172] - loss: 0.5509
Epoch 1 [148/172] - loss: 0.3938
Epoch 1 [149/172] - loss: 0.3719
Epoch 1 [150/172] - loss: 0.4534, acc: 0.7500
Epoch 1 [151/172] - loss: 0.4553
Epoch 1 [152/172] - loss: 0.3921
Epoch 1 [153/172] - loss: 0.4624
Epoch 1 [154/172] - loss: 0.3832
Epoch 1 [155/172] - loss: 0.4407
Epoch 1 [156/172] - loss: 0.5108
Epoch 1 [157/172] - loss: 0.4183
Epoch 1 [158/172] - loss: 0.3458
Epoch 1 [159/172] - loss: 0.5741
Epoch 1 [160/172] - loss: 0.3763, acc: 0.8125
Epoch 1 [161/172] - loss: 0.3328
Epoch 1 [162/172] - loss: 0.3192
Epoch 1 [163/172] - loss: 0.3994
Epoch 1 [164/172] - loss: 0.3925
Epoch 1 [165/172] - loss: 0.3102
Epoch 1 [166/172] - loss: 0.4883
Epoch 1 [167/172] - loss: 0.3237
Epoch 1 [168/172] - loss: 0.6119
Epoch 1 [169/172] - loss: 0.4142
Epoch 1 [170/172] - loss: 0.3023, acc: 0.8438
Epoch 1 [171/172] - loss: 0.3298
Epoch 1 [172/172] - loss: 0.4095

类别准确率:
positive: 0.7216 (337/467)
neutral: 0.6867 (57/83)
negative: 0.4800 (120/250)

Epoch 1/10
Train Loss: 0.3968, Train Acc: 0.8040
Val Loss: 0.8115, Val Acc: 0.6425
Epoch 2 [1/172] - loss: 0.3656, acc: 0.8438
Epoch 2 [2/172] - loss: 0.2974
Epoch 2 [3/172] - loss: 0.2871
Epoch 2 [4/172] - loss: 0.4532
Epoch 2 [5/172] - loss: 0.4871
Epoch 2 [6/172] - loss: 0.4053
Epoch 2 [7/172] - loss: 0.3203
Epoch 2 [8/172] - loss: 0.3184
Epoch 2 [9/172] - loss: 0.2842
Epoch 2 [10/172] - loss: 0.3126, acc: 0.8438
Epoch 2 [11/172] - loss: 0.3324
Epoch 2 [12/172] - loss: 0.2620
Epoch 2 [13/172] - loss: 0.3662
Epoch 2 [14/172] - loss: 0.3461
Epoch 2 [15/172] - loss: 0.4222
Epoch 2 [16/172] - loss: 0.3713
Epoch 2 [17/172] - loss: 0.3795
Epoch 2 [18/172] - loss: 0.4797
Epoch 2 [19/172] - loss: 0.2918
Epoch 2 [20/172] - loss: 0.2919, acc: 0.8750
Epoch 2 [21/172] - loss: 0.3005
Epoch 2 [22/172] - loss: 0.2937
Epoch 2 [23/172] - loss: 0.2269
Epoch 2 [24/172] - loss: 0.4362
Epoch 2 [25/172] - loss: 0.3314
Epoch 2 [26/172] - loss: 0.2114
Epoch 2 [27/172] - loss: 0.2435
Epoch 2 [28/172] - loss: 0.2519

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4640, log_difficulty=0.3812, weight=2.9060
neutral: count=1952.0, difficulty=0.4037, log_difficulty=0.3391, weight=2.6957
negative: count=2216.0, difficulty=0.4389, log_difficulty=0.3639, weight=2.8194

当前batch的pt分布：
positive: min=0.4529, max=0.9755, mean=0.7759
neutral: min=0.5786, max=0.9992, mean=0.8489
negative: min=0.0263, max=0.9904, mean=0.7174

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8889
neutral 准确率: 1.0000
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.4071
焦点损失: 0.2080
边界损失: 0.2358
总损失: 0.3236
Epoch 2 [29/172] - loss: 0.3236
Epoch 2 [30/172] - loss: 0.2772, acc: 0.8750
Epoch 2 [31/172] - loss: 0.2937
Epoch 2 [32/172] - loss: 0.2605
Epoch 2 [33/172] - loss: 0.2760
Epoch 2 [34/172] - loss: 0.3118
Epoch 2 [35/172] - loss: 0.2202
Epoch 2 [36/172] - loss: 0.3620
Epoch 2 [37/172] - loss: 0.2372
Epoch 2 [38/172] - loss: 0.3047
Epoch 2 [39/172] - loss: 0.2774
Epoch 2 [40/172] - loss: 0.3465, acc: 0.7500
Epoch 2 [41/172] - loss: 0.3163
Epoch 2 [42/172] - loss: 0.2402
Epoch 2 [43/172] - loss: 0.1952
Epoch 2 [44/172] - loss: 0.4350
Epoch 2 [45/172] - loss: 0.1959
Epoch 2 [46/172] - loss: 0.2701
Epoch 2 [47/172] - loss: 0.2638
Epoch 2 [48/172] - loss: 0.3138
Epoch 2 [49/172] - loss: 0.2847
Epoch 2 [50/172] - loss: 0.3121, acc: 0.8438
Epoch 2 [51/172] - loss: 0.3790
Epoch 2 [52/172] - loss: 0.2656
Epoch 2 [53/172] - loss: 0.2148
Epoch 2 [54/172] - loss: 0.2790
Epoch 2 [55/172] - loss: 0.2400
Epoch 2 [56/172] - loss: 0.1930
Epoch 2 [57/172] - loss: 0.2009
Epoch 2 [58/172] - loss: 0.2645
Epoch 2 [59/172] - loss: 0.4161
Epoch 2 [60/172] - loss: 0.3279, acc: 0.7812
Epoch 2 [61/172] - loss: 0.1827
Epoch 2 [62/172] - loss: 0.1889
Epoch 2 [63/172] - loss: 0.3627
Epoch 2 [64/172] - loss: 0.2535
Epoch 2 [65/172] - loss: 0.3062
Epoch 2 [66/172] - loss: 0.2897
Epoch 2 [67/172] - loss: 0.2203
Epoch 2 [68/172] - loss: 0.3175
Epoch 2 [69/172] - loss: 0.2272
Epoch 2 [70/172] - loss: 0.3470, acc: 0.8750
Epoch 2 [71/172] - loss: 0.3225
Epoch 2 [72/172] - loss: 0.2579
Epoch 2 [73/172] - loss: 0.2747
Epoch 2 [74/172] - loss: 0.2542
Epoch 2 [75/172] - loss: 0.2101
Epoch 2 [76/172] - loss: 0.2045
Epoch 2 [77/172] - loss: 0.3200
Epoch 2 [78/172] - loss: 0.2809
Epoch 2 [79/172] - loss: 0.2470
Epoch 2 [80/172] - loss: 0.1817, acc: 0.9688
Epoch 2 [81/172] - loss: 0.2591
Epoch 2 [82/172] - loss: 0.2483
Epoch 2 [83/172] - loss: 0.2394
Epoch 2 [84/172] - loss: 0.2767
Epoch 2 [85/172] - loss: 0.2114
Epoch 2 [86/172] - loss: 0.2477
Epoch 2 [87/172] - loss: 0.4693
Epoch 2 [88/172] - loss: 0.2091
Epoch 2 [89/172] - loss: 0.1980
Epoch 2 [90/172] - loss: 0.2322, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1843
Epoch 2 [92/172] - loss: 0.3701
Epoch 2 [93/172] - loss: 0.2944
Epoch 2 [94/172] - loss: 0.2684
Epoch 2 [95/172] - loss: 0.3543
Epoch 2 [96/172] - loss: 0.1752
Epoch 2 [97/172] - loss: 0.2834
Epoch 2 [98/172] - loss: 0.2318
Epoch 2 [99/172] - loss: 0.1706
Epoch 2 [100/172] - loss: 0.2201, acc: 0.9375
Epoch 2 [101/172] - loss: 0.2225
Epoch 2 [102/172] - loss: 0.2230
Epoch 2 [103/172] - loss: 0.2963
Epoch 2 [104/172] - loss: 0.2798
Epoch 2 [105/172] - loss: 0.2148
Epoch 2 [106/172] - loss: 0.2407
Epoch 2 [107/172] - loss: 0.2368
Epoch 2 [108/172] - loss: 0.2741
Epoch 2 [109/172] - loss: 0.2171
Epoch 2 [110/172] - loss: 0.2275, acc: 0.9062
Epoch 2 [111/172] - loss: 0.1983
Epoch 2 [112/172] - loss: 0.1778
Epoch 2 [113/172] - loss: 0.1615
Epoch 2 [114/172] - loss: 0.2855
Epoch 2 [115/172] - loss: 0.2370
Epoch 2 [116/172] - loss: 0.2173
Epoch 2 [117/172] - loss: 0.3920
Epoch 2 [118/172] - loss: 0.1676
Epoch 2 [119/172] - loss: 0.2224
Epoch 2 [120/172] - loss: 0.2009, acc: 0.9375
Epoch 2 [121/172] - loss: 0.2472
Epoch 2 [122/172] - loss: 0.4231
Epoch 2 [123/172] - loss: 0.2403
Epoch 2 [124/172] - loss: 0.2693
Epoch 2 [125/172] - loss: 0.1818
Epoch 2 [126/172] - loss: 0.2035
Epoch 2 [127/172] - loss: 0.1893
Epoch 2 [128/172] - loss: 0.2645

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3930, log_difficulty=0.3314, weight=2.6571
neutral: count=2949.0, difficulty=0.3099, log_difficulty=0.2699, weight=2.3497
negative: count=3294.0, difficulty=0.3687, log_difficulty=0.3138, weight=2.5692

当前batch的pt分布：
positive: min=0.1094, max=0.9880, mean=0.7850
neutral: min=0.7179, max=0.9994, mean=0.9099
negative: min=0.0415, max=0.9904, mean=0.7846

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8000
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.3121
焦点损失: 0.1608
边界损失: 0.2017
总损失: 0.2559
Epoch 2 [129/172] - loss: 0.2559
Epoch 2 [130/172] - loss: 0.2407, acc: 0.8438
Epoch 2 [131/172] - loss: 0.1902
Epoch 2 [132/172] - loss: 0.2658
Epoch 2 [133/172] - loss: 0.2032
Epoch 2 [134/172] - loss: 0.2717
Epoch 2 [135/172] - loss: 0.2592
Epoch 2 [136/172] - loss: 0.2433
Epoch 2 [137/172] - loss: 0.2074
Epoch 2 [138/172] - loss: 0.2302
Epoch 2 [139/172] - loss: 0.2955
Epoch 2 [140/172] - loss: 0.2874, acc: 0.7188
Epoch 2 [141/172] - loss: 0.2213
Epoch 2 [142/172] - loss: 0.2987
Epoch 2 [143/172] - loss: 0.2925
Epoch 2 [144/172] - loss: 0.3080
Epoch 2 [145/172] - loss: 0.4452
Epoch 2 [146/172] - loss: 0.1736
Epoch 2 [147/172] - loss: 0.2376
Epoch 2 [148/172] - loss: 0.2246
Epoch 2 [149/172] - loss: 0.2804
Epoch 2 [150/172] - loss: 0.2444, acc: 0.9688
Epoch 2 [151/172] - loss: 0.2059
Epoch 2 [152/172] - loss: 0.2574
Epoch 2 [153/172] - loss: 0.2599
Epoch 2 [154/172] - loss: 0.1731
Epoch 2 [155/172] - loss: 0.2365
Epoch 2 [156/172] - loss: 0.2342
Epoch 2 [157/172] - loss: 0.1513
Epoch 2 [158/172] - loss: 0.2522
Epoch 2 [159/172] - loss: 0.1994
Epoch 2 [160/172] - loss: 0.1949, acc: 0.9062
Epoch 2 [161/172] - loss: 0.1441
Epoch 2 [162/172] - loss: 0.1789
Epoch 2 [163/172] - loss: 0.2951
Epoch 2 [164/172] - loss: 0.2068
Epoch 2 [165/172] - loss: 0.2683
Epoch 2 [166/172] - loss: 0.2836
Epoch 2 [167/172] - loss: 0.2955
Epoch 2 [168/172] - loss: 0.2402
Epoch 2 [169/172] - loss: 0.1323
Epoch 2 [170/172] - loss: 0.2181, acc: 0.9062
Epoch 2 [171/172] - loss: 0.2269
Epoch 2 [172/172] - loss: 0.3680

类别准确率:
positive: 0.8223 (384/467)
neutral: 0.5060 (42/83)
negative: 0.4200 (105/250)

Epoch 2/10
Train Loss: 0.2285, Train Acc: 0.9091
Val Loss: 1.0384, Val Acc: 0.6637
Epoch 3 [1/172] - loss: 0.2076, acc: 0.8750
Epoch 3 [2/172] - loss: 0.1775
Epoch 3 [3/172] - loss: 0.1504
Epoch 3 [4/172] - loss: 0.1409
Epoch 3 [5/172] - loss: 0.1670
Epoch 3 [6/172] - loss: 0.1629
Epoch 3 [7/172] - loss: 0.1421
Epoch 3 [8/172] - loss: 0.1620
Epoch 3 [9/172] - loss: 0.1471
Epoch 3 [10/172] - loss: 0.1651, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1710
Epoch 3 [12/172] - loss: 0.1329
Epoch 3 [13/172] - loss: 0.1350
Epoch 3 [14/172] - loss: 0.1402
Epoch 3 [15/172] - loss: 0.1706
Epoch 3 [16/172] - loss: 0.2411
Epoch 3 [17/172] - loss: 0.2025
Epoch 3 [18/172] - loss: 0.2907
Epoch 3 [19/172] - loss: 0.1450
Epoch 3 [20/172] - loss: 0.1322, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1541
Epoch 3 [22/172] - loss: 0.2270
Epoch 3 [23/172] - loss: 0.1537
Epoch 3 [24/172] - loss: 0.1696
Epoch 3 [25/172] - loss: 0.1288
Epoch 3 [26/172] - loss: 0.1214
Epoch 3 [27/172] - loss: 0.1461
Epoch 3 [28/172] - loss: 0.1267
Epoch 3 [29/172] - loss: 0.2341
Epoch 3 [30/172] - loss: 0.1897, acc: 0.9688
Epoch 3 [31/172] - loss: 0.1403
Epoch 3 [32/172] - loss: 0.1359
Epoch 3 [33/172] - loss: 0.1239
Epoch 3 [34/172] - loss: 0.1563
Epoch 3 [35/172] - loss: 0.1557
Epoch 3 [36/172] - loss: 0.1288
Epoch 3 [37/172] - loss: 0.1717
Epoch 3 [38/172] - loss: 0.1883
Epoch 3 [39/172] - loss: 0.1313
Epoch 3 [40/172] - loss: 0.2459, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1598
Epoch 3 [42/172] - loss: 0.1695
Epoch 3 [43/172] - loss: 0.1311
Epoch 3 [44/172] - loss: 0.1346
Epoch 3 [45/172] - loss: 0.1757
Epoch 3 [46/172] - loss: 0.1432
Epoch 3 [47/172] - loss: 0.1210
Epoch 3 [48/172] - loss: 0.1463
Epoch 3 [49/172] - loss: 0.1258
Epoch 3 [50/172] - loss: 0.1218, acc: 1.0000
Epoch 3 [51/172] - loss: 0.1999
Epoch 3 [52/172] - loss: 0.2134
Epoch 3 [53/172] - loss: 0.1261
Epoch 3 [54/172] - loss: 0.1607
Epoch 3 [55/172] - loss: 0.1285
Epoch 3 [56/172] - loss: 0.1280

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3333, log_difficulty=0.2877, weight=2.4385
neutral: count=3923.0, difficulty=0.2536, log_difficulty=0.2260, weight=2.1301
negative: count=4382.0, difficulty=0.3125, log_difficulty=0.2719, weight=2.3596

当前batch的pt分布：
positive: min=0.2091, max=0.9951, mean=0.8683
neutral: min=0.0043, max=0.9917, mean=0.8517
negative: min=0.9777, max=0.9978, mean=0.9909

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9091
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2928
焦点损失: 0.2008
边界损失: 0.1747
总损失: 0.2402
Epoch 3 [57/172] - loss: 0.2402
Epoch 3 [58/172] - loss: 0.1464
Epoch 3 [59/172] - loss: 0.1469
Epoch 3 [60/172] - loss: 0.1325, acc: 1.0000
Epoch 3 [61/172] - loss: 0.1280
Epoch 3 [62/172] - loss: 0.1468
Epoch 3 [63/172] - loss: 0.1211
Epoch 3 [64/172] - loss: 0.1729
Epoch 3 [65/172] - loss: 0.1583
Epoch 3 [66/172] - loss: 0.1681
Epoch 3 [67/172] - loss: 0.1813
Epoch 3 [68/172] - loss: 0.1270
Epoch 3 [69/172] - loss: 0.1723
Epoch 3 [70/172] - loss: 0.1178, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1882
Epoch 3 [72/172] - loss: 0.1862
Epoch 3 [73/172] - loss: 0.1190
Epoch 3 [74/172] - loss: 0.1695
Epoch 3 [75/172] - loss: 0.1287
Epoch 3 [76/172] - loss: 0.1479
Epoch 3 [77/172] - loss: 0.1497
Epoch 3 [78/172] - loss: 0.2828
Epoch 3 [79/172] - loss: 0.1185
Epoch 3 [80/172] - loss: 0.1433, acc: 0.9688
Epoch 3 [81/172] - loss: 0.1384
Epoch 3 [82/172] - loss: 0.1875
Epoch 3 [83/172] - loss: 0.1284
Epoch 3 [84/172] - loss: 0.1196
Epoch 3 [85/172] - loss: 0.1691
Epoch 3 [86/172] - loss: 0.1282
Epoch 3 [87/172] - loss: 0.1902
Epoch 3 [88/172] - loss: 0.1305
Epoch 3 [89/172] - loss: 0.1227
Epoch 3 [90/172] - loss: 0.1221, acc: 1.0000
Epoch 3 [91/172] - loss: 0.2093
Epoch 3 [92/172] - loss: 0.1705
Epoch 3 [93/172] - loss: 0.1969
Epoch 3 [94/172] - loss: 0.2051
Epoch 3 [95/172] - loss: 0.1247
Epoch 3 [96/172] - loss: 0.1467
Epoch 3 [97/172] - loss: 0.1411
Epoch 3 [98/172] - loss: 0.1227
Epoch 3 [99/172] - loss: 0.1416
Epoch 3 [100/172] - loss: 0.2068, acc: 0.9688
Epoch 3 [101/172] - loss: 0.2288
Epoch 3 [102/172] - loss: 0.1254
Epoch 3 [103/172] - loss: 0.2066
Epoch 3 [104/172] - loss: 0.1416
Epoch 3 [105/172] - loss: 0.1808
Epoch 3 [106/172] - loss: 0.1435
Epoch 3 [107/172] - loss: 0.1199
Epoch 3 [108/172] - loss: 0.1464
Epoch 3 [109/172] - loss: 0.1385
Epoch 3 [110/172] - loss: 0.1405, acc: 1.0000
Epoch 3 [111/172] - loss: 0.1342
Epoch 3 [112/172] - loss: 0.1325
Epoch 3 [113/172] - loss: 0.1397
Epoch 3 [114/172] - loss: 0.1268
Epoch 3 [115/172] - loss: 0.1812
Epoch 3 [116/172] - loss: 0.1337
Epoch 3 [117/172] - loss: 0.1371
Epoch 3 [118/172] - loss: 0.1623
Epoch 3 [119/172] - loss: 0.1415
Epoch 3 [120/172] - loss: 0.1663, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1611
Epoch 3 [122/172] - loss: 0.1272
Epoch 3 [123/172] - loss: 0.1504
Epoch 3 [124/172] - loss: 0.1285
Epoch 3 [125/172] - loss: 0.1651
Epoch 3 [126/172] - loss: 0.2970
Epoch 3 [127/172] - loss: 0.2057
Epoch 3 [128/172] - loss: 0.1208
Epoch 3 [129/172] - loss: 0.1194
Epoch 3 [130/172] - loss: 0.1436, acc: 0.9688
Epoch 3 [131/172] - loss: 0.2043
Epoch 3 [132/172] - loss: 0.1181
Epoch 3 [133/172] - loss: 0.1190
Epoch 3 [134/172] - loss: 0.1423
Epoch 3 [135/172] - loss: 0.1364
Epoch 3 [136/172] - loss: 0.1898
Epoch 3 [137/172] - loss: 0.1149
Epoch 3 [138/172] - loss: 0.1458
Epoch 3 [139/172] - loss: 0.1600
Epoch 3 [140/172] - loss: 0.1533, acc: 0.9375
Epoch 3 [141/172] - loss: 0.2051
Epoch 3 [142/172] - loss: 0.1834
Epoch 3 [143/172] - loss: 0.1282
Epoch 3 [144/172] - loss: 0.2938
Epoch 3 [145/172] - loss: 0.1336
Epoch 3 [146/172] - loss: 0.1813
Epoch 3 [147/172] - loss: 0.1700
Epoch 3 [148/172] - loss: 0.1565
Epoch 3 [149/172] - loss: 0.1417
Epoch 3 [150/172] - loss: 0.1360, acc: 0.9688
Epoch 3 [151/172] - loss: 0.1953
Epoch 3 [152/172] - loss: 0.1580
Epoch 3 [153/172] - loss: 0.1268
Epoch 3 [154/172] - loss: 0.1480
Epoch 3 [155/172] - loss: 0.1349
Epoch 3 [156/172] - loss: 0.1409

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2867, log_difficulty=0.2521, weight=2.2604
neutral: count=4903.0, difficulty=0.2131, log_difficulty=0.1932, weight=1.9658
negative: count=5500.0, difficulty=0.2687, log_difficulty=0.2380, weight=2.1899

当前batch的pt分布：
positive: min=0.4540, max=0.9962, mean=0.9159
neutral: min=0.9151, max=0.9977, mean=0.9702
negative: min=0.6324, max=0.9938, mean=0.9057

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0818
焦点损失: 0.0086
边界损失: 0.1706
总损失: 0.1327
Epoch 3 [157/172] - loss: 0.1327
Epoch 3 [158/172] - loss: 0.1476
Epoch 3 [159/172] - loss: 0.1590
Epoch 3 [160/172] - loss: 0.1944, acc: 0.8750
Epoch 3 [161/172] - loss: 0.1930
Epoch 3 [162/172] - loss: 0.1752
Epoch 3 [163/172] - loss: 0.1533
Epoch 3 [164/172] - loss: 0.1200
Epoch 3 [165/172] - loss: 0.1159
Epoch 3 [166/172] - loss: 0.1504
Epoch 3 [167/172] - loss: 0.1694
Epoch 3 [168/172] - loss: 0.1755
Epoch 3 [169/172] - loss: 0.1572
Epoch 3 [170/172] - loss: 0.1479, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1220
Epoch 3 [172/172] - loss: 0.1674

类别准确率:
positive: 0.8437 (394/467)
neutral: 0.1687 (14/83)
negative: 0.6680 (167/250)

Epoch 3/10
Train Loss: 0.1551, Train Acc: 0.9596
Val Loss: 0.9715, Val Acc: 0.7188
Epoch 4 [1/172] - loss: 0.1178, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1301
Epoch 4 [3/172] - loss: 0.1570
Epoch 4 [4/172] - loss: 0.1357
Epoch 4 [5/172] - loss: 0.1252
Epoch 4 [6/172] - loss: 0.1133
Epoch 4 [7/172] - loss: 0.1451
Epoch 4 [8/172] - loss: 0.1102
Epoch 4 [9/172] - loss: 0.1366
Epoch 4 [10/172] - loss: 0.1747, acc: 0.9688
Epoch 4 [11/172] - loss: 0.1137
Epoch 4 [12/172] - loss: 0.1493
Epoch 4 [13/172] - loss: 0.1457
Epoch 4 [14/172] - loss: 0.1309
Epoch 4 [15/172] - loss: 0.1397
Epoch 4 [16/172] - loss: 0.1192
Epoch 4 [17/172] - loss: 0.1604
Epoch 4 [18/172] - loss: 0.1461
Epoch 4 [19/172] - loss: 0.1166
Epoch 4 [20/172] - loss: 0.1185, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1620
Epoch 4 [22/172] - loss: 0.1213
Epoch 4 [23/172] - loss: 0.1732
Epoch 4 [24/172] - loss: 0.1171
Epoch 4 [25/172] - loss: 0.1152
Epoch 4 [26/172] - loss: 0.1474
Epoch 4 [27/172] - loss: 0.1106
Epoch 4 [28/172] - loss: 0.1312
Epoch 4 [29/172] - loss: 0.1275
Epoch 4 [30/172] - loss: 0.1789, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1386
Epoch 4 [32/172] - loss: 0.1289
Epoch 4 [33/172] - loss: 0.1264
Epoch 4 [34/172] - loss: 0.1145
Epoch 4 [35/172] - loss: 0.1430
Epoch 4 [36/172] - loss: 0.1179
Epoch 4 [37/172] - loss: 0.1079
Epoch 4 [38/172] - loss: 0.1092
Epoch 4 [39/172] - loss: 0.1381
Epoch 4 [40/172] - loss: 0.1830, acc: 0.9688
Epoch 4 [41/172] - loss: 0.1144
Epoch 4 [42/172] - loss: 0.1199
Epoch 4 [43/172] - loss: 0.1865
Epoch 4 [44/172] - loss: 0.1223
Epoch 4 [45/172] - loss: 0.1238
Epoch 4 [46/172] - loss: 0.1255
Epoch 4 [47/172] - loss: 0.1236
Epoch 4 [48/172] - loss: 0.1166
Epoch 4 [49/172] - loss: 0.1115
Epoch 4 [50/172] - loss: 0.1408, acc: 0.9688
Epoch 4 [51/172] - loss: 0.1320
Epoch 4 [52/172] - loss: 0.1278
Epoch 4 [53/172] - loss: 0.1109
Epoch 4 [54/172] - loss: 0.1355
Epoch 4 [55/172] - loss: 0.1829
Epoch 4 [56/172] - loss: 0.1100
Epoch 4 [57/172] - loss: 0.1288
Epoch 4 [58/172] - loss: 0.1149
Epoch 4 [59/172] - loss: 0.1129
Epoch 4 [60/172] - loss: 0.1259, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1178
Epoch 4 [62/172] - loss: 0.1361
Epoch 4 [63/172] - loss: 0.1251
Epoch 4 [64/172] - loss: 0.1187
Epoch 4 [65/172] - loss: 0.1337
Epoch 4 [66/172] - loss: 0.1164
Epoch 4 [67/172] - loss: 0.1204
Epoch 4 [68/172] - loss: 0.1166
Epoch 4 [69/172] - loss: 0.1190
Epoch 4 [70/172] - loss: 0.1123, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1178
Epoch 4 [72/172] - loss: 0.1176
Epoch 4 [73/172] - loss: 0.1955
Epoch 4 [74/172] - loss: 0.1940
Epoch 4 [75/172] - loss: 0.1657
Epoch 4 [76/172] - loss: 0.1526
Epoch 4 [77/172] - loss: 0.2187
Epoch 4 [78/172] - loss: 0.1318
Epoch 4 [79/172] - loss: 0.1277
Epoch 4 [80/172] - loss: 0.1202, acc: 0.9688
Epoch 4 [81/172] - loss: 0.1395
Epoch 4 [82/172] - loss: 0.1308
Epoch 4 [83/172] - loss: 0.1137
Epoch 4 [84/172] - loss: 0.1229

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2505, log_difficulty=0.2235, weight=2.1177
neutral: count=5865.0, difficulty=0.1856, log_difficulty=0.1703, weight=1.8513
negative: count=6629.0, difficulty=0.2345, log_difficulty=0.2107, weight=2.0533

当前batch的pt分布：
positive: min=0.8470, max=0.9903, mean=0.9320
neutral: min=0.9808, max=0.9991, mean=0.9951
negative: min=0.7500, max=0.9993, mean=0.9286

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0593
焦点损失: 0.0011
边界损失: 0.1632
总损失: 0.1230
Epoch 4 [85/172] - loss: 0.1230
Epoch 4 [86/172] - loss: 0.1287
Epoch 4 [87/172] - loss: 0.1653
Epoch 4 [88/172] - loss: 0.1263
Epoch 4 [89/172] - loss: 0.1489
Epoch 4 [90/172] - loss: 0.1140, acc: 1.0000
Epoch 4 [91/172] - loss: 0.2063
Epoch 4 [92/172] - loss: 0.1996
Epoch 4 [93/172] - loss: 0.1108
Epoch 4 [94/172] - loss: 0.1106
Epoch 4 [95/172] - loss: 0.1267
Epoch 4 [96/172] - loss: 0.1400
Epoch 4 [97/172] - loss: 0.1215
Epoch 4 [98/172] - loss: 0.1225
Epoch 4 [99/172] - loss: 0.1254
Epoch 4 [100/172] - loss: 0.1237, acc: 1.0000
Epoch 4 [101/172] - loss: 0.1245
Epoch 4 [102/172] - loss: 0.1354
Epoch 4 [103/172] - loss: 0.1261
Epoch 4 [104/172] - loss: 0.1172
Epoch 4 [105/172] - loss: 0.1675
Epoch 4 [106/172] - loss: 0.1138
Epoch 4 [107/172] - loss: 0.1513
Epoch 4 [108/172] - loss: 0.1236
Epoch 4 [109/172] - loss: 0.1359
Epoch 4 [110/172] - loss: 0.2151, acc: 0.9375
Epoch 4 [111/172] - loss: 0.1338
Epoch 4 [112/172] - loss: 0.1077
Epoch 4 [113/172] - loss: 0.1102
Epoch 4 [114/172] - loss: 0.1503
Epoch 4 [115/172] - loss: 0.1444
Epoch 4 [116/172] - loss: 0.1213
Epoch 4 [117/172] - loss: 0.1186
Epoch 4 [118/172] - loss: 0.1278
Epoch 4 [119/172] - loss: 0.1156
Epoch 4 [120/172] - loss: 0.1175, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1439
Epoch 4 [122/172] - loss: 0.2052
Epoch 4 [123/172] - loss: 0.1101
Epoch 4 [124/172] - loss: 0.1178
Epoch 4 [125/172] - loss: 0.1196
Epoch 4 [126/172] - loss: 0.2191
Epoch 4 [127/172] - loss: 0.1275
Epoch 4 [128/172] - loss: 0.1188
Epoch 4 [129/172] - loss: 0.1124
Epoch 4 [130/172] - loss: 0.1101, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1123
Epoch 4 [132/172] - loss: 0.1426
Epoch 4 [133/172] - loss: 0.1153
Epoch 4 [134/172] - loss: 0.1170
Epoch 4 [135/172] - loss: 0.1601
Epoch 4 [136/172] - loss: 0.1999
Epoch 4 [137/172] - loss: 0.1201
Epoch 4 [138/172] - loss: 0.1161
Epoch 4 [139/172] - loss: 0.1331
Epoch 4 [140/172] - loss: 0.1340, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1433
Epoch 4 [142/172] - loss: 0.1294
Epoch 4 [143/172] - loss: 0.1212
Epoch 4 [144/172] - loss: 0.1103
Epoch 4 [145/172] - loss: 0.1898
Epoch 4 [146/172] - loss: 0.1121
Epoch 4 [147/172] - loss: 0.1272
Epoch 4 [148/172] - loss: 0.1608
Epoch 4 [149/172] - loss: 0.1138
Epoch 4 [150/172] - loss: 0.1465, acc: 0.9688
Epoch 4 [151/172] - loss: 0.1983
Epoch 4 [152/172] - loss: 0.1090
Epoch 4 [153/172] - loss: 0.1246
Epoch 4 [154/172] - loss: 0.1576
Epoch 4 [155/172] - loss: 0.1306
Epoch 4 [156/172] - loss: 0.1290
Epoch 4 [157/172] - loss: 0.1979
Epoch 4 [158/172] - loss: 0.1145
Epoch 4 [159/172] - loss: 0.1127
Epoch 4 [160/172] - loss: 0.1155, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1306
Epoch 4 [162/172] - loss: 0.1097
Epoch 4 [163/172] - loss: 0.1458
Epoch 4 [164/172] - loss: 0.1098
Epoch 4 [165/172] - loss: 0.1393
Epoch 4 [166/172] - loss: 0.1307
Epoch 4 [167/172] - loss: 0.1553
Epoch 4 [168/172] - loss: 0.1691
Epoch 4 [169/172] - loss: 0.1653
Epoch 4 [170/172] - loss: 0.1533, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1223
Epoch 4 [172/172] - loss: 0.1277

类别准确率:
positive: 0.8844 (413/467)
neutral: 0.1928 (16/83)
negative: 0.5360 (134/250)

Epoch 4/10
Train Loss: 0.1375, Train Acc: 0.9717
Val Loss: 1.0413, Val Acc: 0.7037
Epoch 5 [1/172] - loss: 0.1076, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1219
Epoch 5 [3/172] - loss: 0.1118
Epoch 5 [4/172] - loss: 0.1121
Epoch 5 [5/172] - loss: 0.1105
Epoch 5 [6/172] - loss: 0.1207
Epoch 5 [7/172] - loss: 0.1077
Epoch 5 [8/172] - loss: 0.1340
Epoch 5 [9/172] - loss: 0.1497
Epoch 5 [10/172] - loss: 0.1106, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1235
Epoch 5 [12/172] - loss: 0.1093

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2232, log_difficulty=0.2015, weight=2.0075
neutral: count=6845.0, difficulty=0.1648, log_difficulty=0.1525, weight=1.7626
negative: count=7694.0, difficulty=0.2102, log_difficulty=0.1908, weight=1.9538

当前batch的pt分布：
positive: min=0.1554, max=0.9968, mean=0.9160
neutral: min=0.9963, max=0.9994, mean=0.9979
negative: min=0.9470, max=0.9943, mean=0.9809

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0758
焦点损失: 0.0408
边界损失: 0.1523
总损失: 0.1347
Epoch 5 [13/172] - loss: 0.1347
Epoch 5 [14/172] - loss: 0.1602
Epoch 5 [15/172] - loss: 0.1121
Epoch 5 [16/172] - loss: 0.1066
Epoch 5 [17/172] - loss: 0.1124
Epoch 5 [18/172] - loss: 0.1075
Epoch 5 [19/172] - loss: 0.1805
Epoch 5 [20/172] - loss: 0.1261, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1710
Epoch 5 [22/172] - loss: 0.2437
Epoch 5 [23/172] - loss: 0.1118
Epoch 5 [24/172] - loss: 0.1420
Epoch 5 [25/172] - loss: 0.1186
Epoch 5 [26/172] - loss: 0.1641
Epoch 5 [27/172] - loss: 0.1154
Epoch 5 [28/172] - loss: 0.1368
Epoch 5 [29/172] - loss: 0.1104
Epoch 5 [30/172] - loss: 0.1219, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1129
Epoch 5 [32/172] - loss: 0.1101
Epoch 5 [33/172] - loss: 0.1264
Epoch 5 [34/172] - loss: 0.1197
Epoch 5 [35/172] - loss: 0.1137
Epoch 5 [36/172] - loss: 0.1120
Epoch 5 [37/172] - loss: 0.1200
Epoch 5 [38/172] - loss: 0.1099
Epoch 5 [39/172] - loss: 0.1647
Epoch 5 [40/172] - loss: 0.1306, acc: 0.9688
Epoch 5 [41/172] - loss: 0.1407
Epoch 5 [42/172] - loss: 0.1118
Epoch 5 [43/172] - loss: 0.1835
Epoch 5 [44/172] - loss: 0.1415
Epoch 5 [45/172] - loss: 0.1093
Epoch 5 [46/172] - loss: 0.1170
Epoch 5 [47/172] - loss: 0.1139
Epoch 5 [48/172] - loss: 0.1184
Epoch 5 [49/172] - loss: 0.1194
Epoch 5 [50/172] - loss: 0.1208, acc: 0.9688
Epoch 5 [51/172] - loss: 0.1101
Epoch 5 [52/172] - loss: 0.1141
Epoch 5 [53/172] - loss: 0.1147
Epoch 5 [54/172] - loss: 0.1155
Epoch 5 [55/172] - loss: 0.1218
Epoch 5 [56/172] - loss: 0.1092
Epoch 5 [57/172] - loss: 0.1074
Epoch 5 [58/172] - loss: 0.1074
Epoch 5 [59/172] - loss: 0.1322
Epoch 5 [60/172] - loss: 0.1151, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1332
Epoch 5 [62/172] - loss: 0.1087
Epoch 5 [63/172] - loss: 0.1268
Epoch 5 [64/172] - loss: 0.1331
Epoch 5 [65/172] - loss: 0.1388
Epoch 5 [66/172] - loss: 0.1078
Epoch 5 [67/172] - loss: 0.1084
Epoch 5 [68/172] - loss: 0.1819
Epoch 5 [69/172] - loss: 0.1146
Epoch 5 [70/172] - loss: 0.1109, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1173
Epoch 5 [72/172] - loss: 0.1112
Epoch 5 [73/172] - loss: 0.1151
Epoch 5 [74/172] - loss: 0.1292
Epoch 5 [75/172] - loss: 0.1090
Epoch 5 [76/172] - loss: 0.1082
Epoch 5 [77/172] - loss: 0.1076
Epoch 5 [78/172] - loss: 0.1318
Epoch 5 [79/172] - loss: 0.1137
Epoch 5 [80/172] - loss: 0.1089, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1804
Epoch 5 [82/172] - loss: 0.1767
Epoch 5 [83/172] - loss: 0.1115
Epoch 5 [84/172] - loss: 0.1102
Epoch 5 [85/172] - loss: 0.2041
Epoch 5 [86/172] - loss: 0.1234
Epoch 5 [87/172] - loss: 0.1247
Epoch 5 [88/172] - loss: 0.1394
Epoch 5 [89/172] - loss: 0.1071
Epoch 5 [90/172] - loss: 0.1369, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1149
Epoch 5 [92/172] - loss: 0.1090
Epoch 5 [93/172] - loss: 0.1069
Epoch 5 [94/172] - loss: 0.1079
Epoch 5 [95/172] - loss: 0.1132
Epoch 5 [96/172] - loss: 0.1252
Epoch 5 [97/172] - loss: 0.1170
Epoch 5 [98/172] - loss: 0.1105
Epoch 5 [99/172] - loss: 0.1188
Epoch 5 [100/172] - loss: 0.1376, acc: 0.9688
Epoch 5 [101/172] - loss: 0.1189
Epoch 5 [102/172] - loss: 0.1104
Epoch 5 [103/172] - loss: 0.1173
Epoch 5 [104/172] - loss: 0.1541
Epoch 5 [105/172] - loss: 0.2035
Epoch 5 [106/172] - loss: 0.1144
Epoch 5 [107/172] - loss: 0.1236
Epoch 5 [108/172] - loss: 0.1545
Epoch 5 [109/172] - loss: 0.1479
Epoch 5 [110/172] - loss: 0.1207, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1095
Epoch 5 [112/172] - loss: 0.1077

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2002, log_difficulty=0.1825, weight=1.9125
neutral: count=7825.0, difficulty=0.1479, log_difficulty=0.1379, weight=1.6896
negative: count=8780.0, difficulty=0.1904, log_difficulty=0.1743, weight=1.8715

当前batch的pt分布：
positive: min=0.7134, max=0.9937, mean=0.9326
neutral: min=0.8521, max=0.9975, mean=0.9762
negative: min=0.9967, max=0.9998, mean=0.9990

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0457
焦点损失: 0.0014
边界损失: 0.1570
总损失: 0.1184
Epoch 5 [113/172] - loss: 0.1184
Epoch 5 [114/172] - loss: 0.1400
Epoch 5 [115/172] - loss: 0.1109
Epoch 5 [116/172] - loss: 0.1179
Epoch 5 [117/172] - loss: 0.1121
Epoch 5 [118/172] - loss: 0.1081
Epoch 5 [119/172] - loss: 0.1100
Epoch 5 [120/172] - loss: 0.1313, acc: 0.9688
Epoch 5 [121/172] - loss: 0.1128
Epoch 5 [122/172] - loss: 0.1095
Epoch 5 [123/172] - loss: 0.1109
Epoch 5 [124/172] - loss: 0.1105
Epoch 5 [125/172] - loss: 0.1145
Epoch 5 [126/172] - loss: 0.1110
Epoch 5 [127/172] - loss: 0.1128
Epoch 5 [128/172] - loss: 0.1150
Epoch 5 [129/172] - loss: 0.1640
Epoch 5 [130/172] - loss: 0.1076, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1103
Epoch 5 [132/172] - loss: 0.1827
Epoch 5 [133/172] - loss: 0.1277
Epoch 5 [134/172] - loss: 0.1648
Epoch 5 [135/172] - loss: 0.1061
Epoch 5 [136/172] - loss: 0.1082
Epoch 5 [137/172] - loss: 0.1191
Epoch 5 [138/172] - loss: 0.1434
Epoch 5 [139/172] - loss: 0.2770
Epoch 5 [140/172] - loss: 0.1974, acc: 0.9688
Epoch 5 [141/172] - loss: 0.1112
Epoch 5 [142/172] - loss: 0.1659
Epoch 5 [143/172] - loss: 0.1086
Epoch 5 [144/172] - loss: 0.1076
Epoch 5 [145/172] - loss: 0.1241
Epoch 5 [146/172] - loss: 0.1098
Epoch 5 [147/172] - loss: 0.1260
Epoch 5 [148/172] - loss: 0.1062
Epoch 5 [149/172] - loss: 0.1133
Epoch 5 [150/172] - loss: 0.1745, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1192
Epoch 5 [152/172] - loss: 0.1592
Epoch 5 [153/172] - loss: 0.1058
Epoch 5 [154/172] - loss: 0.1074
Epoch 5 [155/172] - loss: 0.2061
Epoch 5 [156/172] - loss: 0.1393
Epoch 5 [157/172] - loss: 0.1103
Epoch 5 [158/172] - loss: 0.1246
Epoch 5 [159/172] - loss: 0.1102
Epoch 5 [160/172] - loss: 0.1082, acc: 1.0000
Epoch 5 [161/172] - loss: 0.1169
Epoch 5 [162/172] - loss: 0.1216
Epoch 5 [163/172] - loss: 0.1600
Epoch 5 [164/172] - loss: 0.1063
Epoch 5 [165/172] - loss: 0.1388
Epoch 5 [166/172] - loss: 0.1494
Epoch 5 [167/172] - loss: 0.1123
Epoch 5 [168/172] - loss: 0.1081
Epoch 5 [169/172] - loss: 0.1089
Epoch 5 [170/172] - loss: 0.1102, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1089
Epoch 5 [172/172] - loss: 0.1541

类别准确率:
positive: 0.9122 (426/467)
neutral: 0.2530 (21/83)
negative: 0.3720 (93/250)

Epoch 5/10
Train Loss: 0.1218, Train Acc: 0.9899
Val Loss: 1.1530, Val Acc: 0.6750
Epoch 6 [1/172] - loss: 0.1197, acc: 1.0000
Epoch 6 [2/172] - loss: 0.1204
Epoch 6 [3/172] - loss: 0.1086
Epoch 6 [4/172] - loss: 0.1082
Epoch 6 [5/172] - loss: 0.1376
Epoch 6 [6/172] - loss: 0.1102
Epoch 6 [7/172] - loss: 0.1441
Epoch 6 [8/172] - loss: 0.1141
Epoch 6 [9/172] - loss: 0.1135
Epoch 6 [10/172] - loss: 0.1110, acc: 1.0000
Epoch 6 [11/172] - loss: 0.1101
Epoch 6 [12/172] - loss: 0.1079
Epoch 6 [13/172] - loss: 0.1244
Epoch 6 [14/172] - loss: 0.1062
Epoch 6 [15/172] - loss: 0.1088
Epoch 6 [16/172] - loss: 0.1099
Epoch 6 [17/172] - loss: 0.1181
Epoch 6 [18/172] - loss: 0.1088
Epoch 6 [19/172] - loss: 0.2178
Epoch 6 [20/172] - loss: 0.1092, acc: 1.0000
Epoch 6 [21/172] - loss: 0.1164
Epoch 6 [22/172] - loss: 0.1074
Epoch 6 [23/172] - loss: 0.1240
Epoch 6 [24/172] - loss: 0.1208
Epoch 6 [25/172] - loss: 0.1110
Epoch 6 [26/172] - loss: 0.1158
Epoch 6 [27/172] - loss: 0.1243
Epoch 6 [28/172] - loss: 0.1203
Epoch 6 [29/172] - loss: 0.1062
Epoch 6 [30/172] - loss: 0.1067, acc: 1.0000
Epoch 6 [31/172] - loss: 0.1068
Epoch 6 [32/172] - loss: 0.1056
Epoch 6 [33/172] - loss: 0.1081
Epoch 6 [34/172] - loss: 0.1062
Epoch 6 [35/172] - loss: 0.1064
Epoch 6 [36/172] - loss: 0.1192
Epoch 6 [37/172] - loss: 0.1069
Epoch 6 [38/172] - loss: 0.1073
Epoch 6 [39/172] - loss: 0.1093
Epoch 6 [40/172] - loss: 0.1714, acc: 0.9375

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1820, log_difficulty=0.1672, weight=1.8359
neutral: count=8815.0, difficulty=0.1345, log_difficulty=0.1262, weight=1.6312
negative: count=9870.0, difficulty=0.1738, log_difficulty=0.1603, weight=1.8014

当前batch的pt分布：
positive: min=0.0063, max=0.9991, mean=0.9048
neutral: min=0.9491, max=0.9983, mean=0.9884
negative: min=0.9650, max=0.9957, mean=0.9857

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1686
焦点损失: 0.1563
边界损失: 0.1401
总损失: 0.1768
Epoch 6 [41/172] - loss: 0.1768
Epoch 6 [42/172] - loss: 0.1110
Epoch 6 [43/172] - loss: 0.1252
Epoch 6 [44/172] - loss: 0.1095
Epoch 6 [45/172] - loss: 0.1168
Epoch 6 [46/172] - loss: 0.1291
Epoch 6 [47/172] - loss: 0.1064
Epoch 6 [48/172] - loss: 0.1065
Epoch 6 [49/172] - loss: 0.1085
Epoch 6 [50/172] - loss: 0.1328, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1437
Epoch 6 [52/172] - loss: 0.1330
Epoch 6 [53/172] - loss: 0.1059
Epoch 6 [54/172] - loss: 0.1651
Epoch 6 [55/172] - loss: 0.1098
Epoch 6 [56/172] - loss: 0.1124
Epoch 6 [57/172] - loss: 0.1083
Epoch 6 [58/172] - loss: 0.1062
Epoch 6 [59/172] - loss: 0.1171
Epoch 6 [60/172] - loss: 0.1193, acc: 1.0000
Epoch 6 [61/172] - loss: 0.1067
Epoch 6 [62/172] - loss: 0.1263
Epoch 6 [63/172] - loss: 0.1208
Epoch 6 [64/172] - loss: 0.1552
Epoch 6 [65/172] - loss: 0.1173
Epoch 6 [66/172] - loss: 0.1093
Epoch 6 [67/172] - loss: 0.1052
Epoch 6 [68/172] - loss: 0.1355
Epoch 6 [69/172] - loss: 0.1154
Epoch 6 [70/172] - loss: 0.1096, acc: 1.0000
Epoch 6 [71/172] - loss: 0.1214
Epoch 6 [72/172] - loss: 0.1119
Epoch 6 [73/172] - loss: 0.1147
Epoch 6 [74/172] - loss: 0.1077
Epoch 6 [75/172] - loss: 0.1143
Epoch 6 [76/172] - loss: 0.1097
Epoch 6 [77/172] - loss: 0.1216
Epoch 6 [78/172] - loss: 0.1169
Epoch 6 [79/172] - loss: 0.1058
Epoch 6 [80/172] - loss: 0.1242, acc: 0.9688
Epoch 6 [81/172] - loss: 0.1845
Epoch 6 [82/172] - loss: 0.1135
Epoch 6 [83/172] - loss: 0.1108
Epoch 6 [84/172] - loss: 0.1066
Epoch 6 [85/172] - loss: 0.1187
Epoch 6 [86/172] - loss: 0.1151
Epoch 6 [87/172] - loss: 0.1090
Epoch 6 [88/172] - loss: 0.1354
Epoch 6 [89/172] - loss: 0.1078
Epoch 6 [90/172] - loss: 0.1072, acc: 1.0000
Epoch 6 [91/172] - loss: 0.1062
Epoch 6 [92/172] - loss: 0.1065
Epoch 6 [93/172] - loss: 0.1063
Epoch 6 [94/172] - loss: 0.1251
Epoch 6 [95/172] - loss: 0.1205
Epoch 6 [96/172] - loss: 0.1054
Epoch 6 [97/172] - loss: 0.1180
Epoch 6 [98/172] - loss: 0.1099
Epoch 6 [99/172] - loss: 0.1063
Epoch 6 [100/172] - loss: 0.1058, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1128
Epoch 6 [102/172] - loss: 0.1071
Epoch 6 [103/172] - loss: 0.1181
Epoch 6 [104/172] - loss: 0.1442
Epoch 6 [105/172] - loss: 0.1065
Epoch 6 [106/172] - loss: 0.1162
Epoch 6 [107/172] - loss: 0.1067
Epoch 6 [108/172] - loss: 0.1056
Epoch 6 [109/172] - loss: 0.1464
Epoch 6 [110/172] - loss: 0.1217, acc: 0.9688
Epoch 6 [111/172] - loss: 0.1057
Epoch 6 [112/172] - loss: 0.1052
Epoch 6 [113/172] - loss: 0.1225
Epoch 6 [114/172] - loss: 0.1113
Epoch 6 [115/172] - loss: 0.1256
Epoch 6 [116/172] - loss: 0.1587
Epoch 6 [117/172] - loss: 0.1066
Epoch 6 [118/172] - loss: 0.1058
Epoch 6 [119/172] - loss: 0.1422
Epoch 6 [120/172] - loss: 0.1080, acc: 1.0000
Epoch 6 [121/172] - loss: 0.1130
Epoch 6 [122/172] - loss: 0.1167
Epoch 6 [123/172] - loss: 0.1072
Epoch 6 [124/172] - loss: 0.1066
Epoch 6 [125/172] - loss: 0.1155
Epoch 6 [126/172] - loss: 0.1474
Epoch 6 [127/172] - loss: 0.1463
Epoch 6 [128/172] - loss: 0.1829
Epoch 6 [129/172] - loss: 0.1070
Epoch 6 [130/172] - loss: 0.1157, acc: 1.0000
Epoch 6 [131/172] - loss: 0.1130
Epoch 6 [132/172] - loss: 0.1121
Epoch 6 [133/172] - loss: 0.1046
Epoch 6 [134/172] - loss: 0.1057
Epoch 6 [135/172] - loss: 0.1055
Epoch 6 [136/172] - loss: 0.1088
Epoch 6 [137/172] - loss: 0.1073
Epoch 6 [138/172] - loss: 0.1090
Epoch 6 [139/172] - loss: 0.1126
Epoch 6 [140/172] - loss: 0.1120, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1667, log_difficulty=0.1542, weight=1.7709
neutral: count=9796.0, difficulty=0.1240, log_difficulty=0.1169, weight=1.5844
negative: count=10972.0, difficulty=0.1598, log_difficulty=0.1482, weight=1.7411

当前batch的pt分布：
positive: min=0.9849, max=0.9990, mean=0.9955
neutral: min=0.9735, max=0.9990, mean=0.9899
negative: min=0.9580, max=0.9940, mean=0.9813

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0122
焦点损失: 0.0000
边界损失: 0.1409
总损失: 0.1057
Epoch 6 [141/172] - loss: 0.1057
Epoch 6 [142/172] - loss: 0.1062
Epoch 6 [143/172] - loss: 0.1065
Epoch 6 [144/172] - loss: 0.1086
Epoch 6 [145/172] - loss: 0.1062
Epoch 6 [146/172] - loss: 0.1056
Epoch 6 [147/172] - loss: 0.1246
Epoch 6 [148/172] - loss: 0.1212
Epoch 6 [149/172] - loss: 0.1090
Epoch 6 [150/172] - loss: 0.1072, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1079
Epoch 6 [152/172] - loss: 0.1176
Epoch 6 [153/172] - loss: 0.1051
Epoch 6 [154/172] - loss: 0.1062
Epoch 6 [155/172] - loss: 0.1194
Epoch 6 [156/172] - loss: 0.1180
Epoch 6 [157/172] - loss: 0.1066
Epoch 6 [158/172] - loss: 0.1119
Epoch 6 [159/172] - loss: 0.1067
Epoch 6 [160/172] - loss: 0.1290, acc: 0.9688
Epoch 6 [161/172] - loss: 0.1065
Epoch 6 [162/172] - loss: 0.1058
Epoch 6 [163/172] - loss: 0.1074
Epoch 6 [164/172] - loss: 0.1211
Epoch 6 [165/172] - loss: 0.1992
Epoch 6 [166/172] - loss: 0.1080
Epoch 6 [167/172] - loss: 0.1065
Epoch 6 [168/172] - loss: 0.1059
Epoch 6 [169/172] - loss: 0.1351
Epoch 6 [170/172] - loss: 0.1057, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1092
Epoch 6 [172/172] - loss: 0.1085

类别准确率:
positive: 0.8779 (410/467)
neutral: 0.2410 (20/83)
negative: 0.5960 (149/250)

Epoch 6/10
Train Loss: 0.1171, Train Acc: 0.9919
Val Loss: 1.0707, Val Acc: 0.7238
Epoch 7 [1/172] - loss: 0.1077, acc: 1.0000
Epoch 7 [2/172] - loss: 0.1057
Epoch 7 [3/172] - loss: 0.1060
Epoch 7 [4/172] - loss: 0.1136
Epoch 7 [5/172] - loss: 0.1054
Epoch 7 [6/172] - loss: 0.1048
Epoch 7 [7/172] - loss: 0.1064
Epoch 7 [8/172] - loss: 0.1192
Epoch 7 [9/172] - loss: 0.1069
Epoch 7 [10/172] - loss: 0.1048, acc: 1.0000
Epoch 7 [11/172] - loss: 0.1127
Epoch 7 [12/172] - loss: 0.1186
Epoch 7 [13/172] - loss: 0.1099
Epoch 7 [14/172] - loss: 0.1108
Epoch 7 [15/172] - loss: 0.1169
Epoch 7 [16/172] - loss: 0.1078
Epoch 7 [17/172] - loss: 0.1386
Epoch 7 [18/172] - loss: 0.1067
Epoch 7 [19/172] - loss: 0.1088
Epoch 7 [20/172] - loss: 0.1051, acc: 1.0000
Epoch 7 [21/172] - loss: 0.1166
Epoch 7 [22/172] - loss: 0.1095
Epoch 7 [23/172] - loss: 0.1047
Epoch 7 [24/172] - loss: 0.1057
Epoch 7 [25/172] - loss: 0.1055
Epoch 7 [26/172] - loss: 0.1289
Epoch 7 [27/172] - loss: 0.1079
Epoch 7 [28/172] - loss: 0.1078
Epoch 7 [29/172] - loss: 0.1148
Epoch 7 [30/172] - loss: 0.1353, acc: 0.9688
Epoch 7 [31/172] - loss: 0.1063
Epoch 7 [32/172] - loss: 0.1049
Epoch 7 [33/172] - loss: 0.1150
Epoch 7 [34/172] - loss: 0.1105
Epoch 7 [35/172] - loss: 0.1049
Epoch 7 [36/172] - loss: 0.1316
Epoch 7 [37/172] - loss: 0.1066
Epoch 7 [38/172] - loss: 0.1053
Epoch 7 [39/172] - loss: 0.1086
Epoch 7 [40/172] - loss: 0.1046, acc: 1.0000
Epoch 7 [41/172] - loss: 0.1521
Epoch 7 [42/172] - loss: 0.1061
Epoch 7 [43/172] - loss: 0.1059
Epoch 7 [44/172] - loss: 0.1107
Epoch 7 [45/172] - loss: 0.1098
Epoch 7 [46/172] - loss: 0.1160
Epoch 7 [47/172] - loss: 0.1280
Epoch 7 [48/172] - loss: 0.1066
Epoch 7 [49/172] - loss: 0.1049
Epoch 7 [50/172] - loss: 0.1052, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1479
Epoch 7 [52/172] - loss: 0.1091
Epoch 7 [53/172] - loss: 0.1045
Epoch 7 [54/172] - loss: 0.1184
Epoch 7 [55/172] - loss: 0.1077
Epoch 7 [56/172] - loss: 0.1074
Epoch 7 [57/172] - loss: 0.1158
Epoch 7 [58/172] - loss: 0.1177
Epoch 7 [59/172] - loss: 0.1065
Epoch 7 [60/172] - loss: 0.2022, acc: 0.9688
Epoch 7 [61/172] - loss: 0.1163
Epoch 7 [62/172] - loss: 0.1090
Epoch 7 [63/172] - loss: 0.1455
Epoch 7 [64/172] - loss: 0.1074
Epoch 7 [65/172] - loss: 0.1200
Epoch 7 [66/172] - loss: 0.1063
Epoch 7 [67/172] - loss: 0.1166
Epoch 7 [68/172] - loss: 0.1189

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1540, log_difficulty=0.1432, weight=1.7160
neutral: count=10756.0, difficulty=0.1146, log_difficulty=0.1085, weight=1.5424
negative: count=12072.0, difficulty=0.1477, log_difficulty=0.1378, weight=1.6890

当前batch的pt分布：
positive: min=0.9871, max=0.9990, mean=0.9941
neutral: min=0.9878, max=0.9995, mean=0.9961
negative: min=0.9616, max=0.9933, mean=0.9780

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0126
焦点损失: 0.0000
边界损失: 0.1409
总损失: 0.1057
Epoch 7 [69/172] - loss: 0.1057
Epoch 7 [70/172] - loss: 0.1085, acc: 1.0000
Epoch 7 [71/172] - loss: 0.1080
Epoch 7 [72/172] - loss: 0.1078
Epoch 7 [73/172] - loss: 0.1099
Epoch 7 [74/172] - loss: 0.1052
Epoch 7 [75/172] - loss: 0.1052
Epoch 7 [76/172] - loss: 0.1124
Epoch 7 [77/172] - loss: 0.1085
Epoch 7 [78/172] - loss: 0.1074
Epoch 7 [79/172] - loss: 0.1180
Epoch 7 [80/172] - loss: 0.1250, acc: 0.9688
Epoch 7 [81/172] - loss: 0.1057
Epoch 7 [82/172] - loss: 0.1063
Epoch 7 [83/172] - loss: 0.1359
Epoch 7 [84/172] - loss: 0.1088
Epoch 7 [85/172] - loss: 0.1101
Epoch 7 [86/172] - loss: 0.1066
Epoch 7 [87/172] - loss: 0.1075
Epoch 7 [88/172] - loss: 0.1073
Epoch 7 [89/172] - loss: 0.1085
Epoch 7 [90/172] - loss: 0.1062, acc: 1.0000
Epoch 7 [91/172] - loss: 0.1063
Epoch 7 [92/172] - loss: 0.1068
Epoch 7 [93/172] - loss: 0.1201
Epoch 7 [94/172] - loss: 0.1122
Epoch 7 [95/172] - loss: 0.1064
Epoch 7 [96/172] - loss: 0.1063
Epoch 7 [97/172] - loss: 0.1114
Epoch 7 [98/172] - loss: 0.1289
Epoch 7 [99/172] - loss: 0.1048
Epoch 7 [100/172] - loss: 0.1057, acc: 1.0000
Epoch 7 [101/172] - loss: 0.1079
Epoch 7 [102/172] - loss: 0.1065
Epoch 7 [103/172] - loss: 0.1045
Epoch 7 [104/172] - loss: 0.1055
Epoch 7 [105/172] - loss: 0.1239
Epoch 7 [106/172] - loss: 0.1232
Epoch 7 [107/172] - loss: 0.1052
Epoch 7 [108/172] - loss: 0.1056
Epoch 7 [109/172] - loss: 0.1230
Epoch 7 [110/172] - loss: 0.1090, acc: 1.0000
Epoch 7 [111/172] - loss: 0.1068
Epoch 7 [112/172] - loss: 0.1167
Epoch 7 [113/172] - loss: 0.1058
Epoch 7 [114/172] - loss: 0.1062
Epoch 7 [115/172] - loss: 0.1068
Epoch 7 [116/172] - loss: 0.1316
Epoch 7 [117/172] - loss: 0.1096
Epoch 7 [118/172] - loss: 0.1147
Epoch 7 [119/172] - loss: 0.1099
Epoch 7 [120/172] - loss: 0.1073, acc: 1.0000
Epoch 7 [121/172] - loss: 0.1093
Epoch 7 [122/172] - loss: 0.1056
Epoch 7 [123/172] - loss: 0.1053
Epoch 7 [124/172] - loss: 0.1216
Epoch 7 [125/172] - loss: 0.1057
Epoch 7 [126/172] - loss: 0.1051
Epoch 7 [127/172] - loss: 0.1078
Epoch 7 [128/172] - loss: 0.1057
Epoch 7 [129/172] - loss: 0.1083
Epoch 7 [130/172] - loss: 0.1074, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1396
Epoch 7 [132/172] - loss: 0.1765
Epoch 7 [133/172] - loss: 0.1044
Epoch 7 [134/172] - loss: 0.1098
Epoch 7 [135/172] - loss: 0.1117
Epoch 7 [136/172] - loss: 0.1062
Epoch 7 [137/172] - loss: 0.1127
Epoch 7 [138/172] - loss: 0.1039
Epoch 7 [139/172] - loss: 0.1184
Epoch 7 [140/172] - loss: 0.1065, acc: 1.0000
Epoch 7 [141/172] - loss: 0.1429
Epoch 7 [142/172] - loss: 0.1081
Epoch 7 [143/172] - loss: 0.1118
Epoch 7 [144/172] - loss: 0.1116
Epoch 7 [145/172] - loss: 0.1201
Epoch 7 [146/172] - loss: 0.1804
Epoch 7 [147/172] - loss: 0.1105
Epoch 7 [148/172] - loss: 0.1104
Epoch 7 [149/172] - loss: 0.1059
Epoch 7 [150/172] - loss: 0.1056, acc: 1.0000
Epoch 7 [151/172] - loss: 0.2193
Epoch 7 [152/172] - loss: 0.1069
Epoch 7 [153/172] - loss: 0.1059
Epoch 7 [154/172] - loss: 0.1141
Epoch 7 [155/172] - loss: 0.1063
Epoch 7 [156/172] - loss: 0.1438
Epoch 7 [157/172] - loss: 0.1057
Epoch 7 [158/172] - loss: 0.1133
Epoch 7 [159/172] - loss: 0.1067
Epoch 7 [160/172] - loss: 0.1104, acc: 1.0000
Epoch 7 [161/172] - loss: 0.1055
Epoch 7 [162/172] - loss: 0.1160
Epoch 7 [163/172] - loss: 0.1091
Epoch 7 [164/172] - loss: 0.1212
Epoch 7 [165/172] - loss: 0.1305
Epoch 7 [166/172] - loss: 0.1059
Epoch 7 [167/172] - loss: 0.1211
Epoch 7 [168/172] - loss: 0.1130

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1431, log_difficulty=0.1337, weight=1.6687
neutral: count=11731.0, difficulty=0.1070, log_difficulty=0.1017, weight=1.5083
negative: count=13173.0, difficulty=0.1375, log_difficulty=0.1288, weight=1.6441

当前batch的pt分布：
positive: min=0.9880, max=0.9987, mean=0.9942
neutral: min=0.9866, max=0.9992, mean=0.9951
negative: min=0.9301, max=0.9957, mean=0.9850

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0091
焦点损失: 0.0000
边界损失: 0.1394
总损失: 0.1045
Epoch 7 [169/172] - loss: 0.1045
Epoch 7 [170/172] - loss: 0.1102, acc: 1.0000
Epoch 7 [171/172] - loss: 0.1061
Epoch 7 [172/172] - loss: 0.1043

类别准确率:
positive: 0.8394 (392/467)
neutral: 0.2651 (22/83)
negative: 0.6360 (159/250)

Epoch 7/10
Train Loss: 0.1115, Train Acc: 0.9939
Val Loss: 1.0713, Val Acc: 0.7163
Epoch 8 [1/172] - loss: 0.1058, acc: 1.0000
Epoch 8 [2/172] - loss: 0.1261
Epoch 8 [3/172] - loss: 0.1062
Epoch 8 [4/172] - loss: 0.1051
Epoch 8 [5/172] - loss: 0.1060
Epoch 8 [6/172] - loss: 0.1173
Epoch 8 [7/172] - loss: 0.1063
Epoch 8 [8/172] - loss: 0.1051
Epoch 8 [9/172] - loss: 0.1714
Epoch 8 [10/172] - loss: 0.1204, acc: 0.9688
Epoch 8 [11/172] - loss: 0.1158
Epoch 8 [12/172] - loss: 0.1492
Epoch 8 [13/172] - loss: 0.1063
Epoch 8 [14/172] - loss: 0.1058
Epoch 8 [15/172] - loss: 0.1100
Epoch 8 [16/172] - loss: 0.1146
Epoch 8 [17/172] - loss: 0.1058
Epoch 8 [18/172] - loss: 0.1061
Epoch 8 [19/172] - loss: 0.1103
Epoch 8 [20/172] - loss: 0.1056, acc: 1.0000
Epoch 8 [21/172] - loss: 0.1066
Epoch 8 [22/172] - loss: 0.1114
Epoch 8 [23/172] - loss: 0.1099
Epoch 8 [24/172] - loss: 0.1085
Epoch 8 [25/172] - loss: 0.1065
Epoch 8 [26/172] - loss: 0.1079
Epoch 8 [27/172] - loss: 0.1197
Epoch 8 [28/172] - loss: 0.1180
Epoch 8 [29/172] - loss: 0.1063
Epoch 8 [30/172] - loss: 0.1039, acc: 1.0000
Epoch 8 [31/172] - loss: 0.1055
Epoch 8 [32/172] - loss: 0.1056
Epoch 8 [33/172] - loss: 0.1069
Epoch 8 [34/172] - loss: 0.1054
Epoch 8 [35/172] - loss: 0.1083
Epoch 8 [36/172] - loss: 0.1093
Epoch 8 [37/172] - loss: 0.1135
Epoch 8 [38/172] - loss: 0.1179
Epoch 8 [39/172] - loss: 0.1092
Epoch 8 [40/172] - loss: 0.1077, acc: 1.0000
Epoch 8 [41/172] - loss: 0.1090
Epoch 8 [42/172] - loss: 0.1275
Epoch 8 [43/172] - loss: 0.1108
Epoch 8 [44/172] - loss: 0.1077
Epoch 8 [45/172] - loss: 0.1082
Epoch 8 [46/172] - loss: 0.1052
Epoch 8 [47/172] - loss: 0.1052
Epoch 8 [48/172] - loss: 0.1260
Epoch 8 [49/172] - loss: 0.1065
Epoch 8 [50/172] - loss: 0.1067, acc: 1.0000
Epoch 8 [51/172] - loss: 0.1059
Epoch 8 [52/172] - loss: 0.1049
Epoch 8 [53/172] - loss: 0.1117
Epoch 8 [54/172] - loss: 0.1153
Epoch 8 [55/172] - loss: 0.1048
Epoch 8 [56/172] - loss: 0.1375
Epoch 8 [57/172] - loss: 0.1070
Epoch 8 [58/172] - loss: 0.1074
Epoch 8 [59/172] - loss: 0.1066
Epoch 8 [60/172] - loss: 0.1059, acc: 1.0000
Epoch 8 [61/172] - loss: 0.1062
Epoch 8 [62/172] - loss: 0.1049
Epoch 8 [63/172] - loss: 0.1046
Epoch 8 [64/172] - loss: 0.1046
Epoch 8 [65/172] - loss: 0.1050
Epoch 8 [66/172] - loss: 0.1215
Epoch 8 [67/172] - loss: 0.1056
Epoch 8 [68/172] - loss: 0.1047
Epoch 8 [69/172] - loss: 0.1061
Epoch 8 [70/172] - loss: 0.1061, acc: 1.0000
Epoch 8 [71/172] - loss: 0.1195
Epoch 8 [72/172] - loss: 0.1049
Epoch 8 [73/172] - loss: 0.1236
Epoch 8 [74/172] - loss: 0.1370
Epoch 8 [75/172] - loss: 0.1050
Epoch 8 [76/172] - loss: 0.1448
Epoch 8 [77/172] - loss: 0.1057
Epoch 8 [78/172] - loss: 0.1425
Epoch 8 [79/172] - loss: 0.1092
Epoch 8 [80/172] - loss: 0.1099, acc: 1.0000
Epoch 8 [81/172] - loss: 0.1070
Epoch 8 [82/172] - loss: 0.1057
Epoch 8 [83/172] - loss: 0.1048
Epoch 8 [84/172] - loss: 0.1044
Epoch 8 [85/172] - loss: 0.1085
Epoch 8 [86/172] - loss: 0.1083
Epoch 8 [87/172] - loss: 0.1045
Epoch 8 [88/172] - loss: 0.1169
Epoch 8 [89/172] - loss: 0.1046
Epoch 8 [90/172] - loss: 0.1140, acc: 1.0000
Epoch 8 [91/172] - loss: 0.1639
Epoch 8 [92/172] - loss: 0.1160
Epoch 8 [93/172] - loss: 0.1110
Epoch 8 [94/172] - loss: 0.1120
Epoch 8 [95/172] - loss: 0.1066
Epoch 8 [96/172] - loss: 0.1053

=== 第 1301 次迭代调试信息 ===
当前类别统计：
positive: count=14487.0, difficulty=0.1341, log_difficulty=0.1258, weight=1.6292
neutral: count=12738.0, difficulty=0.1001, log_difficulty=0.0954, weight=1.4772
negative: count=14288.0, difficulty=0.1287, log_difficulty=0.1211, weight=1.6053

当前batch的pt分布：
positive: min=0.9758, max=0.9989, mean=0.9919
neutral: min=0.2976, max=0.9933, mean=0.9131
negative: min=0.9618, max=0.9997, mean=0.9936

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9333
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0620
焦点损失: 0.0209
边界损失: 0.1522
总损失: 0.1218
Epoch 8 [97/172] - loss: 0.1218
Epoch 8 [98/172] - loss: 0.1074
Epoch 8 [99/172] - loss: 0.1140
Epoch 8 [100/172] - loss: 0.1074, acc: 1.0000
Epoch 8 [101/172] - loss: 0.1080
Epoch 8 [102/172] - loss: 0.1124
Epoch 8 [103/172] - loss: 0.1182
Epoch 8 [104/172] - loss: 0.1138
Epoch 8 [105/172] - loss: 0.1057
Epoch 8 [106/172] - loss: 0.1059
Epoch 8 [107/172] - loss: 0.1062
Epoch 8 [108/172] - loss: 0.1080
Epoch 8 [109/172] - loss: 0.1324
Epoch 8 [110/172] - loss: 0.1215, acc: 0.9688
Epoch 8 [111/172] - loss: 0.1478
Epoch 8 [112/172] - loss: 0.1202
Epoch 8 [113/172] - loss: 0.1047
Epoch 8 [114/172] - loss: 0.1058
Epoch 8 [115/172] - loss: 0.1053
Epoch 8 [116/172] - loss: 0.1047
Epoch 8 [117/172] - loss: 0.1055
Epoch 8 [118/172] - loss: 0.1070
Epoch 8 [119/172] - loss: 0.1047
Epoch 8 [120/172] - loss: 0.1084, acc: 1.0000
Epoch 8 [121/172] - loss: 0.1364
Epoch 8 [122/172] - loss: 0.1070
Epoch 8 [123/172] - loss: 0.1146
Epoch 8 [124/172] - loss: 0.1103
Epoch 8 [125/172] - loss: 0.1114
Epoch 8 [126/172] - loss: 0.1049
Epoch 8 [127/172] - loss: 0.1397
Epoch 8 [128/172] - loss: 0.1318
Epoch 8 [129/172] - loss: 0.1083
Epoch 8 [130/172] - loss: 0.1061, acc: 1.0000
Epoch 8 [131/172] - loss: 0.1080
Epoch 8 [132/172] - loss: 0.1048
Epoch 8 [133/172] - loss: 0.1081
Epoch 8 [134/172] - loss: 0.1151
Epoch 8 [135/172] - loss: 0.1047
Epoch 8 [136/172] - loss: 0.1070
Epoch 8 [137/172] - loss: 0.1070
Epoch 8 [138/172] - loss: 0.1636
Epoch 8 [139/172] - loss: 0.1070
Epoch 8 [140/172] - loss: 0.1046, acc: 1.0000
Epoch 8 [141/172] - loss: 0.1043
Epoch 8 [142/172] - loss: 0.1072
Epoch 8 [143/172] - loss: 0.1146
Epoch 8 [144/172] - loss: 0.1153
Epoch 8 [145/172] - loss: 0.1082
Epoch 8 [146/172] - loss: 0.1046
Epoch 8 [147/172] - loss: 0.1090
Epoch 8 [148/172] - loss: 0.1177
Epoch 8 [149/172] - loss: 0.1062
Epoch 8 [150/172] - loss: 0.1063, acc: 1.0000
Epoch 8 [151/172] - loss: 0.1111
Epoch 8 [152/172] - loss: 0.1340
Epoch 8 [153/172] - loss: 0.1078
Epoch 8 [154/172] - loss: 0.1217
Epoch 8 [155/172] - loss: 0.1052
Epoch 8 [156/172] - loss: 0.1067
Epoch 8 [157/172] - loss: 0.1092
Epoch 8 [158/172] - loss: 0.1069
Epoch 8 [159/172] - loss: 0.1131
Epoch 8 [160/172] - loss: 0.1114, acc: 1.0000
Epoch 8 [161/172] - loss: 0.1074
Epoch 8 [162/172] - loss: 0.1212
Epoch 8 [163/172] - loss: 0.1061
Epoch 8 [164/172] - loss: 0.1095
Epoch 8 [165/172] - loss: 0.1045
Epoch 8 [166/172] - loss: 0.1100
Epoch 8 [167/172] - loss: 0.1041
Epoch 8 [168/172] - loss: 0.1089
Epoch 8 [169/172] - loss: 0.1179
Epoch 8 [170/172] - loss: 0.1072, acc: 1.0000
Epoch 8 [171/172] - loss: 0.1152
Epoch 8 [172/172] - loss: 0.1049

类别准确率:
positive: 0.8801 (411/467)
neutral: 0.2410 (20/83)
negative: 0.5880 (147/250)

Epoch 8/10
Train Loss: 0.1098, Train Acc: 0.9960
Val Loss: 1.1220, Val Acc: 0.7225
Epoch 9 [1/172] - loss: 0.1266, acc: 0.9688
Epoch 9 [2/172] - loss: 0.1083
Epoch 9 [3/172] - loss: 0.1053
Epoch 9 [4/172] - loss: 0.1064
Epoch 9 [5/172] - loss: 0.1050
Epoch 9 [6/172] - loss: 0.1051
Epoch 9 [7/172] - loss: 0.1113
Epoch 9 [8/172] - loss: 0.1221
Epoch 9 [9/172] - loss: 0.1056
Epoch 9 [10/172] - loss: 0.1055, acc: 1.0000
Epoch 9 [11/172] - loss: 0.1039
Epoch 9 [12/172] - loss: 0.1113
Epoch 9 [13/172] - loss: 0.1054
Epoch 9 [14/172] - loss: 0.1150
Epoch 9 [15/172] - loss: 0.1159
Epoch 9 [16/172] - loss: 0.1061
Epoch 9 [17/172] - loss: 0.1069
Epoch 9 [18/172] - loss: 0.1044
Epoch 9 [19/172] - loss: 0.1132
Epoch 9 [20/172] - loss: 0.1055, acc: 1.0000
Epoch 9 [21/172] - loss: 0.1048
Epoch 9 [22/172] - loss: 0.1056
Epoch 9 [23/172] - loss: 0.1051
Epoch 9 [24/172] - loss: 0.1052

=== 第 1401 次迭代调试信息 ===
当前类别统计：
positive: count=15648.0, difficulty=0.1259, log_difficulty=0.1186, weight=1.5930
neutral: count=13691.0, difficulty=0.0944, log_difficulty=0.0902, weight=1.4511
negative: count=15357.0, difficulty=0.1212, log_difficulty=0.1144, weight=1.5720

当前batch的pt分布：
positive: min=0.9808, max=0.9982, mean=0.9919
neutral: min=0.9861, max=0.9991, mean=0.9927
negative: min=0.6192, max=0.9980, mean=0.9598

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0220
焦点损失: 0.0025
边界损失: 0.1448
总损失: 0.1096
Epoch 9 [25/172] - loss: 0.1096
Epoch 9 [26/172] - loss: 0.1059
Epoch 9 [27/172] - loss: 0.1084
Epoch 9 [28/172] - loss: 0.1481
Epoch 9 [29/172] - loss: 0.1084
Epoch 9 [30/172] - loss: 0.1084, acc: 1.0000
Epoch 9 [31/172] - loss: 0.1113
Epoch 9 [32/172] - loss: 0.1057
Epoch 9 [33/172] - loss: 0.1429
Epoch 9 [34/172] - loss: 0.1203
Epoch 9 [35/172] - loss: 0.1047
Epoch 9 [36/172] - loss: 0.1059
Epoch 9 [37/172] - loss: 0.1113
Epoch 9 [38/172] - loss: 0.1236
Epoch 9 [39/172] - loss: 0.1067
Epoch 9 [40/172] - loss: 0.1052, acc: 1.0000
Epoch 9 [41/172] - loss: 0.1055
Epoch 9 [42/172] - loss: 0.1048
Epoch 9 [43/172] - loss: 0.1052
Epoch 9 [44/172] - loss: 0.1127
Epoch 9 [45/172] - loss: 0.1060
Epoch 9 [46/172] - loss: 0.1058
Epoch 9 [47/172] - loss: 0.1049
Epoch 9 [48/172] - loss: 0.1061
Epoch 9 [49/172] - loss: 0.1203
Epoch 9 [50/172] - loss: 0.1043, acc: 1.0000
Epoch 9 [51/172] - loss: 0.1053
Epoch 9 [52/172] - loss: 0.1077
Epoch 9 [53/172] - loss: 0.1069
Epoch 9 [54/172] - loss: 0.1148
Epoch 9 [55/172] - loss: 0.1175
Epoch 9 [56/172] - loss: 0.1047
Epoch 9 [57/172] - loss: 0.1050
Epoch 9 [58/172] - loss: 0.1074
Epoch 9 [59/172] - loss: 0.1192
Epoch 9 [60/172] - loss: 0.1436, acc: 0.9688
Epoch 9 [61/172] - loss: 0.1107
Epoch 9 [62/172] - loss: 0.1052
Epoch 9 [63/172] - loss: 0.1274
Epoch 9 [64/172] - loss: 0.1069
Epoch 9 [65/172] - loss: 0.1044
Epoch 9 [66/172] - loss: 0.1072
Epoch 9 [67/172] - loss: 0.1195
Epoch 9 [68/172] - loss: 0.1056
Epoch 9 [69/172] - loss: 0.1044
Epoch 9 [70/172] - loss: 0.1064, acc: 1.0000
Epoch 9 [71/172] - loss: 0.1072
Epoch 9 [72/172] - loss: 0.1236
Epoch 9 [73/172] - loss: 0.1045
Epoch 9 [74/172] - loss: 0.1057
Epoch 9 [75/172] - loss: 0.1066
Epoch 9 [76/172] - loss: 0.1040
Epoch 9 [77/172] - loss: 0.1144
Epoch 9 [78/172] - loss: 0.1094
Epoch 9 [79/172] - loss: 0.1438
Epoch 9 [80/172] - loss: 0.1163, acc: 0.9688
Epoch 9 [81/172] - loss: 0.1103
Epoch 9 [82/172] - loss: 0.1432
Epoch 9 [83/172] - loss: 0.1053
Epoch 9 [84/172] - loss: 0.1067
Epoch 9 [85/172] - loss: 0.1064
Epoch 9 [86/172] - loss: 0.1108
Epoch 9 [87/172] - loss: 0.1093
Epoch 9 [88/172] - loss: 0.1044
Epoch 9 [89/172] - loss: 0.1404
Epoch 9 [90/172] - loss: 0.1049, acc: 1.0000
Epoch 9 [91/172] - loss: 0.1099
Epoch 9 [92/172] - loss: 0.1070
Epoch 9 [93/172] - loss: 0.1090
Epoch 9 [94/172] - loss: 0.1047
Epoch 9 [95/172] - loss: 0.1066
Epoch 9 [96/172] - loss: 0.1095
Epoch 9 [97/172] - loss: 0.1046
Epoch 9 [98/172] - loss: 0.1179
Epoch 9 [99/172] - loss: 0.1070
Epoch 9 [100/172] - loss: 0.1542, acc: 0.9375
Epoch 9 [101/172] - loss: 0.1048
Epoch 9 [102/172] - loss: 0.1061
Epoch 9 [103/172] - loss: 0.1096
Epoch 9 [104/172] - loss: 0.1278
Epoch 9 [105/172] - loss: 0.1065
Epoch 9 [106/172] - loss: 0.1059
Epoch 9 [107/172] - loss: 0.1141
Epoch 9 [108/172] - loss: 0.1075
Epoch 9 [109/172] - loss: 0.1330
Epoch 9 [110/172] - loss: 0.1097, acc: 1.0000
Epoch 9 [111/172] - loss: 0.1069
Epoch 9 [112/172] - loss: 0.1156
Epoch 9 [113/172] - loss: 0.1049
Epoch 9 [114/172] - loss: 0.1053
Epoch 9 [115/172] - loss: 0.1119
Epoch 9 [116/172] - loss: 0.1055
Epoch 9 [117/172] - loss: 0.1086
Epoch 9 [118/172] - loss: 0.1223
Epoch 9 [119/172] - loss: 0.1085
Epoch 9 [120/172] - loss: 0.1141, acc: 1.0000
Epoch 9 [121/172] - loss: 0.1045
Epoch 9 [122/172] - loss: 0.1309
Epoch 9 [123/172] - loss: 0.1047
Epoch 9 [124/172] - loss: 0.1058

=== 第 1501 次迭代调试信息 ===
当前类别统计：
positive: count=16764.0, difficulty=0.1188, log_difficulty=0.1123, weight=1.5614
neutral: count=14673.0, difficulty=0.0895, log_difficulty=0.0857, weight=1.4285
negative: count=16459.0, difficulty=0.1147, log_difficulty=0.1086, weight=1.5431

当前batch的pt分布：
positive: min=0.9138, max=0.9955, mean=0.9721
neutral: min=0.9552, max=0.9991, mean=0.9893
negative: min=0.9987, max=0.9998, mean=0.9994

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0177
焦点损失: 0.0001
边界损失: 0.1435
总损失: 0.1076
Epoch 9 [125/172] - loss: 0.1076
Epoch 9 [126/172] - loss: 0.1091
Epoch 9 [127/172] - loss: 0.1055
Epoch 9 [128/172] - loss: 0.1077
Epoch 9 [129/172] - loss: 0.1119
Epoch 9 [130/172] - loss: 0.1058, acc: 1.0000
Epoch 9 [131/172] - loss: 0.1055
Epoch 9 [132/172] - loss: 0.1202
Epoch 9 [133/172] - loss: 0.1199
Epoch 9 [134/172] - loss: 0.1101
Epoch 9 [135/172] - loss: 0.1074
Epoch 9 [136/172] - loss: 0.1081
Epoch 9 [137/172] - loss: 0.1132
Epoch 9 [138/172] - loss: 0.1067
Epoch 9 [139/172] - loss: 0.1204
Epoch 9 [140/172] - loss: 0.1054, acc: 1.0000
Epoch 9 [141/172] - loss: 0.1049
Epoch 9 [142/172] - loss: 0.1058
Epoch 9 [143/172] - loss: 0.1355
Epoch 9 [144/172] - loss: 0.1056
Epoch 9 [145/172] - loss: 0.1165
Epoch 9 [146/172] - loss: 0.1045
Epoch 9 [147/172] - loss: 0.1131
Epoch 9 [148/172] - loss: 0.1055
Epoch 9 [149/172] - loss: 0.1247
Epoch 9 [150/172] - loss: 0.1062, acc: 1.0000
Epoch 9 [151/172] - loss: 0.1052
Epoch 9 [152/172] - loss: 0.1064
Epoch 9 [153/172] - loss: 0.1084
Epoch 9 [154/172] - loss: 0.1083
Epoch 9 [155/172] - loss: 0.1055
Epoch 9 [156/172] - loss: 0.1358
Epoch 9 [157/172] - loss: 0.1070
Epoch 9 [158/172] - loss: 0.1082
Epoch 9 [159/172] - loss: 0.1057
Epoch 9 [160/172] - loss: 0.1051, acc: 1.0000
Epoch 9 [161/172] - loss: 0.1055
Epoch 9 [162/172] - loss: 0.1209
Epoch 9 [163/172] - loss: 0.1054
Epoch 9 [164/172] - loss: 0.1056
Epoch 9 [165/172] - loss: 0.1080
Epoch 9 [166/172] - loss: 0.1067
Epoch 9 [167/172] - loss: 0.1083
Epoch 9 [168/172] - loss: 0.1057
Epoch 9 [169/172] - loss: 0.1078
Epoch 9 [170/172] - loss: 0.1071, acc: 1.0000
Epoch 9 [171/172] - loss: 0.1113
Epoch 9 [172/172] - loss: 0.1085

类别准确率:
positive: 0.8565 (400/467)
neutral: 0.2651 (22/83)
negative: 0.6200 (155/250)

Epoch 9/10
Train Loss: 0.1079, Train Acc: 0.9980
Val Loss: 1.0735, Val Acc: 0.7212
Early stopping triggered!
Best validation accuracy: 0.7238

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_055529-xq2zycg9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.3_Multimodal_iterations_20250118_055527
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/xq2zycg9
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█
wandb:  train_acc ▁▅▅▅▇▇▇▆▇▆▇▇████████████████████████████
wandb: train_loss █▇▆▅▅▃▃▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1546
wandb:  train_acc 1
wandb: train_loss 0.1071
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.3_Multimodal_iterations_20250118_055527 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/xq2zycg9
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_055529-xq2zycg9/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_060903-7v4ia802
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.3_Multimodal_epochs_20250118_060903
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/7v4ia802
wandb: uploading history steps 0-0, summary; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▄▅▅▆▇█
wandb:  train_acc ▁▅▇▇█████
wandb: train_loss █▄▂▂▁▁▁▁▁
wandb:    val_acc ▁▃█▆▄█▇██
wandb:   val_loss ▁▆▄▆█▆▆▇▆
wandb: 
wandb: Run summary:
wandb:      epoch 9
wandb:  train_acc 0.99798
wandb: train_loss 0.10791
wandb:    val_acc 0.72125
wandb:   val_loss 1.07349
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.3_Multimodal_epochs_20250118_060903 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/7v4ia802
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_060903-7v4ia802/logs

