=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 1.5 --dropout 0.35 --name loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.35 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.35
text_dim: 128
image_dim: 256
dropout: 0.35
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6863, log_difficulty=0.5225, weight=3.6127
neutral: count=7.0, difficulty=0.7095, log_difficulty=0.5362, weight=3.6811
negative: count=13.0, difficulty=0.6647, log_difficulty=0.5096, weight=3.5481

当前batch的pt分布：
positive: min=0.1608, max=0.5577, mean=0.3137
neutral: min=0.1725, max=0.3864, mean=0.2905
negative: min=0.0818, max=0.5285, mean=0.3353

当前batch准确率：
整体准确率: 0.2500
positive 准确率: 0.2500
neutral 准确率: 0.1429
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.2075
焦点损失: 0.4538
边界损失: 0.7615
总损失: 1.1982
Epoch 1 [1/172] - loss: 1.1982, acc: 0.2500
Epoch 1 [2/172] - loss: 0.9766
Epoch 1 [3/172] - loss: 1.0917
Epoch 1 [4/172] - loss: 1.1465
Epoch 1 [5/172] - loss: 1.1455
Epoch 1 [6/172] - loss: 1.3872
Epoch 1 [7/172] - loss: 1.1835
Epoch 1 [8/172] - loss: 1.3584
Epoch 1 [9/172] - loss: 0.9901
Epoch 1 [10/172] - loss: 1.1457, acc: 0.3125
Epoch 1 [11/172] - loss: 1.1980
Epoch 1 [12/172] - loss: 1.0658
Epoch 1 [13/172] - loss: 0.9676
Epoch 1 [14/172] - loss: 1.2640
Epoch 1 [15/172] - loss: 1.0579
Epoch 1 [16/172] - loss: 0.9715
Epoch 1 [17/172] - loss: 0.9162
Epoch 1 [18/172] - loss: 0.9285
Epoch 1 [19/172] - loss: 1.0122
Epoch 1 [20/172] - loss: 1.0006, acc: 0.5312
Epoch 1 [21/172] - loss: 0.9929
Epoch 1 [22/172] - loss: 0.9193
Epoch 1 [23/172] - loss: 0.9126
Epoch 1 [24/172] - loss: 1.1460
Epoch 1 [25/172] - loss: 1.0505
Epoch 1 [26/172] - loss: 1.2382
Epoch 1 [27/172] - loss: 1.0400
Epoch 1 [28/172] - loss: 0.9261
Epoch 1 [29/172] - loss: 0.9525
Epoch 1 [30/172] - loss: 0.9446, acc: 0.4375
Epoch 1 [31/172] - loss: 0.9813
Epoch 1 [32/172] - loss: 0.7958
Epoch 1 [33/172] - loss: 0.9633
Epoch 1 [34/172] - loss: 1.0093
Epoch 1 [35/172] - loss: 1.0401
Epoch 1 [36/172] - loss: 0.8283
Epoch 1 [37/172] - loss: 0.8736
Epoch 1 [38/172] - loss: 0.9343
Epoch 1 [39/172] - loss: 0.7912
Epoch 1 [40/172] - loss: 1.0539, acc: 0.5000
Epoch 1 [41/172] - loss: 0.7462
Epoch 1 [42/172] - loss: 0.7129
Epoch 1 [43/172] - loss: 0.9116
Epoch 1 [44/172] - loss: 0.9151
Epoch 1 [45/172] - loss: 0.9341
Epoch 1 [46/172] - loss: 0.8422
Epoch 1 [47/172] - loss: 0.9586
Epoch 1 [48/172] - loss: 0.8232
Epoch 1 [49/172] - loss: 0.9678
Epoch 1 [50/172] - loss: 0.7509, acc: 0.5312
Epoch 1 [51/172] - loss: 0.9020
Epoch 1 [52/172] - loss: 0.9699
Epoch 1 [53/172] - loss: 1.0684
Epoch 1 [54/172] - loss: 0.9071
Epoch 1 [55/172] - loss: 0.7759
Epoch 1 [56/172] - loss: 0.7673
Epoch 1 [57/172] - loss: 0.9661
Epoch 1 [58/172] - loss: 0.5809
Epoch 1 [59/172] - loss: 0.9125
Epoch 1 [60/172] - loss: 0.5605, acc: 0.7812
Epoch 1 [61/172] - loss: 0.8107
Epoch 1 [62/172] - loss: 0.7695
Epoch 1 [63/172] - loss: 0.9122
Epoch 1 [64/172] - loss: 0.6620
Epoch 1 [65/172] - loss: 0.8140
Epoch 1 [66/172] - loss: 1.2876
Epoch 1 [67/172] - loss: 0.9123
Epoch 1 [68/172] - loss: 0.9456
Epoch 1 [69/172] - loss: 0.9818
Epoch 1 [70/172] - loss: 0.8496, acc: 0.5312
Epoch 1 [71/172] - loss: 0.8329
Epoch 1 [72/172] - loss: 0.8857
Epoch 1 [73/172] - loss: 0.6912
Epoch 1 [74/172] - loss: 0.9261
Epoch 1 [75/172] - loss: 0.6778
Epoch 1 [76/172] - loss: 0.7289
Epoch 1 [77/172] - loss: 0.7974
Epoch 1 [78/172] - loss: 0.7554
Epoch 1 [79/172] - loss: 0.7348
Epoch 1 [80/172] - loss: 0.4815, acc: 0.8125
Epoch 1 [81/172] - loss: 0.7381
Epoch 1 [82/172] - loss: 1.4162
Epoch 1 [83/172] - loss: 0.7016
Epoch 1 [84/172] - loss: 0.7425
Epoch 1 [85/172] - loss: 0.7481
Epoch 1 [86/172] - loss: 0.9729
Epoch 1 [87/172] - loss: 0.7981
Epoch 1 [88/172] - loss: 0.8999
Epoch 1 [89/172] - loss: 0.9273
Epoch 1 [90/172] - loss: 0.8356, acc: 0.6250
Epoch 1 [91/172] - loss: 0.6068
Epoch 1 [92/172] - loss: 0.9583
Epoch 1 [93/172] - loss: 0.7743
Epoch 1 [94/172] - loss: 0.5904
Epoch 1 [95/172] - loss: 0.5667
Epoch 1 [96/172] - loss: 0.9006
Epoch 1 [97/172] - loss: 0.6470
Epoch 1 [98/172] - loss: 0.8091
Epoch 1 [99/172] - loss: 0.7547
Epoch 1 [100/172] - loss: 0.6789, acc: 0.7812

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5869, log_difficulty=0.4618, weight=3.3089
neutral: count=983.0, difficulty=0.5921, log_difficulty=0.4650, weight=3.3252
negative: count=1119.0, difficulty=0.5827, log_difficulty=0.4591, weight=3.2955

当前batch的pt分布：
positive: min=0.0901, max=0.7994, mean=0.4711
neutral: min=0.4225, max=0.9271, mean=0.6495
negative: min=0.0589, max=0.7144, mean=0.4228

当前batch准确率：
整体准确率: 0.5938
positive 准确率: 0.5833
neutral 准确率: 0.7500
negative 准确率: 0.5625

损失分量：
基础交叉熵: 0.9036
焦点损失: 0.3416
边界损失: 0.5254
总损失: 0.8266
Epoch 1 [101/172] - loss: 0.8266
Epoch 1 [102/172] - loss: 0.7477
Epoch 1 [103/172] - loss: 0.6662
Epoch 1 [104/172] - loss: 0.4689
Epoch 1 [105/172] - loss: 0.9375
Epoch 1 [106/172] - loss: 0.7739
Epoch 1 [107/172] - loss: 0.7861
Epoch 1 [108/172] - loss: 0.7660
Epoch 1 [109/172] - loss: 0.6372
Epoch 1 [110/172] - loss: 0.9095, acc: 0.6250
Epoch 1 [111/172] - loss: 0.6537
Epoch 1 [112/172] - loss: 0.6242
Epoch 1 [113/172] - loss: 0.5932
Epoch 1 [114/172] - loss: 0.5928
Epoch 1 [115/172] - loss: 0.7114
Epoch 1 [116/172] - loss: 0.8033
Epoch 1 [117/172] - loss: 0.7121
Epoch 1 [118/172] - loss: 0.6358
Epoch 1 [119/172] - loss: 0.6314
Epoch 1 [120/172] - loss: 0.4844, acc: 0.8438
Epoch 1 [121/172] - loss: 0.6181
Epoch 1 [122/172] - loss: 0.6468
Epoch 1 [123/172] - loss: 0.4381
Epoch 1 [124/172] - loss: 0.5928
Epoch 1 [125/172] - loss: 0.4930
Epoch 1 [126/172] - loss: 0.8765
Epoch 1 [127/172] - loss: 0.4608
Epoch 1 [128/172] - loss: 0.5388
Epoch 1 [129/172] - loss: 0.7911
Epoch 1 [130/172] - loss: 0.5059, acc: 0.7188
Epoch 1 [131/172] - loss: 0.2771
Epoch 1 [132/172] - loss: 0.7444
Epoch 1 [133/172] - loss: 0.6806
Epoch 1 [134/172] - loss: 0.4776
Epoch 1 [135/172] - loss: 0.6694
Epoch 1 [136/172] - loss: 0.4388
Epoch 1 [137/172] - loss: 0.4290
Epoch 1 [138/172] - loss: 0.3769
Epoch 1 [139/172] - loss: 0.4692
Epoch 1 [140/172] - loss: 0.4647, acc: 0.7188
Epoch 1 [141/172] - loss: 0.5459
Epoch 1 [142/172] - loss: 0.5613
Epoch 1 [143/172] - loss: 0.6635
Epoch 1 [144/172] - loss: 0.5862
Epoch 1 [145/172] - loss: 0.5257
Epoch 1 [146/172] - loss: 0.6886
Epoch 1 [147/172] - loss: 0.6188
Epoch 1 [148/172] - loss: 0.4858
Epoch 1 [149/172] - loss: 0.4639
Epoch 1 [150/172] - loss: 0.5188, acc: 0.7500
Epoch 1 [151/172] - loss: 0.6489
Epoch 1 [152/172] - loss: 0.5849
Epoch 1 [153/172] - loss: 0.4880
Epoch 1 [154/172] - loss: 0.5296
Epoch 1 [155/172] - loss: 0.4559
Epoch 1 [156/172] - loss: 0.7446
Epoch 1 [157/172] - loss: 0.6972
Epoch 1 [158/172] - loss: 0.4861
Epoch 1 [159/172] - loss: 0.6619
Epoch 1 [160/172] - loss: 0.4541, acc: 0.7500
Epoch 1 [161/172] - loss: 0.3731
Epoch 1 [162/172] - loss: 0.5110
Epoch 1 [163/172] - loss: 0.5731
Epoch 1 [164/172] - loss: 0.5247
Epoch 1 [165/172] - loss: 0.4842
Epoch 1 [166/172] - loss: 0.4142
Epoch 1 [167/172] - loss: 0.3415
Epoch 1 [168/172] - loss: 0.4614
Epoch 1 [169/172] - loss: 0.4811
Epoch 1 [170/172] - loss: 0.4514, acc: 0.7500
Epoch 1 [171/172] - loss: 0.3885
Epoch 1 [172/172] - loss: 0.3996

类别准确率:
positive: 0.5567 (260/467)
neutral: 0.2410 (20/83)
negative: 0.9280 (232/250)

Epoch 1/10
Train Loss: 0.4815, Train Acc: 0.7495
Val Loss: 0.8445, Val Acc: 0.6400
Epoch 2 [1/172] - loss: 0.3935, acc: 0.8438
Epoch 2 [2/172] - loss: 0.2802
Epoch 2 [3/172] - loss: 0.3706
Epoch 2 [4/172] - loss: 0.4934
Epoch 2 [5/172] - loss: 0.5072
Epoch 2 [6/172] - loss: 0.3640
Epoch 2 [7/172] - loss: 0.4687
Epoch 2 [8/172] - loss: 0.4256
Epoch 2 [9/172] - loss: 0.3372
Epoch 2 [10/172] - loss: 0.4460, acc: 0.9062
Epoch 2 [11/172] - loss: 0.2863
Epoch 2 [12/172] - loss: 0.2808
Epoch 2 [13/172] - loss: 0.4629
Epoch 2 [14/172] - loss: 0.4109
Epoch 2 [15/172] - loss: 0.6734
Epoch 2 [16/172] - loss: 0.3783
Epoch 2 [17/172] - loss: 0.4974
Epoch 2 [18/172] - loss: 0.5249
Epoch 2 [19/172] - loss: 0.3854
Epoch 2 [20/172] - loss: 0.3184, acc: 0.8125
Epoch 2 [21/172] - loss: 0.3420
Epoch 2 [22/172] - loss: 0.3870
Epoch 2 [23/172] - loss: 0.2552
Epoch 2 [24/172] - loss: 0.7624
Epoch 2 [25/172] - loss: 0.3783
Epoch 2 [26/172] - loss: 0.2850
Epoch 2 [27/172] - loss: 0.2696
Epoch 2 [28/172] - loss: 0.3945

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5111, log_difficulty=0.4129, weight=3.0643
neutral: count=1952.0, difficulty=0.4652, log_difficulty=0.3820, weight=2.9101
negative: count=2216.0, difficulty=0.5092, log_difficulty=0.4116, weight=3.0579

当前batch的pt分布：
positive: min=0.4726, max=0.9210, mean=0.7137
neutral: min=0.1416, max=0.9883, mean=0.7337
negative: min=0.1133, max=0.9288, mean=0.5580

当前batch准确率：
整体准确率: 0.8125
positive 准确率: 0.8889
neutral 准确率: 0.9091
negative 准确率: 0.6667

损失分量：
基础交叉熵: 0.5178
焦点损失: 0.1623
边界损失: 0.3653
总损失: 0.4275
Epoch 2 [29/172] - loss: 0.4275
Epoch 2 [30/172] - loss: 0.4596, acc: 0.7500
Epoch 2 [31/172] - loss: 0.4444
Epoch 2 [32/172] - loss: 0.2506
Epoch 2 [33/172] - loss: 0.3318
Epoch 2 [34/172] - loss: 0.3660
Epoch 2 [35/172] - loss: 0.3156
Epoch 2 [36/172] - loss: 0.4925
Epoch 2 [37/172] - loss: 0.2489
Epoch 2 [38/172] - loss: 0.3607
Epoch 2 [39/172] - loss: 0.3692
Epoch 2 [40/172] - loss: 0.3837, acc: 0.8438
Epoch 2 [41/172] - loss: 0.2758
Epoch 2 [42/172] - loss: 0.2888
Epoch 2 [43/172] - loss: 0.2470
Epoch 2 [44/172] - loss: 0.4812
Epoch 2 [45/172] - loss: 0.2207
Epoch 2 [46/172] - loss: 0.2864
Epoch 2 [47/172] - loss: 0.5503
Epoch 2 [48/172] - loss: 0.4513
Epoch 2 [49/172] - loss: 0.4244
Epoch 2 [50/172] - loss: 0.4887, acc: 0.7188
Epoch 2 [51/172] - loss: 0.3854
Epoch 2 [52/172] - loss: 0.3649
Epoch 2 [53/172] - loss: 0.2236
Epoch 2 [54/172] - loss: 0.1984
Epoch 2 [55/172] - loss: 0.2798
Epoch 2 [56/172] - loss: 0.2499
Epoch 2 [57/172] - loss: 0.2550
Epoch 2 [58/172] - loss: 0.4187
Epoch 2 [59/172] - loss: 0.4518
Epoch 2 [60/172] - loss: 0.4504, acc: 0.9062
Epoch 2 [61/172] - loss: 0.2085
Epoch 2 [62/172] - loss: 0.2131
Epoch 2 [63/172] - loss: 0.4819
Epoch 2 [64/172] - loss: 0.2354
Epoch 2 [65/172] - loss: 0.3640
Epoch 2 [66/172] - loss: 0.2265
Epoch 2 [67/172] - loss: 0.1808
Epoch 2 [68/172] - loss: 0.3237
Epoch 2 [69/172] - loss: 0.1783
Epoch 2 [70/172] - loss: 0.4043, acc: 0.8125
Epoch 2 [71/172] - loss: 0.3788
Epoch 2 [72/172] - loss: 0.2179
Epoch 2 [73/172] - loss: 0.2825
Epoch 2 [74/172] - loss: 0.1821
Epoch 2 [75/172] - loss: 0.2614
Epoch 2 [76/172] - loss: 0.2461
Epoch 2 [77/172] - loss: 0.2709
Epoch 2 [78/172] - loss: 0.3224
Epoch 2 [79/172] - loss: 0.3061
Epoch 2 [80/172] - loss: 0.2813, acc: 0.8438
Epoch 2 [81/172] - loss: 0.2472
Epoch 2 [82/172] - loss: 0.2377
Epoch 2 [83/172] - loss: 0.2179
Epoch 2 [84/172] - loss: 0.3745
Epoch 2 [85/172] - loss: 0.2937
Epoch 2 [86/172] - loss: 0.1827
Epoch 2 [87/172] - loss: 0.5176
Epoch 2 [88/172] - loss: 0.2457
Epoch 2 [89/172] - loss: 0.1847
Epoch 2 [90/172] - loss: 0.3449, acc: 0.7812
Epoch 2 [91/172] - loss: 0.1648
Epoch 2 [92/172] - loss: 0.3860
Epoch 2 [93/172] - loss: 0.2124
Epoch 2 [94/172] - loss: 0.2284
Epoch 2 [95/172] - loss: 0.3451
Epoch 2 [96/172] - loss: 0.1725
Epoch 2 [97/172] - loss: 0.2117
Epoch 2 [98/172] - loss: 0.3031
Epoch 2 [99/172] - loss: 0.2012
Epoch 2 [100/172] - loss: 0.2646, acc: 0.8438
Epoch 2 [101/172] - loss: 0.2734
Epoch 2 [102/172] - loss: 0.2037
Epoch 2 [103/172] - loss: 0.2169
Epoch 2 [104/172] - loss: 0.3163
Epoch 2 [105/172] - loss: 0.2439
Epoch 2 [106/172] - loss: 0.2049
Epoch 2 [107/172] - loss: 0.3556
Epoch 2 [108/172] - loss: 0.5297
Epoch 2 [109/172] - loss: 0.1984
Epoch 2 [110/172] - loss: 0.2242, acc: 0.9062
Epoch 2 [111/172] - loss: 0.2138
Epoch 2 [112/172] - loss: 0.1650
Epoch 2 [113/172] - loss: 0.1505
Epoch 2 [114/172] - loss: 0.2736
Epoch 2 [115/172] - loss: 0.2335
Epoch 2 [116/172] - loss: 0.2554
Epoch 2 [117/172] - loss: 0.4571
Epoch 2 [118/172] - loss: 0.2426
Epoch 2 [119/172] - loss: 0.2304
Epoch 2 [120/172] - loss: 0.1608, acc: 0.9375
Epoch 2 [121/172] - loss: 0.1768
Epoch 2 [122/172] - loss: 0.4079
Epoch 2 [123/172] - loss: 0.2577
Epoch 2 [124/172] - loss: 0.1662
Epoch 2 [125/172] - loss: 0.1644
Epoch 2 [126/172] - loss: 0.1930
Epoch 2 [127/172] - loss: 0.2134
Epoch 2 [128/172] - loss: 0.2661

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4410, log_difficulty=0.3653, weight=2.8265
neutral: count=2949.0, difficulty=0.3668, log_difficulty=0.3125, weight=2.5625
negative: count=3294.0, difficulty=0.4357, log_difficulty=0.3616, weight=2.8082

当前batch的pt分布：
positive: min=0.2168, max=0.9631, mean=0.7479
neutral: min=0.5423, max=0.9949, mean=0.8447
negative: min=0.0571, max=0.9796, mean=0.6614

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.8000
neutral 准确率: 1.0000
negative 准确率: 0.7273

损失分量：
基础交叉熵: 0.4144
焦点损失: 0.1756
边界损失: 0.2392
总损失: 0.3660
Epoch 2 [129/172] - loss: 0.3660
Epoch 2 [130/172] - loss: 0.2043, acc: 0.9062
Epoch 2 [131/172] - loss: 0.2322
Epoch 2 [132/172] - loss: 0.3542
Epoch 2 [133/172] - loss: 0.3165
Epoch 2 [134/172] - loss: 0.1635
Epoch 2 [135/172] - loss: 0.3976
Epoch 2 [136/172] - loss: 0.2151
Epoch 2 [137/172] - loss: 0.1612
Epoch 2 [138/172] - loss: 0.2543
Epoch 2 [139/172] - loss: 0.2677
Epoch 2 [140/172] - loss: 0.3359, acc: 0.8438
Epoch 2 [141/172] - loss: 0.2812
Epoch 2 [142/172] - loss: 0.2309
Epoch 2 [143/172] - loss: 0.1932
Epoch 2 [144/172] - loss: 0.2412
Epoch 2 [145/172] - loss: 0.5650
Epoch 2 [146/172] - loss: 0.1550
Epoch 2 [147/172] - loss: 0.2467
Epoch 2 [148/172] - loss: 0.2798
Epoch 2 [149/172] - loss: 0.2615
Epoch 2 [150/172] - loss: 0.2692, acc: 0.8750
Epoch 2 [151/172] - loss: 0.2068
Epoch 2 [152/172] - loss: 0.1776
Epoch 2 [153/172] - loss: 0.2687
Epoch 2 [154/172] - loss: 0.2515
Epoch 2 [155/172] - loss: 0.1929
Epoch 2 [156/172] - loss: 0.1958
Epoch 2 [157/172] - loss: 0.1765
Epoch 2 [158/172] - loss: 0.1909
Epoch 2 [159/172] - loss: 0.2798
Epoch 2 [160/172] - loss: 0.1998, acc: 0.8750
Epoch 2 [161/172] - loss: 0.1879
Epoch 2 [162/172] - loss: 0.1822
Epoch 2 [163/172] - loss: 0.3605
Epoch 2 [164/172] - loss: 0.2604
Epoch 2 [165/172] - loss: 0.3298
Epoch 2 [166/172] - loss: 0.5436
Epoch 2 [167/172] - loss: 0.4136
Epoch 2 [168/172] - loss: 0.2074
Epoch 2 [169/172] - loss: 0.1626
Epoch 2 [170/172] - loss: 0.2542, acc: 0.8438
Epoch 2 [171/172] - loss: 0.3141
Epoch 2 [172/172] - loss: 0.5930

类别准确率:
positive: 0.8587 (401/467)
neutral: 0.3855 (32/83)
negative: 0.6360 (159/250)

Epoch 2/10
Train Loss: 0.2910, Train Acc: 0.8970
Val Loss: 0.7028, Val Acc: 0.7400
Epoch 3 [1/172] - loss: 0.1501, acc: 1.0000
Epoch 3 [2/172] - loss: 0.2224
Epoch 3 [3/172] - loss: 0.1350
Epoch 3 [4/172] - loss: 0.1386
Epoch 3 [5/172] - loss: 0.1690
Epoch 3 [6/172] - loss: 0.1522
Epoch 3 [7/172] - loss: 0.1244
Epoch 3 [8/172] - loss: 0.1176
Epoch 3 [9/172] - loss: 0.1352
Epoch 3 [10/172] - loss: 0.1402, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1300
Epoch 3 [12/172] - loss: 0.1034
Epoch 3 [13/172] - loss: 0.1288
Epoch 3 [14/172] - loss: 0.1204
Epoch 3 [15/172] - loss: 0.1210
Epoch 3 [16/172] - loss: 0.1656
Epoch 3 [17/172] - loss: 0.1839
Epoch 3 [18/172] - loss: 0.3044
Epoch 3 [19/172] - loss: 0.1312
Epoch 3 [20/172] - loss: 0.1203, acc: 1.0000
Epoch 3 [21/172] - loss: 0.2052
Epoch 3 [22/172] - loss: 0.2748
Epoch 3 [23/172] - loss: 0.1164
Epoch 3 [24/172] - loss: 0.1550
Epoch 3 [25/172] - loss: 0.2037
Epoch 3 [26/172] - loss: 0.1561
Epoch 3 [27/172] - loss: 0.1285
Epoch 3 [28/172] - loss: 0.1020
Epoch 3 [29/172] - loss: 0.1935
Epoch 3 [30/172] - loss: 0.1444, acc: 0.9688
Epoch 3 [31/172] - loss: 0.1449
Epoch 3 [32/172] - loss: 0.1366
Epoch 3 [33/172] - loss: 0.1869
Epoch 3 [34/172] - loss: 0.1468
Epoch 3 [35/172] - loss: 0.1913
Epoch 3 [36/172] - loss: 0.1175
Epoch 3 [37/172] - loss: 0.2148
Epoch 3 [38/172] - loss: 0.0900
Epoch 3 [39/172] - loss: 0.1134
Epoch 3 [40/172] - loss: 0.1232, acc: 1.0000
Epoch 3 [41/172] - loss: 0.1284
Epoch 3 [42/172] - loss: 0.1223
Epoch 3 [43/172] - loss: 0.0967
Epoch 3 [44/172] - loss: 0.1040
Epoch 3 [45/172] - loss: 0.1843
Epoch 3 [46/172] - loss: 0.1059
Epoch 3 [47/172] - loss: 0.1094
Epoch 3 [48/172] - loss: 0.1130
Epoch 3 [49/172] - loss: 0.1536
Epoch 3 [50/172] - loss: 0.1051, acc: 1.0000
Epoch 3 [51/172] - loss: 0.1519
Epoch 3 [52/172] - loss: 0.3130
Epoch 3 [53/172] - loss: 0.1098
Epoch 3 [54/172] - loss: 0.1903
Epoch 3 [55/172] - loss: 0.1030
Epoch 3 [56/172] - loss: 0.1131

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3826, log_difficulty=0.3240, weight=2.6199
neutral: count=3923.0, difficulty=0.3069, log_difficulty=0.2677, weight=2.3384
negative: count=4382.0, difficulty=0.3756, log_difficulty=0.3189, weight=2.5945

当前batch的pt分布：
positive: min=0.1277, max=0.9886, mean=0.8276
neutral: min=0.0266, max=0.9886, mean=0.7693
negative: min=0.8943, max=0.9910, mean=0.9629

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9091
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3250
焦点损失: 0.1680
边界损失: 0.2124
总损失: 0.3093
Epoch 3 [57/172] - loss: 0.3093
Epoch 3 [58/172] - loss: 0.2267
Epoch 3 [59/172] - loss: 0.1073
Epoch 3 [60/172] - loss: 0.1432, acc: 0.9375
Epoch 3 [61/172] - loss: 0.1368
Epoch 3 [62/172] - loss: 0.1420
Epoch 3 [63/172] - loss: 0.1069
Epoch 3 [64/172] - loss: 0.1289
Epoch 3 [65/172] - loss: 0.1290
Epoch 3 [66/172] - loss: 0.2207
Epoch 3 [67/172] - loss: 0.1394
Epoch 3 [68/172] - loss: 0.1350
Epoch 3 [69/172] - loss: 0.2237
Epoch 3 [70/172] - loss: 0.1006, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1131
Epoch 3 [72/172] - loss: 0.2472
Epoch 3 [73/172] - loss: 0.1256
Epoch 3 [74/172] - loss: 0.1414
Epoch 3 [75/172] - loss: 0.1233
Epoch 3 [76/172] - loss: 0.1076
Epoch 3 [77/172] - loss: 0.1119
Epoch 3 [78/172] - loss: 0.2172
Epoch 3 [79/172] - loss: 0.1088
Epoch 3 [80/172] - loss: 0.2130, acc: 0.8750
Epoch 3 [81/172] - loss: 0.1137
Epoch 3 [82/172] - loss: 0.1326
Epoch 3 [83/172] - loss: 0.1007
Epoch 3 [84/172] - loss: 0.1017
Epoch 3 [85/172] - loss: 0.1511
Epoch 3 [86/172] - loss: 0.0928
Epoch 3 [87/172] - loss: 0.2242
Epoch 3 [88/172] - loss: 0.2906
Epoch 3 [89/172] - loss: 0.1042
Epoch 3 [90/172] - loss: 0.1924, acc: 0.9375
Epoch 3 [91/172] - loss: 0.1552
Epoch 3 [92/172] - loss: 0.1604
Epoch 3 [93/172] - loss: 0.1708
Epoch 3 [94/172] - loss: 0.1536
Epoch 3 [95/172] - loss: 0.1062
Epoch 3 [96/172] - loss: 0.1532
Epoch 3 [97/172] - loss: 0.1329
Epoch 3 [98/172] - loss: 0.0966
Epoch 3 [99/172] - loss: 0.1076
Epoch 3 [100/172] - loss: 0.2245, acc: 0.9375
Epoch 3 [101/172] - loss: 0.2201
Epoch 3 [102/172] - loss: 0.1111
Epoch 3 [103/172] - loss: 0.2107
Epoch 3 [104/172] - loss: 0.1200
Epoch 3 [105/172] - loss: 0.1022
Epoch 3 [106/172] - loss: 0.1736
Epoch 3 [107/172] - loss: 0.1775
Epoch 3 [108/172] - loss: 0.1405
Epoch 3 [109/172] - loss: 0.1049
Epoch 3 [110/172] - loss: 0.1325, acc: 0.9688
Epoch 3 [111/172] - loss: 0.1282
Epoch 3 [112/172] - loss: 0.1203
Epoch 3 [113/172] - loss: 0.0958
Epoch 3 [114/172] - loss: 0.1539
Epoch 3 [115/172] - loss: 0.1221
Epoch 3 [116/172] - loss: 0.1050
Epoch 3 [117/172] - loss: 0.1167
Epoch 3 [118/172] - loss: 0.1748
Epoch 3 [119/172] - loss: 0.0948
Epoch 3 [120/172] - loss: 0.2598, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1938
Epoch 3 [122/172] - loss: 0.1584
Epoch 3 [123/172] - loss: 0.1386
Epoch 3 [124/172] - loss: 0.1081
Epoch 3 [125/172] - loss: 0.1493
Epoch 3 [126/172] - loss: 0.2530
Epoch 3 [127/172] - loss: 0.1564
Epoch 3 [128/172] - loss: 0.0947
Epoch 3 [129/172] - loss: 0.1215
Epoch 3 [130/172] - loss: 0.2003, acc: 0.9688
Epoch 3 [131/172] - loss: 0.2247
Epoch 3 [132/172] - loss: 0.1031
Epoch 3 [133/172] - loss: 0.1860
Epoch 3 [134/172] - loss: 0.0910
Epoch 3 [135/172] - loss: 0.1504
Epoch 3 [136/172] - loss: 0.1462
Epoch 3 [137/172] - loss: 0.1138
Epoch 3 [138/172] - loss: 0.1124
Epoch 3 [139/172] - loss: 0.1011
Epoch 3 [140/172] - loss: 0.1725, acc: 0.9688
Epoch 3 [141/172] - loss: 0.2845
Epoch 3 [142/172] - loss: 0.3570
Epoch 3 [143/172] - loss: 0.1023
Epoch 3 [144/172] - loss: 0.2108
Epoch 3 [145/172] - loss: 0.1521
Epoch 3 [146/172] - loss: 0.1904
Epoch 3 [147/172] - loss: 0.1111
Epoch 3 [148/172] - loss: 0.1051
Epoch 3 [149/172] - loss: 0.1338
Epoch 3 [150/172] - loss: 0.2665, acc: 0.8750
Epoch 3 [151/172] - loss: 0.2239
Epoch 3 [152/172] - loss: 0.1569
Epoch 3 [153/172] - loss: 0.1328
Epoch 3 [154/172] - loss: 0.1190
Epoch 3 [155/172] - loss: 0.0940
Epoch 3 [156/172] - loss: 0.1845

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3350, log_difficulty=0.2889, weight=2.4447
neutral: count=4903.0, difficulty=0.2644, log_difficulty=0.2346, weight=2.1729
negative: count=5500.0, difficulty=0.3294, log_difficulty=0.2847, weight=2.4237

当前batch的pt分布：
positive: min=0.6429, max=0.9787, mean=0.8677
neutral: min=0.5741, max=0.9946, mean=0.9005
negative: min=0.3505, max=0.9895, mean=0.8031

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1730
焦点损失: 0.0205
边界损失: 0.2188
总损失: 0.1339
Epoch 3 [157/172] - loss: 0.1339
Epoch 3 [158/172] - loss: 0.3412
Epoch 3 [159/172] - loss: 0.1405
Epoch 3 [160/172] - loss: 0.1589, acc: 0.9688
Epoch 3 [161/172] - loss: 0.1810
Epoch 3 [162/172] - loss: 0.1316
Epoch 3 [163/172] - loss: 0.1780
Epoch 3 [164/172] - loss: 0.1151
Epoch 3 [165/172] - loss: 0.1339
Epoch 3 [166/172] - loss: 0.1160
Epoch 3 [167/172] - loss: 0.2229
Epoch 3 [168/172] - loss: 0.0931
Epoch 3 [169/172] - loss: 0.0987
Epoch 3 [170/172] - loss: 0.1221, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1012
Epoch 3 [172/172] - loss: 0.0973

类别准确率:
positive: 0.8715 (407/467)
neutral: 0.1928 (16/83)
negative: 0.6240 (156/250)

Epoch 3/10
Train Loss: 0.1478, Train Acc: 0.9697
Val Loss: 0.7648, Val Acc: 0.7238
Epoch 4 [1/172] - loss: 0.1024, acc: 0.9688
Epoch 4 [2/172] - loss: 0.1488
Epoch 4 [3/172] - loss: 0.1102
Epoch 4 [4/172] - loss: 0.0960
Epoch 4 [5/172] - loss: 0.1300
Epoch 4 [6/172] - loss: 0.0873
Epoch 4 [7/172] - loss: 0.1175
Epoch 4 [8/172] - loss: 0.0840
Epoch 4 [9/172] - loss: 0.2019
Epoch 4 [10/172] - loss: 0.1425, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0894
Epoch 4 [12/172] - loss: 0.0971
Epoch 4 [13/172] - loss: 0.1806
Epoch 4 [14/172] - loss: 0.1295
Epoch 4 [15/172] - loss: 0.0928
Epoch 4 [16/172] - loss: 0.0827
Epoch 4 [17/172] - loss: 0.1098
Epoch 4 [18/172] - loss: 0.1546
Epoch 4 [19/172] - loss: 0.1125
Epoch 4 [20/172] - loss: 0.1081, acc: 0.9688
Epoch 4 [21/172] - loss: 0.1476
Epoch 4 [22/172] - loss: 0.1112
Epoch 4 [23/172] - loss: 0.1140
Epoch 4 [24/172] - loss: 0.0937
Epoch 4 [25/172] - loss: 0.0810
Epoch 4 [26/172] - loss: 0.2422
Epoch 4 [27/172] - loss: 0.0807
Epoch 4 [28/172] - loss: 0.1133
Epoch 4 [29/172] - loss: 0.1087
Epoch 4 [30/172] - loss: 0.1371, acc: 0.9375
Epoch 4 [31/172] - loss: 0.1578
Epoch 4 [32/172] - loss: 0.1434
Epoch 4 [33/172] - loss: 0.1260
Epoch 4 [34/172] - loss: 0.0912
Epoch 4 [35/172] - loss: 0.1241
Epoch 4 [36/172] - loss: 0.1140
Epoch 4 [37/172] - loss: 0.0926
Epoch 4 [38/172] - loss: 0.0874
Epoch 4 [39/172] - loss: 0.2541
Epoch 4 [40/172] - loss: 0.1574, acc: 0.9688
Epoch 4 [41/172] - loss: 0.1019
Epoch 4 [42/172] - loss: 0.2126
Epoch 4 [43/172] - loss: 0.1851
Epoch 4 [44/172] - loss: 0.0882
Epoch 4 [45/172] - loss: 0.1008
Epoch 4 [46/172] - loss: 0.0994
Epoch 4 [47/172] - loss: 0.1105
Epoch 4 [48/172] - loss: 0.0998
Epoch 4 [49/172] - loss: 0.1214
Epoch 4 [50/172] - loss: 0.1137, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0857
Epoch 4 [52/172] - loss: 0.1731
Epoch 4 [53/172] - loss: 0.0921
Epoch 4 [54/172] - loss: 0.1063
Epoch 4 [55/172] - loss: 0.1849
Epoch 4 [56/172] - loss: 0.0907
Epoch 4 [57/172] - loss: 0.0809
Epoch 4 [58/172] - loss: 0.0855
Epoch 4 [59/172] - loss: 0.0813
Epoch 4 [60/172] - loss: 0.0891, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1280
Epoch 4 [62/172] - loss: 0.1800
Epoch 4 [63/172] - loss: 0.0988
Epoch 4 [64/172] - loss: 0.0907
Epoch 4 [65/172] - loss: 0.1065
Epoch 4 [66/172] - loss: 0.0851
Epoch 4 [67/172] - loss: 0.0990
Epoch 4 [68/172] - loss: 0.0828
Epoch 4 [69/172] - loss: 0.0939
Epoch 4 [70/172] - loss: 0.1011, acc: 0.9688
Epoch 4 [71/172] - loss: 0.1042
Epoch 4 [72/172] - loss: 0.0967
Epoch 4 [73/172] - loss: 0.0862
Epoch 4 [74/172] - loss: 0.3637
Epoch 4 [75/172] - loss: 0.1511
Epoch 4 [76/172] - loss: 0.2150
Epoch 4 [77/172] - loss: 0.1336
Epoch 4 [78/172] - loss: 0.1159
Epoch 4 [79/172] - loss: 0.0867
Epoch 4 [80/172] - loss: 0.1018, acc: 0.9688
Epoch 4 [81/172] - loss: 0.2390
Epoch 4 [82/172] - loss: 0.1321
Epoch 4 [83/172] - loss: 0.0828
Epoch 4 [84/172] - loss: 0.0825

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2973, log_difficulty=0.2603, weight=2.3016
neutral: count=5865.0, difficulty=0.2340, log_difficulty=0.2103, weight=2.0515
negative: count=6629.0, difficulty=0.2917, log_difficulty=0.2559, weight=2.2796

当前batch的pt分布：
positive: min=0.2859, max=0.9870, mean=0.8230
neutral: min=0.9062, max=0.9991, mean=0.9813
negative: min=0.7145, max=0.9918, mean=0.9487

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1365
焦点损失: 0.0237
边界损失: 0.1866
总损失: 0.1206
Epoch 4 [85/172] - loss: 0.1206
Epoch 4 [86/172] - loss: 0.1661
Epoch 4 [87/172] - loss: 0.1088
Epoch 4 [88/172] - loss: 0.1067
Epoch 4 [89/172] - loss: 0.1038
Epoch 4 [90/172] - loss: 0.0965, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1816
Epoch 4 [92/172] - loss: 0.2853
Epoch 4 [93/172] - loss: 0.1013
Epoch 4 [94/172] - loss: 0.0861
Epoch 4 [95/172] - loss: 0.1303
Epoch 4 [96/172] - loss: 0.1128
Epoch 4 [97/172] - loss: 0.0945
Epoch 4 [98/172] - loss: 0.0978
Epoch 4 [99/172] - loss: 0.1426
Epoch 4 [100/172] - loss: 0.0973, acc: 1.0000
Epoch 4 [101/172] - loss: 0.0954
Epoch 4 [102/172] - loss: 0.1159
Epoch 4 [103/172] - loss: 0.1170
Epoch 4 [104/172] - loss: 0.1235
Epoch 4 [105/172] - loss: 0.1197
Epoch 4 [106/172] - loss: 0.0866
Epoch 4 [107/172] - loss: 0.1481
Epoch 4 [108/172] - loss: 0.1489
Epoch 4 [109/172] - loss: 0.0972
Epoch 4 [110/172] - loss: 0.2612, acc: 0.9062
Epoch 4 [111/172] - loss: 0.0796
Epoch 4 [112/172] - loss: 0.0863
Epoch 4 [113/172] - loss: 0.0827
Epoch 4 [114/172] - loss: 0.1054
Epoch 4 [115/172] - loss: 0.1263
Epoch 4 [116/172] - loss: 0.1414
Epoch 4 [117/172] - loss: 0.0800
Epoch 4 [118/172] - loss: 0.1053
Epoch 4 [119/172] - loss: 0.0829
Epoch 4 [120/172] - loss: 0.0852, acc: 1.0000
Epoch 4 [121/172] - loss: 0.0976
Epoch 4 [122/172] - loss: 0.1572
Epoch 4 [123/172] - loss: 0.0849
Epoch 4 [124/172] - loss: 0.0799
Epoch 4 [125/172] - loss: 0.0921
Epoch 4 [126/172] - loss: 0.1803
Epoch 4 [127/172] - loss: 0.0919
Epoch 4 [128/172] - loss: 0.0891
Epoch 4 [129/172] - loss: 0.1015
Epoch 4 [130/172] - loss: 0.0787, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0827
Epoch 4 [132/172] - loss: 0.0861
Epoch 4 [133/172] - loss: 0.1253
Epoch 4 [134/172] - loss: 0.0837
Epoch 4 [135/172] - loss: 0.1013
Epoch 4 [136/172] - loss: 0.1521
Epoch 4 [137/172] - loss: 0.1502
Epoch 4 [138/172] - loss: 0.0810
Epoch 4 [139/172] - loss: 0.1217
Epoch 4 [140/172] - loss: 0.0885, acc: 1.0000
Epoch 4 [141/172] - loss: 0.1530
Epoch 4 [142/172] - loss: 0.0907
Epoch 4 [143/172] - loss: 0.0867
Epoch 4 [144/172] - loss: 0.0945
Epoch 4 [145/172] - loss: 0.2160
Epoch 4 [146/172] - loss: 0.0917
Epoch 4 [147/172] - loss: 0.1587
Epoch 4 [148/172] - loss: 0.0842
Epoch 4 [149/172] - loss: 0.0808
Epoch 4 [150/172] - loss: 0.1860, acc: 0.9375
Epoch 4 [151/172] - loss: 0.2199
Epoch 4 [152/172] - loss: 0.0855
Epoch 4 [153/172] - loss: 0.0835
Epoch 4 [154/172] - loss: 0.2011
Epoch 4 [155/172] - loss: 0.0957
Epoch 4 [156/172] - loss: 0.0912
Epoch 4 [157/172] - loss: 0.2579
Epoch 4 [158/172] - loss: 0.0831
Epoch 4 [159/172] - loss: 0.0885
Epoch 4 [160/172] - loss: 0.0969, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1521
Epoch 4 [162/172] - loss: 0.0878
Epoch 4 [163/172] - loss: 0.1150
Epoch 4 [164/172] - loss: 0.0871
Epoch 4 [165/172] - loss: 0.1102
Epoch 4 [166/172] - loss: 0.1173
Epoch 4 [167/172] - loss: 0.1284
Epoch 4 [168/172] - loss: 0.0943
Epoch 4 [169/172] - loss: 0.2439
Epoch 4 [170/172] - loss: 0.1259, acc: 1.0000
Epoch 4 [171/172] - loss: 0.0999
Epoch 4 [172/172] - loss: 0.0984

类别准确率:
positive: 0.9165 (428/467)
neutral: 0.2048 (17/83)
negative: 0.5440 (136/250)

Epoch 4/10
Train Loss: 0.1242, Train Acc: 0.9758
Val Loss: 0.7863, Val Acc: 0.7262
Epoch 5 [1/172] - loss: 0.0830, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0965
Epoch 5 [3/172] - loss: 0.0826
Epoch 5 [4/172] - loss: 0.0879
Epoch 5 [5/172] - loss: 0.0769
Epoch 5 [6/172] - loss: 0.1003
Epoch 5 [7/172] - loss: 0.0833
Epoch 5 [8/172] - loss: 0.1027
Epoch 5 [9/172] - loss: 0.2068
Epoch 5 [10/172] - loss: 0.0812, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1518
Epoch 5 [12/172] - loss: 0.0790

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2687, log_difficulty=0.2380, weight=2.1900
neutral: count=6845.0, difficulty=0.2089, log_difficulty=0.1897, weight=1.9487
negative: count=7694.0, difficulty=0.2642, log_difficulty=0.2345, weight=2.1723

当前batch的pt分布：
positive: min=0.1510, max=0.9920, mean=0.8707
neutral: min=0.9627, max=0.9989, mean=0.9871
negative: min=0.8858, max=0.9889, mean=0.9435

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1157
焦点损失: 0.0429
边界损失: 0.1652
总损失: 0.1295
Epoch 5 [13/172] - loss: 0.1295
Epoch 5 [14/172] - loss: 0.1729
Epoch 5 [15/172] - loss: 0.0819
Epoch 5 [16/172] - loss: 0.0777
Epoch 5 [17/172] - loss: 0.0923
Epoch 5 [18/172] - loss: 0.0872
Epoch 5 [19/172] - loss: 0.1346
Epoch 5 [20/172] - loss: 0.1381, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1356
Epoch 5 [22/172] - loss: 0.1293
Epoch 5 [23/172] - loss: 0.1039
Epoch 5 [24/172] - loss: 0.0816
Epoch 5 [25/172] - loss: 0.0806
Epoch 5 [26/172] - loss: 0.1072
Epoch 5 [27/172] - loss: 0.0815
Epoch 5 [28/172] - loss: 0.0803
Epoch 5 [29/172] - loss: 0.0803
Epoch 5 [30/172] - loss: 0.0810, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0841
Epoch 5 [32/172] - loss: 0.1062
Epoch 5 [33/172] - loss: 0.1093
Epoch 5 [34/172] - loss: 0.0912
Epoch 5 [35/172] - loss: 0.0807
Epoch 5 [36/172] - loss: 0.0790
Epoch 5 [37/172] - loss: 0.0823
Epoch 5 [38/172] - loss: 0.0796
Epoch 5 [39/172] - loss: 0.0936
Epoch 5 [40/172] - loss: 0.0872, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0892
Epoch 5 [42/172] - loss: 0.0818
Epoch 5 [43/172] - loss: 0.0982
Epoch 5 [44/172] - loss: 0.0838
Epoch 5 [45/172] - loss: 0.0785
Epoch 5 [46/172] - loss: 0.0864
Epoch 5 [47/172] - loss: 0.0865
Epoch 5 [48/172] - loss: 0.0878
Epoch 5 [49/172] - loss: 0.0847
Epoch 5 [50/172] - loss: 0.0896, acc: 1.0000
Epoch 5 [51/172] - loss: 0.0837
Epoch 5 [52/172] - loss: 0.0770
Epoch 5 [53/172] - loss: 0.0961
Epoch 5 [54/172] - loss: 0.0940
Epoch 5 [55/172] - loss: 0.0954
Epoch 5 [56/172] - loss: 0.0819
Epoch 5 [57/172] - loss: 0.0827
Epoch 5 [58/172] - loss: 0.0821
Epoch 5 [59/172] - loss: 0.1011
Epoch 5 [60/172] - loss: 0.0854, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1447
Epoch 5 [62/172] - loss: 0.0809
Epoch 5 [63/172] - loss: 0.1540
Epoch 5 [64/172] - loss: 0.0999
Epoch 5 [65/172] - loss: 0.0887
Epoch 5 [66/172] - loss: 0.0818
Epoch 5 [67/172] - loss: 0.0855
Epoch 5 [68/172] - loss: 0.1075
Epoch 5 [69/172] - loss: 0.0817
Epoch 5 [70/172] - loss: 0.0819, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0866
Epoch 5 [72/172] - loss: 0.0883
Epoch 5 [73/172] - loss: 0.1478
Epoch 5 [74/172] - loss: 0.0888
Epoch 5 [75/172] - loss: 0.0784
Epoch 5 [76/172] - loss: 0.0795
Epoch 5 [77/172] - loss: 0.0856
Epoch 5 [78/172] - loss: 0.1057
Epoch 5 [79/172] - loss: 0.0818
Epoch 5 [80/172] - loss: 0.0784, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1179
Epoch 5 [82/172] - loss: 0.0877
Epoch 5 [83/172] - loss: 0.0793
Epoch 5 [84/172] - loss: 0.0786
Epoch 5 [85/172] - loss: 0.1103
Epoch 5 [86/172] - loss: 0.0773
Epoch 5 [87/172] - loss: 0.1027
Epoch 5 [88/172] - loss: 0.1156
Epoch 5 [89/172] - loss: 0.0801
Epoch 5 [90/172] - loss: 0.1304, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0862
Epoch 5 [92/172] - loss: 0.0761
Epoch 5 [93/172] - loss: 0.0806
Epoch 5 [94/172] - loss: 0.0834
Epoch 5 [95/172] - loss: 0.0823
Epoch 5 [96/172] - loss: 0.0930
Epoch 5 [97/172] - loss: 0.0974
Epoch 5 [98/172] - loss: 0.1448
Epoch 5 [99/172] - loss: 0.1678
Epoch 5 [100/172] - loss: 0.0920, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0827
Epoch 5 [102/172] - loss: 0.0848
Epoch 5 [103/172] - loss: 0.0833
Epoch 5 [104/172] - loss: 0.1312
Epoch 5 [105/172] - loss: 0.2623
Epoch 5 [106/172] - loss: 0.0800
Epoch 5 [107/172] - loss: 0.0913
Epoch 5 [108/172] - loss: 0.1218
Epoch 5 [109/172] - loss: 0.0826
Epoch 5 [110/172] - loss: 0.0808, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1009
Epoch 5 [112/172] - loss: 0.0900

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2429, log_difficulty=0.2175, weight=2.0874
neutral: count=7825.0, difficulty=0.1898, log_difficulty=0.1738, weight=1.8691
negative: count=8780.0, difficulty=0.2403, log_difficulty=0.2153, weight=2.0767

当前batch的pt分布：
positive: min=0.2213, max=0.9908, mean=0.8603
neutral: min=0.8861, max=0.9947, mean=0.9612
negative: min=0.9952, max=0.9998, mean=0.9976

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1162
焦点损失: 0.0348
边界损失: 0.1699
总损失: 0.1213
Epoch 5 [113/172] - loss: 0.1213
Epoch 5 [114/172] - loss: 0.0921
Epoch 5 [115/172] - loss: 0.1292
Epoch 5 [116/172] - loss: 0.0819
Epoch 5 [117/172] - loss: 0.0924
Epoch 5 [118/172] - loss: 0.0756
Epoch 5 [119/172] - loss: 0.0776
Epoch 5 [120/172] - loss: 0.0793, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0924
Epoch 5 [122/172] - loss: 0.0788
Epoch 5 [123/172] - loss: 0.0841
Epoch 5 [124/172] - loss: 0.0781
Epoch 5 [125/172] - loss: 0.0781
Epoch 5 [126/172] - loss: 0.0901
Epoch 5 [127/172] - loss: 0.0876
Epoch 5 [128/172] - loss: 0.0826
Epoch 5 [129/172] - loss: 0.0960
Epoch 5 [130/172] - loss: 0.0754, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0855
Epoch 5 [132/172] - loss: 0.1022
Epoch 5 [133/172] - loss: 0.1024
Epoch 5 [134/172] - loss: 0.1590
Epoch 5 [135/172] - loss: 0.0757
Epoch 5 [136/172] - loss: 0.0811
Epoch 5 [137/172] - loss: 0.0929
Epoch 5 [138/172] - loss: 0.1217
Epoch 5 [139/172] - loss: 0.2101
Epoch 5 [140/172] - loss: 0.0914, acc: 1.0000
Epoch 5 [141/172] - loss: 0.0798
Epoch 5 [142/172] - loss: 0.0817
Epoch 5 [143/172] - loss: 0.0775
Epoch 5 [144/172] - loss: 0.0767
Epoch 5 [145/172] - loss: 0.0986
Epoch 5 [146/172] - loss: 0.0778
Epoch 5 [147/172] - loss: 0.1156
Epoch 5 [148/172] - loss: 0.0786
Epoch 5 [149/172] - loss: 0.0781
Epoch 5 [150/172] - loss: 0.1122, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0785
Epoch 5 [152/172] - loss: 0.0792
Epoch 5 [153/172] - loss: 0.0784
Epoch 5 [154/172] - loss: 0.0806
Epoch 5 [155/172] - loss: 0.0906
Epoch 5 [156/172] - loss: 0.0851
Epoch 5 [157/172] - loss: 0.1096
Epoch 5 [158/172] - loss: 0.0765
Epoch 5 [159/172] - loss: 0.0773
Epoch 5 [160/172] - loss: 0.0799, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0763
Epoch 5 [162/172] - loss: 0.0904
Epoch 5 [163/172] - loss: 0.0892
Epoch 5 [164/172] - loss: 0.0760
Epoch 5 [165/172] - loss: 0.1079
Epoch 5 [166/172] - loss: 0.0857
Epoch 5 [167/172] - loss: 0.0983
Epoch 5 [168/172] - loss: 0.0912
Epoch 5 [169/172] - loss: 0.0817
Epoch 5 [170/172] - loss: 0.0765, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0799
Epoch 5 [172/172] - loss: 0.0975

类别准确率:
positive: 0.8458 (395/467)
neutral: 0.3012 (25/83)
negative: 0.6360 (159/250)

Epoch 5/10
Train Loss: 0.0871, Train Acc: 0.9919
Val Loss: 0.7708, Val Acc: 0.7238
Early stopping triggered!
Best validation accuracy: 0.7400

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_093702-kej7bp8q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.35_Multimodal_iterations_20250118_093701
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/kej7bp8q
wandb: uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇████
wandb:  train_acc ▁▅▂▃▅▅▆▇▆▆▆▇▇▆▆▆██▇▆▇█████████▇█████████
wandb: train_loss ██▆▆▆▄▃▃▃▃▃▄▃▂▃▃▂▂▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 858
wandb:  train_acc 1
wandb: train_loss 0.07646
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.35_Multimodal_iterations_20250118_093701 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/kej7bp8q
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_093702-kej7bp8q/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_094445-pjxyii9h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.35_Multimodal_epochs_20250118_094445
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/pjxyii9h
wandb: uploading summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▃▅▆█
wandb:  train_acc ▁▅▇██
wandb: train_loss █▅▂▂▁
wandb:    val_acc ▁█▇▇▇
wandb:   val_loss █▁▄▅▄
wandb: 
wandb: Run summary:
wandb:      epoch 5
wandb:  train_acc 0.99192
wandb: train_loss 0.08712
wandb:    val_acc 0.72375
wandb:   val_loss 0.77084
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.35_Multimodal_epochs_20250118_094445 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/pjxyii9h
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_094445-pjxyii9h/logs

