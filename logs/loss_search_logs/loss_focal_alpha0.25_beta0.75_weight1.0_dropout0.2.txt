=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 1.0 --dropout 0.2 --name loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.2 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.2
text_dim: 128
image_dim: 256
dropout: 0.2
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6980, log_difficulty=0.5294, weight=3.6472
neutral: count=7.0, difficulty=0.6892, log_difficulty=0.5242, weight=3.6212
negative: count=13.0, difficulty=0.6569, log_difficulty=0.5050, weight=3.5248

当前batch的pt分布：
positive: min=0.1748, max=0.4884, mean=0.3020
neutral: min=0.1743, max=0.4673, mean=0.3108
negative: min=0.1711, max=0.7272, mean=0.3431

当前batch准确率：
整体准确率: 0.2812
positive 准确率: 0.1667
neutral 准确率: 0.4286
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1885
焦点损失: 0.4319
边界损失: 0.7564
总损失: 0.9554
Epoch 1 [1/172] - loss: 0.9554, acc: 0.2812
Epoch 1 [2/172] - loss: 0.9440
Epoch 1 [3/172] - loss: 1.0031
Epoch 1 [4/172] - loss: 0.8661
Epoch 1 [5/172] - loss: 0.9813
Epoch 1 [6/172] - loss: 0.9796
Epoch 1 [7/172] - loss: 0.8645
Epoch 1 [8/172] - loss: 0.8537
Epoch 1 [9/172] - loss: 0.7900
Epoch 1 [10/172] - loss: 0.8983, acc: 0.3438
Epoch 1 [11/172] - loss: 0.7965
Epoch 1 [12/172] - loss: 0.8198
Epoch 1 [13/172] - loss: 0.6685
Epoch 1 [14/172] - loss: 0.8699
Epoch 1 [15/172] - loss: 0.8617
Epoch 1 [16/172] - loss: 0.8274
Epoch 1 [17/172] - loss: 0.7297
Epoch 1 [18/172] - loss: 0.9005
Epoch 1 [19/172] - loss: 0.8399
Epoch 1 [20/172] - loss: 0.9556, acc: 0.3125
Epoch 1 [21/172] - loss: 0.7813
Epoch 1 [22/172] - loss: 0.6863
Epoch 1 [23/172] - loss: 0.6870
Epoch 1 [24/172] - loss: 0.9305
Epoch 1 [25/172] - loss: 0.9241
Epoch 1 [26/172] - loss: 0.8321
Epoch 1 [27/172] - loss: 0.8178
Epoch 1 [28/172] - loss: 0.7510
Epoch 1 [29/172] - loss: 0.7898
Epoch 1 [30/172] - loss: 0.6193, acc: 0.6875
Epoch 1 [31/172] - loss: 0.8046
Epoch 1 [32/172] - loss: 0.6930
Epoch 1 [33/172] - loss: 0.6843
Epoch 1 [34/172] - loss: 0.5986
Epoch 1 [35/172] - loss: 0.8549
Epoch 1 [36/172] - loss: 0.5198
Epoch 1 [37/172] - loss: 0.7163
Epoch 1 [38/172] - loss: 0.7584
Epoch 1 [39/172] - loss: 0.6589
Epoch 1 [40/172] - loss: 0.7114, acc: 0.5938
Epoch 1 [41/172] - loss: 0.5763
Epoch 1 [42/172] - loss: 0.6568
Epoch 1 [43/172] - loss: 0.6493
Epoch 1 [44/172] - loss: 0.7470
Epoch 1 [45/172] - loss: 0.7511
Epoch 1 [46/172] - loss: 0.6063
Epoch 1 [47/172] - loss: 0.6132
Epoch 1 [48/172] - loss: 0.5586
Epoch 1 [49/172] - loss: 0.7751
Epoch 1 [50/172] - loss: 0.4967, acc: 0.6875
Epoch 1 [51/172] - loss: 0.6308
Epoch 1 [52/172] - loss: 0.6608
Epoch 1 [53/172] - loss: 0.7810
Epoch 1 [54/172] - loss: 0.7936
Epoch 1 [55/172] - loss: 0.5600
Epoch 1 [56/172] - loss: 0.5423
Epoch 1 [57/172] - loss: 0.8935
Epoch 1 [58/172] - loss: 0.5364
Epoch 1 [59/172] - loss: 0.6644
Epoch 1 [60/172] - loss: 0.5107, acc: 0.6875
Epoch 1 [61/172] - loss: 0.6631
Epoch 1 [62/172] - loss: 0.4943
Epoch 1 [63/172] - loss: 0.5450
Epoch 1 [64/172] - loss: 0.4625
Epoch 1 [65/172] - loss: 0.5275
Epoch 1 [66/172] - loss: 0.6422
Epoch 1 [67/172] - loss: 0.6267
Epoch 1 [68/172] - loss: 0.7380
Epoch 1 [69/172] - loss: 0.7806
Epoch 1 [70/172] - loss: 0.5943, acc: 0.5625
Epoch 1 [71/172] - loss: 0.4138
Epoch 1 [72/172] - loss: 0.7179
Epoch 1 [73/172] - loss: 0.7281
Epoch 1 [74/172] - loss: 0.5483
Epoch 1 [75/172] - loss: 0.4008
Epoch 1 [76/172] - loss: 0.5800
Epoch 1 [77/172] - loss: 0.4974
Epoch 1 [78/172] - loss: 0.5195
Epoch 1 [79/172] - loss: 0.5568
Epoch 1 [80/172] - loss: 0.5145, acc: 0.6562
Epoch 1 [81/172] - loss: 0.4234
Epoch 1 [82/172] - loss: 0.6860
Epoch 1 [83/172] - loss: 0.5120
Epoch 1 [84/172] - loss: 0.3554
Epoch 1 [85/172] - loss: 0.4287
Epoch 1 [86/172] - loss: 0.5098
Epoch 1 [87/172] - loss: 0.4206
Epoch 1 [88/172] - loss: 0.6621
Epoch 1 [89/172] - loss: 0.8085
Epoch 1 [90/172] - loss: 0.4767, acc: 0.7500
Epoch 1 [91/172] - loss: 0.4641
Epoch 1 [92/172] - loss: 0.4091
Epoch 1 [93/172] - loss: 0.4435
Epoch 1 [94/172] - loss: 0.3398
Epoch 1 [95/172] - loss: 0.3478
Epoch 1 [96/172] - loss: 0.4164
Epoch 1 [97/172] - loss: 0.4882
Epoch 1 [98/172] - loss: 0.4959
Epoch 1 [99/172] - loss: 0.5829
Epoch 1 [100/172] - loss: 0.5537, acc: 0.7188

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5784, log_difficulty=0.4564, weight=3.2820
neutral: count=983.0, difficulty=0.4441, log_difficulty=0.3675, weight=2.8375
negative: count=1119.0, difficulty=0.4931, log_difficulty=0.4008, weight=3.0042

当前batch的pt分布：
positive: min=0.0079, max=0.9806, mean=0.4905
neutral: min=0.5825, max=0.9907, mean=0.8135
negative: min=0.0915, max=0.8875, mean=0.4738

当前batch准确率：
整体准确率: 0.6562
positive 准确率: 0.5833
neutral 准确率: 1.0000
negative 准确率: 0.6250

损失分量：
基础交叉熵: 0.9034
焦点损失: 0.4384
边界损失: 0.4069
总损失: 0.6532
Epoch 1 [101/172] - loss: 0.6532
Epoch 1 [102/172] - loss: 0.5027
Epoch 1 [103/172] - loss: 0.3698
Epoch 1 [104/172] - loss: 0.3087
Epoch 1 [105/172] - loss: 0.5682
Epoch 1 [106/172] - loss: 0.5129
Epoch 1 [107/172] - loss: 0.5320
Epoch 1 [108/172] - loss: 0.6910
Epoch 1 [109/172] - loss: 0.4096
Epoch 1 [110/172] - loss: 0.4354, acc: 0.7188
Epoch 1 [111/172] - loss: 0.5401
Epoch 1 [112/172] - loss: 0.3042
Epoch 1 [113/172] - loss: 0.3193
Epoch 1 [114/172] - loss: 0.4298
Epoch 1 [115/172] - loss: 0.5305
Epoch 1 [116/172] - loss: 0.4052
Epoch 1 [117/172] - loss: 0.4404
Epoch 1 [118/172] - loss: 0.3811
Epoch 1 [119/172] - loss: 0.6112
Epoch 1 [120/172] - loss: 0.4519, acc: 0.7500
Epoch 1 [121/172] - loss: 0.3273
Epoch 1 [122/172] - loss: 0.5387
Epoch 1 [123/172] - loss: 0.3262
Epoch 1 [124/172] - loss: 0.3521
Epoch 1 [125/172] - loss: 0.3243
Epoch 1 [126/172] - loss: 0.5569
Epoch 1 [127/172] - loss: 0.4261
Epoch 1 [128/172] - loss: 0.4021
Epoch 1 [129/172] - loss: 0.5840
Epoch 1 [130/172] - loss: 0.3258, acc: 0.8750
Epoch 1 [131/172] - loss: 0.2061
Epoch 1 [132/172] - loss: 0.4363
Epoch 1 [133/172] - loss: 0.4816
Epoch 1 [134/172] - loss: 0.3419
Epoch 1 [135/172] - loss: 0.5117
Epoch 1 [136/172] - loss: 0.3165
Epoch 1 [137/172] - loss: 0.5401
Epoch 1 [138/172] - loss: 0.3561
Epoch 1 [139/172] - loss: 0.3368
Epoch 1 [140/172] - loss: 0.3369, acc: 0.7500
Epoch 1 [141/172] - loss: 0.4627
Epoch 1 [142/172] - loss: 0.4856
Epoch 1 [143/172] - loss: 0.3971
Epoch 1 [144/172] - loss: 0.2266
Epoch 1 [145/172] - loss: 0.4691
Epoch 1 [146/172] - loss: 0.4359
Epoch 1 [147/172] - loss: 0.5840
Epoch 1 [148/172] - loss: 0.3233
Epoch 1 [149/172] - loss: 0.3246
Epoch 1 [150/172] - loss: 0.4267, acc: 0.7500
Epoch 1 [151/172] - loss: 0.3935
Epoch 1 [152/172] - loss: 0.4469
Epoch 1 [153/172] - loss: 0.2871
Epoch 1 [154/172] - loss: 0.2927
Epoch 1 [155/172] - loss: 0.4045
Epoch 1 [156/172] - loss: 0.6474
Epoch 1 [157/172] - loss: 0.3328
Epoch 1 [158/172] - loss: 0.4267
Epoch 1 [159/172] - loss: 0.4908
Epoch 1 [160/172] - loss: 0.3534, acc: 0.7812
Epoch 1 [161/172] - loss: 0.3361
Epoch 1 [162/172] - loss: 0.3015
Epoch 1 [163/172] - loss: 0.3568
Epoch 1 [164/172] - loss: 0.3875
Epoch 1 [165/172] - loss: 0.3427
Epoch 1 [166/172] - loss: 0.3320
Epoch 1 [167/172] - loss: 0.2766
Epoch 1 [168/172] - loss: 0.4135
Epoch 1 [169/172] - loss: 0.3206
Epoch 1 [170/172] - loss: 0.3315, acc: 0.7812
Epoch 1 [171/172] - loss: 0.2783
Epoch 1 [172/172] - loss: 0.3947

类别准确率:
positive: 0.7173 (335/467)
neutral: 0.4699 (39/83)
negative: 0.7680 (192/250)

Epoch 1/10
Train Loss: 0.3547, Train Acc: 0.7899
Val Loss: 0.7197, Val Acc: 0.7075
Epoch 2 [1/172] - loss: 0.3054, acc: 0.8750
Epoch 2 [2/172] - loss: 0.2983
Epoch 2 [3/172] - loss: 0.2699
Epoch 2 [4/172] - loss: 0.3167
Epoch 2 [5/172] - loss: 0.4162
Epoch 2 [6/172] - loss: 0.3508
Epoch 2 [7/172] - loss: 0.3174
Epoch 2 [8/172] - loss: 0.3354
Epoch 2 [9/172] - loss: 0.2712
Epoch 2 [10/172] - loss: 0.3106, acc: 0.8438
Epoch 2 [11/172] - loss: 0.2281
Epoch 2 [12/172] - loss: 0.3404
Epoch 2 [13/172] - loss: 0.3800
Epoch 2 [14/172] - loss: 0.3753
Epoch 2 [15/172] - loss: 0.3314
Epoch 2 [16/172] - loss: 0.2790
Epoch 2 [17/172] - loss: 0.3636
Epoch 2 [18/172] - loss: 0.3693
Epoch 2 [19/172] - loss: 0.3097
Epoch 2 [20/172] - loss: 0.2939, acc: 0.8125
Epoch 2 [21/172] - loss: 0.3196
Epoch 2 [22/172] - loss: 0.2385
Epoch 2 [23/172] - loss: 0.2676
Epoch 2 [24/172] - loss: 0.4934
Epoch 2 [25/172] - loss: 0.3239
Epoch 2 [26/172] - loss: 0.2363
Epoch 2 [27/172] - loss: 0.2985
Epoch 2 [28/172] - loss: 0.2502

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4690, log_difficulty=0.3846, weight=2.9228
neutral: count=1952.0, difficulty=0.3360, log_difficulty=0.2897, weight=2.4484
negative: count=2216.0, difficulty=0.4147, log_difficulty=0.3469, weight=2.7345

当前batch的pt分布：
positive: min=0.2053, max=0.9982, mean=0.7024
neutral: min=0.4136, max=0.9918, mean=0.8220
negative: min=0.0069, max=0.9475, mean=0.7060

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.7778
neutral 准确率: 1.0000
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.4778
焦点损失: 0.2377
边界损失: 0.2634
总损失: 0.3618
Epoch 2 [29/172] - loss: 0.3618
Epoch 2 [30/172] - loss: 0.4643, acc: 0.7812
Epoch 2 [31/172] - loss: 0.2433
Epoch 2 [32/172] - loss: 0.2294
Epoch 2 [33/172] - loss: 0.2275
Epoch 2 [34/172] - loss: 0.3169
Epoch 2 [35/172] - loss: 0.2756
Epoch 2 [36/172] - loss: 0.3456
Epoch 2 [37/172] - loss: 0.2286
Epoch 2 [38/172] - loss: 0.2882
Epoch 2 [39/172] - loss: 0.3267
Epoch 2 [40/172] - loss: 0.4522, acc: 0.7500
Epoch 2 [41/172] - loss: 0.2498
Epoch 2 [42/172] - loss: 0.2402
Epoch 2 [43/172] - loss: 0.1609
Epoch 2 [44/172] - loss: 0.3326
Epoch 2 [45/172] - loss: 0.2431
Epoch 2 [46/172] - loss: 0.2163
Epoch 2 [47/172] - loss: 0.2850
Epoch 2 [48/172] - loss: 0.2954
Epoch 2 [49/172] - loss: 0.2742
Epoch 2 [50/172] - loss: 0.3336, acc: 0.8125
Epoch 2 [51/172] - loss: 0.3197
Epoch 2 [52/172] - loss: 0.2587
Epoch 2 [53/172] - loss: 0.2474
Epoch 2 [54/172] - loss: 0.2505
Epoch 2 [55/172] - loss: 0.2546
Epoch 2 [56/172] - loss: 0.2349
Epoch 2 [57/172] - loss: 0.2499
Epoch 2 [58/172] - loss: 0.3035
Epoch 2 [59/172] - loss: 0.3920
Epoch 2 [60/172] - loss: 0.2242, acc: 0.9062
Epoch 2 [61/172] - loss: 0.1828
Epoch 2 [62/172] - loss: 0.2027
Epoch 2 [63/172] - loss: 0.2909
Epoch 2 [64/172] - loss: 0.4215
Epoch 2 [65/172] - loss: 0.2945
Epoch 2 [66/172] - loss: 0.2079
Epoch 2 [67/172] - loss: 0.2326
Epoch 2 [68/172] - loss: 0.3546
Epoch 2 [69/172] - loss: 0.1965
Epoch 2 [70/172] - loss: 0.3089, acc: 0.8125
Epoch 2 [71/172] - loss: 0.3287
Epoch 2 [72/172] - loss: 0.2160
Epoch 2 [73/172] - loss: 0.3062
Epoch 2 [74/172] - loss: 0.1791
Epoch 2 [75/172] - loss: 0.2123
Epoch 2 [76/172] - loss: 0.2888
Epoch 2 [77/172] - loss: 0.3398
Epoch 2 [78/172] - loss: 0.2841
Epoch 2 [79/172] - loss: 0.3308
Epoch 2 [80/172] - loss: 0.2069, acc: 0.9375
Epoch 2 [81/172] - loss: 0.1971
Epoch 2 [82/172] - loss: 0.1661
Epoch 2 [83/172] - loss: 0.2329
Epoch 2 [84/172] - loss: 0.2286
Epoch 2 [85/172] - loss: 0.2270
Epoch 2 [86/172] - loss: 0.2282
Epoch 2 [87/172] - loss: 0.4298
Epoch 2 [88/172] - loss: 0.2098
Epoch 2 [89/172] - loss: 0.1974
Epoch 2 [90/172] - loss: 0.2539, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1522
Epoch 2 [92/172] - loss: 0.2732
Epoch 2 [93/172] - loss: 0.1991
Epoch 2 [94/172] - loss: 0.1770
Epoch 2 [95/172] - loss: 0.3082
Epoch 2 [96/172] - loss: 0.1652
Epoch 2 [97/172] - loss: 0.2102
Epoch 2 [98/172] - loss: 0.1916
Epoch 2 [99/172] - loss: 0.1570
Epoch 2 [100/172] - loss: 0.2341, acc: 0.8750
Epoch 2 [101/172] - loss: 0.1971
Epoch 2 [102/172] - loss: 0.1945
Epoch 2 [103/172] - loss: 0.2924
Epoch 2 [104/172] - loss: 0.2192
Epoch 2 [105/172] - loss: 0.1702
Epoch 2 [106/172] - loss: 0.1727
Epoch 2 [107/172] - loss: 0.1612
Epoch 2 [108/172] - loss: 0.3449
Epoch 2 [109/172] - loss: 0.1923
Epoch 2 [110/172] - loss: 0.2101, acc: 0.9688
Epoch 2 [111/172] - loss: 0.2358
Epoch 2 [112/172] - loss: 0.2167
Epoch 2 [113/172] - loss: 0.1507
Epoch 2 [114/172] - loss: 0.2003
Epoch 2 [115/172] - loss: 0.2269
Epoch 2 [116/172] - loss: 0.2286
Epoch 2 [117/172] - loss: 0.4389
Epoch 2 [118/172] - loss: 0.2140
Epoch 2 [119/172] - loss: 0.2623
Epoch 2 [120/172] - loss: 0.1729, acc: 0.9688
Epoch 2 [121/172] - loss: 0.1716
Epoch 2 [122/172] - loss: 0.4476
Epoch 2 [123/172] - loss: 0.2195
Epoch 2 [124/172] - loss: 0.1825
Epoch 2 [125/172] - loss: 0.1631
Epoch 2 [126/172] - loss: 0.2223
Epoch 2 [127/172] - loss: 0.1733
Epoch 2 [128/172] - loss: 0.2038

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3903, log_difficulty=0.3295, weight=2.6474
neutral: count=2949.0, difficulty=0.2610, log_difficulty=0.2319, weight=2.1594
negative: count=3294.0, difficulty=0.3502, log_difficulty=0.3003, weight=2.5013

当前batch的pt分布：
positive: min=0.4224, max=0.9956, mean=0.8566
neutral: min=0.7686, max=0.9942, mean=0.9307
negative: min=0.1199, max=0.9898, mean=0.7317

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.2485
焦点损失: 0.0905
边界损失: 0.2060
总损失: 0.2114
Epoch 2 [129/172] - loss: 0.2114
Epoch 2 [130/172] - loss: 0.2243, acc: 0.8750
Epoch 2 [131/172] - loss: 0.2381
Epoch 2 [132/172] - loss: 0.2299
Epoch 2 [133/172] - loss: 0.2262
Epoch 2 [134/172] - loss: 0.2170
Epoch 2 [135/172] - loss: 0.3521
Epoch 2 [136/172] - loss: 0.2191
Epoch 2 [137/172] - loss: 0.1603
Epoch 2 [138/172] - loss: 0.2308
Epoch 2 [139/172] - loss: 0.2058
Epoch 2 [140/172] - loss: 0.1749, acc: 0.9375
Epoch 2 [141/172] - loss: 0.2371
Epoch 2 [142/172] - loss: 0.1980
Epoch 2 [143/172] - loss: 0.2345
Epoch 2 [144/172] - loss: 0.1642
Epoch 2 [145/172] - loss: 0.3723
Epoch 2 [146/172] - loss: 0.2084
Epoch 2 [147/172] - loss: 0.2088
Epoch 2 [148/172] - loss: 0.2014
Epoch 2 [149/172] - loss: 0.2246
Epoch 2 [150/172] - loss: 0.1840, acc: 0.9375
Epoch 2 [151/172] - loss: 0.1943
Epoch 2 [152/172] - loss: 0.1964
Epoch 2 [153/172] - loss: 0.1554
Epoch 2 [154/172] - loss: 0.2461
Epoch 2 [155/172] - loss: 0.1846
Epoch 2 [156/172] - loss: 0.1862
Epoch 2 [157/172] - loss: 0.1882
Epoch 2 [158/172] - loss: 0.2926
Epoch 2 [159/172] - loss: 0.2347
Epoch 2 [160/172] - loss: 0.1595, acc: 1.0000
Epoch 2 [161/172] - loss: 0.2384
Epoch 2 [162/172] - loss: 0.1478
Epoch 2 [163/172] - loss: 0.3546
Epoch 2 [164/172] - loss: 0.2472
Epoch 2 [165/172] - loss: 0.2647
Epoch 2 [166/172] - loss: 0.2062
Epoch 2 [167/172] - loss: 0.2943
Epoch 2 [168/172] - loss: 0.1937
Epoch 2 [169/172] - loss: 0.1744
Epoch 2 [170/172] - loss: 0.2125, acc: 0.9688
Epoch 2 [171/172] - loss: 0.2687
Epoch 2 [172/172] - loss: 0.5190

类别准确率:
positive: 0.8672 (405/467)
neutral: 0.3735 (31/83)
negative: 0.5760 (144/250)

Epoch 2/10
Train Loss: 0.2498, Train Acc: 0.9091
Val Loss: 0.8145, Val Acc: 0.7250
Epoch 3 [1/172] - loss: 0.1746, acc: 0.9688
Epoch 3 [2/172] - loss: 0.2303
Epoch 3 [3/172] - loss: 0.1363
Epoch 3 [4/172] - loss: 0.1299
Epoch 3 [5/172] - loss: 0.1927
Epoch 3 [6/172] - loss: 0.1339
Epoch 3 [7/172] - loss: 0.1512
Epoch 3 [8/172] - loss: 0.1795
Epoch 3 [9/172] - loss: 0.1592
Epoch 3 [10/172] - loss: 0.1820, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1592
Epoch 3 [12/172] - loss: 0.1633
Epoch 3 [13/172] - loss: 0.1608
Epoch 3 [14/172] - loss: 0.1372
Epoch 3 [15/172] - loss: 0.1361
Epoch 3 [16/172] - loss: 0.2789
Epoch 3 [17/172] - loss: 0.1558
Epoch 3 [18/172] - loss: 0.2142
Epoch 3 [19/172] - loss: 0.1552
Epoch 3 [20/172] - loss: 0.1202, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1628
Epoch 3 [22/172] - loss: 0.2127
Epoch 3 [23/172] - loss: 0.1329
Epoch 3 [24/172] - loss: 0.1352
Epoch 3 [25/172] - loss: 0.1254
Epoch 3 [26/172] - loss: 0.1401
Epoch 3 [27/172] - loss: 0.1357
Epoch 3 [28/172] - loss: 0.1383
Epoch 3 [29/172] - loss: 0.1833
Epoch 3 [30/172] - loss: 0.1644, acc: 0.9375
Epoch 3 [31/172] - loss: 0.1441
Epoch 3 [32/172] - loss: 0.1808
Epoch 3 [33/172] - loss: 0.1287
Epoch 3 [34/172] - loss: 0.1598
Epoch 3 [35/172] - loss: 0.1927
Epoch 3 [36/172] - loss: 0.1491
Epoch 3 [37/172] - loss: 0.1882
Epoch 3 [38/172] - loss: 0.1238
Epoch 3 [39/172] - loss: 0.1342
Epoch 3 [40/172] - loss: 0.1444, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1465
Epoch 3 [42/172] - loss: 0.1705
Epoch 3 [43/172] - loss: 0.1677
Epoch 3 [44/172] - loss: 0.1369
Epoch 3 [45/172] - loss: 0.1954
Epoch 3 [46/172] - loss: 0.1363
Epoch 3 [47/172] - loss: 0.1280
Epoch 3 [48/172] - loss: 0.1740
Epoch 3 [49/172] - loss: 0.1196
Epoch 3 [50/172] - loss: 0.1540, acc: 0.9688
Epoch 3 [51/172] - loss: 0.1588
Epoch 3 [52/172] - loss: 0.2140
Epoch 3 [53/172] - loss: 0.1151
Epoch 3 [54/172] - loss: 0.1825
Epoch 3 [55/172] - loss: 0.1323
Epoch 3 [56/172] - loss: 0.1394

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3285, log_difficulty=0.2841, weight=2.4204
neutral: count=3923.0, difficulty=0.2170, log_difficulty=0.1964, weight=1.9821
negative: count=4382.0, difficulty=0.2979, log_difficulty=0.2607, weight=2.3036

当前batch的pt分布：
positive: min=0.4081, max=0.9996, mean=0.8254
neutral: min=0.0077, max=0.9934, mean=0.8472
negative: min=0.9920, max=0.9994, mean=0.9957

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2850
焦点损失: 0.1679
边界损失: 0.1960
总损失: 0.2320
Epoch 3 [57/172] - loss: 0.2320
Epoch 3 [58/172] - loss: 0.1362
Epoch 3 [59/172] - loss: 0.2246
Epoch 3 [60/172] - loss: 0.1209, acc: 1.0000
Epoch 3 [61/172] - loss: 0.1713
Epoch 3 [62/172] - loss: 0.1265
Epoch 3 [63/172] - loss: 0.1337
Epoch 3 [64/172] - loss: 0.1420
Epoch 3 [65/172] - loss: 0.1529
Epoch 3 [66/172] - loss: 0.2036
Epoch 3 [67/172] - loss: 0.1373
Epoch 3 [68/172] - loss: 0.1521
Epoch 3 [69/172] - loss: 0.2450
Epoch 3 [70/172] - loss: 0.1209, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1276
Epoch 3 [72/172] - loss: 0.2124
Epoch 3 [73/172] - loss: 0.1432
Epoch 3 [74/172] - loss: 0.1856
Epoch 3 [75/172] - loss: 0.1621
Epoch 3 [76/172] - loss: 0.1195
Epoch 3 [77/172] - loss: 0.1241
Epoch 3 [78/172] - loss: 0.1970
Epoch 3 [79/172] - loss: 0.1553
Epoch 3 [80/172] - loss: 0.1543, acc: 0.9688
Epoch 3 [81/172] - loss: 0.1578
Epoch 3 [82/172] - loss: 0.1943
Epoch 3 [83/172] - loss: 0.1163
Epoch 3 [84/172] - loss: 0.1190
Epoch 3 [85/172] - loss: 0.1248
Epoch 3 [86/172] - loss: 0.1240
Epoch 3 [87/172] - loss: 0.2131
Epoch 3 [88/172] - loss: 0.2016
Epoch 3 [89/172] - loss: 0.1323
Epoch 3 [90/172] - loss: 0.1173, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1652
Epoch 3 [92/172] - loss: 0.1706
Epoch 3 [93/172] - loss: 0.1675
Epoch 3 [94/172] - loss: 0.1424
Epoch 3 [95/172] - loss: 0.1693
Epoch 3 [96/172] - loss: 0.1467
Epoch 3 [97/172] - loss: 0.1484
Epoch 3 [98/172] - loss: 0.1244
Epoch 3 [99/172] - loss: 0.1200
Epoch 3 [100/172] - loss: 0.1402, acc: 0.9688
Epoch 3 [101/172] - loss: 0.1614
Epoch 3 [102/172] - loss: 0.1214
Epoch 3 [103/172] - loss: 0.1831
Epoch 3 [104/172] - loss: 0.1461
Epoch 3 [105/172] - loss: 0.1310
Epoch 3 [106/172] - loss: 0.1604
Epoch 3 [107/172] - loss: 0.1561
Epoch 3 [108/172] - loss: 0.1322
Epoch 3 [109/172] - loss: 0.1266
Epoch 3 [110/172] - loss: 0.1885, acc: 0.9062
Epoch 3 [111/172] - loss: 0.1583
Epoch 3 [112/172] - loss: 0.1251
Epoch 3 [113/172] - loss: 0.1489
Epoch 3 [114/172] - loss: 0.1450
Epoch 3 [115/172] - loss: 0.1322
Epoch 3 [116/172] - loss: 0.1690
Epoch 3 [117/172] - loss: 0.1453
Epoch 3 [118/172] - loss: 0.1341
Epoch 3 [119/172] - loss: 0.1411
Epoch 3 [120/172] - loss: 0.1567, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1633
Epoch 3 [122/172] - loss: 0.1564
Epoch 3 [123/172] - loss: 0.1304
Epoch 3 [124/172] - loss: 0.1509
Epoch 3 [125/172] - loss: 0.1559
Epoch 3 [126/172] - loss: 0.1836
Epoch 3 [127/172] - loss: 0.2022
Epoch 3 [128/172] - loss: 0.1140
Epoch 3 [129/172] - loss: 0.1232
Epoch 3 [130/172] - loss: 0.1235, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1530
Epoch 3 [132/172] - loss: 0.1210
Epoch 3 [133/172] - loss: 0.1605
Epoch 3 [134/172] - loss: 0.1151
Epoch 3 [135/172] - loss: 0.1422
Epoch 3 [136/172] - loss: 0.1389
Epoch 3 [137/172] - loss: 0.1429
Epoch 3 [138/172] - loss: 0.1525
Epoch 3 [139/172] - loss: 0.1385
Epoch 3 [140/172] - loss: 0.1594, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1755
Epoch 3 [142/172] - loss: 0.2010
Epoch 3 [143/172] - loss: 0.1616
Epoch 3 [144/172] - loss: 0.2382
Epoch 3 [145/172] - loss: 0.1433
Epoch 3 [146/172] - loss: 0.1235
Epoch 3 [147/172] - loss: 0.1481
Epoch 3 [148/172] - loss: 0.1285
Epoch 3 [149/172] - loss: 0.1347
Epoch 3 [150/172] - loss: 0.1382, acc: 0.9688
Epoch 3 [151/172] - loss: 0.2336
Epoch 3 [152/172] - loss: 0.2225
Epoch 3 [153/172] - loss: 0.1384
Epoch 3 [154/172] - loss: 0.1191
Epoch 3 [155/172] - loss: 0.1384
Epoch 3 [156/172] - loss: 0.1233

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2820, log_difficulty=0.2484, weight=2.2420
neutral: count=4903.0, difficulty=0.1846, log_difficulty=0.1694, weight=1.8469
negative: count=5500.0, difficulty=0.2566, log_difficulty=0.2284, weight=2.1420

当前batch的pt分布：
positive: min=0.8487, max=0.9983, mean=0.9651
neutral: min=0.2681, max=0.9984, mean=0.8957
negative: min=0.8323, max=0.9973, mean=0.9516

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9091
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0837
焦点损失: 0.0225
边界损失: 0.1610
总损失: 0.1312
Epoch 3 [157/172] - loss: 0.1312
Epoch 3 [158/172] - loss: 0.2198
Epoch 3 [159/172] - loss: 0.1583
Epoch 3 [160/172] - loss: 0.1683, acc: 0.9375
Epoch 3 [161/172] - loss: 0.2538
Epoch 3 [162/172] - loss: 0.1322
Epoch 3 [163/172] - loss: 0.1438
Epoch 3 [164/172] - loss: 0.1115
Epoch 3 [165/172] - loss: 0.1267
Epoch 3 [166/172] - loss: 0.1524
Epoch 3 [167/172] - loss: 0.1329
Epoch 3 [168/172] - loss: 0.1201
Epoch 3 [169/172] - loss: 0.1182
Epoch 3 [170/172] - loss: 0.1875, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1171
Epoch 3 [172/172] - loss: 0.1160

类别准确率:
positive: 0.9165 (428/467)
neutral: 0.1928 (16/83)
negative: 0.5240 (131/250)

Epoch 3/10
Train Loss: 0.1494, Train Acc: 0.9697
Val Loss: 0.8858, Val Acc: 0.7188
Epoch 4 [1/172] - loss: 0.1755, acc: 0.9375
Epoch 4 [2/172] - loss: 0.1760
Epoch 4 [3/172] - loss: 0.1417
Epoch 4 [4/172] - loss: 0.1157
Epoch 4 [5/172] - loss: 0.1352
Epoch 4 [6/172] - loss: 0.1100
Epoch 4 [7/172] - loss: 0.1227
Epoch 4 [8/172] - loss: 0.1676
Epoch 4 [9/172] - loss: 0.1384
Epoch 4 [10/172] - loss: 0.1335, acc: 0.9688
Epoch 4 [11/172] - loss: 0.1107
Epoch 4 [12/172] - loss: 0.1233
Epoch 4 [13/172] - loss: 0.1640
Epoch 4 [14/172] - loss: 0.1602
Epoch 4 [15/172] - loss: 0.1434
Epoch 4 [16/172] - loss: 0.1159
Epoch 4 [17/172] - loss: 0.1178
Epoch 4 [18/172] - loss: 0.1603
Epoch 4 [19/172] - loss: 0.1189
Epoch 4 [20/172] - loss: 0.1168, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1495
Epoch 4 [22/172] - loss: 0.1191
Epoch 4 [23/172] - loss: 0.1289
Epoch 4 [24/172] - loss: 0.1232
Epoch 4 [25/172] - loss: 0.1157
Epoch 4 [26/172] - loss: 0.2536
Epoch 4 [27/172] - loss: 0.1140
Epoch 4 [28/172] - loss: 0.1483
Epoch 4 [29/172] - loss: 0.1086
Epoch 4 [30/172] - loss: 0.1628, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1684
Epoch 4 [32/172] - loss: 0.1208
Epoch 4 [33/172] - loss: 0.1436
Epoch 4 [34/172] - loss: 0.1144
Epoch 4 [35/172] - loss: 0.1925
Epoch 4 [36/172] - loss: 0.1160
Epoch 4 [37/172] - loss: 0.1082
Epoch 4 [38/172] - loss: 0.1093
Epoch 4 [39/172] - loss: 0.1516
Epoch 4 [40/172] - loss: 0.1874, acc: 0.9375
Epoch 4 [41/172] - loss: 0.1145
Epoch 4 [42/172] - loss: 0.2045
Epoch 4 [43/172] - loss: 0.1961
Epoch 4 [44/172] - loss: 0.1144
Epoch 4 [45/172] - loss: 0.1114
Epoch 4 [46/172] - loss: 0.1139
Epoch 4 [47/172] - loss: 0.1416
Epoch 4 [48/172] - loss: 0.1204
Epoch 4 [49/172] - loss: 0.1206
Epoch 4 [50/172] - loss: 0.1645, acc: 0.9062
Epoch 4 [51/172] - loss: 0.1137
Epoch 4 [52/172] - loss: 0.1416
Epoch 4 [53/172] - loss: 0.1218
Epoch 4 [54/172] - loss: 0.1232
Epoch 4 [55/172] - loss: 0.2189
Epoch 4 [56/172] - loss: 0.1640
Epoch 4 [57/172] - loss: 0.1230
Epoch 4 [58/172] - loss: 0.1246
Epoch 4 [59/172] - loss: 0.1115
Epoch 4 [60/172] - loss: 0.1182, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1250
Epoch 4 [62/172] - loss: 0.1761
Epoch 4 [63/172] - loss: 0.1163
Epoch 4 [64/172] - loss: 0.1332
Epoch 4 [65/172] - loss: 0.1266
Epoch 4 [66/172] - loss: 0.1103
Epoch 4 [67/172] - loss: 0.1257
Epoch 4 [68/172] - loss: 0.1190
Epoch 4 [69/172] - loss: 0.1356
Epoch 4 [70/172] - loss: 0.1169, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1272
Epoch 4 [72/172] - loss: 0.1550
Epoch 4 [73/172] - loss: 0.1113
Epoch 4 [74/172] - loss: 0.2184
Epoch 4 [75/172] - loss: 0.1542
Epoch 4 [76/172] - loss: 0.1116
Epoch 4 [77/172] - loss: 0.1223
Epoch 4 [78/172] - loss: 0.1136
Epoch 4 [79/172] - loss: 0.1169
Epoch 4 [80/172] - loss: 0.1243, acc: 0.9688
Epoch 4 [81/172] - loss: 0.1400
Epoch 4 [82/172] - loss: 0.1213
Epoch 4 [83/172] - loss: 0.1278
Epoch 4 [84/172] - loss: 0.1085

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2464, log_difficulty=0.2203, weight=2.1014
neutral: count=5865.0, difficulty=0.1620, log_difficulty=0.1502, weight=1.7509
negative: count=6629.0, difficulty=0.2246, log_difficulty=0.2026, weight=2.0131

当前batch的pt分布：
positive: min=0.6138, max=0.9946, mean=0.9058
neutral: min=0.9322, max=0.9998, mean=0.9872
negative: min=0.3471, max=0.9982, mean=0.9179

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.0928
焦点损失: 0.0172
边界损失: 0.1688
总损失: 0.1353
Epoch 4 [85/172] - loss: 0.1353
Epoch 4 [86/172] - loss: 0.1359
Epoch 4 [87/172] - loss: 0.1250
Epoch 4 [88/172] - loss: 0.1323
Epoch 4 [89/172] - loss: 0.1267
Epoch 4 [90/172] - loss: 0.1379, acc: 0.9688
Epoch 4 [91/172] - loss: 0.1843
Epoch 4 [92/172] - loss: 0.2247
Epoch 4 [93/172] - loss: 0.1176
Epoch 4 [94/172] - loss: 0.1135
Epoch 4 [95/172] - loss: 0.1290
Epoch 4 [96/172] - loss: 0.1203
Epoch 4 [97/172] - loss: 0.1193
Epoch 4 [98/172] - loss: 0.1121
Epoch 4 [99/172] - loss: 0.1171
Epoch 4 [100/172] - loss: 0.1762, acc: 0.9688
Epoch 4 [101/172] - loss: 0.1577
Epoch 4 [102/172] - loss: 0.1339
Epoch 4 [103/172] - loss: 0.1142
Epoch 4 [104/172] - loss: 0.1079
Epoch 4 [105/172] - loss: 0.1313
Epoch 4 [106/172] - loss: 0.1127
Epoch 4 [107/172] - loss: 0.1126
Epoch 4 [108/172] - loss: 0.1547
Epoch 4 [109/172] - loss: 0.1484
Epoch 4 [110/172] - loss: 0.2329, acc: 0.9062
Epoch 4 [111/172] - loss: 0.1078
Epoch 4 [112/172] - loss: 0.1118
Epoch 4 [113/172] - loss: 0.1135
Epoch 4 [114/172] - loss: 0.1280
Epoch 4 [115/172] - loss: 0.1382
Epoch 4 [116/172] - loss: 0.1880
Epoch 4 [117/172] - loss: 0.1130
Epoch 4 [118/172] - loss: 0.1278
Epoch 4 [119/172] - loss: 0.1177
Epoch 4 [120/172] - loss: 0.1386, acc: 0.9688
Epoch 4 [121/172] - loss: 0.1337
Epoch 4 [122/172] - loss: 0.1775
Epoch 4 [123/172] - loss: 0.1298
Epoch 4 [124/172] - loss: 0.1187
Epoch 4 [125/172] - loss: 0.1488
Epoch 4 [126/172] - loss: 0.1940
Epoch 4 [127/172] - loss: 0.1368
Epoch 4 [128/172] - loss: 0.1240
Epoch 4 [129/172] - loss: 0.1322
Epoch 4 [130/172] - loss: 0.1081, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1619
Epoch 4 [132/172] - loss: 0.1150
Epoch 4 [133/172] - loss: 0.1542
Epoch 4 [134/172] - loss: 0.1145
Epoch 4 [135/172] - loss: 0.1216
Epoch 4 [136/172] - loss: 0.1378
Epoch 4 [137/172] - loss: 0.1173
Epoch 4 [138/172] - loss: 0.1145
Epoch 4 [139/172] - loss: 0.1279
Epoch 4 [140/172] - loss: 0.1273, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1382
Epoch 4 [142/172] - loss: 0.1302
Epoch 4 [143/172] - loss: 0.1253
Epoch 4 [144/172] - loss: 0.1152
Epoch 4 [145/172] - loss: 0.2367
Epoch 4 [146/172] - loss: 0.1277
Epoch 4 [147/172] - loss: 0.1128
Epoch 4 [148/172] - loss: 0.1108
Epoch 4 [149/172] - loss: 0.1123
Epoch 4 [150/172] - loss: 0.1642, acc: 0.9062
Epoch 4 [151/172] - loss: 0.1425
Epoch 4 [152/172] - loss: 0.1085
Epoch 4 [153/172] - loss: 0.1082
Epoch 4 [154/172] - loss: 0.1302
Epoch 4 [155/172] - loss: 0.1126
Epoch 4 [156/172] - loss: 0.1406
Epoch 4 [157/172] - loss: 0.2536
Epoch 4 [158/172] - loss: 0.1076
Epoch 4 [159/172] - loss: 0.1102
Epoch 4 [160/172] - loss: 0.1349, acc: 0.9688
Epoch 4 [161/172] - loss: 0.1245
Epoch 4 [162/172] - loss: 0.1140
Epoch 4 [163/172] - loss: 0.1172
Epoch 4 [164/172] - loss: 0.1102
Epoch 4 [165/172] - loss: 0.1124
Epoch 4 [166/172] - loss: 0.1299
Epoch 4 [167/172] - loss: 0.1661
Epoch 4 [168/172] - loss: 0.1164
Epoch 4 [169/172] - loss: 0.1735
Epoch 4 [170/172] - loss: 0.1523, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1183
Epoch 4 [172/172] - loss: 0.1120

类别准确率:
positive: 0.8737 (408/467)
neutral: 0.2651 (22/83)
negative: 0.5920 (148/250)

Epoch 4/10
Train Loss: 0.1346, Train Acc: 0.9838
Val Loss: 0.9092, Val Acc: 0.7225
Epoch 5 [1/172] - loss: 0.1074, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1454
Epoch 5 [3/172] - loss: 0.1181
Epoch 5 [4/172] - loss: 0.1077
Epoch 5 [5/172] - loss: 0.1104
Epoch 5 [6/172] - loss: 0.1289
Epoch 5 [7/172] - loss: 0.1100
Epoch 5 [8/172] - loss: 0.1350
Epoch 5 [9/172] - loss: 0.1562
Epoch 5 [10/172] - loss: 0.1109, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1656
Epoch 5 [12/172] - loss: 0.1058

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2194, log_difficulty=0.1984, weight=1.9919
neutral: count=6845.0, difficulty=0.1443, log_difficulty=0.1348, weight=1.6738
negative: count=7694.0, difficulty=0.2012, log_difficulty=0.1833, weight=1.9166

当前batch的pt分布：
positive: min=0.2317, max=0.9985, mean=0.9232
neutral: min=0.9868, max=0.9994, mean=0.9967
negative: min=0.9521, max=0.9982, mean=0.9844

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0617
焦点损失: 0.0263
边界损失: 0.1513
总损失: 0.1266
Epoch 5 [13/172] - loss: 0.1266
Epoch 5 [14/172] - loss: 0.1794
Epoch 5 [15/172] - loss: 0.1106
Epoch 5 [16/172] - loss: 0.1127
Epoch 5 [17/172] - loss: 0.1241
Epoch 5 [18/172] - loss: 0.1110
Epoch 5 [19/172] - loss: 0.1252
Epoch 5 [20/172] - loss: 0.1604, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1173
Epoch 5 [22/172] - loss: 0.1193
Epoch 5 [23/172] - loss: 0.1114
Epoch 5 [24/172] - loss: 0.1088
Epoch 5 [25/172] - loss: 0.1096
Epoch 5 [26/172] - loss: 0.1647
Epoch 5 [27/172] - loss: 0.1093
Epoch 5 [28/172] - loss: 0.1083
Epoch 5 [29/172] - loss: 0.1100
Epoch 5 [30/172] - loss: 0.1071, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1163
Epoch 5 [32/172] - loss: 0.1078
Epoch 5 [33/172] - loss: 0.1095
Epoch 5 [34/172] - loss: 0.1190
Epoch 5 [35/172] - loss: 0.1109
Epoch 5 [36/172] - loss: 0.1079
Epoch 5 [37/172] - loss: 0.1081
Epoch 5 [38/172] - loss: 0.1132
Epoch 5 [39/172] - loss: 0.1311
Epoch 5 [40/172] - loss: 0.1150, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1080
Epoch 5 [42/172] - loss: 0.1115
Epoch 5 [43/172] - loss: 0.1353
Epoch 5 [44/172] - loss: 0.1209
Epoch 5 [45/172] - loss: 0.1081
Epoch 5 [46/172] - loss: 0.1115
Epoch 5 [47/172] - loss: 0.1093
Epoch 5 [48/172] - loss: 0.1108
Epoch 5 [49/172] - loss: 0.1095
Epoch 5 [50/172] - loss: 0.1212, acc: 0.9688
Epoch 5 [51/172] - loss: 0.1224
Epoch 5 [52/172] - loss: 0.1074
Epoch 5 [53/172] - loss: 0.1213
Epoch 5 [54/172] - loss: 0.1096
Epoch 5 [55/172] - loss: 0.1269
Epoch 5 [56/172] - loss: 0.1094
Epoch 5 [57/172] - loss: 0.1149
Epoch 5 [58/172] - loss: 0.1068
Epoch 5 [59/172] - loss: 0.1279
Epoch 5 [60/172] - loss: 0.1099, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1351
Epoch 5 [62/172] - loss: 0.1073
Epoch 5 [63/172] - loss: 0.1432
Epoch 5 [64/172] - loss: 0.1177
Epoch 5 [65/172] - loss: 0.1122
Epoch 5 [66/172] - loss: 0.1109
Epoch 5 [67/172] - loss: 0.1072
Epoch 5 [68/172] - loss: 0.1201
Epoch 5 [69/172] - loss: 0.1089
Epoch 5 [70/172] - loss: 0.1087, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1154
Epoch 5 [72/172] - loss: 0.1120
Epoch 5 [73/172] - loss: 0.1106
Epoch 5 [74/172] - loss: 0.1242
Epoch 5 [75/172] - loss: 0.1156
Epoch 5 [76/172] - loss: 0.1083
Epoch 5 [77/172] - loss: 0.1069
Epoch 5 [78/172] - loss: 0.1216
Epoch 5 [79/172] - loss: 0.1061
Epoch 5 [80/172] - loss: 0.1092, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1276
Epoch 5 [82/172] - loss: 0.1189
Epoch 5 [83/172] - loss: 0.1125
Epoch 5 [84/172] - loss: 0.1060
Epoch 5 [85/172] - loss: 0.1564
Epoch 5 [86/172] - loss: 0.1079
Epoch 5 [87/172] - loss: 0.1164
Epoch 5 [88/172] - loss: 0.1306
Epoch 5 [89/172] - loss: 0.1073
Epoch 5 [90/172] - loss: 0.1124, acc: 1.0000
Epoch 5 [91/172] - loss: 0.1140
Epoch 5 [92/172] - loss: 0.1103
Epoch 5 [93/172] - loss: 0.1170
Epoch 5 [94/172] - loss: 0.1084
Epoch 5 [95/172] - loss: 0.1162
Epoch 5 [96/172] - loss: 0.1078
Epoch 5 [97/172] - loss: 0.1472
Epoch 5 [98/172] - loss: 0.1244
Epoch 5 [99/172] - loss: 0.1983
Epoch 5 [100/172] - loss: 0.1227, acc: 0.9688
Epoch 5 [101/172] - loss: 0.1107
Epoch 5 [102/172] - loss: 0.1105
Epoch 5 [103/172] - loss: 0.1103
Epoch 5 [104/172] - loss: 0.1957
Epoch 5 [105/172] - loss: 0.2047
Epoch 5 [106/172] - loss: 0.1094
Epoch 5 [107/172] - loss: 0.1185
Epoch 5 [108/172] - loss: 0.1602
Epoch 5 [109/172] - loss: 0.1174
Epoch 5 [110/172] - loss: 0.1109, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1174
Epoch 5 [112/172] - loss: 0.1155

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.1962, log_difficulty=0.1792, weight=1.8958
neutral: count=7825.0, difficulty=0.1297, log_difficulty=0.1219, weight=1.6097
negative: count=8780.0, difficulty=0.1810, log_difficulty=0.1664, weight=1.8320

当前batch的pt分布：
positive: min=0.1909, max=0.9888, mean=0.9013
neutral: min=0.9585, max=0.9983, mean=0.9845
negative: min=0.9953, max=1.0000, mean=0.9986

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0831
焦点损失: 0.0342
边界损失: 0.1541
总损失: 0.1318
Epoch 5 [113/172] - loss: 0.1318
Epoch 5 [114/172] - loss: 0.1122
Epoch 5 [115/172] - loss: 0.1326
Epoch 5 [116/172] - loss: 0.1063
Epoch 5 [117/172] - loss: 0.1063
Epoch 5 [118/172] - loss: 0.1080
Epoch 5 [119/172] - loss: 0.1087
Epoch 5 [120/172] - loss: 0.1141, acc: 1.0000
Epoch 5 [121/172] - loss: 0.1134
Epoch 5 [122/172] - loss: 0.1138
Epoch 5 [123/172] - loss: 0.1124
Epoch 5 [124/172] - loss: 0.1092
Epoch 5 [125/172] - loss: 0.1066
Epoch 5 [126/172] - loss: 0.1105
Epoch 5 [127/172] - loss: 0.1135
Epoch 5 [128/172] - loss: 0.1083
Epoch 5 [129/172] - loss: 0.1239
Epoch 5 [130/172] - loss: 0.1066, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1153
Epoch 5 [132/172] - loss: 0.1258
Epoch 5 [133/172] - loss: 0.1181
Epoch 5 [134/172] - loss: 0.1303
Epoch 5 [135/172] - loss: 0.1111
Epoch 5 [136/172] - loss: 0.1063
Epoch 5 [137/172] - loss: 0.1169
Epoch 5 [138/172] - loss: 0.1478
Epoch 5 [139/172] - loss: 0.1850
Epoch 5 [140/172] - loss: 0.1158, acc: 1.0000
Epoch 5 [141/172] - loss: 0.1076
Epoch 5 [142/172] - loss: 0.1065
Epoch 5 [143/172] - loss: 0.1078
Epoch 5 [144/172] - loss: 0.1077
Epoch 5 [145/172] - loss: 0.1168
Epoch 5 [146/172] - loss: 0.1067
Epoch 5 [147/172] - loss: 0.1584
Epoch 5 [148/172] - loss: 0.1071
Epoch 5 [149/172] - loss: 0.1078
Epoch 5 [150/172] - loss: 0.1413, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1073
Epoch 5 [152/172] - loss: 0.1154
Epoch 5 [153/172] - loss: 0.1069
Epoch 5 [154/172] - loss: 0.1074
Epoch 5 [155/172] - loss: 0.1484
Epoch 5 [156/172] - loss: 0.1127
Epoch 5 [157/172] - loss: 0.1140
Epoch 5 [158/172] - loss: 0.1061
Epoch 5 [159/172] - loss: 0.1105
Epoch 5 [160/172] - loss: 0.1293, acc: 0.9688
Epoch 5 [161/172] - loss: 0.1107
Epoch 5 [162/172] - loss: 0.1162
Epoch 5 [163/172] - loss: 0.1484
Epoch 5 [164/172] - loss: 0.1073
Epoch 5 [165/172] - loss: 0.1337
Epoch 5 [166/172] - loss: 0.1142
Epoch 5 [167/172] - loss: 0.1115
Epoch 5 [168/172] - loss: 0.1066
Epoch 5 [169/172] - loss: 0.1123
Epoch 5 [170/172] - loss: 0.1051, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1190
Epoch 5 [172/172] - loss: 0.1200

类别准确率:
positive: 0.8758 (409/467)
neutral: 0.3012 (25/83)
negative: 0.5960 (149/250)

Epoch 5/10
Train Loss: 0.1166, Train Acc: 0.9939
Val Loss: 0.8708, Val Acc: 0.7288
Epoch 6 [1/172] - loss: 0.1206, acc: 1.0000
Epoch 6 [2/172] - loss: 0.1204
Epoch 6 [3/172] - loss: 0.1052
Epoch 6 [4/172] - loss: 0.1056
Epoch 6 [5/172] - loss: 0.1365
Epoch 6 [6/172] - loss: 0.1077
Epoch 6 [7/172] - loss: 0.1172
Epoch 6 [8/172] - loss: 0.1097
Epoch 6 [9/172] - loss: 0.1069
Epoch 6 [10/172] - loss: 0.1059, acc: 1.0000
Epoch 6 [11/172] - loss: 0.1117
Epoch 6 [12/172] - loss: 0.1060
Epoch 6 [13/172] - loss: 0.1095
Epoch 6 [14/172] - loss: 0.1056
Epoch 6 [15/172] - loss: 0.1092
Epoch 6 [16/172] - loss: 0.1133
Epoch 6 [17/172] - loss: 0.1105
Epoch 6 [18/172] - loss: 0.1088
Epoch 6 [19/172] - loss: 0.1063
Epoch 6 [20/172] - loss: 0.1071, acc: 1.0000
Epoch 6 [21/172] - loss: 0.1081
Epoch 6 [22/172] - loss: 0.1098
Epoch 6 [23/172] - loss: 0.1078
Epoch 6 [24/172] - loss: 0.1077
Epoch 6 [25/172] - loss: 0.1055
Epoch 6 [26/172] - loss: 0.1113
Epoch 6 [27/172] - loss: 0.1227
Epoch 6 [28/172] - loss: 0.1093
Epoch 6 [29/172] - loss: 0.1077
Epoch 6 [30/172] - loss: 0.1059, acc: 1.0000
Epoch 6 [31/172] - loss: 0.1061
Epoch 6 [32/172] - loss: 0.1061
Epoch 6 [33/172] - loss: 0.1060
Epoch 6 [34/172] - loss: 0.1064
Epoch 6 [35/172] - loss: 0.1056
Epoch 6 [36/172] - loss: 0.1152
Epoch 6 [37/172] - loss: 0.1078
Epoch 6 [38/172] - loss: 0.1160
Epoch 6 [39/172] - loss: 0.1104
Epoch 6 [40/172] - loss: 0.1255, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1779, log_difficulty=0.1638, weight=1.8188
neutral: count=8815.0, difficulty=0.1177, log_difficulty=0.1113, weight=1.5564
negative: count=9870.0, difficulty=0.1642, log_difficulty=0.1520, weight=1.7600

当前batch的pt分布：
positive: min=0.1152, max=0.9990, mean=0.9139
neutral: min=0.9612, max=0.9981, mean=0.9890
negative: min=0.9122, max=0.9991, mean=0.9783

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0806
焦点损失: 0.0530
边界损失: 0.1438
总损失: 0.1320
Epoch 6 [41/172] - loss: 0.1320
Epoch 6 [42/172] - loss: 0.1080
Epoch 6 [43/172] - loss: 0.1405
Epoch 6 [44/172] - loss: 0.1091
Epoch 6 [45/172] - loss: 0.1165
Epoch 6 [46/172] - loss: 0.1179
Epoch 6 [47/172] - loss: 0.1057
Epoch 6 [48/172] - loss: 0.1058
Epoch 6 [49/172] - loss: 0.1104
Epoch 6 [50/172] - loss: 0.1121, acc: 1.0000
Epoch 6 [51/172] - loss: 0.1219
Epoch 6 [52/172] - loss: 0.1299
Epoch 6 [53/172] - loss: 0.1068
Epoch 6 [54/172] - loss: 0.1386
Epoch 6 [55/172] - loss: 0.1279
Epoch 6 [56/172] - loss: 0.1108
Epoch 6 [57/172] - loss: 0.1116
Epoch 6 [58/172] - loss: 0.1069
Epoch 6 [59/172] - loss: 0.1276
Epoch 6 [60/172] - loss: 0.1196, acc: 0.9688
Epoch 6 [61/172] - loss: 0.1074
Epoch 6 [62/172] - loss: 0.1116
Epoch 6 [63/172] - loss: 0.1096
Epoch 6 [64/172] - loss: 0.1325
Epoch 6 [65/172] - loss: 0.1169
Epoch 6 [66/172] - loss: 0.1077
Epoch 6 [67/172] - loss: 0.1081
Epoch 6 [68/172] - loss: 0.1179
Epoch 6 [69/172] - loss: 0.1168
Epoch 6 [70/172] - loss: 0.1078, acc: 1.0000
Epoch 6 [71/172] - loss: 0.1086
Epoch 6 [72/172] - loss: 0.1202
Epoch 6 [73/172] - loss: 0.1153
Epoch 6 [74/172] - loss: 0.1066
Epoch 6 [75/172] - loss: 0.1141
Epoch 6 [76/172] - loss: 0.1221
Epoch 6 [77/172] - loss: 0.1227
Epoch 6 [78/172] - loss: 0.1142
Epoch 6 [79/172] - loss: 0.1061
Epoch 6 [80/172] - loss: 0.1333, acc: 0.9688
Epoch 6 [81/172] - loss: 0.1304
Epoch 6 [82/172] - loss: 0.1143
Epoch 6 [83/172] - loss: 0.1066
Epoch 6 [84/172] - loss: 0.1065
Epoch 6 [85/172] - loss: 0.1224
Epoch 6 [86/172] - loss: 0.1129
Epoch 6 [87/172] - loss: 0.1196
Epoch 6 [88/172] - loss: 0.1387
Epoch 6 [89/172] - loss: 0.1098
Epoch 6 [90/172] - loss: 0.1067, acc: 1.0000
Epoch 6 [91/172] - loss: 0.1095
Epoch 6 [92/172] - loss: 0.1062
Epoch 6 [93/172] - loss: 0.1073
Epoch 6 [94/172] - loss: 0.1075
Epoch 6 [95/172] - loss: 0.1107
Epoch 6 [96/172] - loss: 0.1053
Epoch 6 [97/172] - loss: 0.1087
Epoch 6 [98/172] - loss: 0.1126
Epoch 6 [99/172] - loss: 0.1066
Epoch 6 [100/172] - loss: 0.1055, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1245
Epoch 6 [102/172] - loss: 0.1069
Epoch 6 [103/172] - loss: 0.1231
Epoch 6 [104/172] - loss: 0.1171
Epoch 6 [105/172] - loss: 0.1086
Epoch 6 [106/172] - loss: 0.1406
Epoch 6 [107/172] - loss: 0.1062
Epoch 6 [108/172] - loss: 0.1068
Epoch 6 [109/172] - loss: 0.1201
Epoch 6 [110/172] - loss: 0.1127, acc: 1.0000
Epoch 6 [111/172] - loss: 0.1074
Epoch 6 [112/172] - loss: 0.1061
Epoch 6 [113/172] - loss: 0.1391
Epoch 6 [114/172] - loss: 0.1163
Epoch 6 [115/172] - loss: 0.1161
Epoch 6 [116/172] - loss: 0.1971
Epoch 6 [117/172] - loss: 0.1069
Epoch 6 [118/172] - loss: 0.1061
Epoch 6 [119/172] - loss: 0.2199
Epoch 6 [120/172] - loss: 0.1093, acc: 1.0000
Epoch 6 [121/172] - loss: 0.1070
Epoch 6 [122/172] - loss: 0.1255
Epoch 6 [123/172] - loss: 0.1068
Epoch 6 [124/172] - loss: 0.1051
Epoch 6 [125/172] - loss: 0.1242
Epoch 6 [126/172] - loss: 0.1096
Epoch 6 [127/172] - loss: 0.1220
Epoch 6 [128/172] - loss: 0.1336
Epoch 6 [129/172] - loss: 0.1081
Epoch 6 [130/172] - loss: 0.1187, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1096
Epoch 6 [132/172] - loss: 0.1221
Epoch 6 [133/172] - loss: 0.1060
Epoch 6 [134/172] - loss: 0.1047
Epoch 6 [135/172] - loss: 0.1067
Epoch 6 [136/172] - loss: 0.1055
Epoch 6 [137/172] - loss: 0.1137
Epoch 6 [138/172] - loss: 0.1082
Epoch 6 [139/172] - loss: 0.1228
Epoch 6 [140/172] - loss: 0.1135, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1630, log_difficulty=0.1510, weight=1.7552
neutral: count=9796.0, difficulty=0.1087, log_difficulty=0.1031, weight=1.5157
negative: count=10972.0, difficulty=0.1511, log_difficulty=0.1407, weight=1.7035

当前batch的pt分布：
positive: min=0.9810, max=0.9999, mean=0.9951
neutral: min=0.9853, max=0.9965, mean=0.9923
negative: min=0.8902, max=0.9981, mean=0.9759

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0139
焦点损失: 0.0001
边界损失: 0.1418
总损失: 0.1063
Epoch 6 [141/172] - loss: 0.1063
Epoch 6 [142/172] - loss: 0.1096
Epoch 6 [143/172] - loss: 0.1107
Epoch 6 [144/172] - loss: 0.1164
Epoch 6 [145/172] - loss: 0.1087
Epoch 6 [146/172] - loss: 0.1057
Epoch 6 [147/172] - loss: 0.1087
Epoch 6 [148/172] - loss: 0.1111
Epoch 6 [149/172] - loss: 0.1087
Epoch 6 [150/172] - loss: 0.1048, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1178
Epoch 6 [152/172] - loss: 0.1308
Epoch 6 [153/172] - loss: 0.1059
Epoch 6 [154/172] - loss: 0.1052
Epoch 6 [155/172] - loss: 0.1339
Epoch 6 [156/172] - loss: 0.1309
Epoch 6 [157/172] - loss: 0.1070
Epoch 6 [158/172] - loss: 0.1148
Epoch 6 [159/172] - loss: 0.1093
Epoch 6 [160/172] - loss: 0.1297, acc: 0.9688
Epoch 6 [161/172] - loss: 0.1064
Epoch 6 [162/172] - loss: 0.1090
Epoch 6 [163/172] - loss: 0.1118
Epoch 6 [164/172] - loss: 0.1181
Epoch 6 [165/172] - loss: 0.2024
Epoch 6 [166/172] - loss: 0.1093
Epoch 6 [167/172] - loss: 0.1056
Epoch 6 [168/172] - loss: 0.1089
Epoch 6 [169/172] - loss: 0.1247
Epoch 6 [170/172] - loss: 0.1050, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1086
Epoch 6 [172/172] - loss: 0.1075

类别准确率:
positive: 0.8630 (403/467)
neutral: 0.2892 (24/83)
negative: 0.6240 (156/250)

Epoch 6/10
Train Loss: 0.1174, Train Acc: 0.9919
Val Loss: 0.9109, Val Acc: 0.7288
Epoch 7 [1/172] - loss: 0.1075, acc: 1.0000
Epoch 7 [2/172] - loss: 0.1050
Epoch 7 [3/172] - loss: 0.1053
Epoch 7 [4/172] - loss: 0.1082
Epoch 7 [5/172] - loss: 0.1065
Epoch 7 [6/172] - loss: 0.1049
Epoch 7 [7/172] - loss: 0.1122
Epoch 7 [8/172] - loss: 0.1232
Epoch 7 [9/172] - loss: 0.1051
Epoch 7 [10/172] - loss: 0.1054, acc: 1.0000
Epoch 7 [11/172] - loss: 0.1138
Epoch 7 [12/172] - loss: 0.1172
Epoch 7 [13/172] - loss: 0.1103
Epoch 7 [14/172] - loss: 0.1170
Epoch 7 [15/172] - loss: 0.1196
Epoch 7 [16/172] - loss: 0.1075
Epoch 7 [17/172] - loss: 0.1399
Epoch 7 [18/172] - loss: 0.1060
Epoch 7 [19/172] - loss: 0.1085
Epoch 7 [20/172] - loss: 0.1068, acc: 1.0000
Epoch 7 [21/172] - loss: 0.1108
Epoch 7 [22/172] - loss: 0.1128
Epoch 7 [23/172] - loss: 0.1316
Epoch 7 [24/172] - loss: 0.1068
Epoch 7 [25/172] - loss: 0.1075
Epoch 7 [26/172] - loss: 0.1155
Epoch 7 [27/172] - loss: 0.1092
Epoch 7 [28/172] - loss: 0.1118
Epoch 7 [29/172] - loss: 0.1138
Epoch 7 [30/172] - loss: 0.1336, acc: 0.9688
Epoch 7 [31/172] - loss: 0.1096
Epoch 7 [32/172] - loss: 0.1052
Epoch 7 [33/172] - loss: 0.1067
Epoch 7 [34/172] - loss: 0.1110
Epoch 7 [35/172] - loss: 0.1135
Epoch 7 [36/172] - loss: 0.1345
Epoch 7 [37/172] - loss: 0.1113
Epoch 7 [38/172] - loss: 0.1050
Epoch 7 [39/172] - loss: 0.1124
Epoch 7 [40/172] - loss: 0.1055, acc: 1.0000
Epoch 7 [41/172] - loss: 0.1287
Epoch 7 [42/172] - loss: 0.1064
Epoch 7 [43/172] - loss: 0.1059
Epoch 7 [44/172] - loss: 0.1215
Epoch 7 [45/172] - loss: 0.1086
Epoch 7 [46/172] - loss: 0.1295
Epoch 7 [47/172] - loss: 0.1393
Epoch 7 [48/172] - loss: 0.1075
Epoch 7 [49/172] - loss: 0.1059
Epoch 7 [50/172] - loss: 0.1053, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1390
Epoch 7 [52/172] - loss: 0.1070
Epoch 7 [53/172] - loss: 0.1049
Epoch 7 [54/172] - loss: 0.1380
Epoch 7 [55/172] - loss: 0.1071
Epoch 7 [56/172] - loss: 0.1123
Epoch 7 [57/172] - loss: 0.1071
Epoch 7 [58/172] - loss: 0.1078
Epoch 7 [59/172] - loss: 0.1063
Epoch 7 [60/172] - loss: 0.1241, acc: 0.9688
Epoch 7 [61/172] - loss: 0.1081
Epoch 7 [62/172] - loss: 0.1098
Epoch 7 [63/172] - loss: 0.1390
Epoch 7 [64/172] - loss: 0.1074
Epoch 7 [65/172] - loss: 0.1306
Epoch 7 [66/172] - loss: 0.1070
Epoch 7 [67/172] - loss: 0.1079
Epoch 7 [68/172] - loss: 0.1125

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1507, log_difficulty=0.1403, weight=1.7017
neutral: count=10756.0, difficulty=0.1008, log_difficulty=0.0961, weight=1.4804
negative: count=12072.0, difficulty=0.1400, log_difficulty=0.1310, weight=1.6551

当前batch的pt分布：
positive: min=0.9800, max=0.9995, mean=0.9930
neutral: min=0.9923, max=0.9996, mean=0.9965
negative: min=0.7683, max=0.9937, mean=0.9624

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0207
焦点损失: 0.0005
边界损失: 0.1447
总损失: 0.1088
Epoch 7 [69/172] - loss: 0.1088
Epoch 7 [70/172] - loss: 0.1064, acc: 1.0000
Epoch 7 [71/172] - loss: 0.1113
Epoch 7 [72/172] - loss: 0.1156
Epoch 7 [73/172] - loss: 0.1105
Epoch 7 [74/172] - loss: 0.1057
Epoch 7 [75/172] - loss: 0.1063
Epoch 7 [76/172] - loss: 0.1166
Epoch 7 [77/172] - loss: 0.1299
Epoch 7 [78/172] - loss: 0.1081
Epoch 7 [79/172] - loss: 0.1118
Epoch 7 [80/172] - loss: 0.1056, acc: 1.0000
Epoch 7 [81/172] - loss: 0.1055
Epoch 7 [82/172] - loss: 0.1072
Epoch 7 [83/172] - loss: 0.1258
Epoch 7 [84/172] - loss: 0.1069
Epoch 7 [85/172] - loss: 0.1810
Epoch 7 [86/172] - loss: 0.1086
Epoch 7 [87/172] - loss: 0.1094
Epoch 7 [88/172] - loss: 0.1132
Epoch 7 [89/172] - loss: 0.1054
Epoch 7 [90/172] - loss: 0.1068, acc: 1.0000
Epoch 7 [91/172] - loss: 0.1075
Epoch 7 [92/172] - loss: 0.1097
Epoch 7 [93/172] - loss: 0.1169
Epoch 7 [94/172] - loss: 0.1132
Epoch 7 [95/172] - loss: 0.1060
Epoch 7 [96/172] - loss: 0.1179
Epoch 7 [97/172] - loss: 0.1104
Epoch 7 [98/172] - loss: 0.1281
Epoch 7 [99/172] - loss: 0.1057
Epoch 7 [100/172] - loss: 0.1052, acc: 1.0000
Epoch 7 [101/172] - loss: 0.1060
Epoch 7 [102/172] - loss: 0.1090
Epoch 7 [103/172] - loss: 0.1057
Epoch 7 [104/172] - loss: 0.1081
Epoch 7 [105/172] - loss: 0.1134
Epoch 7 [106/172] - loss: 0.1406
Epoch 7 [107/172] - loss: 0.1053
Epoch 7 [108/172] - loss: 0.1062
Epoch 7 [109/172] - loss: 0.1310
Epoch 7 [110/172] - loss: 0.1181, acc: 0.9688
Epoch 7 [111/172] - loss: 0.1066
Epoch 7 [112/172] - loss: 0.1081
Epoch 7 [113/172] - loss: 0.1062
Epoch 7 [114/172] - loss: 0.1051
Epoch 7 [115/172] - loss: 0.1061
Epoch 7 [116/172] - loss: 0.1170
Epoch 7 [117/172] - loss: 0.1091
Epoch 7 [118/172] - loss: 0.1170
Epoch 7 [119/172] - loss: 0.1162
Epoch 7 [120/172] - loss: 0.1074, acc: 1.0000
Epoch 7 [121/172] - loss: 0.1096
Epoch 7 [122/172] - loss: 0.1077
Epoch 7 [123/172] - loss: 0.1049
Epoch 7 [124/172] - loss: 0.1231
Epoch 7 [125/172] - loss: 0.1053
Epoch 7 [126/172] - loss: 0.1058
Epoch 7 [127/172] - loss: 0.1092
Epoch 7 [128/172] - loss: 0.1063
Epoch 7 [129/172] - loss: 0.1093
Epoch 7 [130/172] - loss: 0.1114, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1188
Epoch 7 [132/172] - loss: 0.1462
Epoch 7 [133/172] - loss: 0.1049
Epoch 7 [134/172] - loss: 0.1129
Epoch 7 [135/172] - loss: 0.1217
Epoch 7 [136/172] - loss: 0.1088
Epoch 7 [137/172] - loss: 0.1152
Epoch 7 [138/172] - loss: 0.1051
Epoch 7 [139/172] - loss: 0.1330
Epoch 7 [140/172] - loss: 0.1067, acc: 1.0000
Epoch 7 [141/172] - loss: 0.1088
Epoch 7 [142/172] - loss: 0.1093
Epoch 7 [143/172] - loss: 0.1129
Epoch 7 [144/172] - loss: 0.1113
Epoch 7 [145/172] - loss: 0.1214
Epoch 7 [146/172] - loss: 0.1293
Epoch 7 [147/172] - loss: 0.1275
Epoch 7 [148/172] - loss: 0.1171
Epoch 7 [149/172] - loss: 0.1064
Epoch 7 [150/172] - loss: 0.1063, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1329
Epoch 7 [152/172] - loss: 0.1053
Epoch 7 [153/172] - loss: 0.1054
Epoch 7 [154/172] - loss: 0.1156
Epoch 7 [155/172] - loss: 0.1077
Epoch 7 [156/172] - loss: 0.1393
Epoch 7 [157/172] - loss: 0.1093
Epoch 7 [158/172] - loss: 0.1367
Epoch 7 [159/172] - loss: 0.1058
Epoch 7 [160/172] - loss: 0.1142, acc: 1.0000
Epoch 7 [161/172] - loss: 0.1074
Epoch 7 [162/172] - loss: 0.1075
Epoch 7 [163/172] - loss: 0.1134
Epoch 7 [164/172] - loss: 0.1198
Epoch 7 [165/172] - loss: 0.1166
Epoch 7 [166/172] - loss: 0.1097
Epoch 7 [167/172] - loss: 0.1142
Epoch 7 [168/172] - loss: 0.1060

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1402, log_difficulty=0.1312, weight=1.6562
neutral: count=11731.0, difficulty=0.0945, log_difficulty=0.0903, weight=1.4513
negative: count=13173.0, difficulty=0.1305, log_difficulty=0.1226, weight=1.6132

当前batch的pt分布：
positive: min=0.9837, max=0.9985, mean=0.9916
neutral: min=0.9850, max=0.9983, mean=0.9942
negative: min=0.9451, max=0.9986, mean=0.9813

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0117
焦点损失: 0.0000
边界损失: 0.1405
总损失: 0.1054
Epoch 7 [169/172] - loss: 0.1054
Epoch 7 [170/172] - loss: 0.1144, acc: 1.0000
Epoch 7 [171/172] - loss: 0.1059
Epoch 7 [172/172] - loss: 0.1074

类别准确率:
positive: 0.8737 (408/467)
neutral: 0.2651 (22/83)
negative: 0.5960 (149/250)

Epoch 7/10
Train Loss: 0.1121, Train Acc: 0.9960
Val Loss: 0.9503, Val Acc: 0.7238
Epoch 8 [1/172] - loss: 0.1063, acc: 1.0000
Epoch 8 [2/172] - loss: 0.1254
Epoch 8 [3/172] - loss: 0.1073
Epoch 8 [4/172] - loss: 0.1051
Epoch 8 [5/172] - loss: 0.1049
Epoch 8 [6/172] - loss: 0.1202
Epoch 8 [7/172] - loss: 0.1057
Epoch 8 [8/172] - loss: 0.1129
Epoch 8 [9/172] - loss: 0.1124
Epoch 8 [10/172] - loss: 0.1292, acc: 0.9688
Epoch 8 [11/172] - loss: 0.1194
Epoch 8 [12/172] - loss: 0.1413
Epoch 8 [13/172] - loss: 0.1056
Epoch 8 [14/172] - loss: 0.1069
Epoch 8 [15/172] - loss: 0.1118
Epoch 8 [16/172] - loss: 0.1098
Epoch 8 [17/172] - loss: 0.1054
Epoch 8 [18/172] - loss: 0.1048
Epoch 8 [19/172] - loss: 0.1090
Epoch 8 [20/172] - loss: 0.1076, acc: 1.0000
Epoch 8 [21/172] - loss: 0.1060
Epoch 8 [22/172] - loss: 0.1282
Epoch 8 [23/172] - loss: 0.1124
Epoch 8 [24/172] - loss: 0.1059
Epoch 8 [25/172] - loss: 0.1120
Epoch 8 [26/172] - loss: 0.1078
Epoch 8 [27/172] - loss: 0.1209
Epoch 8 [28/172] - loss: 0.1100
Epoch 8 [29/172] - loss: 0.1218
Epoch 8 [30/172] - loss: 0.1049, acc: 1.0000
Epoch 8 [31/172] - loss: 0.1067
Epoch 8 [32/172] - loss: 0.1062
Epoch 8 [33/172] - loss: 0.1105
Epoch 8 [34/172] - loss: 0.1085
Epoch 8 [35/172] - loss: 0.1377
Epoch 8 [36/172] - loss: 0.1102
Epoch 8 [37/172] - loss: 0.1220
Epoch 8 [38/172] - loss: 0.1096
Epoch 8 [39/172] - loss: 0.1070
Epoch 8 [40/172] - loss: 0.1080, acc: 1.0000
Epoch 8 [41/172] - loss: 0.1086
Epoch 8 [42/172] - loss: 0.1128
Epoch 8 [43/172] - loss: 0.1060
Epoch 8 [44/172] - loss: 0.1070
Epoch 8 [45/172] - loss: 0.1088
Epoch 8 [46/172] - loss: 0.1080
Epoch 8 [47/172] - loss: 0.1070
Epoch 8 [48/172] - loss: 0.1196
Epoch 8 [49/172] - loss: 0.1055
Epoch 8 [50/172] - loss: 0.1063, acc: 1.0000
Epoch 8 [51/172] - loss: 0.1080
Epoch 8 [52/172] - loss: 0.1053
Epoch 8 [53/172] - loss: 0.1599
Epoch 8 [54/172] - loss: 0.1308
Epoch 8 [55/172] - loss: 0.1061
Epoch 8 [56/172] - loss: 0.1092
Epoch 8 [57/172] - loss: 0.1048
Epoch 8 [58/172] - loss: 0.1097
Epoch 8 [59/172] - loss: 0.1101
Epoch 8 [60/172] - loss: 0.1062, acc: 1.0000
Epoch 8 [61/172] - loss: 0.1095
Epoch 8 [62/172] - loss: 0.1054
Epoch 8 [63/172] - loss: 0.1043
Epoch 8 [64/172] - loss: 0.1044
Epoch 8 [65/172] - loss: 0.1131
Epoch 8 [66/172] - loss: 0.1174
Epoch 8 [67/172] - loss: 0.1079
Epoch 8 [68/172] - loss: 0.1049
Epoch 8 [69/172] - loss: 0.1052
Epoch 8 [70/172] - loss: 0.1055, acc: 1.0000
Epoch 8 [71/172] - loss: 0.1225
Epoch 8 [72/172] - loss: 0.1056
Epoch 8 [73/172] - loss: 0.1117
Epoch 8 [74/172] - loss: 0.1123
Epoch 8 [75/172] - loss: 0.1063
Epoch 8 [76/172] - loss: 0.1430
Epoch 8 [77/172] - loss: 0.1053
Epoch 8 [78/172] - loss: 0.1147
Epoch 8 [79/172] - loss: 0.1132
Epoch 8 [80/172] - loss: 0.1115, acc: 1.0000
Epoch 8 [81/172] - loss: 0.1078
Epoch 8 [82/172] - loss: 0.1053
Epoch 8 [83/172] - loss: 0.1052
Epoch 8 [84/172] - loss: 0.1063
Epoch 8 [85/172] - loss: 0.1084
Epoch 8 [86/172] - loss: 0.1076
Epoch 8 [87/172] - loss: 0.1050
Epoch 8 [88/172] - loss: 0.1174
Epoch 8 [89/172] - loss: 0.1047
Epoch 8 [90/172] - loss: 0.1069, acc: 1.0000
Epoch 8 [91/172] - loss: 0.1376
Epoch 8 [92/172] - loss: 0.1166
Epoch 8 [93/172] - loss: 0.1054
Epoch 8 [94/172] - loss: 0.1191
Epoch 8 [95/172] - loss: 0.1079
Epoch 8 [96/172] - loss: 0.1184

=== 第 1301 次迭代调试信息 ===
当前类别统计：
positive: count=14487.0, difficulty=0.1314, log_difficulty=0.1234, weight=1.6172
neutral: count=12738.0, difficulty=0.0889, log_difficulty=0.0852, weight=1.4261
negative: count=14288.0, difficulty=0.1222, log_difficulty=0.1152, weight=1.5762

当前batch的pt分布：
positive: min=0.9829, max=0.9977, mean=0.9943
neutral: min=0.5023, max=0.9948, mean=0.9375
negative: min=0.9961, max=0.9996, mean=0.9983

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0378
焦点损失: 0.0064
边界损失: 0.1516
总损失: 0.1160
Epoch 8 [97/172] - loss: 0.1160
Epoch 8 [98/172] - loss: 0.1320
Epoch 8 [99/172] - loss: 0.1083
Epoch 8 [100/172] - loss: 0.1054, acc: 1.0000
Epoch 8 [101/172] - loss: 0.1117
Epoch 8 [102/172] - loss: 0.1075
Epoch 8 [103/172] - loss: 0.1454
Epoch 8 [104/172] - loss: 0.1091
Epoch 8 [105/172] - loss: 0.1066
Epoch 8 [106/172] - loss: 0.1102
Epoch 8 [107/172] - loss: 0.1117
Epoch 8 [108/172] - loss: 0.1105
Epoch 8 [109/172] - loss: 0.1251
Epoch 8 [110/172] - loss: 0.1207, acc: 0.9688
Epoch 8 [111/172] - loss: 0.1342
Epoch 8 [112/172] - loss: 0.1221
Epoch 8 [113/172] - loss: 0.1049
Epoch 8 [114/172] - loss: 0.1053
Epoch 8 [115/172] - loss: 0.1053
Epoch 8 [116/172] - loss: 0.1052
Epoch 8 [117/172] - loss: 0.1054
Epoch 8 [118/172] - loss: 0.1070
Epoch 8 [119/172] - loss: 0.1262
Epoch 8 [120/172] - loss: 0.1070, acc: 1.0000
Epoch 8 [121/172] - loss: 0.1194
Epoch 8 [122/172] - loss: 0.1106
Epoch 8 [123/172] - loss: 0.1088
Epoch 8 [124/172] - loss: 0.1053
Epoch 8 [125/172] - loss: 0.1079
Epoch 8 [126/172] - loss: 0.1151
Epoch 8 [127/172] - loss: 0.1172
Epoch 8 [128/172] - loss: 0.1268
Epoch 8 [129/172] - loss: 0.1073
Epoch 8 [130/172] - loss: 0.1142, acc: 1.0000
Epoch 8 [131/172] - loss: 0.1097
Epoch 8 [132/172] - loss: 0.1041
Epoch 8 [133/172] - loss: 0.1063
Epoch 8 [134/172] - loss: 0.1064
Epoch 8 [135/172] - loss: 0.1043
Epoch 8 [136/172] - loss: 0.1097
Epoch 8 [137/172] - loss: 0.1059
Epoch 8 [138/172] - loss: 0.1143
Epoch 8 [139/172] - loss: 0.1071
Epoch 8 [140/172] - loss: 0.1059, acc: 1.0000
Epoch 8 [141/172] - loss: 0.1049
Epoch 8 [142/172] - loss: 0.1078
Epoch 8 [143/172] - loss: 0.1090
Epoch 8 [144/172] - loss: 0.1178
Epoch 8 [145/172] - loss: 0.1107
Epoch 8 [146/172] - loss: 0.1044
Epoch 8 [147/172] - loss: 0.1061
Epoch 8 [148/172] - loss: 0.1107
Epoch 8 [149/172] - loss: 0.1079
Epoch 8 [150/172] - loss: 0.1098, acc: 1.0000
Epoch 8 [151/172] - loss: 0.1142
Epoch 8 [152/172] - loss: 0.1223
Epoch 8 [153/172] - loss: 0.1081
Epoch 8 [154/172] - loss: 0.1400
Epoch 8 [155/172] - loss: 0.1046
Epoch 8 [156/172] - loss: 0.1110
Epoch 8 [157/172] - loss: 0.1084
Epoch 8 [158/172] - loss: 0.1067
Epoch 8 [159/172] - loss: 0.1156
Epoch 8 [160/172] - loss: 0.1065, acc: 1.0000
Epoch 8 [161/172] - loss: 0.1052
Epoch 8 [162/172] - loss: 0.1102
Epoch 8 [163/172] - loss: 0.1066
Epoch 8 [164/172] - loss: 0.1077
Epoch 8 [165/172] - loss: 0.1049
Epoch 8 [166/172] - loss: 0.1101
Epoch 8 [167/172] - loss: 0.1076
Epoch 8 [168/172] - loss: 0.1067
Epoch 8 [169/172] - loss: 0.1147
Epoch 8 [170/172] - loss: 0.1091, acc: 1.0000
Epoch 8 [171/172] - loss: 0.1114
Epoch 8 [172/172] - loss: 0.1052

类别准确率:
positive: 0.8608 (402/467)
neutral: 0.2771 (23/83)
negative: 0.6120 (153/250)

Epoch 8/10
Train Loss: 0.1085, Train Acc: 1.0000
Val Loss: 0.9286, Val Acc: 0.7225
Early stopping triggered!
Best validation accuracy: 0.7288

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_053254-z81nkdl2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.2_Multimodal_iterations_20250118_053253
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/z81nkdl2
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇████
wandb:  train_acc ▁▇▅▆▆▇█▇███▇██▇█████████████████████████
wandb: train_loss ██▄▅▄▄▃▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1374
wandb:  train_acc 1
wandb: train_loss 0.10907
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.2_Multimodal_iterations_20250118_053253 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/z81nkdl2
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_053254-z81nkdl2/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_054432-fpxdsdnc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.2_Multimodal_epochs_20250118_054432
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/fpxdsdnc
wandb: uploading history steps 0-0, summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▄▅▆▇█
wandb:  train_acc ▁▅▇▇████
wandb: train_loss █▅▂▂▁▁▁▁
wandb:    val_acc ▁▇▅▆██▆▆
wandb:   val_loss ▁▄▆▇▆▇█▇
wandb: 
wandb: Run summary:
wandb:      epoch 8
wandb:  train_acc 1
wandb: train_loss 0.10854
wandb:    val_acc 0.7225
wandb:   val_loss 0.92858
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.2_Multimodal_epochs_20250118_054432 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/fpxdsdnc
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_054432-fpxdsdnc/logs

