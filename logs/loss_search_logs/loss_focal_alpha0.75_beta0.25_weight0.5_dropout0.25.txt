=== 命令 ===
python main.py --loss_type focal --alpha 0.75 --beta 0.25 --neural_init_weight 0.5 --dropout 0.25 --name loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.25 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.25
text_dim: 128
image_dim: 256
dropout: 0.25
loss_type: focal
alpha: 0.75
beta: 0.25
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6935, log_difficulty=0.5268, weight=3.6338
neutral: count=7.0, difficulty=0.6988, log_difficulty=0.5299, weight=3.6497
negative: count=13.0, difficulty=0.6712, log_difficulty=0.5135, weight=3.5677

当前batch的pt分布：
positive: min=0.1767, max=0.5049, mean=0.3065
neutral: min=0.2070, max=0.3802, mean=0.3012
negative: min=0.2273, max=0.4327, mean=0.3288

当前batch准确率：
整体准确率: 0.2188
positive 准确率: 0.1667
neutral 准确率: 0.1429
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1927
焦点损失: 0.4228
边界损失: 0.7719
总损失: 1.3389
Epoch 1 [1/172] - loss: 1.3389, acc: 0.2188
Epoch 1 [2/172] - loss: 1.2159
Epoch 1 [3/172] - loss: 1.2827
Epoch 1 [4/172] - loss: 1.3527
Epoch 1 [5/172] - loss: 1.1418
Epoch 1 [6/172] - loss: 1.5596
Epoch 1 [7/172] - loss: 1.3900
Epoch 1 [8/172] - loss: 1.3085
Epoch 1 [9/172] - loss: 1.2756
Epoch 1 [10/172] - loss: 1.1991, acc: 0.2812
Epoch 1 [11/172] - loss: 1.1616
Epoch 1 [12/172] - loss: 1.2570
Epoch 1 [13/172] - loss: 1.1249
Epoch 1 [14/172] - loss: 1.1024
Epoch 1 [15/172] - loss: 1.2883
Epoch 1 [16/172] - loss: 1.1606
Epoch 1 [17/172] - loss: 1.2242
Epoch 1 [18/172] - loss: 0.8231
Epoch 1 [19/172] - loss: 1.3483
Epoch 1 [20/172] - loss: 1.2183, acc: 0.4375
Epoch 1 [21/172] - loss: 1.0022
Epoch 1 [22/172] - loss: 1.2119
Epoch 1 [23/172] - loss: 1.4335
Epoch 1 [24/172] - loss: 1.0287
Epoch 1 [25/172] - loss: 1.2345
Epoch 1 [26/172] - loss: 1.0823
Epoch 1 [27/172] - loss: 1.2509
Epoch 1 [28/172] - loss: 0.9779
Epoch 1 [29/172] - loss: 1.1579
Epoch 1 [30/172] - loss: 1.2328, acc: 0.4375
Epoch 1 [31/172] - loss: 1.0446
Epoch 1 [32/172] - loss: 0.9424
Epoch 1 [33/172] - loss: 1.2148
Epoch 1 [34/172] - loss: 0.9287
Epoch 1 [35/172] - loss: 1.1642
Epoch 1 [36/172] - loss: 0.7666
Epoch 1 [37/172] - loss: 0.7800
Epoch 1 [38/172] - loss: 0.9851
Epoch 1 [39/172] - loss: 0.9060
Epoch 1 [40/172] - loss: 0.9553, acc: 0.5312
Epoch 1 [41/172] - loss: 0.9044
Epoch 1 [42/172] - loss: 0.9038
Epoch 1 [43/172] - loss: 0.8254
Epoch 1 [44/172] - loss: 1.0931
Epoch 1 [45/172] - loss: 1.0657
Epoch 1 [46/172] - loss: 0.5948
Epoch 1 [47/172] - loss: 0.8638
Epoch 1 [48/172] - loss: 1.0629
Epoch 1 [49/172] - loss: 1.0855
Epoch 1 [50/172] - loss: 0.9249, acc: 0.4688
Epoch 1 [51/172] - loss: 1.0304
Epoch 1 [52/172] - loss: 1.2517
Epoch 1 [53/172] - loss: 0.8840
Epoch 1 [54/172] - loss: 0.8017
Epoch 1 [55/172] - loss: 0.9035
Epoch 1 [56/172] - loss: 1.0734
Epoch 1 [57/172] - loss: 1.2293
Epoch 1 [58/172] - loss: 0.7896
Epoch 1 [59/172] - loss: 0.9508
Epoch 1 [60/172] - loss: 0.6204, acc: 0.8438
Epoch 1 [61/172] - loss: 1.0170
Epoch 1 [62/172] - loss: 0.7993
Epoch 1 [63/172] - loss: 0.9408
Epoch 1 [64/172] - loss: 0.6671
Epoch 1 [65/172] - loss: 0.9651
Epoch 1 [66/172] - loss: 1.0220
Epoch 1 [67/172] - loss: 0.9988
Epoch 1 [68/172] - loss: 1.0462
Epoch 1 [69/172] - loss: 1.1919
Epoch 1 [70/172] - loss: 0.7789, acc: 0.5312
Epoch 1 [71/172] - loss: 0.6311
Epoch 1 [72/172] - loss: 0.8543
Epoch 1 [73/172] - loss: 0.5534
Epoch 1 [74/172] - loss: 0.8533
Epoch 1 [75/172] - loss: 0.4633
Epoch 1 [76/172] - loss: 0.5323
Epoch 1 [77/172] - loss: 0.8207
Epoch 1 [78/172] - loss: 1.2231
Epoch 1 [79/172] - loss: 1.0367
Epoch 1 [80/172] - loss: 0.2916, acc: 0.9375
Epoch 1 [81/172] - loss: 0.6573
Epoch 1 [82/172] - loss: 1.3173
Epoch 1 [83/172] - loss: 0.7428
Epoch 1 [84/172] - loss: 0.6195
Epoch 1 [85/172] - loss: 0.8731
Epoch 1 [86/172] - loss: 1.1097
Epoch 1 [87/172] - loss: 0.7880
Epoch 1 [88/172] - loss: 0.8549
Epoch 1 [89/172] - loss: 0.9485
Epoch 1 [90/172] - loss: 0.7287, acc: 0.5938
Epoch 1 [91/172] - loss: 0.6430
Epoch 1 [92/172] - loss: 0.6799
Epoch 1 [93/172] - loss: 0.8137
Epoch 1 [94/172] - loss: 0.5821
Epoch 1 [95/172] - loss: 0.5421
Epoch 1 [96/172] - loss: 0.8292
Epoch 1 [97/172] - loss: 0.7995
Epoch 1 [98/172] - loss: 0.6930
Epoch 1 [99/172] - loss: 0.9869
Epoch 1 [100/172] - loss: 0.7537, acc: 0.5938

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5921, log_difficulty=0.4651, weight=3.3253
neutral: count=983.0, difficulty=0.5858, log_difficulty=0.4611, weight=3.3054
negative: count=1119.0, difficulty=0.5755, log_difficulty=0.4546, weight=3.2728

当前batch的pt分布：
positive: min=0.2073, max=0.8798, mean=0.4669
neutral: min=0.3205, max=0.7816, mean=0.5747
negative: min=0.1120, max=0.5858, mean=0.3731

当前batch准确率：
整体准确率: 0.5625
positive 准确率: 0.5833
neutral 准确率: 0.7500
negative 准确率: 0.5000

损失分量：
基础交叉熵: 0.9313
焦点损失: 0.3096
边界损失: 0.6242
总损失: 0.9202
Epoch 1 [101/172] - loss: 0.9202
Epoch 1 [102/172] - loss: 0.7153
Epoch 1 [103/172] - loss: 0.7597
Epoch 1 [104/172] - loss: 0.7966
Epoch 1 [105/172] - loss: 0.7652
Epoch 1 [106/172] - loss: 0.6503
Epoch 1 [107/172] - loss: 0.7477
Epoch 1 [108/172] - loss: 1.0105
Epoch 1 [109/172] - loss: 0.5781
Epoch 1 [110/172] - loss: 0.8574, acc: 0.6250
Epoch 1 [111/172] - loss: 0.8208
Epoch 1 [112/172] - loss: 0.5730
Epoch 1 [113/172] - loss: 0.5862
Epoch 1 [114/172] - loss: 0.6703
Epoch 1 [115/172] - loss: 0.5735
Epoch 1 [116/172] - loss: 0.9927
Epoch 1 [117/172] - loss: 0.8693
Epoch 1 [118/172] - loss: 0.4883
Epoch 1 [119/172] - loss: 0.7315
Epoch 1 [120/172] - loss: 0.6166, acc: 0.7188
Epoch 1 [121/172] - loss: 0.4651
Epoch 1 [122/172] - loss: 0.6989
Epoch 1 [123/172] - loss: 0.4920
Epoch 1 [124/172] - loss: 1.1223
Epoch 1 [125/172] - loss: 0.5757
Epoch 1 [126/172] - loss: 0.6311
Epoch 1 [127/172] - loss: 0.6138
Epoch 1 [128/172] - loss: 0.6880
Epoch 1 [129/172] - loss: 0.8716
Epoch 1 [130/172] - loss: 0.5540, acc: 0.7812
Epoch 1 [131/172] - loss: 0.2769
Epoch 1 [132/172] - loss: 0.6430
Epoch 1 [133/172] - loss: 0.5870
Epoch 1 [134/172] - loss: 0.3927
Epoch 1 [135/172] - loss: 0.6714
Epoch 1 [136/172] - loss: 0.5781
Epoch 1 [137/172] - loss: 0.8238
Epoch 1 [138/172] - loss: 0.4338
Epoch 1 [139/172] - loss: 0.3659
Epoch 1 [140/172] - loss: 0.4136, acc: 0.6562
Epoch 1 [141/172] - loss: 0.6802
Epoch 1 [142/172] - loss: 0.4977
Epoch 1 [143/172] - loss: 0.4073
Epoch 1 [144/172] - loss: 0.5524
Epoch 1 [145/172] - loss: 0.5453
Epoch 1 [146/172] - loss: 0.8292
Epoch 1 [147/172] - loss: 0.8285
Epoch 1 [148/172] - loss: 0.4472
Epoch 1 [149/172] - loss: 0.5340
Epoch 1 [150/172] - loss: 0.4648, acc: 0.8125
Epoch 1 [151/172] - loss: 0.5813
Epoch 1 [152/172] - loss: 0.4503
Epoch 1 [153/172] - loss: 0.4097
Epoch 1 [154/172] - loss: 0.5473
Epoch 1 [155/172] - loss: 0.5304
Epoch 1 [156/172] - loss: 0.7530
Epoch 1 [157/172] - loss: 0.5817
Epoch 1 [158/172] - loss: 0.4138
Epoch 1 [159/172] - loss: 0.6093
Epoch 1 [160/172] - loss: 0.5476, acc: 0.7188
Epoch 1 [161/172] - loss: 0.4584
Epoch 1 [162/172] - loss: 0.5149
Epoch 1 [163/172] - loss: 0.6495
Epoch 1 [164/172] - loss: 0.7121
Epoch 1 [165/172] - loss: 0.5344
Epoch 1 [166/172] - loss: 0.7249
Epoch 1 [167/172] - loss: 0.2955
Epoch 1 [168/172] - loss: 0.7589
Epoch 1 [169/172] - loss: 0.5080
Epoch 1 [170/172] - loss: 0.5927, acc: 0.6875
Epoch 1 [171/172] - loss: 0.4170
Epoch 1 [172/172] - loss: 0.3363

类别准确率:
positive: 0.5824 (272/467)
neutral: 0.6988 (58/83)
negative: 0.6160 (154/250)

Epoch 1/10
Train Loss: 0.5410, Train Acc: 0.7313
Val Loss: 0.8635, Val Acc: 0.6050
Epoch 2 [1/172] - loss: 0.5451, acc: 0.7812
Epoch 2 [2/172] - loss: 0.2995
Epoch 2 [3/172] - loss: 0.2857
Epoch 2 [4/172] - loss: 0.4733
Epoch 2 [5/172] - loss: 0.5011
Epoch 2 [6/172] - loss: 0.4138
Epoch 2 [7/172] - loss: 0.4541
Epoch 2 [8/172] - loss: 0.3834
Epoch 2 [9/172] - loss: 0.3150
Epoch 2 [10/172] - loss: 0.4360, acc: 0.8750
Epoch 2 [11/172] - loss: 0.3068
Epoch 2 [12/172] - loss: 0.3624
Epoch 2 [13/172] - loss: 0.4195
Epoch 2 [14/172] - loss: 0.5193
Epoch 2 [15/172] - loss: 0.4425
Epoch 2 [16/172] - loss: 0.4614
Epoch 2 [17/172] - loss: 0.2248
Epoch 2 [18/172] - loss: 0.5748
Epoch 2 [19/172] - loss: 0.2902
Epoch 2 [20/172] - loss: 0.2719, acc: 0.9062
Epoch 2 [21/172] - loss: 0.4853
Epoch 2 [22/172] - loss: 0.3267
Epoch 2 [23/172] - loss: 0.2318
Epoch 2 [24/172] - loss: 0.9645
Epoch 2 [25/172] - loss: 0.5209
Epoch 2 [26/172] - loss: 0.2713
Epoch 2 [27/172] - loss: 0.4794
Epoch 2 [28/172] - loss: 0.2839

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5282, log_difficulty=0.4241, weight=3.1203
neutral: count=1952.0, difficulty=0.4855, log_difficulty=0.3958, weight=2.9788
negative: count=2216.0, difficulty=0.5190, log_difficulty=0.4181, weight=3.0903

当前batch的pt分布：
positive: min=0.3574, max=0.9417, mean=0.6100
neutral: min=0.3377, max=0.8993, mean=0.6785
negative: min=0.1459, max=0.9717, mean=0.5386

当前batch准确率：
整体准确率: 0.7812
positive 准确率: 0.7778
neutral 准确率: 0.9091
negative 准确率: 0.6667

损失分量：
基础交叉熵: 0.5788
焦点损失: 0.1433
边界损失: 0.4469
总损失: 0.4426
Epoch 2 [29/172] - loss: 0.4426
Epoch 2 [30/172] - loss: 0.3717, acc: 0.8125
Epoch 2 [31/172] - loss: 0.4756
Epoch 2 [32/172] - loss: 0.4314
Epoch 2 [33/172] - loss: 0.3031
Epoch 2 [34/172] - loss: 0.3996
Epoch 2 [35/172] - loss: 0.2079
Epoch 2 [36/172] - loss: 0.7436
Epoch 2 [37/172] - loss: 0.2047
Epoch 2 [38/172] - loss: 0.2501
Epoch 2 [39/172] - loss: 0.8134
Epoch 2 [40/172] - loss: 0.3200, acc: 0.9375
Epoch 2 [41/172] - loss: 0.3120
Epoch 2 [42/172] - loss: 0.2669
Epoch 2 [43/172] - loss: 0.2693
Epoch 2 [44/172] - loss: 0.4818
Epoch 2 [45/172] - loss: 0.3139
Epoch 2 [46/172] - loss: 0.3647
Epoch 2 [47/172] - loss: 0.3156
Epoch 2 [48/172] - loss: 0.6372
Epoch 2 [49/172] - loss: 0.4311
Epoch 2 [50/172] - loss: 0.3778, acc: 0.8125
Epoch 2 [51/172] - loss: 0.4938
Epoch 2 [52/172] - loss: 0.3375
Epoch 2 [53/172] - loss: 0.5361
Epoch 2 [54/172] - loss: 0.3003
Epoch 2 [55/172] - loss: 0.3779
Epoch 2 [56/172] - loss: 0.2958
Epoch 2 [57/172] - loss: 0.2531
Epoch 2 [58/172] - loss: 0.2807
Epoch 2 [59/172] - loss: 0.4918
Epoch 2 [60/172] - loss: 0.2796, acc: 0.9062
Epoch 2 [61/172] - loss: 0.1920
Epoch 2 [62/172] - loss: 0.2313
Epoch 2 [63/172] - loss: 0.7492
Epoch 2 [64/172] - loss: 0.2950
Epoch 2 [65/172] - loss: 0.4178
Epoch 2 [66/172] - loss: 0.3564
Epoch 2 [67/172] - loss: 0.2030
Epoch 2 [68/172] - loss: 0.3854
Epoch 2 [69/172] - loss: 0.2211
Epoch 2 [70/172] - loss: 0.6112, acc: 0.7188
Epoch 2 [71/172] - loss: 0.3472
Epoch 2 [72/172] - loss: 0.2355
Epoch 2 [73/172] - loss: 0.4386
Epoch 2 [74/172] - loss: 0.1816
Epoch 2 [75/172] - loss: 0.3508
Epoch 2 [76/172] - loss: 0.5636
Epoch 2 [77/172] - loss: 0.3222
Epoch 2 [78/172] - loss: 0.6032
Epoch 2 [79/172] - loss: 0.2214
Epoch 2 [80/172] - loss: 0.4095, acc: 0.8125
Epoch 2 [81/172] - loss: 0.3080
Epoch 2 [82/172] - loss: 0.2977
Epoch 2 [83/172] - loss: 0.2430
Epoch 2 [84/172] - loss: 0.3743
Epoch 2 [85/172] - loss: 0.3060
Epoch 2 [86/172] - loss: 0.3606
Epoch 2 [87/172] - loss: 0.8351
Epoch 2 [88/172] - loss: 0.3021
Epoch 2 [89/172] - loss: 0.5282
Epoch 2 [90/172] - loss: 0.3381, acc: 0.7812
Epoch 2 [91/172] - loss: 0.2106
Epoch 2 [92/172] - loss: 0.3098
Epoch 2 [93/172] - loss: 0.1968
Epoch 2 [94/172] - loss: 0.1978
Epoch 2 [95/172] - loss: 0.6048
Epoch 2 [96/172] - loss: 0.2306
Epoch 2 [97/172] - loss: 0.2184
Epoch 2 [98/172] - loss: 0.2469
Epoch 2 [99/172] - loss: 0.1644
Epoch 2 [100/172] - loss: 0.5080, acc: 0.7188
Epoch 2 [101/172] - loss: 0.2104
Epoch 2 [102/172] - loss: 0.2218
Epoch 2 [103/172] - loss: 0.2996
Epoch 2 [104/172] - loss: 0.5247
Epoch 2 [105/172] - loss: 0.1938
Epoch 2 [106/172] - loss: 0.3101
Epoch 2 [107/172] - loss: 0.2387
Epoch 2 [108/172] - loss: 0.6211
Epoch 2 [109/172] - loss: 0.1777
Epoch 2 [110/172] - loss: 0.4493, acc: 0.7500
Epoch 2 [111/172] - loss: 0.2185
Epoch 2 [112/172] - loss: 0.1892
Epoch 2 [113/172] - loss: 0.2008
Epoch 2 [114/172] - loss: 0.3640
Epoch 2 [115/172] - loss: 0.2018
Epoch 2 [116/172] - loss: 0.1677
Epoch 2 [117/172] - loss: 0.4112
Epoch 2 [118/172] - loss: 0.2811
Epoch 2 [119/172] - loss: 0.2955
Epoch 2 [120/172] - loss: 0.2461, acc: 0.8438
Epoch 2 [121/172] - loss: 0.2453
Epoch 2 [122/172] - loss: 0.6135
Epoch 2 [123/172] - loss: 0.1992
Epoch 2 [124/172] - loss: 0.2468
Epoch 2 [125/172] - loss: 0.1467
Epoch 2 [126/172] - loss: 0.1758
Epoch 2 [127/172] - loss: 0.2764
Epoch 2 [128/172] - loss: 0.2870

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4760, log_difficulty=0.3894, weight=2.9468
neutral: count=2949.0, difficulty=0.4020, log_difficulty=0.3379, weight=2.6896
negative: count=3294.0, difficulty=0.4673, log_difficulty=0.3835, weight=2.9173

当前batch的pt分布：
positive: min=0.2165, max=0.8845, mean=0.6500
neutral: min=0.5170, max=0.9873, mean=0.8118
negative: min=0.1378, max=0.9151, mean=0.6332

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.7000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.4318
焦点损失: 0.1106
边界损失: 0.3343
总损失: 0.3257
Epoch 2 [129/172] - loss: 0.3257
Epoch 2 [130/172] - loss: 0.2612, acc: 0.8438
Epoch 2 [131/172] - loss: 0.2312
Epoch 2 [132/172] - loss: 0.2010
Epoch 2 [133/172] - loss: 0.3431
Epoch 2 [134/172] - loss: 0.2006
Epoch 2 [135/172] - loss: 0.4901
Epoch 2 [136/172] - loss: 0.2082
Epoch 2 [137/172] - loss: 0.2247
Epoch 2 [138/172] - loss: 0.2036
Epoch 2 [139/172] - loss: 0.2245
Epoch 2 [140/172] - loss: 0.3768, acc: 0.8438
Epoch 2 [141/172] - loss: 0.2813
Epoch 2 [142/172] - loss: 0.2534
Epoch 2 [143/172] - loss: 0.2484
Epoch 2 [144/172] - loss: 0.1834
Epoch 2 [145/172] - loss: 0.6739
Epoch 2 [146/172] - loss: 0.1393
Epoch 2 [147/172] - loss: 0.3611
Epoch 2 [148/172] - loss: 0.2388
Epoch 2 [149/172] - loss: 0.2615
Epoch 2 [150/172] - loss: 0.2983, acc: 0.8438
Epoch 2 [151/172] - loss: 0.2082
Epoch 2 [152/172] - loss: 0.1600
Epoch 2 [153/172] - loss: 0.2466
Epoch 2 [154/172] - loss: 0.1964
Epoch 2 [155/172] - loss: 0.2172
Epoch 2 [156/172] - loss: 0.1845
Epoch 2 [157/172] - loss: 0.1412
Epoch 2 [158/172] - loss: 0.2178
Epoch 2 [159/172] - loss: 0.2442
Epoch 2 [160/172] - loss: 0.1433, acc: 0.9688
Epoch 2 [161/172] - loss: 0.1598
Epoch 2 [162/172] - loss: 0.1440
Epoch 2 [163/172] - loss: 0.3479
Epoch 2 [164/172] - loss: 0.3033
Epoch 2 [165/172] - loss: 0.1846
Epoch 2 [166/172] - loss: 0.2718
Epoch 2 [167/172] - loss: 0.3325
Epoch 2 [168/172] - loss: 0.1492
Epoch 2 [169/172] - loss: 0.1511
Epoch 2 [170/172] - loss: 0.2073, acc: 0.9062
Epoch 2 [171/172] - loss: 0.3564
Epoch 2 [172/172] - loss: 0.7938

类别准确率:
positive: 0.7345 (343/467)
neutral: 0.2892 (24/83)
negative: 0.7680 (192/250)

Epoch 2/10
Train Loss: 0.2593, Train Acc: 0.9051
Val Loss: 0.7200, Val Acc: 0.6987
Epoch 3 [1/172] - loss: 0.1194, acc: 0.9688
Epoch 3 [2/172] - loss: 0.3887
Epoch 3 [3/172] - loss: 0.0913
Epoch 3 [4/172] - loss: 0.2079
Epoch 3 [5/172] - loss: 0.1489
Epoch 3 [6/172] - loss: 0.1207
Epoch 3 [7/172] - loss: 0.1080
Epoch 3 [8/172] - loss: 0.2468
Epoch 3 [9/172] - loss: 0.1209
Epoch 3 [10/172] - loss: 0.1341, acc: 0.9375
Epoch 3 [11/172] - loss: 0.1351
Epoch 3 [12/172] - loss: 0.0793
Epoch 3 [13/172] - loss: 0.0848
Epoch 3 [14/172] - loss: 0.0767
Epoch 3 [15/172] - loss: 0.1000
Epoch 3 [16/172] - loss: 0.1900
Epoch 3 [17/172] - loss: 0.2188
Epoch 3 [18/172] - loss: 0.1951
Epoch 3 [19/172] - loss: 0.0992
Epoch 3 [20/172] - loss: 0.0948, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1401
Epoch 3 [22/172] - loss: 0.3554
Epoch 3 [23/172] - loss: 0.3075
Epoch 3 [24/172] - loss: 0.2212
Epoch 3 [25/172] - loss: 0.0860
Epoch 3 [26/172] - loss: 0.1418
Epoch 3 [27/172] - loss: 0.0898
Epoch 3 [28/172] - loss: 0.0683
Epoch 3 [29/172] - loss: 0.1501
Epoch 3 [30/172] - loss: 0.1781, acc: 0.9688
Epoch 3 [31/172] - loss: 0.0835
Epoch 3 [32/172] - loss: 0.1379
Epoch 3 [33/172] - loss: 0.1358
Epoch 3 [34/172] - loss: 0.2474
Epoch 3 [35/172] - loss: 0.3483
Epoch 3 [36/172] - loss: 0.1322
Epoch 3 [37/172] - loss: 0.1048
Epoch 3 [38/172] - loss: 0.0640
Epoch 3 [39/172] - loss: 0.1369
Epoch 3 [40/172] - loss: 0.1067, acc: 0.9688
Epoch 3 [41/172] - loss: 0.0926
Epoch 3 [42/172] - loss: 0.1351
Epoch 3 [43/172] - loss: 0.0839
Epoch 3 [44/172] - loss: 0.1053
Epoch 3 [45/172] - loss: 0.2540
Epoch 3 [46/172] - loss: 0.0919
Epoch 3 [47/172] - loss: 0.0873
Epoch 3 [48/172] - loss: 0.0884
Epoch 3 [49/172] - loss: 0.0767
Epoch 3 [50/172] - loss: 0.1137, acc: 0.9375
Epoch 3 [51/172] - loss: 0.0879
Epoch 3 [52/172] - loss: 0.3899
Epoch 3 [53/172] - loss: 0.0736
Epoch 3 [54/172] - loss: 0.1925
Epoch 3 [55/172] - loss: 0.1229
Epoch 3 [56/172] - loss: 0.0788

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.4196, log_difficulty=0.3504, weight=2.7519
neutral: count=3923.0, difficulty=0.3432, log_difficulty=0.2950, weight=2.4751
negative: count=4382.0, difficulty=0.4173, log_difficulty=0.3488, weight=2.7439

当前batch的pt分布：
positive: min=0.2133, max=0.9729, mean=0.7506
neutral: min=0.0154, max=0.8867, mean=0.7464
negative: min=0.9200, max=0.9858, mean=0.9521

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.7273
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3860
焦点损失: 0.1812
边界损失: 0.2328
总损失: 0.4051
Epoch 3 [57/172] - loss: 0.4051
Epoch 3 [58/172] - loss: 0.1160
Epoch 3 [59/172] - loss: 0.1536
Epoch 3 [60/172] - loss: 0.0996, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1089
Epoch 3 [62/172] - loss: 0.1728
Epoch 3 [63/172] - loss: 0.0916
Epoch 3 [64/172] - loss: 0.2792
Epoch 3 [65/172] - loss: 0.1289
Epoch 3 [66/172] - loss: 0.1611
Epoch 3 [67/172] - loss: 0.3037
Epoch 3 [68/172] - loss: 0.1561
Epoch 3 [69/172] - loss: 0.2101
Epoch 3 [70/172] - loss: 0.0759, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1506
Epoch 3 [72/172] - loss: 0.1245
Epoch 3 [73/172] - loss: 0.1331
Epoch 3 [74/172] - loss: 0.2126
Epoch 3 [75/172] - loss: 0.0988
Epoch 3 [76/172] - loss: 0.0877
Epoch 3 [77/172] - loss: 0.1161
Epoch 3 [78/172] - loss: 0.2179
Epoch 3 [79/172] - loss: 0.1100
Epoch 3 [80/172] - loss: 0.1384, acc: 0.9062
Epoch 3 [81/172] - loss: 0.1810
Epoch 3 [82/172] - loss: 0.1526
Epoch 3 [83/172] - loss: 0.0789
Epoch 3 [84/172] - loss: 0.1020
Epoch 3 [85/172] - loss: 0.1007
Epoch 3 [86/172] - loss: 0.0725
Epoch 3 [87/172] - loss: 0.1163
Epoch 3 [88/172] - loss: 0.2618
Epoch 3 [89/172] - loss: 0.1804
Epoch 3 [90/172] - loss: 0.0717, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1027
Epoch 3 [92/172] - loss: 0.1325
Epoch 3 [93/172] - loss: 0.2056
Epoch 3 [94/172] - loss: 0.1610
Epoch 3 [95/172] - loss: 0.1084
Epoch 3 [96/172] - loss: 0.1154
Epoch 3 [97/172] - loss: 0.1048
Epoch 3 [98/172] - loss: 0.1574
Epoch 3 [99/172] - loss: 0.0765
Epoch 3 [100/172] - loss: 0.2167, acc: 0.9375
Epoch 3 [101/172] - loss: 0.1512
Epoch 3 [102/172] - loss: 0.0892
Epoch 3 [103/172] - loss: 0.2196
Epoch 3 [104/172] - loss: 0.1418
Epoch 3 [105/172] - loss: 0.1079
Epoch 3 [106/172] - loss: 0.2829
Epoch 3 [107/172] - loss: 0.0784
Epoch 3 [108/172] - loss: 0.0920
Epoch 3 [109/172] - loss: 0.0832
Epoch 3 [110/172] - loss: 0.1823, acc: 0.9062
Epoch 3 [111/172] - loss: 0.1829
Epoch 3 [112/172] - loss: 0.0833
Epoch 3 [113/172] - loss: 0.0777
Epoch 3 [114/172] - loss: 0.0743
Epoch 3 [115/172] - loss: 0.1236
Epoch 3 [116/172] - loss: 0.0919
Epoch 3 [117/172] - loss: 0.1174
Epoch 3 [118/172] - loss: 0.1128
Epoch 3 [119/172] - loss: 0.0886
Epoch 3 [120/172] - loss: 0.1811, acc: 0.9062
Epoch 3 [121/172] - loss: 0.2613
Epoch 3 [122/172] - loss: 0.0897
Epoch 3 [123/172] - loss: 0.0724
Epoch 3 [124/172] - loss: 0.0928
Epoch 3 [125/172] - loss: 0.0914
Epoch 3 [126/172] - loss: 0.3397
Epoch 3 [127/172] - loss: 0.1051
Epoch 3 [128/172] - loss: 0.0570
Epoch 3 [129/172] - loss: 0.1261
Epoch 3 [130/172] - loss: 0.1580, acc: 0.9688
Epoch 3 [131/172] - loss: 0.1405
Epoch 3 [132/172] - loss: 0.0831
Epoch 3 [133/172] - loss: 0.0732
Epoch 3 [134/172] - loss: 0.0615
Epoch 3 [135/172] - loss: 0.0823
Epoch 3 [136/172] - loss: 0.1610
Epoch 3 [137/172] - loss: 0.0832
Epoch 3 [138/172] - loss: 0.0758
Epoch 3 [139/172] - loss: 0.0888
Epoch 3 [140/172] - loss: 0.0924, acc: 1.0000
Epoch 3 [141/172] - loss: 0.1961
Epoch 3 [142/172] - loss: 0.1721
Epoch 3 [143/172] - loss: 0.0889
Epoch 3 [144/172] - loss: 0.1572
Epoch 3 [145/172] - loss: 0.0919
Epoch 3 [146/172] - loss: 0.1718
Epoch 3 [147/172] - loss: 0.1369
Epoch 3 [148/172] - loss: 0.1664
Epoch 3 [149/172] - loss: 0.0783
Epoch 3 [150/172] - loss: 0.2039, acc: 0.9062
Epoch 3 [151/172] - loss: 0.3020
Epoch 3 [152/172] - loss: 0.1568
Epoch 3 [153/172] - loss: 0.1216
Epoch 3 [154/172] - loss: 0.3425
Epoch 3 [155/172] - loss: 0.0633
Epoch 3 [156/172] - loss: 0.1341

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3754, log_difficulty=0.3188, weight=2.5938
neutral: count=4903.0, difficulty=0.3007, log_difficulty=0.2629, weight=2.3144
negative: count=5500.0, difficulty=0.3759, log_difficulty=0.3191, weight=2.5956

当前batch的pt分布：
positive: min=0.6696, max=0.9901, mean=0.8671
neutral: min=0.8277, max=0.9599, mean=0.9205
negative: min=0.3826, max=0.9866, mean=0.7595

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1757
焦点损失: 0.0141
边界损失: 0.2254
总损失: 0.0836
Epoch 3 [157/172] - loss: 0.0836
Epoch 3 [158/172] - loss: 0.3055
Epoch 3 [159/172] - loss: 0.0978
Epoch 3 [160/172] - loss: 0.2069, acc: 0.8438
Epoch 3 [161/172] - loss: 0.2992
Epoch 3 [162/172] - loss: 0.1593
Epoch 3 [163/172] - loss: 0.0864
Epoch 3 [164/172] - loss: 0.1162
Epoch 3 [165/172] - loss: 0.0893
Epoch 3 [166/172] - loss: 0.1205
Epoch 3 [167/172] - loss: 0.1024
Epoch 3 [168/172] - loss: 0.0788
Epoch 3 [169/172] - loss: 0.0735
Epoch 3 [170/172] - loss: 0.1158, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1013
Epoch 3 [172/172] - loss: 0.1015

类别准确率:
positive: 0.8651 (404/467)
neutral: 0.3373 (28/83)
negative: 0.6000 (150/250)

Epoch 3/10
Train Loss: 0.1336, Train Acc: 0.9616
Val Loss: 0.6805, Val Acc: 0.7275
Epoch 4 [1/172] - loss: 0.0614, acc: 1.0000
Epoch 4 [2/172] - loss: 0.0941
Epoch 4 [3/172] - loss: 0.0949
Epoch 4 [4/172] - loss: 0.0607
Epoch 4 [5/172] - loss: 0.1505
Epoch 4 [6/172] - loss: 0.0569
Epoch 4 [7/172] - loss: 0.0998
Epoch 4 [8/172] - loss: 0.0659
Epoch 4 [9/172] - loss: 0.1531
Epoch 4 [10/172] - loss: 0.1260, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0525
Epoch 4 [12/172] - loss: 0.1370
Epoch 4 [13/172] - loss: 0.0880
Epoch 4 [14/172] - loss: 0.1627
Epoch 4 [15/172] - loss: 0.0575
Epoch 4 [16/172] - loss: 0.0833
Epoch 4 [17/172] - loss: 0.0701
Epoch 4 [18/172] - loss: 0.0885
Epoch 4 [19/172] - loss: 0.1000
Epoch 4 [20/172] - loss: 0.0840, acc: 0.9688
Epoch 4 [21/172] - loss: 0.1145
Epoch 4 [22/172] - loss: 0.0888
Epoch 4 [23/172] - loss: 0.0974
Epoch 4 [24/172] - loss: 0.0677
Epoch 4 [25/172] - loss: 0.0618
Epoch 4 [26/172] - loss: 0.1344
Epoch 4 [27/172] - loss: 0.0586
Epoch 4 [28/172] - loss: 0.1004
Epoch 4 [29/172] - loss: 0.0568
Epoch 4 [30/172] - loss: 0.1325, acc: 0.9375
Epoch 4 [31/172] - loss: 0.1248
Epoch 4 [32/172] - loss: 0.0960
Epoch 4 [33/172] - loss: 0.0589
Epoch 4 [34/172] - loss: 0.0651
Epoch 4 [35/172] - loss: 0.1232
Epoch 4 [36/172] - loss: 0.0711
Epoch 4 [37/172] - loss: 0.0470
Epoch 4 [38/172] - loss: 0.0580
Epoch 4 [39/172] - loss: 0.0673
Epoch 4 [40/172] - loss: 0.1468, acc: 0.9688
Epoch 4 [41/172] - loss: 0.0776
Epoch 4 [42/172] - loss: 0.1412
Epoch 4 [43/172] - loss: 0.1177
Epoch 4 [44/172] - loss: 0.0591
Epoch 4 [45/172] - loss: 0.0557
Epoch 4 [46/172] - loss: 0.0980
Epoch 4 [47/172] - loss: 0.0675
Epoch 4 [48/172] - loss: 0.0611
Epoch 4 [49/172] - loss: 0.0568
Epoch 4 [50/172] - loss: 0.2882, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0799
Epoch 4 [52/172] - loss: 0.0806
Epoch 4 [53/172] - loss: 0.0598
Epoch 4 [54/172] - loss: 0.0903
Epoch 4 [55/172] - loss: 0.2217
Epoch 4 [56/172] - loss: 0.0564
Epoch 4 [57/172] - loss: 0.0485
Epoch 4 [58/172] - loss: 0.0595
Epoch 4 [59/172] - loss: 0.0526
Epoch 4 [60/172] - loss: 0.0513, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1510
Epoch 4 [62/172] - loss: 0.0883
Epoch 4 [63/172] - loss: 0.0716
Epoch 4 [64/172] - loss: 0.1425
Epoch 4 [65/172] - loss: 0.0869
Epoch 4 [66/172] - loss: 0.0582
Epoch 4 [67/172] - loss: 0.0541
Epoch 4 [68/172] - loss: 0.0589
Epoch 4 [69/172] - loss: 0.1721
Epoch 4 [70/172] - loss: 0.0862, acc: 0.9688
Epoch 4 [71/172] - loss: 0.0804
Epoch 4 [72/172] - loss: 0.0687
Epoch 4 [73/172] - loss: 0.0959
Epoch 4 [74/172] - loss: 0.3146
Epoch 4 [75/172] - loss: 0.0679
Epoch 4 [76/172] - loss: 0.0518
Epoch 4 [77/172] - loss: 0.0623
Epoch 4 [78/172] - loss: 0.0624
Epoch 4 [79/172] - loss: 0.0697
Epoch 4 [80/172] - loss: 0.0577, acc: 1.0000
Epoch 4 [81/172] - loss: 0.0877
Epoch 4 [82/172] - loss: 0.0862
Epoch 4 [83/172] - loss: 0.0505
Epoch 4 [84/172] - loss: 0.0483

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3387, log_difficulty=0.2917, weight=2.4587
neutral: count=5865.0, difficulty=0.2669, log_difficulty=0.2366, weight=2.1830
negative: count=6629.0, difficulty=0.3389, log_difficulty=0.2919, weight=2.4593

当前batch的pt分布：
positive: min=0.4790, max=0.9585, mean=0.7815
neutral: min=0.9029, max=0.9986, mean=0.9722
negative: min=0.3675, max=0.9687, mean=0.8118

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.2075
焦点损失: 0.0242
边界损失: 0.2428
总损失: 0.1053
Epoch 4 [85/172] - loss: 0.1053
Epoch 4 [86/172] - loss: 0.1299
Epoch 4 [87/172] - loss: 0.0802
Epoch 4 [88/172] - loss: 0.0491
Epoch 4 [89/172] - loss: 0.0689
Epoch 4 [90/172] - loss: 0.0539, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1878
Epoch 4 [92/172] - loss: 0.3623
Epoch 4 [93/172] - loss: 0.0509
Epoch 4 [94/172] - loss: 0.0544
Epoch 4 [95/172] - loss: 0.1026
Epoch 4 [96/172] - loss: 0.0523
Epoch 4 [97/172] - loss: 0.0664
Epoch 4 [98/172] - loss: 0.0606
Epoch 4 [99/172] - loss: 0.0789
Epoch 4 [100/172] - loss: 0.0616, acc: 1.0000
Epoch 4 [101/172] - loss: 0.0670
Epoch 4 [102/172] - loss: 0.1198
Epoch 4 [103/172] - loss: 0.0723
Epoch 4 [104/172] - loss: 0.0561
Epoch 4 [105/172] - loss: 0.1789
Epoch 4 [106/172] - loss: 0.0849
Epoch 4 [107/172] - loss: 0.0619
Epoch 4 [108/172] - loss: 0.0893
Epoch 4 [109/172] - loss: 0.0592
Epoch 4 [110/172] - loss: 0.2040, acc: 0.9375
Epoch 4 [111/172] - loss: 0.0517
Epoch 4 [112/172] - loss: 0.0451
Epoch 4 [113/172] - loss: 0.0518
Epoch 4 [114/172] - loss: 0.0842
Epoch 4 [115/172] - loss: 0.1090
Epoch 4 [116/172] - loss: 0.1041
Epoch 4 [117/172] - loss: 0.0463
Epoch 4 [118/172] - loss: 0.0959
Epoch 4 [119/172] - loss: 0.0476
Epoch 4 [120/172] - loss: 0.0508, acc: 1.0000
Epoch 4 [121/172] - loss: 0.0821
Epoch 4 [122/172] - loss: 0.2557
Epoch 4 [123/172] - loss: 0.0572
Epoch 4 [124/172] - loss: 0.0450
Epoch 4 [125/172] - loss: 0.1140
Epoch 4 [126/172] - loss: 0.1674
Epoch 4 [127/172] - loss: 0.0844
Epoch 4 [128/172] - loss: 0.0741
Epoch 4 [129/172] - loss: 0.0577
Epoch 4 [130/172] - loss: 0.0608, acc: 0.9688
Epoch 4 [131/172] - loss: 0.0593
Epoch 4 [132/172] - loss: 0.0468
Epoch 4 [133/172] - loss: 0.0502
Epoch 4 [134/172] - loss: 0.0793
Epoch 4 [135/172] - loss: 0.0557
Epoch 4 [136/172] - loss: 0.0950
Epoch 4 [137/172] - loss: 0.0486
Epoch 4 [138/172] - loss: 0.0689
Epoch 4 [139/172] - loss: 0.0537
Epoch 4 [140/172] - loss: 0.1545, acc: 0.9375
Epoch 4 [141/172] - loss: 0.0709
Epoch 4 [142/172] - loss: 0.0955
Epoch 4 [143/172] - loss: 0.0600
Epoch 4 [144/172] - loss: 0.0785
Epoch 4 [145/172] - loss: 0.1909
Epoch 4 [146/172] - loss: 0.0542
Epoch 4 [147/172] - loss: 0.1091
Epoch 4 [148/172] - loss: 0.0860
Epoch 4 [149/172] - loss: 0.0572
Epoch 4 [150/172] - loss: 0.0962, acc: 0.9375
Epoch 4 [151/172] - loss: 0.0823
Epoch 4 [152/172] - loss: 0.0494
Epoch 4 [153/172] - loss: 0.0546
Epoch 4 [154/172] - loss: 0.0989
Epoch 4 [155/172] - loss: 0.0513
Epoch 4 [156/172] - loss: 0.0752
Epoch 4 [157/172] - loss: 0.2200
Epoch 4 [158/172] - loss: 0.0799
Epoch 4 [159/172] - loss: 0.0560
Epoch 4 [160/172] - loss: 0.0955, acc: 0.9375
Epoch 4 [161/172] - loss: 0.0700
Epoch 4 [162/172] - loss: 0.0511
Epoch 4 [163/172] - loss: 0.0733
Epoch 4 [164/172] - loss: 0.0501
Epoch 4 [165/172] - loss: 0.1095
Epoch 4 [166/172] - loss: 0.0491
Epoch 4 [167/172] - loss: 0.0798
Epoch 4 [168/172] - loss: 0.1869
Epoch 4 [169/172] - loss: 0.1460
Epoch 4 [170/172] - loss: 0.1984, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0587
Epoch 4 [172/172] - loss: 0.0509

类别准确率:
positive: 0.8715 (407/467)
neutral: 0.3614 (30/83)
negative: 0.5960 (149/250)

Epoch 4/10
Train Loss: 0.0984, Train Acc: 0.9737
Val Loss: 0.7348, Val Acc: 0.7325
Epoch 5 [1/172] - loss: 0.0461, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0621
Epoch 5 [3/172] - loss: 0.0530
Epoch 5 [4/172] - loss: 0.1310
Epoch 5 [5/172] - loss: 0.0476
Epoch 5 [6/172] - loss: 0.0629
Epoch 5 [7/172] - loss: 0.0551
Epoch 5 [8/172] - loss: 0.1306
Epoch 5 [9/172] - loss: 0.0966
Epoch 5 [10/172] - loss: 0.0485, acc: 1.0000
Epoch 5 [11/172] - loss: 0.0572
Epoch 5 [12/172] - loss: 0.0469

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.3078, log_difficulty=0.2683, weight=2.3416
neutral: count=6845.0, difficulty=0.2389, log_difficulty=0.2142, weight=2.0709
negative: count=7694.0, difficulty=0.3098, log_difficulty=0.2699, weight=2.3494

当前batch的pt分布：
positive: min=0.0277, max=0.9919, mean=0.8228
neutral: min=0.9210, max=0.9955, mean=0.9734
negative: min=0.7376, max=0.9685, mean=0.9095

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2036
焦点损失: 0.1068
边界损失: 0.1848
总损失: 0.2338
Epoch 5 [13/172] - loss: 0.2338
Epoch 5 [14/172] - loss: 0.0715
Epoch 5 [15/172] - loss: 0.0452
Epoch 5 [16/172] - loss: 0.0511
Epoch 5 [17/172] - loss: 0.1072
Epoch 5 [18/172] - loss: 0.0461
Epoch 5 [19/172] - loss: 0.1120
Epoch 5 [20/172] - loss: 0.1786, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1062
Epoch 5 [22/172] - loss: 0.2051
Epoch 5 [23/172] - loss: 0.0537
Epoch 5 [24/172] - loss: 0.1550
Epoch 5 [25/172] - loss: 0.0522
Epoch 5 [26/172] - loss: 0.0678
Epoch 5 [27/172] - loss: 0.0803
Epoch 5 [28/172] - loss: 0.1803
Epoch 5 [29/172] - loss: 0.0667
Epoch 5 [30/172] - loss: 0.0530, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0849
Epoch 5 [32/172] - loss: 0.0525
Epoch 5 [33/172] - loss: 0.0598
Epoch 5 [34/172] - loss: 0.0977
Epoch 5 [35/172] - loss: 0.0493
Epoch 5 [36/172] - loss: 0.0536
Epoch 5 [37/172] - loss: 0.0554
Epoch 5 [38/172] - loss: 0.0504
Epoch 5 [39/172] - loss: 0.0803
Epoch 5 [40/172] - loss: 0.0945, acc: 0.9375
Epoch 5 [41/172] - loss: 0.0526
Epoch 5 [42/172] - loss: 0.1072
Epoch 5 [43/172] - loss: 0.1674
Epoch 5 [44/172] - loss: 0.0731
Epoch 5 [45/172] - loss: 0.0496
Epoch 5 [46/172] - loss: 0.1670
Epoch 5 [47/172] - loss: 0.0446
Epoch 5 [48/172] - loss: 0.0818
Epoch 5 [49/172] - loss: 0.0601
Epoch 5 [50/172] - loss: 0.1082, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0638
Epoch 5 [52/172] - loss: 0.0556
Epoch 5 [53/172] - loss: 0.0699
Epoch 5 [54/172] - loss: 0.0610
Epoch 5 [55/172] - loss: 0.0734
Epoch 5 [56/172] - loss: 0.0818
Epoch 5 [57/172] - loss: 0.0453
Epoch 5 [58/172] - loss: 0.0474
Epoch 5 [59/172] - loss: 0.1815
Epoch 5 [60/172] - loss: 0.0578, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1167
Epoch 5 [62/172] - loss: 0.0587
Epoch 5 [63/172] - loss: 0.0798
Epoch 5 [64/172] - loss: 0.0549
Epoch 5 [65/172] - loss: 0.0495
Epoch 5 [66/172] - loss: 0.0758
Epoch 5 [67/172] - loss: 0.0428
Epoch 5 [68/172] - loss: 0.0626
Epoch 5 [69/172] - loss: 0.0468
Epoch 5 [70/172] - loss: 0.0881, acc: 0.9375
Epoch 5 [71/172] - loss: 0.0639
Epoch 5 [72/172] - loss: 0.0450
Epoch 5 [73/172] - loss: 0.0655
Epoch 5 [74/172] - loss: 0.1763
Epoch 5 [75/172] - loss: 0.0648
Epoch 5 [76/172] - loss: 0.0635
Epoch 5 [77/172] - loss: 0.0461
Epoch 5 [78/172] - loss: 0.1427
Epoch 5 [79/172] - loss: 0.0554
Epoch 5 [80/172] - loss: 0.0451, acc: 1.0000
Epoch 5 [81/172] - loss: 0.2593
Epoch 5 [82/172] - loss: 0.1815
Epoch 5 [83/172] - loss: 0.0467
Epoch 5 [84/172] - loss: 0.0428
Epoch 5 [85/172] - loss: 0.2385
Epoch 5 [86/172] - loss: 0.0634
Epoch 5 [87/172] - loss: 0.0799
Epoch 5 [88/172] - loss: 0.0667
Epoch 5 [89/172] - loss: 0.0614
Epoch 5 [90/172] - loss: 0.1038, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1123
Epoch 5 [92/172] - loss: 0.0654
Epoch 5 [93/172] - loss: 0.0526
Epoch 5 [94/172] - loss: 0.0502
Epoch 5 [95/172] - loss: 0.0554
Epoch 5 [96/172] - loss: 0.0824
Epoch 5 [97/172] - loss: 0.0866
Epoch 5 [98/172] - loss: 0.0820
Epoch 5 [99/172] - loss: 0.0997
Epoch 5 [100/172] - loss: 0.0612, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0684
Epoch 5 [102/172] - loss: 0.0706
Epoch 5 [103/172] - loss: 0.0489
Epoch 5 [104/172] - loss: 0.2180
Epoch 5 [105/172] - loss: 0.2691
Epoch 5 [106/172] - loss: 0.0875
Epoch 5 [107/172] - loss: 0.0579
Epoch 5 [108/172] - loss: 0.1079
Epoch 5 [109/172] - loss: 0.0467
Epoch 5 [110/172] - loss: 0.0523, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0776
Epoch 5 [112/172] - loss: 0.0513

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2834, log_difficulty=0.2495, weight=2.2475
neutral: count=7825.0, difficulty=0.2192, log_difficulty=0.1982, weight=1.9909
negative: count=8780.0, difficulty=0.2877, log_difficulty=0.2529, weight=2.2644

当前batch的pt分布：
positive: min=0.3926, max=0.9701, mean=0.7724
neutral: min=0.7536, max=0.9864, mean=0.9264
negative: min=0.8922, max=0.9895, mean=0.9510

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1822
焦点损失: 0.0257
边界损失: 0.2218
总损失: 0.0987
Epoch 5 [113/172] - loss: 0.0987
Epoch 5 [114/172] - loss: 0.2921
Epoch 5 [115/172] - loss: 0.0618
Epoch 5 [116/172] - loss: 0.0483
Epoch 5 [117/172] - loss: 0.0560
Epoch 5 [118/172] - loss: 0.0473
Epoch 5 [119/172] - loss: 0.0534
Epoch 5 [120/172] - loss: 0.1636, acc: 0.9688
Epoch 5 [121/172] - loss: 0.0623
Epoch 5 [122/172] - loss: 0.0510
Epoch 5 [123/172] - loss: 0.0527
Epoch 5 [124/172] - loss: 0.0942
Epoch 5 [125/172] - loss: 0.0651
Epoch 5 [126/172] - loss: 0.0672
Epoch 5 [127/172] - loss: 0.0786
Epoch 5 [128/172] - loss: 0.0514
Epoch 5 [129/172] - loss: 0.0792
Epoch 5 [130/172] - loss: 0.0551, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0645
Epoch 5 [132/172] - loss: 0.1860
Epoch 5 [133/172] - loss: 0.0740
Epoch 5 [134/172] - loss: 0.1460
Epoch 5 [135/172] - loss: 0.0489
Epoch 5 [136/172] - loss: 0.0562
Epoch 5 [137/172] - loss: 0.0575
Epoch 5 [138/172] - loss: 0.0671
Epoch 5 [139/172] - loss: 0.1115
Epoch 5 [140/172] - loss: 0.0899, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0585
Epoch 5 [142/172] - loss: 0.0860
Epoch 5 [143/172] - loss: 0.0467
Epoch 5 [144/172] - loss: 0.0572
Epoch 5 [145/172] - loss: 0.1115
Epoch 5 [146/172] - loss: 0.1085
Epoch 5 [147/172] - loss: 0.0625
Epoch 5 [148/172] - loss: 0.0432
Epoch 5 [149/172] - loss: 0.0541
Epoch 5 [150/172] - loss: 0.1068, acc: 0.9375
Epoch 5 [151/172] - loss: 0.0421
Epoch 5 [152/172] - loss: 0.0489
Epoch 5 [153/172] - loss: 0.0460
Epoch 5 [154/172] - loss: 0.0426
Epoch 5 [155/172] - loss: 0.0483
Epoch 5 [156/172] - loss: 0.0709
Epoch 5 [157/172] - loss: 0.0525
Epoch 5 [158/172] - loss: 0.0602
Epoch 5 [159/172] - loss: 0.0414
Epoch 5 [160/172] - loss: 0.0603, acc: 0.9688
Epoch 5 [161/172] - loss: 0.0439
Epoch 5 [162/172] - loss: 0.0633
Epoch 5 [163/172] - loss: 0.1236
Epoch 5 [164/172] - loss: 0.0456
Epoch 5 [165/172] - loss: 0.1227
Epoch 5 [166/172] - loss: 0.0648
Epoch 5 [167/172] - loss: 0.0521
Epoch 5 [168/172] - loss: 0.0608
Epoch 5 [169/172] - loss: 0.0460
Epoch 5 [170/172] - loss: 0.0433, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0659
Epoch 5 [172/172] - loss: 0.1106

类别准确率:
positive: 0.8458 (395/467)
neutral: 0.3012 (25/83)
negative: 0.5760 (144/250)

Epoch 5/10
Train Loss: 0.0661, Train Acc: 0.9818
Val Loss: 0.8204, Val Acc: 0.7050
Epoch 6 [1/172] - loss: 0.0662, acc: 0.9688
Epoch 6 [2/172] - loss: 0.0654
Epoch 6 [3/172] - loss: 0.0400
Epoch 6 [4/172] - loss: 0.0802
Epoch 6 [5/172] - loss: 0.1219
Epoch 6 [6/172] - loss: 0.0485
Epoch 6 [7/172] - loss: 0.0546
Epoch 6 [8/172] - loss: 0.1030
Epoch 6 [9/172] - loss: 0.0492
Epoch 6 [10/172] - loss: 0.0469, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0824
Epoch 6 [12/172] - loss: 0.0458
Epoch 6 [13/172] - loss: 0.2334
Epoch 6 [14/172] - loss: 0.0468
Epoch 6 [15/172] - loss: 0.0631
Epoch 6 [16/172] - loss: 0.1516
Epoch 6 [17/172] - loss: 0.0500
Epoch 6 [18/172] - loss: 0.0444
Epoch 6 [19/172] - loss: 0.0459
Epoch 6 [20/172] - loss: 0.0446, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0895
Epoch 6 [22/172] - loss: 0.1033
Epoch 6 [23/172] - loss: 0.0835
Epoch 6 [24/172] - loss: 0.0714
Epoch 6 [25/172] - loss: 0.0591
Epoch 6 [26/172] - loss: 0.0456
Epoch 6 [27/172] - loss: 0.0637
Epoch 6 [28/172] - loss: 0.0464
Epoch 6 [29/172] - loss: 0.0523
Epoch 6 [30/172] - loss: 0.0540, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0457
Epoch 6 [32/172] - loss: 0.0424
Epoch 6 [33/172] - loss: 0.0613
Epoch 6 [34/172] - loss: 0.0464
Epoch 6 [35/172] - loss: 0.0432
Epoch 6 [36/172] - loss: 0.0760
Epoch 6 [37/172] - loss: 0.0432
Epoch 6 [38/172] - loss: 0.0576
Epoch 6 [39/172] - loss: 0.0470
Epoch 6 [40/172] - loss: 0.0671, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2623, log_difficulty=0.2329, weight=2.1647
neutral: count=8815.0, difficulty=0.2036, log_difficulty=0.1853, weight=1.9265
negative: count=9870.0, difficulty=0.2668, log_difficulty=0.2365, weight=2.1825

当前batch的pt分布：
positive: min=0.0583, max=0.9956, mean=0.8735
neutral: min=0.8633, max=0.9895, mean=0.9548
negative: min=0.5133, max=0.9898, mean=0.8722

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1707
焦点损失: 0.0832
边界损失: 0.1761
总损失: 0.1791
Epoch 6 [41/172] - loss: 0.1791
Epoch 6 [42/172] - loss: 0.0453
Epoch 6 [43/172] - loss: 0.1672
Epoch 6 [44/172] - loss: 0.0463
Epoch 6 [45/172] - loss: 0.0563
Epoch 6 [46/172] - loss: 0.0622
Epoch 6 [47/172] - loss: 0.0551
Epoch 6 [48/172] - loss: 0.0464
Epoch 6 [49/172] - loss: 0.0518
Epoch 6 [50/172] - loss: 0.1011, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0658
Epoch 6 [52/172] - loss: 0.1050
Epoch 6 [53/172] - loss: 0.0427
Epoch 6 [54/172] - loss: 0.1183
Epoch 6 [55/172] - loss: 0.0557
Epoch 6 [56/172] - loss: 0.0820
Epoch 6 [57/172] - loss: 0.0445
Epoch 6 [58/172] - loss: 0.0446
Epoch 6 [59/172] - loss: 0.0936
Epoch 6 [60/172] - loss: 0.0572, acc: 1.0000
Epoch 6 [61/172] - loss: 0.0459
Epoch 6 [62/172] - loss: 0.0604
Epoch 6 [63/172] - loss: 0.0472
Epoch 6 [64/172] - loss: 0.1281
Epoch 6 [65/172] - loss: 0.0665
Epoch 6 [66/172] - loss: 0.0633
Epoch 6 [67/172] - loss: 0.0432
Epoch 6 [68/172] - loss: 0.1663
Epoch 6 [69/172] - loss: 0.1325
Epoch 6 [70/172] - loss: 0.0442, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0538
Epoch 6 [72/172] - loss: 0.0653
Epoch 6 [73/172] - loss: 0.0837
Epoch 6 [74/172] - loss: 0.0440
Epoch 6 [75/172] - loss: 0.0980
Epoch 6 [76/172] - loss: 0.0435
Epoch 6 [77/172] - loss: 0.0590
Epoch 6 [78/172] - loss: 0.0572
Epoch 6 [79/172] - loss: 0.0405
Epoch 6 [80/172] - loss: 0.0783, acc: 0.9688
Epoch 6 [81/172] - loss: 0.0811
Epoch 6 [82/172] - loss: 0.1258
Epoch 6 [83/172] - loss: 0.0414
Epoch 6 [84/172] - loss: 0.0414
Epoch 6 [85/172] - loss: 0.1167
Epoch 6 [86/172] - loss: 0.0796
Epoch 6 [87/172] - loss: 0.0987
Epoch 6 [88/172] - loss: 0.0704
Epoch 6 [89/172] - loss: 0.0689
Epoch 6 [90/172] - loss: 0.1579, acc: 0.9375
Epoch 6 [91/172] - loss: 0.0873
Epoch 6 [92/172] - loss: 0.0836
Epoch 6 [93/172] - loss: 0.0594
Epoch 6 [94/172] - loss: 0.1416
Epoch 6 [95/172] - loss: 0.0430
Epoch 6 [96/172] - loss: 0.0456
Epoch 6 [97/172] - loss: 0.0691
Epoch 6 [98/172] - loss: 0.0619
Epoch 6 [99/172] - loss: 0.0504
Epoch 6 [100/172] - loss: 0.0457, acc: 1.0000
Epoch 6 [101/172] - loss: 0.0674
Epoch 6 [102/172] - loss: 0.0569
Epoch 6 [103/172] - loss: 0.0656
Epoch 6 [104/172] - loss: 0.0925
Epoch 6 [105/172] - loss: 0.0545
Epoch 6 [106/172] - loss: 0.1254
Epoch 6 [107/172] - loss: 0.0497
Epoch 6 [108/172] - loss: 0.0415
Epoch 6 [109/172] - loss: 0.2545
Epoch 6 [110/172] - loss: 0.0451, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0447
Epoch 6 [112/172] - loss: 0.0771
Epoch 6 [113/172] - loss: 0.1216
Epoch 6 [114/172] - loss: 0.0515
Epoch 6 [115/172] - loss: 0.0701
Epoch 6 [116/172] - loss: 0.3547
Epoch 6 [117/172] - loss: 0.0510
Epoch 6 [118/172] - loss: 0.0448
Epoch 6 [119/172] - loss: 0.1522
Epoch 6 [120/172] - loss: 0.0488, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0486
Epoch 6 [122/172] - loss: 0.1419
Epoch 6 [123/172] - loss: 0.0604
Epoch 6 [124/172] - loss: 0.0510
Epoch 6 [125/172] - loss: 0.0477
Epoch 6 [126/172] - loss: 0.1414
Epoch 6 [127/172] - loss: 0.2113
Epoch 6 [128/172] - loss: 0.0544
Epoch 6 [129/172] - loss: 0.0765
Epoch 6 [130/172] - loss: 0.1078, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1148
Epoch 6 [132/172] - loss: 0.0985
Epoch 6 [133/172] - loss: 0.0437
Epoch 6 [134/172] - loss: 0.0461
Epoch 6 [135/172] - loss: 0.0509
Epoch 6 [136/172] - loss: 0.0448
Epoch 6 [137/172] - loss: 0.0543
Epoch 6 [138/172] - loss: 0.0746
Epoch 6 [139/172] - loss: 0.0491
Epoch 6 [140/172] - loss: 0.0513, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2454, log_difficulty=0.2195, weight=2.0975
neutral: count=9796.0, difficulty=0.1910, log_difficulty=0.1748, weight=1.8739
negative: count=10972.0, difficulty=0.2494, log_difficulty=0.2227, weight=2.1134

当前batch的pt分布：
positive: min=0.8959, max=0.9979, mean=0.9626
neutral: min=0.8685, max=0.9946, mean=0.9560
negative: min=0.6286, max=0.9820, mean=0.8894

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0753
焦点损失: 0.0023
边界损失: 0.1744
总损失: 0.0473
Epoch 6 [141/172] - loss: 0.0473
Epoch 6 [142/172] - loss: 0.0565
Epoch 6 [143/172] - loss: 0.0510
Epoch 6 [144/172] - loss: 0.0584
Epoch 6 [145/172] - loss: 0.0442
Epoch 6 [146/172] - loss: 0.0417
Epoch 6 [147/172] - loss: 0.0619
Epoch 6 [148/172] - loss: 0.1357
Epoch 6 [149/172] - loss: 0.0532
Epoch 6 [150/172] - loss: 0.0403, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0463
Epoch 6 [152/172] - loss: 0.0604
Epoch 6 [153/172] - loss: 0.0513
Epoch 6 [154/172] - loss: 0.0525
Epoch 6 [155/172] - loss: 0.0530
Epoch 6 [156/172] - loss: 0.1634
Epoch 6 [157/172] - loss: 0.0796
Epoch 6 [158/172] - loss: 0.0607
Epoch 6 [159/172] - loss: 0.0646
Epoch 6 [160/172] - loss: 0.1496, acc: 0.9375
Epoch 6 [161/172] - loss: 0.0669
Epoch 6 [162/172] - loss: 0.0690
Epoch 6 [163/172] - loss: 0.1039
Epoch 6 [164/172] - loss: 0.0687
Epoch 6 [165/172] - loss: 0.4303
Epoch 6 [166/172] - loss: 0.1291
Epoch 6 [167/172] - loss: 0.0552
Epoch 6 [168/172] - loss: 0.0865
Epoch 6 [169/172] - loss: 0.0672
Epoch 6 [170/172] - loss: 0.0935, acc: 0.9688
Epoch 6 [171/172] - loss: 0.0469
Epoch 6 [172/172] - loss: 0.0907

类别准确率:
positive: 0.9443 (441/467)
neutral: 0.1084 (9/83)
negative: 0.3920 (98/250)

Epoch 6/10
Train Loss: 0.1039, Train Acc: 0.9657
Val Loss: 0.9181, Val Acc: 0.6850
Epoch 7 [1/172] - loss: 0.0553, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0533
Epoch 7 [3/172] - loss: 0.0525
Epoch 7 [4/172] - loss: 0.0854
Epoch 7 [5/172] - loss: 0.0497
Epoch 7 [6/172] - loss: 0.0468
Epoch 7 [7/172] - loss: 0.0590
Epoch 7 [8/172] - loss: 0.0650
Epoch 7 [9/172] - loss: 0.0459
Epoch 7 [10/172] - loss: 0.0456, acc: 1.0000
Epoch 7 [11/172] - loss: 0.2239
Epoch 7 [12/172] - loss: 0.0634
Epoch 7 [13/172] - loss: 0.0451
Epoch 7 [14/172] - loss: 0.0507
Epoch 7 [15/172] - loss: 0.1363
Epoch 7 [16/172] - loss: 0.1569
Epoch 7 [17/172] - loss: 0.1247
Epoch 7 [18/172] - loss: 0.0614
Epoch 7 [19/172] - loss: 0.0473
Epoch 7 [20/172] - loss: 0.0471, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0534
Epoch 7 [22/172] - loss: 0.0451
Epoch 7 [23/172] - loss: 0.0423
Epoch 7 [24/172] - loss: 0.0459
Epoch 7 [25/172] - loss: 0.0469
Epoch 7 [26/172] - loss: 0.0885
Epoch 7 [27/172] - loss: 0.0501
Epoch 7 [28/172] - loss: 0.0691
Epoch 7 [29/172] - loss: 0.0591
Epoch 7 [30/172] - loss: 0.1075, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0466
Epoch 7 [32/172] - loss: 0.0458
Epoch 7 [33/172] - loss: 0.0494
Epoch 7 [34/172] - loss: 0.0458
Epoch 7 [35/172] - loss: 0.0458
Epoch 7 [36/172] - loss: 0.1960
Epoch 7 [37/172] - loss: 0.0513
Epoch 7 [38/172] - loss: 0.0492
Epoch 7 [39/172] - loss: 0.0481
Epoch 7 [40/172] - loss: 0.0542, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0437
Epoch 7 [42/172] - loss: 0.0498
Epoch 7 [43/172] - loss: 0.0463
Epoch 7 [44/172] - loss: 0.0644
Epoch 7 [45/172] - loss: 0.0722
Epoch 7 [46/172] - loss: 0.1488
Epoch 7 [47/172] - loss: 0.1369
Epoch 7 [48/172] - loss: 0.0405
Epoch 7 [49/172] - loss: 0.0559
Epoch 7 [50/172] - loss: 0.0440, acc: 1.0000
Epoch 7 [51/172] - loss: 0.0844
Epoch 7 [52/172] - loss: 0.0437
Epoch 7 [53/172] - loss: 0.0468
Epoch 7 [54/172] - loss: 0.0451
Epoch 7 [55/172] - loss: 0.0474
Epoch 7 [56/172] - loss: 0.0556
Epoch 7 [57/172] - loss: 0.1140
Epoch 7 [58/172] - loss: 0.0874
Epoch 7 [59/172] - loss: 0.0433
Epoch 7 [60/172] - loss: 0.0650, acc: 1.0000
Epoch 7 [61/172] - loss: 0.0517
Epoch 7 [62/172] - loss: 0.0629
Epoch 7 [63/172] - loss: 0.1390
Epoch 7 [64/172] - loss: 0.0478
Epoch 7 [65/172] - loss: 0.0632
Epoch 7 [66/172] - loss: 0.0458
Epoch 7 [67/172] - loss: 0.0554
Epoch 7 [68/172] - loss: 0.0786

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.2317, log_difficulty=0.2084, weight=2.0418
neutral: count=10756.0, difficulty=0.1802, log_difficulty=0.1657, weight=1.8283
negative: count=12072.0, difficulty=0.2355, log_difficulty=0.2115, weight=2.0575

当前batch的pt分布：
positive: min=0.9187, max=0.9982, mean=0.9683
neutral: min=0.9411, max=0.9934, mean=0.9765
negative: min=0.6973, max=0.9795, mean=0.9076

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0601
焦点损失: 0.0012
边界损失: 0.1645
总损失: 0.0430
Epoch 7 [69/172] - loss: 0.0430
Epoch 7 [70/172] - loss: 0.0549, acc: 0.9688
Epoch 7 [71/172] - loss: 0.0460
Epoch 7 [72/172] - loss: 0.0437
Epoch 7 [73/172] - loss: 0.0709
Epoch 7 [74/172] - loss: 0.0412
Epoch 7 [75/172] - loss: 0.0413
Epoch 7 [76/172] - loss: 0.0502
Epoch 7 [77/172] - loss: 0.0560
Epoch 7 [78/172] - loss: 0.0451
Epoch 7 [79/172] - loss: 0.0698
Epoch 7 [80/172] - loss: 0.0776, acc: 0.9688
Epoch 7 [81/172] - loss: 0.0419
Epoch 7 [82/172] - loss: 0.0423
Epoch 7 [83/172] - loss: 0.0790
Epoch 7 [84/172] - loss: 0.0442
Epoch 7 [85/172] - loss: 0.0431
Epoch 7 [86/172] - loss: 0.0441
Epoch 7 [87/172] - loss: 0.1840
Epoch 7 [88/172] - loss: 0.0425
Epoch 7 [89/172] - loss: 0.0552
Epoch 7 [90/172] - loss: 0.0451, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0612
Epoch 7 [92/172] - loss: 0.0458
Epoch 7 [93/172] - loss: 0.0554
Epoch 7 [94/172] - loss: 0.0445
Epoch 7 [95/172] - loss: 0.0491
Epoch 7 [96/172] - loss: 0.0437
Epoch 7 [97/172] - loss: 0.0452
Epoch 7 [98/172] - loss: 0.0648
Epoch 7 [99/172] - loss: 0.0473
Epoch 7 [100/172] - loss: 0.0676, acc: 0.9688
Epoch 7 [101/172] - loss: 0.0431
Epoch 7 [102/172] - loss: 0.0406
Epoch 7 [103/172] - loss: 0.0563
Epoch 7 [104/172] - loss: 0.0518
Epoch 7 [105/172] - loss: 0.0881
Epoch 7 [106/172] - loss: 0.1028
Epoch 7 [107/172] - loss: 0.0398
Epoch 7 [108/172] - loss: 0.0411
Epoch 7 [109/172] - loss: 0.1683
Epoch 7 [110/172] - loss: 0.0472, acc: 1.0000
Epoch 7 [111/172] - loss: 0.0426
Epoch 7 [112/172] - loss: 0.0443
Epoch 7 [113/172] - loss: 0.0408
Epoch 7 [114/172] - loss: 0.0415
Epoch 7 [115/172] - loss: 0.0422
Epoch 7 [116/172] - loss: 0.0874
Epoch 7 [117/172] - loss: 0.0445
Epoch 7 [118/172] - loss: 0.0523
Epoch 7 [119/172] - loss: 0.0442
Epoch 7 [120/172] - loss: 0.0434, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0457
Epoch 7 [122/172] - loss: 0.0412
Epoch 7 [123/172] - loss: 0.0614
Epoch 7 [124/172] - loss: 0.0553
Epoch 7 [125/172] - loss: 0.0397
Epoch 7 [126/172] - loss: 0.1609
Epoch 7 [127/172] - loss: 0.0483
Epoch 7 [128/172] - loss: 0.0600
Epoch 7 [129/172] - loss: 0.0460
Epoch 7 [130/172] - loss: 0.0432, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1825
Epoch 7 [132/172] - loss: 0.1427
Epoch 7 [133/172] - loss: 0.0401
Epoch 7 [134/172] - loss: 0.0483
Epoch 7 [135/172] - loss: 0.0505
Epoch 7 [136/172] - loss: 0.0440
Epoch 7 [137/172] - loss: 0.0570
Epoch 7 [138/172] - loss: 0.0384
Epoch 7 [139/172] - loss: 0.0710
Epoch 7 [140/172] - loss: 0.0472, acc: 1.0000
Epoch 7 [141/172] - loss: 0.1253
Epoch 7 [142/172] - loss: 0.0455
Epoch 7 [143/172] - loss: 0.0522
Epoch 7 [144/172] - loss: 0.0438
Epoch 7 [145/172] - loss: 0.0779
Epoch 7 [146/172] - loss: 0.1139
Epoch 7 [147/172] - loss: 0.0477
Epoch 7 [148/172] - loss: 0.0625
Epoch 7 [149/172] - loss: 0.0463
Epoch 7 [150/172] - loss: 0.0453, acc: 1.0000
Epoch 7 [151/172] - loss: 0.0853
Epoch 7 [152/172] - loss: 0.0396
Epoch 7 [153/172] - loss: 0.0497
Epoch 7 [154/172] - loss: 0.0527
Epoch 7 [155/172] - loss: 0.0406
Epoch 7 [156/172] - loss: 0.0669
Epoch 7 [157/172] - loss: 0.0484
Epoch 7 [158/172] - loss: 0.0491
Epoch 7 [159/172] - loss: 0.0404
Epoch 7 [160/172] - loss: 0.0495, acc: 1.0000
Epoch 7 [161/172] - loss: 0.0459
Epoch 7 [162/172] - loss: 0.0435
Epoch 7 [163/172] - loss: 0.0429
Epoch 7 [164/172] - loss: 0.0549
Epoch 7 [165/172] - loss: 0.0619
Epoch 7 [166/172] - loss: 0.0830
Epoch 7 [167/172] - loss: 0.0537
Epoch 7 [168/172] - loss: 0.0502

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.2180, log_difficulty=0.1972, weight=1.9861
neutral: count=11731.0, difficulty=0.1706, log_difficulty=0.1575, weight=1.7875
negative: count=13173.0, difficulty=0.2222, log_difficulty=0.2007, weight=2.0033

当前batch的pt分布：
positive: min=0.8615, max=0.9927, mean=0.9515
neutral: min=0.9662, max=0.9874, mean=0.9770
negative: min=0.8483, max=0.9868, mean=0.9340

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0500
焦点损失: 0.0003
边界损失: 0.1598
总损失: 0.0405
Epoch 7 [169/172] - loss: 0.0405
Epoch 7 [170/172] - loss: 0.0557, acc: 1.0000
Epoch 7 [171/172] - loss: 0.0420
Epoch 7 [172/172] - loss: 0.0380

类别准确率:
positive: 0.8415 (393/467)
neutral: 0.3373 (28/83)
negative: 0.6200 (155/250)

Epoch 7/10
Train Loss: 0.0500, Train Acc: 0.9939
Val Loss: 0.7633, Val Acc: 0.7200
Early stopping triggered!
Best validation accuracy: 0.7325

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_100839-9tigqkps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.25_Multimodal_iterations_20250118_100838
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/9tigqkps
wandb: uploading wandb-summary.json; uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████
wandb:  train_acc ▁▇▃▅▅▅▆▇▇▆▇███▇█▇█████▇███▇████████▇████
wandb: train_loss █▇▄▅▃▃▄▃▄▂▃▂▁▁▂▂▁▁▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 1
wandb: train_loss 0.05571
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.25_Multimodal_iterations_20250118_100838 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/9tigqkps
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_100839-9tigqkps/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_102010-fgai5lbr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.25_Multimodal_epochs_20250118_102010
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/fgai5lbr
wandb: uploading wandb-metadata.json; uploading requirements.txt; uploading history steps 0-0, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▆▇▇█▇█
wandb: train_loss █▄▂▂▁▂▁
wandb:    val_acc ▁▆██▆▅▇
wandb:   val_loss ▆▂▁▃▅█▃
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.99394
wandb: train_loss 0.04997
wandb:    val_acc 0.72
wandb:   val_loss 0.76325
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight0.5_dropout0.25_Multimodal_epochs_20250118_102010 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/fgai5lbr
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_102010-fgai5lbr/logs

