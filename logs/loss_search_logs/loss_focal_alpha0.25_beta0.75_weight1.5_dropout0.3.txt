=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 1.5 --dropout 0.3 --name loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.3 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.3
text_dim: 128
image_dim: 256
dropout: 0.3
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6849, log_difficulty=0.5217, weight=3.6086
neutral: count=7.0, difficulty=0.7124, log_difficulty=0.5379, weight=3.6894
negative: count=13.0, difficulty=0.6648, log_difficulty=0.5097, weight=3.5485

当前batch的pt分布：
positive: min=0.1442, max=0.5773, mean=0.3151
neutral: min=0.2072, max=0.4000, mean=0.2876
negative: min=0.1625, max=0.5190, mean=0.3352

当前batch准确率：
整体准确率: 0.2500
positive 准确率: 0.2500
neutral 准确率: 0.1429
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1966
焦点损失: 0.4367
边界损失: 0.7241
总损失: 0.9368
Epoch 1 [1/172] - loss: 0.9368, acc: 0.2500
Epoch 1 [2/172] - loss: 0.9395
Epoch 1 [3/172] - loss: 0.9685
Epoch 1 [4/172] - loss: 0.9377
Epoch 1 [5/172] - loss: 1.0871
Epoch 1 [6/172] - loss: 0.8881
Epoch 1 [7/172] - loss: 1.0196
Epoch 1 [8/172] - loss: 0.9921
Epoch 1 [9/172] - loss: 0.8998
Epoch 1 [10/172] - loss: 0.9852, acc: 0.3125
Epoch 1 [11/172] - loss: 1.1527
Epoch 1 [12/172] - loss: 0.8145
Epoch 1 [13/172] - loss: 0.8039
Epoch 1 [14/172] - loss: 0.9542
Epoch 1 [15/172] - loss: 0.9372
Epoch 1 [16/172] - loss: 0.8373
Epoch 1 [17/172] - loss: 0.8459
Epoch 1 [18/172] - loss: 0.8881
Epoch 1 [19/172] - loss: 0.9310
Epoch 1 [20/172] - loss: 0.9087, acc: 0.2812
Epoch 1 [21/172] - loss: 0.8295
Epoch 1 [22/172] - loss: 0.7583
Epoch 1 [23/172] - loss: 0.9446
Epoch 1 [24/172] - loss: 0.8816
Epoch 1 [25/172] - loss: 0.8240
Epoch 1 [26/172] - loss: 0.8207
Epoch 1 [27/172] - loss: 0.8176
Epoch 1 [28/172] - loss: 0.7672
Epoch 1 [29/172] - loss: 0.8355
Epoch 1 [30/172] - loss: 0.6362, acc: 0.5625
Epoch 1 [31/172] - loss: 0.7344
Epoch 1 [32/172] - loss: 0.7484
Epoch 1 [33/172] - loss: 0.8075
Epoch 1 [34/172] - loss: 0.7209
Epoch 1 [35/172] - loss: 0.8141
Epoch 1 [36/172] - loss: 0.7662
Epoch 1 [37/172] - loss: 0.8778
Epoch 1 [38/172] - loss: 0.8019
Epoch 1 [39/172] - loss: 0.8491
Epoch 1 [40/172] - loss: 0.7512, acc: 0.5000
Epoch 1 [41/172] - loss: 0.6937
Epoch 1 [42/172] - loss: 0.5550
Epoch 1 [43/172] - loss: 0.7279
Epoch 1 [44/172] - loss: 0.8169
Epoch 1 [45/172] - loss: 0.9761
Epoch 1 [46/172] - loss: 0.6427
Epoch 1 [47/172] - loss: 0.7383
Epoch 1 [48/172] - loss: 0.7043
Epoch 1 [49/172] - loss: 0.7909
Epoch 1 [50/172] - loss: 0.6327, acc: 0.5312
Epoch 1 [51/172] - loss: 0.7598
Epoch 1 [52/172] - loss: 0.8114
Epoch 1 [53/172] - loss: 0.8030
Epoch 1 [54/172] - loss: 0.8440
Epoch 1 [55/172] - loss: 0.7216
Epoch 1 [56/172] - loss: 0.6040
Epoch 1 [57/172] - loss: 0.7251
Epoch 1 [58/172] - loss: 0.6431
Epoch 1 [59/172] - loss: 0.7133
Epoch 1 [60/172] - loss: 0.6348, acc: 0.6250
Epoch 1 [61/172] - loss: 0.5676
Epoch 1 [62/172] - loss: 0.6328
Epoch 1 [63/172] - loss: 0.7744
Epoch 1 [64/172] - loss: 0.5183
Epoch 1 [65/172] - loss: 0.6645
Epoch 1 [66/172] - loss: 0.5711
Epoch 1 [67/172] - loss: 0.8411
Epoch 1 [68/172] - loss: 0.7952
Epoch 1 [69/172] - loss: 0.7947
Epoch 1 [70/172] - loss: 0.5615, acc: 0.5312
Epoch 1 [71/172] - loss: 0.5481
Epoch 1 [72/172] - loss: 0.5377
Epoch 1 [73/172] - loss: 0.5452
Epoch 1 [74/172] - loss: 0.6939
Epoch 1 [75/172] - loss: 0.3727
Epoch 1 [76/172] - loss: 0.5779
Epoch 1 [77/172] - loss: 0.6324
Epoch 1 [78/172] - loss: 0.5329
Epoch 1 [79/172] - loss: 0.7180
Epoch 1 [80/172] - loss: 0.4527, acc: 0.7500
Epoch 1 [81/172] - loss: 0.5510
Epoch 1 [82/172] - loss: 0.7452
Epoch 1 [83/172] - loss: 0.7070
Epoch 1 [84/172] - loss: 0.4987
Epoch 1 [85/172] - loss: 0.5285
Epoch 1 [86/172] - loss: 0.6064
Epoch 1 [87/172] - loss: 0.5549
Epoch 1 [88/172] - loss: 0.6835
Epoch 1 [89/172] - loss: 0.6866
Epoch 1 [90/172] - loss: 0.6067, acc: 0.6250
Epoch 1 [91/172] - loss: 0.6043
Epoch 1 [92/172] - loss: 0.5173
Epoch 1 [93/172] - loss: 0.6283
Epoch 1 [94/172] - loss: 0.4165
Epoch 1 [95/172] - loss: 0.4704
Epoch 1 [96/172] - loss: 0.5188
Epoch 1 [97/172] - loss: 0.5152
Epoch 1 [98/172] - loss: 0.4474
Epoch 1 [99/172] - loss: 0.7265
Epoch 1 [100/172] - loss: 0.6685, acc: 0.6562

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5947, log_difficulty=0.4667, weight=3.3334
neutral: count=983.0, difficulty=0.5230, log_difficulty=0.4207, weight=3.1035
negative: count=1119.0, difficulty=0.5172, log_difficulty=0.4169, weight=3.0844

当前batch的pt分布：
positive: min=0.0621, max=0.9483, mean=0.3866
neutral: min=0.1228, max=0.9760, mean=0.6779
negative: min=0.0359, max=0.8346, mean=0.4260

当前batch准确率：
整体准确率: 0.4688
positive 准确率: 0.4167
neutral 准确率: 0.7500
negative 准确率: 0.4375

损失分量：
基础交叉熵: 1.0703
焦点损失: 0.5361
边界损失: 0.4405
总损失: 0.7575
Epoch 1 [101/172] - loss: 0.7575
Epoch 1 [102/172] - loss: 0.5087
Epoch 1 [103/172] - loss: 0.4104
Epoch 1 [104/172] - loss: 0.4850
Epoch 1 [105/172] - loss: 0.6505
Epoch 1 [106/172] - loss: 0.7324
Epoch 1 [107/172] - loss: 0.4748
Epoch 1 [108/172] - loss: 0.6675
Epoch 1 [109/172] - loss: 0.5877
Epoch 1 [110/172] - loss: 0.5343, acc: 0.6250
Epoch 1 [111/172] - loss: 0.6180
Epoch 1 [112/172] - loss: 0.3858
Epoch 1 [113/172] - loss: 0.2997
Epoch 1 [114/172] - loss: 0.5074
Epoch 1 [115/172] - loss: 0.5327
Epoch 1 [116/172] - loss: 0.4821
Epoch 1 [117/172] - loss: 0.4465
Epoch 1 [118/172] - loss: 0.4518
Epoch 1 [119/172] - loss: 0.6206
Epoch 1 [120/172] - loss: 0.4257, acc: 0.7500
Epoch 1 [121/172] - loss: 0.4525
Epoch 1 [122/172] - loss: 0.6962
Epoch 1 [123/172] - loss: 0.3798
Epoch 1 [124/172] - loss: 0.5498
Epoch 1 [125/172] - loss: 0.4070
Epoch 1 [126/172] - loss: 0.5791
Epoch 1 [127/172] - loss: 0.3958
Epoch 1 [128/172] - loss: 0.4404
Epoch 1 [129/172] - loss: 0.4978
Epoch 1 [130/172] - loss: 0.4007, acc: 0.8125
Epoch 1 [131/172] - loss: 0.2571
Epoch 1 [132/172] - loss: 0.4747
Epoch 1 [133/172] - loss: 0.5168
Epoch 1 [134/172] - loss: 0.3480
Epoch 1 [135/172] - loss: 0.4880
Epoch 1 [136/172] - loss: 0.3769
Epoch 1 [137/172] - loss: 0.5436
Epoch 1 [138/172] - loss: 0.4051
Epoch 1 [139/172] - loss: 0.2956
Epoch 1 [140/172] - loss: 0.4331, acc: 0.7188
Epoch 1 [141/172] - loss: 0.4772
Epoch 1 [142/172] - loss: 0.4490
Epoch 1 [143/172] - loss: 0.4308
Epoch 1 [144/172] - loss: 0.3279
Epoch 1 [145/172] - loss: 0.4068
Epoch 1 [146/172] - loss: 0.5017
Epoch 1 [147/172] - loss: 0.6353
Epoch 1 [148/172] - loss: 0.4119
Epoch 1 [149/172] - loss: 0.4460
Epoch 1 [150/172] - loss: 0.4446, acc: 0.7812
Epoch 1 [151/172] - loss: 0.5370
Epoch 1 [152/172] - loss: 0.3961
Epoch 1 [153/172] - loss: 0.3377
Epoch 1 [154/172] - loss: 0.4367
Epoch 1 [155/172] - loss: 0.3693
Epoch 1 [156/172] - loss: 0.5517
Epoch 1 [157/172] - loss: 0.5052
Epoch 1 [158/172] - loss: 0.3789
Epoch 1 [159/172] - loss: 0.6333
Epoch 1 [160/172] - loss: 0.3723, acc: 0.8438
Epoch 1 [161/172] - loss: 0.3671
Epoch 1 [162/172] - loss: 0.3108
Epoch 1 [163/172] - loss: 0.4087
Epoch 1 [164/172] - loss: 0.4247
Epoch 1 [165/172] - loss: 0.4462
Epoch 1 [166/172] - loss: 0.4268
Epoch 1 [167/172] - loss: 0.3238
Epoch 1 [168/172] - loss: 0.4309
Epoch 1 [169/172] - loss: 0.4755
Epoch 1 [170/172] - loss: 0.3559, acc: 0.7500
Epoch 1 [171/172] - loss: 0.2392
Epoch 1 [172/172] - loss: 0.4707

类别准确率:
positive: 0.6274 (293/467)
neutral: 0.4940 (41/83)
negative: 0.7480 (187/250)

Epoch 1/10
Train Loss: 0.4106, Train Acc: 0.7859
Val Loss: 0.8354, Val Acc: 0.6512
Epoch 2 [1/172] - loss: 0.2920, acc: 0.8750
Epoch 2 [2/172] - loss: 0.3048
Epoch 2 [3/172] - loss: 0.3093
Epoch 2 [4/172] - loss: 0.3319
Epoch 2 [5/172] - loss: 0.4248
Epoch 2 [6/172] - loss: 0.3348
Epoch 2 [7/172] - loss: 0.3194
Epoch 2 [8/172] - loss: 0.4040
Epoch 2 [9/172] - loss: 0.2874
Epoch 2 [10/172] - loss: 0.2647, acc: 0.9375
Epoch 2 [11/172] - loss: 0.2275
Epoch 2 [12/172] - loss: 0.2683
Epoch 2 [13/172] - loss: 0.4521
Epoch 2 [14/172] - loss: 0.2790
Epoch 2 [15/172] - loss: 0.3960
Epoch 2 [16/172] - loss: 0.2968
Epoch 2 [17/172] - loss: 0.3212
Epoch 2 [18/172] - loss: 0.3556
Epoch 2 [19/172] - loss: 0.3165
Epoch 2 [20/172] - loss: 0.3115, acc: 0.8438
Epoch 2 [21/172] - loss: 0.2928
Epoch 2 [22/172] - loss: 0.2696
Epoch 2 [23/172] - loss: 0.2070
Epoch 2 [24/172] - loss: 0.5064
Epoch 2 [25/172] - loss: 0.3006
Epoch 2 [26/172] - loss: 0.2242
Epoch 2 [27/172] - loss: 0.2698
Epoch 2 [28/172] - loss: 0.2685

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4849, log_difficulty=0.3954, weight=2.9768
neutral: count=1952.0, difficulty=0.3953, log_difficulty=0.3331, weight=2.6654
negative: count=2216.0, difficulty=0.4364, log_difficulty=0.3622, weight=2.8108

当前batch的pt分布：
positive: min=0.3036, max=0.9972, mean=0.7373
neutral: min=0.6491, max=0.9830, mean=0.8669
negative: min=0.0876, max=0.9929, mean=0.6486

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.8889
neutral 准确率: 1.0000
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.4129
焦点损失: 0.1686
边界损失: 0.2451
总损失: 0.3031
Epoch 2 [29/172] - loss: 0.3031
Epoch 2 [30/172] - loss: 0.3396, acc: 0.8750
Epoch 2 [31/172] - loss: 0.2643
Epoch 2 [32/172] - loss: 0.3626
Epoch 2 [33/172] - loss: 0.2487
Epoch 2 [34/172] - loss: 0.2526
Epoch 2 [35/172] - loss: 0.2096
Epoch 2 [36/172] - loss: 0.2917
Epoch 2 [37/172] - loss: 0.2511
Epoch 2 [38/172] - loss: 0.2572
Epoch 2 [39/172] - loss: 0.3742
Epoch 2 [40/172] - loss: 0.3734, acc: 0.7500
Epoch 2 [41/172] - loss: 0.2626
Epoch 2 [42/172] - loss: 0.2062
Epoch 2 [43/172] - loss: 0.1672
Epoch 2 [44/172] - loss: 0.4965
Epoch 2 [45/172] - loss: 0.2435
Epoch 2 [46/172] - loss: 0.2406
Epoch 2 [47/172] - loss: 0.3188
Epoch 2 [48/172] - loss: 0.3369
Epoch 2 [49/172] - loss: 0.2305
Epoch 2 [50/172] - loss: 0.3249, acc: 0.7812
Epoch 2 [51/172] - loss: 0.3805
Epoch 2 [52/172] - loss: 0.2566
Epoch 2 [53/172] - loss: 0.2457
Epoch 2 [54/172] - loss: 0.1978
Epoch 2 [55/172] - loss: 0.2631
Epoch 2 [56/172] - loss: 0.2818
Epoch 2 [57/172] - loss: 0.2264
Epoch 2 [58/172] - loss: 0.2395
Epoch 2 [59/172] - loss: 0.4073
Epoch 2 [60/172] - loss: 0.2642, acc: 0.8438
Epoch 2 [61/172] - loss: 0.2097
Epoch 2 [62/172] - loss: 0.1707
Epoch 2 [63/172] - loss: 0.2716
Epoch 2 [64/172] - loss: 0.2187
Epoch 2 [65/172] - loss: 0.2593
Epoch 2 [66/172] - loss: 0.2449
Epoch 2 [67/172] - loss: 0.2872
Epoch 2 [68/172] - loss: 0.3337
Epoch 2 [69/172] - loss: 0.2183
Epoch 2 [70/172] - loss: 0.2867, acc: 0.8125
Epoch 2 [71/172] - loss: 0.3385
Epoch 2 [72/172] - loss: 0.3157
Epoch 2 [73/172] - loss: 0.2624
Epoch 2 [74/172] - loss: 0.2473
Epoch 2 [75/172] - loss: 0.2188
Epoch 2 [76/172] - loss: 0.2503
Epoch 2 [77/172] - loss: 0.2618
Epoch 2 [78/172] - loss: 0.3591
Epoch 2 [79/172] - loss: 0.2574
Epoch 2 [80/172] - loss: 0.1961, acc: 0.9375
Epoch 2 [81/172] - loss: 0.2672
Epoch 2 [82/172] - loss: 0.1574
Epoch 2 [83/172] - loss: 0.1913
Epoch 2 [84/172] - loss: 0.2576
Epoch 2 [85/172] - loss: 0.2456
Epoch 2 [86/172] - loss: 0.2936
Epoch 2 [87/172] - loss: 0.4703
Epoch 2 [88/172] - loss: 0.2761
Epoch 2 [89/172] - loss: 0.2217
Epoch 2 [90/172] - loss: 0.2846, acc: 0.8438
Epoch 2 [91/172] - loss: 0.1999
Epoch 2 [92/172] - loss: 0.2875
Epoch 2 [93/172] - loss: 0.1993
Epoch 2 [94/172] - loss: 0.2009
Epoch 2 [95/172] - loss: 0.3901
Epoch 2 [96/172] - loss: 0.2024
Epoch 2 [97/172] - loss: 0.2330
Epoch 2 [98/172] - loss: 0.2512
Epoch 2 [99/172] - loss: 0.1741
Epoch 2 [100/172] - loss: 0.2262, acc: 0.9062
Epoch 2 [101/172] - loss: 0.1985
Epoch 2 [102/172] - loss: 0.1911
Epoch 2 [103/172] - loss: 0.2336
Epoch 2 [104/172] - loss: 0.2422
Epoch 2 [105/172] - loss: 0.1588
Epoch 2 [106/172] - loss: 0.2377
Epoch 2 [107/172] - loss: 0.2101
Epoch 2 [108/172] - loss: 0.3394
Epoch 2 [109/172] - loss: 0.2062
Epoch 2 [110/172] - loss: 0.2235, acc: 0.9062
Epoch 2 [111/172] - loss: 0.2344
Epoch 2 [112/172] - loss: 0.1721
Epoch 2 [113/172] - loss: 0.1616
Epoch 2 [114/172] - loss: 0.2209
Epoch 2 [115/172] - loss: 0.2329
Epoch 2 [116/172] - loss: 0.2125
Epoch 2 [117/172] - loss: 0.2621
Epoch 2 [118/172] - loss: 0.1683
Epoch 2 [119/172] - loss: 0.2578
Epoch 2 [120/172] - loss: 0.1979, acc: 0.9375
Epoch 2 [121/172] - loss: 0.1762
Epoch 2 [122/172] - loss: 0.3429
Epoch 2 [123/172] - loss: 0.2723
Epoch 2 [124/172] - loss: 0.3117
Epoch 2 [125/172] - loss: 0.1999
Epoch 2 [126/172] - loss: 0.2930
Epoch 2 [127/172] - loss: 0.2277
Epoch 2 [128/172] - loss: 0.2843

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4063, log_difficulty=0.3410, weight=2.7048
neutral: count=2949.0, difficulty=0.3026, log_difficulty=0.2643, weight=2.3217
negative: count=3294.0, difficulty=0.3658, log_difficulty=0.3117, weight=2.5587

当前batch的pt分布：
positive: min=0.2388, max=0.9955, mean=0.8243
neutral: min=0.5703, max=0.9981, mean=0.8774
negative: min=0.1885, max=0.9972, mean=0.7957

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.2538
焦点损失: 0.0865
边界损失: 0.2120
总损失: 0.2149
Epoch 2 [129/172] - loss: 0.2149
Epoch 2 [130/172] - loss: 0.2096, acc: 0.9062
Epoch 2 [131/172] - loss: 0.2599
Epoch 2 [132/172] - loss: 0.2639
Epoch 2 [133/172] - loss: 0.1939
Epoch 2 [134/172] - loss: 0.2010
Epoch 2 [135/172] - loss: 0.3634
Epoch 2 [136/172] - loss: 0.2007
Epoch 2 [137/172] - loss: 0.1575
Epoch 2 [138/172] - loss: 0.2380
Epoch 2 [139/172] - loss: 0.2421
Epoch 2 [140/172] - loss: 0.2415, acc: 0.9375
Epoch 2 [141/172] - loss: 0.2176
Epoch 2 [142/172] - loss: 0.2112
Epoch 2 [143/172] - loss: 0.2410
Epoch 2 [144/172] - loss: 0.1923
Epoch 2 [145/172] - loss: 0.4091
Epoch 2 [146/172] - loss: 0.1588
Epoch 2 [147/172] - loss: 0.2770
Epoch 2 [148/172] - loss: 0.2192
Epoch 2 [149/172] - loss: 0.1520
Epoch 2 [150/172] - loss: 0.3069, acc: 0.8125
Epoch 2 [151/172] - loss: 0.1698
Epoch 2 [152/172] - loss: 0.1792
Epoch 2 [153/172] - loss: 0.1833
Epoch 2 [154/172] - loss: 0.1708
Epoch 2 [155/172] - loss: 0.2322
Epoch 2 [156/172] - loss: 0.2371
Epoch 2 [157/172] - loss: 0.1646
Epoch 2 [158/172] - loss: 0.1943
Epoch 2 [159/172] - loss: 0.2902
Epoch 2 [160/172] - loss: 0.1860, acc: 0.9062
Epoch 2 [161/172] - loss: 0.1922
Epoch 2 [162/172] - loss: 0.2181
Epoch 2 [163/172] - loss: 0.2533
Epoch 2 [164/172] - loss: 0.2493
Epoch 2 [165/172] - loss: 0.3163
Epoch 2 [166/172] - loss: 0.2483
Epoch 2 [167/172] - loss: 0.4385
Epoch 2 [168/172] - loss: 0.1886
Epoch 2 [169/172] - loss: 0.1573
Epoch 2 [170/172] - loss: 0.1891, acc: 0.9062
Epoch 2 [171/172] - loss: 0.2994
Epoch 2 [172/172] - loss: 0.6106

类别准确率:
positive: 0.7580 (354/467)
neutral: 0.5904 (49/83)
negative: 0.5120 (128/250)

Epoch 2/10
Train Loss: 0.2623, Train Acc: 0.8929
Val Loss: 0.9233, Val Acc: 0.6637
Epoch 3 [1/172] - loss: 0.2081, acc: 0.9688
Epoch 3 [2/172] - loss: 0.1719
Epoch 3 [3/172] - loss: 0.1524
Epoch 3 [4/172] - loss: 0.1477
Epoch 3 [5/172] - loss: 0.2090
Epoch 3 [6/172] - loss: 0.1570
Epoch 3 [7/172] - loss: 0.1972
Epoch 3 [8/172] - loss: 0.1795
Epoch 3 [9/172] - loss: 0.1620
Epoch 3 [10/172] - loss: 0.1929, acc: 0.9375
Epoch 3 [11/172] - loss: 0.1420
Epoch 3 [12/172] - loss: 0.1454
Epoch 3 [13/172] - loss: 0.1535
Epoch 3 [14/172] - loss: 0.1289
Epoch 3 [15/172] - loss: 0.1596
Epoch 3 [16/172] - loss: 0.1956
Epoch 3 [17/172] - loss: 0.2185
Epoch 3 [18/172] - loss: 0.1832
Epoch 3 [19/172] - loss: 0.1509
Epoch 3 [20/172] - loss: 0.1395, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1448
Epoch 3 [22/172] - loss: 0.1787
Epoch 3 [23/172] - loss: 0.1391
Epoch 3 [24/172] - loss: 0.1712
Epoch 3 [25/172] - loss: 0.2010
Epoch 3 [26/172] - loss: 0.1489
Epoch 3 [27/172] - loss: 0.2538
Epoch 3 [28/172] - loss: 0.1570
Epoch 3 [29/172] - loss: 0.1685
Epoch 3 [30/172] - loss: 0.1440, acc: 1.0000
Epoch 3 [31/172] - loss: 0.1357
Epoch 3 [32/172] - loss: 0.1563
Epoch 3 [33/172] - loss: 0.1471
Epoch 3 [34/172] - loss: 0.1865
Epoch 3 [35/172] - loss: 0.2231
Epoch 3 [36/172] - loss: 0.1443
Epoch 3 [37/172] - loss: 0.1639
Epoch 3 [38/172] - loss: 0.1308
Epoch 3 [39/172] - loss: 0.1365
Epoch 3 [40/172] - loss: 0.1750, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1479
Epoch 3 [42/172] - loss: 0.1817
Epoch 3 [43/172] - loss: 0.1325
Epoch 3 [44/172] - loss: 0.1328
Epoch 3 [45/172] - loss: 0.1434
Epoch 3 [46/172] - loss: 0.1254
Epoch 3 [47/172] - loss: 0.1293
Epoch 3 [48/172] - loss: 0.1279
Epoch 3 [49/172] - loss: 0.1184
Epoch 3 [50/172] - loss: 0.1386, acc: 0.9688
Epoch 3 [51/172] - loss: 0.1734
Epoch 3 [52/172] - loss: 0.2011
Epoch 3 [53/172] - loss: 0.1336
Epoch 3 [54/172] - loss: 0.1381
Epoch 3 [55/172] - loss: 0.1325
Epoch 3 [56/172] - loss: 0.1869

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3435, log_difficulty=0.2953, weight=2.4764
neutral: count=3923.0, difficulty=0.2499, log_difficulty=0.2231, weight=2.1153
negative: count=4382.0, difficulty=0.3088, log_difficulty=0.2691, weight=2.3457

当前batch的pt分布：
positive: min=0.3791, max=0.9916, mean=0.9166
neutral: min=0.0279, max=0.9962, mean=0.8011
negative: min=0.9902, max=0.9992, mean=0.9960

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9091
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2487
焦点损失: 0.1427
边界损失: 0.1819
总损失: 0.2128
Epoch 3 [57/172] - loss: 0.2128
Epoch 3 [58/172] - loss: 0.1254
Epoch 3 [59/172] - loss: 0.1887
Epoch 3 [60/172] - loss: 0.1494, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1692
Epoch 3 [62/172] - loss: 0.1630
Epoch 3 [63/172] - loss: 0.1649
Epoch 3 [64/172] - loss: 0.2151
Epoch 3 [65/172] - loss: 0.1660
Epoch 3 [66/172] - loss: 0.1858
Epoch 3 [67/172] - loss: 0.1563
Epoch 3 [68/172] - loss: 0.1805
Epoch 3 [69/172] - loss: 0.2024
Epoch 3 [70/172] - loss: 0.1195, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1339
Epoch 3 [72/172] - loss: 0.1798
Epoch 3 [73/172] - loss: 0.1314
Epoch 3 [74/172] - loss: 0.2975
Epoch 3 [75/172] - loss: 0.1307
Epoch 3 [76/172] - loss: 0.1746
Epoch 3 [77/172] - loss: 0.1305
Epoch 3 [78/172] - loss: 0.1765
Epoch 3 [79/172] - loss: 0.1349
Epoch 3 [80/172] - loss: 0.2312, acc: 0.8750
Epoch 3 [81/172] - loss: 0.1380
Epoch 3 [82/172] - loss: 0.2032
Epoch 3 [83/172] - loss: 0.1862
Epoch 3 [84/172] - loss: 0.1340
Epoch 3 [85/172] - loss: 0.1351
Epoch 3 [86/172] - loss: 0.1225
Epoch 3 [87/172] - loss: 0.1528
Epoch 3 [88/172] - loss: 0.1214
Epoch 3 [89/172] - loss: 0.1365
Epoch 3 [90/172] - loss: 0.1559, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1598
Epoch 3 [92/172] - loss: 0.1472
Epoch 3 [93/172] - loss: 0.2057
Epoch 3 [94/172] - loss: 0.2518
Epoch 3 [95/172] - loss: 0.1278
Epoch 3 [96/172] - loss: 0.1638
Epoch 3 [97/172] - loss: 0.1388
Epoch 3 [98/172] - loss: 0.1345
Epoch 3 [99/172] - loss: 0.1344
Epoch 3 [100/172] - loss: 0.1897, acc: 0.9375
Epoch 3 [101/172] - loss: 0.1809
Epoch 3 [102/172] - loss: 0.1246
Epoch 3 [103/172] - loss: 0.2024
Epoch 3 [104/172] - loss: 0.1451
Epoch 3 [105/172] - loss: 0.1545
Epoch 3 [106/172] - loss: 0.1794
Epoch 3 [107/172] - loss: 0.1297
Epoch 3 [108/172] - loss: 0.1310
Epoch 3 [109/172] - loss: 0.1342
Epoch 3 [110/172] - loss: 0.1691, acc: 0.9688
Epoch 3 [111/172] - loss: 0.1807
Epoch 3 [112/172] - loss: 0.1417
Epoch 3 [113/172] - loss: 0.1139
Epoch 3 [114/172] - loss: 0.1416
Epoch 3 [115/172] - loss: 0.1753
Epoch 3 [116/172] - loss: 0.1582
Epoch 3 [117/172] - loss: 0.1546
Epoch 3 [118/172] - loss: 0.1678
Epoch 3 [119/172] - loss: 0.1248
Epoch 3 [120/172] - loss: 0.1807, acc: 0.9375
Epoch 3 [121/172] - loss: 0.1692
Epoch 3 [122/172] - loss: 0.2149
Epoch 3 [123/172] - loss: 0.1438
Epoch 3 [124/172] - loss: 0.1440
Epoch 3 [125/172] - loss: 0.1600
Epoch 3 [126/172] - loss: 0.2737
Epoch 3 [127/172] - loss: 0.1796
Epoch 3 [128/172] - loss: 0.1163
Epoch 3 [129/172] - loss: 0.1733
Epoch 3 [130/172] - loss: 0.1437, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1771
Epoch 3 [132/172] - loss: 0.1244
Epoch 3 [133/172] - loss: 0.1751
Epoch 3 [134/172] - loss: 0.1650
Epoch 3 [135/172] - loss: 0.1226
Epoch 3 [136/172] - loss: 0.2237
Epoch 3 [137/172] - loss: 0.1405
Epoch 3 [138/172] - loss: 0.2026
Epoch 3 [139/172] - loss: 0.1968
Epoch 3 [140/172] - loss: 0.1500, acc: 1.0000
Epoch 3 [141/172] - loss: 0.1708
Epoch 3 [142/172] - loss: 0.1675
Epoch 3 [143/172] - loss: 0.1449
Epoch 3 [144/172] - loss: 0.1912
Epoch 3 [145/172] - loss: 0.1336
Epoch 3 [146/172] - loss: 0.1854
Epoch 3 [147/172] - loss: 0.1864
Epoch 3 [148/172] - loss: 0.1799
Epoch 3 [149/172] - loss: 0.1761
Epoch 3 [150/172] - loss: 0.1981, acc: 0.9375
Epoch 3 [151/172] - loss: 0.2643
Epoch 3 [152/172] - loss: 0.1658
Epoch 3 [153/172] - loss: 0.1602
Epoch 3 [154/172] - loss: 0.1206
Epoch 3 [155/172] - loss: 0.1289
Epoch 3 [156/172] - loss: 0.1481

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2970, log_difficulty=0.2600, weight=2.3001
neutral: count=4903.0, difficulty=0.2119, log_difficulty=0.1922, weight=1.9611
negative: count=5500.0, difficulty=0.2682, log_difficulty=0.2376, weight=2.1881

当前batch的pt分布：
positive: min=0.7055, max=0.9971, mean=0.9493
neutral: min=0.9568, max=0.9956, mean=0.9799
negative: min=0.7620, max=0.9964, mean=0.9136

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0560
焦点损失: 0.0014
边界损失: 0.1635
总损失: 0.1235
Epoch 3 [157/172] - loss: 0.1235
Epoch 3 [158/172] - loss: 0.1577
Epoch 3 [159/172] - loss: 0.1445
Epoch 3 [160/172] - loss: 0.2103, acc: 0.8750
Epoch 3 [161/172] - loss: 0.2384
Epoch 3 [162/172] - loss: 0.1503
Epoch 3 [163/172] - loss: 0.1339
Epoch 3 [164/172] - loss: 0.1149
Epoch 3 [165/172] - loss: 0.1443
Epoch 3 [166/172] - loss: 0.1837
Epoch 3 [167/172] - loss: 0.1267
Epoch 3 [168/172] - loss: 0.1265
Epoch 3 [169/172] - loss: 0.1263
Epoch 3 [170/172] - loss: 0.1499, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1476
Epoch 3 [172/172] - loss: 0.1685

类别准确率:
positive: 0.9272 (433/467)
neutral: 0.2892 (24/83)
negative: 0.3840 (96/250)

Epoch 3/10
Train Loss: 0.1529, Train Acc: 0.9636
Val Loss: 1.0727, Val Acc: 0.6913
Epoch 4 [1/172] - loss: 0.1191, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1133
Epoch 4 [3/172] - loss: 0.1213
Epoch 4 [4/172] - loss: 0.1387
Epoch 4 [5/172] - loss: 0.1615
Epoch 4 [6/172] - loss: 0.1212
Epoch 4 [7/172] - loss: 0.1442
Epoch 4 [8/172] - loss: 0.1582
Epoch 4 [9/172] - loss: 0.1827
Epoch 4 [10/172] - loss: 0.1397, acc: 0.9688
Epoch 4 [11/172] - loss: 0.1137
Epoch 4 [12/172] - loss: 0.1180
Epoch 4 [13/172] - loss: 0.1496
Epoch 4 [14/172] - loss: 0.1890
Epoch 4 [15/172] - loss: 0.1228
Epoch 4 [16/172] - loss: 0.1299
Epoch 4 [17/172] - loss: 0.1171
Epoch 4 [18/172] - loss: 0.1270
Epoch 4 [19/172] - loss: 0.1218
Epoch 4 [20/172] - loss: 0.1386, acc: 0.9688
Epoch 4 [21/172] - loss: 0.1702
Epoch 4 [22/172] - loss: 0.1125
Epoch 4 [23/172] - loss: 0.1365
Epoch 4 [24/172] - loss: 0.1248
Epoch 4 [25/172] - loss: 0.1281
Epoch 4 [26/172] - loss: 0.3149
Epoch 4 [27/172] - loss: 0.1120
Epoch 4 [28/172] - loss: 0.1659
Epoch 4 [29/172] - loss: 0.1119
Epoch 4 [30/172] - loss: 0.1654, acc: 0.9688
Epoch 4 [31/172] - loss: 0.2015
Epoch 4 [32/172] - loss: 0.1236
Epoch 4 [33/172] - loss: 0.1465
Epoch 4 [34/172] - loss: 0.1139
Epoch 4 [35/172] - loss: 0.1418
Epoch 4 [36/172] - loss: 0.1199
Epoch 4 [37/172] - loss: 0.1146
Epoch 4 [38/172] - loss: 0.1373
Epoch 4 [39/172] - loss: 0.1938
Epoch 4 [40/172] - loss: 0.1793, acc: 0.9688
Epoch 4 [41/172] - loss: 0.1164
Epoch 4 [42/172] - loss: 0.1488
Epoch 4 [43/172] - loss: 0.1249
Epoch 4 [44/172] - loss: 0.1427
Epoch 4 [45/172] - loss: 0.1107
Epoch 4 [46/172] - loss: 0.1312
Epoch 4 [47/172] - loss: 0.1340
Epoch 4 [48/172] - loss: 0.1395
Epoch 4 [49/172] - loss: 0.1278
Epoch 4 [50/172] - loss: 0.2101, acc: 0.9375
Epoch 4 [51/172] - loss: 0.1130
Epoch 4 [52/172] - loss: 0.1969
Epoch 4 [53/172] - loss: 0.1136
Epoch 4 [54/172] - loss: 0.1434
Epoch 4 [55/172] - loss: 0.2134
Epoch 4 [56/172] - loss: 0.1239
Epoch 4 [57/172] - loss: 0.1142
Epoch 4 [58/172] - loss: 0.1093
Epoch 4 [59/172] - loss: 0.1267
Epoch 4 [60/172] - loss: 0.1126, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1419
Epoch 4 [62/172] - loss: 0.1545
Epoch 4 [63/172] - loss: 0.1498
Epoch 4 [64/172] - loss: 0.1128
Epoch 4 [65/172] - loss: 0.1300
Epoch 4 [66/172] - loss: 0.1267
Epoch 4 [67/172] - loss: 0.1184
Epoch 4 [68/172] - loss: 0.1124
Epoch 4 [69/172] - loss: 0.1672
Epoch 4 [70/172] - loss: 0.1282, acc: 0.9688
Epoch 4 [71/172] - loss: 0.1182
Epoch 4 [72/172] - loss: 0.1223
Epoch 4 [73/172] - loss: 0.1128
Epoch 4 [74/172] - loss: 0.1263
Epoch 4 [75/172] - loss: 0.1119
Epoch 4 [76/172] - loss: 0.1069
Epoch 4 [77/172] - loss: 0.1223
Epoch 4 [78/172] - loss: 0.1105
Epoch 4 [79/172] - loss: 0.1093
Epoch 4 [80/172] - loss: 0.1611, acc: 0.9375
Epoch 4 [81/172] - loss: 0.1430
Epoch 4 [82/172] - loss: 0.1125
Epoch 4 [83/172] - loss: 0.1126
Epoch 4 [84/172] - loss: 0.1150

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2591, log_difficulty=0.2304, weight=2.1520
neutral: count=5865.0, difficulty=0.1846, log_difficulty=0.1694, weight=1.8468
negative: count=6629.0, difficulty=0.2351, log_difficulty=0.2111, weight=2.0556

当前batch的pt分布：
positive: min=0.6111, max=0.9928, mean=0.9181
neutral: min=0.9743, max=0.9996, mean=0.9917
negative: min=0.7435, max=0.9985, mean=0.9633

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0595
焦点损失: 0.0029
边界损失: 0.1631
总损失: 0.1239
Epoch 4 [85/172] - loss: 0.1239
Epoch 4 [86/172] - loss: 0.1323
Epoch 4 [87/172] - loss: 0.1701
Epoch 4 [88/172] - loss: 0.1105
Epoch 4 [89/172] - loss: 0.1189
Epoch 4 [90/172] - loss: 0.1180, acc: 1.0000
Epoch 4 [91/172] - loss: 0.2054
Epoch 4 [92/172] - loss: 0.2088
Epoch 4 [93/172] - loss: 0.1071
Epoch 4 [94/172] - loss: 0.1182
Epoch 4 [95/172] - loss: 0.1395
Epoch 4 [96/172] - loss: 0.1171
Epoch 4 [97/172] - loss: 0.1227
Epoch 4 [98/172] - loss: 0.1553
Epoch 4 [99/172] - loss: 0.1279
Epoch 4 [100/172] - loss: 0.1258, acc: 0.9688
Epoch 4 [101/172] - loss: 0.1116
Epoch 4 [102/172] - loss: 0.1202
Epoch 4 [103/172] - loss: 0.1127
Epoch 4 [104/172] - loss: 0.1182
Epoch 4 [105/172] - loss: 0.1590
Epoch 4 [106/172] - loss: 0.1336
Epoch 4 [107/172] - loss: 0.1200
Epoch 4 [108/172] - loss: 0.1434
Epoch 4 [109/172] - loss: 0.1328
Epoch 4 [110/172] - loss: 0.1546, acc: 0.9375
Epoch 4 [111/172] - loss: 0.1122
Epoch 4 [112/172] - loss: 0.1168
Epoch 4 [113/172] - loss: 0.1264
Epoch 4 [114/172] - loss: 0.1146
Epoch 4 [115/172] - loss: 0.1189
Epoch 4 [116/172] - loss: 0.1497
Epoch 4 [117/172] - loss: 0.1106
Epoch 4 [118/172] - loss: 0.1270
Epoch 4 [119/172] - loss: 0.1119
Epoch 4 [120/172] - loss: 0.1163, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1239
Epoch 4 [122/172] - loss: 0.2204
Epoch 4 [123/172] - loss: 0.1129
Epoch 4 [124/172] - loss: 0.1126
Epoch 4 [125/172] - loss: 0.1195
Epoch 4 [126/172] - loss: 0.2223
Epoch 4 [127/172] - loss: 0.1193
Epoch 4 [128/172] - loss: 0.1149
Epoch 4 [129/172] - loss: 0.1147
Epoch 4 [130/172] - loss: 0.1163, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1300
Epoch 4 [132/172] - loss: 0.1085
Epoch 4 [133/172] - loss: 0.1297
Epoch 4 [134/172] - loss: 0.1101
Epoch 4 [135/172] - loss: 0.1400
Epoch 4 [136/172] - loss: 0.1479
Epoch 4 [137/172] - loss: 0.1107
Epoch 4 [138/172] - loss: 0.1149
Epoch 4 [139/172] - loss: 0.1115
Epoch 4 [140/172] - loss: 0.1486, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1291
Epoch 4 [142/172] - loss: 0.1180
Epoch 4 [143/172] - loss: 0.1123
Epoch 4 [144/172] - loss: 0.1167
Epoch 4 [145/172] - loss: 0.2796
Epoch 4 [146/172] - loss: 0.1480
Epoch 4 [147/172] - loss: 0.1268
Epoch 4 [148/172] - loss: 0.1644
Epoch 4 [149/172] - loss: 0.1160
Epoch 4 [150/172] - loss: 0.1236, acc: 1.0000
Epoch 4 [151/172] - loss: 0.1839
Epoch 4 [152/172] - loss: 0.1707
Epoch 4 [153/172] - loss: 0.1313
Epoch 4 [154/172] - loss: 0.1381
Epoch 4 [155/172] - loss: 0.1500
Epoch 4 [156/172] - loss: 0.1263
Epoch 4 [157/172] - loss: 0.1783
Epoch 4 [158/172] - loss: 0.1121
Epoch 4 [159/172] - loss: 0.1131
Epoch 4 [160/172] - loss: 0.1194, acc: 0.9688
Epoch 4 [161/172] - loss: 0.1416
Epoch 4 [162/172] - loss: 0.1471
Epoch 4 [163/172] - loss: 0.1719
Epoch 4 [164/172] - loss: 0.1225
Epoch 4 [165/172] - loss: 0.1629
Epoch 4 [166/172] - loss: 0.1237
Epoch 4 [167/172] - loss: 0.1814
Epoch 4 [168/172] - loss: 0.1237
Epoch 4 [169/172] - loss: 0.1900
Epoch 4 [170/172] - loss: 0.1608, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1469
Epoch 4 [172/172] - loss: 0.1166

类别准确率:
positive: 0.8373 (391/467)
neutral: 0.2651 (22/83)
negative: 0.6560 (164/250)

Epoch 4/10
Train Loss: 0.1445, Train Acc: 0.9677
Val Loss: 0.8376, Val Acc: 0.7212
Epoch 5 [1/172] - loss: 0.1116, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1526
Epoch 5 [3/172] - loss: 0.1098
Epoch 5 [4/172] - loss: 0.1233
Epoch 5 [5/172] - loss: 0.1121
Epoch 5 [6/172] - loss: 0.1257
Epoch 5 [7/172] - loss: 0.1234
Epoch 5 [8/172] - loss: 0.1564
Epoch 5 [9/172] - loss: 0.1441
Epoch 5 [10/172] - loss: 0.1154, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1384
Epoch 5 [12/172] - loss: 0.1148

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2308, log_difficulty=0.2076, weight=2.0382
neutral: count=6845.0, difficulty=0.1643, log_difficulty=0.1521, weight=1.7607
negative: count=7694.0, difficulty=0.2106, log_difficulty=0.1911, weight=1.9557

当前batch的pt分布：
positive: min=0.1127, max=0.9987, mean=0.8957
neutral: min=0.9787, max=0.9998, mean=0.9937
negative: min=0.9697, max=0.9942, mean=0.9844

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0943
焦点损失: 0.0533
边界损失: 0.1494
总损失: 0.1392
Epoch 5 [13/172] - loss: 0.1392
Epoch 5 [14/172] - loss: 0.2321
Epoch 5 [15/172] - loss: 0.1091
Epoch 5 [16/172] - loss: 0.1167
Epoch 5 [17/172] - loss: 0.1297
Epoch 5 [18/172] - loss: 0.1071
Epoch 5 [19/172] - loss: 0.1310
Epoch 5 [20/172] - loss: 0.1322, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1586
Epoch 5 [22/172] - loss: 0.1717
Epoch 5 [23/172] - loss: 0.1820
Epoch 5 [24/172] - loss: 0.1093
Epoch 5 [25/172] - loss: 0.1153
Epoch 5 [26/172] - loss: 0.1184
Epoch 5 [27/172] - loss: 0.1123
Epoch 5 [28/172] - loss: 0.1266
Epoch 5 [29/172] - loss: 0.1104
Epoch 5 [30/172] - loss: 0.1404, acc: 0.9688
Epoch 5 [31/172] - loss: 0.1230
Epoch 5 [32/172] - loss: 0.1305
Epoch 5 [33/172] - loss: 0.1877
Epoch 5 [34/172] - loss: 0.1420
Epoch 5 [35/172] - loss: 0.1080
Epoch 5 [36/172] - loss: 0.1073
Epoch 5 [37/172] - loss: 0.1161
Epoch 5 [38/172] - loss: 0.1099
Epoch 5 [39/172] - loss: 0.1605
Epoch 5 [40/172] - loss: 0.1216, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1132
Epoch 5 [42/172] - loss: 0.1154
Epoch 5 [43/172] - loss: 0.1706
Epoch 5 [44/172] - loss: 0.1144
Epoch 5 [45/172] - loss: 0.1108
Epoch 5 [46/172] - loss: 0.1269
Epoch 5 [47/172] - loss: 0.1072
Epoch 5 [48/172] - loss: 0.1199
Epoch 5 [49/172] - loss: 0.1088
Epoch 5 [50/172] - loss: 0.1237, acc: 0.9688
Epoch 5 [51/172] - loss: 0.1669
Epoch 5 [52/172] - loss: 0.1122
Epoch 5 [53/172] - loss: 0.1309
Epoch 5 [54/172] - loss: 0.1177
Epoch 5 [55/172] - loss: 0.1181
Epoch 5 [56/172] - loss: 0.1075
Epoch 5 [57/172] - loss: 0.1125
Epoch 5 [58/172] - loss: 0.1202
Epoch 5 [59/172] - loss: 0.1282
Epoch 5 [60/172] - loss: 0.1155, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1102
Epoch 5 [62/172] - loss: 0.1121
Epoch 5 [63/172] - loss: 0.1482
Epoch 5 [64/172] - loss: 0.1297
Epoch 5 [65/172] - loss: 0.1567
Epoch 5 [66/172] - loss: 0.1181
Epoch 5 [67/172] - loss: 0.1173
Epoch 5 [68/172] - loss: 0.1143
Epoch 5 [69/172] - loss: 0.1087
Epoch 5 [70/172] - loss: 0.1171, acc: 0.9688
Epoch 5 [71/172] - loss: 0.1329
Epoch 5 [72/172] - loss: 0.1107
Epoch 5 [73/172] - loss: 0.1098
Epoch 5 [74/172] - loss: 0.1458
Epoch 5 [75/172] - loss: 0.1080
Epoch 5 [76/172] - loss: 0.1135
Epoch 5 [77/172] - loss: 0.1147
Epoch 5 [78/172] - loss: 0.1276
Epoch 5 [79/172] - loss: 0.1096
Epoch 5 [80/172] - loss: 0.1134, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1264
Epoch 5 [82/172] - loss: 0.1272
Epoch 5 [83/172] - loss: 0.1132
Epoch 5 [84/172] - loss: 0.1110
Epoch 5 [85/172] - loss: 0.1490
Epoch 5 [86/172] - loss: 0.1103
Epoch 5 [87/172] - loss: 0.1205
Epoch 5 [88/172] - loss: 0.1278
Epoch 5 [89/172] - loss: 0.1165
Epoch 5 [90/172] - loss: 0.1397, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1090
Epoch 5 [92/172] - loss: 0.1662
Epoch 5 [93/172] - loss: 0.1096
Epoch 5 [94/172] - loss: 0.1085
Epoch 5 [95/172] - loss: 0.1137
Epoch 5 [96/172] - loss: 0.1423
Epoch 5 [97/172] - loss: 0.1235
Epoch 5 [98/172] - loss: 0.1141
Epoch 5 [99/172] - loss: 0.1656
Epoch 5 [100/172] - loss: 0.1197, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1098
Epoch 5 [102/172] - loss: 0.1125
Epoch 5 [103/172] - loss: 0.1183
Epoch 5 [104/172] - loss: 0.1674
Epoch 5 [105/172] - loss: 0.2058
Epoch 5 [106/172] - loss: 0.1085
Epoch 5 [107/172] - loss: 0.1279
Epoch 5 [108/172] - loss: 0.1753
Epoch 5 [109/172] - loss: 0.1077
Epoch 5 [110/172] - loss: 0.1110, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1103
Epoch 5 [112/172] - loss: 0.1139

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2071, log_difficulty=0.1882, weight=1.9410
neutral: count=7825.0, difficulty=0.1477, log_difficulty=0.1378, weight=1.6888
negative: count=8780.0, difficulty=0.1911, log_difficulty=0.1749, weight=1.8743

当前batch的pt分布：
positive: min=0.5921, max=0.9961, mean=0.9345
neutral: min=0.9018, max=0.9959, mean=0.9808
negative: min=0.9988, max=0.9998, mean=0.9993

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0441
焦点损失: 0.0028
边界损失: 0.1565
总损失: 0.1187
Epoch 5 [113/172] - loss: 0.1187
Epoch 5 [114/172] - loss: 0.1389
Epoch 5 [115/172] - loss: 0.1218
Epoch 5 [116/172] - loss: 0.1124
Epoch 5 [117/172] - loss: 0.1082
Epoch 5 [118/172] - loss: 0.1100
Epoch 5 [119/172] - loss: 0.1075
Epoch 5 [120/172] - loss: 0.1596, acc: 0.9688
Epoch 5 [121/172] - loss: 0.1111
Epoch 5 [122/172] - loss: 0.1134
Epoch 5 [123/172] - loss: 0.1609
Epoch 5 [124/172] - loss: 0.1082
Epoch 5 [125/172] - loss: 0.1103
Epoch 5 [126/172] - loss: 0.1075
Epoch 5 [127/172] - loss: 0.1173
Epoch 5 [128/172] - loss: 0.1104
Epoch 5 [129/172] - loss: 0.1659
Epoch 5 [130/172] - loss: 0.1063, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1172
Epoch 5 [132/172] - loss: 0.1824
Epoch 5 [133/172] - loss: 0.1803
Epoch 5 [134/172] - loss: 0.1928
Epoch 5 [135/172] - loss: 0.1056
Epoch 5 [136/172] - loss: 0.1470
Epoch 5 [137/172] - loss: 0.1187
Epoch 5 [138/172] - loss: 0.1385
Epoch 5 [139/172] - loss: 0.2164
Epoch 5 [140/172] - loss: 0.1712, acc: 0.9688
Epoch 5 [141/172] - loss: 0.1088
Epoch 5 [142/172] - loss: 0.1264
Epoch 5 [143/172] - loss: 0.1071
Epoch 5 [144/172] - loss: 0.1105
Epoch 5 [145/172] - loss: 0.1276
Epoch 5 [146/172] - loss: 0.1204
Epoch 5 [147/172] - loss: 0.1260
Epoch 5 [148/172] - loss: 0.1066
Epoch 5 [149/172] - loss: 0.1123
Epoch 5 [150/172] - loss: 0.1602, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1091
Epoch 5 [152/172] - loss: 0.1059
Epoch 5 [153/172] - loss: 0.1819
Epoch 5 [154/172] - loss: 0.1256
Epoch 5 [155/172] - loss: 0.1276
Epoch 5 [156/172] - loss: 0.1120
Epoch 5 [157/172] - loss: 0.1203
Epoch 5 [158/172] - loss: 0.1153
Epoch 5 [159/172] - loss: 0.1057
Epoch 5 [160/172] - loss: 0.1402, acc: 0.9688
Epoch 5 [161/172] - loss: 0.1079
Epoch 5 [162/172] - loss: 0.1503
Epoch 5 [163/172] - loss: 0.1559
Epoch 5 [164/172] - loss: 0.1114
Epoch 5 [165/172] - loss: 0.1885
Epoch 5 [166/172] - loss: 0.1126
Epoch 5 [167/172] - loss: 0.1279
Epoch 5 [168/172] - loss: 0.1080
Epoch 5 [169/172] - loss: 0.1278
Epoch 5 [170/172] - loss: 0.1138, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1190
Epoch 5 [172/172] - loss: 0.1309

类别准确率:
positive: 0.8779 (410/467)
neutral: 0.3133 (26/83)
negative: 0.5080 (127/250)

Epoch 5/10
Train Loss: 0.1272, Train Acc: 0.9859
Val Loss: 1.0079, Val Acc: 0.7037
Epoch 6 [1/172] - loss: 0.1238, acc: 1.0000
Epoch 6 [2/172] - loss: 0.1190
Epoch 6 [3/172] - loss: 0.1067
Epoch 6 [4/172] - loss: 0.1182
Epoch 6 [5/172] - loss: 0.1721
Epoch 6 [6/172] - loss: 0.1182
Epoch 6 [7/172] - loss: 0.1114
Epoch 6 [8/172] - loss: 0.1068
Epoch 6 [9/172] - loss: 0.1126
Epoch 6 [10/172] - loss: 0.1073, acc: 1.0000
Epoch 6 [11/172] - loss: 0.1073
Epoch 6 [12/172] - loss: 0.1171
Epoch 6 [13/172] - loss: 0.1137
Epoch 6 [14/172] - loss: 0.1096
Epoch 6 [15/172] - loss: 0.1096
Epoch 6 [16/172] - loss: 0.1777
Epoch 6 [17/172] - loss: 0.1110
Epoch 6 [18/172] - loss: 0.1097
Epoch 6 [19/172] - loss: 0.1074
Epoch 6 [20/172] - loss: 0.1097, acc: 1.0000
Epoch 6 [21/172] - loss: 0.1121
Epoch 6 [22/172] - loss: 0.1086
Epoch 6 [23/172] - loss: 0.1257
Epoch 6 [24/172] - loss: 0.1134
Epoch 6 [25/172] - loss: 0.1089
Epoch 6 [26/172] - loss: 0.1107
Epoch 6 [27/172] - loss: 0.1147
Epoch 6 [28/172] - loss: 0.1141
Epoch 6 [29/172] - loss: 0.1070
Epoch 6 [30/172] - loss: 0.1116, acc: 1.0000
Epoch 6 [31/172] - loss: 0.1096
Epoch 6 [32/172] - loss: 0.1217
Epoch 6 [33/172] - loss: 0.1075
Epoch 6 [34/172] - loss: 0.1085
Epoch 6 [35/172] - loss: 0.1078
Epoch 6 [36/172] - loss: 0.1109
Epoch 6 [37/172] - loss: 0.1108
Epoch 6 [38/172] - loss: 0.1086
Epoch 6 [39/172] - loss: 0.1167
Epoch 6 [40/172] - loss: 0.1256, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1885, log_difficulty=0.1727, weight=1.8635
neutral: count=8815.0, difficulty=0.1349, log_difficulty=0.1265, weight=1.6327
negative: count=9870.0, difficulty=0.1739, log_difficulty=0.1604, weight=1.8018

当前batch的pt分布：
positive: min=0.0713, max=0.9990, mean=0.9113
neutral: min=0.9659, max=0.9987, mean=0.9895
negative: min=0.9532, max=0.9990, mean=0.9825

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0934
焦点损失: 0.0711
边界损失: 0.1418
总损失: 0.1395
Epoch 6 [41/172] - loss: 0.1395
Epoch 6 [42/172] - loss: 0.1067
Epoch 6 [43/172] - loss: 0.1919
Epoch 6 [44/172] - loss: 0.1060
Epoch 6 [45/172] - loss: 0.1180
Epoch 6 [46/172] - loss: 0.1225
Epoch 6 [47/172] - loss: 0.1060
Epoch 6 [48/172] - loss: 0.1141
Epoch 6 [49/172] - loss: 0.1187
Epoch 6 [50/172] - loss: 0.1487, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1334
Epoch 6 [52/172] - loss: 0.1252
Epoch 6 [53/172] - loss: 0.1082
Epoch 6 [54/172] - loss: 0.1339
Epoch 6 [55/172] - loss: 0.1083
Epoch 6 [56/172] - loss: 0.1094
Epoch 6 [57/172] - loss: 0.1068
Epoch 6 [58/172] - loss: 0.1060
Epoch 6 [59/172] - loss: 0.1090
Epoch 6 [60/172] - loss: 0.1245, acc: 0.9688
Epoch 6 [61/172] - loss: 0.1082
Epoch 6 [62/172] - loss: 0.1063
Epoch 6 [63/172] - loss: 0.1236
Epoch 6 [64/172] - loss: 0.1806
Epoch 6 [65/172] - loss: 0.1072
Epoch 6 [66/172] - loss: 0.1075
Epoch 6 [67/172] - loss: 0.1046
Epoch 6 [68/172] - loss: 0.1652
Epoch 6 [69/172] - loss: 0.1147
Epoch 6 [70/172] - loss: 0.1053, acc: 1.0000
Epoch 6 [71/172] - loss: 0.1080
Epoch 6 [72/172] - loss: 0.1238
Epoch 6 [73/172] - loss: 0.1362
Epoch 6 [74/172] - loss: 0.1100
Epoch 6 [75/172] - loss: 0.1146
Epoch 6 [76/172] - loss: 0.1077
Epoch 6 [77/172] - loss: 0.1173
Epoch 6 [78/172] - loss: 0.1129
Epoch 6 [79/172] - loss: 0.1197
Epoch 6 [80/172] - loss: 0.1540, acc: 0.9688
Epoch 6 [81/172] - loss: 0.1143
Epoch 6 [82/172] - loss: 0.1213
Epoch 6 [83/172] - loss: 0.1091
Epoch 6 [84/172] - loss: 0.1109
Epoch 6 [85/172] - loss: 0.1296
Epoch 6 [86/172] - loss: 0.1198
Epoch 6 [87/172] - loss: 0.1206
Epoch 6 [88/172] - loss: 0.1228
Epoch 6 [89/172] - loss: 0.1062
Epoch 6 [90/172] - loss: 0.1058, acc: 1.0000
Epoch 6 [91/172] - loss: 0.1055
Epoch 6 [92/172] - loss: 0.1057
Epoch 6 [93/172] - loss: 0.1129
Epoch 6 [94/172] - loss: 0.1065
Epoch 6 [95/172] - loss: 0.1194
Epoch 6 [96/172] - loss: 0.1047
Epoch 6 [97/172] - loss: 0.1080
Epoch 6 [98/172] - loss: 0.1319
Epoch 6 [99/172] - loss: 0.1135
Epoch 6 [100/172] - loss: 0.1107, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1254
Epoch 6 [102/172] - loss: 0.1061
Epoch 6 [103/172] - loss: 0.1137
Epoch 6 [104/172] - loss: 0.1274
Epoch 6 [105/172] - loss: 0.1068
Epoch 6 [106/172] - loss: 0.1162
Epoch 6 [107/172] - loss: 0.1072
Epoch 6 [108/172] - loss: 0.1066
Epoch 6 [109/172] - loss: 0.1573
Epoch 6 [110/172] - loss: 0.1178, acc: 0.9688
Epoch 6 [111/172] - loss: 0.1073
Epoch 6 [112/172] - loss: 0.1063
Epoch 6 [113/172] - loss: 0.1126
Epoch 6 [114/172] - loss: 0.1055
Epoch 6 [115/172] - loss: 0.1475
Epoch 6 [116/172] - loss: 0.2100
Epoch 6 [117/172] - loss: 0.1074
Epoch 6 [118/172] - loss: 0.1062
Epoch 6 [119/172] - loss: 0.1867
Epoch 6 [120/172] - loss: 0.1747, acc: 0.9375
Epoch 6 [121/172] - loss: 0.1161
Epoch 6 [122/172] - loss: 0.1132
Epoch 6 [123/172] - loss: 0.1085
Epoch 6 [124/172] - loss: 0.1131
Epoch 6 [125/172] - loss: 0.1116
Epoch 6 [126/172] - loss: 0.1698
Epoch 6 [127/172] - loss: 0.1523
Epoch 6 [128/172] - loss: 0.1181
Epoch 6 [129/172] - loss: 0.1087
Epoch 6 [130/172] - loss: 0.1498, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1283
Epoch 6 [132/172] - loss: 0.1588
Epoch 6 [133/172] - loss: 0.1106
Epoch 6 [134/172] - loss: 0.1093
Epoch 6 [135/172] - loss: 0.1098
Epoch 6 [136/172] - loss: 0.1348
Epoch 6 [137/172] - loss: 0.1183
Epoch 6 [138/172] - loss: 0.1118
Epoch 6 [139/172] - loss: 0.1163
Epoch 6 [140/172] - loss: 0.1136, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1730, log_difficulty=0.1596, weight=1.7980
neutral: count=9796.0, difficulty=0.1242, log_difficulty=0.1170, weight=1.5852
negative: count=10972.0, difficulty=0.1600, log_difficulty=0.1484, weight=1.7419

当前batch的pt分布：
positive: min=0.9609, max=0.9999, mean=0.9901
neutral: min=0.9854, max=0.9992, mean=0.9924
negative: min=0.9720, max=0.9951, mean=0.9829

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0122
焦点损失: 0.0000
边界损失: 0.1409
总损失: 0.1057
Epoch 6 [141/172] - loss: 0.1057
Epoch 6 [142/172] - loss: 0.1297
Epoch 6 [143/172] - loss: 0.1327
Epoch 6 [144/172] - loss: 0.1151
Epoch 6 [145/172] - loss: 0.1077
Epoch 6 [146/172] - loss: 0.1175
Epoch 6 [147/172] - loss: 0.1141
Epoch 6 [148/172] - loss: 0.1149
Epoch 6 [149/172] - loss: 0.1089
Epoch 6 [150/172] - loss: 0.1053, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1064
Epoch 6 [152/172] - loss: 0.1287
Epoch 6 [153/172] - loss: 0.1064
Epoch 6 [154/172] - loss: 0.1068
Epoch 6 [155/172] - loss: 0.1251
Epoch 6 [156/172] - loss: 0.1173
Epoch 6 [157/172] - loss: 0.1068
Epoch 6 [158/172] - loss: 0.1186
Epoch 6 [159/172] - loss: 0.1089
Epoch 6 [160/172] - loss: 0.1218, acc: 0.9688
Epoch 6 [161/172] - loss: 0.1083
Epoch 6 [162/172] - loss: 0.1124
Epoch 6 [163/172] - loss: 0.1144
Epoch 6 [164/172] - loss: 0.1297
Epoch 6 [165/172] - loss: 0.2433
Epoch 6 [166/172] - loss: 0.1114
Epoch 6 [167/172] - loss: 0.1090
Epoch 6 [168/172] - loss: 0.1095
Epoch 6 [169/172] - loss: 0.1238
Epoch 6 [170/172] - loss: 0.1062, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1078
Epoch 6 [172/172] - loss: 0.1133

类别准确率:
positive: 0.7602 (355/467)
neutral: 0.2771 (23/83)
negative: 0.7200 (180/250)

Epoch 6/10
Train Loss: 0.1216, Train Acc: 0.9899
Val Loss: 1.1284, Val Acc: 0.6975
Epoch 7 [1/172] - loss: 0.1072, acc: 1.0000
Epoch 7 [2/172] - loss: 0.1082
Epoch 7 [3/172] - loss: 0.1071
Epoch 7 [4/172] - loss: 0.1093
Epoch 7 [5/172] - loss: 0.1401
Epoch 7 [6/172] - loss: 0.1080
Epoch 7 [7/172] - loss: 0.1055
Epoch 7 [8/172] - loss: 0.1428
Epoch 7 [9/172] - loss: 0.1058
Epoch 7 [10/172] - loss: 0.1051, acc: 1.0000
Epoch 7 [11/172] - loss: 0.1204
Epoch 7 [12/172] - loss: 0.1358
Epoch 7 [13/172] - loss: 0.1083
Epoch 7 [14/172] - loss: 0.1086
Epoch 7 [15/172] - loss: 0.1274
Epoch 7 [16/172] - loss: 0.1206
Epoch 7 [17/172] - loss: 0.1137
Epoch 7 [18/172] - loss: 0.1067
Epoch 7 [19/172] - loss: 0.1075
Epoch 7 [20/172] - loss: 0.1057, acc: 1.0000
Epoch 7 [21/172] - loss: 0.1163
Epoch 7 [22/172] - loss: 0.1084
Epoch 7 [23/172] - loss: 0.1066
Epoch 7 [24/172] - loss: 0.1065
Epoch 7 [25/172] - loss: 0.1192
Epoch 7 [26/172] - loss: 0.1185
Epoch 7 [27/172] - loss: 0.1074
Epoch 7 [28/172] - loss: 0.1192
Epoch 7 [29/172] - loss: 0.1102
Epoch 7 [30/172] - loss: 0.1545, acc: 0.9688
Epoch 7 [31/172] - loss: 0.1066
Epoch 7 [32/172] - loss: 0.1059
Epoch 7 [33/172] - loss: 0.1076
Epoch 7 [34/172] - loss: 0.1166
Epoch 7 [35/172] - loss: 0.1112
Epoch 7 [36/172] - loss: 0.1504
Epoch 7 [37/172] - loss: 0.1081
Epoch 7 [38/172] - loss: 0.1061
Epoch 7 [39/172] - loss: 0.1067
Epoch 7 [40/172] - loss: 0.1051, acc: 1.0000
Epoch 7 [41/172] - loss: 0.1061
Epoch 7 [42/172] - loss: 0.1121
Epoch 7 [43/172] - loss: 0.1060
Epoch 7 [44/172] - loss: 0.1299
Epoch 7 [45/172] - loss: 0.1070
Epoch 7 [46/172] - loss: 0.1161
Epoch 7 [47/172] - loss: 0.1292
Epoch 7 [48/172] - loss: 0.1057
Epoch 7 [49/172] - loss: 0.1043
Epoch 7 [50/172] - loss: 0.1049, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1347
Epoch 7 [52/172] - loss: 0.1081
Epoch 7 [53/172] - loss: 0.1046
Epoch 7 [54/172] - loss: 0.1057
Epoch 7 [55/172] - loss: 0.1082
Epoch 7 [56/172] - loss: 0.1091
Epoch 7 [57/172] - loss: 0.1501
Epoch 7 [58/172] - loss: 0.1091
Epoch 7 [59/172] - loss: 0.1348
Epoch 7 [60/172] - loss: 0.1234, acc: 0.9688
Epoch 7 [61/172] - loss: 0.1130
Epoch 7 [62/172] - loss: 0.1124
Epoch 7 [63/172] - loss: 0.2026
Epoch 7 [64/172] - loss: 0.1118
Epoch 7 [65/172] - loss: 0.1097
Epoch 7 [66/172] - loss: 0.1123
Epoch 7 [67/172] - loss: 0.1091
Epoch 7 [68/172] - loss: 0.1231

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1598, log_difficulty=0.1482, weight=1.7412
neutral: count=10756.0, difficulty=0.1152, log_difficulty=0.1091, weight=1.5454
negative: count=12072.0, difficulty=0.1483, log_difficulty=0.1382, weight=1.6912

当前batch的pt分布：
positive: min=0.9895, max=0.9991, mean=0.9957
neutral: min=0.9900, max=0.9994, mean=0.9966
negative: min=0.8810, max=0.9935, mean=0.9736

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0141
焦点损失: 0.0001
边界损失: 0.1416
总损失: 0.1062
Epoch 7 [69/172] - loss: 0.1062
Epoch 7 [70/172] - loss: 0.1169, acc: 0.9688
Epoch 7 [71/172] - loss: 0.1110
Epoch 7 [72/172] - loss: 0.1166
Epoch 7 [73/172] - loss: 0.1090
Epoch 7 [74/172] - loss: 0.1072
Epoch 7 [75/172] - loss: 0.1255
Epoch 7 [76/172] - loss: 0.1064
Epoch 7 [77/172] - loss: 0.1082
Epoch 7 [78/172] - loss: 0.1047
Epoch 7 [79/172] - loss: 0.1186
Epoch 7 [80/172] - loss: 0.1075, acc: 1.0000
Epoch 7 [81/172] - loss: 0.1049
Epoch 7 [82/172] - loss: 0.1072
Epoch 7 [83/172] - loss: 0.1226
Epoch 7 [84/172] - loss: 0.1058
Epoch 7 [85/172] - loss: 0.1077
Epoch 7 [86/172] - loss: 0.1075
Epoch 7 [87/172] - loss: 0.1381
Epoch 7 [88/172] - loss: 0.1057
Epoch 7 [89/172] - loss: 0.1054
Epoch 7 [90/172] - loss: 0.1061, acc: 1.0000
Epoch 7 [91/172] - loss: 0.1060
Epoch 7 [92/172] - loss: 0.1063
Epoch 7 [93/172] - loss: 0.1480
Epoch 7 [94/172] - loss: 0.1058
Epoch 7 [95/172] - loss: 0.1105
Epoch 7 [96/172] - loss: 0.1066
Epoch 7 [97/172] - loss: 0.1089
Epoch 7 [98/172] - loss: 0.1375
Epoch 7 [99/172] - loss: 0.1063
Epoch 7 [100/172] - loss: 0.1051, acc: 1.0000
Epoch 7 [101/172] - loss: 0.1051
Epoch 7 [102/172] - loss: 0.1086
Epoch 7 [103/172] - loss: 0.1045
Epoch 7 [104/172] - loss: 0.1082
Epoch 7 [105/172] - loss: 0.1170
Epoch 7 [106/172] - loss: 0.1152
Epoch 7 [107/172] - loss: 0.1059
Epoch 7 [108/172] - loss: 0.1069
Epoch 7 [109/172] - loss: 0.1666
Epoch 7 [110/172] - loss: 0.1314, acc: 0.9688
Epoch 7 [111/172] - loss: 0.1136
Epoch 7 [112/172] - loss: 0.1102
Epoch 7 [113/172] - loss: 0.1049
Epoch 7 [114/172] - loss: 0.1051
Epoch 7 [115/172] - loss: 0.1069
Epoch 7 [116/172] - loss: 0.1126
Epoch 7 [117/172] - loss: 0.1083
Epoch 7 [118/172] - loss: 0.1063
Epoch 7 [119/172] - loss: 0.1072
Epoch 7 [120/172] - loss: 0.1078, acc: 1.0000
Epoch 7 [121/172] - loss: 0.1184
Epoch 7 [122/172] - loss: 0.1059
Epoch 7 [123/172] - loss: 0.1056
Epoch 7 [124/172] - loss: 0.1115
Epoch 7 [125/172] - loss: 0.1046
Epoch 7 [126/172] - loss: 0.1048
Epoch 7 [127/172] - loss: 0.1092
Epoch 7 [128/172] - loss: 0.1062
Epoch 7 [129/172] - loss: 0.1069
Epoch 7 [130/172] - loss: 0.1076, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1239
Epoch 7 [132/172] - loss: 0.1744
Epoch 7 [133/172] - loss: 0.1051
Epoch 7 [134/172] - loss: 0.1116
Epoch 7 [135/172] - loss: 0.1089
Epoch 7 [136/172] - loss: 0.1059
Epoch 7 [137/172] - loss: 0.1107
Epoch 7 [138/172] - loss: 0.1044
Epoch 7 [139/172] - loss: 0.1242
Epoch 7 [140/172] - loss: 0.1062, acc: 1.0000
Epoch 7 [141/172] - loss: 0.1665
Epoch 7 [142/172] - loss: 0.1094
Epoch 7 [143/172] - loss: 0.1120
Epoch 7 [144/172] - loss: 0.1059
Epoch 7 [145/172] - loss: 0.1098
Epoch 7 [146/172] - loss: 0.1226
Epoch 7 [147/172] - loss: 0.1261
Epoch 7 [148/172] - loss: 0.1130
Epoch 7 [149/172] - loss: 0.1081
Epoch 7 [150/172] - loss: 0.1158, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1356
Epoch 7 [152/172] - loss: 0.1057
Epoch 7 [153/172] - loss: 0.1047
Epoch 7 [154/172] - loss: 0.1464
Epoch 7 [155/172] - loss: 0.1053
Epoch 7 [156/172] - loss: 0.1280
Epoch 7 [157/172] - loss: 0.1089
Epoch 7 [158/172] - loss: 0.1073
Epoch 7 [159/172] - loss: 0.1053
Epoch 7 [160/172] - loss: 0.1052, acc: 1.0000
Epoch 7 [161/172] - loss: 0.1084
Epoch 7 [162/172] - loss: 0.1057
Epoch 7 [163/172] - loss: 0.1076
Epoch 7 [164/172] - loss: 0.1178
Epoch 7 [165/172] - loss: 0.1267
Epoch 7 [166/172] - loss: 0.1058
Epoch 7 [167/172] - loss: 0.1201
Epoch 7 [168/172] - loss: 0.1091

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1484, log_difficulty=0.1384, weight=1.6918
neutral: count=11731.0, difficulty=0.1077, log_difficulty=0.1023, weight=1.5114
negative: count=13173.0, difficulty=0.1378, log_difficulty=0.1291, weight=1.6455

当前batch的pt分布：
positive: min=0.9718, max=0.9990, mean=0.9912
neutral: min=0.9884, max=0.9987, mean=0.9953
negative: min=0.9589, max=0.9974, mean=0.9868

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0093
焦点损失: 0.0000
边界损失: 0.1395
总损失: 0.1046
Epoch 7 [169/172] - loss: 0.1046
Epoch 7 [170/172] - loss: 0.1312, acc: 0.9688
Epoch 7 [171/172] - loss: 0.1047
Epoch 7 [172/172] - loss: 0.1044

类别准确率:
positive: 0.8158 (381/467)
neutral: 0.2771 (23/83)
negative: 0.6400 (160/250)

Epoch 7/10
Train Loss: 0.1108, Train Acc: 0.9960
Val Loss: 1.1226, Val Acc: 0.7050
Early stopping triggered!
Best validation accuracy: 0.7212

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_064359-96fp8hkp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.3_Multimodal_iterations_20250118_064358
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/96fp8hkp
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇██
wandb:  train_acc ▁▁▃▅▆▆▇▆▆▇▇█▇█▇███████████████▇█████████
wandb: train_loss █▇▅▇▄▃▄▂▂▂▁▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 0.96875
wandb: train_loss 0.13115
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.3_Multimodal_iterations_20250118_064358 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/96fp8hkp
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_064359-96fp8hkp/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_065421-a0w6gb49
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.3_Multimodal_epochs_20250118_065421
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/a0w6gb49
wandb: uploading history steps 0-0, summary; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▅▇▇███
wandb: train_loss █▅▂▂▁▁▁
wandb:    val_acc ▁▂▅█▆▆▆
wandb:   val_loss ▁▃▇▁▅██
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.99596
wandb: train_loss 0.1108
wandb:    val_acc 0.705
wandb:   val_loss 1.12265
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.3_Multimodal_epochs_20250118_065421 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/a0w6gb49
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_065421-a0w6gb49/logs

