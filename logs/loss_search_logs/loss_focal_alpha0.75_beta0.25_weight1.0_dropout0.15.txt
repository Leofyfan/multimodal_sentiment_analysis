=== 命令 ===
python main.py --loss_type focal --alpha 0.75 --beta 0.25 --neural_init_weight 1.0 --dropout 0.15 --name loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.15 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.15
text_dim: 128
image_dim: 256
dropout: 0.15
loss_type: focal
alpha: 0.75
beta: 0.25
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6906, log_difficulty=0.5251, weight=3.6253
neutral: count=7.0, difficulty=0.6779, log_difficulty=0.5175, weight=3.5877
negative: count=13.0, difficulty=0.6521, log_difficulty=0.5020, weight=3.5101

当前batch的pt分布：
positive: min=0.1995, max=0.4353, mean=0.3094
neutral: min=0.1717, max=0.4271, mean=0.3221
negative: min=0.1774, max=0.6364, mean=0.3479

当前batch准确率：
整体准确率: 0.3125
positive 准确率: 0.2500
neutral 准确率: 0.4286
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1565
焦点损失: 0.4006
边界损失: 0.8033
总损失: 1.2743
Epoch 1 [1/172] - loss: 1.2743, acc: 0.3125
Epoch 1 [2/172] - loss: 1.1656
Epoch 1 [3/172] - loss: 1.1867
Epoch 1 [4/172] - loss: 1.2622
Epoch 1 [5/172] - loss: 1.2181
Epoch 1 [6/172] - loss: 1.2679
Epoch 1 [7/172] - loss: 1.2714
Epoch 1 [8/172] - loss: 1.2377
Epoch 1 [9/172] - loss: 1.0321
Epoch 1 [10/172] - loss: 1.0956, acc: 0.4375
Epoch 1 [11/172] - loss: 1.1597
Epoch 1 [12/172] - loss: 0.9200
Epoch 1 [13/172] - loss: 1.1263
Epoch 1 [14/172] - loss: 1.2881
Epoch 1 [15/172] - loss: 1.1077
Epoch 1 [16/172] - loss: 1.3164
Epoch 1 [17/172] - loss: 1.2611
Epoch 1 [18/172] - loss: 1.1224
Epoch 1 [19/172] - loss: 0.9969
Epoch 1 [20/172] - loss: 1.1137, acc: 0.4375
Epoch 1 [21/172] - loss: 1.0497
Epoch 1 [22/172] - loss: 1.0098
Epoch 1 [23/172] - loss: 1.1924
Epoch 1 [24/172] - loss: 1.1431
Epoch 1 [25/172] - loss: 0.9864
Epoch 1 [26/172] - loss: 0.9355
Epoch 1 [27/172] - loss: 1.0425
Epoch 1 [28/172] - loss: 0.9328
Epoch 1 [29/172] - loss: 0.9359
Epoch 1 [30/172] - loss: 0.8598, acc: 0.5000
Epoch 1 [31/172] - loss: 1.1292
Epoch 1 [32/172] - loss: 0.8379
Epoch 1 [33/172] - loss: 0.7684
Epoch 1 [34/172] - loss: 1.0089
Epoch 1 [35/172] - loss: 1.0250
Epoch 1 [36/172] - loss: 0.7163
Epoch 1 [37/172] - loss: 0.9499
Epoch 1 [38/172] - loss: 1.2349
Epoch 1 [39/172] - loss: 0.5316
Epoch 1 [40/172] - loss: 0.8292, acc: 0.5625
Epoch 1 [41/172] - loss: 0.9462
Epoch 1 [42/172] - loss: 0.8138
Epoch 1 [43/172] - loss: 1.1507
Epoch 1 [44/172] - loss: 1.0826
Epoch 1 [45/172] - loss: 0.9920
Epoch 1 [46/172] - loss: 0.8115
Epoch 1 [47/172] - loss: 0.9797
Epoch 1 [48/172] - loss: 0.9529
Epoch 1 [49/172] - loss: 0.8783
Epoch 1 [50/172] - loss: 0.7864, acc: 0.6562
Epoch 1 [51/172] - loss: 1.0162
Epoch 1 [52/172] - loss: 0.9490
Epoch 1 [53/172] - loss: 0.8855
Epoch 1 [54/172] - loss: 1.0550
Epoch 1 [55/172] - loss: 0.6153
Epoch 1 [56/172] - loss: 0.7576
Epoch 1 [57/172] - loss: 0.9154
Epoch 1 [58/172] - loss: 0.5804
Epoch 1 [59/172] - loss: 0.9273
Epoch 1 [60/172] - loss: 0.4675, acc: 0.8438
Epoch 1 [61/172] - loss: 0.7596
Epoch 1 [62/172] - loss: 0.7894
Epoch 1 [63/172] - loss: 1.2054
Epoch 1 [64/172] - loss: 0.7325
Epoch 1 [65/172] - loss: 1.0305
Epoch 1 [66/172] - loss: 0.7728
Epoch 1 [67/172] - loss: 0.7906
Epoch 1 [68/172] - loss: 0.9949
Epoch 1 [69/172] - loss: 0.9748
Epoch 1 [70/172] - loss: 0.7920, acc: 0.7500
Epoch 1 [71/172] - loss: 0.6776
Epoch 1 [72/172] - loss: 0.8511
Epoch 1 [73/172] - loss: 0.7326
Epoch 1 [74/172] - loss: 0.8368
Epoch 1 [75/172] - loss: 0.5568
Epoch 1 [76/172] - loss: 0.5823
Epoch 1 [77/172] - loss: 0.6535
Epoch 1 [78/172] - loss: 0.6200
Epoch 1 [79/172] - loss: 0.8038
Epoch 1 [80/172] - loss: 0.4607, acc: 0.8125
Epoch 1 [81/172] - loss: 0.7071
Epoch 1 [82/172] - loss: 1.3810
Epoch 1 [83/172] - loss: 0.6805
Epoch 1 [84/172] - loss: 0.5874
Epoch 1 [85/172] - loss: 0.8960
Epoch 1 [86/172] - loss: 0.8178
Epoch 1 [87/172] - loss: 0.6918
Epoch 1 [88/172] - loss: 0.6919
Epoch 1 [89/172] - loss: 1.0388
Epoch 1 [90/172] - loss: 0.6841, acc: 0.6562
Epoch 1 [91/172] - loss: 0.4718
Epoch 1 [92/172] - loss: 0.6069
Epoch 1 [93/172] - loss: 0.4564
Epoch 1 [94/172] - loss: 0.5625
Epoch 1 [95/172] - loss: 0.6723
Epoch 1 [96/172] - loss: 0.5102
Epoch 1 [97/172] - loss: 0.6106
Epoch 1 [98/172] - loss: 0.4410
Epoch 1 [99/172] - loss: 0.7246
Epoch 1 [100/172] - loss: 0.7288, acc: 0.6875

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5664, log_difficulty=0.4488, weight=3.2439
neutral: count=983.0, difficulty=0.5583, log_difficulty=0.4436, weight=3.2179
negative: count=1119.0, difficulty=0.5573, log_difficulty=0.4430, weight=3.2148

当前batch的pt分布：
positive: min=0.0868, max=0.7920, mean=0.4370
neutral: min=0.5031, max=0.9170, mean=0.6876
negative: min=0.0507, max=0.7329, mean=0.3897

当前batch准确率：
整体准确率: 0.5312
positive 准确率: 0.5000
neutral 准确率: 1.0000
negative 准确率: 0.4375

损失分量：
基础交叉熵: 0.9840
焦点损失: 0.4166
边界损失: 0.5179
总损失: 1.1381
Epoch 1 [101/172] - loss: 1.1381
Epoch 1 [102/172] - loss: 0.5459
Epoch 1 [103/172] - loss: 0.5991
Epoch 1 [104/172] - loss: 0.4474
Epoch 1 [105/172] - loss: 0.8280
Epoch 1 [106/172] - loss: 0.8471
Epoch 1 [107/172] - loss: 0.5952
Epoch 1 [108/172] - loss: 0.6533
Epoch 1 [109/172] - loss: 0.4756
Epoch 1 [110/172] - loss: 0.5629, acc: 0.7188
Epoch 1 [111/172] - loss: 0.6294
Epoch 1 [112/172] - loss: 0.6887
Epoch 1 [113/172] - loss: 0.4753
Epoch 1 [114/172] - loss: 0.6636
Epoch 1 [115/172] - loss: 0.6660
Epoch 1 [116/172] - loss: 0.5184
Epoch 1 [117/172] - loss: 0.6540
Epoch 1 [118/172] - loss: 0.6167
Epoch 1 [119/172] - loss: 0.5706
Epoch 1 [120/172] - loss: 0.3378, acc: 0.8750
Epoch 1 [121/172] - loss: 0.4498
Epoch 1 [122/172] - loss: 0.5530
Epoch 1 [123/172] - loss: 0.4733
Epoch 1 [124/172] - loss: 0.3439
Epoch 1 [125/172] - loss: 0.5998
Epoch 1 [126/172] - loss: 0.8300
Epoch 1 [127/172] - loss: 0.4128
Epoch 1 [128/172] - loss: 0.5262
Epoch 1 [129/172] - loss: 0.5777
Epoch 1 [130/172] - loss: 0.2946, acc: 0.8750
Epoch 1 [131/172] - loss: 0.2705
Epoch 1 [132/172] - loss: 0.8081
Epoch 1 [133/172] - loss: 0.6443
Epoch 1 [134/172] - loss: 0.2945
Epoch 1 [135/172] - loss: 0.5874
Epoch 1 [136/172] - loss: 0.8575
Epoch 1 [137/172] - loss: 0.7630
Epoch 1 [138/172] - loss: 0.5426
Epoch 1 [139/172] - loss: 0.7228
Epoch 1 [140/172] - loss: 0.4904, acc: 0.7500
Epoch 1 [141/172] - loss: 0.6467
Epoch 1 [142/172] - loss: 0.3554
Epoch 1 [143/172] - loss: 0.7685
Epoch 1 [144/172] - loss: 0.4227
Epoch 1 [145/172] - loss: 0.4228
Epoch 1 [146/172] - loss: 0.7278
Epoch 1 [147/172] - loss: 0.6846
Epoch 1 [148/172] - loss: 0.4091
Epoch 1 [149/172] - loss: 0.3359
Epoch 1 [150/172] - loss: 0.4031, acc: 0.8438
Epoch 1 [151/172] - loss: 0.4734
Epoch 1 [152/172] - loss: 0.6446
Epoch 1 [153/172] - loss: 0.5568
Epoch 1 [154/172] - loss: 0.3229
Epoch 1 [155/172] - loss: 0.3912
Epoch 1 [156/172] - loss: 0.6493
Epoch 1 [157/172] - loss: 0.5333
Epoch 1 [158/172] - loss: 0.4503
Epoch 1 [159/172] - loss: 0.5881
Epoch 1 [160/172] - loss: 0.3905, acc: 0.8438
Epoch 1 [161/172] - loss: 0.4582
Epoch 1 [162/172] - loss: 0.4128
Epoch 1 [163/172] - loss: 0.6367
Epoch 1 [164/172] - loss: 0.7014
Epoch 1 [165/172] - loss: 0.4263
Epoch 1 [166/172] - loss: 0.3271
Epoch 1 [167/172] - loss: 0.3984
Epoch 1 [168/172] - loss: 0.6312
Epoch 1 [169/172] - loss: 0.4763
Epoch 1 [170/172] - loss: 0.3908, acc: 0.7812
Epoch 1 [171/172] - loss: 0.4566
Epoch 1 [172/172] - loss: 0.3463

类别准确率:
positive: 0.6017 (281/467)
neutral: 0.4819 (40/83)
negative: 0.8160 (204/250)

Epoch 1/10
Train Loss: 0.4765, Train Acc: 0.7838
Val Loss: 0.7581, Val Acc: 0.6562
Epoch 2 [1/172] - loss: 0.3433, acc: 0.9062
Epoch 2 [2/172] - loss: 0.3110
Epoch 2 [3/172] - loss: 0.2036
Epoch 2 [4/172] - loss: 0.3796
Epoch 2 [5/172] - loss: 0.4989
Epoch 2 [6/172] - loss: 0.5263
Epoch 2 [7/172] - loss: 0.3265
Epoch 2 [8/172] - loss: 0.2924
Epoch 2 [9/172] - loss: 0.2540
Epoch 2 [10/172] - loss: 0.3798, acc: 0.7812
Epoch 2 [11/172] - loss: 0.2718
Epoch 2 [12/172] - loss: 0.2785
Epoch 2 [13/172] - loss: 0.3633
Epoch 2 [14/172] - loss: 0.3048
Epoch 2 [15/172] - loss: 0.3535
Epoch 2 [16/172] - loss: 0.3767
Epoch 2 [17/172] - loss: 0.3641
Epoch 2 [18/172] - loss: 0.3952
Epoch 2 [19/172] - loss: 0.3216
Epoch 2 [20/172] - loss: 0.2935, acc: 0.8438
Epoch 2 [21/172] - loss: 0.3339
Epoch 2 [22/172] - loss: 0.1984
Epoch 2 [23/172] - loss: 0.3159
Epoch 2 [24/172] - loss: 0.4648
Epoch 2 [25/172] - loss: 0.2986
Epoch 2 [26/172] - loss: 0.1873
Epoch 2 [27/172] - loss: 0.2700
Epoch 2 [28/172] - loss: 0.2001

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4991, log_difficulty=0.4049, weight=3.0243
neutral: count=1952.0, difficulty=0.4530, log_difficulty=0.3736, weight=2.8681
negative: count=2216.0, difficulty=0.4965, log_difficulty=0.4031, weight=3.0157

当前batch的pt分布：
positive: min=0.3284, max=0.9879, mean=0.6971
neutral: min=0.5412, max=0.9577, mean=0.7603
negative: min=0.2546, max=0.9109, mean=0.6695

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.7778
neutral 准确率: 1.0000
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.3946
焦点损失: 0.0689
边界损失: 0.3342
总损失: 0.2390
Epoch 2 [29/172] - loss: 0.2390
Epoch 2 [30/172] - loss: 0.3447, acc: 0.7812
Epoch 2 [31/172] - loss: 0.4325
Epoch 2 [32/172] - loss: 0.2537
Epoch 2 [33/172] - loss: 0.2886
Epoch 2 [34/172] - loss: 0.2444
Epoch 2 [35/172] - loss: 0.1824
Epoch 2 [36/172] - loss: 0.4946
Epoch 2 [37/172] - loss: 0.2532
Epoch 2 [38/172] - loss: 0.3115
Epoch 2 [39/172] - loss: 0.4122
Epoch 2 [40/172] - loss: 0.3658, acc: 0.8438
Epoch 2 [41/172] - loss: 0.4111
Epoch 2 [42/172] - loss: 0.1412
Epoch 2 [43/172] - loss: 0.1691
Epoch 2 [44/172] - loss: 0.4988
Epoch 2 [45/172] - loss: 0.1746
Epoch 2 [46/172] - loss: 0.1889
Epoch 2 [47/172] - loss: 0.3880
Epoch 2 [48/172] - loss: 0.3377
Epoch 2 [49/172] - loss: 0.2181
Epoch 2 [50/172] - loss: 0.2819, acc: 0.8750
Epoch 2 [51/172] - loss: 0.3408
Epoch 2 [52/172] - loss: 0.2398
Epoch 2 [53/172] - loss: 0.2400
Epoch 2 [54/172] - loss: 0.1500
Epoch 2 [55/172] - loss: 0.2623
Epoch 2 [56/172] - loss: 0.2072
Epoch 2 [57/172] - loss: 0.2030
Epoch 2 [58/172] - loss: 0.3298
Epoch 2 [59/172] - loss: 0.4129
Epoch 2 [60/172] - loss: 0.2330, acc: 0.9375
Epoch 2 [61/172] - loss: 0.1268
Epoch 2 [62/172] - loss: 0.1659
Epoch 2 [63/172] - loss: 0.3629
Epoch 2 [64/172] - loss: 0.2002
Epoch 2 [65/172] - loss: 0.3278
Epoch 2 [66/172] - loss: 0.2153
Epoch 2 [67/172] - loss: 0.1510
Epoch 2 [68/172] - loss: 0.2283
Epoch 2 [69/172] - loss: 0.1471
Epoch 2 [70/172] - loss: 0.3609, acc: 0.8750
Epoch 2 [71/172] - loss: 0.3834
Epoch 2 [72/172] - loss: 0.3452
Epoch 2 [73/172] - loss: 0.1999
Epoch 2 [74/172] - loss: 0.1998
Epoch 2 [75/172] - loss: 0.2311
Epoch 2 [76/172] - loss: 0.1992
Epoch 2 [77/172] - loss: 0.2080
Epoch 2 [78/172] - loss: 0.3602
Epoch 2 [79/172] - loss: 0.2780
Epoch 2 [80/172] - loss: 0.1791, acc: 0.9688
Epoch 2 [81/172] - loss: 0.3615
Epoch 2 [82/172] - loss: 0.2291
Epoch 2 [83/172] - loss: 0.3131
Epoch 2 [84/172] - loss: 0.3646
Epoch 2 [85/172] - loss: 0.3017
Epoch 2 [86/172] - loss: 0.3192
Epoch 2 [87/172] - loss: 0.4904
Epoch 2 [88/172] - loss: 0.2121
Epoch 2 [89/172] - loss: 0.2589
Epoch 2 [90/172] - loss: 0.1954, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1513
Epoch 2 [92/172] - loss: 0.4113
Epoch 2 [93/172] - loss: 0.2226
Epoch 2 [94/172] - loss: 0.2244
Epoch 2 [95/172] - loss: 0.4538
Epoch 2 [96/172] - loss: 0.1184
Epoch 2 [97/172] - loss: 0.1859
Epoch 2 [98/172] - loss: 0.1993
Epoch 2 [99/172] - loss: 0.1547
Epoch 2 [100/172] - loss: 0.2511, acc: 0.8750
Epoch 2 [101/172] - loss: 0.2371
Epoch 2 [102/172] - loss: 0.1219
Epoch 2 [103/172] - loss: 0.3509
Epoch 2 [104/172] - loss: 0.4411
Epoch 2 [105/172] - loss: 0.1971
Epoch 2 [106/172] - loss: 0.1877
Epoch 2 [107/172] - loss: 0.1172
Epoch 2 [108/172] - loss: 0.2991
Epoch 2 [109/172] - loss: 0.1866
Epoch 2 [110/172] - loss: 0.1714, acc: 0.9375
Epoch 2 [111/172] - loss: 0.1309
Epoch 2 [112/172] - loss: 0.1515
Epoch 2 [113/172] - loss: 0.1200
Epoch 2 [114/172] - loss: 0.1978
Epoch 2 [115/172] - loss: 0.1911
Epoch 2 [116/172] - loss: 0.1776
Epoch 2 [117/172] - loss: 0.3732
Epoch 2 [118/172] - loss: 0.2892
Epoch 2 [119/172] - loss: 0.4539
Epoch 2 [120/172] - loss: 0.1725, acc: 0.9375
Epoch 2 [121/172] - loss: 0.3208
Epoch 2 [122/172] - loss: 0.1493
Epoch 2 [123/172] - loss: 0.2495
Epoch 2 [124/172] - loss: 0.2965
Epoch 2 [125/172] - loss: 0.1017
Epoch 2 [126/172] - loss: 0.1066
Epoch 2 [127/172] - loss: 0.1627
Epoch 2 [128/172] - loss: 0.1913

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4388, log_difficulty=0.3638, weight=2.8191
neutral: count=2949.0, difficulty=0.3656, log_difficulty=0.3116, weight=2.5580
negative: count=3294.0, difficulty=0.4369, log_difficulty=0.3625, weight=2.8123

当前batch的pt分布：
positive: min=0.3440, max=0.9413, mean=0.7299
neutral: min=0.2631, max=0.9681, mean=0.7598
negative: min=0.0939, max=0.9223, mean=0.6528

当前batch准确率：
整体准确率: 0.8125
positive 准确率: 0.7000
neutral 准确率: 0.9091
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.4337
焦点损失: 0.1370
边界损失: 0.3092
总损失: 0.3610
Epoch 2 [129/172] - loss: 0.3610
Epoch 2 [130/172] - loss: 0.1601, acc: 0.9688
Epoch 2 [131/172] - loss: 0.1689
Epoch 2 [132/172] - loss: 0.2476
Epoch 2 [133/172] - loss: 0.1211
Epoch 2 [134/172] - loss: 0.2738
Epoch 2 [135/172] - loss: 0.5451
Epoch 2 [136/172] - loss: 0.1870
Epoch 2 [137/172] - loss: 0.1955
Epoch 2 [138/172] - loss: 0.3299
Epoch 2 [139/172] - loss: 0.1323
Epoch 2 [140/172] - loss: 0.2863, acc: 0.8750
Epoch 2 [141/172] - loss: 0.1600
Epoch 2 [142/172] - loss: 0.2281
Epoch 2 [143/172] - loss: 0.1589
Epoch 2 [144/172] - loss: 0.1874
Epoch 2 [145/172] - loss: 0.7025
Epoch 2 [146/172] - loss: 0.1937
Epoch 2 [147/172] - loss: 0.4656
Epoch 2 [148/172] - loss: 0.4335
Epoch 2 [149/172] - loss: 0.2073
Epoch 2 [150/172] - loss: 0.2885, acc: 0.8750
Epoch 2 [151/172] - loss: 0.2666
Epoch 2 [152/172] - loss: 0.2711
Epoch 2 [153/172] - loss: 0.2280
Epoch 2 [154/172] - loss: 0.2416
Epoch 2 [155/172] - loss: 0.2723
Epoch 2 [156/172] - loss: 0.1440
Epoch 2 [157/172] - loss: 0.1172
Epoch 2 [158/172] - loss: 0.1510
Epoch 2 [159/172] - loss: 0.2067
Epoch 2 [160/172] - loss: 0.1798, acc: 0.9688
Epoch 2 [161/172] - loss: 0.2066
Epoch 2 [162/172] - loss: 0.1226
Epoch 2 [163/172] - loss: 0.2659
Epoch 2 [164/172] - loss: 0.4106
Epoch 2 [165/172] - loss: 0.3546
Epoch 2 [166/172] - loss: 0.3500
Epoch 2 [167/172] - loss: 0.2649
Epoch 2 [168/172] - loss: 0.1172
Epoch 2 [169/172] - loss: 0.1089
Epoch 2 [170/172] - loss: 0.3017, acc: 0.8438
Epoch 2 [171/172] - loss: 0.4139
Epoch 2 [172/172] - loss: 0.3158

类别准确率:
positive: 0.8929 (417/467)
neutral: 0.1807 (15/83)
negative: 0.5680 (142/250)

Epoch 2/10
Train Loss: 0.2430, Train Acc: 0.8990
Val Loss: 0.6811, Val Acc: 0.7175
Epoch 3 [1/172] - loss: 0.1284, acc: 1.0000
Epoch 3 [2/172] - loss: 0.3519
Epoch 3 [3/172] - loss: 0.1379
Epoch 3 [4/172] - loss: 0.1218
Epoch 3 [5/172] - loss: 0.1340
Epoch 3 [6/172] - loss: 0.0775
Epoch 3 [7/172] - loss: 0.1059
Epoch 3 [8/172] - loss: 0.1885
Epoch 3 [9/172] - loss: 0.1697
Epoch 3 [10/172] - loss: 0.1366, acc: 0.9375
Epoch 3 [11/172] - loss: 0.1420
Epoch 3 [12/172] - loss: 0.0832
Epoch 3 [13/172] - loss: 0.0814
Epoch 3 [14/172] - loss: 0.0891
Epoch 3 [15/172] - loss: 0.0993
Epoch 3 [16/172] - loss: 0.1752
Epoch 3 [17/172] - loss: 0.1983
Epoch 3 [18/172] - loss: 0.2734
Epoch 3 [19/172] - loss: 0.1244
Epoch 3 [20/172] - loss: 0.0925, acc: 1.0000
Epoch 3 [21/172] - loss: 0.0960
Epoch 3 [22/172] - loss: 0.1299
Epoch 3 [23/172] - loss: 0.0927
Epoch 3 [24/172] - loss: 0.1204
Epoch 3 [25/172] - loss: 0.1035
Epoch 3 [26/172] - loss: 0.1272
Epoch 3 [27/172] - loss: 0.1358
Epoch 3 [28/172] - loss: 0.0658
Epoch 3 [29/172] - loss: 0.1783
Epoch 3 [30/172] - loss: 0.1318, acc: 0.9375
Epoch 3 [31/172] - loss: 0.1012
Epoch 3 [32/172] - loss: 0.1051
Epoch 3 [33/172] - loss: 0.0791
Epoch 3 [34/172] - loss: 0.1059
Epoch 3 [35/172] - loss: 0.2236
Epoch 3 [36/172] - loss: 0.1303
Epoch 3 [37/172] - loss: 0.2017
Epoch 3 [38/172] - loss: 0.0687
Epoch 3 [39/172] - loss: 0.0837
Epoch 3 [40/172] - loss: 0.1797, acc: 0.9375
Epoch 3 [41/172] - loss: 0.0931
Epoch 3 [42/172] - loss: 0.1132
Epoch 3 [43/172] - loss: 0.0885
Epoch 3 [44/172] - loss: 0.0653
Epoch 3 [45/172] - loss: 0.1778
Epoch 3 [46/172] - loss: 0.0964
Epoch 3 [47/172] - loss: 0.0918
Epoch 3 [48/172] - loss: 0.1964
Epoch 3 [49/172] - loss: 0.1204
Epoch 3 [50/172] - loss: 0.1095, acc: 0.9688
Epoch 3 [51/172] - loss: 0.1679
Epoch 3 [52/172] - loss: 0.2215
Epoch 3 [53/172] - loss: 0.0880
Epoch 3 [54/172] - loss: 0.1296
Epoch 3 [55/172] - loss: 0.0942
Epoch 3 [56/172] - loss: 0.1035

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3879, log_difficulty=0.3278, weight=2.6390
neutral: count=3923.0, difficulty=0.3176, log_difficulty=0.2758, weight=2.3789
negative: count=4382.0, difficulty=0.3884, log_difficulty=0.3282, weight=2.6408

当前batch的pt分布：
positive: min=0.6897, max=0.9795, mean=0.8460
neutral: min=0.0233, max=0.9514, mean=0.7223
negative: min=0.8913, max=0.9854, mean=0.9524

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3212
焦点损失: 0.1315
边界损失: 0.2399
总损失: 0.2950
Epoch 3 [57/172] - loss: 0.2950
Epoch 3 [58/172] - loss: 0.1438
Epoch 3 [59/172] - loss: 0.1182
Epoch 3 [60/172] - loss: 0.0805, acc: 1.0000
Epoch 3 [61/172] - loss: 0.0782
Epoch 3 [62/172] - loss: 0.1371
Epoch 3 [63/172] - loss: 0.0810
Epoch 3 [64/172] - loss: 0.1135
Epoch 3 [65/172] - loss: 0.1052
Epoch 3 [66/172] - loss: 0.1989
Epoch 3 [67/172] - loss: 0.1007
Epoch 3 [68/172] - loss: 0.1269
Epoch 3 [69/172] - loss: 0.2520
Epoch 3 [70/172] - loss: 0.0546, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1594
Epoch 3 [72/172] - loss: 0.0921
Epoch 3 [73/172] - loss: 0.1591
Epoch 3 [74/172] - loss: 0.1142
Epoch 3 [75/172] - loss: 0.1236
Epoch 3 [76/172] - loss: 0.1011
Epoch 3 [77/172] - loss: 0.1109
Epoch 3 [78/172] - loss: 0.2111
Epoch 3 [79/172] - loss: 0.0706
Epoch 3 [80/172] - loss: 0.1603, acc: 0.9688
Epoch 3 [81/172] - loss: 0.1541
Epoch 3 [82/172] - loss: 0.2131
Epoch 3 [83/172] - loss: 0.0896
Epoch 3 [84/172] - loss: 0.1102
Epoch 3 [85/172] - loss: 0.1164
Epoch 3 [86/172] - loss: 0.0922
Epoch 3 [87/172] - loss: 0.1431
Epoch 3 [88/172] - loss: 0.1450
Epoch 3 [89/172] - loss: 0.1037
Epoch 3 [90/172] - loss: 0.0624, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1529
Epoch 3 [92/172] - loss: 0.0768
Epoch 3 [93/172] - loss: 0.1439
Epoch 3 [94/172] - loss: 0.0735
Epoch 3 [95/172] - loss: 0.0974
Epoch 3 [96/172] - loss: 0.1040
Epoch 3 [97/172] - loss: 0.0584
Epoch 3 [98/172] - loss: 0.0864
Epoch 3 [99/172] - loss: 0.0750
Epoch 3 [100/172] - loss: 0.2123, acc: 0.9688
Epoch 3 [101/172] - loss: 0.2511
Epoch 3 [102/172] - loss: 0.0655
Epoch 3 [103/172] - loss: 0.1047
Epoch 3 [104/172] - loss: 0.0713
Epoch 3 [105/172] - loss: 0.1110
Epoch 3 [106/172] - loss: 0.1168
Epoch 3 [107/172] - loss: 0.0884
Epoch 3 [108/172] - loss: 0.0577
Epoch 3 [109/172] - loss: 0.0557
Epoch 3 [110/172] - loss: 0.0711, acc: 0.9688
Epoch 3 [111/172] - loss: 0.1043
Epoch 3 [112/172] - loss: 0.0598
Epoch 3 [113/172] - loss: 0.0504
Epoch 3 [114/172] - loss: 0.1186
Epoch 3 [115/172] - loss: 0.1564
Epoch 3 [116/172] - loss: 0.0646
Epoch 3 [117/172] - loss: 0.2281
Epoch 3 [118/172] - loss: 0.0847
Epoch 3 [119/172] - loss: 0.0800
Epoch 3 [120/172] - loss: 0.2269, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1051
Epoch 3 [122/172] - loss: 0.1578
Epoch 3 [123/172] - loss: 0.1118
Epoch 3 [124/172] - loss: 0.1400
Epoch 3 [125/172] - loss: 0.0703
Epoch 3 [126/172] - loss: 0.3629
Epoch 3 [127/172] - loss: 0.0988
Epoch 3 [128/172] - loss: 0.1044
Epoch 3 [129/172] - loss: 0.1334
Epoch 3 [130/172] - loss: 0.0895, acc: 0.9688
Epoch 3 [131/172] - loss: 0.1472
Epoch 3 [132/172] - loss: 0.0692
Epoch 3 [133/172] - loss: 0.1366
Epoch 3 [134/172] - loss: 0.0581
Epoch 3 [135/172] - loss: 0.0553
Epoch 3 [136/172] - loss: 0.0770
Epoch 3 [137/172] - loss: 0.0660
Epoch 3 [138/172] - loss: 0.0800
Epoch 3 [139/172] - loss: 0.0752
Epoch 3 [140/172] - loss: 0.0984, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1505
Epoch 3 [142/172] - loss: 0.1300
Epoch 3 [143/172] - loss: 0.0671
Epoch 3 [144/172] - loss: 0.1875
Epoch 3 [145/172] - loss: 0.1616
Epoch 3 [146/172] - loss: 0.0965
Epoch 3 [147/172] - loss: 0.1457
Epoch 3 [148/172] - loss: 0.0991
Epoch 3 [149/172] - loss: 0.0877
Epoch 3 [150/172] - loss: 0.1561, acc: 0.9688
Epoch 3 [151/172] - loss: 0.3155
Epoch 3 [152/172] - loss: 0.2055
Epoch 3 [153/172] - loss: 0.0750
Epoch 3 [154/172] - loss: 0.1371
Epoch 3 [155/172] - loss: 0.0847
Epoch 3 [156/172] - loss: 0.0650

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3441, log_difficulty=0.2958, weight=2.4788
neutral: count=4903.0, difficulty=0.2772, log_difficulty=0.2447, weight=2.2233
negative: count=5500.0, difficulty=0.3455, log_difficulty=0.2968, weight=2.4838

当前batch的pt分布：
positive: min=0.4331, max=0.9901, mean=0.8617
neutral: min=0.7471, max=0.9962, mean=0.8933
negative: min=0.4380, max=0.9593, mean=0.8212

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1681
焦点损失: 0.0162
边界损失: 0.2208
总损失: 0.0852
Epoch 3 [157/172] - loss: 0.0852
Epoch 3 [158/172] - loss: 0.3120
Epoch 3 [159/172] - loss: 0.0879
Epoch 3 [160/172] - loss: 0.1774, acc: 0.9062
Epoch 3 [161/172] - loss: 0.2332
Epoch 3 [162/172] - loss: 0.1686
Epoch 3 [163/172] - loss: 0.0923
Epoch 3 [164/172] - loss: 0.0762
Epoch 3 [165/172] - loss: 0.0701
Epoch 3 [166/172] - loss: 0.0857
Epoch 3 [167/172] - loss: 0.0846
Epoch 3 [168/172] - loss: 0.0918
Epoch 3 [169/172] - loss: 0.1064
Epoch 3 [170/172] - loss: 0.1806, acc: 0.9688
Epoch 3 [171/172] - loss: 0.0949
Epoch 3 [172/172] - loss: 0.0536

类别准确率:
positive: 0.8522 (398/467)
neutral: 0.3976 (33/83)
negative: 0.5840 (146/250)

Epoch 3/10
Train Loss: 0.1250, Train Acc: 0.9596
Val Loss: 0.7222, Val Acc: 0.7212
Epoch 4 [1/172] - loss: 0.0665, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1117
Epoch 4 [3/172] - loss: 0.0683
Epoch 4 [4/172] - loss: 0.0837
Epoch 4 [5/172] - loss: 0.0957
Epoch 4 [6/172] - loss: 0.0485
Epoch 4 [7/172] - loss: 0.0754
Epoch 4 [8/172] - loss: 0.0576
Epoch 4 [9/172] - loss: 0.1328
Epoch 4 [10/172] - loss: 0.1165, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0484
Epoch 4 [12/172] - loss: 0.0617
Epoch 4 [13/172] - loss: 0.0893
Epoch 4 [14/172] - loss: 0.0767
Epoch 4 [15/172] - loss: 0.0905
Epoch 4 [16/172] - loss: 0.0528
Epoch 4 [17/172] - loss: 0.0611
Epoch 4 [18/172] - loss: 0.0659
Epoch 4 [19/172] - loss: 0.0551
Epoch 4 [20/172] - loss: 0.0898, acc: 0.9688
Epoch 4 [21/172] - loss: 0.1823
Epoch 4 [22/172] - loss: 0.0507
Epoch 4 [23/172] - loss: 0.1385
Epoch 4 [24/172] - loss: 0.0504
Epoch 4 [25/172] - loss: 0.0721
Epoch 4 [26/172] - loss: 0.4111
Epoch 4 [27/172] - loss: 0.0514
Epoch 4 [28/172] - loss: 0.0764
Epoch 4 [29/172] - loss: 0.0627
Epoch 4 [30/172] - loss: 0.0959, acc: 0.9688
Epoch 4 [31/172] - loss: 0.0776
Epoch 4 [32/172] - loss: 0.0983
Epoch 4 [33/172] - loss: 0.0617
Epoch 4 [34/172] - loss: 0.0498
Epoch 4 [35/172] - loss: 0.0849
Epoch 4 [36/172] - loss: 0.1670
Epoch 4 [37/172] - loss: 0.0454
Epoch 4 [38/172] - loss: 0.1254
Epoch 4 [39/172] - loss: 0.1251
Epoch 4 [40/172] - loss: 0.1701, acc: 0.8750
Epoch 4 [41/172] - loss: 0.0544
Epoch 4 [42/172] - loss: 0.0885
Epoch 4 [43/172] - loss: 0.0893
Epoch 4 [44/172] - loss: 0.0661
Epoch 4 [45/172] - loss: 0.0553
Epoch 4 [46/172] - loss: 0.0615
Epoch 4 [47/172] - loss: 0.0686
Epoch 4 [48/172] - loss: 0.0775
Epoch 4 [49/172] - loss: 0.0596
Epoch 4 [50/172] - loss: 0.0917, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0550
Epoch 4 [52/172] - loss: 0.1164
Epoch 4 [53/172] - loss: 0.0505
Epoch 4 [54/172] - loss: 0.0638
Epoch 4 [55/172] - loss: 0.1880
Epoch 4 [56/172] - loss: 0.0698
Epoch 4 [57/172] - loss: 0.0549
Epoch 4 [58/172] - loss: 0.0493
Epoch 4 [59/172] - loss: 0.0457
Epoch 4 [60/172] - loss: 0.0504, acc: 1.0000
Epoch 4 [61/172] - loss: 0.0703
Epoch 4 [62/172] - loss: 0.0702
Epoch 4 [63/172] - loss: 0.0777
Epoch 4 [64/172] - loss: 0.0423
Epoch 4 [65/172] - loss: 0.0609
Epoch 4 [66/172] - loss: 0.0513
Epoch 4 [67/172] - loss: 0.0601
Epoch 4 [68/172] - loss: 0.0510
Epoch 4 [69/172] - loss: 0.0601
Epoch 4 [70/172] - loss: 0.0568, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0537
Epoch 4 [72/172] - loss: 0.0541
Epoch 4 [73/172] - loss: 0.0601
Epoch 4 [74/172] - loss: 0.2624
Epoch 4 [75/172] - loss: 0.0679
Epoch 4 [76/172] - loss: 0.0481
Epoch 4 [77/172] - loss: 0.0751
Epoch 4 [78/172] - loss: 0.0873
Epoch 4 [79/172] - loss: 0.0575
Epoch 4 [80/172] - loss: 0.0625, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1474
Epoch 4 [82/172] - loss: 0.0526
Epoch 4 [83/172] - loss: 0.0505
Epoch 4 [84/172] - loss: 0.0674

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3094, log_difficulty=0.2695, weight=2.3477
neutral: count=5865.0, difficulty=0.2457, log_difficulty=0.2197, weight=2.0986
negative: count=6629.0, difficulty=0.3110, log_difficulty=0.2708, weight=2.3540

当前batch的pt分布：
positive: min=0.4518, max=0.9639, mean=0.8135
neutral: min=0.5386, max=0.9972, mean=0.9214
negative: min=0.1371, max=0.9797, mean=0.8638

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.2101
焦点损失: 0.0606
边界损失: 0.2125
总损失: 0.1593
Epoch 4 [85/172] - loss: 0.1593
Epoch 4 [86/172] - loss: 0.1001
Epoch 4 [87/172] - loss: 0.0473
Epoch 4 [88/172] - loss: 0.0515
Epoch 4 [89/172] - loss: 0.0451
Epoch 4 [90/172] - loss: 0.0479, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1984
Epoch 4 [92/172] - loss: 0.1805
Epoch 4 [93/172] - loss: 0.0487
Epoch 4 [94/172] - loss: 0.0456
Epoch 4 [95/172] - loss: 0.0917
Epoch 4 [96/172] - loss: 0.0581
Epoch 4 [97/172] - loss: 0.0535
Epoch 4 [98/172] - loss: 0.0489
Epoch 4 [99/172] - loss: 0.1112
Epoch 4 [100/172] - loss: 0.0575, acc: 1.0000
Epoch 4 [101/172] - loss: 0.0981
Epoch 4 [102/172] - loss: 0.0672
Epoch 4 [103/172] - loss: 0.0502
Epoch 4 [104/172] - loss: 0.0920
Epoch 4 [105/172] - loss: 0.0522
Epoch 4 [106/172] - loss: 0.0625
Epoch 4 [107/172] - loss: 0.0452
Epoch 4 [108/172] - loss: 0.0498
Epoch 4 [109/172] - loss: 0.0464
Epoch 4 [110/172] - loss: 0.2257, acc: 0.8750
Epoch 4 [111/172] - loss: 0.0528
Epoch 4 [112/172] - loss: 0.0419
Epoch 4 [113/172] - loss: 0.0459
Epoch 4 [114/172] - loss: 0.0475
Epoch 4 [115/172] - loss: 0.0745
Epoch 4 [116/172] - loss: 0.0763
Epoch 4 [117/172] - loss: 0.0431
Epoch 4 [118/172] - loss: 0.0801
Epoch 4 [119/172] - loss: 0.0443
Epoch 4 [120/172] - loss: 0.0972, acc: 0.9688
Epoch 4 [121/172] - loss: 0.0864
Epoch 4 [122/172] - loss: 0.1630
Epoch 4 [123/172] - loss: 0.0553
Epoch 4 [124/172] - loss: 0.0423
Epoch 4 [125/172] - loss: 0.0929
Epoch 4 [126/172] - loss: 0.1758
Epoch 4 [127/172] - loss: 0.0781
Epoch 4 [128/172] - loss: 0.0502
Epoch 4 [129/172] - loss: 0.0617
Epoch 4 [130/172] - loss: 0.0643, acc: 0.9688
Epoch 4 [131/172] - loss: 0.0746
Epoch 4 [132/172] - loss: 0.0451
Epoch 4 [133/172] - loss: 0.0549
Epoch 4 [134/172] - loss: 0.0505
Epoch 4 [135/172] - loss: 0.1233
Epoch 4 [136/172] - loss: 0.1431
Epoch 4 [137/172] - loss: 0.0660
Epoch 4 [138/172] - loss: 0.0602
Epoch 4 [139/172] - loss: 0.0941
Epoch 4 [140/172] - loss: 0.0615, acc: 1.0000
Epoch 4 [141/172] - loss: 0.1154
Epoch 4 [142/172] - loss: 0.0617
Epoch 4 [143/172] - loss: 0.0481
Epoch 4 [144/172] - loss: 0.0752
Epoch 4 [145/172] - loss: 0.5652
Epoch 4 [146/172] - loss: 0.0583
Epoch 4 [147/172] - loss: 0.0873
Epoch 4 [148/172] - loss: 0.0756
Epoch 4 [149/172] - loss: 0.0545
Epoch 4 [150/172] - loss: 0.1030, acc: 0.9062
Epoch 4 [151/172] - loss: 0.1747
Epoch 4 [152/172] - loss: 0.0485
Epoch 4 [153/172] - loss: 0.0491
Epoch 4 [154/172] - loss: 0.0805
Epoch 4 [155/172] - loss: 0.0841
Epoch 4 [156/172] - loss: 0.0752
Epoch 4 [157/172] - loss: 0.3227
Epoch 4 [158/172] - loss: 0.0462
Epoch 4 [159/172] - loss: 0.0557
Epoch 4 [160/172] - loss: 0.0617, acc: 1.0000
Epoch 4 [161/172] - loss: 0.0655
Epoch 4 [162/172] - loss: 0.0569
Epoch 4 [163/172] - loss: 0.0782
Epoch 4 [164/172] - loss: 0.0665
Epoch 4 [165/172] - loss: 0.1196
Epoch 4 [166/172] - loss: 0.0606
Epoch 4 [167/172] - loss: 0.0737
Epoch 4 [168/172] - loss: 0.0477
Epoch 4 [169/172] - loss: 0.0772
Epoch 4 [170/172] - loss: 0.0734, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0808
Epoch 4 [172/172] - loss: 0.0801

类别准确率:
positive: 0.8865 (414/467)
neutral: 0.3133 (26/83)
negative: 0.5240 (131/250)

Epoch 4/10
Train Loss: 0.0854, Train Acc: 0.9798
Val Loss: 0.7664, Val Acc: 0.7137
Epoch 5 [1/172] - loss: 0.0430, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0601
Epoch 5 [3/172] - loss: 0.0471
Epoch 5 [4/172] - loss: 0.0594
Epoch 5 [5/172] - loss: 0.0453
Epoch 5 [6/172] - loss: 0.0773
Epoch 5 [7/172] - loss: 0.0505
Epoch 5 [8/172] - loss: 0.1227
Epoch 5 [9/172] - loss: 0.0734
Epoch 5 [10/172] - loss: 0.0516, acc: 1.0000
Epoch 5 [11/172] - loss: 0.0748
Epoch 5 [12/172] - loss: 0.0474

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2812, log_difficulty=0.2478, weight=2.2390
neutral: count=6845.0, difficulty=0.2218, log_difficulty=0.2003, weight=2.0015
negative: count=7694.0, difficulty=0.2836, log_difficulty=0.2496, weight=2.2481

当前batch的pt分布：
positive: min=0.0702, max=0.9672, mean=0.8266
neutral: min=0.9790, max=0.9956, mean=0.9876
negative: min=0.6302, max=0.9927, mean=0.9097

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1747
焦点损失: 0.0761
边界损失: 0.1817
总损失: 0.1732
Epoch 5 [13/172] - loss: 0.1732
Epoch 5 [14/172] - loss: 0.3248
Epoch 5 [15/172] - loss: 0.0542
Epoch 5 [16/172] - loss: 0.0459
Epoch 5 [17/172] - loss: 0.0496
Epoch 5 [18/172] - loss: 0.1136
Epoch 5 [19/172] - loss: 0.0953
Epoch 5 [20/172] - loss: 0.1332, acc: 0.9375
Epoch 5 [21/172] - loss: 0.0816
Epoch 5 [22/172] - loss: 0.1017
Epoch 5 [23/172] - loss: 0.0448
Epoch 5 [24/172] - loss: 0.0646
Epoch 5 [25/172] - loss: 0.0466
Epoch 5 [26/172] - loss: 0.0784
Epoch 5 [27/172] - loss: 0.0463
Epoch 5 [28/172] - loss: 0.0459
Epoch 5 [29/172] - loss: 0.0450
Epoch 5 [30/172] - loss: 0.0862, acc: 0.9688
Epoch 5 [31/172] - loss: 0.0593
Epoch 5 [32/172] - loss: 0.0480
Epoch 5 [33/172] - loss: 0.0757
Epoch 5 [34/172] - loss: 0.0521
Epoch 5 [35/172] - loss: 0.0625
Epoch 5 [36/172] - loss: 0.0503
Epoch 5 [37/172] - loss: 0.0447
Epoch 5 [38/172] - loss: 0.0478
Epoch 5 [39/172] - loss: 0.2106
Epoch 5 [40/172] - loss: 0.0588, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0470
Epoch 5 [42/172] - loss: 0.0757
Epoch 5 [43/172] - loss: 0.1804
Epoch 5 [44/172] - loss: 0.0825
Epoch 5 [45/172] - loss: 0.0451
Epoch 5 [46/172] - loss: 0.0713
Epoch 5 [47/172] - loss: 0.0497
Epoch 5 [48/172] - loss: 0.1082
Epoch 5 [49/172] - loss: 0.0466
Epoch 5 [50/172] - loss: 0.0845, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0561
Epoch 5 [52/172] - loss: 0.0483
Epoch 5 [53/172] - loss: 0.0525
Epoch 5 [54/172] - loss: 0.0478
Epoch 5 [55/172] - loss: 0.0508
Epoch 5 [56/172] - loss: 0.0527
Epoch 5 [57/172] - loss: 0.0556
Epoch 5 [58/172] - loss: 0.0415
Epoch 5 [59/172] - loss: 0.0666
Epoch 5 [60/172] - loss: 0.0490, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0451
Epoch 5 [62/172] - loss: 0.0507
Epoch 5 [63/172] - loss: 0.2107
Epoch 5 [64/172] - loss: 0.0536
Epoch 5 [65/172] - loss: 0.0432
Epoch 5 [66/172] - loss: 0.0489
Epoch 5 [67/172] - loss: 0.0599
Epoch 5 [68/172] - loss: 0.0493
Epoch 5 [69/172] - loss: 0.0748
Epoch 5 [70/172] - loss: 0.0489, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0499
Epoch 5 [72/172] - loss: 0.0838
Epoch 5 [73/172] - loss: 0.1133
Epoch 5 [74/172] - loss: 0.0727
Epoch 5 [75/172] - loss: 0.0506
Epoch 5 [76/172] - loss: 0.0542
Epoch 5 [77/172] - loss: 0.0442
Epoch 5 [78/172] - loss: 0.0783
Epoch 5 [79/172] - loss: 0.0499
Epoch 5 [80/172] - loss: 0.0456, acc: 1.0000
Epoch 5 [81/172] - loss: 0.0807
Epoch 5 [82/172] - loss: 0.0515
Epoch 5 [83/172] - loss: 0.0535
Epoch 5 [84/172] - loss: 0.0421
Epoch 5 [85/172] - loss: 0.2109
Epoch 5 [86/172] - loss: 0.0503
Epoch 5 [87/172] - loss: 0.1029
Epoch 5 [88/172] - loss: 0.0674
Epoch 5 [89/172] - loss: 0.0435
Epoch 5 [90/172] - loss: 0.1303, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0820
Epoch 5 [92/172] - loss: 0.0630
Epoch 5 [93/172] - loss: 0.0525
Epoch 5 [94/172] - loss: 0.0600
Epoch 5 [95/172] - loss: 0.0575
Epoch 5 [96/172] - loss: 0.0625
Epoch 5 [97/172] - loss: 0.0712
Epoch 5 [98/172] - loss: 0.0438
Epoch 5 [99/172] - loss: 0.2009
Epoch 5 [100/172] - loss: 0.0619, acc: 0.9688
Epoch 5 [101/172] - loss: 0.0560
Epoch 5 [102/172] - loss: 0.0846
Epoch 5 [103/172] - loss: 0.0891
Epoch 5 [104/172] - loss: 0.1293
Epoch 5 [105/172] - loss: 0.1953
Epoch 5 [106/172] - loss: 0.0513
Epoch 5 [107/172] - loss: 0.0542
Epoch 5 [108/172] - loss: 0.0831
Epoch 5 [109/172] - loss: 0.0398
Epoch 5 [110/172] - loss: 0.0516, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0534
Epoch 5 [112/172] - loss: 0.0444

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2577, log_difficulty=0.2293, weight=2.1464
neutral: count=7825.0, difficulty=0.2019, log_difficulty=0.1839, weight=1.9197
negative: count=8780.0, difficulty=0.2624, log_difficulty=0.2330, weight=2.1650

当前batch的pt分布：
positive: min=0.4678, max=0.9562, mean=0.8399
neutral: min=0.7789, max=0.9865, mean=0.9379
negative: min=0.9572, max=0.9992, mean=0.9812

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1194
焦点损失: 0.0085
边界损失: 0.1956
总损失: 0.0624
Epoch 5 [113/172] - loss: 0.0624
Epoch 5 [114/172] - loss: 0.0905
Epoch 5 [115/172] - loss: 0.0613
Epoch 5 [116/172] - loss: 0.0408
Epoch 5 [117/172] - loss: 0.0430
Epoch 5 [118/172] - loss: 0.0474
Epoch 5 [119/172] - loss: 0.0486
Epoch 5 [120/172] - loss: 0.0850, acc: 0.9688
Epoch 5 [121/172] - loss: 0.0531
Epoch 5 [122/172] - loss: 0.0497
Epoch 5 [123/172] - loss: 0.0547
Epoch 5 [124/172] - loss: 0.0420
Epoch 5 [125/172] - loss: 0.0410
Epoch 5 [126/172] - loss: 0.0442
Epoch 5 [127/172] - loss: 0.0820
Epoch 5 [128/172] - loss: 0.0478
Epoch 5 [129/172] - loss: 0.0942
Epoch 5 [130/172] - loss: 0.0445, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0526
Epoch 5 [132/172] - loss: 0.0809
Epoch 5 [133/172] - loss: 0.0681
Epoch 5 [134/172] - loss: 0.1083
Epoch 5 [135/172] - loss: 0.0423
Epoch 5 [136/172] - loss: 0.0539
Epoch 5 [137/172] - loss: 0.0584
Epoch 5 [138/172] - loss: 0.1071
Epoch 5 [139/172] - loss: 0.1825
Epoch 5 [140/172] - loss: 0.0888, acc: 0.9688
Epoch 5 [141/172] - loss: 0.0464
Epoch 5 [142/172] - loss: 0.0440
Epoch 5 [143/172] - loss: 0.0427
Epoch 5 [144/172] - loss: 0.0414
Epoch 5 [145/172] - loss: 0.0510
Epoch 5 [146/172] - loss: 0.0415
Epoch 5 [147/172] - loss: 0.0677
Epoch 5 [148/172] - loss: 0.0397
Epoch 5 [149/172] - loss: 0.1494
Epoch 5 [150/172] - loss: 0.0975, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0454
Epoch 5 [152/172] - loss: 0.0546
Epoch 5 [153/172] - loss: 0.0494
Epoch 5 [154/172] - loss: 0.0787
Epoch 5 [155/172] - loss: 0.0451
Epoch 5 [156/172] - loss: 0.0462
Epoch 5 [157/172] - loss: 0.0514
Epoch 5 [158/172] - loss: 0.0452
Epoch 5 [159/172] - loss: 0.0517
Epoch 5 [160/172] - loss: 0.0780, acc: 0.9688
Epoch 5 [161/172] - loss: 0.0467
Epoch 5 [162/172] - loss: 0.0500
Epoch 5 [163/172] - loss: 0.0794
Epoch 5 [164/172] - loss: 0.0432
Epoch 5 [165/172] - loss: 0.1777
Epoch 5 [166/172] - loss: 0.0683
Epoch 5 [167/172] - loss: 0.0653
Epoch 5 [168/172] - loss: 0.0563
Epoch 5 [169/172] - loss: 0.0480
Epoch 5 [170/172] - loss: 0.0520, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0612
Epoch 5 [172/172] - loss: 0.0652

类别准确率:
positive: 0.9036 (422/467)
neutral: 0.2892 (24/83)
negative: 0.4960 (124/250)

Epoch 5/10
Train Loss: 0.0650, Train Acc: 0.9899
Val Loss: 0.7983, Val Acc: 0.7125
Epoch 6 [1/172] - loss: 0.0703, acc: 1.0000
Epoch 6 [2/172] - loss: 0.0641
Epoch 6 [3/172] - loss: 0.0666
Epoch 6 [4/172] - loss: 0.0451
Epoch 6 [5/172] - loss: 0.0894
Epoch 6 [6/172] - loss: 0.0449
Epoch 6 [7/172] - loss: 0.0938
Epoch 6 [8/172] - loss: 0.0708
Epoch 6 [9/172] - loss: 0.0461
Epoch 6 [10/172] - loss: 0.0587, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0595
Epoch 6 [12/172] - loss: 0.0403
Epoch 6 [13/172] - loss: 0.0849
Epoch 6 [14/172] - loss: 0.0435
Epoch 6 [15/172] - loss: 0.0432
Epoch 6 [16/172] - loss: 0.1149
Epoch 6 [17/172] - loss: 0.0473
Epoch 6 [18/172] - loss: 0.0444
Epoch 6 [19/172] - loss: 0.0491
Epoch 6 [20/172] - loss: 0.0434, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0836
Epoch 6 [22/172] - loss: 0.0412
Epoch 6 [23/172] - loss: 0.0446
Epoch 6 [24/172] - loss: 0.0447
Epoch 6 [25/172] - loss: 0.0521
Epoch 6 [26/172] - loss: 0.0448
Epoch 6 [27/172] - loss: 0.0453
Epoch 6 [28/172] - loss: 0.0453
Epoch 6 [29/172] - loss: 0.0414
Epoch 6 [30/172] - loss: 0.0398, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0476
Epoch 6 [32/172] - loss: 0.0404
Epoch 6 [33/172] - loss: 0.0444
Epoch 6 [34/172] - loss: 0.0576
Epoch 6 [35/172] - loss: 0.0568
Epoch 6 [36/172] - loss: 0.0626
Epoch 6 [37/172] - loss: 0.0421
Epoch 6 [38/172] - loss: 0.0439
Epoch 6 [39/172] - loss: 0.0448
Epoch 6 [40/172] - loss: 0.2511, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2381, log_difficulty=0.2136, weight=2.0678
neutral: count=8815.0, difficulty=0.1869, log_difficulty=0.1714, weight=1.8568
negative: count=9870.0, difficulty=0.2427, log_difficulty=0.2173, weight=2.0864

当前batch的pt分布：
positive: min=0.4207, max=0.9961, mean=0.9137
neutral: min=0.9220, max=0.9851, mean=0.9673
negative: min=0.8451, max=0.9846, mean=0.9406

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0711
焦点损失: 0.0087
边界损失: 0.1665
总损失: 0.0551
Epoch 6 [41/172] - loss: 0.0551
Epoch 6 [42/172] - loss: 0.0444
Epoch 6 [43/172] - loss: 0.0538
Epoch 6 [44/172] - loss: 0.0406
Epoch 6 [45/172] - loss: 0.0903
Epoch 6 [46/172] - loss: 0.0529
Epoch 6 [47/172] - loss: 0.0471
Epoch 6 [48/172] - loss: 0.0452
Epoch 6 [49/172] - loss: 0.0516
Epoch 6 [50/172] - loss: 0.1945, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0534
Epoch 6 [52/172] - loss: 0.0476
Epoch 6 [53/172] - loss: 0.0404
Epoch 6 [54/172] - loss: 0.1924
Epoch 6 [55/172] - loss: 0.0632
Epoch 6 [56/172] - loss: 0.0523
Epoch 6 [57/172] - loss: 0.0436
Epoch 6 [58/172] - loss: 0.0394
Epoch 6 [59/172] - loss: 0.0785
Epoch 6 [60/172] - loss: 0.0684, acc: 0.9688
Epoch 6 [61/172] - loss: 0.0408
Epoch 6 [62/172] - loss: 0.0546
Epoch 6 [63/172] - loss: 0.0465
Epoch 6 [64/172] - loss: 0.0640
Epoch 6 [65/172] - loss: 0.0583
Epoch 6 [66/172] - loss: 0.0460
Epoch 6 [67/172] - loss: 0.0425
Epoch 6 [68/172] - loss: 0.0693
Epoch 6 [69/172] - loss: 0.0561
Epoch 6 [70/172] - loss: 0.0514, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0658
Epoch 6 [72/172] - loss: 0.0499
Epoch 6 [73/172] - loss: 0.0497
Epoch 6 [74/172] - loss: 0.0482
Epoch 6 [75/172] - loss: 0.0633
Epoch 6 [76/172] - loss: 0.0445
Epoch 6 [77/172] - loss: 0.0515
Epoch 6 [78/172] - loss: 0.0500
Epoch 6 [79/172] - loss: 0.0405
Epoch 6 [80/172] - loss: 0.0564, acc: 0.9688
Epoch 6 [81/172] - loss: 0.0555
Epoch 6 [82/172] - loss: 0.0475
Epoch 6 [83/172] - loss: 0.0417
Epoch 6 [84/172] - loss: 0.0405
Epoch 6 [85/172] - loss: 0.0963
Epoch 6 [86/172] - loss: 0.0520
Epoch 6 [87/172] - loss: 0.0466
Epoch 6 [88/172] - loss: 0.0685
Epoch 6 [89/172] - loss: 0.0413
Epoch 6 [90/172] - loss: 0.0409, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0515
Epoch 6 [92/172] - loss: 0.0455
Epoch 6 [93/172] - loss: 0.0394
Epoch 6 [94/172] - loss: 0.0748
Epoch 6 [95/172] - loss: 0.0698
Epoch 6 [96/172] - loss: 0.0403
Epoch 6 [97/172] - loss: 0.0847
Epoch 6 [98/172] - loss: 0.0427
Epoch 6 [99/172] - loss: 0.0415
Epoch 6 [100/172] - loss: 0.0429, acc: 1.0000
Epoch 6 [101/172] - loss: 0.0846
Epoch 6 [102/172] - loss: 0.0429
Epoch 6 [103/172] - loss: 0.0438
Epoch 6 [104/172] - loss: 0.0574
Epoch 6 [105/172] - loss: 0.0461
Epoch 6 [106/172] - loss: 0.0512
Epoch 6 [107/172] - loss: 0.0524
Epoch 6 [108/172] - loss: 0.0408
Epoch 6 [109/172] - loss: 0.1137
Epoch 6 [110/172] - loss: 0.0501, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0436
Epoch 6 [112/172] - loss: 0.0472
Epoch 6 [113/172] - loss: 0.0539
Epoch 6 [114/172] - loss: 0.0414
Epoch 6 [115/172] - loss: 0.0550
Epoch 6 [116/172] - loss: 0.1812
Epoch 6 [117/172] - loss: 0.0439
Epoch 6 [118/172] - loss: 0.0405
Epoch 6 [119/172] - loss: 0.0514
Epoch 6 [120/172] - loss: 0.0404, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0487
Epoch 6 [122/172] - loss: 0.0482
Epoch 6 [123/172] - loss: 0.0405
Epoch 6 [124/172] - loss: 0.0704
Epoch 6 [125/172] - loss: 0.0442
Epoch 6 [126/172] - loss: 0.0477
Epoch 6 [127/172] - loss: 0.0649
Epoch 6 [128/172] - loss: 0.0718
Epoch 6 [129/172] - loss: 0.0470
Epoch 6 [130/172] - loss: 0.0436, acc: 1.0000
Epoch 6 [131/172] - loss: 0.0503
Epoch 6 [132/172] - loss: 0.0544
Epoch 6 [133/172] - loss: 0.0433
Epoch 6 [134/172] - loss: 0.0411
Epoch 6 [135/172] - loss: 0.0399
Epoch 6 [136/172] - loss: 0.0476
Epoch 6 [137/172] - loss: 0.0431
Epoch 6 [138/172] - loss: 0.0410
Epoch 6 [139/172] - loss: 0.0443
Epoch 6 [140/172] - loss: 0.0462, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2213, log_difficulty=0.2000, weight=1.9998
neutral: count=9796.0, difficulty=0.1746, log_difficulty=0.1609, weight=1.8045
negative: count=10972.0, difficulty=0.2255, log_difficulty=0.2033, weight=2.0166

当前batch的pt分布：
positive: min=0.9365, max=0.9932, mean=0.9754
neutral: min=0.9586, max=0.9889, mean=0.9743
negative: min=0.7865, max=0.9891, mean=0.9257

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0473
焦点损失: 0.0005
边界损失: 0.1590
总损失: 0.0405
Epoch 6 [141/172] - loss: 0.0405
Epoch 6 [142/172] - loss: 0.0393
Epoch 6 [143/172] - loss: 0.0523
Epoch 6 [144/172] - loss: 0.0472
Epoch 6 [145/172] - loss: 0.0438
Epoch 6 [146/172] - loss: 0.0402
Epoch 6 [147/172] - loss: 0.0430
Epoch 6 [148/172] - loss: 0.0478
Epoch 6 [149/172] - loss: 0.0412
Epoch 6 [150/172] - loss: 0.0406, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0474
Epoch 6 [152/172] - loss: 0.0473
Epoch 6 [153/172] - loss: 0.0398
Epoch 6 [154/172] - loss: 0.0402
Epoch 6 [155/172] - loss: 0.0586
Epoch 6 [156/172] - loss: 0.0685
Epoch 6 [157/172] - loss: 0.0395
Epoch 6 [158/172] - loss: 0.0478
Epoch 6 [159/172] - loss: 0.0467
Epoch 6 [160/172] - loss: 0.0619, acc: 0.9688
Epoch 6 [161/172] - loss: 0.0404
Epoch 6 [162/172] - loss: 0.0405
Epoch 6 [163/172] - loss: 0.0457
Epoch 6 [164/172] - loss: 0.0554
Epoch 6 [165/172] - loss: 0.2227
Epoch 6 [166/172] - loss: 0.0399
Epoch 6 [167/172] - loss: 0.0396
Epoch 6 [168/172] - loss: 0.0574
Epoch 6 [169/172] - loss: 0.0557
Epoch 6 [170/172] - loss: 0.0394, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0475
Epoch 6 [172/172] - loss: 0.0481

类别准确率:
positive: 0.8587 (401/467)
neutral: 0.2892 (24/83)
negative: 0.6160 (154/250)

Epoch 6/10
Train Loss: 0.0580, Train Acc: 0.9919
Val Loss: 0.7976, Val Acc: 0.7238
Epoch 7 [1/172] - loss: 0.0433, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0395
Epoch 7 [3/172] - loss: 0.0395
Epoch 7 [4/172] - loss: 0.0435
Epoch 7 [5/172] - loss: 0.0551
Epoch 7 [6/172] - loss: 0.0415
Epoch 7 [7/172] - loss: 0.0403
Epoch 7 [8/172] - loss: 0.0716
Epoch 7 [9/172] - loss: 0.0380
Epoch 7 [10/172] - loss: 0.0385, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0493
Epoch 7 [12/172] - loss: 0.0538
Epoch 7 [13/172] - loss: 0.0554
Epoch 7 [14/172] - loss: 0.0468
Epoch 7 [15/172] - loss: 0.0647
Epoch 7 [16/172] - loss: 0.0415
Epoch 7 [17/172] - loss: 0.0783
Epoch 7 [18/172] - loss: 0.0400
Epoch 7 [19/172] - loss: 0.0819
Epoch 7 [20/172] - loss: 0.0416, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0481
Epoch 7 [22/172] - loss: 0.0410
Epoch 7 [23/172] - loss: 0.0408
Epoch 7 [24/172] - loss: 0.0461
Epoch 7 [25/172] - loss: 0.0423
Epoch 7 [26/172] - loss: 0.0734
Epoch 7 [27/172] - loss: 0.0430
Epoch 7 [28/172] - loss: 0.0555
Epoch 7 [29/172] - loss: 0.0539
Epoch 7 [30/172] - loss: 0.0568, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0417
Epoch 7 [32/172] - loss: 0.0404
Epoch 7 [33/172] - loss: 0.0415
Epoch 7 [34/172] - loss: 0.0410
Epoch 7 [35/172] - loss: 0.0498
Epoch 7 [36/172] - loss: 0.0915
Epoch 7 [37/172] - loss: 0.0396
Epoch 7 [38/172] - loss: 0.0389
Epoch 7 [39/172] - loss: 0.0422
Epoch 7 [40/172] - loss: 0.0385, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0416
Epoch 7 [42/172] - loss: 0.0403
Epoch 7 [43/172] - loss: 0.0469
Epoch 7 [44/172] - loss: 0.0534
Epoch 7 [45/172] - loss: 0.0419
Epoch 7 [46/172] - loss: 0.0533
Epoch 7 [47/172] - loss: 0.0655
Epoch 7 [48/172] - loss: 0.0397
Epoch 7 [49/172] - loss: 0.0379
Epoch 7 [50/172] - loss: 0.0415, acc: 1.0000
Epoch 7 [51/172] - loss: 0.0717
Epoch 7 [52/172] - loss: 0.0395
Epoch 7 [53/172] - loss: 0.0400
Epoch 7 [54/172] - loss: 0.0454
Epoch 7 [55/172] - loss: 0.0405
Epoch 7 [56/172] - loss: 0.0421
Epoch 7 [57/172] - loss: 0.0548
Epoch 7 [58/172] - loss: 0.0473
Epoch 7 [59/172] - loss: 0.0414
Epoch 7 [60/172] - loss: 0.0452, acc: 1.0000
Epoch 7 [61/172] - loss: 0.0459
Epoch 7 [62/172] - loss: 0.0420
Epoch 7 [63/172] - loss: 0.0657
Epoch 7 [64/172] - loss: 0.0435
Epoch 7 [65/172] - loss: 0.0641
Epoch 7 [66/172] - loss: 0.0396
Epoch 7 [67/172] - loss: 0.0509
Epoch 7 [68/172] - loss: 0.0626

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.2067, log_difficulty=0.1879, weight=1.9394
neutral: count=10756.0, difficulty=0.1634, log_difficulty=0.1514, weight=1.7569
negative: count=12072.0, difficulty=0.2108, log_difficulty=0.1913, weight=1.9565

当前batch的pt分布：
positive: min=0.9151, max=0.9980, mean=0.9681
neutral: min=0.9396, max=0.9952, mean=0.9767
negative: min=0.6224, max=0.9811, mean=0.9175

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0563
焦点损失: 0.0022
边界损失: 0.1625
总损失: 0.0438
Epoch 7 [69/172] - loss: 0.0438
Epoch 7 [70/172] - loss: 0.0403, acc: 1.0000
Epoch 7 [71/172] - loss: 0.0458
Epoch 7 [72/172] - loss: 0.0431
Epoch 7 [73/172] - loss: 0.0460
Epoch 7 [74/172] - loss: 0.0382
Epoch 7 [75/172] - loss: 0.0388
Epoch 7 [76/172] - loss: 0.0499
Epoch 7 [77/172] - loss: 0.0406
Epoch 7 [78/172] - loss: 0.0396
Epoch 7 [79/172] - loss: 0.0486
Epoch 7 [80/172] - loss: 0.0487, acc: 1.0000
Epoch 7 [81/172] - loss: 0.0387
Epoch 7 [82/172] - loss: 0.0409
Epoch 7 [83/172] - loss: 0.0614
Epoch 7 [84/172] - loss: 0.0399
Epoch 7 [85/172] - loss: 0.0437
Epoch 7 [86/172] - loss: 0.0405
Epoch 7 [87/172] - loss: 0.0399
Epoch 7 [88/172] - loss: 0.0400
Epoch 7 [89/172] - loss: 0.0433
Epoch 7 [90/172] - loss: 0.0447, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0399
Epoch 7 [92/172] - loss: 0.0420
Epoch 7 [93/172] - loss: 0.0421
Epoch 7 [94/172] - loss: 0.0417
Epoch 7 [95/172] - loss: 0.0399
Epoch 7 [96/172] - loss: 0.0445
Epoch 7 [97/172] - loss: 0.0422
Epoch 7 [98/172] - loss: 0.0736
Epoch 7 [99/172] - loss: 0.0383
Epoch 7 [100/172] - loss: 0.0387, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0385
Epoch 7 [102/172] - loss: 0.0390
Epoch 7 [103/172] - loss: 0.0397
Epoch 7 [104/172] - loss: 0.0403
Epoch 7 [105/172] - loss: 0.0622
Epoch 7 [106/172] - loss: 0.0523
Epoch 7 [107/172] - loss: 0.0382
Epoch 7 [108/172] - loss: 0.0398
Epoch 7 [109/172] - loss: 0.0601
Epoch 7 [110/172] - loss: 0.0486, acc: 1.0000
Epoch 7 [111/172] - loss: 0.0418
Epoch 7 [112/172] - loss: 0.0408
Epoch 7 [113/172] - loss: 0.0382
Epoch 7 [114/172] - loss: 0.0384
Epoch 7 [115/172] - loss: 0.0387
Epoch 7 [116/172] - loss: 0.0847
Epoch 7 [117/172] - loss: 0.0461
Epoch 7 [118/172] - loss: 0.0525
Epoch 7 [119/172] - loss: 0.0430
Epoch 7 [120/172] - loss: 0.0422, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0425
Epoch 7 [122/172] - loss: 0.0396
Epoch 7 [123/172] - loss: 0.0382
Epoch 7 [124/172] - loss: 0.0444
Epoch 7 [125/172] - loss: 0.0571
Epoch 7 [126/172] - loss: 0.0399
Epoch 7 [127/172] - loss: 0.0421
Epoch 7 [128/172] - loss: 0.0396
Epoch 7 [129/172] - loss: 0.0391
Epoch 7 [130/172] - loss: 0.0399, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1058
Epoch 7 [132/172] - loss: 0.1212
Epoch 7 [133/172] - loss: 0.0377
Epoch 7 [134/172] - loss: 0.0605
Epoch 7 [135/172] - loss: 0.0403
Epoch 7 [136/172] - loss: 0.0384
Epoch 7 [137/172] - loss: 0.0522
Epoch 7 [138/172] - loss: 0.0375
Epoch 7 [139/172] - loss: 0.0732
Epoch 7 [140/172] - loss: 0.0392, acc: 1.0000
Epoch 7 [141/172] - loss: 0.0699
Epoch 7 [142/172] - loss: 0.0409
Epoch 7 [143/172] - loss: 0.0502
Epoch 7 [144/172] - loss: 0.0408
Epoch 7 [145/172] - loss: 0.1327
Epoch 7 [146/172] - loss: 0.0794
Epoch 7 [147/172] - loss: 0.0407
Epoch 7 [148/172] - loss: 0.0479
Epoch 7 [149/172] - loss: 0.0464
Epoch 7 [150/172] - loss: 0.0386, acc: 1.0000
Epoch 7 [151/172] - loss: 0.0765
Epoch 7 [152/172] - loss: 0.0371
Epoch 7 [153/172] - loss: 0.0380
Epoch 7 [154/172] - loss: 0.0512
Epoch 7 [155/172] - loss: 0.0406
Epoch 7 [156/172] - loss: 0.0822
Epoch 7 [157/172] - loss: 0.0447
Epoch 7 [158/172] - loss: 0.0538
Epoch 7 [159/172] - loss: 0.0404
Epoch 7 [160/172] - loss: 0.0471, acc: 1.0000
Epoch 7 [161/172] - loss: 0.0429
Epoch 7 [162/172] - loss: 0.0540
Epoch 7 [163/172] - loss: 0.0479
Epoch 7 [164/172] - loss: 0.0554
Epoch 7 [165/172] - loss: 0.0886
Epoch 7 [166/172] - loss: 0.0404
Epoch 7 [167/172] - loss: 0.0465
Epoch 7 [168/172] - loss: 0.0453

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1939, log_difficulty=0.1773, weight=1.8863
neutral: count=11731.0, difficulty=0.1541, log_difficulty=0.1433, weight=1.7166
negative: count=13173.0, difficulty=0.1978, log_difficulty=0.1805, weight=1.9025

当前batch的pt分布：
positive: min=0.8124, max=0.9955, mean=0.9534
neutral: min=0.9431, max=0.9939, mean=0.9790
negative: min=0.6960, max=0.9906, mean=0.9270

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0530
焦点损失: 0.0014
边界损失: 0.1612
总损失: 0.0423
Epoch 7 [169/172] - loss: 0.0423
Epoch 7 [170/172] - loss: 0.0546, acc: 1.0000
Epoch 7 [171/172] - loss: 0.0415
Epoch 7 [172/172] - loss: 0.0370

类别准确率:
positive: 0.8672 (405/467)
neutral: 0.2892 (24/83)
negative: 0.5600 (140/250)

Epoch 7/10
Train Loss: 0.0489, Train Acc: 0.9939
Val Loss: 0.8530, Val Acc: 0.7113
Epoch 8 [1/172] - loss: 0.0390, acc: 1.0000
Epoch 8 [2/172] - loss: 0.0575
Epoch 8 [3/172] - loss: 0.0385
Epoch 8 [4/172] - loss: 0.0401
Epoch 8 [5/172] - loss: 0.0393
Epoch 8 [6/172] - loss: 0.0540
Epoch 8 [7/172] - loss: 0.0391
Epoch 8 [8/172] - loss: 0.0377
Epoch 8 [9/172] - loss: 0.0471
Epoch 8 [10/172] - loss: 0.0514, acc: 0.9688
Epoch 8 [11/172] - loss: 0.0412
Epoch 8 [12/172] - loss: 0.0662
Epoch 8 [13/172] - loss: 0.0415
Epoch 8 [14/172] - loss: 0.0398
Epoch 8 [15/172] - loss: 0.0425
Epoch 8 [16/172] - loss: 0.0403
Epoch 8 [17/172] - loss: 0.0560
Epoch 8 [18/172] - loss: 0.0390
Epoch 8 [19/172] - loss: 0.0430
Epoch 8 [20/172] - loss: 0.0374, acc: 1.0000
Epoch 8 [21/172] - loss: 0.0402
Epoch 8 [22/172] - loss: 0.0454
Epoch 8 [23/172] - loss: 0.0479
Epoch 8 [24/172] - loss: 0.0503
Epoch 8 [25/172] - loss: 0.0408
Epoch 8 [26/172] - loss: 0.0430
Epoch 8 [27/172] - loss: 0.0507
Epoch 8 [28/172] - loss: 0.0651
Epoch 8 [29/172] - loss: 0.0424
Epoch 8 [30/172] - loss: 0.0374, acc: 1.0000
Epoch 8 [31/172] - loss: 0.0387
Epoch 8 [32/172] - loss: 0.0385
Epoch 8 [33/172] - loss: 0.0390
Epoch 8 [34/172] - loss: 0.0469
Epoch 8 [35/172] - loss: 0.0409
Epoch 8 [36/172] - loss: 0.0417
Epoch 8 [37/172] - loss: 0.0512
Epoch 8 [38/172] - loss: 0.0518
Epoch 8 [39/172] - loss: 0.0418
Epoch 8 [40/172] - loss: 0.0385, acc: 1.0000
Epoch 8 [41/172] - loss: 0.0412
Epoch 8 [42/172] - loss: 0.0468
Epoch 8 [43/172] - loss: 0.0448
Epoch 8 [44/172] - loss: 0.0404
Epoch 8 [45/172] - loss: 0.0441
Epoch 8 [46/172] - loss: 0.0423
Epoch 8 [47/172] - loss: 0.0385
Epoch 8 [48/172] - loss: 0.0552
Epoch 8 [49/172] - loss: 0.0387
Epoch 8 [50/172] - loss: 0.0387, acc: 1.0000
Epoch 8 [51/172] - loss: 0.0401
Epoch 8 [52/172] - loss: 0.0383
Epoch 8 [53/172] - loss: 0.0455
Epoch 8 [54/172] - loss: 0.0732
Epoch 8 [55/172] - loss: 0.0413
Epoch 8 [56/172] - loss: 0.0397
Epoch 8 [57/172] - loss: 0.0404
Epoch 8 [58/172] - loss: 0.0395
Epoch 8 [59/172] - loss: 0.0390
Epoch 8 [60/172] - loss: 0.0400, acc: 1.0000
Epoch 8 [61/172] - loss: 0.0401
Epoch 8 [62/172] - loss: 0.0375
Epoch 8 [63/172] - loss: 0.0380
Epoch 8 [64/172] - loss: 0.0387
Epoch 8 [65/172] - loss: 0.0378
Epoch 8 [66/172] - loss: 0.0645
Epoch 8 [67/172] - loss: 0.0402
Epoch 8 [68/172] - loss: 0.0372
Epoch 8 [69/172] - loss: 0.0399
Epoch 8 [70/172] - loss: 0.0428, acc: 1.0000
Epoch 8 [71/172] - loss: 0.0596
Epoch 8 [72/172] - loss: 0.0378
Epoch 8 [73/172] - loss: 0.0598
Epoch 8 [74/172] - loss: 0.0459
Epoch 8 [75/172] - loss: 0.0388
Epoch 8 [76/172] - loss: 0.0844
Epoch 8 [77/172] - loss: 0.0377
Epoch 8 [78/172] - loss: 0.0564
Epoch 8 [79/172] - loss: 0.0500
Epoch 8 [80/172] - loss: 0.0570, acc: 0.9688
Epoch 8 [81/172] - loss: 0.0400
Epoch 8 [82/172] - loss: 0.0382
Epoch 8 [83/172] - loss: 0.0383
Epoch 8 [84/172] - loss: 0.0392
Epoch 8 [85/172] - loss: 0.0402
Epoch 8 [86/172] - loss: 0.0418
Epoch 8 [87/172] - loss: 0.0384
Epoch 8 [88/172] - loss: 0.0677
Epoch 8 [89/172] - loss: 0.0377
Epoch 8 [90/172] - loss: 0.0394, acc: 1.0000
Epoch 8 [91/172] - loss: 0.0571
Epoch 8 [92/172] - loss: 0.0629
Epoch 8 [93/172] - loss: 0.0383
Epoch 8 [94/172] - loss: 0.0452
Epoch 8 [95/172] - loss: 0.0389
Epoch 8 [96/172] - loss: 0.0399

=== 第 1301 次迭代调试信息 ===
当前类别统计：
positive: count=14487.0, difficulty=0.1829, log_difficulty=0.1680, weight=1.8400
neutral: count=12738.0, difficulty=0.1457, log_difficulty=0.1360, weight=1.6800
negative: count=14288.0, difficulty=0.1863, log_difficulty=0.1709, weight=1.8543

当前batch的pt分布：
positive: min=0.5985, max=0.9931, mean=0.9364
neutral: min=0.3696, max=0.9795, mean=0.8599
negative: min=0.8934, max=0.9971, mean=0.9801

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 0.8667
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1159
焦点损失: 0.0256
边界损失: 0.1816
总损失: 0.0779
Epoch 8 [97/172] - loss: 0.0779
Epoch 8 [98/172] - loss: 0.0408
Epoch 8 [99/172] - loss: 0.0407
Epoch 8 [100/172] - loss: 0.0474, acc: 1.0000
Epoch 8 [101/172] - loss: 0.0429
Epoch 8 [102/172] - loss: 0.0529
Epoch 8 [103/172] - loss: 0.0825
Epoch 8 [104/172] - loss: 0.0428
Epoch 8 [105/172] - loss: 0.0404
Epoch 8 [106/172] - loss: 0.0405
Epoch 8 [107/172] - loss: 0.0457
Epoch 8 [108/172] - loss: 0.0390
Epoch 8 [109/172] - loss: 0.1468
Epoch 8 [110/172] - loss: 0.0494, acc: 0.9688
Epoch 8 [111/172] - loss: 0.1045
Epoch 8 [112/172] - loss: 0.0548
Epoch 8 [113/172] - loss: 0.0377
Epoch 8 [114/172] - loss: 0.0378
Epoch 8 [115/172] - loss: 0.0387
Epoch 8 [116/172] - loss: 0.0385
Epoch 8 [117/172] - loss: 0.0383
Epoch 8 [118/172] - loss: 0.0396
Epoch 8 [119/172] - loss: 0.0383
Epoch 8 [120/172] - loss: 0.0399, acc: 1.0000
Epoch 8 [121/172] - loss: 0.0840
Epoch 8 [122/172] - loss: 0.0384
Epoch 8 [123/172] - loss: 0.0394
Epoch 8 [124/172] - loss: 0.0469
Epoch 8 [125/172] - loss: 0.0414
Epoch 8 [126/172] - loss: 0.0398
Epoch 8 [127/172] - loss: 0.0809
Epoch 8 [128/172] - loss: 0.0535
Epoch 8 [129/172] - loss: 0.0400
Epoch 8 [130/172] - loss: 0.0419, acc: 1.0000
Epoch 8 [131/172] - loss: 0.0415
Epoch 8 [132/172] - loss: 0.0465
Epoch 8 [133/172] - loss: 0.0441
Epoch 8 [134/172] - loss: 0.0392
Epoch 8 [135/172] - loss: 0.0401
Epoch 8 [136/172] - loss: 0.0438
Epoch 8 [137/172] - loss: 0.0414
Epoch 8 [138/172] - loss: 0.0847
Epoch 8 [139/172] - loss: 0.0485
Epoch 8 [140/172] - loss: 0.0393, acc: 1.0000
Epoch 8 [141/172] - loss: 0.0371
Epoch 8 [142/172] - loss: 0.0406
Epoch 8 [143/172] - loss: 0.0407
Epoch 8 [144/172] - loss: 0.0439
Epoch 8 [145/172] - loss: 0.0553
Epoch 8 [146/172] - loss: 0.0370
Epoch 8 [147/172] - loss: 0.0389
Epoch 8 [148/172] - loss: 0.0467
Epoch 8 [149/172] - loss: 0.0410
Epoch 8 [150/172] - loss: 0.0389, acc: 1.0000
Epoch 8 [151/172] - loss: 0.0645
Epoch 8 [152/172] - loss: 0.0633
Epoch 8 [153/172] - loss: 0.0417
Epoch 8 [154/172] - loss: 0.0729
Epoch 8 [155/172] - loss: 0.0394
Epoch 8 [156/172] - loss: 0.0399
Epoch 8 [157/172] - loss: 0.0440
Epoch 8 [158/172] - loss: 0.0447
Epoch 8 [159/172] - loss: 0.0477
Epoch 8 [160/172] - loss: 0.0403, acc: 1.0000
Epoch 8 [161/172] - loss: 0.0414
Epoch 8 [162/172] - loss: 0.0594
Epoch 8 [163/172] - loss: 0.0397
Epoch 8 [164/172] - loss: 0.0418
Epoch 8 [165/172] - loss: 0.0376
Epoch 8 [166/172] - loss: 0.0413
Epoch 8 [167/172] - loss: 0.0390
Epoch 8 [168/172] - loss: 0.0394
Epoch 8 [169/172] - loss: 0.0419
Epoch 8 [170/172] - loss: 0.0410, acc: 1.0000
Epoch 8 [171/172] - loss: 0.0495
Epoch 8 [172/172] - loss: 0.0393

类别准确率:
positive: 0.8415 (393/467)
neutral: 0.2771 (23/83)
negative: 0.6640 (166/250)

Epoch 8/10
Train Loss: 0.0430, Train Acc: 0.9960
Val Loss: 0.8555, Val Acc: 0.7275
Epoch 9 [1/172] - loss: 0.0445, acc: 1.0000
Epoch 9 [2/172] - loss: 0.0457
Epoch 9 [3/172] - loss: 0.0389
Epoch 9 [4/172] - loss: 0.0393
Epoch 9 [5/172] - loss: 0.0392
Epoch 9 [6/172] - loss: 0.0390
Epoch 9 [7/172] - loss: 0.0413
Epoch 9 [8/172] - loss: 0.0631
Epoch 9 [9/172] - loss: 0.0396
Epoch 9 [10/172] - loss: 0.0425, acc: 1.0000
Epoch 9 [11/172] - loss: 0.0380
Epoch 9 [12/172] - loss: 0.0450
Epoch 9 [13/172] - loss: 0.0384
Epoch 9 [14/172] - loss: 0.0409
Epoch 9 [15/172] - loss: 0.0525
Epoch 9 [16/172] - loss: 0.0438
Epoch 9 [17/172] - loss: 0.0400
Epoch 9 [18/172] - loss: 0.0375
Epoch 9 [19/172] - loss: 0.0722
Epoch 9 [20/172] - loss: 0.0379, acc: 1.0000
Epoch 9 [21/172] - loss: 0.0406
Epoch 9 [22/172] - loss: 0.0418
Epoch 9 [23/172] - loss: 0.0433
Epoch 9 [24/172] - loss: 0.0373

=== 第 1401 次迭代调试信息 ===
当前类别统计：
positive: count=15648.0, difficulty=0.1732, log_difficulty=0.1597, weight=1.7986
neutral: count=13691.0, difficulty=0.1384, log_difficulty=0.1296, weight=1.6482
negative: count=15357.0, difficulty=0.1767, log_difficulty=0.1627, weight=1.8135

当前batch的pt分布：
positive: min=0.9124, max=0.9948, mean=0.9739
neutral: min=0.9500, max=0.9912, mean=0.9779
negative: min=0.9204, max=0.9876, mean=0.9653

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0284
焦点损失: 0.0001
边界损失: 0.1487
总损失: 0.0373
Epoch 9 [25/172] - loss: 0.0373
Epoch 9 [26/172] - loss: 0.0386
Epoch 9 [27/172] - loss: 0.0416
Epoch 9 [28/172] - loss: 0.0637
Epoch 9 [29/172] - loss: 0.0398
Epoch 9 [30/172] - loss: 0.0470, acc: 1.0000
Epoch 9 [31/172] - loss: 0.0499
Epoch 9 [32/172] - loss: 0.0393
Epoch 9 [33/172] - loss: 0.0976
Epoch 9 [34/172] - loss: 0.0837
Epoch 9 [35/172] - loss: 0.0372
Epoch 9 [36/172] - loss: 0.0556
Epoch 9 [37/172] - loss: 0.0532
Epoch 9 [38/172] - loss: 0.0864
Epoch 9 [39/172] - loss: 0.0390
Epoch 9 [40/172] - loss: 0.0377, acc: 1.0000
Epoch 9 [41/172] - loss: 0.0397
Epoch 9 [42/172] - loss: 0.0378
Epoch 9 [43/172] - loss: 0.0380
Epoch 9 [44/172] - loss: 0.0464
Epoch 9 [45/172] - loss: 0.0443
Epoch 9 [46/172] - loss: 0.0391
Epoch 9 [47/172] - loss: 0.0376
Epoch 9 [48/172] - loss: 0.0469
Epoch 9 [49/172] - loss: 0.0967
Epoch 9 [50/172] - loss: 0.0376, acc: 1.0000
Epoch 9 [51/172] - loss: 0.0442
Epoch 9 [52/172] - loss: 0.0400
Epoch 9 [53/172] - loss: 0.0379
Epoch 9 [54/172] - loss: 0.0432
Epoch 9 [55/172] - loss: 0.1277
Epoch 9 [56/172] - loss: 0.0388
Epoch 9 [57/172] - loss: 0.0410
Epoch 9 [58/172] - loss: 0.0386
Epoch 9 [59/172] - loss: 0.0654
Epoch 9 [60/172] - loss: 0.0400, acc: 1.0000
Epoch 9 [61/172] - loss: 0.0515
Epoch 9 [62/172] - loss: 0.0401
Epoch 9 [63/172] - loss: 0.0890
Epoch 9 [64/172] - loss: 0.0401
Epoch 9 [65/172] - loss: 0.0376
Epoch 9 [66/172] - loss: 0.0639
Epoch 9 [67/172] - loss: 0.0489
Epoch 9 [68/172] - loss: 0.0381
Epoch 9 [69/172] - loss: 0.0392
Epoch 9 [70/172] - loss: 0.0453, acc: 1.0000
Epoch 9 [71/172] - loss: 0.0469
Epoch 9 [72/172] - loss: 0.0590
Epoch 9 [73/172] - loss: 0.0391
Epoch 9 [74/172] - loss: 0.0376
Epoch 9 [75/172] - loss: 0.0408
Epoch 9 [76/172] - loss: 0.0368
Epoch 9 [77/172] - loss: 0.0379
Epoch 9 [78/172] - loss: 0.0502
Epoch 9 [79/172] - loss: 0.0645
Epoch 9 [80/172] - loss: 0.0462, acc: 1.0000
Epoch 9 [81/172] - loss: 0.0407
Epoch 9 [82/172] - loss: 0.1429
Epoch 9 [83/172] - loss: 0.0401
Epoch 9 [84/172] - loss: 0.0528
Epoch 9 [85/172] - loss: 0.0430
Epoch 9 [86/172] - loss: 0.0418
Epoch 9 [87/172] - loss: 0.0443
Epoch 9 [88/172] - loss: 0.0379
Epoch 9 [89/172] - loss: 0.0651
Epoch 9 [90/172] - loss: 0.0388, acc: 1.0000
Epoch 9 [91/172] - loss: 0.0586
Epoch 9 [92/172] - loss: 0.0459
Epoch 9 [93/172] - loss: 0.0475
Epoch 9 [94/172] - loss: 0.0406
Epoch 9 [95/172] - loss: 0.0388
Epoch 9 [96/172] - loss: 0.0422
Epoch 9 [97/172] - loss: 0.0389
Epoch 9 [98/172] - loss: 0.0544
Epoch 9 [99/172] - loss: 0.0412
Epoch 9 [100/172] - loss: 0.0383, acc: 1.0000
Epoch 9 [101/172] - loss: 0.0375
Epoch 9 [102/172] - loss: 0.0408
Epoch 9 [103/172] - loss: 0.0430
Epoch 9 [104/172] - loss: 0.0497
Epoch 9 [105/172] - loss: 0.0417
Epoch 9 [106/172] - loss: 0.0424
Epoch 9 [107/172] - loss: 0.0664
Epoch 9 [108/172] - loss: 0.0403
Epoch 9 [109/172] - loss: 0.0698
Epoch 9 [110/172] - loss: 0.0558, acc: 0.9688
Epoch 9 [111/172] - loss: 0.0394
Epoch 9 [112/172] - loss: 0.0384
Epoch 9 [113/172] - loss: 0.0379
Epoch 9 [114/172] - loss: 0.0381
Epoch 9 [115/172] - loss: 0.0440
Epoch 9 [116/172] - loss: 0.0400
Epoch 9 [117/172] - loss: 0.0412
Epoch 9 [118/172] - loss: 0.0774
Epoch 9 [119/172] - loss: 0.0412
Epoch 9 [120/172] - loss: 0.0442, acc: 1.0000
Epoch 9 [121/172] - loss: 0.0425
Epoch 9 [122/172] - loss: 0.1043
Epoch 9 [123/172] - loss: 0.0383
Epoch 9 [124/172] - loss: 0.0391

=== 第 1501 次迭代调试信息 ===
当前类别统计：
positive: count=16764.0, difficulty=0.1649, log_difficulty=0.1526, weight=1.7632
neutral: count=14673.0, difficulty=0.1321, log_difficulty=0.1241, weight=1.6205
negative: count=16459.0, difficulty=0.1683, log_difficulty=0.1555, weight=1.7777

当前batch的pt分布：
positive: min=0.8130, max=0.9821, mean=0.9217
neutral: min=0.9619, max=0.9912, mean=0.9781
negative: min=0.9919, max=0.9986, mean=0.9948

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0496
焦点损失: 0.0008
边界损失: 0.1601
总损失: 0.0411
Epoch 9 [125/172] - loss: 0.0411
Epoch 9 [126/172] - loss: 0.0386
Epoch 9 [127/172] - loss: 0.0410
Epoch 9 [128/172] - loss: 0.0408
Epoch 9 [129/172] - loss: 0.0413
Epoch 9 [130/172] - loss: 0.0426, acc: 1.0000
Epoch 9 [131/172] - loss: 0.0390
Epoch 9 [132/172] - loss: 0.0584
Epoch 9 [133/172] - loss: 0.0478
Epoch 9 [134/172] - loss: 0.0473
Epoch 9 [135/172] - loss: 0.0412
Epoch 9 [136/172] - loss: 0.0486
Epoch 9 [137/172] - loss: 0.0422
Epoch 9 [138/172] - loss: 0.0424
Epoch 9 [139/172] - loss: 0.0495
Epoch 9 [140/172] - loss: 0.0380, acc: 1.0000
Epoch 9 [141/172] - loss: 0.0382
Epoch 9 [142/172] - loss: 0.0378
Epoch 9 [143/172] - loss: 0.0687
Epoch 9 [144/172] - loss: 0.0383
Epoch 9 [145/172] - loss: 0.0497
Epoch 9 [146/172] - loss: 0.0386
Epoch 9 [147/172] - loss: 0.0492
Epoch 9 [148/172] - loss: 0.0387
Epoch 9 [149/172] - loss: 0.0379
Epoch 9 [150/172] - loss: 0.0386, acc: 1.0000
Epoch 9 [151/172] - loss: 0.0405
Epoch 9 [152/172] - loss: 0.0390
Epoch 9 [153/172] - loss: 0.0449
Epoch 9 [154/172] - loss: 0.0405
Epoch 9 [155/172] - loss: 0.0520
Epoch 9 [156/172] - loss: 0.0790
Epoch 9 [157/172] - loss: 0.0435
Epoch 9 [158/172] - loss: 0.0508
Epoch 9 [159/172] - loss: 0.0382
Epoch 9 [160/172] - loss: 0.0375, acc: 1.0000
Epoch 9 [161/172] - loss: 0.0380
Epoch 9 [162/172] - loss: 0.0586
Epoch 9 [163/172] - loss: 0.0408
Epoch 9 [164/172] - loss: 0.0381
Epoch 9 [165/172] - loss: 0.0368
Epoch 9 [166/172] - loss: 0.0396
Epoch 9 [167/172] - loss: 0.0377
Epoch 9 [168/172] - loss: 0.0370
Epoch 9 [169/172] - loss: 0.0422
Epoch 9 [170/172] - loss: 0.0460, acc: 1.0000
Epoch 9 [171/172] - loss: 0.0483
Epoch 9 [172/172] - loss: 0.0377

类别准确率:
positive: 0.8201 (383/467)
neutral: 0.2892 (24/83)
negative: 0.6640 (166/250)

Epoch 9/10
Train Loss: 0.0419, Train Acc: 0.9980
Val Loss: 0.8625, Val Acc: 0.7163
Epoch 10 [1/172] - loss: 0.0558, acc: 0.9688
Epoch 10 [2/172] - loss: 0.0914
Epoch 10 [3/172] - loss: 0.0379
Epoch 10 [4/172] - loss: 0.0673
Epoch 10 [5/172] - loss: 0.0406
Epoch 10 [6/172] - loss: 0.0420
Epoch 10 [7/172] - loss: 0.0455
Epoch 10 [8/172] - loss: 0.0382
Epoch 10 [9/172] - loss: 0.0538
Epoch 10 [10/172] - loss: 0.0515, acc: 1.0000
Epoch 10 [11/172] - loss: 0.0378
Epoch 10 [12/172] - loss: 0.0385
Epoch 10 [13/172] - loss: 0.0396
Epoch 10 [14/172] - loss: 0.0508
Epoch 10 [15/172] - loss: 0.0380
Epoch 10 [16/172] - loss: 0.0599
Epoch 10 [17/172] - loss: 0.0381
Epoch 10 [18/172] - loss: 0.0496
Epoch 10 [19/172] - loss: 0.0408
Epoch 10 [20/172] - loss: 0.0387, acc: 1.0000
Epoch 10 [21/172] - loss: 0.0418
Epoch 10 [22/172] - loss: 0.0371
Epoch 10 [23/172] - loss: 0.0426
Epoch 10 [24/172] - loss: 0.0667
Epoch 10 [25/172] - loss: 0.0381
Epoch 10 [26/172] - loss: 0.0382
Epoch 10 [27/172] - loss: 0.0373
Epoch 10 [28/172] - loss: 0.0389
Epoch 10 [29/172] - loss: 0.0377
Epoch 10 [30/172] - loss: 0.0381, acc: 1.0000
Epoch 10 [31/172] - loss: 0.0495
Epoch 10 [32/172] - loss: 0.0416
Epoch 10 [33/172] - loss: 0.0373
Epoch 10 [34/172] - loss: 0.0391
Epoch 10 [35/172] - loss: 0.0422
Epoch 10 [36/172] - loss: 0.1398
Epoch 10 [37/172] - loss: 0.0500
Epoch 10 [38/172] - loss: 0.0459
Epoch 10 [39/172] - loss: 0.0945
Epoch 10 [40/172] - loss: 0.1331, acc: 0.9688
Epoch 10 [41/172] - loss: 0.0384
Epoch 10 [42/172] - loss: 0.0428
Epoch 10 [43/172] - loss: 0.0393
Epoch 10 [44/172] - loss: 0.0696
Epoch 10 [45/172] - loss: 0.0383
Epoch 10 [46/172] - loss: 0.0377
Epoch 10 [47/172] - loss: 0.0368
Epoch 10 [48/172] - loss: 0.0451
Epoch 10 [49/172] - loss: 0.0395
Epoch 10 [50/172] - loss: 0.0368, acc: 1.0000
Epoch 10 [51/172] - loss: 0.0399
Epoch 10 [52/172] - loss: 0.0436

=== 第 1601 次迭代调试信息 ===
当前类别统计：
positive: count=17907.0, difficulty=0.1572, log_difficulty=0.1460, weight=1.7302
neutral: count=15634.0, difficulty=0.1265, log_difficulty=0.1191, weight=1.5954
negative: count=17538.0, difficulty=0.1608, log_difficulty=0.1491, weight=1.7456

当前batch的pt分布：
positive: min=0.8204, max=0.9962, mean=0.9565
neutral: min=0.6642, max=0.9912, mean=0.9391
negative: min=0.9432, max=0.9818, mean=0.9692

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0489
焦点损失: 0.0021
边界损失: 0.1592
总损失: 0.0424
Epoch 10 [53/172] - loss: 0.0424
Epoch 10 [54/172] - loss: 0.0472
Epoch 10 [55/172] - loss: 0.0443
Epoch 10 [56/172] - loss: 0.0372
Epoch 10 [57/172] - loss: 0.0386
Epoch 10 [58/172] - loss: 0.0473
Epoch 10 [59/172] - loss: 0.0367
Epoch 10 [60/172] - loss: 0.0403, acc: 1.0000
Epoch 10 [61/172] - loss: 0.0411
Epoch 10 [62/172] - loss: 0.0519
Epoch 10 [63/172] - loss: 0.0594
Epoch 10 [64/172] - loss: 0.0400
Epoch 10 [65/172] - loss: 0.1082
Epoch 10 [66/172] - loss: 0.0462
Epoch 10 [67/172] - loss: 0.0428
Epoch 10 [68/172] - loss: 0.0375
Epoch 10 [69/172] - loss: 0.0371
Epoch 10 [70/172] - loss: 0.0395, acc: 1.0000
Epoch 10 [71/172] - loss: 0.1945
Epoch 10 [72/172] - loss: 0.0384
Epoch 10 [73/172] - loss: 0.0371
Epoch 10 [74/172] - loss: 0.0390
Epoch 10 [75/172] - loss: 0.0436
Epoch 10 [76/172] - loss: 0.0376
Epoch 10 [77/172] - loss: 0.0379
Epoch 10 [78/172] - loss: 0.0417
Epoch 10 [79/172] - loss: 0.0405
Epoch 10 [80/172] - loss: 0.0394, acc: 1.0000
Epoch 10 [81/172] - loss: 0.0462
Epoch 10 [82/172] - loss: 0.0382
Epoch 10 [83/172] - loss: 0.0600
Epoch 10 [84/172] - loss: 0.0383
Epoch 10 [85/172] - loss: 0.0376
Epoch 10 [86/172] - loss: 0.0380
Epoch 10 [87/172] - loss: 0.0379
Epoch 10 [88/172] - loss: 0.0437
Epoch 10 [89/172] - loss: 0.0387
Epoch 10 [90/172] - loss: 0.0561, acc: 0.9688
Epoch 10 [91/172] - loss: 0.0387
Epoch 10 [92/172] - loss: 0.0401
Epoch 10 [93/172] - loss: 0.0442
Epoch 10 [94/172] - loss: 0.0382
Epoch 10 [95/172] - loss: 0.0394
Epoch 10 [96/172] - loss: 0.0451
Epoch 10 [97/172] - loss: 0.0524
Epoch 10 [98/172] - loss: 0.0392
Epoch 10 [99/172] - loss: 0.0367
Epoch 10 [100/172] - loss: 0.0404, acc: 1.0000
Epoch 10 [101/172] - loss: 0.0384
Epoch 10 [102/172] - loss: 0.0370
Epoch 10 [103/172] - loss: 0.0381
Epoch 10 [104/172] - loss: 0.0677
Epoch 10 [105/172] - loss: 0.0387
Epoch 10 [106/172] - loss: 0.0441
Epoch 10 [107/172] - loss: 0.0375
Epoch 10 [108/172] - loss: 0.0446
Epoch 10 [109/172] - loss: 0.0375
Epoch 10 [110/172] - loss: 0.0529, acc: 0.9688
Epoch 10 [111/172] - loss: 0.0452
Epoch 10 [112/172] - loss: 0.0383
Epoch 10 [113/172] - loss: 0.0400
Epoch 10 [114/172] - loss: 0.0395
Epoch 10 [115/172] - loss: 0.0405
Epoch 10 [116/172] - loss: 0.0386
Epoch 10 [117/172] - loss: 0.0517
Epoch 10 [118/172] - loss: 0.0373
Epoch 10 [119/172] - loss: 0.0388
Epoch 10 [120/172] - loss: 0.0750, acc: 0.9688
Epoch 10 [121/172] - loss: 0.0487
Epoch 10 [122/172] - loss: 0.0406
Epoch 10 [123/172] - loss: 0.0789
Epoch 10 [124/172] - loss: 0.0375
Epoch 10 [125/172] - loss: 0.0369
Epoch 10 [126/172] - loss: 0.0440
Epoch 10 [127/172] - loss: 0.0393
Epoch 10 [128/172] - loss: 0.0575
Epoch 10 [129/172] - loss: 0.0368
Epoch 10 [130/172] - loss: 0.0448, acc: 1.0000
Epoch 10 [131/172] - loss: 0.0379
Epoch 10 [132/172] - loss: 0.1032
Epoch 10 [133/172] - loss: 0.0461
Epoch 10 [134/172] - loss: 0.0388
Epoch 10 [135/172] - loss: 0.0640
Epoch 10 [136/172] - loss: 0.0388
Epoch 10 [137/172] - loss: 0.0402
Epoch 10 [138/172] - loss: 0.0387
Epoch 10 [139/172] - loss: 0.0403
Epoch 10 [140/172] - loss: 0.0388, acc: 1.0000
Epoch 10 [141/172] - loss: 0.0403
Epoch 10 [142/172] - loss: 0.0383
Epoch 10 [143/172] - loss: 0.0393
Epoch 10 [144/172] - loss: 0.1195
Epoch 10 [145/172] - loss: 0.0397
Epoch 10 [146/172] - loss: 0.0378
Epoch 10 [147/172] - loss: 0.0372
Epoch 10 [148/172] - loss: 0.0603
Epoch 10 [149/172] - loss: 0.0445
Epoch 10 [150/172] - loss: 0.0390, acc: 1.0000
Epoch 10 [151/172] - loss: 0.0388
Epoch 10 [152/172] - loss: 0.0374

=== 第 1701 次迭代调试信息 ===
当前类别统计：
positive: count=19021.0, difficulty=0.1504, log_difficulty=0.1401, weight=1.7007
neutral: count=16607.0, difficulty=0.1214, log_difficulty=0.1146, weight=1.5729
negative: count=18651.0, difficulty=0.1540, log_difficulty=0.1432, weight=1.7160

当前batch的pt分布：
positive: min=0.8803, max=0.9975, mean=0.9540
neutral: min=0.9304, max=0.9932, mean=0.9800
negative: min=0.6920, max=0.9967, mean=0.9497

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0429
焦点损失: 0.0014
边界损失: 0.1553
总损失: 0.0406
Epoch 10 [153/172] - loss: 0.0406
Epoch 10 [154/172] - loss: 0.0632
Epoch 10 [155/172] - loss: 0.0388
Epoch 10 [156/172] - loss: 0.0380
Epoch 10 [157/172] - loss: 0.0402
Epoch 10 [158/172] - loss: 0.0386
Epoch 10 [159/172] - loss: 0.0413
Epoch 10 [160/172] - loss: 0.0370, acc: 1.0000
Epoch 10 [161/172] - loss: 0.0397
Epoch 10 [162/172] - loss: 0.0657
Epoch 10 [163/172] - loss: 0.0557
Epoch 10 [164/172] - loss: 0.0371
Epoch 10 [165/172] - loss: 0.0421
Epoch 10 [166/172] - loss: 0.0383
Epoch 10 [167/172] - loss: 0.0446
Epoch 10 [168/172] - loss: 0.0380
Epoch 10 [169/172] - loss: 0.0370
Epoch 10 [170/172] - loss: 0.0427, acc: 1.0000
Epoch 10 [171/172] - loss: 0.0479
Epoch 10 [172/172] - loss: 0.0404

类别准确率:
positive: 0.8715 (407/467)
neutral: 0.2771 (23/83)
negative: 0.6200 (155/250)

Epoch 10/10
Train Loss: 0.0429, Train Acc: 0.9960
Val Loss: 0.8818, Val Acc: 0.7312
Best validation accuracy: 0.7312

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_104408-2pdim3o8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.15_Multimodal_iterations_20250118_104407
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/2pdim3o8
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█
wandb:  train_acc ▁▄▄▄▆▅▆▇▆███████▇███████████████████████
wandb: train_loss █▇▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1718
wandb:  train_acc 1
wandb: train_loss 0.0427
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.15_Multimodal_iterations_20250118_104407 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/2pdim3o8
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_104408-2pdim3o8/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_105941-oshb2leh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.15_Multimodal_epochs_20250118_105941
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/oshb2leh
wandb: uploading summary; updating run config
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▃▄▅▆▆▇█
wandb:  train_acc ▁▅▇▇██████
wandb: train_loss █▄▂▂▁▁▁▁▁▁
wandb:    val_acc ▁▇▇▆▆▇▆█▇█
wandb:   val_loss ▄▁▂▄▅▅▇▇▇█
wandb: 
wandb: Run summary:
wandb:      epoch 10
wandb:  train_acc 0.99596
wandb: train_loss 0.04289
wandb:    val_acc 0.73125
wandb:   val_loss 0.88179
wandb: 
wandb: 🚀 View run loss_focal_alpha0.75_beta0.25_weight1.0_dropout0.15_Multimodal_epochs_20250118_105941 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/oshb2leh
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_105941-oshb2leh/logs

