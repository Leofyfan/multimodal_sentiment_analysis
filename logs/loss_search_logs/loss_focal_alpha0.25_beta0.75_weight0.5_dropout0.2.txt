=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 0.5 --dropout 0.2 --name loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.2 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.2
text_dim: 128
image_dim: 256
dropout: 0.2
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6991, log_difficulty=0.5301, weight=3.6505
neutral: count=7.0, difficulty=0.6946, log_difficulty=0.5275, weight=3.6373
negative: count=13.0, difficulty=0.6600, log_difficulty=0.5068, weight=3.5342

当前batch的pt分布：
positive: min=0.1782, max=0.4855, mean=0.3009
neutral: min=0.1602, max=0.4640, mean=0.3054
negative: min=0.1726, max=0.7219, mean=0.3400

当前batch准确率：
整体准确率: 0.2500
positive 准确率: 0.1667
neutral 准确率: 0.2857
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1999
焦点损失: 0.4425
边界损失: 0.7582
总损失: 0.9673
Epoch 1 [1/172] - loss: 0.9673, acc: 0.2500
Epoch 1 [2/172] - loss: 0.9210
Epoch 1 [3/172] - loss: 1.0616
Epoch 1 [4/172] - loss: 0.9563
Epoch 1 [5/172] - loss: 0.9493
Epoch 1 [6/172] - loss: 1.0692
Epoch 1 [7/172] - loss: 0.9797
Epoch 1 [8/172] - loss: 0.9113
Epoch 1 [9/172] - loss: 0.8380
Epoch 1 [10/172] - loss: 0.9658, acc: 0.4062
Epoch 1 [11/172] - loss: 0.9150
Epoch 1 [12/172] - loss: 0.8661
Epoch 1 [13/172] - loss: 0.8155
Epoch 1 [14/172] - loss: 0.8796
Epoch 1 [15/172] - loss: 0.8886
Epoch 1 [16/172] - loss: 0.8783
Epoch 1 [17/172] - loss: 0.9329
Epoch 1 [18/172] - loss: 0.8298
Epoch 1 [19/172] - loss: 0.7696
Epoch 1 [20/172] - loss: 0.9093, acc: 0.3750
Epoch 1 [21/172] - loss: 0.8314
Epoch 1 [22/172] - loss: 0.7811
Epoch 1 [23/172] - loss: 0.9468
Epoch 1 [24/172] - loss: 0.8232
Epoch 1 [25/172] - loss: 0.8350
Epoch 1 [26/172] - loss: 0.7706
Epoch 1 [27/172] - loss: 0.7368
Epoch 1 [28/172] - loss: 0.7063
Epoch 1 [29/172] - loss: 0.7308
Epoch 1 [30/172] - loss: 0.6203, acc: 0.5938
Epoch 1 [31/172] - loss: 0.7288
Epoch 1 [32/172] - loss: 0.6748
Epoch 1 [33/172] - loss: 0.7556
Epoch 1 [34/172] - loss: 0.7214
Epoch 1 [35/172] - loss: 0.8087
Epoch 1 [36/172] - loss: 0.5480
Epoch 1 [37/172] - loss: 0.7042
Epoch 1 [38/172] - loss: 0.7227
Epoch 1 [39/172] - loss: 0.5913
Epoch 1 [40/172] - loss: 0.7342, acc: 0.5938
Epoch 1 [41/172] - loss: 0.6465
Epoch 1 [42/172] - loss: 0.4969
Epoch 1 [43/172] - loss: 0.7354
Epoch 1 [44/172] - loss: 0.7810
Epoch 1 [45/172] - loss: 0.7803
Epoch 1 [46/172] - loss: 0.6479
Epoch 1 [47/172] - loss: 0.6418
Epoch 1 [48/172] - loss: 0.6411
Epoch 1 [49/172] - loss: 0.7390
Epoch 1 [50/172] - loss: 0.5839, acc: 0.7500
Epoch 1 [51/172] - loss: 0.6669
Epoch 1 [52/172] - loss: 0.7633
Epoch 1 [53/172] - loss: 0.6100
Epoch 1 [54/172] - loss: 0.6467
Epoch 1 [55/172] - loss: 0.4438
Epoch 1 [56/172] - loss: 0.5676
Epoch 1 [57/172] - loss: 0.6783
Epoch 1 [58/172] - loss: 0.4725
Epoch 1 [59/172] - loss: 0.7329
Epoch 1 [60/172] - loss: 0.4808, acc: 0.7500
Epoch 1 [61/172] - loss: 0.7519
Epoch 1 [62/172] - loss: 0.4701
Epoch 1 [63/172] - loss: 0.6241
Epoch 1 [64/172] - loss: 0.4849
Epoch 1 [65/172] - loss: 0.6729
Epoch 1 [66/172] - loss: 0.5920
Epoch 1 [67/172] - loss: 0.5247
Epoch 1 [68/172] - loss: 0.5919
Epoch 1 [69/172] - loss: 0.6951
Epoch 1 [70/172] - loss: 0.4941, acc: 0.7812
Epoch 1 [71/172] - loss: 0.4479
Epoch 1 [72/172] - loss: 0.4758
Epoch 1 [73/172] - loss: 0.5149
Epoch 1 [74/172] - loss: 0.5860
Epoch 1 [75/172] - loss: 0.3698
Epoch 1 [76/172] - loss: 0.4754
Epoch 1 [77/172] - loss: 0.4833
Epoch 1 [78/172] - loss: 0.4187
Epoch 1 [79/172] - loss: 0.6599
Epoch 1 [80/172] - loss: 0.3987, acc: 0.7188
Epoch 1 [81/172] - loss: 0.5727
Epoch 1 [82/172] - loss: 0.6150
Epoch 1 [83/172] - loss: 0.6025
Epoch 1 [84/172] - loss: 0.3810
Epoch 1 [85/172] - loss: 0.4415
Epoch 1 [86/172] - loss: 0.6251
Epoch 1 [87/172] - loss: 0.4546
Epoch 1 [88/172] - loss: 0.7333
Epoch 1 [89/172] - loss: 0.7674
Epoch 1 [90/172] - loss: 0.5896, acc: 0.6875
Epoch 1 [91/172] - loss: 0.5803
Epoch 1 [92/172] - loss: 0.5294
Epoch 1 [93/172] - loss: 0.4756
Epoch 1 [94/172] - loss: 0.4080
Epoch 1 [95/172] - loss: 0.5200
Epoch 1 [96/172] - loss: 0.4468
Epoch 1 [97/172] - loss: 0.4623
Epoch 1 [98/172] - loss: 0.4111
Epoch 1 [99/172] - loss: 0.5191
Epoch 1 [100/172] - loss: 0.5371, acc: 0.7188

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5370, log_difficulty=0.4299, weight=3.1493
neutral: count=983.0, difficulty=0.5029, log_difficulty=0.4074, weight=3.0369
negative: count=1119.0, difficulty=0.4935, log_difficulty=0.4011, weight=3.0055

当前batch的pt分布：
positive: min=0.0180, max=0.9720, mean=0.4917
neutral: min=0.4164, max=0.9883, mean=0.7746
negative: min=0.0816, max=0.9428, mean=0.5080

当前batch准确率：
整体准确率: 0.5625
positive 准确率: 0.5000
neutral 准确率: 1.0000
negative 准确率: 0.5000

损失分量：
基础交叉熵: 0.9401
焦点损失: 0.5249
边界损失: 0.3267
总损失: 0.6503
Epoch 1 [101/172] - loss: 0.6503
Epoch 1 [102/172] - loss: 0.5081
Epoch 1 [103/172] - loss: 0.4811
Epoch 1 [104/172] - loss: 0.4724
Epoch 1 [105/172] - loss: 0.5371
Epoch 1 [106/172] - loss: 0.6374
Epoch 1 [107/172] - loss: 0.5079
Epoch 1 [108/172] - loss: 0.5173
Epoch 1 [109/172] - loss: 0.4828
Epoch 1 [110/172] - loss: 0.4976, acc: 0.6250
Epoch 1 [111/172] - loss: 0.4712
Epoch 1 [112/172] - loss: 0.4046
Epoch 1 [113/172] - loss: 0.3436
Epoch 1 [114/172] - loss: 0.3505
Epoch 1 [115/172] - loss: 0.5206
Epoch 1 [116/172] - loss: 0.4750
Epoch 1 [117/172] - loss: 0.4379
Epoch 1 [118/172] - loss: 0.4372
Epoch 1 [119/172] - loss: 0.5304
Epoch 1 [120/172] - loss: 0.3326, acc: 0.8750
Epoch 1 [121/172] - loss: 0.3382
Epoch 1 [122/172] - loss: 0.4889
Epoch 1 [123/172] - loss: 0.3405
Epoch 1 [124/172] - loss: 0.3565
Epoch 1 [125/172] - loss: 0.3435
Epoch 1 [126/172] - loss: 0.6032
Epoch 1 [127/172] - loss: 0.3891
Epoch 1 [128/172] - loss: 0.3285
Epoch 1 [129/172] - loss: 0.4847
Epoch 1 [130/172] - loss: 0.2878, acc: 0.9062
Epoch 1 [131/172] - loss: 0.2743
Epoch 1 [132/172] - loss: 0.4101
Epoch 1 [133/172] - loss: 0.4397
Epoch 1 [134/172] - loss: 0.3104
Epoch 1 [135/172] - loss: 0.4034
Epoch 1 [136/172] - loss: 0.3920
Epoch 1 [137/172] - loss: 0.4249
Epoch 1 [138/172] - loss: 0.3904
Epoch 1 [139/172] - loss: 0.2648
Epoch 1 [140/172] - loss: 0.3064, acc: 0.8438
Epoch 1 [141/172] - loss: 0.4214
Epoch 1 [142/172] - loss: 0.4464
Epoch 1 [143/172] - loss: 0.3642
Epoch 1 [144/172] - loss: 0.3615
Epoch 1 [145/172] - loss: 0.4087
Epoch 1 [146/172] - loss: 0.4318
Epoch 1 [147/172] - loss: 0.5783
Epoch 1 [148/172] - loss: 0.3385
Epoch 1 [149/172] - loss: 0.2993
Epoch 1 [150/172] - loss: 0.5265, acc: 0.6562
Epoch 1 [151/172] - loss: 0.4477
Epoch 1 [152/172] - loss: 0.4919
Epoch 1 [153/172] - loss: 0.3267
Epoch 1 [154/172] - loss: 0.2752
Epoch 1 [155/172] - loss: 0.3688
Epoch 1 [156/172] - loss: 0.5661
Epoch 1 [157/172] - loss: 0.3519
Epoch 1 [158/172] - loss: 0.3506
Epoch 1 [159/172] - loss: 0.4607
Epoch 1 [160/172] - loss: 0.2979, acc: 0.8750
Epoch 1 [161/172] - loss: 0.2266
Epoch 1 [162/172] - loss: 0.3360
Epoch 1 [163/172] - loss: 0.3837
Epoch 1 [164/172] - loss: 0.5105
Epoch 1 [165/172] - loss: 0.3310
Epoch 1 [166/172] - loss: 0.5282
Epoch 1 [167/172] - loss: 0.2642
Epoch 1 [168/172] - loss: 0.4654
Epoch 1 [169/172] - loss: 0.3679
Epoch 1 [170/172] - loss: 0.3839, acc: 0.8438
Epoch 1 [171/172] - loss: 0.2519
Epoch 1 [172/172] - loss: 0.3706

类别准确率:
positive: 0.7709 (360/467)
neutral: 0.4819 (40/83)
negative: 0.6280 (157/250)

Epoch 1/10
Train Loss: 0.3676, Train Acc: 0.8040
Val Loss: 0.6953, Val Acc: 0.6963
Epoch 2 [1/172] - loss: 0.2532, acc: 0.9062
Epoch 2 [2/172] - loss: 0.2659
Epoch 2 [3/172] - loss: 0.2490
Epoch 2 [4/172] - loss: 0.3447
Epoch 2 [5/172] - loss: 0.4071
Epoch 2 [6/172] - loss: 0.3419
Epoch 2 [7/172] - loss: 0.3627
Epoch 2 [8/172] - loss: 0.3576
Epoch 2 [9/172] - loss: 0.3222
Epoch 2 [10/172] - loss: 0.2710, acc: 0.9062
Epoch 2 [11/172] - loss: 0.2368
Epoch 2 [12/172] - loss: 0.2420
Epoch 2 [13/172] - loss: 0.2838
Epoch 2 [14/172] - loss: 0.2883
Epoch 2 [15/172] - loss: 0.3782
Epoch 2 [16/172] - loss: 0.2987
Epoch 2 [17/172] - loss: 0.3594
Epoch 2 [18/172] - loss: 0.3459
Epoch 2 [19/172] - loss: 0.2610
Epoch 2 [20/172] - loss: 0.2556, acc: 0.8438
Epoch 2 [21/172] - loss: 0.2207
Epoch 2 [22/172] - loss: 0.2981
Epoch 2 [23/172] - loss: 0.1734
Epoch 2 [24/172] - loss: 0.5376
Epoch 2 [25/172] - loss: 0.2695
Epoch 2 [26/172] - loss: 0.2051
Epoch 2 [27/172] - loss: 0.2673
Epoch 2 [28/172] - loss: 0.2614

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4449, log_difficulty=0.3681, weight=2.8403
neutral: count=1952.0, difficulty=0.3673, log_difficulty=0.3129, weight=2.5643
negative: count=2216.0, difficulty=0.4087, log_difficulty=0.3427, weight=2.7134

当前batch的pt分布：
positive: min=0.4430, max=0.9821, mean=0.8110
neutral: min=0.8068, max=0.9716, mean=0.9212
negative: min=0.2743, max=0.9874, mean=0.7220

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.8889
neutral 准确率: 1.0000
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.2509
焦点损失: 0.0523
边界损失: 0.2344
总损失: 0.2114
Epoch 2 [29/172] - loss: 0.2114
Epoch 2 [30/172] - loss: 0.2978, acc: 0.8438
Epoch 2 [31/172] - loss: 0.3091
Epoch 2 [32/172] - loss: 0.2369
Epoch 2 [33/172] - loss: 0.2642
Epoch 2 [34/172] - loss: 0.3509
Epoch 2 [35/172] - loss: 0.2304
Epoch 2 [36/172] - loss: 0.3005
Epoch 2 [37/172] - loss: 0.1678
Epoch 2 [38/172] - loss: 0.2315
Epoch 2 [39/172] - loss: 0.3031
Epoch 2 [40/172] - loss: 0.2624, acc: 0.8750
Epoch 2 [41/172] - loss: 0.2960
Epoch 2 [42/172] - loss: 0.1429
Epoch 2 [43/172] - loss: 0.1434
Epoch 2 [44/172] - loss: 0.4186
Epoch 2 [45/172] - loss: 0.2069
Epoch 2 [46/172] - loss: 0.1998
Epoch 2 [47/172] - loss: 0.4169
Epoch 2 [48/172] - loss: 0.2410
Epoch 2 [49/172] - loss: 0.2061
Epoch 2 [50/172] - loss: 0.2757, acc: 0.8750
Epoch 2 [51/172] - loss: 0.2630
Epoch 2 [52/172] - loss: 0.2213
Epoch 2 [53/172] - loss: 0.2695
Epoch 2 [54/172] - loss: 0.1862
Epoch 2 [55/172] - loss: 0.2668
Epoch 2 [56/172] - loss: 0.2290
Epoch 2 [57/172] - loss: 0.1696
Epoch 2 [58/172] - loss: 0.2540
Epoch 2 [59/172] - loss: 0.3989
Epoch 2 [60/172] - loss: 0.2174, acc: 0.8438
Epoch 2 [61/172] - loss: 0.1632
Epoch 2 [62/172] - loss: 0.1734
Epoch 2 [63/172] - loss: 0.2472
Epoch 2 [64/172] - loss: 0.2517
Epoch 2 [65/172] - loss: 0.2489
Epoch 2 [66/172] - loss: 0.2929
Epoch 2 [67/172] - loss: 0.2297
Epoch 2 [68/172] - loss: 0.3260
Epoch 2 [69/172] - loss: 0.2492
Epoch 2 [70/172] - loss: 0.2833, acc: 0.8750
Epoch 2 [71/172] - loss: 0.3039
Epoch 2 [72/172] - loss: 0.2610
Epoch 2 [73/172] - loss: 0.2581
Epoch 2 [74/172] - loss: 0.2400
Epoch 2 [75/172] - loss: 0.2215
Epoch 2 [76/172] - loss: 0.2321
Epoch 2 [77/172] - loss: 0.2216
Epoch 2 [78/172] - loss: 0.3096
Epoch 2 [79/172] - loss: 0.2308
Epoch 2 [80/172] - loss: 0.1547, acc: 1.0000
Epoch 2 [81/172] - loss: 0.1906
Epoch 2 [82/172] - loss: 0.1896
Epoch 2 [83/172] - loss: 0.2709
Epoch 2 [84/172] - loss: 0.2486
Epoch 2 [85/172] - loss: 0.2350
Epoch 2 [86/172] - loss: 0.2484
Epoch 2 [87/172] - loss: 0.4711
Epoch 2 [88/172] - loss: 0.1884
Epoch 2 [89/172] - loss: 0.1606
Epoch 2 [90/172] - loss: 0.2833, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1529
Epoch 2 [92/172] - loss: 0.2603
Epoch 2 [93/172] - loss: 0.2522
Epoch 2 [94/172] - loss: 0.2471
Epoch 2 [95/172] - loss: 0.2932
Epoch 2 [96/172] - loss: 0.1973
Epoch 2 [97/172] - loss: 0.2262
Epoch 2 [98/172] - loss: 0.1727
Epoch 2 [99/172] - loss: 0.1511
Epoch 2 [100/172] - loss: 0.2075, acc: 0.9375
Epoch 2 [101/172] - loss: 0.2206
Epoch 2 [102/172] - loss: 0.1539
Epoch 2 [103/172] - loss: 0.2857
Epoch 2 [104/172] - loss: 0.2420
Epoch 2 [105/172] - loss: 0.2222
Epoch 2 [106/172] - loss: 0.1718
Epoch 2 [107/172] - loss: 0.2037
Epoch 2 [108/172] - loss: 0.4275
Epoch 2 [109/172] - loss: 0.1995
Epoch 2 [110/172] - loss: 0.2497, acc: 0.8750
Epoch 2 [111/172] - loss: 0.2735
Epoch 2 [112/172] - loss: 0.1562
Epoch 2 [113/172] - loss: 0.1505
Epoch 2 [114/172] - loss: 0.1676
Epoch 2 [115/172] - loss: 0.2011
Epoch 2 [116/172] - loss: 0.3233
Epoch 2 [117/172] - loss: 0.2586
Epoch 2 [118/172] - loss: 0.1787
Epoch 2 [119/172] - loss: 0.1968
Epoch 2 [120/172] - loss: 0.1771, acc: 0.9688
Epoch 2 [121/172] - loss: 0.2517
Epoch 2 [122/172] - loss: 0.4243
Epoch 2 [123/172] - loss: 0.2031
Epoch 2 [124/172] - loss: 0.2481
Epoch 2 [125/172] - loss: 0.1604
Epoch 2 [126/172] - loss: 0.2202
Epoch 2 [127/172] - loss: 0.1961
Epoch 2 [128/172] - loss: 0.2455

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3695, log_difficulty=0.3145, weight=2.5723
neutral: count=2949.0, difficulty=0.2837, log_difficulty=0.2498, weight=2.2489
negative: count=3294.0, difficulty=0.3400, log_difficulty=0.2927, weight=2.4633

当前batch的pt分布：
positive: min=0.3733, max=0.9914, mean=0.8858
neutral: min=0.8646, max=0.9931, mean=0.9489
negative: min=0.1156, max=0.9931, mean=0.8078

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.1943
焦点损失: 0.0847
边界损失: 0.1766
总损失: 0.1849
Epoch 2 [129/172] - loss: 0.1849
Epoch 2 [130/172] - loss: 0.2178, acc: 0.9375
Epoch 2 [131/172] - loss: 0.1621
Epoch 2 [132/172] - loss: 0.2136
Epoch 2 [133/172] - loss: 0.1920
Epoch 2 [134/172] - loss: 0.2449
Epoch 2 [135/172] - loss: 0.3196
Epoch 2 [136/172] - loss: 0.2536
Epoch 2 [137/172] - loss: 0.1540
Epoch 2 [138/172] - loss: 0.1618
Epoch 2 [139/172] - loss: 0.3081
Epoch 2 [140/172] - loss: 0.1888, acc: 0.9375
Epoch 2 [141/172] - loss: 0.2650
Epoch 2 [142/172] - loss: 0.2802
Epoch 2 [143/172] - loss: 0.2640
Epoch 2 [144/172] - loss: 0.1705
Epoch 2 [145/172] - loss: 0.4842
Epoch 2 [146/172] - loss: 0.1901
Epoch 2 [147/172] - loss: 0.1416
Epoch 2 [148/172] - loss: 0.2798
Epoch 2 [149/172] - loss: 0.2857
Epoch 2 [150/172] - loss: 0.2297, acc: 0.8438
Epoch 2 [151/172] - loss: 0.2026
Epoch 2 [152/172] - loss: 0.1784
Epoch 2 [153/172] - loss: 0.1964
Epoch 2 [154/172] - loss: 0.2305
Epoch 2 [155/172] - loss: 0.1964
Epoch 2 [156/172] - loss: 0.1776
Epoch 2 [157/172] - loss: 0.1577
Epoch 2 [158/172] - loss: 0.1956
Epoch 2 [159/172] - loss: 0.2098
Epoch 2 [160/172] - loss: 0.2017, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1582
Epoch 2 [162/172] - loss: 0.1622
Epoch 2 [163/172] - loss: 0.2881
Epoch 2 [164/172] - loss: 0.1920
Epoch 2 [165/172] - loss: 0.2692
Epoch 2 [166/172] - loss: 0.2567
Epoch 2 [167/172] - loss: 0.2231
Epoch 2 [168/172] - loss: 0.1875
Epoch 2 [169/172] - loss: 0.1762
Epoch 2 [170/172] - loss: 0.2222, acc: 0.8750
Epoch 2 [171/172] - loss: 0.2390
Epoch 2 [172/172] - loss: 0.5718

类别准确率:
positive: 0.8137 (380/467)
neutral: 0.4337 (36/83)
negative: 0.5960 (149/250)

Epoch 2/10
Train Loss: 0.2319, Train Acc: 0.9192
Val Loss: 0.7761, Val Acc: 0.7063
Epoch 3 [1/172] - loss: 0.1661, acc: 0.9688
Epoch 3 [2/172] - loss: 0.1564
Epoch 3 [3/172] - loss: 0.1307
Epoch 3 [4/172] - loss: 0.1414
Epoch 3 [5/172] - loss: 0.1456
Epoch 3 [6/172] - loss: 0.1440
Epoch 3 [7/172] - loss: 0.1513
Epoch 3 [8/172] - loss: 0.1333
Epoch 3 [9/172] - loss: 0.1931
Epoch 3 [10/172] - loss: 0.1703, acc: 0.9375
Epoch 3 [11/172] - loss: 0.1354
Epoch 3 [12/172] - loss: 0.1210
Epoch 3 [13/172] - loss: 0.1446
Epoch 3 [14/172] - loss: 0.1516
Epoch 3 [15/172] - loss: 0.1333
Epoch 3 [16/172] - loss: 0.2796
Epoch 3 [17/172] - loss: 0.1607
Epoch 3 [18/172] - loss: 0.1707
Epoch 3 [19/172] - loss: 0.1349
Epoch 3 [20/172] - loss: 0.1252, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1618
Epoch 3 [22/172] - loss: 0.1993
Epoch 3 [23/172] - loss: 0.1513
Epoch 3 [24/172] - loss: 0.1406
Epoch 3 [25/172] - loss: 0.1534
Epoch 3 [26/172] - loss: 0.1476
Epoch 3 [27/172] - loss: 0.1278
Epoch 3 [28/172] - loss: 0.1166
Epoch 3 [29/172] - loss: 0.1928
Epoch 3 [30/172] - loss: 0.1493, acc: 0.9688
Epoch 3 [31/172] - loss: 0.1160
Epoch 3 [32/172] - loss: 0.1509
Epoch 3 [33/172] - loss: 0.1435
Epoch 3 [34/172] - loss: 0.1758
Epoch 3 [35/172] - loss: 0.1665
Epoch 3 [36/172] - loss: 0.1367
Epoch 3 [37/172] - loss: 0.1981
Epoch 3 [38/172] - loss: 0.1528
Epoch 3 [39/172] - loss: 0.1166
Epoch 3 [40/172] - loss: 0.1842, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1282
Epoch 3 [42/172] - loss: 0.1661
Epoch 3 [43/172] - loss: 0.1477
Epoch 3 [44/172] - loss: 0.1390
Epoch 3 [45/172] - loss: 0.1807
Epoch 3 [46/172] - loss: 0.1874
Epoch 3 [47/172] - loss: 0.1252
Epoch 3 [48/172] - loss: 0.1736
Epoch 3 [49/172] - loss: 0.1208
Epoch 3 [50/172] - loss: 0.1325, acc: 1.0000
Epoch 3 [51/172] - loss: 0.1796
Epoch 3 [52/172] - loss: 0.2189
Epoch 3 [53/172] - loss: 0.1247
Epoch 3 [54/172] - loss: 0.1615
Epoch 3 [55/172] - loss: 0.1608
Epoch 3 [56/172] - loss: 0.1505

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3143, log_difficulty=0.2733, weight=2.3664
neutral: count=3923.0, difficulty=0.2326, log_difficulty=0.2091, weight=2.0457
negative: count=4382.0, difficulty=0.2864, log_difficulty=0.2518, weight=2.2592

当前batch的pt分布：
positive: min=0.6066, max=0.9965, mean=0.8967
neutral: min=0.0097, max=0.9962, mean=0.8509
negative: min=0.9912, max=0.9980, mean=0.9954

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2345
焦点损失: 0.1458
边界损失: 0.1810
总损失: 0.2106
Epoch 3 [57/172] - loss: 0.2106
Epoch 3 [58/172] - loss: 0.1310
Epoch 3 [59/172] - loss: 0.1604
Epoch 3 [60/172] - loss: 0.1637, acc: 0.9062
Epoch 3 [61/172] - loss: 0.1286
Epoch 3 [62/172] - loss: 0.1667
Epoch 3 [63/172] - loss: 0.1300
Epoch 3 [64/172] - loss: 0.1639
Epoch 3 [65/172] - loss: 0.1535
Epoch 3 [66/172] - loss: 0.2149
Epoch 3 [67/172] - loss: 0.1270
Epoch 3 [68/172] - loss: 0.1261
Epoch 3 [69/172] - loss: 0.2048
Epoch 3 [70/172] - loss: 0.1524, acc: 0.9688
Epoch 3 [71/172] - loss: 0.1615
Epoch 3 [72/172] - loss: 0.1654
Epoch 3 [73/172] - loss: 0.1254
Epoch 3 [74/172] - loss: 0.1755
Epoch 3 [75/172] - loss: 0.1306
Epoch 3 [76/172] - loss: 0.1279
Epoch 3 [77/172] - loss: 0.1260
Epoch 3 [78/172] - loss: 0.2215
Epoch 3 [79/172] - loss: 0.1243
Epoch 3 [80/172] - loss: 0.2176, acc: 0.9375
Epoch 3 [81/172] - loss: 0.1607
Epoch 3 [82/172] - loss: 0.1414
Epoch 3 [83/172] - loss: 0.1464
Epoch 3 [84/172] - loss: 0.1267
Epoch 3 [85/172] - loss: 0.1226
Epoch 3 [86/172] - loss: 0.1169
Epoch 3 [87/172] - loss: 0.1798
Epoch 3 [88/172] - loss: 0.1220
Epoch 3 [89/172] - loss: 0.1328
Epoch 3 [90/172] - loss: 0.1212, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1788
Epoch 3 [92/172] - loss: 0.1849
Epoch 3 [93/172] - loss: 0.2334
Epoch 3 [94/172] - loss: 0.1618
Epoch 3 [95/172] - loss: 0.1241
Epoch 3 [96/172] - loss: 0.1402
Epoch 3 [97/172] - loss: 0.1369
Epoch 3 [98/172] - loss: 0.1560
Epoch 3 [99/172] - loss: 0.1242
Epoch 3 [100/172] - loss: 0.1765, acc: 0.9375
Epoch 3 [101/172] - loss: 0.1532
Epoch 3 [102/172] - loss: 0.1188
Epoch 3 [103/172] - loss: 0.1752
Epoch 3 [104/172] - loss: 0.1467
Epoch 3 [105/172] - loss: 0.1344
Epoch 3 [106/172] - loss: 0.1486
Epoch 3 [107/172] - loss: 0.2001
Epoch 3 [108/172] - loss: 0.1282
Epoch 3 [109/172] - loss: 0.1165
Epoch 3 [110/172] - loss: 0.1273, acc: 1.0000
Epoch 3 [111/172] - loss: 0.1544
Epoch 3 [112/172] - loss: 0.1247
Epoch 3 [113/172] - loss: 0.1262
Epoch 3 [114/172] - loss: 0.1264
Epoch 3 [115/172] - loss: 0.1620
Epoch 3 [116/172] - loss: 0.1191
Epoch 3 [117/172] - loss: 0.1789
Epoch 3 [118/172] - loss: 0.1487
Epoch 3 [119/172] - loss: 0.1171
Epoch 3 [120/172] - loss: 0.1404, acc: 0.9688
Epoch 3 [121/172] - loss: 0.2204
Epoch 3 [122/172] - loss: 0.1979
Epoch 3 [123/172] - loss: 0.1301
Epoch 3 [124/172] - loss: 0.1157
Epoch 3 [125/172] - loss: 0.1328
Epoch 3 [126/172] - loss: 0.2080
Epoch 3 [127/172] - loss: 0.1794
Epoch 3 [128/172] - loss: 0.1278
Epoch 3 [129/172] - loss: 0.1229
Epoch 3 [130/172] - loss: 0.1184, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1409
Epoch 3 [132/172] - loss: 0.1209
Epoch 3 [133/172] - loss: 0.1242
Epoch 3 [134/172] - loss: 0.1147
Epoch 3 [135/172] - loss: 0.1145
Epoch 3 [136/172] - loss: 0.1519
Epoch 3 [137/172] - loss: 0.1146
Epoch 3 [138/172] - loss: 0.1578
Epoch 3 [139/172] - loss: 0.1257
Epoch 3 [140/172] - loss: 0.1271, acc: 1.0000
Epoch 3 [141/172] - loss: 0.1615
Epoch 3 [142/172] - loss: 0.1604
Epoch 3 [143/172] - loss: 0.1240
Epoch 3 [144/172] - loss: 0.1736
Epoch 3 [145/172] - loss: 0.1613
Epoch 3 [146/172] - loss: 0.1315
Epoch 3 [147/172] - loss: 0.1418
Epoch 3 [148/172] - loss: 0.1174
Epoch 3 [149/172] - loss: 0.1162
Epoch 3 [150/172] - loss: 0.1289, acc: 1.0000
Epoch 3 [151/172] - loss: 0.2165
Epoch 3 [152/172] - loss: 0.2329
Epoch 3 [153/172] - loss: 0.1220
Epoch 3 [154/172] - loss: 0.1669
Epoch 3 [155/172] - loss: 0.1175
Epoch 3 [156/172] - loss: 0.1217

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2689, log_difficulty=0.2382, weight=2.1908
neutral: count=4903.0, difficulty=0.1959, log_difficulty=0.1789, weight=1.8944
negative: count=5500.0, difficulty=0.2466, log_difficulty=0.2204, weight=2.1021

当前batch的pt分布：
positive: min=0.7278, max=0.9950, mean=0.9521
neutral: min=0.8067, max=0.9957, mean=0.9695
negative: min=0.1576, max=0.9997, mean=0.8935

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.0943
焦点损失: 0.0407
边界损失: 0.1558
总损失: 0.1382
Epoch 3 [157/172] - loss: 0.1382
Epoch 3 [158/172] - loss: 0.2469
Epoch 3 [159/172] - loss: 0.1406
Epoch 3 [160/172] - loss: 0.1591, acc: 0.9688
Epoch 3 [161/172] - loss: 0.1469
Epoch 3 [162/172] - loss: 0.1393
Epoch 3 [163/172] - loss: 0.1482
Epoch 3 [164/172] - loss: 0.1245
Epoch 3 [165/172] - loss: 0.1341
Epoch 3 [166/172] - loss: 0.1370
Epoch 3 [167/172] - loss: 0.1309
Epoch 3 [168/172] - loss: 0.1363
Epoch 3 [169/172] - loss: 0.1199
Epoch 3 [170/172] - loss: 0.1446, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1315
Epoch 3 [172/172] - loss: 0.1221

类别准确率:
positive: 0.8715 (407/467)
neutral: 0.2651 (22/83)
negative: 0.5720 (143/250)

Epoch 3/10
Train Loss: 0.1438, Train Acc: 0.9697
Val Loss: 0.8686, Val Acc: 0.7150
Epoch 4 [1/172] - loss: 0.1120, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1813
Epoch 4 [3/172] - loss: 0.1262
Epoch 4 [4/172] - loss: 0.1299
Epoch 4 [5/172] - loss: 0.1564
Epoch 4 [6/172] - loss: 0.1191
Epoch 4 [7/172] - loss: 0.1242
Epoch 4 [8/172] - loss: 0.1108
Epoch 4 [9/172] - loss: 0.1569
Epoch 4 [10/172] - loss: 0.1229, acc: 0.9688
Epoch 4 [11/172] - loss: 0.1202
Epoch 4 [12/172] - loss: 0.1223
Epoch 4 [13/172] - loss: 0.1418
Epoch 4 [14/172] - loss: 0.1410
Epoch 4 [15/172] - loss: 0.1115
Epoch 4 [16/172] - loss: 0.1155
Epoch 4 [17/172] - loss: 0.1246
Epoch 4 [18/172] - loss: 0.1232
Epoch 4 [19/172] - loss: 0.1239
Epoch 4 [20/172] - loss: 0.1235, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1788
Epoch 4 [22/172] - loss: 0.1126
Epoch 4 [23/172] - loss: 0.1339
Epoch 4 [24/172] - loss: 0.1078
Epoch 4 [25/172] - loss: 0.1158
Epoch 4 [26/172] - loss: 0.3002
Epoch 4 [27/172] - loss: 0.1104
Epoch 4 [28/172] - loss: 0.1460
Epoch 4 [29/172] - loss: 0.1072
Epoch 4 [30/172] - loss: 0.1185, acc: 1.0000
Epoch 4 [31/172] - loss: 0.1426
Epoch 4 [32/172] - loss: 0.1594
Epoch 4 [33/172] - loss: 0.1131
Epoch 4 [34/172] - loss: 0.1281
Epoch 4 [35/172] - loss: 0.1211
Epoch 4 [36/172] - loss: 0.1141
Epoch 4 [37/172] - loss: 0.1106
Epoch 4 [38/172] - loss: 0.1198
Epoch 4 [39/172] - loss: 0.2169
Epoch 4 [40/172] - loss: 0.1658, acc: 0.9375
Epoch 4 [41/172] - loss: 0.1128
Epoch 4 [42/172] - loss: 0.1160
Epoch 4 [43/172] - loss: 0.1298
Epoch 4 [44/172] - loss: 0.1417
Epoch 4 [45/172] - loss: 0.1073
Epoch 4 [46/172] - loss: 0.1156
Epoch 4 [47/172] - loss: 0.1241
Epoch 4 [48/172] - loss: 0.1167
Epoch 4 [49/172] - loss: 0.1210
Epoch 4 [50/172] - loss: 0.1133, acc: 1.0000
Epoch 4 [51/172] - loss: 0.1129
Epoch 4 [52/172] - loss: 0.1325
Epoch 4 [53/172] - loss: 0.1101
Epoch 4 [54/172] - loss: 0.1527
Epoch 4 [55/172] - loss: 0.1909
Epoch 4 [56/172] - loss: 0.1117
Epoch 4 [57/172] - loss: 0.1123
Epoch 4 [58/172] - loss: 0.1122
Epoch 4 [59/172] - loss: 0.1263
Epoch 4 [60/172] - loss: 0.1566, acc: 0.9688
Epoch 4 [61/172] - loss: 0.1274
Epoch 4 [62/172] - loss: 0.1531
Epoch 4 [63/172] - loss: 0.1150
Epoch 4 [64/172] - loss: 0.1106
Epoch 4 [65/172] - loss: 0.1486
Epoch 4 [66/172] - loss: 0.1110
Epoch 4 [67/172] - loss: 0.1368
Epoch 4 [68/172] - loss: 0.1148
Epoch 4 [69/172] - loss: 0.1303
Epoch 4 [70/172] - loss: 0.1150, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1309
Epoch 4 [72/172] - loss: 0.1176
Epoch 4 [73/172] - loss: 0.1133
Epoch 4 [74/172] - loss: 0.1916
Epoch 4 [75/172] - loss: 0.1512
Epoch 4 [76/172] - loss: 0.1072
Epoch 4 [77/172] - loss: 0.1215
Epoch 4 [78/172] - loss: 0.1237
Epoch 4 [79/172] - loss: 0.1114
Epoch 4 [80/172] - loss: 0.1406, acc: 0.9688
Epoch 4 [81/172] - loss: 0.1490
Epoch 4 [82/172] - loss: 0.1152
Epoch 4 [83/172] - loss: 0.1126
Epoch 4 [84/172] - loss: 0.1118

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2339, log_difficulty=0.2102, weight=2.0511
neutral: count=5865.0, difficulty=0.1705, log_difficulty=0.1575, weight=1.7874
negative: count=6629.0, difficulty=0.2155, log_difficulty=0.1951, weight=1.9757

当前batch的pt分布：
positive: min=0.6182, max=0.9963, mean=0.9116
neutral: min=0.7712, max=0.9996, mean=0.9652
negative: min=0.0250, max=0.9988, mean=0.8788

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.1768
焦点损失: 0.1121
边界损失: 0.1645
总损失: 0.1788
Epoch 4 [85/172] - loss: 0.1788
Epoch 4 [86/172] - loss: 0.1358
Epoch 4 [87/172] - loss: 0.1188
Epoch 4 [88/172] - loss: 0.1091
Epoch 4 [89/172] - loss: 0.1082
Epoch 4 [90/172] - loss: 0.1156, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1799
Epoch 4 [92/172] - loss: 0.1742
Epoch 4 [93/172] - loss: 0.1087
Epoch 4 [94/172] - loss: 0.1128
Epoch 4 [95/172] - loss: 0.1380
Epoch 4 [96/172] - loss: 0.1195
Epoch 4 [97/172] - loss: 0.1121
Epoch 4 [98/172] - loss: 0.1108
Epoch 4 [99/172] - loss: 0.1139
Epoch 4 [100/172] - loss: 0.1210, acc: 0.9688
Epoch 4 [101/172] - loss: 0.1107
Epoch 4 [102/172] - loss: 0.1273
Epoch 4 [103/172] - loss: 0.1235
Epoch 4 [104/172] - loss: 0.1087
Epoch 4 [105/172] - loss: 0.1399
Epoch 4 [106/172] - loss: 0.1078
Epoch 4 [107/172] - loss: 0.1085
Epoch 4 [108/172] - loss: 0.1248
Epoch 4 [109/172] - loss: 0.1398
Epoch 4 [110/172] - loss: 0.1846, acc: 0.9062
Epoch 4 [111/172] - loss: 0.1111
Epoch 4 [112/172] - loss: 0.1094
Epoch 4 [113/172] - loss: 0.1079
Epoch 4 [114/172] - loss: 0.1127
Epoch 4 [115/172] - loss: 0.1179
Epoch 4 [116/172] - loss: 0.1241
Epoch 4 [117/172] - loss: 0.1089
Epoch 4 [118/172] - loss: 0.1192
Epoch 4 [119/172] - loss: 0.1073
Epoch 4 [120/172] - loss: 0.1105, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1740
Epoch 4 [122/172] - loss: 0.2174
Epoch 4 [123/172] - loss: 0.1172
Epoch 4 [124/172] - loss: 0.1075
Epoch 4 [125/172] - loss: 0.1375
Epoch 4 [126/172] - loss: 0.1449
Epoch 4 [127/172] - loss: 0.1298
Epoch 4 [128/172] - loss: 0.1061
Epoch 4 [129/172] - loss: 0.1093
Epoch 4 [130/172] - loss: 0.1066, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1060
Epoch 4 [132/172] - loss: 0.1075
Epoch 4 [133/172] - loss: 0.1186
Epoch 4 [134/172] - loss: 0.1128
Epoch 4 [135/172] - loss: 0.1502
Epoch 4 [136/172] - loss: 0.1431
Epoch 4 [137/172] - loss: 0.1162
Epoch 4 [138/172] - loss: 0.1393
Epoch 4 [139/172] - loss: 0.1166
Epoch 4 [140/172] - loss: 0.1265, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1421
Epoch 4 [142/172] - loss: 0.1163
Epoch 4 [143/172] - loss: 0.1120
Epoch 4 [144/172] - loss: 0.1132
Epoch 4 [145/172] - loss: 0.2498
Epoch 4 [146/172] - loss: 0.1138
Epoch 4 [147/172] - loss: 0.1079
Epoch 4 [148/172] - loss: 0.1221
Epoch 4 [149/172] - loss: 0.1190
Epoch 4 [150/172] - loss: 0.1337, acc: 1.0000
Epoch 4 [151/172] - loss: 0.1963
Epoch 4 [152/172] - loss: 0.1658
Epoch 4 [153/172] - loss: 0.1218
Epoch 4 [154/172] - loss: 0.1462
Epoch 4 [155/172] - loss: 0.1107
Epoch 4 [156/172] - loss: 0.1179
Epoch 4 [157/172] - loss: 0.2000
Epoch 4 [158/172] - loss: 0.1200
Epoch 4 [159/172] - loss: 0.1083
Epoch 4 [160/172] - loss: 0.1164, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1873
Epoch 4 [162/172] - loss: 0.1160
Epoch 4 [163/172] - loss: 0.1198
Epoch 4 [164/172] - loss: 0.1145
Epoch 4 [165/172] - loss: 0.1819
Epoch 4 [166/172] - loss: 0.1276
Epoch 4 [167/172] - loss: 0.2155
Epoch 4 [168/172] - loss: 0.1151
Epoch 4 [169/172] - loss: 0.1828
Epoch 4 [170/172] - loss: 0.1374, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1185
Epoch 4 [172/172] - loss: 0.1177

类别准确率:
positive: 0.8565 (400/467)
neutral: 0.2410 (20/83)
negative: 0.6120 (153/250)

Epoch 4/10
Train Loss: 0.1424, Train Acc: 0.9636
Val Loss: 0.8556, Val Acc: 0.7163
Epoch 5 [1/172] - loss: 0.1087, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1209
Epoch 5 [3/172] - loss: 0.1115
Epoch 5 [4/172] - loss: 0.1250
Epoch 5 [5/172] - loss: 0.1205
Epoch 5 [6/172] - loss: 0.1366
Epoch 5 [7/172] - loss: 0.1138
Epoch 5 [8/172] - loss: 0.1864
Epoch 5 [9/172] - loss: 0.1705
Epoch 5 [10/172] - loss: 0.1232, acc: 0.9688
Epoch 5 [11/172] - loss: 0.1498
Epoch 5 [12/172] - loss: 0.1104

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2078, log_difficulty=0.1888, weight=1.9438
neutral: count=6845.0, difficulty=0.1511, log_difficulty=0.1407, weight=1.7036
negative: count=7694.0, difficulty=0.1926, log_difficulty=0.1761, weight=1.8806

当前batch的pt分布：
positive: min=0.0018, max=0.9980, mean=0.8917
neutral: min=0.9803, max=0.9995, mean=0.9958
negative: min=0.9247, max=0.9981, mean=0.9735

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2245
焦点损失: 0.1966
边界损失: 0.1476
总损失: 0.2063
Epoch 5 [13/172] - loss: 0.2063
Epoch 5 [14/172] - loss: 0.1884
Epoch 5 [15/172] - loss: 0.1121
Epoch 5 [16/172] - loss: 0.1152
Epoch 5 [17/172] - loss: 0.1342
Epoch 5 [18/172] - loss: 0.1155
Epoch 5 [19/172] - loss: 0.1408
Epoch 5 [20/172] - loss: 0.1163, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1526
Epoch 5 [22/172] - loss: 0.1853
Epoch 5 [23/172] - loss: 0.1152
Epoch 5 [24/172] - loss: 0.1183
Epoch 5 [25/172] - loss: 0.1093
Epoch 5 [26/172] - loss: 0.1227
Epoch 5 [27/172] - loss: 0.1095
Epoch 5 [28/172] - loss: 0.1117
Epoch 5 [29/172] - loss: 0.1118
Epoch 5 [30/172] - loss: 0.1210, acc: 0.9688
Epoch 5 [31/172] - loss: 0.1227
Epoch 5 [32/172] - loss: 0.1103
Epoch 5 [33/172] - loss: 0.1101
Epoch 5 [34/172] - loss: 0.1115
Epoch 5 [35/172] - loss: 0.1122
Epoch 5 [36/172] - loss: 0.1066
Epoch 5 [37/172] - loss: 0.1290
Epoch 5 [38/172] - loss: 0.1260
Epoch 5 [39/172] - loss: 0.1466
Epoch 5 [40/172] - loss: 0.1232, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1086
Epoch 5 [42/172] - loss: 0.1106
Epoch 5 [43/172] - loss: 0.1694
Epoch 5 [44/172] - loss: 0.1266
Epoch 5 [45/172] - loss: 0.1068
Epoch 5 [46/172] - loss: 0.1284
Epoch 5 [47/172] - loss: 0.1119
Epoch 5 [48/172] - loss: 0.1228
Epoch 5 [49/172] - loss: 0.1237
Epoch 5 [50/172] - loss: 0.1196, acc: 1.0000
Epoch 5 [51/172] - loss: 0.1111
Epoch 5 [52/172] - loss: 0.1229
Epoch 5 [53/172] - loss: 0.1361
Epoch 5 [54/172] - loss: 0.1083
Epoch 5 [55/172] - loss: 0.1767
Epoch 5 [56/172] - loss: 0.1193
Epoch 5 [57/172] - loss: 0.1094
Epoch 5 [58/172] - loss: 0.1212
Epoch 5 [59/172] - loss: 0.1159
Epoch 5 [60/172] - loss: 0.1095, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1120
Epoch 5 [62/172] - loss: 0.1080
Epoch 5 [63/172] - loss: 0.1471
Epoch 5 [64/172] - loss: 0.1694
Epoch 5 [65/172] - loss: 0.1083
Epoch 5 [66/172] - loss: 0.1252
Epoch 5 [67/172] - loss: 0.1072
Epoch 5 [68/172] - loss: 0.1127
Epoch 5 [69/172] - loss: 0.1094
Epoch 5 [70/172] - loss: 0.1255, acc: 0.9688
Epoch 5 [71/172] - loss: 0.1145
Epoch 5 [72/172] - loss: 0.1312
Epoch 5 [73/172] - loss: 0.1136
Epoch 5 [74/172] - loss: 0.1197
Epoch 5 [75/172] - loss: 0.1085
Epoch 5 [76/172] - loss: 0.1348
Epoch 5 [77/172] - loss: 0.1111
Epoch 5 [78/172] - loss: 0.1673
Epoch 5 [79/172] - loss: 0.1148
Epoch 5 [80/172] - loss: 0.1101, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1941
Epoch 5 [82/172] - loss: 0.1348
Epoch 5 [83/172] - loss: 0.1117
Epoch 5 [84/172] - loss: 0.1113
Epoch 5 [85/172] - loss: 0.1750
Epoch 5 [86/172] - loss: 0.1094
Epoch 5 [87/172] - loss: 0.1249
Epoch 5 [88/172] - loss: 0.1837
Epoch 5 [89/172] - loss: 0.1106
Epoch 5 [90/172] - loss: 0.1652, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1215
Epoch 5 [92/172] - loss: 0.1133
Epoch 5 [93/172] - loss: 0.1182
Epoch 5 [94/172] - loss: 0.1075
Epoch 5 [95/172] - loss: 0.1144
Epoch 5 [96/172] - loss: 0.1143
Epoch 5 [97/172] - loss: 0.1446
Epoch 5 [98/172] - loss: 0.1154
Epoch 5 [99/172] - loss: 0.2016
Epoch 5 [100/172] - loss: 0.1129, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1119
Epoch 5 [102/172] - loss: 0.1243
Epoch 5 [103/172] - loss: 0.1271
Epoch 5 [104/172] - loss: 0.2230
Epoch 5 [105/172] - loss: 0.2339
Epoch 5 [106/172] - loss: 0.1258
Epoch 5 [107/172] - loss: 0.1358
Epoch 5 [108/172] - loss: 0.1359
Epoch 5 [109/172] - loss: 0.1101
Epoch 5 [110/172] - loss: 0.1170, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1482
Epoch 5 [112/172] - loss: 0.1132

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.1875, log_difficulty=0.1719, weight=1.8593
neutral: count=7825.0, difficulty=0.1359, log_difficulty=0.1274, weight=1.6371
negative: count=8780.0, difficulty=0.1754, log_difficulty=0.1616, weight=1.8081

当前batch的pt分布：
positive: min=0.2716, max=0.9974, mean=0.8838
neutral: min=0.8631, max=0.9977, mean=0.9633
negative: min=0.9951, max=1.0000, mean=0.9982

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0929
焦点损失: 0.0231
边界损失: 0.1665
总损失: 0.1356
Epoch 5 [113/172] - loss: 0.1356
Epoch 5 [114/172] - loss: 0.1676
Epoch 5 [115/172] - loss: 0.1369
Epoch 5 [116/172] - loss: 0.1134
Epoch 5 [117/172] - loss: 0.1155
Epoch 5 [118/172] - loss: 0.1205
Epoch 5 [119/172] - loss: 0.1114
Epoch 5 [120/172] - loss: 0.1217, acc: 1.0000
Epoch 5 [121/172] - loss: 0.1454
Epoch 5 [122/172] - loss: 0.1132
Epoch 5 [123/172] - loss: 0.1299
Epoch 5 [124/172] - loss: 0.1229
Epoch 5 [125/172] - loss: 0.1082
Epoch 5 [126/172] - loss: 0.1113
Epoch 5 [127/172] - loss: 0.1278
Epoch 5 [128/172] - loss: 0.1175
Epoch 5 [129/172] - loss: 0.1595
Epoch 5 [130/172] - loss: 0.1089, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1677
Epoch 5 [132/172] - loss: 0.1732
Epoch 5 [133/172] - loss: 0.1320
Epoch 5 [134/172] - loss: 0.1298
Epoch 5 [135/172] - loss: 0.1100
Epoch 5 [136/172] - loss: 0.1086
Epoch 5 [137/172] - loss: 0.2109
Epoch 5 [138/172] - loss: 0.1375
Epoch 5 [139/172] - loss: 0.2481
Epoch 5 [140/172] - loss: 0.1366, acc: 0.9688
Epoch 5 [141/172] - loss: 0.1074
Epoch 5 [142/172] - loss: 0.1104
Epoch 5 [143/172] - loss: 0.1066
Epoch 5 [144/172] - loss: 0.1059
Epoch 5 [145/172] - loss: 0.1316
Epoch 5 [146/172] - loss: 0.1073
Epoch 5 [147/172] - loss: 0.1249
Epoch 5 [148/172] - loss: 0.1088
Epoch 5 [149/172] - loss: 0.1071
Epoch 5 [150/172] - loss: 0.1362, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1100
Epoch 5 [152/172] - loss: 0.1218
Epoch 5 [153/172] - loss: 0.1058
Epoch 5 [154/172] - loss: 0.1136
Epoch 5 [155/172] - loss: 0.1633
Epoch 5 [156/172] - loss: 0.1213
Epoch 5 [157/172] - loss: 0.1177
Epoch 5 [158/172] - loss: 0.1052
Epoch 5 [159/172] - loss: 0.1080
Epoch 5 [160/172] - loss: 0.1074, acc: 1.0000
Epoch 5 [161/172] - loss: 0.1205
Epoch 5 [162/172] - loss: 0.1239
Epoch 5 [163/172] - loss: 0.1605
Epoch 5 [164/172] - loss: 0.1122
Epoch 5 [165/172] - loss: 0.1577
Epoch 5 [166/172] - loss: 0.1219
Epoch 5 [167/172] - loss: 0.1116
Epoch 5 [168/172] - loss: 0.1064
Epoch 5 [169/172] - loss: 0.1140
Epoch 5 [170/172] - loss: 0.1072, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1170
Epoch 5 [172/172] - loss: 0.1379

类别准确率:
positive: 0.7794 (364/467)
neutral: 0.2892 (24/83)
negative: 0.7280 (182/250)

Epoch 5/10
Train Loss: 0.1206, Train Acc: 0.9859
Val Loss: 0.9691, Val Acc: 0.7125
Epoch 6 [1/172] - loss: 0.1151, acc: 1.0000
Epoch 6 [2/172] - loss: 0.1212
Epoch 6 [3/172] - loss: 0.1066
Epoch 6 [4/172] - loss: 0.1133
Epoch 6 [5/172] - loss: 0.1546
Epoch 6 [6/172] - loss: 0.1279
Epoch 6 [7/172] - loss: 0.1240
Epoch 6 [8/172] - loss: 0.1232
Epoch 6 [9/172] - loss: 0.1097
Epoch 6 [10/172] - loss: 0.1760, acc: 0.9688
Epoch 6 [11/172] - loss: 0.1060
Epoch 6 [12/172] - loss: 0.1083
Epoch 6 [13/172] - loss: 0.1422
Epoch 6 [14/172] - loss: 0.1065
Epoch 6 [15/172] - loss: 0.1096
Epoch 6 [16/172] - loss: 0.1148
Epoch 6 [17/172] - loss: 0.1154
Epoch 6 [18/172] - loss: 0.1099
Epoch 6 [19/172] - loss: 0.1060
Epoch 6 [20/172] - loss: 0.1122, acc: 1.0000
Epoch 6 [21/172] - loss: 0.1074
Epoch 6 [22/172] - loss: 0.1051
Epoch 6 [23/172] - loss: 0.1163
Epoch 6 [24/172] - loss: 0.1250
Epoch 6 [25/172] - loss: 0.1144
Epoch 6 [26/172] - loss: 0.1189
Epoch 6 [27/172] - loss: 0.1789
Epoch 6 [28/172] - loss: 0.1418
Epoch 6 [29/172] - loss: 0.1090
Epoch 6 [30/172] - loss: 0.1074, acc: 1.0000
Epoch 6 [31/172] - loss: 0.1097
Epoch 6 [32/172] - loss: 0.1050
Epoch 6 [33/172] - loss: 0.1061
Epoch 6 [34/172] - loss: 0.1093
Epoch 6 [35/172] - loss: 0.1061
Epoch 6 [36/172] - loss: 0.1243
Epoch 6 [37/172] - loss: 0.1112
Epoch 6 [38/172] - loss: 0.1078
Epoch 6 [39/172] - loss: 0.1156
Epoch 6 [40/172] - loss: 0.1180, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1710, log_difficulty=0.1579, weight=1.7895
neutral: count=8815.0, difficulty=0.1249, log_difficulty=0.1177, weight=1.5884
negative: count=9870.0, difficulty=0.1600, log_difficulty=0.1484, weight=1.7419

当前batch的pt分布：
positive: min=0.0292, max=0.9998, mean=0.9054
neutral: min=0.9758, max=0.9983, mean=0.9929
negative: min=0.9030, max=0.9969, mean=0.9793

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1222
焦点损失: 0.1042
边界损失: 0.1413
总损失: 0.1525
Epoch 6 [41/172] - loss: 0.1525
Epoch 6 [42/172] - loss: 0.1081
Epoch 6 [43/172] - loss: 0.1749
Epoch 6 [44/172] - loss: 0.1063
Epoch 6 [45/172] - loss: 0.1286
Epoch 6 [46/172] - loss: 0.1146
Epoch 6 [47/172] - loss: 0.1127
Epoch 6 [48/172] - loss: 0.1061
Epoch 6 [49/172] - loss: 0.1103
Epoch 6 [50/172] - loss: 0.1403, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1411
Epoch 6 [52/172] - loss: 0.1148
Epoch 6 [53/172] - loss: 0.1060
Epoch 6 [54/172] - loss: 0.1526
Epoch 6 [55/172] - loss: 0.1232
Epoch 6 [56/172] - loss: 0.1072
Epoch 6 [57/172] - loss: 0.1130
Epoch 6 [58/172] - loss: 0.1057
Epoch 6 [59/172] - loss: 0.1216
Epoch 6 [60/172] - loss: 0.1235, acc: 0.9688
Epoch 6 [61/172] - loss: 0.1100
Epoch 6 [62/172] - loss: 0.1205
Epoch 6 [63/172] - loss: 0.1101
Epoch 6 [64/172] - loss: 0.1889
Epoch 6 [65/172] - loss: 0.1149
Epoch 6 [66/172] - loss: 0.1116
Epoch 6 [67/172] - loss: 0.1084
Epoch 6 [68/172] - loss: 0.1566
Epoch 6 [69/172] - loss: 0.1238
Epoch 6 [70/172] - loss: 0.1086, acc: 1.0000
Epoch 6 [71/172] - loss: 0.1077
Epoch 6 [72/172] - loss: 0.1136
Epoch 6 [73/172] - loss: 0.1316
Epoch 6 [74/172] - loss: 0.1068
Epoch 6 [75/172] - loss: 0.1257
Epoch 6 [76/172] - loss: 0.1094
Epoch 6 [77/172] - loss: 0.1207
Epoch 6 [78/172] - loss: 0.1213
Epoch 6 [79/172] - loss: 0.1057
Epoch 6 [80/172] - loss: 0.1114, acc: 1.0000
Epoch 6 [81/172] - loss: 0.1235
Epoch 6 [82/172] - loss: 0.1152
Epoch 6 [83/172] - loss: 0.1060
Epoch 6 [84/172] - loss: 0.1050
Epoch 6 [85/172] - loss: 0.1609
Epoch 6 [86/172] - loss: 0.1230
Epoch 6 [87/172] - loss: 0.1096
Epoch 6 [88/172] - loss: 0.1280
Epoch 6 [89/172] - loss: 0.1078
Epoch 6 [90/172] - loss: 0.1042, acc: 1.0000
Epoch 6 [91/172] - loss: 0.1094
Epoch 6 [92/172] - loss: 0.1061
Epoch 6 [93/172] - loss: 0.1110
Epoch 6 [94/172] - loss: 0.1207
Epoch 6 [95/172] - loss: 0.1144
Epoch 6 [96/172] - loss: 0.1083
Epoch 6 [97/172] - loss: 0.1074
Epoch 6 [98/172] - loss: 0.1079
Epoch 6 [99/172] - loss: 0.1067
Epoch 6 [100/172] - loss: 0.1091, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1359
Epoch 6 [102/172] - loss: 0.1071
Epoch 6 [103/172] - loss: 0.1129
Epoch 6 [104/172] - loss: 0.1427
Epoch 6 [105/172] - loss: 0.1104
Epoch 6 [106/172] - loss: 0.1132
Epoch 6 [107/172] - loss: 0.1102
Epoch 6 [108/172] - loss: 0.1237
Epoch 6 [109/172] - loss: 0.1589
Epoch 6 [110/172] - loss: 0.1078, acc: 1.0000
Epoch 6 [111/172] - loss: 0.1074
Epoch 6 [112/172] - loss: 0.1045
Epoch 6 [113/172] - loss: 0.1066
Epoch 6 [114/172] - loss: 0.1047
Epoch 6 [115/172] - loss: 0.1195
Epoch 6 [116/172] - loss: 0.1727
Epoch 6 [117/172] - loss: 0.1064
Epoch 6 [118/172] - loss: 0.1099
Epoch 6 [119/172] - loss: 0.1902
Epoch 6 [120/172] - loss: 0.1071, acc: 1.0000
Epoch 6 [121/172] - loss: 0.1078
Epoch 6 [122/172] - loss: 0.1092
Epoch 6 [123/172] - loss: 0.1061
Epoch 6 [124/172] - loss: 0.1140
Epoch 6 [125/172] - loss: 0.1116
Epoch 6 [126/172] - loss: 0.1268
Epoch 6 [127/172] - loss: 0.1618
Epoch 6 [128/172] - loss: 0.1256
Epoch 6 [129/172] - loss: 0.1073
Epoch 6 [130/172] - loss: 0.1635, acc: 0.9375
Epoch 6 [131/172] - loss: 0.1101
Epoch 6 [132/172] - loss: 0.1288
Epoch 6 [133/172] - loss: 0.1056
Epoch 6 [134/172] - loss: 0.1050
Epoch 6 [135/172] - loss: 0.1182
Epoch 6 [136/172] - loss: 0.1055
Epoch 6 [137/172] - loss: 0.1079
Epoch 6 [138/172] - loss: 0.1097
Epoch 6 [139/172] - loss: 0.1304
Epoch 6 [140/172] - loss: 0.1108, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1575, log_difficulty=0.1463, weight=1.7314
neutral: count=9796.0, difficulty=0.1149, log_difficulty=0.1087, weight=1.5437
negative: count=10972.0, difficulty=0.1473, log_difficulty=0.1375, weight=1.6873

当前batch的pt分布：
positive: min=0.9963, max=0.9993, mean=0.9979
neutral: min=0.9889, max=0.9992, mean=0.9943
negative: min=0.8866, max=0.9982, mean=0.9769

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0121
焦点损失: 0.0001
边界损失: 0.1409
总损失: 0.1057
Epoch 6 [141/172] - loss: 0.1057
Epoch 6 [142/172] - loss: 0.1063
Epoch 6 [143/172] - loss: 0.1292
Epoch 6 [144/172] - loss: 0.1067
Epoch 6 [145/172] - loss: 0.1060
Epoch 6 [146/172] - loss: 0.1056
Epoch 6 [147/172] - loss: 0.1142
Epoch 6 [148/172] - loss: 0.1063
Epoch 6 [149/172] - loss: 0.1072
Epoch 6 [150/172] - loss: 0.1081, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1123
Epoch 6 [152/172] - loss: 0.1091
Epoch 6 [153/172] - loss: 0.1152
Epoch 6 [154/172] - loss: 0.1047
Epoch 6 [155/172] - loss: 0.1301
Epoch 6 [156/172] - loss: 0.1366
Epoch 6 [157/172] - loss: 0.1047
Epoch 6 [158/172] - loss: 0.1132
Epoch 6 [159/172] - loss: 0.1370
Epoch 6 [160/172] - loss: 0.1319, acc: 0.9688
Epoch 6 [161/172] - loss: 0.1083
Epoch 6 [162/172] - loss: 0.1072
Epoch 6 [163/172] - loss: 0.1079
Epoch 6 [164/172] - loss: 0.1287
Epoch 6 [165/172] - loss: 0.2534
Epoch 6 [166/172] - loss: 0.1110
Epoch 6 [167/172] - loss: 0.1242
Epoch 6 [168/172] - loss: 0.1170
Epoch 6 [169/172] - loss: 0.1185
Epoch 6 [170/172] - loss: 0.1091, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1159
Epoch 6 [172/172] - loss: 0.1296

类别准确率:
positive: 0.8887 (415/467)
neutral: 0.3012 (25/83)
negative: 0.4760 (119/250)

Epoch 6/10
Train Loss: 0.1261, Train Acc: 0.9859
Val Loss: 1.1500, Val Acc: 0.6987
Epoch 7 [1/172] - loss: 0.1226, acc: 0.9688
Epoch 7 [2/172] - loss: 0.1045
Epoch 7 [3/172] - loss: 0.1048
Epoch 7 [4/172] - loss: 0.1057
Epoch 7 [5/172] - loss: 0.1051
Epoch 7 [6/172] - loss: 0.1070
Epoch 7 [7/172] - loss: 0.1227
Epoch 7 [8/172] - loss: 0.1213
Epoch 7 [9/172] - loss: 0.1056
Epoch 7 [10/172] - loss: 0.1063, acc: 1.0000
Epoch 7 [11/172] - loss: 0.1051
Epoch 7 [12/172] - loss: 0.1460
Epoch 7 [13/172] - loss: 0.1121
Epoch 7 [14/172] - loss: 0.1082
Epoch 7 [15/172] - loss: 0.1278
Epoch 7 [16/172] - loss: 0.1530
Epoch 7 [17/172] - loss: 0.1436
Epoch 7 [18/172] - loss: 0.1079
Epoch 7 [19/172] - loss: 0.1144
Epoch 7 [20/172] - loss: 0.1058, acc: 1.0000
Epoch 7 [21/172] - loss: 0.1112
Epoch 7 [22/172] - loss: 0.1073
Epoch 7 [23/172] - loss: 0.1102
Epoch 7 [24/172] - loss: 0.1060
Epoch 7 [25/172] - loss: 0.1093
Epoch 7 [26/172] - loss: 0.1164
Epoch 7 [27/172] - loss: 0.1073
Epoch 7 [28/172] - loss: 0.1132
Epoch 7 [29/172] - loss: 0.1260
Epoch 7 [30/172] - loss: 0.1485, acc: 0.9688
Epoch 7 [31/172] - loss: 0.1067
Epoch 7 [32/172] - loss: 0.1078
Epoch 7 [33/172] - loss: 0.1106
Epoch 7 [34/172] - loss: 0.1059
Epoch 7 [35/172] - loss: 0.1331
Epoch 7 [36/172] - loss: 0.1434
Epoch 7 [37/172] - loss: 0.1073
Epoch 7 [38/172] - loss: 0.1072
Epoch 7 [39/172] - loss: 0.1061
Epoch 7 [40/172] - loss: 0.1049, acc: 1.0000
Epoch 7 [41/172] - loss: 0.1076
Epoch 7 [42/172] - loss: 0.1072
Epoch 7 [43/172] - loss: 0.1095
Epoch 7 [44/172] - loss: 0.1248
Epoch 7 [45/172] - loss: 0.1081
Epoch 7 [46/172] - loss: 0.1186
Epoch 7 [47/172] - loss: 0.1347
Epoch 7 [48/172] - loss: 0.1050
Epoch 7 [49/172] - loss: 0.1143
Epoch 7 [50/172] - loss: 0.1079, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1599
Epoch 7 [52/172] - loss: 0.1179
Epoch 7 [53/172] - loss: 0.1071
Epoch 7 [54/172] - loss: 0.1156
Epoch 7 [55/172] - loss: 0.1084
Epoch 7 [56/172] - loss: 0.1064
Epoch 7 [57/172] - loss: 0.1192
Epoch 7 [58/172] - loss: 0.1087
Epoch 7 [59/172] - loss: 0.1065
Epoch 7 [60/172] - loss: 0.1109, acc: 1.0000
Epoch 7 [61/172] - loss: 0.1203
Epoch 7 [62/172] - loss: 0.1065
Epoch 7 [63/172] - loss: 0.1306
Epoch 7 [64/172] - loss: 0.1134
Epoch 7 [65/172] - loss: 0.1266
Epoch 7 [66/172] - loss: 0.1105
Epoch 7 [67/172] - loss: 0.1076
Epoch 7 [68/172] - loss: 0.1653

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1457, log_difficulty=0.1360, weight=1.6802
neutral: count=10756.0, difficulty=0.1065, log_difficulty=0.1012, weight=1.5060
negative: count=12072.0, difficulty=0.1371, log_difficulty=0.1285, weight=1.6426

当前batch的pt分布：
positive: min=0.9841, max=0.9995, mean=0.9954
neutral: min=0.9964, max=0.9993, mean=0.9980
negative: min=0.9445, max=0.9980, mean=0.9786

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0114
焦点损失: 0.0000
边界损失: 0.1403
总损失: 0.1052
Epoch 7 [69/172] - loss: 0.1052
Epoch 7 [70/172] - loss: 0.1152, acc: 0.9688
Epoch 7 [71/172] - loss: 0.1091
Epoch 7 [72/172] - loss: 0.1134
Epoch 7 [73/172] - loss: 0.1072
Epoch 7 [74/172] - loss: 0.1053
Epoch 7 [75/172] - loss: 0.1045
Epoch 7 [76/172] - loss: 0.1062
Epoch 7 [77/172] - loss: 0.1060
Epoch 7 [78/172] - loss: 0.1064
Epoch 7 [79/172] - loss: 0.1127
Epoch 7 [80/172] - loss: 0.1337, acc: 0.9375
Epoch 7 [81/172] - loss: 0.1040
Epoch 7 [82/172] - loss: 0.1071
Epoch 7 [83/172] - loss: 0.1263
Epoch 7 [84/172] - loss: 0.1050
Epoch 7 [85/172] - loss: 0.1103
Epoch 7 [86/172] - loss: 0.1060
Epoch 7 [87/172] - loss: 0.1093
Epoch 7 [88/172] - loss: 0.1045
Epoch 7 [89/172] - loss: 0.1071
Epoch 7 [90/172] - loss: 0.1050, acc: 1.0000
Epoch 7 [91/172] - loss: 0.1069
Epoch 7 [92/172] - loss: 0.1059
Epoch 7 [93/172] - loss: 0.1110
Epoch 7 [94/172] - loss: 0.1045
Epoch 7 [95/172] - loss: 0.1068
Epoch 7 [96/172] - loss: 0.1073
Epoch 7 [97/172] - loss: 0.1086
Epoch 7 [98/172] - loss: 0.1221
Epoch 7 [99/172] - loss: 0.1051
Epoch 7 [100/172] - loss: 0.1094, acc: 1.0000
Epoch 7 [101/172] - loss: 0.1046
Epoch 7 [102/172] - loss: 0.1060
Epoch 7 [103/172] - loss: 0.1054
Epoch 7 [104/172] - loss: 0.1057
Epoch 7 [105/172] - loss: 0.1507
Epoch 7 [106/172] - loss: 0.1138
Epoch 7 [107/172] - loss: 0.1053
Epoch 7 [108/172] - loss: 0.1057
Epoch 7 [109/172] - loss: 0.1291
Epoch 7 [110/172] - loss: 0.1096, acc: 1.0000
Epoch 7 [111/172] - loss: 0.1063
Epoch 7 [112/172] - loss: 0.1091
Epoch 7 [113/172] - loss: 0.1048
Epoch 7 [114/172] - loss: 0.1044
Epoch 7 [115/172] - loss: 0.1152
Epoch 7 [116/172] - loss: 0.1248
Epoch 7 [117/172] - loss: 0.1704
Epoch 7 [118/172] - loss: 0.1286
Epoch 7 [119/172] - loss: 0.1065
Epoch 7 [120/172] - loss: 0.1058, acc: 1.0000
Epoch 7 [121/172] - loss: 0.1101
Epoch 7 [122/172] - loss: 0.1056
Epoch 7 [123/172] - loss: 0.1041
Epoch 7 [124/172] - loss: 0.1162
Epoch 7 [125/172] - loss: 0.1042
Epoch 7 [126/172] - loss: 0.1038
Epoch 7 [127/172] - loss: 0.1170
Epoch 7 [128/172] - loss: 0.1061
Epoch 7 [129/172] - loss: 0.1056
Epoch 7 [130/172] - loss: 0.1060, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1370
Epoch 7 [132/172] - loss: 0.1638
Epoch 7 [133/172] - loss: 0.1037
Epoch 7 [134/172] - loss: 0.1059
Epoch 7 [135/172] - loss: 0.1081
Epoch 7 [136/172] - loss: 0.1240
Epoch 7 [137/172] - loss: 0.1146
Epoch 7 [138/172] - loss: 0.1044
Epoch 7 [139/172] - loss: 0.1206
Epoch 7 [140/172] - loss: 0.1064, acc: 1.0000
Epoch 7 [141/172] - loss: 0.1193
Epoch 7 [142/172] - loss: 0.1060
Epoch 7 [143/172] - loss: 0.1102
Epoch 7 [144/172] - loss: 0.1076
Epoch 7 [145/172] - loss: 0.1291
Epoch 7 [146/172] - loss: 0.1419
Epoch 7 [147/172] - loss: 0.1068
Epoch 7 [148/172] - loss: 0.1205
Epoch 7 [149/172] - loss: 0.1128
Epoch 7 [150/172] - loss: 0.1072, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1363
Epoch 7 [152/172] - loss: 0.1040
Epoch 7 [153/172] - loss: 0.1292
Epoch 7 [154/172] - loss: 0.1250
Epoch 7 [155/172] - loss: 0.1063
Epoch 7 [156/172] - loss: 0.1401
Epoch 7 [157/172] - loss: 0.1067
Epoch 7 [158/172] - loss: 0.1079
Epoch 7 [159/172] - loss: 0.1066
Epoch 7 [160/172] - loss: 0.1106, acc: 1.0000
Epoch 7 [161/172] - loss: 0.1070
Epoch 7 [162/172] - loss: 0.1089
Epoch 7 [163/172] - loss: 0.1086
Epoch 7 [164/172] - loss: 0.1095
Epoch 7 [165/172] - loss: 0.1207
Epoch 7 [166/172] - loss: 0.1078
Epoch 7 [167/172] - loss: 0.1132
Epoch 7 [168/172] - loss: 0.1060

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1354, log_difficulty=0.1270, weight=1.6348
neutral: count=11731.0, difficulty=0.0994, log_difficulty=0.0948, weight=1.4740
negative: count=13173.0, difficulty=0.1276, log_difficulty=0.1201, weight=1.6006

当前batch的pt分布：
positive: min=0.9867, max=0.9986, mean=0.9947
neutral: min=0.9839, max=0.9992, mean=0.9965
negative: min=0.9043, max=0.9995, mean=0.9836

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0092
焦点损失: 0.0000
边界损失: 0.1392
总损失: 0.1044
Epoch 7 [169/172] - loss: 0.1044
Epoch 7 [170/172] - loss: 0.1655, acc: 0.9375
Epoch 7 [171/172] - loss: 0.1054
Epoch 7 [172/172] - loss: 0.1036

类别准确率:
positive: 0.8651 (404/467)
neutral: 0.2771 (23/83)
negative: 0.5560 (139/250)

Epoch 7/10
Train Loss: 0.1120, Train Acc: 0.9960
Val Loss: 1.0949, Val Acc: 0.7075
Early stopping triggered!
Best validation accuracy: 0.7163

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_044255-7o7zuznd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.2_Multimodal_iterations_20250118_044254
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/7o7zuznd
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇█████
wandb:  train_acc ▁▂▄▆▆▇▇▇█▇█▇▇▇██▇███████▇█████████▇█████
wandb: train_loss ██▃▅▅▂▃▃▃▂▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 0.9375
wandb: train_loss 0.16555
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.2_Multimodal_iterations_20250118_044254 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/7o7zuznd
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_044255-7o7zuznd/logs
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_045317-lmpc7psc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.2_Multimodal_epochs_20250118_045317
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/lmpc7psc
wandb: uploading summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▅▇▇███
wandb: train_loss █▄▂▂▁▁▁
wandb:    val_acc ▁▅██▇▂▅
wandb:   val_loss ▁▂▄▃▅█▇
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.99596
wandb: train_loss 0.11204
wandb:    val_acc 0.7075
wandb:   val_loss 1.09491
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight0.5_dropout0.2_Multimodal_epochs_20250118_045317 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/lmpc7psc
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_045317-lmpc7psc/logs

