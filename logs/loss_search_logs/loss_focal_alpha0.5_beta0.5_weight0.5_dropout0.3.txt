=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 0.5 --dropout 0.3 --name loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.3 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.3
text_dim: 128
image_dim: 256
dropout: 0.3
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6879, log_difficulty=0.5235, weight=3.6173
neutral: count=7.0, difficulty=0.6721, log_difficulty=0.5141, weight=3.5705
negative: count=13.0, difficulty=0.6390, log_difficulty=0.4941, weight=3.4706

当前batch的pt分布：
positive: min=0.1802, max=0.4115, mean=0.3121
neutral: min=0.2126, max=0.4141, mean=0.3279
negative: min=0.1951, max=0.7183, mean=0.3610

当前batch准确率：
整体准确率: 0.2188
positive 准确率: 0.1667
neutral 准确率: 0.1429
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1326
焦点损失: 0.3818
边界损失: 0.8404
总损失: 1.0986
Epoch 1 [1/172] - loss: 1.0986, acc: 0.2188
Epoch 1 [2/172] - loss: 1.1160
Epoch 1 [3/172] - loss: 1.1310
Epoch 1 [4/172] - loss: 1.0695
Epoch 1 [5/172] - loss: 1.0095
Epoch 1 [6/172] - loss: 1.3890
Epoch 1 [7/172] - loss: 1.0181
Epoch 1 [8/172] - loss: 1.2211
Epoch 1 [9/172] - loss: 1.0984
Epoch 1 [10/172] - loss: 1.1358, acc: 0.2812
Epoch 1 [11/172] - loss: 1.1695
Epoch 1 [12/172] - loss: 1.0193
Epoch 1 [13/172] - loss: 0.9218
Epoch 1 [14/172] - loss: 1.0400
Epoch 1 [15/172] - loss: 1.1523
Epoch 1 [16/172] - loss: 0.9107
Epoch 1 [17/172] - loss: 1.0838
Epoch 1 [18/172] - loss: 0.8272
Epoch 1 [19/172] - loss: 0.9678
Epoch 1 [20/172] - loss: 0.9348, acc: 0.4375
Epoch 1 [21/172] - loss: 0.9957
Epoch 1 [22/172] - loss: 0.9048
Epoch 1 [23/172] - loss: 1.0219
Epoch 1 [24/172] - loss: 1.0362
Epoch 1 [25/172] - loss: 0.8336
Epoch 1 [26/172] - loss: 0.9167
Epoch 1 [27/172] - loss: 1.0819
Epoch 1 [28/172] - loss: 0.8663
Epoch 1 [29/172] - loss: 1.0580
Epoch 1 [30/172] - loss: 0.7641, acc: 0.6562
Epoch 1 [31/172] - loss: 0.9714
Epoch 1 [32/172] - loss: 0.8822
Epoch 1 [33/172] - loss: 0.9625
Epoch 1 [34/172] - loss: 0.8586
Epoch 1 [35/172] - loss: 0.9377
Epoch 1 [36/172] - loss: 0.7809
Epoch 1 [37/172] - loss: 0.8622
Epoch 1 [38/172] - loss: 0.9069
Epoch 1 [39/172] - loss: 0.7587
Epoch 1 [40/172] - loss: 0.8337, acc: 0.5625
Epoch 1 [41/172] - loss: 0.8594
Epoch 1 [42/172] - loss: 0.6282
Epoch 1 [43/172] - loss: 0.7816
Epoch 1 [44/172] - loss: 1.1356
Epoch 1 [45/172] - loss: 0.8731
Epoch 1 [46/172] - loss: 0.9741
Epoch 1 [47/172] - loss: 1.1114
Epoch 1 [48/172] - loss: 0.9042
Epoch 1 [49/172] - loss: 1.0113
Epoch 1 [50/172] - loss: 0.7853, acc: 0.5000
Epoch 1 [51/172] - loss: 0.8534
Epoch 1 [52/172] - loss: 0.8217
Epoch 1 [53/172] - loss: 0.9817
Epoch 1 [54/172] - loss: 0.7897
Epoch 1 [55/172] - loss: 0.7124
Epoch 1 [56/172] - loss: 0.8882
Epoch 1 [57/172] - loss: 0.8640
Epoch 1 [58/172] - loss: 0.5830
Epoch 1 [59/172] - loss: 0.7944
Epoch 1 [60/172] - loss: 0.6296, acc: 0.6875
Epoch 1 [61/172] - loss: 0.8803
Epoch 1 [62/172] - loss: 0.7074
Epoch 1 [63/172] - loss: 0.6927
Epoch 1 [64/172] - loss: 0.7533
Epoch 1 [65/172] - loss: 0.6813
Epoch 1 [66/172] - loss: 0.8341
Epoch 1 [67/172] - loss: 0.8071
Epoch 1 [68/172] - loss: 0.8823
Epoch 1 [69/172] - loss: 0.7971
Epoch 1 [70/172] - loss: 0.6738, acc: 0.7188
Epoch 1 [71/172] - loss: 0.5260
Epoch 1 [72/172] - loss: 0.6808
Epoch 1 [73/172] - loss: 0.7084
Epoch 1 [74/172] - loss: 0.8372
Epoch 1 [75/172] - loss: 0.5116
Epoch 1 [76/172] - loss: 0.5757
Epoch 1 [77/172] - loss: 0.7082
Epoch 1 [78/172] - loss: 0.7412
Epoch 1 [79/172] - loss: 0.5319
Epoch 1 [80/172] - loss: 0.5414, acc: 0.7500
Epoch 1 [81/172] - loss: 0.5353
Epoch 1 [82/172] - loss: 1.1144
Epoch 1 [83/172] - loss: 0.7194
Epoch 1 [84/172] - loss: 0.5998
Epoch 1 [85/172] - loss: 0.5712
Epoch 1 [86/172] - loss: 0.7337
Epoch 1 [87/172] - loss: 0.6344
Epoch 1 [88/172] - loss: 0.8429
Epoch 1 [89/172] - loss: 0.8359
Epoch 1 [90/172] - loss: 0.8052, acc: 0.6250
Epoch 1 [91/172] - loss: 0.5625
Epoch 1 [92/172] - loss: 0.6894
Epoch 1 [93/172] - loss: 0.6309
Epoch 1 [94/172] - loss: 0.5289
Epoch 1 [95/172] - loss: 0.4626
Epoch 1 [96/172] - loss: 0.6140
Epoch 1 [97/172] - loss: 0.6454
Epoch 1 [98/172] - loss: 0.6210
Epoch 1 [99/172] - loss: 0.9470
Epoch 1 [100/172] - loss: 0.6793, acc: 0.7812

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5690, log_difficulty=0.4504, weight=3.2521
neutral: count=983.0, difficulty=0.5640, log_difficulty=0.4473, weight=3.2363
negative: count=1119.0, difficulty=0.5452, log_difficulty=0.4352, weight=3.1759

当前batch的pt分布：
positive: min=0.0475, max=0.9248, mean=0.4052
neutral: min=0.1945, max=0.9529, mean=0.6310
negative: min=0.0895, max=0.7711, mean=0.3941

当前batch准确率：
整体准确率: 0.4688
positive 准确率: 0.4167
neutral 准确率: 0.7500
negative 准确率: 0.4375

损失分量：
基础交叉熵: 1.1195
焦点损失: 0.5855
边界损失: 0.4377
总损失: 1.1605
Epoch 1 [101/172] - loss: 1.1605
Epoch 1 [102/172] - loss: 0.7003
Epoch 1 [103/172] - loss: 0.4910
Epoch 1 [104/172] - loss: 0.6124
Epoch 1 [105/172] - loss: 0.6724
Epoch 1 [106/172] - loss: 0.8279
Epoch 1 [107/172] - loss: 0.5040
Epoch 1 [108/172] - loss: 0.7161
Epoch 1 [109/172] - loss: 0.7133
Epoch 1 [110/172] - loss: 0.7777, acc: 0.6562
Epoch 1 [111/172] - loss: 0.6756
Epoch 1 [112/172] - loss: 0.4617
Epoch 1 [113/172] - loss: 0.4327
Epoch 1 [114/172] - loss: 0.5837
Epoch 1 [115/172] - loss: 0.5259
Epoch 1 [116/172] - loss: 0.7603
Epoch 1 [117/172] - loss: 0.5491
Epoch 1 [118/172] - loss: 0.4248
Epoch 1 [119/172] - loss: 0.5014
Epoch 1 [120/172] - loss: 0.2783, acc: 0.9062
Epoch 1 [121/172] - loss: 0.5238
Epoch 1 [122/172] - loss: 0.6082
Epoch 1 [123/172] - loss: 0.3479
Epoch 1 [124/172] - loss: 0.5747
Epoch 1 [125/172] - loss: 0.4703
Epoch 1 [126/172] - loss: 0.6490
Epoch 1 [127/172] - loss: 0.5056
Epoch 1 [128/172] - loss: 0.5030
Epoch 1 [129/172] - loss: 0.6002
Epoch 1 [130/172] - loss: 0.5156, acc: 0.6875
Epoch 1 [131/172] - loss: 0.3413
Epoch 1 [132/172] - loss: 0.4471
Epoch 1 [133/172] - loss: 0.4666
Epoch 1 [134/172] - loss: 0.3773
Epoch 1 [135/172] - loss: 0.5887
Epoch 1 [136/172] - loss: 0.4235
Epoch 1 [137/172] - loss: 0.6886
Epoch 1 [138/172] - loss: 0.4591
Epoch 1 [139/172] - loss: 0.4433
Epoch 1 [140/172] - loss: 0.3515, acc: 0.7812
Epoch 1 [141/172] - loss: 0.3938
Epoch 1 [142/172] - loss: 0.4838
Epoch 1 [143/172] - loss: 0.7151
Epoch 1 [144/172] - loss: 0.4051
Epoch 1 [145/172] - loss: 0.4621
Epoch 1 [146/172] - loss: 0.6281
Epoch 1 [147/172] - loss: 0.6404
Epoch 1 [148/172] - loss: 0.4971
Epoch 1 [149/172] - loss: 0.3041
Epoch 1 [150/172] - loss: 0.5196, acc: 0.7188
Epoch 1 [151/172] - loss: 0.6082
Epoch 1 [152/172] - loss: 0.3547
Epoch 1 [153/172] - loss: 0.4910
Epoch 1 [154/172] - loss: 0.3856
Epoch 1 [155/172] - loss: 0.5160
Epoch 1 [156/172] - loss: 0.7895
Epoch 1 [157/172] - loss: 0.5097
Epoch 1 [158/172] - loss: 0.4035
Epoch 1 [159/172] - loss: 0.7187
Epoch 1 [160/172] - loss: 0.3620, acc: 0.8750
Epoch 1 [161/172] - loss: 0.4870
Epoch 1 [162/172] - loss: 0.4477
Epoch 1 [163/172] - loss: 0.6502
Epoch 1 [164/172] - loss: 0.5875
Epoch 1 [165/172] - loss: 0.4164
Epoch 1 [166/172] - loss: 0.4554
Epoch 1 [167/172] - loss: 0.5701
Epoch 1 [168/172] - loss: 0.6014
Epoch 1 [169/172] - loss: 0.4374
Epoch 1 [170/172] - loss: 0.3586, acc: 0.8750
Epoch 1 [171/172] - loss: 0.4727
Epoch 1 [172/172] - loss: 0.3719

类别准确率:
positive: 0.5289 (247/467)
neutral: 0.7590 (63/83)
negative: 0.5920 (148/250)

Epoch 1/10
Train Loss: 0.4906, Train Acc: 0.7616
Val Loss: 0.9494, Val Acc: 0.5725
Epoch 2 [1/172] - loss: 0.3783, acc: 0.7812
Epoch 2 [2/172] - loss: 0.3345
Epoch 2 [3/172] - loss: 0.3880
Epoch 2 [4/172] - loss: 0.3941
Epoch 2 [5/172] - loss: 0.4411
Epoch 2 [6/172] - loss: 0.4613
Epoch 2 [7/172] - loss: 0.2815
Epoch 2 [8/172] - loss: 0.3011
Epoch 2 [9/172] - loss: 0.2886
Epoch 2 [10/172] - loss: 0.3744, acc: 0.7812
Epoch 2 [11/172] - loss: 0.2623
Epoch 2 [12/172] - loss: 0.2971
Epoch 2 [13/172] - loss: 0.4977
Epoch 2 [14/172] - loss: 0.3161
Epoch 2 [15/172] - loss: 0.5023
Epoch 2 [16/172] - loss: 0.3323
Epoch 2 [17/172] - loss: 0.4368
Epoch 2 [18/172] - loss: 0.6084
Epoch 2 [19/172] - loss: 0.2698
Epoch 2 [20/172] - loss: 0.3602, acc: 0.8750
Epoch 2 [21/172] - loss: 0.3377
Epoch 2 [22/172] - loss: 0.2642
Epoch 2 [23/172] - loss: 0.2018
Epoch 2 [24/172] - loss: 0.6918
Epoch 2 [25/172] - loss: 0.3406
Epoch 2 [26/172] - loss: 0.1756
Epoch 2 [27/172] - loss: 0.2199
Epoch 2 [28/172] - loss: 0.2651

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4922, log_difficulty=0.4002, weight=3.0011
neutral: count=1952.0, difficulty=0.4330, log_difficulty=0.3598, weight=2.7988
negative: count=2216.0, difficulty=0.4756, log_difficulty=0.3891, weight=2.9453

当前batch的pt分布：
positive: min=0.2977, max=0.9910, mean=0.7104
neutral: min=0.4465, max=0.9807, mean=0.7947
negative: min=0.2763, max=0.9196, mean=0.6478

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.7778
neutral 准确率: 1.0000
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.3857
焦点损失: 0.0681
边界损失: 0.3366
总损失: 0.2688
Epoch 2 [29/172] - loss: 0.2688
Epoch 2 [30/172] - loss: 0.3097, acc: 0.9062
Epoch 2 [31/172] - loss: 0.4297
Epoch 2 [32/172] - loss: 0.3116
Epoch 2 [33/172] - loss: 0.2930
Epoch 2 [34/172] - loss: 0.3590
Epoch 2 [35/172] - loss: 0.2031
Epoch 2 [36/172] - loss: 0.3081
Epoch 2 [37/172] - loss: 0.3078
Epoch 2 [38/172] - loss: 0.2520
Epoch 2 [39/172] - loss: 0.4382
Epoch 2 [40/172] - loss: 0.4603, acc: 0.7500
Epoch 2 [41/172] - loss: 0.2253
Epoch 2 [42/172] - loss: 0.1497
Epoch 2 [43/172] - loss: 0.2053
Epoch 2 [44/172] - loss: 0.4343
Epoch 2 [45/172] - loss: 0.3454
Epoch 2 [46/172] - loss: 0.2421
Epoch 2 [47/172] - loss: 0.3431
Epoch 2 [48/172] - loss: 0.4326
Epoch 2 [49/172] - loss: 0.2231
Epoch 2 [50/172] - loss: 0.3595, acc: 0.8125
Epoch 2 [51/172] - loss: 0.3891
Epoch 2 [52/172] - loss: 0.2207
Epoch 2 [53/172] - loss: 0.2972
Epoch 2 [54/172] - loss: 0.2141
Epoch 2 [55/172] - loss: 0.2647
Epoch 2 [56/172] - loss: 0.2440
Epoch 2 [57/172] - loss: 0.1903
Epoch 2 [58/172] - loss: 0.3077
Epoch 2 [59/172] - loss: 0.2791
Epoch 2 [60/172] - loss: 0.1973, acc: 0.9062
Epoch 2 [61/172] - loss: 0.1657
Epoch 2 [62/172] - loss: 0.1600
Epoch 2 [63/172] - loss: 0.3918
Epoch 2 [64/172] - loss: 0.2542
Epoch 2 [65/172] - loss: 0.2460
Epoch 2 [66/172] - loss: 0.3639
Epoch 2 [67/172] - loss: 0.2321
Epoch 2 [68/172] - loss: 0.2944
Epoch 2 [69/172] - loss: 0.2014
Epoch 2 [70/172] - loss: 0.3094, acc: 0.8125
Epoch 2 [71/172] - loss: 0.3228
Epoch 2 [72/172] - loss: 0.3695
Epoch 2 [73/172] - loss: 0.2856
Epoch 2 [74/172] - loss: 0.2270
Epoch 2 [75/172] - loss: 0.2859
Epoch 2 [76/172] - loss: 0.3202
Epoch 2 [77/172] - loss: 0.2727
Epoch 2 [78/172] - loss: 0.3417
Epoch 2 [79/172] - loss: 0.2988
Epoch 2 [80/172] - loss: 0.1769, acc: 0.9375
Epoch 2 [81/172] - loss: 0.2727
Epoch 2 [82/172] - loss: 0.1680
Epoch 2 [83/172] - loss: 0.3093
Epoch 2 [84/172] - loss: 0.2647
Epoch 2 [85/172] - loss: 0.2205
Epoch 2 [86/172] - loss: 0.2851
Epoch 2 [87/172] - loss: 0.6426
Epoch 2 [88/172] - loss: 0.2969
Epoch 2 [89/172] - loss: 0.1447
Epoch 2 [90/172] - loss: 0.2116, acc: 0.9062
Epoch 2 [91/172] - loss: 0.1836
Epoch 2 [92/172] - loss: 0.3000
Epoch 2 [93/172] - loss: 0.3048
Epoch 2 [94/172] - loss: 0.2152
Epoch 2 [95/172] - loss: 0.6173
Epoch 2 [96/172] - loss: 0.2049
Epoch 2 [97/172] - loss: 0.3068
Epoch 2 [98/172] - loss: 0.2511
Epoch 2 [99/172] - loss: 0.1607
Epoch 2 [100/172] - loss: 0.2979, acc: 0.8750
Epoch 2 [101/172] - loss: 0.2728
Epoch 2 [102/172] - loss: 0.1788
Epoch 2 [103/172] - loss: 0.2920
Epoch 2 [104/172] - loss: 0.3252
Epoch 2 [105/172] - loss: 0.1657
Epoch 2 [106/172] - loss: 0.1777
Epoch 2 [107/172] - loss: 0.1890
Epoch 2 [108/172] - loss: 0.4348
Epoch 2 [109/172] - loss: 0.2361
Epoch 2 [110/172] - loss: 0.2072, acc: 0.9062
Epoch 2 [111/172] - loss: 0.2250
Epoch 2 [112/172] - loss: 0.1812
Epoch 2 [113/172] - loss: 0.1443
Epoch 2 [114/172] - loss: 0.2424
Epoch 2 [115/172] - loss: 0.2027
Epoch 2 [116/172] - loss: 0.2539
Epoch 2 [117/172] - loss: 0.5358
Epoch 2 [118/172] - loss: 0.1526
Epoch 2 [119/172] - loss: 0.2315
Epoch 2 [120/172] - loss: 0.1648, acc: 0.9688
Epoch 2 [121/172] - loss: 0.2157
Epoch 2 [122/172] - loss: 0.7155
Epoch 2 [123/172] - loss: 0.1811
Epoch 2 [124/172] - loss: 0.2785
Epoch 2 [125/172] - loss: 0.1356
Epoch 2 [126/172] - loss: 0.1510
Epoch 2 [127/172] - loss: 0.2377
Epoch 2 [128/172] - loss: 0.2325

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4202, log_difficulty=0.3508, weight=2.7541
neutral: count=2949.0, difficulty=0.3428, log_difficulty=0.2948, weight=2.4739
negative: count=3294.0, difficulty=0.4117, log_difficulty=0.3448, weight=2.7238

当前batch的pt分布：
positive: min=0.3679, max=0.9884, mean=0.7531
neutral: min=0.5904, max=0.9681, mean=0.8649
negative: min=0.0296, max=0.9713, mean=0.6241

当前batch准确率：
整体准确率: 0.8125
positive 准确率: 0.8000
neutral 准确率: 1.0000
negative 准确率: 0.6364

损失分量：
基础交叉熵: 0.4666
焦点损失: 0.2414
边界损失: 0.2413
总损失: 0.4493
Epoch 2 [129/172] - loss: 0.4493
Epoch 2 [130/172] - loss: 0.3260, acc: 0.8438
Epoch 2 [131/172] - loss: 0.2065
Epoch 2 [132/172] - loss: 0.3916
Epoch 2 [133/172] - loss: 0.1527
Epoch 2 [134/172] - loss: 0.3020
Epoch 2 [135/172] - loss: 0.4615
Epoch 2 [136/172] - loss: 0.1716
Epoch 2 [137/172] - loss: 0.1731
Epoch 2 [138/172] - loss: 0.2449
Epoch 2 [139/172] - loss: 0.2371
Epoch 2 [140/172] - loss: 0.2714, acc: 0.8750
Epoch 2 [141/172] - loss: 0.2264
Epoch 2 [142/172] - loss: 0.2003
Epoch 2 [143/172] - loss: 0.2570
Epoch 2 [144/172] - loss: 0.1961
Epoch 2 [145/172] - loss: 0.4947
Epoch 2 [146/172] - loss: 0.2577
Epoch 2 [147/172] - loss: 0.2395
Epoch 2 [148/172] - loss: 0.2999
Epoch 2 [149/172] - loss: 0.2310
Epoch 2 [150/172] - loss: 0.2321, acc: 0.9062
Epoch 2 [151/172] - loss: 0.2649
Epoch 2 [152/172] - loss: 0.2150
Epoch 2 [153/172] - loss: 0.1428
Epoch 2 [154/172] - loss: 0.1525
Epoch 2 [155/172] - loss: 0.1772
Epoch 2 [156/172] - loss: 0.1872
Epoch 2 [157/172] - loss: 0.1505
Epoch 2 [158/172] - loss: 0.1815
Epoch 2 [159/172] - loss: 0.4077
Epoch 2 [160/172] - loss: 0.2009, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1614
Epoch 2 [162/172] - loss: 0.1427
Epoch 2 [163/172] - loss: 0.3746
Epoch 2 [164/172] - loss: 0.2025
Epoch 2 [165/172] - loss: 0.3400
Epoch 2 [166/172] - loss: 0.2963
Epoch 2 [167/172] - loss: 0.4373
Epoch 2 [168/172] - loss: 0.2121
Epoch 2 [169/172] - loss: 0.1852
Epoch 2 [170/172] - loss: 0.2478, acc: 0.9688
Epoch 2 [171/172] - loss: 0.4047
Epoch 2 [172/172] - loss: 0.5135

类别准确率:
positive: 0.8779 (410/467)
neutral: 0.1325 (11/83)
negative: 0.6160 (154/250)

Epoch 2/10
Train Loss: 0.2787, Train Acc: 0.8949
Val Loss: 0.6726, Val Acc: 0.7188
Epoch 3 [1/172] - loss: 0.1727, acc: 0.9688
Epoch 3 [2/172] - loss: 0.1660
Epoch 3 [3/172] - loss: 0.1209
Epoch 3 [4/172] - loss: 0.2083
Epoch 3 [5/172] - loss: 0.1894
Epoch 3 [6/172] - loss: 0.1852
Epoch 3 [7/172] - loss: 0.1613
Epoch 3 [8/172] - loss: 0.1582
Epoch 3 [9/172] - loss: 0.1943
Epoch 3 [10/172] - loss: 0.1615, acc: 0.9375
Epoch 3 [11/172] - loss: 0.1960
Epoch 3 [12/172] - loss: 0.1185
Epoch 3 [13/172] - loss: 0.1659
Epoch 3 [14/172] - loss: 0.1360
Epoch 3 [15/172] - loss: 0.1322
Epoch 3 [16/172] - loss: 0.3915
Epoch 3 [17/172] - loss: 0.1611
Epoch 3 [18/172] - loss: 0.2383
Epoch 3 [19/172] - loss: 0.1490
Epoch 3 [20/172] - loss: 0.1243, acc: 0.9688
Epoch 3 [21/172] - loss: 0.3326
Epoch 3 [22/172] - loss: 0.2110
Epoch 3 [23/172] - loss: 0.1187
Epoch 3 [24/172] - loss: 0.1904
Epoch 3 [25/172] - loss: 0.1131
Epoch 3 [26/172] - loss: 0.1321
Epoch 3 [27/172] - loss: 0.1302
Epoch 3 [28/172] - loss: 0.1525
Epoch 3 [29/172] - loss: 0.1366
Epoch 3 [30/172] - loss: 0.1813, acc: 0.9062
Epoch 3 [31/172] - loss: 0.1119
Epoch 3 [32/172] - loss: 0.1814
Epoch 3 [33/172] - loss: 0.1054
Epoch 3 [34/172] - loss: 0.2844
Epoch 3 [35/172] - loss: 0.2520
Epoch 3 [36/172] - loss: 0.1219
Epoch 3 [37/172] - loss: 0.2182
Epoch 3 [38/172] - loss: 0.0916
Epoch 3 [39/172] - loss: 0.1472
Epoch 3 [40/172] - loss: 0.1289, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1085
Epoch 3 [42/172] - loss: 0.1430
Epoch 3 [43/172] - loss: 0.1145
Epoch 3 [44/172] - loss: 0.0978
Epoch 3 [45/172] - loss: 0.1307
Epoch 3 [46/172] - loss: 0.1076
Epoch 3 [47/172] - loss: 0.0975
Epoch 3 [48/172] - loss: 0.1904
Epoch 3 [49/172] - loss: 0.0934
Epoch 3 [50/172] - loss: 0.1308, acc: 0.9688
Epoch 3 [51/172] - loss: 0.2557
Epoch 3 [52/172] - loss: 0.2653
Epoch 3 [53/172] - loss: 0.1717
Epoch 3 [54/172] - loss: 0.1102
Epoch 3 [55/172] - loss: 0.1272
Epoch 3 [56/172] - loss: 0.1683

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3643, log_difficulty=0.3106, weight=2.5530
neutral: count=3923.0, difficulty=0.2945, log_difficulty=0.2581, weight=2.2905
negative: count=4382.0, difficulty=0.3594, log_difficulty=0.3071, weight=2.5354

当前batch的pt分布：
positive: min=0.4413, max=0.9897, mean=0.8372
neutral: min=0.0009, max=0.9863, mean=0.7751
negative: min=0.9628, max=0.9960, mean=0.9821

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9091
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3991
焦点损失: 0.2482
边界损失: 0.2185
总损失: 0.3950
Epoch 3 [57/172] - loss: 0.3950
Epoch 3 [58/172] - loss: 0.1405
Epoch 3 [59/172] - loss: 0.1004
Epoch 3 [60/172] - loss: 0.1193, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1492
Epoch 3 [62/172] - loss: 0.1220
Epoch 3 [63/172] - loss: 0.1799
Epoch 3 [64/172] - loss: 0.1549
Epoch 3 [65/172] - loss: 0.2210
Epoch 3 [66/172] - loss: 0.2066
Epoch 3 [67/172] - loss: 0.1648
Epoch 3 [68/172] - loss: 0.2260
Epoch 3 [69/172] - loss: 0.2113
Epoch 3 [70/172] - loss: 0.1129, acc: 0.9688
Epoch 3 [71/172] - loss: 0.1791
Epoch 3 [72/172] - loss: 0.2485
Epoch 3 [73/172] - loss: 0.1293
Epoch 3 [74/172] - loss: 0.2025
Epoch 3 [75/172] - loss: 0.1285
Epoch 3 [76/172] - loss: 0.1387
Epoch 3 [77/172] - loss: 0.1635
Epoch 3 [78/172] - loss: 0.2754
Epoch 3 [79/172] - loss: 0.1021
Epoch 3 [80/172] - loss: 0.2581, acc: 0.8750
Epoch 3 [81/172] - loss: 0.1225
Epoch 3 [82/172] - loss: 0.1849
Epoch 3 [83/172] - loss: 0.1149
Epoch 3 [84/172] - loss: 0.1018
Epoch 3 [85/172] - loss: 0.1118
Epoch 3 [86/172] - loss: 0.1008
Epoch 3 [87/172] - loss: 0.1227
Epoch 3 [88/172] - loss: 0.1242
Epoch 3 [89/172] - loss: 0.1221
Epoch 3 [90/172] - loss: 0.1107, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1811
Epoch 3 [92/172] - loss: 0.1428
Epoch 3 [93/172] - loss: 0.2118
Epoch 3 [94/172] - loss: 0.1164
Epoch 3 [95/172] - loss: 0.0901
Epoch 3 [96/172] - loss: 0.1307
Epoch 3 [97/172] - loss: 0.1997
Epoch 3 [98/172] - loss: 0.1448
Epoch 3 [99/172] - loss: 0.1030
Epoch 3 [100/172] - loss: 0.2730, acc: 0.9375
Epoch 3 [101/172] - loss: 0.2773
Epoch 3 [102/172] - loss: 0.0935
Epoch 3 [103/172] - loss: 0.1529
Epoch 3 [104/172] - loss: 0.0999
Epoch 3 [105/172] - loss: 0.1561
Epoch 3 [106/172] - loss: 0.2267
Epoch 3 [107/172] - loss: 0.0918
Epoch 3 [108/172] - loss: 0.0885
Epoch 3 [109/172] - loss: 0.1163
Epoch 3 [110/172] - loss: 0.1380, acc: 0.9688
Epoch 3 [111/172] - loss: 0.1484
Epoch 3 [112/172] - loss: 0.1739
Epoch 3 [113/172] - loss: 0.1401
Epoch 3 [114/172] - loss: 0.1279
Epoch 3 [115/172] - loss: 0.1186
Epoch 3 [116/172] - loss: 0.2079
Epoch 3 [117/172] - loss: 0.0943
Epoch 3 [118/172] - loss: 0.1088
Epoch 3 [119/172] - loss: 0.2202
Epoch 3 [120/172] - loss: 0.1623, acc: 0.9688
Epoch 3 [121/172] - loss: 0.2057
Epoch 3 [122/172] - loss: 0.1454
Epoch 3 [123/172] - loss: 0.2142
Epoch 3 [124/172] - loss: 0.1254
Epoch 3 [125/172] - loss: 0.1080
Epoch 3 [126/172] - loss: 0.3813
Epoch 3 [127/172] - loss: 0.1381
Epoch 3 [128/172] - loss: 0.1141
Epoch 3 [129/172] - loss: 0.0971
Epoch 3 [130/172] - loss: 0.1532, acc: 0.9375
Epoch 3 [131/172] - loss: 0.1612
Epoch 3 [132/172] - loss: 0.0861
Epoch 3 [133/172] - loss: 0.1652
Epoch 3 [134/172] - loss: 0.0918
Epoch 3 [135/172] - loss: 0.1094
Epoch 3 [136/172] - loss: 0.1286
Epoch 3 [137/172] - loss: 0.1124
Epoch 3 [138/172] - loss: 0.1440
Epoch 3 [139/172] - loss: 0.1188
Epoch 3 [140/172] - loss: 0.1153, acc: 1.0000
Epoch 3 [141/172] - loss: 0.2278
Epoch 3 [142/172] - loss: 0.2283
Epoch 3 [143/172] - loss: 0.0975
Epoch 3 [144/172] - loss: 0.1514
Epoch 3 [145/172] - loss: 0.1132
Epoch 3 [146/172] - loss: 0.1572
Epoch 3 [147/172] - loss: 0.1350
Epoch 3 [148/172] - loss: 0.1122
Epoch 3 [149/172] - loss: 0.2005
Epoch 3 [150/172] - loss: 0.1149, acc: 1.0000
Epoch 3 [151/172] - loss: 0.3208
Epoch 3 [152/172] - loss: 0.2166
Epoch 3 [153/172] - loss: 0.1868
Epoch 3 [154/172] - loss: 0.2045
Epoch 3 [155/172] - loss: 0.1379
Epoch 3 [156/172] - loss: 0.1082

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3197, log_difficulty=0.2774, weight=2.3872
neutral: count=4903.0, difficulty=0.2537, log_difficulty=0.2261, weight=2.1306
negative: count=5500.0, difficulty=0.3158, log_difficulty=0.2745, weight=2.3723

当前batch的pt分布：
positive: min=0.5644, max=0.9895, mean=0.8746
neutral: min=0.9067, max=0.9966, mean=0.9556
negative: min=0.4368, max=0.9976, mean=0.8190

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1370
焦点损失: 0.0127
边界损失: 0.2035
总损失: 0.1168
Epoch 3 [157/172] - loss: 0.1168
Epoch 3 [158/172] - loss: 0.2717
Epoch 3 [159/172] - loss: 0.1062
Epoch 3 [160/172] - loss: 0.2830, acc: 0.9062
Epoch 3 [161/172] - loss: 0.1826
Epoch 3 [162/172] - loss: 0.1297
Epoch 3 [163/172] - loss: 0.1972
Epoch 3 [164/172] - loss: 0.0983
Epoch 3 [165/172] - loss: 0.1116
Epoch 3 [166/172] - loss: 0.1102
Epoch 3 [167/172] - loss: 0.1212
Epoch 3 [168/172] - loss: 0.1160
Epoch 3 [169/172] - loss: 0.1040
Epoch 3 [170/172] - loss: 0.1849, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1261
Epoch 3 [172/172] - loss: 0.1090

类别准确率:
positive: 0.8394 (392/467)
neutral: 0.1325 (11/83)
negative: 0.6840 (171/250)

Epoch 3/10
Train Loss: 0.1480, Train Acc: 0.9636
Val Loss: 0.7679, Val Acc: 0.7175
Epoch 4 [1/172] - loss: 0.1355, acc: 0.9688
Epoch 4 [2/172] - loss: 0.1667
Epoch 4 [3/172] - loss: 0.1360
Epoch 4 [4/172] - loss: 0.1077
Epoch 4 [5/172] - loss: 0.1114
Epoch 4 [6/172] - loss: 0.0955
Epoch 4 [7/172] - loss: 0.0876
Epoch 4 [8/172] - loss: 0.0873
Epoch 4 [9/172] - loss: 0.2235
Epoch 4 [10/172] - loss: 0.1116, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0837
Epoch 4 [12/172] - loss: 0.1373
Epoch 4 [13/172] - loss: 0.1304
Epoch 4 [14/172] - loss: 0.1333
Epoch 4 [15/172] - loss: 0.1144
Epoch 4 [16/172] - loss: 0.0827
Epoch 4 [17/172] - loss: 0.0916
Epoch 4 [18/172] - loss: 0.1014
Epoch 4 [19/172] - loss: 0.0973
Epoch 4 [20/172] - loss: 0.0945, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1012
Epoch 4 [22/172] - loss: 0.0901
Epoch 4 [23/172] - loss: 0.1530
Epoch 4 [24/172] - loss: 0.0919
Epoch 4 [25/172] - loss: 0.0844
Epoch 4 [26/172] - loss: 0.2718
Epoch 4 [27/172] - loss: 0.0777
Epoch 4 [28/172] - loss: 0.1069
Epoch 4 [29/172] - loss: 0.1087
Epoch 4 [30/172] - loss: 0.1435, acc: 0.9375
Epoch 4 [31/172] - loss: 0.0928
Epoch 4 [32/172] - loss: 0.0807
Epoch 4 [33/172] - loss: 0.1135
Epoch 4 [34/172] - loss: 0.0858
Epoch 4 [35/172] - loss: 0.1318
Epoch 4 [36/172] - loss: 0.1287
Epoch 4 [37/172] - loss: 0.0869
Epoch 4 [38/172] - loss: 0.0847
Epoch 4 [39/172] - loss: 0.2035
Epoch 4 [40/172] - loss: 0.2100, acc: 0.8750
Epoch 4 [41/172] - loss: 0.1062
Epoch 4 [42/172] - loss: 0.1975
Epoch 4 [43/172] - loss: 0.0990
Epoch 4 [44/172] - loss: 0.1346
Epoch 4 [45/172] - loss: 0.0792
Epoch 4 [46/172] - loss: 0.1016
Epoch 4 [47/172] - loss: 0.0943
Epoch 4 [48/172] - loss: 0.1645
Epoch 4 [49/172] - loss: 0.0862
Epoch 4 [50/172] - loss: 0.1341, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0843
Epoch 4 [52/172] - loss: 0.1629
Epoch 4 [53/172] - loss: 0.0886
Epoch 4 [54/172] - loss: 0.1043
Epoch 4 [55/172] - loss: 0.1885
Epoch 4 [56/172] - loss: 0.0899
Epoch 4 [57/172] - loss: 0.0819
Epoch 4 [58/172] - loss: 0.0832
Epoch 4 [59/172] - loss: 0.0817
Epoch 4 [60/172] - loss: 0.0898, acc: 1.0000
Epoch 4 [61/172] - loss: 0.2009
Epoch 4 [62/172] - loss: 0.1259
Epoch 4 [63/172] - loss: 0.1036
Epoch 4 [64/172] - loss: 0.0833
Epoch 4 [65/172] - loss: 0.1631
Epoch 4 [66/172] - loss: 0.1712
Epoch 4 [67/172] - loss: 0.2580
Epoch 4 [68/172] - loss: 0.0945
Epoch 4 [69/172] - loss: 0.1648
Epoch 4 [70/172] - loss: 0.1598, acc: 0.9688
Epoch 4 [71/172] - loss: 0.0885
Epoch 4 [72/172] - loss: 0.1059
Epoch 4 [73/172] - loss: 0.0852
Epoch 4 [74/172] - loss: 0.2916
Epoch 4 [75/172] - loss: 0.0994
Epoch 4 [76/172] - loss: 0.0789
Epoch 4 [77/172] - loss: 0.1062
Epoch 4 [78/172] - loss: 0.1192
Epoch 4 [79/172] - loss: 0.0795
Epoch 4 [80/172] - loss: 0.0853, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1265
Epoch 4 [82/172] - loss: 0.1184
Epoch 4 [83/172] - loss: 0.0816
Epoch 4 [84/172] - loss: 0.0995

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2850, log_difficulty=0.2508, weight=2.2539
neutral: count=5865.0, difficulty=0.2238, log_difficulty=0.2020, weight=2.0099
negative: count=6629.0, difficulty=0.2793, log_difficulty=0.2463, weight=2.2316

当前batch的pt分布：
positive: min=0.7486, max=0.9876, mean=0.8731
neutral: min=0.7253, max=0.9990, mean=0.9559
negative: min=0.0774, max=0.9930, mean=0.8799

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.1657
焦点损失: 0.0690
边界损失: 0.1784
总损失: 0.1661
Epoch 4 [85/172] - loss: 0.1661
Epoch 4 [86/172] - loss: 0.1388
Epoch 4 [87/172] - loss: 0.1060
Epoch 4 [88/172] - loss: 0.0806
Epoch 4 [89/172] - loss: 0.0932
Epoch 4 [90/172] - loss: 0.1056, acc: 0.9688
Epoch 4 [91/172] - loss: 0.3289
Epoch 4 [92/172] - loss: 0.1806
Epoch 4 [93/172] - loss: 0.0789
Epoch 4 [94/172] - loss: 0.0832
Epoch 4 [95/172] - loss: 0.1639
Epoch 4 [96/172] - loss: 0.1166
Epoch 4 [97/172] - loss: 0.0851
Epoch 4 [98/172] - loss: 0.0862
Epoch 4 [99/172] - loss: 0.0949
Epoch 4 [100/172] - loss: 0.0859, acc: 1.0000
Epoch 4 [101/172] - loss: 0.1159
Epoch 4 [102/172] - loss: 0.0894
Epoch 4 [103/172] - loss: 0.0871
Epoch 4 [104/172] - loss: 0.0828
Epoch 4 [105/172] - loss: 0.1288
Epoch 4 [106/172] - loss: 0.0967
Epoch 4 [107/172] - loss: 0.0921
Epoch 4 [108/172] - loss: 0.1682
Epoch 4 [109/172] - loss: 0.0846
Epoch 4 [110/172] - loss: 0.3302, acc: 0.8750
Epoch 4 [111/172] - loss: 0.0858
Epoch 4 [112/172] - loss: 0.0843
Epoch 4 [113/172] - loss: 0.0827
Epoch 4 [114/172] - loss: 0.1106
Epoch 4 [115/172] - loss: 0.0932
Epoch 4 [116/172] - loss: 0.0943
Epoch 4 [117/172] - loss: 0.0812
Epoch 4 [118/172] - loss: 0.1639
Epoch 4 [119/172] - loss: 0.0898
Epoch 4 [120/172] - loss: 0.0897, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1632
Epoch 4 [122/172] - loss: 0.2060
Epoch 4 [123/172] - loss: 0.0816
Epoch 4 [124/172] - loss: 0.0845
Epoch 4 [125/172] - loss: 0.1276
Epoch 4 [126/172] - loss: 0.1221
Epoch 4 [127/172] - loss: 0.1208
Epoch 4 [128/172] - loss: 0.1047
Epoch 4 [129/172] - loss: 0.0779
Epoch 4 [130/172] - loss: 0.0798, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0862
Epoch 4 [132/172] - loss: 0.0880
Epoch 4 [133/172] - loss: 0.0834
Epoch 4 [134/172] - loss: 0.0867
Epoch 4 [135/172] - loss: 0.1784
Epoch 4 [136/172] - loss: 0.1127
Epoch 4 [137/172] - loss: 0.0802
Epoch 4 [138/172] - loss: 0.0950
Epoch 4 [139/172] - loss: 0.0860
Epoch 4 [140/172] - loss: 0.2743, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1751
Epoch 4 [142/172] - loss: 0.0847
Epoch 4 [143/172] - loss: 0.0909
Epoch 4 [144/172] - loss: 0.0925
Epoch 4 [145/172] - loss: 0.2889
Epoch 4 [146/172] - loss: 0.1537
Epoch 4 [147/172] - loss: 0.1166
Epoch 4 [148/172] - loss: 0.1308
Epoch 4 [149/172] - loss: 0.1015
Epoch 4 [150/172] - loss: 0.1024, acc: 1.0000
Epoch 4 [151/172] - loss: 0.1990
Epoch 4 [152/172] - loss: 0.0890
Epoch 4 [153/172] - loss: 0.0851
Epoch 4 [154/172] - loss: 0.1279
Epoch 4 [155/172] - loss: 0.1049
Epoch 4 [156/172] - loss: 0.1051
Epoch 4 [157/172] - loss: 0.2734
Epoch 4 [158/172] - loss: 0.0794
Epoch 4 [159/172] - loss: 0.1003
Epoch 4 [160/172] - loss: 0.0850, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1045
Epoch 4 [162/172] - loss: 0.1139
Epoch 4 [163/172] - loss: 0.1415
Epoch 4 [164/172] - loss: 0.0874
Epoch 4 [165/172] - loss: 0.1542
Epoch 4 [166/172] - loss: 0.0876
Epoch 4 [167/172] - loss: 0.2420
Epoch 4 [168/172] - loss: 0.0902
Epoch 4 [169/172] - loss: 0.1965
Epoch 4 [170/172] - loss: 0.1338, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1089
Epoch 4 [172/172] - loss: 0.0874

类别准确率:
positive: 0.8972 (419/467)
neutral: 0.2410 (20/83)
negative: 0.5520 (138/250)

Epoch 4/10
Train Loss: 0.1304, Train Acc: 0.9717
Val Loss: 0.7647, Val Acc: 0.7212
Epoch 5 [1/172] - loss: 0.0838, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0913
Epoch 5 [3/172] - loss: 0.0925
Epoch 5 [4/172] - loss: 0.0847
Epoch 5 [5/172] - loss: 0.0840
Epoch 5 [6/172] - loss: 0.1415
Epoch 5 [7/172] - loss: 0.0962
Epoch 5 [8/172] - loss: 0.0866
Epoch 5 [9/172] - loss: 0.1387
Epoch 5 [10/172] - loss: 0.0886, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1147
Epoch 5 [12/172] - loss: 0.0792

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2579, log_difficulty=0.2294, weight=2.1472
neutral: count=6845.0, difficulty=0.2005, log_difficulty=0.1827, weight=1.9136
negative: count=7694.0, difficulty=0.2521, log_difficulty=0.2248, weight=2.1242

当前batch的pt分布：
positive: min=0.3229, max=0.9884, mean=0.8625
neutral: min=0.8857, max=0.9988, mean=0.9704
negative: min=0.7813, max=0.9974, mean=0.9438

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1074
焦点损失: 0.0182
边界损失: 0.1805
总损失: 0.1097
Epoch 5 [13/172] - loss: 0.1097
Epoch 5 [14/172] - loss: 0.1515
Epoch 5 [15/172] - loss: 0.0810
Epoch 5 [16/172] - loss: 0.0802
Epoch 5 [17/172] - loss: 0.2177
Epoch 5 [18/172] - loss: 0.0770
Epoch 5 [19/172] - loss: 0.1536
Epoch 5 [20/172] - loss: 0.1257, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1083
Epoch 5 [22/172] - loss: 0.2863
Epoch 5 [23/172] - loss: 0.0767
Epoch 5 [24/172] - loss: 0.1271
Epoch 5 [25/172] - loss: 0.0815
Epoch 5 [26/172] - loss: 0.1021
Epoch 5 [27/172] - loss: 0.0765
Epoch 5 [28/172] - loss: 0.0838
Epoch 5 [29/172] - loss: 0.0920
Epoch 5 [30/172] - loss: 0.0870, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0888
Epoch 5 [32/172] - loss: 0.0781
Epoch 5 [33/172] - loss: 0.0859
Epoch 5 [34/172] - loss: 0.0887
Epoch 5 [35/172] - loss: 0.0834
Epoch 5 [36/172] - loss: 0.0818
Epoch 5 [37/172] - loss: 0.0789
Epoch 5 [38/172] - loss: 0.0885
Epoch 5 [39/172] - loss: 0.1921
Epoch 5 [40/172] - loss: 0.0860, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0821
Epoch 5 [42/172] - loss: 0.0766
Epoch 5 [43/172] - loss: 0.1405
Epoch 5 [44/172] - loss: 0.1108
Epoch 5 [45/172] - loss: 0.0776
Epoch 5 [46/172] - loss: 0.1254
Epoch 5 [47/172] - loss: 0.0824
Epoch 5 [48/172] - loss: 0.1925
Epoch 5 [49/172] - loss: 0.0816
Epoch 5 [50/172] - loss: 0.1211, acc: 0.9688
Epoch 5 [51/172] - loss: 0.1116
Epoch 5 [52/172] - loss: 0.0829
Epoch 5 [53/172] - loss: 0.0886
Epoch 5 [54/172] - loss: 0.0825
Epoch 5 [55/172] - loss: 0.0906
Epoch 5 [56/172] - loss: 0.0887
Epoch 5 [57/172] - loss: 0.0892
Epoch 5 [58/172] - loss: 0.0813
Epoch 5 [59/172] - loss: 0.1099
Epoch 5 [60/172] - loss: 0.1128, acc: 0.9375
Epoch 5 [61/172] - loss: 0.1307
Epoch 5 [62/172] - loss: 0.0880
Epoch 5 [63/172] - loss: 0.1488
Epoch 5 [64/172] - loss: 0.1406
Epoch 5 [65/172] - loss: 0.0898
Epoch 5 [66/172] - loss: 0.0835
Epoch 5 [67/172] - loss: 0.0790
Epoch 5 [68/172] - loss: 0.0904
Epoch 5 [69/172] - loss: 0.0954
Epoch 5 [70/172] - loss: 0.0839, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0841
Epoch 5 [72/172] - loss: 0.1269
Epoch 5 [73/172] - loss: 0.1273
Epoch 5 [74/172] - loss: 0.1399
Epoch 5 [75/172] - loss: 0.0918
Epoch 5 [76/172] - loss: 0.0972
Epoch 5 [77/172] - loss: 0.1596
Epoch 5 [78/172] - loss: 0.0969
Epoch 5 [79/172] - loss: 0.0787
Epoch 5 [80/172] - loss: 0.0799, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1545
Epoch 5 [82/172] - loss: 0.1268
Epoch 5 [83/172] - loss: 0.0805
Epoch 5 [84/172] - loss: 0.0769
Epoch 5 [85/172] - loss: 0.1770
Epoch 5 [86/172] - loss: 0.0949
Epoch 5 [87/172] - loss: 0.1199
Epoch 5 [88/172] - loss: 0.1196
Epoch 5 [89/172] - loss: 0.1055
Epoch 5 [90/172] - loss: 0.1164, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0891
Epoch 5 [92/172] - loss: 0.0788
Epoch 5 [93/172] - loss: 0.0831
Epoch 5 [94/172] - loss: 0.0814
Epoch 5 [95/172] - loss: 0.0869
Epoch 5 [96/172] - loss: 0.0928
Epoch 5 [97/172] - loss: 0.1193
Epoch 5 [98/172] - loss: 0.0842
Epoch 5 [99/172] - loss: 0.1193
Epoch 5 [100/172] - loss: 0.0956, acc: 0.9688
Epoch 5 [101/172] - loss: 0.0915
Epoch 5 [102/172] - loss: 0.0790
Epoch 5 [103/172] - loss: 0.0934
Epoch 5 [104/172] - loss: 0.2126
Epoch 5 [105/172] - loss: 0.1835
Epoch 5 [106/172] - loss: 0.0819
Epoch 5 [107/172] - loss: 0.0922
Epoch 5 [108/172] - loss: 0.1047
Epoch 5 [109/172] - loss: 0.0761
Epoch 5 [110/172] - loss: 0.0945, acc: 0.9688
Epoch 5 [111/172] - loss: 0.0907
Epoch 5 [112/172] - loss: 0.0782

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2345, log_difficulty=0.2107, weight=2.0535
neutral: count=7825.0, difficulty=0.1818, log_difficulty=0.1670, weight=1.8351
negative: count=8780.0, difficulty=0.2307, log_difficulty=0.2076, weight=2.0381

当前batch的pt分布：
positive: min=0.1980, max=0.9822, mean=0.8638
neutral: min=0.8702, max=0.9936, mean=0.9597
negative: min=0.9911, max=0.9995, mean=0.9952

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1152
焦点损失: 0.0358
边界损失: 0.1708
总损失: 0.1222
Epoch 5 [113/172] - loss: 0.1222
Epoch 5 [114/172] - loss: 0.1090
Epoch 5 [115/172] - loss: 0.1019
Epoch 5 [116/172] - loss: 0.0751
Epoch 5 [117/172] - loss: 0.1172
Epoch 5 [118/172] - loss: 0.0748
Epoch 5 [119/172] - loss: 0.0787
Epoch 5 [120/172] - loss: 0.0932, acc: 0.9688
Epoch 5 [121/172] - loss: 0.0804
Epoch 5 [122/172] - loss: 0.0926
Epoch 5 [123/172] - loss: 0.0803
Epoch 5 [124/172] - loss: 0.0794
Epoch 5 [125/172] - loss: 0.0864
Epoch 5 [126/172] - loss: 0.1099
Epoch 5 [127/172] - loss: 0.0886
Epoch 5 [128/172] - loss: 0.0850
Epoch 5 [129/172] - loss: 0.1727
Epoch 5 [130/172] - loss: 0.0897, acc: 0.9688
Epoch 5 [131/172] - loss: 0.0869
Epoch 5 [132/172] - loss: 0.1419
Epoch 5 [133/172] - loss: 0.1231
Epoch 5 [134/172] - loss: 0.1311
Epoch 5 [135/172] - loss: 0.0756
Epoch 5 [136/172] - loss: 0.0786
Epoch 5 [137/172] - loss: 0.0840
Epoch 5 [138/172] - loss: 0.1173
Epoch 5 [139/172] - loss: 0.2037
Epoch 5 [140/172] - loss: 0.0863, acc: 1.0000
Epoch 5 [141/172] - loss: 0.0771
Epoch 5 [142/172] - loss: 0.0916
Epoch 5 [143/172] - loss: 0.0860
Epoch 5 [144/172] - loss: 0.0762
Epoch 5 [145/172] - loss: 0.1269
Epoch 5 [146/172] - loss: 0.0781
Epoch 5 [147/172] - loss: 0.1196
Epoch 5 [148/172] - loss: 0.0747
Epoch 5 [149/172] - loss: 0.0783
Epoch 5 [150/172] - loss: 0.2127, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0999
Epoch 5 [152/172] - loss: 0.0860
Epoch 5 [153/172] - loss: 0.0743
Epoch 5 [154/172] - loss: 0.1012
Epoch 5 [155/172] - loss: 0.0984
Epoch 5 [156/172] - loss: 0.0895
Epoch 5 [157/172] - loss: 0.0753
Epoch 5 [158/172] - loss: 0.0762
Epoch 5 [159/172] - loss: 0.0772
Epoch 5 [160/172] - loss: 0.0818, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0801
Epoch 5 [162/172] - loss: 0.1090
Epoch 5 [163/172] - loss: 0.1881
Epoch 5 [164/172] - loss: 0.0807
Epoch 5 [165/172] - loss: 0.1006
Epoch 5 [166/172] - loss: 0.1503
Epoch 5 [167/172] - loss: 0.0924
Epoch 5 [168/172] - loss: 0.0792
Epoch 5 [169/172] - loss: 0.0886
Epoch 5 [170/172] - loss: 0.0789, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0793
Epoch 5 [172/172] - loss: 0.1316

类别准确率:
positive: 0.8801 (411/467)
neutral: 0.2771 (23/83)
negative: 0.6360 (159/250)

Epoch 5/10
Train Loss: 0.0981, Train Acc: 0.9899
Val Loss: 0.7789, Val Acc: 0.7412
Epoch 6 [1/172] - loss: 0.1040, acc: 1.0000
Epoch 6 [2/172] - loss: 0.0970
Epoch 6 [3/172] - loss: 0.0771
Epoch 6 [4/172] - loss: 0.0773
Epoch 6 [5/172] - loss: 0.1001
Epoch 6 [6/172] - loss: 0.0738
Epoch 6 [7/172] - loss: 0.0916
Epoch 6 [8/172] - loss: 0.0828
Epoch 6 [9/172] - loss: 0.0926
Epoch 6 [10/172] - loss: 0.0782, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0738
Epoch 6 [12/172] - loss: 0.0758
Epoch 6 [13/172] - loss: 0.0859
Epoch 6 [14/172] - loss: 0.0745
Epoch 6 [15/172] - loss: 0.0773
Epoch 6 [16/172] - loss: 0.1214
Epoch 6 [17/172] - loss: 0.0815
Epoch 6 [18/172] - loss: 0.0842
Epoch 6 [19/172] - loss: 0.0922
Epoch 6 [20/172] - loss: 0.0786, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0878
Epoch 6 [22/172] - loss: 0.0758
Epoch 6 [23/172] - loss: 0.0783
Epoch 6 [24/172] - loss: 0.0771
Epoch 6 [25/172] - loss: 0.0848
Epoch 6 [26/172] - loss: 0.0849
Epoch 6 [27/172] - loss: 0.0891
Epoch 6 [28/172] - loss: 0.1325
Epoch 6 [29/172] - loss: 0.0770
Epoch 6 [30/172] - loss: 0.0746, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0779
Epoch 6 [32/172] - loss: 0.0744
Epoch 6 [33/172] - loss: 0.0850
Epoch 6 [34/172] - loss: 0.0743
Epoch 6 [35/172] - loss: 0.0807
Epoch 6 [36/172] - loss: 0.0830
Epoch 6 [37/172] - loss: 0.0762
Epoch 6 [38/172] - loss: 0.0795
Epoch 6 [39/172] - loss: 0.0771
Epoch 6 [40/172] - loss: 0.1416, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2153, log_difficulty=0.1950, weight=1.9748
neutral: count=8815.0, difficulty=0.1664, log_difficulty=0.1539, weight=1.7696
negative: count=9870.0, difficulty=0.2112, log_difficulty=0.1916, weight=1.9581

当前batch的pt分布：
positive: min=0.1664, max=0.9952, mean=0.9103
neutral: min=0.9592, max=0.9949, mean=0.9809
negative: min=0.7464, max=0.9956, mean=0.9568

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0831
焦点损失: 0.0389
边界损失: 0.1508
总损失: 0.1138
Epoch 6 [41/172] - loss: 0.1138
Epoch 6 [42/172] - loss: 0.0772
Epoch 6 [43/172] - loss: 0.0823
Epoch 6 [44/172] - loss: 0.0748
Epoch 6 [45/172] - loss: 0.0962
Epoch 6 [46/172] - loss: 0.0780
Epoch 6 [47/172] - loss: 0.0785
Epoch 6 [48/172] - loss: 0.0754
Epoch 6 [49/172] - loss: 0.0906
Epoch 6 [50/172] - loss: 0.1228, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0983
Epoch 6 [52/172] - loss: 0.0833
Epoch 6 [53/172] - loss: 0.0765
Epoch 6 [54/172] - loss: 0.1742
Epoch 6 [55/172] - loss: 0.0787
Epoch 6 [56/172] - loss: 0.1046
Epoch 6 [57/172] - loss: 0.0738
Epoch 6 [58/172] - loss: 0.0786
Epoch 6 [59/172] - loss: 0.0870
Epoch 6 [60/172] - loss: 0.1060, acc: 0.9375
Epoch 6 [61/172] - loss: 0.0903
Epoch 6 [62/172] - loss: 0.0773
Epoch 6 [63/172] - loss: 0.0762
Epoch 6 [64/172] - loss: 0.1073
Epoch 6 [65/172] - loss: 0.1148
Epoch 6 [66/172] - loss: 0.0762
Epoch 6 [67/172] - loss: 0.0736
Epoch 6 [68/172] - loss: 0.0993
Epoch 6 [69/172] - loss: 0.1198
Epoch 6 [70/172] - loss: 0.0786, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0827
Epoch 6 [72/172] - loss: 0.0854
Epoch 6 [73/172] - loss: 0.1147
Epoch 6 [74/172] - loss: 0.0778
Epoch 6 [75/172] - loss: 0.0807
Epoch 6 [76/172] - loss: 0.0823
Epoch 6 [77/172] - loss: 0.0905
Epoch 6 [78/172] - loss: 0.0992
Epoch 6 [79/172] - loss: 0.0759
Epoch 6 [80/172] - loss: 0.1402, acc: 0.9688
Epoch 6 [81/172] - loss: 0.1051
Epoch 6 [82/172] - loss: 0.0951
Epoch 6 [83/172] - loss: 0.0753
Epoch 6 [84/172] - loss: 0.0777
Epoch 6 [85/172] - loss: 0.0938
Epoch 6 [86/172] - loss: 0.0928
Epoch 6 [87/172] - loss: 0.0790
Epoch 6 [88/172] - loss: 0.0956
Epoch 6 [89/172] - loss: 0.0778
Epoch 6 [90/172] - loss: 0.0942, acc: 0.9688
Epoch 6 [91/172] - loss: 0.0732
Epoch 6 [92/172] - loss: 0.0748
Epoch 6 [93/172] - loss: 0.0738
Epoch 6 [94/172] - loss: 0.1490
Epoch 6 [95/172] - loss: 0.0740
Epoch 6 [96/172] - loss: 0.0725
Epoch 6 [97/172] - loss: 0.1220
Epoch 6 [98/172] - loss: 0.0785
Epoch 6 [99/172] - loss: 0.0752
Epoch 6 [100/172] - loss: 0.0933, acc: 0.9688
Epoch 6 [101/172] - loss: 0.1063
Epoch 6 [102/172] - loss: 0.0748
Epoch 6 [103/172] - loss: 0.0820
Epoch 6 [104/172] - loss: 0.1035
Epoch 6 [105/172] - loss: 0.0776
Epoch 6 [106/172] - loss: 0.0830
Epoch 6 [107/172] - loss: 0.0756
Epoch 6 [108/172] - loss: 0.1223
Epoch 6 [109/172] - loss: 0.1845
Epoch 6 [110/172] - loss: 0.0923, acc: 0.9688
Epoch 6 [111/172] - loss: 0.0865
Epoch 6 [112/172] - loss: 0.0757
Epoch 6 [113/172] - loss: 0.0967
Epoch 6 [114/172] - loss: 0.0822
Epoch 6 [115/172] - loss: 0.1426
Epoch 6 [116/172] - loss: 0.2092
Epoch 6 [117/172] - loss: 0.0837
Epoch 6 [118/172] - loss: 0.0752
Epoch 6 [119/172] - loss: 0.1444
Epoch 6 [120/172] - loss: 0.0971, acc: 0.9688
Epoch 6 [121/172] - loss: 0.0807
Epoch 6 [122/172] - loss: 0.0922
Epoch 6 [123/172] - loss: 0.0788
Epoch 6 [124/172] - loss: 0.0759
Epoch 6 [125/172] - loss: 0.0965
Epoch 6 [126/172] - loss: 0.0937
Epoch 6 [127/172] - loss: 0.1059
Epoch 6 [128/172] - loss: 0.0905
Epoch 6 [129/172] - loss: 0.0823
Epoch 6 [130/172] - loss: 0.0879, acc: 1.0000
Epoch 6 [131/172] - loss: 0.1002
Epoch 6 [132/172] - loss: 0.1382
Epoch 6 [133/172] - loss: 0.0783
Epoch 6 [134/172] - loss: 0.0758
Epoch 6 [135/172] - loss: 0.0855
Epoch 6 [136/172] - loss: 0.0773
Epoch 6 [137/172] - loss: 0.0826
Epoch 6 [138/172] - loss: 0.0777
Epoch 6 [139/172] - loss: 0.0907
Epoch 6 [140/172] - loss: 0.0903, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1993, log_difficulty=0.1817, weight=1.9085
neutral: count=9796.0, difficulty=0.1543, log_difficulty=0.1435, weight=1.7176
negative: count=10972.0, difficulty=0.1957, log_difficulty=0.1787, weight=1.8936

当前batch的pt分布：
positive: min=0.9298, max=0.9988, mean=0.9796
neutral: min=0.9465, max=0.9978, mean=0.9793
negative: min=0.1016, max=0.9920, mean=0.8884

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9231

损失分量：
基础交叉熵: 0.1025
焦点损失: 0.0580
边界损失: 0.1519
总损失: 0.1308
Epoch 6 [141/172] - loss: 0.1308
Epoch 6 [142/172] - loss: 0.0859
Epoch 6 [143/172] - loss: 0.0778
Epoch 6 [144/172] - loss: 0.0793
Epoch 6 [145/172] - loss: 0.0775
Epoch 6 [146/172] - loss: 0.0917
Epoch 6 [147/172] - loss: 0.0825
Epoch 6 [148/172] - loss: 0.0997
Epoch 6 [149/172] - loss: 0.1092
Epoch 6 [150/172] - loss: 0.0827, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1162
Epoch 6 [152/172] - loss: 0.0912
Epoch 6 [153/172] - loss: 0.0811
Epoch 6 [154/172] - loss: 0.1408
Epoch 6 [155/172] - loss: 0.0893
Epoch 6 [156/172] - loss: 0.1774
Epoch 6 [157/172] - loss: 0.0744
Epoch 6 [158/172] - loss: 0.1137
Epoch 6 [159/172] - loss: 0.0817
Epoch 6 [160/172] - loss: 0.1760, acc: 0.9688
Epoch 6 [161/172] - loss: 0.0808
Epoch 6 [162/172] - loss: 0.1339
Epoch 6 [163/172] - loss: 0.1184
Epoch 6 [164/172] - loss: 0.0981
Epoch 6 [165/172] - loss: 0.3299
Epoch 6 [166/172] - loss: 0.1279
Epoch 6 [167/172] - loss: 0.1163
Epoch 6 [168/172] - loss: 0.1056
Epoch 6 [169/172] - loss: 0.0895
Epoch 6 [170/172] - loss: 0.0916, acc: 0.9688
Epoch 6 [171/172] - loss: 0.0784
Epoch 6 [172/172] - loss: 0.0863

类别准确率:
positive: 0.8929 (417/467)
neutral: 0.3133 (26/83)
negative: 0.5440 (136/250)

Epoch 6/10
Train Loss: 0.1189, Train Acc: 0.9737
Val Loss: 0.8198, Val Acc: 0.7238
Epoch 7 [1/172] - loss: 0.0834, acc: 1.0000
Epoch 7 [2/172] - loss: 0.1214
Epoch 7 [3/172] - loss: 0.0768
Epoch 7 [4/172] - loss: 0.0889
Epoch 7 [5/172] - loss: 0.0783
Epoch 7 [6/172] - loss: 0.1041
Epoch 7 [7/172] - loss: 0.0844
Epoch 7 [8/172] - loss: 0.1115
Epoch 7 [9/172] - loss: 0.0749
Epoch 7 [10/172] - loss: 0.0852, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0869
Epoch 7 [12/172] - loss: 0.1407
Epoch 7 [13/172] - loss: 0.0851
Epoch 7 [14/172] - loss: 0.0776
Epoch 7 [15/172] - loss: 0.1184
Epoch 7 [16/172] - loss: 0.0864
Epoch 7 [17/172] - loss: 0.1760
Epoch 7 [18/172] - loss: 0.0738
Epoch 7 [19/172] - loss: 0.0828
Epoch 7 [20/172] - loss: 0.0774, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0954
Epoch 7 [22/172] - loss: 0.0821
Epoch 7 [23/172] - loss: 0.0825
Epoch 7 [24/172] - loss: 0.0831
Epoch 7 [25/172] - loss: 0.0786
Epoch 7 [26/172] - loss: 0.0965
Epoch 7 [27/172] - loss: 0.1176
Epoch 7 [28/172] - loss: 0.1400
Epoch 7 [29/172] - loss: 0.2082
Epoch 7 [30/172] - loss: 0.1534, acc: 0.9688
Epoch 7 [31/172] - loss: 0.1826
Epoch 7 [32/172] - loss: 0.0736
Epoch 7 [33/172] - loss: 0.0757
Epoch 7 [34/172] - loss: 0.0783
Epoch 7 [35/172] - loss: 0.0778
Epoch 7 [36/172] - loss: 0.1414
Epoch 7 [37/172] - loss: 0.0800
Epoch 7 [38/172] - loss: 0.0774
Epoch 7 [39/172] - loss: 0.0940
Epoch 7 [40/172] - loss: 0.0911, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0810
Epoch 7 [42/172] - loss: 0.0755
Epoch 7 [43/172] - loss: 0.0783
Epoch 7 [44/172] - loss: 0.0901
Epoch 7 [45/172] - loss: 0.0940
Epoch 7 [46/172] - loss: 0.1141
Epoch 7 [47/172] - loss: 0.1958
Epoch 7 [48/172] - loss: 0.0831
Epoch 7 [49/172] - loss: 0.1290
Epoch 7 [50/172] - loss: 0.0775, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1431
Epoch 7 [52/172] - loss: 0.0761
Epoch 7 [53/172] - loss: 0.0824
Epoch 7 [54/172] - loss: 0.0863
Epoch 7 [55/172] - loss: 0.0896
Epoch 7 [56/172] - loss: 0.0881
Epoch 7 [57/172] - loss: 0.2029
Epoch 7 [58/172] - loss: 0.1003
Epoch 7 [59/172] - loss: 0.0812
Epoch 7 [60/172] - loss: 0.1133, acc: 1.0000
Epoch 7 [61/172] - loss: 0.1551
Epoch 7 [62/172] - loss: 0.0942
Epoch 7 [63/172] - loss: 0.1664
Epoch 7 [64/172] - loss: 0.1030
Epoch 7 [65/172] - loss: 0.1215
Epoch 7 [66/172] - loss: 0.0769
Epoch 7 [67/172] - loss: 0.1082
Epoch 7 [68/172] - loss: 0.0820

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1878, log_difficulty=0.1721, weight=1.8604
neutral: count=10756.0, difficulty=0.1437, log_difficulty=0.1343, weight=1.6715
negative: count=12072.0, difficulty=0.1848, log_difficulty=0.1696, weight=1.8478

当前batch的pt分布：
positive: min=0.9865, max=0.9972, mean=0.9906
neutral: min=0.9305, max=0.9993, mean=0.9861
negative: min=0.6784, max=0.9932, mean=0.9046

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0538
焦点损失: 0.0029
边界损失: 0.1607
总损失: 0.0830
Epoch 7 [69/172] - loss: 0.0830
Epoch 7 [70/172] - loss: 0.0784, acc: 1.0000
Epoch 7 [71/172] - loss: 0.0780
Epoch 7 [72/172] - loss: 0.0811
Epoch 7 [73/172] - loss: 0.1775
Epoch 7 [74/172] - loss: 0.0794
Epoch 7 [75/172] - loss: 0.0785
Epoch 7 [76/172] - loss: 0.1583
Epoch 7 [77/172] - loss: 0.1174
Epoch 7 [78/172] - loss: 0.0807
Epoch 7 [79/172] - loss: 0.0954
Epoch 7 [80/172] - loss: 0.0850, acc: 1.0000
Epoch 7 [81/172] - loss: 0.0812
Epoch 7 [82/172] - loss: 0.0812
Epoch 7 [83/172] - loss: 0.1264
Epoch 7 [84/172] - loss: 0.0802
Epoch 7 [85/172] - loss: 0.0927
Epoch 7 [86/172] - loss: 0.0777
Epoch 7 [87/172] - loss: 0.0792
Epoch 7 [88/172] - loss: 0.0754
Epoch 7 [89/172] - loss: 0.0788
Epoch 7 [90/172] - loss: 0.0777, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0783
Epoch 7 [92/172] - loss: 0.0814
Epoch 7 [93/172] - loss: 0.0846
Epoch 7 [94/172] - loss: 0.0797
Epoch 7 [95/172] - loss: 0.0745
Epoch 7 [96/172] - loss: 0.0863
Epoch 7 [97/172] - loss: 0.0935
Epoch 7 [98/172] - loss: 0.1482
Epoch 7 [99/172] - loss: 0.0813
Epoch 7 [100/172] - loss: 0.0760, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0811
Epoch 7 [102/172] - loss: 0.0777
Epoch 7 [103/172] - loss: 0.0737
Epoch 7 [104/172] - loss: 0.0836
Epoch 7 [105/172] - loss: 0.0817
Epoch 7 [106/172] - loss: 0.2274
Epoch 7 [107/172] - loss: 0.0862
Epoch 7 [108/172] - loss: 0.0779
Epoch 7 [109/172] - loss: 0.1263
Epoch 7 [110/172] - loss: 0.0856, acc: 0.9688
Epoch 7 [111/172] - loss: 0.0778
Epoch 7 [112/172] - loss: 0.0804
Epoch 7 [113/172] - loss: 0.0749
Epoch 7 [114/172] - loss: 0.0741
Epoch 7 [115/172] - loss: 0.0754
Epoch 7 [116/172] - loss: 0.1069
Epoch 7 [117/172] - loss: 0.0815
Epoch 7 [118/172] - loss: 0.0867
Epoch 7 [119/172] - loss: 0.0922
Epoch 7 [120/172] - loss: 0.0772, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0903
Epoch 7 [122/172] - loss: 0.0824
Epoch 7 [123/172] - loss: 0.0890
Epoch 7 [124/172] - loss: 0.1127
Epoch 7 [125/172] - loss: 0.0742
Epoch 7 [126/172] - loss: 0.0850
Epoch 7 [127/172] - loss: 0.0849
Epoch 7 [128/172] - loss: 0.0811
Epoch 7 [129/172] - loss: 0.0769
Epoch 7 [130/172] - loss: 0.0805, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1481
Epoch 7 [132/172] - loss: 0.2070
Epoch 7 [133/172] - loss: 0.0741
Epoch 7 [134/172] - loss: 0.0770
Epoch 7 [135/172] - loss: 0.1861
Epoch 7 [136/172] - loss: 0.0739
Epoch 7 [137/172] - loss: 0.0813
Epoch 7 [138/172] - loss: 0.0728
Epoch 7 [139/172] - loss: 0.1062
Epoch 7 [140/172] - loss: 0.0740, acc: 1.0000
Epoch 7 [141/172] - loss: 0.0746
Epoch 7 [142/172] - loss: 0.1075
Epoch 7 [143/172] - loss: 0.0830
Epoch 7 [144/172] - loss: 0.0766
Epoch 7 [145/172] - loss: 0.1709
Epoch 7 [146/172] - loss: 0.1503
Epoch 7 [147/172] - loss: 0.1041
Epoch 7 [148/172] - loss: 0.1036
Epoch 7 [149/172] - loss: 0.0867
Epoch 7 [150/172] - loss: 0.0960, acc: 0.9688
Epoch 7 [151/172] - loss: 0.1125
Epoch 7 [152/172] - loss: 0.0760
Epoch 7 [153/172] - loss: 0.1156
Epoch 7 [154/172] - loss: 0.0858
Epoch 7 [155/172] - loss: 0.0731
Epoch 7 [156/172] - loss: 0.1498
Epoch 7 [157/172] - loss: 0.0892
Epoch 7 [158/172] - loss: 0.0768
Epoch 7 [159/172] - loss: 0.0767
Epoch 7 [160/172] - loss: 0.0753, acc: 1.0000
Epoch 7 [161/172] - loss: 0.0750
Epoch 7 [162/172] - loss: 0.1015
Epoch 7 [163/172] - loss: 0.0766
Epoch 7 [164/172] - loss: 0.1314
Epoch 7 [165/172] - loss: 0.1093
Epoch 7 [166/172] - loss: 0.0753
Epoch 7 [167/172] - loss: 0.1331
Epoch 7 [168/172] - loss: 0.0782

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1763, log_difficulty=0.1624, weight=1.8120
neutral: count=11731.0, difficulty=0.1350, log_difficulty=0.1266, weight=1.6329
negative: count=13173.0, difficulty=0.1742, log_difficulty=0.1606, weight=1.8029

当前batch的pt分布：
positive: min=0.9646, max=0.9953, mean=0.9869
neutral: min=0.9546, max=0.9988, mean=0.9824
negative: min=0.9081, max=0.9969, mean=0.9672

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0223
焦点损失: 0.0001
边界损失: 0.1457
总损失: 0.0729
Epoch 7 [169/172] - loss: 0.0729
Epoch 7 [170/172] - loss: 0.1160, acc: 0.9688
Epoch 7 [171/172] - loss: 0.0751
Epoch 7 [172/172] - loss: 0.0717

类别准确率:
positive: 0.7773 (363/467)
neutral: 0.3976 (33/83)
negative: 0.6480 (162/250)

Epoch 7/10
Train Loss: 0.0896, Train Acc: 0.9818
Val Loss: 0.9105, Val Acc: 0.6975
Epoch 8 [1/172] - loss: 0.0746, acc: 1.0000
Epoch 8 [2/172] - loss: 0.1443
Epoch 8 [3/172] - loss: 0.0744
Epoch 8 [4/172] - loss: 0.0739
Epoch 8 [5/172] - loss: 0.0848
Epoch 8 [6/172] - loss: 0.1272
Epoch 8 [7/172] - loss: 0.0774
Epoch 8 [8/172] - loss: 0.0724
Epoch 8 [9/172] - loss: 0.0911
Epoch 8 [10/172] - loss: 0.1099, acc: 0.9375
Epoch 8 [11/172] - loss: 0.1010
Epoch 8 [12/172] - loss: 0.1054
Epoch 8 [13/172] - loss: 0.0793
Epoch 8 [14/172] - loss: 0.0847
Epoch 8 [15/172] - loss: 0.0823
Epoch 8 [16/172] - loss: 0.0908
Epoch 8 [17/172] - loss: 0.0746
Epoch 8 [18/172] - loss: 0.0726
Epoch 8 [19/172] - loss: 0.0767
Epoch 8 [20/172] - loss: 0.0755, acc: 1.0000
Epoch 8 [21/172] - loss: 0.0755
Epoch 8 [22/172] - loss: 0.0989
Epoch 8 [23/172] - loss: 0.1488
Epoch 8 [24/172] - loss: 0.0962
Epoch 8 [25/172] - loss: 0.1408
Epoch 8 [26/172] - loss: 0.0797
Epoch 8 [27/172] - loss: 0.1029
Epoch 8 [28/172] - loss: 0.0777
Epoch 8 [29/172] - loss: 0.0830
Epoch 8 [30/172] - loss: 0.0720, acc: 1.0000
Epoch 8 [31/172] - loss: 0.0737
Epoch 8 [32/172] - loss: 0.0752
Epoch 8 [33/172] - loss: 0.0815
Epoch 8 [34/172] - loss: 0.0834
Epoch 8 [35/172] - loss: 0.0786
Epoch 8 [36/172] - loss: 0.0743
Epoch 8 [37/172] - loss: 0.1823
Epoch 8 [38/172] - loss: 0.0777
Epoch 8 [39/172] - loss: 0.0778
Epoch 8 [40/172] - loss: 0.0753, acc: 1.0000
Epoch 8 [41/172] - loss: 0.0771
Epoch 8 [42/172] - loss: 0.0870
Epoch 8 [43/172] - loss: 0.0859
Epoch 8 [44/172] - loss: 0.0753
Epoch 8 [45/172] - loss: 0.0758
Epoch 8 [46/172] - loss: 0.0809
Epoch 8 [47/172] - loss: 0.0738
Epoch 8 [48/172] - loss: 0.1172
Epoch 8 [49/172] - loss: 0.0731
Epoch 8 [50/172] - loss: 0.0735, acc: 1.0000
Epoch 8 [51/172] - loss: 0.0767
Epoch 8 [52/172] - loss: 0.0804
Epoch 8 [53/172] - loss: 0.0911
Epoch 8 [54/172] - loss: 0.0964
Epoch 8 [55/172] - loss: 0.0726
Epoch 8 [56/172] - loss: 0.0762
Epoch 8 [57/172] - loss: 0.0733
Epoch 8 [58/172] - loss: 0.0738
Epoch 8 [59/172] - loss: 0.0758
Epoch 8 [60/172] - loss: 0.0725, acc: 1.0000
Epoch 8 [61/172] - loss: 0.0808
Epoch 8 [62/172] - loss: 0.0724
Epoch 8 [63/172] - loss: 0.0721
Epoch 8 [64/172] - loss: 0.1157
Epoch 8 [65/172] - loss: 0.0748
Epoch 8 [66/172] - loss: 0.0877
Epoch 8 [67/172] - loss: 0.0797
Epoch 8 [68/172] - loss: 0.0737
Epoch 8 [69/172] - loss: 0.0768
Epoch 8 [70/172] - loss: 0.0725, acc: 1.0000
Epoch 8 [71/172] - loss: 0.1136
Epoch 8 [72/172] - loss: 0.0731
Epoch 8 [73/172] - loss: 0.0854
Epoch 8 [74/172] - loss: 0.0742
Epoch 8 [75/172] - loss: 0.0738
Epoch 8 [76/172] - loss: 0.1673
Epoch 8 [77/172] - loss: 0.0726
Epoch 8 [78/172] - loss: 0.0994
Epoch 8 [79/172] - loss: 0.0913
Epoch 8 [80/172] - loss: 0.0831, acc: 1.0000
Epoch 8 [81/172] - loss: 0.0763
Epoch 8 [82/172] - loss: 0.0733
Epoch 8 [83/172] - loss: 0.0728
Epoch 8 [84/172] - loss: 0.0770
Epoch 8 [85/172] - loss: 0.0745
Epoch 8 [86/172] - loss: 0.0744
Epoch 8 [87/172] - loss: 0.0722
Epoch 8 [88/172] - loss: 0.0942
Epoch 8 [89/172] - loss: 0.0727
Epoch 8 [90/172] - loss: 0.0744, acc: 1.0000
Epoch 8 [91/172] - loss: 0.1026
Epoch 8 [92/172] - loss: 0.0892
Epoch 8 [93/172] - loss: 0.0732
Epoch 8 [94/172] - loss: 0.0840
Epoch 8 [95/172] - loss: 0.0736
Epoch 8 [96/172] - loss: 0.0737

=== 第 1301 次迭代调试信息 ===
当前类别统计：
positive: count=14487.0, difficulty=0.1660, log_difficulty=0.1536, weight=1.7681
neutral: count=12738.0, difficulty=0.1270, log_difficulty=0.1196, weight=1.5980
negative: count=14288.0, difficulty=0.1639, log_difficulty=0.1518, weight=1.7590

当前batch的pt分布：
positive: min=0.9373, max=0.9991, mean=0.9777
neutral: min=0.3483, max=0.9932, mean=0.9295
negative: min=0.9754, max=0.9994, mean=0.9934

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9333
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0544
焦点损失: 0.0149
边界损失: 0.1527
总损失: 0.0883
Epoch 8 [97/172] - loss: 0.0883
Epoch 8 [98/172] - loss: 0.0809
Epoch 8 [99/172] - loss: 0.0737
Epoch 8 [100/172] - loss: 0.0807, acc: 1.0000
Epoch 8 [101/172] - loss: 0.0975
Epoch 8 [102/172] - loss: 0.0834
Epoch 8 [103/172] - loss: 0.1361
Epoch 8 [104/172] - loss: 0.0789
Epoch 8 [105/172] - loss: 0.0755
Epoch 8 [106/172] - loss: 0.0821
Epoch 8 [107/172] - loss: 0.0769
Epoch 8 [108/172] - loss: 0.0732
Epoch 8 [109/172] - loss: 0.0860
Epoch 8 [110/172] - loss: 0.0821, acc: 1.0000
Epoch 8 [111/172] - loss: 0.1115
Epoch 8 [112/172] - loss: 0.0887
Epoch 8 [113/172] - loss: 0.0724
Epoch 8 [114/172] - loss: 0.0720
Epoch 8 [115/172] - loss: 0.0732
Epoch 8 [116/172] - loss: 0.0710
Epoch 8 [117/172] - loss: 0.0740
Epoch 8 [118/172] - loss: 0.0726
Epoch 8 [119/172] - loss: 0.0733
Epoch 8 [120/172] - loss: 0.0761, acc: 1.0000
Epoch 8 [121/172] - loss: 0.0902
Epoch 8 [122/172] - loss: 0.0735
Epoch 8 [123/172] - loss: 0.0759
Epoch 8 [124/172] - loss: 0.0729
Epoch 8 [125/172] - loss: 0.0789
Epoch 8 [126/172] - loss: 0.0739
Epoch 8 [127/172] - loss: 0.0884
Epoch 8 [128/172] - loss: 0.0910
Epoch 8 [129/172] - loss: 0.0744
Epoch 8 [130/172] - loss: 0.0758, acc: 1.0000
Epoch 8 [131/172] - loss: 0.0739
Epoch 8 [132/172] - loss: 0.0721
Epoch 8 [133/172] - loss: 0.0772
Epoch 8 [134/172] - loss: 0.0747
Epoch 8 [135/172] - loss: 0.0719
Epoch 8 [136/172] - loss: 0.0883
Epoch 8 [137/172] - loss: 0.0824
Epoch 8 [138/172] - loss: 0.1395
Epoch 8 [139/172] - loss: 0.0762
Epoch 8 [140/172] - loss: 0.0706, acc: 1.0000
Epoch 8 [141/172] - loss: 0.0710
Epoch 8 [142/172] - loss: 0.0788
Epoch 8 [143/172] - loss: 0.0760
Epoch 8 [144/172] - loss: 0.0811
Epoch 8 [145/172] - loss: 0.0823
Epoch 8 [146/172] - loss: 0.0766
Epoch 8 [147/172] - loss: 0.0733
Epoch 8 [148/172] - loss: 0.0859
Epoch 8 [149/172] - loss: 0.0746
Epoch 8 [150/172] - loss: 0.1085, acc: 0.9688
Epoch 8 [151/172] - loss: 0.0795
Epoch 8 [152/172] - loss: 0.0885
Epoch 8 [153/172] - loss: 0.0764
Epoch 8 [154/172] - loss: 0.1004
Epoch 8 [155/172] - loss: 0.0749
Epoch 8 [156/172] - loss: 0.0757
Epoch 8 [157/172] - loss: 0.0835
Epoch 8 [158/172] - loss: 0.0795
Epoch 8 [159/172] - loss: 0.0819
Epoch 8 [160/172] - loss: 0.0792, acc: 1.0000
Epoch 8 [161/172] - loss: 0.0722
Epoch 8 [162/172] - loss: 0.0890
Epoch 8 [163/172] - loss: 0.0755
Epoch 8 [164/172] - loss: 0.0773
Epoch 8 [165/172] - loss: 0.0721
Epoch 8 [166/172] - loss: 0.0897
Epoch 8 [167/172] - loss: 0.0726
Epoch 8 [168/172] - loss: 0.0738
Epoch 8 [169/172] - loss: 0.0875
Epoch 8 [170/172] - loss: 0.0749, acc: 1.0000
Epoch 8 [171/172] - loss: 0.0780
Epoch 8 [172/172] - loss: 0.0795

类别准确率:
positive: 0.8715 (407/467)
neutral: 0.2410 (20/83)
negative: 0.5640 (141/250)

Epoch 8/10
Train Loss: 0.0791, Train Acc: 0.9939
Val Loss: 0.8955, Val Acc: 0.7100
Early stopping triggered!
Best validation accuracy: 0.7412

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_073522-g36v8cak
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.3_Multimodal_iterations_20250118_073521
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/g36v8cak
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████
wandb:  train_acc ▁▄▃▆▆▆▆▇▆▇▇████▇████▇███████▇███████████
wandb: train_loss █▅▅▄▆▃▃▃▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1374
wandb:  train_acc 1
wandb: train_loss 0.07492
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.3_Multimodal_iterations_20250118_073521 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/g36v8cak
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_073522-g36v8cak/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_074715-afewwtxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.3_Multimodal_epochs_20250118_074715
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/afewwtxw
wandb: uploading history steps 0-0, summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▄▅▆▇█
wandb:  train_acc ▁▅▇▇█▇██
wandb: train_loss █▄▂▂▁▂▁▁
wandb:    val_acc ▁▇▇▇█▇▆▇
wandb:   val_loss █▁▃▃▄▅▇▇
wandb: 
wandb: Run summary:
wandb:      epoch 8
wandb:  train_acc 0.99394
wandb: train_loss 0.07913
wandb:    val_acc 0.71
wandb:   val_loss 0.89551
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.3_Multimodal_epochs_20250118_074715 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/afewwtxw
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_074715-afewwtxw/logs

