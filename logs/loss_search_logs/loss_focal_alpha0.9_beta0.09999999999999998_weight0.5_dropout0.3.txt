=== 命令 ===
python main.py --loss_type focal --alpha 0.9 --beta 0.09999999999999998 --neural_init_weight 0.5 --dropout 0.3 --name loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.3 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.3
text_dim: 128
image_dim: 256
dropout: 0.3
loss_type: focal
alpha: 0.9
beta: 0.09999999999999998
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6550, log_difficulty=0.5038, weight=3.5189
neutral: count=7.0, difficulty=0.6497, log_difficulty=0.5006, weight=3.5030
negative: count=13.0, difficulty=0.6585, log_difficulty=0.5059, weight=3.5296

当前batch的pt分布：
positive: min=0.1676, max=0.4795, mean=0.3450
neutral: min=0.2251, max=0.6644, mean=0.3503
negative: min=0.0251, max=0.6644, mean=0.3415

当前batch准确率：
整体准确率: 0.4062
positive 准确率: 0.5000
neutral 准确率: 0.4286
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1613
焦点损失: 0.4436
边界损失: 0.7799
总损失: 1.4837
Epoch 1 [1/172] - loss: 1.4837, acc: 0.4062
Epoch 1 [2/172] - loss: 1.1114
Epoch 1 [3/172] - loss: 1.7088
Epoch 1 [4/172] - loss: 1.3436
Epoch 1 [5/172] - loss: 1.0558
Epoch 1 [6/172] - loss: 1.7303
Epoch 1 [7/172] - loss: 1.8200
Epoch 1 [8/172] - loss: 1.5561
Epoch 1 [9/172] - loss: 1.0922
Epoch 1 [10/172] - loss: 1.2796, acc: 0.4062
Epoch 1 [11/172] - loss: 1.2274
Epoch 1 [12/172] - loss: 1.3186
Epoch 1 [13/172] - loss: 1.3132
Epoch 1 [14/172] - loss: 1.2295
Epoch 1 [15/172] - loss: 1.2854
Epoch 1 [16/172] - loss: 1.6361
Epoch 1 [17/172] - loss: 1.1395
Epoch 1 [18/172] - loss: 1.0123
Epoch 1 [19/172] - loss: 1.1037
Epoch 1 [20/172] - loss: 2.1196, acc: 0.3125
Epoch 1 [21/172] - loss: 1.5264
Epoch 1 [22/172] - loss: 1.1041
Epoch 1 [23/172] - loss: 1.1258
Epoch 1 [24/172] - loss: 0.9802
Epoch 1 [25/172] - loss: 1.4542
Epoch 1 [26/172] - loss: 0.9476
Epoch 1 [27/172] - loss: 1.1307
Epoch 1 [28/172] - loss: 0.8117
Epoch 1 [29/172] - loss: 1.1878
Epoch 1 [30/172] - loss: 0.7244, acc: 0.7500
Epoch 1 [31/172] - loss: 0.8134
Epoch 1 [32/172] - loss: 0.8788
Epoch 1 [33/172] - loss: 0.8593
Epoch 1 [34/172] - loss: 1.2329
Epoch 1 [35/172] - loss: 1.2387
Epoch 1 [36/172] - loss: 0.8253
Epoch 1 [37/172] - loss: 0.9724
Epoch 1 [38/172] - loss: 1.0121
Epoch 1 [39/172] - loss: 0.9837
Epoch 1 [40/172] - loss: 1.1240, acc: 0.6250
Epoch 1 [41/172] - loss: 0.9681
Epoch 1 [42/172] - loss: 1.1085
Epoch 1 [43/172] - loss: 1.0707
Epoch 1 [44/172] - loss: 1.1332
Epoch 1 [45/172] - loss: 1.2346
Epoch 1 [46/172] - loss: 1.0155
Epoch 1 [47/172] - loss: 1.1349
Epoch 1 [48/172] - loss: 1.2252
Epoch 1 [49/172] - loss: 0.9547
Epoch 1 [50/172] - loss: 0.8845, acc: 0.6562
Epoch 1 [51/172] - loss: 1.1042
Epoch 1 [52/172] - loss: 1.1548
Epoch 1 [53/172] - loss: 1.2135
Epoch 1 [54/172] - loss: 1.3723
Epoch 1 [55/172] - loss: 0.8192
Epoch 1 [56/172] - loss: 0.7759
Epoch 1 [57/172] - loss: 1.0056
Epoch 1 [58/172] - loss: 0.8756
Epoch 1 [59/172] - loss: 1.0164
Epoch 1 [60/172] - loss: 0.9423, acc: 0.5000
Epoch 1 [61/172] - loss: 0.8382
Epoch 1 [62/172] - loss: 0.8996
Epoch 1 [63/172] - loss: 0.8844
Epoch 1 [64/172] - loss: 0.6444
Epoch 1 [65/172] - loss: 1.0107
Epoch 1 [66/172] - loss: 0.9072
Epoch 1 [67/172] - loss: 1.1358
Epoch 1 [68/172] - loss: 1.3528
Epoch 1 [69/172] - loss: 1.1149
Epoch 1 [70/172] - loss: 0.8104, acc: 0.5938
Epoch 1 [71/172] - loss: 0.5836
Epoch 1 [72/172] - loss: 0.7722
Epoch 1 [73/172] - loss: 0.8132
Epoch 1 [74/172] - loss: 0.9728
Epoch 1 [75/172] - loss: 0.6584
Epoch 1 [76/172] - loss: 1.1651
Epoch 1 [77/172] - loss: 0.8239
Epoch 1 [78/172] - loss: 0.9208
Epoch 1 [79/172] - loss: 0.9345
Epoch 1 [80/172] - loss: 0.6295, acc: 0.6875
Epoch 1 [81/172] - loss: 0.8600
Epoch 1 [82/172] - loss: 1.4939
Epoch 1 [83/172] - loss: 0.8865
Epoch 1 [84/172] - loss: 0.8660
Epoch 1 [85/172] - loss: 1.0023
Epoch 1 [86/172] - loss: 0.8512
Epoch 1 [87/172] - loss: 0.6485
Epoch 1 [88/172] - loss: 1.4815
Epoch 1 [89/172] - loss: 1.1537
Epoch 1 [90/172] - loss: 0.7382, acc: 0.5625
Epoch 1 [91/172] - loss: 0.7593
Epoch 1 [92/172] - loss: 0.7978
Epoch 1 [93/172] - loss: 0.6835
Epoch 1 [94/172] - loss: 0.5883
Epoch 1 [95/172] - loss: 0.7290
Epoch 1 [96/172] - loss: 0.8709
Epoch 1 [97/172] - loss: 0.7034
Epoch 1 [98/172] - loss: 0.5862
Epoch 1 [99/172] - loss: 1.0305
Epoch 1 [100/172] - loss: 0.9134, acc: 0.6875

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5958, log_difficulty=0.4674, weight=3.3369
neutral: count=983.0, difficulty=0.5745, log_difficulty=0.4539, weight=3.2697
negative: count=1119.0, difficulty=0.5812, log_difficulty=0.4582, weight=3.2909

当前batch的pt分布：
positive: min=0.0619, max=0.8066, mean=0.4173
neutral: min=0.2801, max=0.8872, mean=0.6122
negative: min=0.1666, max=0.7447, mean=0.4446

当前batch准确率：
整体准确率: 0.5938
positive 准确率: 0.5833
neutral 准确率: 0.7500
negative 准确率: 0.5625

损失分量：
基础交叉熵: 0.9248
焦点损失: 0.3453
边界损失: 0.5507
总损失: 1.0847
Epoch 1 [101/172] - loss: 1.0847
Epoch 1 [102/172] - loss: 0.8904
Epoch 1 [103/172] - loss: 0.8024
Epoch 1 [104/172] - loss: 0.5317
Epoch 1 [105/172] - loss: 0.6576
Epoch 1 [106/172] - loss: 1.3847
Epoch 1 [107/172] - loss: 0.6010
Epoch 1 [108/172] - loss: 0.9576
Epoch 1 [109/172] - loss: 0.9002
Epoch 1 [110/172] - loss: 1.0681, acc: 0.5000
Epoch 1 [111/172] - loss: 0.7199
Epoch 1 [112/172] - loss: 0.5156
Epoch 1 [113/172] - loss: 0.6451
Epoch 1 [114/172] - loss: 0.5765
Epoch 1 [115/172] - loss: 0.7042
Epoch 1 [116/172] - loss: 0.7406
Epoch 1 [117/172] - loss: 0.7962
Epoch 1 [118/172] - loss: 0.5690
Epoch 1 [119/172] - loss: 0.9152
Epoch 1 [120/172] - loss: 0.5071, acc: 0.6875
Epoch 1 [121/172] - loss: 0.3466
Epoch 1 [122/172] - loss: 0.8000
Epoch 1 [123/172] - loss: 0.4122
Epoch 1 [124/172] - loss: 0.7124
Epoch 1 [125/172] - loss: 0.4427
Epoch 1 [126/172] - loss: 1.0046
Epoch 1 [127/172] - loss: 0.6998
Epoch 1 [128/172] - loss: 0.5663
Epoch 1 [129/172] - loss: 1.0601
Epoch 1 [130/172] - loss: 0.5044, acc: 0.7188
Epoch 1 [131/172] - loss: 0.3601
Epoch 1 [132/172] - loss: 0.5984
Epoch 1 [133/172] - loss: 0.6064
Epoch 1 [134/172] - loss: 0.5177
Epoch 1 [135/172] - loss: 0.5500
Epoch 1 [136/172] - loss: 0.5658
Epoch 1 [137/172] - loss: 0.7959
Epoch 1 [138/172] - loss: 0.5222
Epoch 1 [139/172] - loss: 0.3453
Epoch 1 [140/172] - loss: 0.3800, acc: 0.7500
Epoch 1 [141/172] - loss: 0.5397
Epoch 1 [142/172] - loss: 0.5634
Epoch 1 [143/172] - loss: 0.8484
Epoch 1 [144/172] - loss: 0.2270
Epoch 1 [145/172] - loss: 0.5431
Epoch 1 [146/172] - loss: 0.8949
Epoch 1 [147/172] - loss: 0.7092
Epoch 1 [148/172] - loss: 0.4596
Epoch 1 [149/172] - loss: 0.4028
Epoch 1 [150/172] - loss: 0.5878, acc: 0.6250
Epoch 1 [151/172] - loss: 0.4553
Epoch 1 [152/172] - loss: 0.6386
Epoch 1 [153/172] - loss: 0.7073
Epoch 1 [154/172] - loss: 0.4154
Epoch 1 [155/172] - loss: 0.9149
Epoch 1 [156/172] - loss: 0.4957
Epoch 1 [157/172] - loss: 0.5509
Epoch 1 [158/172] - loss: 0.5784
Epoch 1 [159/172] - loss: 0.8940
Epoch 1 [160/172] - loss: 0.5064, acc: 0.7500
Epoch 1 [161/172] - loss: 0.5803
Epoch 1 [162/172] - loss: 0.6737
Epoch 1 [163/172] - loss: 0.8541
Epoch 1 [164/172] - loss: 0.8749
Epoch 1 [165/172] - loss: 0.5559
Epoch 1 [166/172] - loss: 0.5289
Epoch 1 [167/172] - loss: 0.4325
Epoch 1 [168/172] - loss: 0.4605
Epoch 1 [169/172] - loss: 0.5969
Epoch 1 [170/172] - loss: 0.4531, acc: 0.7500
Epoch 1 [171/172] - loss: 0.4297
Epoch 1 [172/172] - loss: 0.3514

类别准确率:
positive: 0.6809 (318/467)
neutral: 0.6386 (53/83)
negative: 0.5000 (125/250)

Epoch 1/10
Train Loss: 0.5826, Train Acc: 0.7475
Val Loss: 0.8407, Val Acc: 0.6200
Epoch 2 [1/172] - loss: 0.6925, acc: 0.7500
Epoch 2 [2/172] - loss: 0.3319
Epoch 2 [3/172] - loss: 0.4358
Epoch 2 [4/172] - loss: 0.5731
Epoch 2 [5/172] - loss: 0.6970
Epoch 2 [6/172] - loss: 0.4712
Epoch 2 [7/172] - loss: 0.7717
Epoch 2 [8/172] - loss: 0.3735
Epoch 2 [9/172] - loss: 0.4703
Epoch 2 [10/172] - loss: 0.4420, acc: 0.7812
Epoch 2 [11/172] - loss: 0.4004
Epoch 2 [12/172] - loss: 0.2321
Epoch 2 [13/172] - loss: 0.5663
Epoch 2 [14/172] - loss: 0.4456
Epoch 2 [15/172] - loss: 0.5126
Epoch 2 [16/172] - loss: 0.4468
Epoch 2 [17/172] - loss: 0.4348
Epoch 2 [18/172] - loss: 0.4465
Epoch 2 [19/172] - loss: 0.3640
Epoch 2 [20/172] - loss: 0.3090, acc: 0.7812
Epoch 2 [21/172] - loss: 0.3762
Epoch 2 [22/172] - loss: 0.3209
Epoch 2 [23/172] - loss: 0.2103
Epoch 2 [24/172] - loss: 0.9137
Epoch 2 [25/172] - loss: 0.4184
Epoch 2 [26/172] - loss: 0.3637
Epoch 2 [27/172] - loss: 0.5425
Epoch 2 [28/172] - loss: 0.3758

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5364, log_difficulty=0.4294, weight=3.1471
neutral: count=1952.0, difficulty=0.4904, log_difficulty=0.3991, weight=2.9953
negative: count=2216.0, difficulty=0.5304, log_difficulty=0.4255, weight=3.1277

当前batch的pt分布：
positive: min=0.1832, max=0.9363, mean=0.6032
neutral: min=0.2888, max=0.8075, mean=0.5406
negative: min=0.2820, max=0.8103, mean=0.5447

当前batch准确率：
整体准确率: 0.6562
positive 准确率: 0.6667
neutral 准确率: 0.5455
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.6553
焦点损失: 0.1627
边界损失: 0.4871
总损失: 0.5006
Epoch 2 [29/172] - loss: 0.5006
Epoch 2 [30/172] - loss: 0.4013, acc: 0.8125
Epoch 2 [31/172] - loss: 0.3641
Epoch 2 [32/172] - loss: 0.3358
Epoch 2 [33/172] - loss: 0.3017
Epoch 2 [34/172] - loss: 0.5553
Epoch 2 [35/172] - loss: 0.2458
Epoch 2 [36/172] - loss: 0.5839
Epoch 2 [37/172] - loss: 0.1734
Epoch 2 [38/172] - loss: 0.2231
Epoch 2 [39/172] - loss: 0.3926
Epoch 2 [40/172] - loss: 0.2862, acc: 0.8438
Epoch 2 [41/172] - loss: 0.2724
Epoch 2 [42/172] - loss: 0.1588
Epoch 2 [43/172] - loss: 0.1600
Epoch 2 [44/172] - loss: 0.5194
Epoch 2 [45/172] - loss: 0.2253
Epoch 2 [46/172] - loss: 0.3108
Epoch 2 [47/172] - loss: 0.4645
Epoch 2 [48/172] - loss: 0.3450
Epoch 2 [49/172] - loss: 0.2788
Epoch 2 [50/172] - loss: 0.4351, acc: 0.7500
Epoch 2 [51/172] - loss: 0.3865
Epoch 2 [52/172] - loss: 0.2330
Epoch 2 [53/172] - loss: 0.3734
Epoch 2 [54/172] - loss: 0.2874
Epoch 2 [55/172] - loss: 0.2369
Epoch 2 [56/172] - loss: 0.2032
Epoch 2 [57/172] - loss: 0.2190
Epoch 2 [58/172] - loss: 0.3864
Epoch 2 [59/172] - loss: 0.3373
Epoch 2 [60/172] - loss: 0.1785, acc: 0.9688
Epoch 2 [61/172] - loss: 0.4073
Epoch 2 [62/172] - loss: 0.1381
Epoch 2 [63/172] - loss: 0.3578
Epoch 2 [64/172] - loss: 0.1987
Epoch 2 [65/172] - loss: 0.3266
Epoch 2 [66/172] - loss: 0.1341
Epoch 2 [67/172] - loss: 0.2699
Epoch 2 [68/172] - loss: 0.5331
Epoch 2 [69/172] - loss: 0.1915
Epoch 2 [70/172] - loss: 0.5621, acc: 0.8125
Epoch 2 [71/172] - loss: 0.4055
Epoch 2 [72/172] - loss: 0.4725
Epoch 2 [73/172] - loss: 0.3282
Epoch 2 [74/172] - loss: 0.2111
Epoch 2 [75/172] - loss: 0.1538
Epoch 2 [76/172] - loss: 0.2723
Epoch 2 [77/172] - loss: 0.2087
Epoch 2 [78/172] - loss: 0.2717
Epoch 2 [79/172] - loss: 0.2748
Epoch 2 [80/172] - loss: 0.1285, acc: 0.9688
Epoch 2 [81/172] - loss: 0.2017
Epoch 2 [82/172] - loss: 0.1491
Epoch 2 [83/172] - loss: 0.1782
Epoch 2 [84/172] - loss: 0.4431
Epoch 2 [85/172] - loss: 0.2319
Epoch 2 [86/172] - loss: 0.2613
Epoch 2 [87/172] - loss: 0.8219
Epoch 2 [88/172] - loss: 0.2411
Epoch 2 [89/172] - loss: 0.2537
Epoch 2 [90/172] - loss: 0.4545, acc: 0.7812
Epoch 2 [91/172] - loss: 0.1319
Epoch 2 [92/172] - loss: 0.2764
Epoch 2 [93/172] - loss: 0.2526
Epoch 2 [94/172] - loss: 0.5536
Epoch 2 [95/172] - loss: 0.4383
Epoch 2 [96/172] - loss: 0.1372
Epoch 2 [97/172] - loss: 0.2445
Epoch 2 [98/172] - loss: 0.2226
Epoch 2 [99/172] - loss: 0.1724
Epoch 2 [100/172] - loss: 0.2748, acc: 0.8750
Epoch 2 [101/172] - loss: 0.2309
Epoch 2 [102/172] - loss: 0.3181
Epoch 2 [103/172] - loss: 0.3555
Epoch 2 [104/172] - loss: 0.4407
Epoch 2 [105/172] - loss: 0.2697
Epoch 2 [106/172] - loss: 0.3025
Epoch 2 [107/172] - loss: 0.1602
Epoch 2 [108/172] - loss: 0.5712
Epoch 2 [109/172] - loss: 0.2252
Epoch 2 [110/172] - loss: 0.2638, acc: 0.8438
Epoch 2 [111/172] - loss: 0.3973
Epoch 2 [112/172] - loss: 0.1459
Epoch 2 [113/172] - loss: 0.1168
Epoch 2 [114/172] - loss: 0.2870
Epoch 2 [115/172] - loss: 0.1233
Epoch 2 [116/172] - loss: 0.4684
Epoch 2 [117/172] - loss: 0.4102
Epoch 2 [118/172] - loss: 0.1004
Epoch 2 [119/172] - loss: 0.2613
Epoch 2 [120/172] - loss: 0.2897, acc: 0.8438
Epoch 2 [121/172] - loss: 0.2832
Epoch 2 [122/172] - loss: 0.6627
Epoch 2 [123/172] - loss: 0.3517
Epoch 2 [124/172] - loss: 0.3366
Epoch 2 [125/172] - loss: 0.0960
Epoch 2 [126/172] - loss: 0.3303
Epoch 2 [127/172] - loss: 0.1620
Epoch 2 [128/172] - loss: 0.1958

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4819, log_difficulty=0.3934, weight=2.9668
neutral: count=2949.0, difficulty=0.4040, log_difficulty=0.3394, weight=2.6968
negative: count=3294.0, difficulty=0.4785, log_difficulty=0.3910, weight=2.9550

当前batch的pt分布：
positive: min=0.3610, max=0.8774, mean=0.6691
neutral: min=0.3925, max=0.9587, mean=0.8170
negative: min=0.2009, max=0.9281, mean=0.6459

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 0.8000
neutral 准确率: 0.9091
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.3945
焦点损失: 0.0770
边界损失: 0.3270
总损失: 0.2356
Epoch 2 [129/172] - loss: 0.2356
Epoch 2 [130/172] - loss: 0.2619, acc: 0.8438
Epoch 2 [131/172] - loss: 0.2106
Epoch 2 [132/172] - loss: 0.4033
Epoch 2 [133/172] - loss: 0.3262
Epoch 2 [134/172] - loss: 0.3804
Epoch 2 [135/172] - loss: 0.2858
Epoch 2 [136/172] - loss: 0.1882
Epoch 2 [137/172] - loss: 0.3240
Epoch 2 [138/172] - loss: 0.1257
Epoch 2 [139/172] - loss: 0.2562
Epoch 2 [140/172] - loss: 0.2022, acc: 0.8438
Epoch 2 [141/172] - loss: 0.4261
Epoch 2 [142/172] - loss: 0.4470
Epoch 2 [143/172] - loss: 0.1938
Epoch 2 [144/172] - loss: 0.3149
Epoch 2 [145/172] - loss: 0.6825
Epoch 2 [146/172] - loss: 0.1836
Epoch 2 [147/172] - loss: 0.2756
Epoch 2 [148/172] - loss: 0.1670
Epoch 2 [149/172] - loss: 0.2587
Epoch 2 [150/172] - loss: 0.2244, acc: 0.9062
Epoch 2 [151/172] - loss: 0.1887
Epoch 2 [152/172] - loss: 0.3187
Epoch 2 [153/172] - loss: 0.2037
Epoch 2 [154/172] - loss: 0.2056
Epoch 2 [155/172] - loss: 0.4055
Epoch 2 [156/172] - loss: 0.1769
Epoch 2 [157/172] - loss: 0.1732
Epoch 2 [158/172] - loss: 0.1668
Epoch 2 [159/172] - loss: 0.2403
Epoch 2 [160/172] - loss: 0.1481, acc: 0.9375
Epoch 2 [161/172] - loss: 0.3423
Epoch 2 [162/172] - loss: 0.1598
Epoch 2 [163/172] - loss: 0.4080
Epoch 2 [164/172] - loss: 0.4665
Epoch 2 [165/172] - loss: 0.2448
Epoch 2 [166/172] - loss: 0.3874
Epoch 2 [167/172] - loss: 0.1743
Epoch 2 [168/172] - loss: 0.1442
Epoch 2 [169/172] - loss: 0.4426
Epoch 2 [170/172] - loss: 0.1164, acc: 0.9375
Epoch 2 [171/172] - loss: 0.2393
Epoch 2 [172/172] - loss: 0.4712

类别准确率:
positive: 0.8737 (408/467)
neutral: 0.1566 (13/83)
negative: 0.6520 (163/250)

Epoch 2/10
Train Loss: 0.2703, Train Acc: 0.8788
Val Loss: 0.6997, Val Acc: 0.7300
Epoch 3 [1/172] - loss: 0.1699, acc: 0.9375
Epoch 3 [2/172] - loss: 0.1950
Epoch 3 [3/172] - loss: 0.0663
Epoch 3 [4/172] - loss: 0.2951
Epoch 3 [5/172] - loss: 0.2196
Epoch 3 [6/172] - loss: 0.1599
Epoch 3 [7/172] - loss: 0.1235
Epoch 3 [8/172] - loss: 0.1475
Epoch 3 [9/172] - loss: 0.1002
Epoch 3 [10/172] - loss: 0.0813, acc: 1.0000
Epoch 3 [11/172] - loss: 0.0942
Epoch 3 [12/172] - loss: 0.0700
Epoch 3 [13/172] - loss: 0.2835
Epoch 3 [14/172] - loss: 0.0748
Epoch 3 [15/172] - loss: 0.0985
Epoch 3 [16/172] - loss: 0.2641
Epoch 3 [17/172] - loss: 0.2017
Epoch 3 [18/172] - loss: 0.1507
Epoch 3 [19/172] - loss: 0.0710
Epoch 3 [20/172] - loss: 0.1348, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1964
Epoch 3 [22/172] - loss: 0.3760
Epoch 3 [23/172] - loss: 0.0557
Epoch 3 [24/172] - loss: 0.1162
Epoch 3 [25/172] - loss: 0.1823
Epoch 3 [26/172] - loss: 0.0984
Epoch 3 [27/172] - loss: 0.2034
Epoch 3 [28/172] - loss: 0.0600
Epoch 3 [29/172] - loss: 0.1158
Epoch 3 [30/172] - loss: 0.1495, acc: 0.9062
Epoch 3 [31/172] - loss: 0.1326
Epoch 3 [32/172] - loss: 0.1461
Epoch 3 [33/172] - loss: 0.0753
Epoch 3 [34/172] - loss: 0.2223
Epoch 3 [35/172] - loss: 0.1398
Epoch 3 [36/172] - loss: 0.1362
Epoch 3 [37/172] - loss: 0.1821
Epoch 3 [38/172] - loss: 0.0633
Epoch 3 [39/172] - loss: 0.0689
Epoch 3 [40/172] - loss: 0.0840, acc: 0.9688
Epoch 3 [41/172] - loss: 0.0630
Epoch 3 [42/172] - loss: 0.1220
Epoch 3 [43/172] - loss: 0.0516
Epoch 3 [44/172] - loss: 0.0840
Epoch 3 [45/172] - loss: 0.1070
Epoch 3 [46/172] - loss: 0.1908
Epoch 3 [47/172] - loss: 0.0435
Epoch 3 [48/172] - loss: 0.0712
Epoch 3 [49/172] - loss: 0.0321
Epoch 3 [50/172] - loss: 0.0689, acc: 1.0000
Epoch 3 [51/172] - loss: 0.1456
Epoch 3 [52/172] - loss: 0.3460
Epoch 3 [53/172] - loss: 0.2155
Epoch 3 [54/172] - loss: 0.0714
Epoch 3 [55/172] - loss: 0.0755
Epoch 3 [56/172] - loss: 0.1227

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.4374, log_difficulty=0.3628, weight=2.8141
neutral: count=3923.0, difficulty=0.3560, log_difficulty=0.3045, weight=2.5226
negative: count=4382.0, difficulty=0.4274, log_difficulty=0.3559, weight=2.7793

当前batch的pt分布：
positive: min=0.2078, max=0.9473, mean=0.7258
neutral: min=0.0128, max=0.9586, mean=0.7276
negative: min=0.7907, max=0.9750, mean=0.9022

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.8182
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.4257
焦点损失: 0.1908
边界损失: 0.2604
总损失: 0.4695
Epoch 3 [57/172] - loss: 0.4695
Epoch 3 [58/172] - loss: 0.1014
Epoch 3 [59/172] - loss: 0.0977
Epoch 3 [60/172] - loss: 0.2159, acc: 0.8438
Epoch 3 [61/172] - loss: 0.0826
Epoch 3 [62/172] - loss: 0.0750
Epoch 3 [63/172] - loss: 0.0886
Epoch 3 [64/172] - loss: 0.2614
Epoch 3 [65/172] - loss: 0.1484
Epoch 3 [66/172] - loss: 0.1832
Epoch 3 [67/172] - loss: 0.0766
Epoch 3 [68/172] - loss: 0.0382
Epoch 3 [69/172] - loss: 0.1579
Epoch 3 [70/172] - loss: 0.0708, acc: 0.9688
Epoch 3 [71/172] - loss: 0.1390
Epoch 3 [72/172] - loss: 0.2788
Epoch 3 [73/172] - loss: 0.0516
Epoch 3 [74/172] - loss: 0.1500
Epoch 3 [75/172] - loss: 0.0624
Epoch 3 [76/172] - loss: 0.0822
Epoch 3 [77/172] - loss: 0.0441
Epoch 3 [78/172] - loss: 0.3122
Epoch 3 [79/172] - loss: 0.0837
Epoch 3 [80/172] - loss: 0.0852, acc: 0.9375
Epoch 3 [81/172] - loss: 0.0957
Epoch 3 [82/172] - loss: 0.1347
Epoch 3 [83/172] - loss: 0.1614
Epoch 3 [84/172] - loss: 0.0533
Epoch 3 [85/172] - loss: 0.0869
Epoch 3 [86/172] - loss: 0.0673
Epoch 3 [87/172] - loss: 0.1309
Epoch 3 [88/172] - loss: 0.1619
Epoch 3 [89/172] - loss: 0.0923
Epoch 3 [90/172] - loss: 0.0577, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1407
Epoch 3 [92/172] - loss: 0.0785
Epoch 3 [93/172] - loss: 0.1703
Epoch 3 [94/172] - loss: 0.1175
Epoch 3 [95/172] - loss: 0.0603
Epoch 3 [96/172] - loss: 0.0776
Epoch 3 [97/172] - loss: 0.0896
Epoch 3 [98/172] - loss: 0.0578
Epoch 3 [99/172] - loss: 0.0884
Epoch 3 [100/172] - loss: 0.1225, acc: 0.9375
Epoch 3 [101/172] - loss: 0.1409
Epoch 3 [102/172] - loss: 0.0426
Epoch 3 [103/172] - loss: 0.1171
Epoch 3 [104/172] - loss: 0.2193
Epoch 3 [105/172] - loss: 0.0676
Epoch 3 [106/172] - loss: 0.1896
Epoch 3 [107/172] - loss: 0.0765
Epoch 3 [108/172] - loss: 0.0547
Epoch 3 [109/172] - loss: 0.0969
Epoch 3 [110/172] - loss: 0.0624, acc: 0.9688
Epoch 3 [111/172] - loss: 0.1395
Epoch 3 [112/172] - loss: 0.0877
Epoch 3 [113/172] - loss: 0.0770
Epoch 3 [114/172] - loss: 0.0987
Epoch 3 [115/172] - loss: 0.0480
Epoch 3 [116/172] - loss: 0.1311
Epoch 3 [117/172] - loss: 0.2172
Epoch 3 [118/172] - loss: 0.0373
Epoch 3 [119/172] - loss: 0.1069
Epoch 3 [120/172] - loss: 0.1827, acc: 0.9375
Epoch 3 [121/172] - loss: 0.1080
Epoch 3 [122/172] - loss: 0.0693
Epoch 3 [123/172] - loss: 0.1936
Epoch 3 [124/172] - loss: 0.1147
Epoch 3 [125/172] - loss: 0.0470
Epoch 3 [126/172] - loss: 0.4752
Epoch 3 [127/172] - loss: 0.1221
Epoch 3 [128/172] - loss: 0.0374
Epoch 3 [129/172] - loss: 0.0676
Epoch 3 [130/172] - loss: 0.0811, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1120
Epoch 3 [132/172] - loss: 0.0610
Epoch 3 [133/172] - loss: 0.0963
Epoch 3 [134/172] - loss: 0.0544
Epoch 3 [135/172] - loss: 0.1060
Epoch 3 [136/172] - loss: 0.1334
Epoch 3 [137/172] - loss: 0.1160
Epoch 3 [138/172] - loss: 0.1106
Epoch 3 [139/172] - loss: 0.1768
Epoch 3 [140/172] - loss: 0.0853, acc: 0.9688
Epoch 3 [141/172] - loss: 0.0784
Epoch 3 [142/172] - loss: 0.2080
Epoch 3 [143/172] - loss: 0.1055
Epoch 3 [144/172] - loss: 0.2499
Epoch 3 [145/172] - loss: 0.0739
Epoch 3 [146/172] - loss: 0.0837
Epoch 3 [147/172] - loss: 0.1479
Epoch 3 [148/172] - loss: 0.0576
Epoch 3 [149/172] - loss: 0.0720
Epoch 3 [150/172] - loss: 0.2746, acc: 0.9062
Epoch 3 [151/172] - loss: 0.1310
Epoch 3 [152/172] - loss: 0.2177
Epoch 3 [153/172] - loss: 0.1978
Epoch 3 [154/172] - loss: 0.0687
Epoch 3 [155/172] - loss: 0.1109
Epoch 3 [156/172] - loss: 0.0438

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3935, log_difficulty=0.3318, weight=2.6592
neutral: count=4903.0, difficulty=0.3122, log_difficulty=0.2717, weight=2.3586
negative: count=5500.0, difficulty=0.3872, log_difficulty=0.3273, weight=2.6365

当前batch的pt分布：
positive: min=0.6067, max=0.9639, mean=0.8051
neutral: min=0.7917, max=0.9741, mean=0.9140
negative: min=0.4333, max=0.9666, mean=0.8080

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1834
焦点损失: 0.0118
边界损失: 0.2382
总损失: 0.0518
Epoch 3 [157/172] - loss: 0.0518
Epoch 3 [158/172] - loss: 0.0930
Epoch 3 [159/172] - loss: 0.0560
Epoch 3 [160/172] - loss: 0.1463, acc: 0.8750
Epoch 3 [161/172] - loss: 0.1273
Epoch 3 [162/172] - loss: 0.2374
Epoch 3 [163/172] - loss: 0.1320
Epoch 3 [164/172] - loss: 0.0711
Epoch 3 [165/172] - loss: 0.0619
Epoch 3 [166/172] - loss: 0.1168
Epoch 3 [167/172] - loss: 0.1288
Epoch 3 [168/172] - loss: 0.0857
Epoch 3 [169/172] - loss: 0.0514
Epoch 3 [170/172] - loss: 0.0944, acc: 0.9062
Epoch 3 [171/172] - loss: 0.0583
Epoch 3 [172/172] - loss: 0.0315

类别准确率:
positive: 0.8715 (407/467)
neutral: 0.2410 (20/83)
negative: 0.5960 (149/250)

Epoch 3/10
Train Loss: 0.0965, Train Acc: 0.9495
Val Loss: 0.6894, Val Acc: 0.7200
Epoch 4 [1/172] - loss: 0.0380, acc: 1.0000
Epoch 4 [2/172] - loss: 0.0521
Epoch 4 [3/172] - loss: 0.0648
Epoch 4 [4/172] - loss: 0.0461
Epoch 4 [5/172] - loss: 0.0771
Epoch 4 [6/172] - loss: 0.0419
Epoch 4 [7/172] - loss: 0.0463
Epoch 4 [8/172] - loss: 0.0293
Epoch 4 [9/172] - loss: 0.1034
Epoch 4 [10/172] - loss: 0.1224, acc: 0.9375
Epoch 4 [11/172] - loss: 0.0460
Epoch 4 [12/172] - loss: 0.0674
Epoch 4 [13/172] - loss: 0.2031
Epoch 4 [14/172] - loss: 0.1099
Epoch 4 [15/172] - loss: 0.0326
Epoch 4 [16/172] - loss: 0.0479
Epoch 4 [17/172] - loss: 0.0285
Epoch 4 [18/172] - loss: 0.0333
Epoch 4 [19/172] - loss: 0.0482
Epoch 4 [20/172] - loss: 0.1076, acc: 0.9688
Epoch 4 [21/172] - loss: 0.1392
Epoch 4 [22/172] - loss: 0.0273
Epoch 4 [23/172] - loss: 0.0953
Epoch 4 [24/172] - loss: 0.0741
Epoch 4 [25/172] - loss: 0.0273
Epoch 4 [26/172] - loss: 0.1720
Epoch 4 [27/172] - loss: 0.0266
Epoch 4 [28/172] - loss: 0.0570
Epoch 4 [29/172] - loss: 0.0567
Epoch 4 [30/172] - loss: 0.0972, acc: 0.9688
Epoch 4 [31/172] - loss: 0.0701
Epoch 4 [32/172] - loss: 0.0336
Epoch 4 [33/172] - loss: 0.0350
Epoch 4 [34/172] - loss: 0.1098
Epoch 4 [35/172] - loss: 0.1077
Epoch 4 [36/172] - loss: 0.0848
Epoch 4 [37/172] - loss: 0.0346
Epoch 4 [38/172] - loss: 0.0473
Epoch 4 [39/172] - loss: 0.2443
Epoch 4 [40/172] - loss: 0.1424, acc: 0.9062
Epoch 4 [41/172] - loss: 0.0590
Epoch 4 [42/172] - loss: 0.1593
Epoch 4 [43/172] - loss: 0.0667
Epoch 4 [44/172] - loss: 0.0325
Epoch 4 [45/172] - loss: 0.0676
Epoch 4 [46/172] - loss: 0.0332
Epoch 4 [47/172] - loss: 0.0703
Epoch 4 [48/172] - loss: 0.0698
Epoch 4 [49/172] - loss: 0.0452
Epoch 4 [50/172] - loss: 0.1963, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0365
Epoch 4 [52/172] - loss: 0.0603
Epoch 4 [53/172] - loss: 0.0260
Epoch 4 [54/172] - loss: 0.0875
Epoch 4 [55/172] - loss: 0.2848
Epoch 4 [56/172] - loss: 0.0454
Epoch 4 [57/172] - loss: 0.0319
Epoch 4 [58/172] - loss: 0.0308
Epoch 4 [59/172] - loss: 0.0229
Epoch 4 [60/172] - loss: 0.0426, acc: 1.0000
Epoch 4 [61/172] - loss: 0.0489
Epoch 4 [62/172] - loss: 0.1658
Epoch 4 [63/172] - loss: 0.0491
Epoch 4 [64/172] - loss: 0.0365
Epoch 4 [65/172] - loss: 0.0483
Epoch 4 [66/172] - loss: 0.0321
Epoch 4 [67/172] - loss: 0.0665
Epoch 4 [68/172] - loss: 0.0693
Epoch 4 [69/172] - loss: 0.0294
Epoch 4 [70/172] - loss: 0.0358, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0766
Epoch 4 [72/172] - loss: 0.0504
Epoch 4 [73/172] - loss: 0.0768
Epoch 4 [74/172] - loss: 0.2136
Epoch 4 [75/172] - loss: 0.0824
Epoch 4 [76/172] - loss: 0.0340
Epoch 4 [77/172] - loss: 0.0555
Epoch 4 [78/172] - loss: 0.0528
Epoch 4 [79/172] - loss: 0.0350
Epoch 4 [80/172] - loss: 0.0451, acc: 0.9688
Epoch 4 [81/172] - loss: 0.1506
Epoch 4 [82/172] - loss: 0.0298
Epoch 4 [83/172] - loss: 0.0596
Epoch 4 [84/172] - loss: 0.0415

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3570, log_difficulty=0.3053, weight=2.5263
neutral: count=5865.0, difficulty=0.2798, log_difficulty=0.2467, weight=2.2335
negative: count=6629.0, difficulty=0.3520, log_difficulty=0.3016, weight=2.5079

当前batch的pt分布：
positive: min=0.4460, max=0.9358, mean=0.7676
neutral: min=0.9095, max=0.9888, mean=0.9700
negative: min=0.6580, max=0.9791, mean=0.8729

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1898
焦点损失: 0.0154
边界损失: 0.2329
总损失: 0.0582
Epoch 4 [85/172] - loss: 0.0582
Epoch 4 [86/172] - loss: 0.2026
Epoch 4 [87/172] - loss: 0.0445
Epoch 4 [88/172] - loss: 0.0658
Epoch 4 [89/172] - loss: 0.0513
Epoch 4 [90/172] - loss: 0.0332, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1603
Epoch 4 [92/172] - loss: 0.1919
Epoch 4 [93/172] - loss: 0.0348
Epoch 4 [94/172] - loss: 0.0354
Epoch 4 [95/172] - loss: 0.0452
Epoch 4 [96/172] - loss: 0.0360
Epoch 4 [97/172] - loss: 0.0536
Epoch 4 [98/172] - loss: 0.0285
Epoch 4 [99/172] - loss: 0.0505
Epoch 4 [100/172] - loss: 0.1000, acc: 0.9062
Epoch 4 [101/172] - loss: 0.0780
Epoch 4 [102/172] - loss: 0.0387
Epoch 4 [103/172] - loss: 0.0435
Epoch 4 [104/172] - loss: 0.0387
Epoch 4 [105/172] - loss: 0.0543
Epoch 4 [106/172] - loss: 0.0228
Epoch 4 [107/172] - loss: 0.0395
Epoch 4 [108/172] - loss: 0.0746
Epoch 4 [109/172] - loss: 0.0444
Epoch 4 [110/172] - loss: 0.4311, acc: 0.8750
Epoch 4 [111/172] - loss: 0.0212
Epoch 4 [112/172] - loss: 0.0263
Epoch 4 [113/172] - loss: 0.0826
Epoch 4 [114/172] - loss: 0.0990
Epoch 4 [115/172] - loss: 0.0276
Epoch 4 [116/172] - loss: 0.1001
Epoch 4 [117/172] - loss: 0.0375
Epoch 4 [118/172] - loss: 0.0466
Epoch 4 [119/172] - loss: 0.0233
Epoch 4 [120/172] - loss: 0.0314, acc: 1.0000
Epoch 4 [121/172] - loss: 0.0565
Epoch 4 [122/172] - loss: 0.1891
Epoch 4 [123/172] - loss: 0.0540
Epoch 4 [124/172] - loss: 0.0637
Epoch 4 [125/172] - loss: 0.0758
Epoch 4 [126/172] - loss: 0.1320
Epoch 4 [127/172] - loss: 0.0620
Epoch 4 [128/172] - loss: 0.0247
Epoch 4 [129/172] - loss: 0.0808
Epoch 4 [130/172] - loss: 0.0229, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0293
Epoch 4 [132/172] - loss: 0.0338
Epoch 4 [133/172] - loss: 0.0786
Epoch 4 [134/172] - loss: 0.0507
Epoch 4 [135/172] - loss: 0.0509
Epoch 4 [136/172] - loss: 0.1478
Epoch 4 [137/172] - loss: 0.0906
Epoch 4 [138/172] - loss: 0.1182
Epoch 4 [139/172] - loss: 0.1129
Epoch 4 [140/172] - loss: 0.2833, acc: 0.9062
Epoch 4 [141/172] - loss: 0.0350
Epoch 4 [142/172] - loss: 0.0363
Epoch 4 [143/172] - loss: 0.0337
Epoch 4 [144/172] - loss: 0.0416
Epoch 4 [145/172] - loss: 0.1655
Epoch 4 [146/172] - loss: 0.1158
Epoch 4 [147/172] - loss: 0.0358
Epoch 4 [148/172] - loss: 0.0764
Epoch 4 [149/172] - loss: 0.0267
Epoch 4 [150/172] - loss: 0.0426, acc: 1.0000
Epoch 4 [151/172] - loss: 0.2469
Epoch 4 [152/172] - loss: 0.0327
Epoch 4 [153/172] - loss: 0.0875
Epoch 4 [154/172] - loss: 0.1833
Epoch 4 [155/172] - loss: 0.0490
Epoch 4 [156/172] - loss: 0.0416
Epoch 4 [157/172] - loss: 0.1342
Epoch 4 [158/172] - loss: 0.0256
Epoch 4 [159/172] - loss: 0.0572
Epoch 4 [160/172] - loss: 0.0373, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1146
Epoch 4 [162/172] - loss: 0.1598
Epoch 4 [163/172] - loss: 0.0744
Epoch 4 [164/172] - loss: 0.0468
Epoch 4 [165/172] - loss: 0.1949
Epoch 4 [166/172] - loss: 0.0502
Epoch 4 [167/172] - loss: 0.0870
Epoch 4 [168/172] - loss: 0.0465
Epoch 4 [169/172] - loss: 0.1510
Epoch 4 [170/172] - loss: 0.1018, acc: 0.9375
Epoch 4 [171/172] - loss: 0.0341
Epoch 4 [172/172] - loss: 0.1310

类别准确率:
positive: 0.8951 (418/467)
neutral: 0.1446 (12/83)
negative: 0.6440 (161/250)

Epoch 4/10
Train Loss: 0.0904, Train Acc: 0.9556
Val Loss: 0.6996, Val Acc: 0.7388
Epoch 5 [1/172] - loss: 0.0328, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0377
Epoch 5 [3/172] - loss: 0.0470
Epoch 5 [4/172] - loss: 0.0539
Epoch 5 [5/172] - loss: 0.0274
Epoch 5 [6/172] - loss: 0.0573
Epoch 5 [7/172] - loss: 0.0605
Epoch 5 [8/172] - loss: 0.0675
Epoch 5 [9/172] - loss: 0.0795
Epoch 5 [10/172] - loss: 0.0498, acc: 0.9688
Epoch 5 [11/172] - loss: 0.0817
Epoch 5 [12/172] - loss: 0.0246

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.3279, log_difficulty=0.2836, weight=2.4181
neutral: count=6845.0, difficulty=0.2549, log_difficulty=0.2270, weight=2.1352
negative: count=7694.0, difficulty=0.3254, log_difficulty=0.2817, weight=2.4087

当前batch的pt分布：
positive: min=0.1502, max=0.9878, mean=0.8249
neutral: min=0.7454, max=0.9962, mean=0.9156
negative: min=0.6932, max=0.9680, mean=0.8615

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1870
焦点损失: 0.0434
边界损失: 0.2101
总损失: 0.1152
Epoch 5 [13/172] - loss: 0.1152
Epoch 5 [14/172] - loss: 0.0912
Epoch 5 [15/172] - loss: 0.0432
Epoch 5 [16/172] - loss: 0.0304
Epoch 5 [17/172] - loss: 0.0852
Epoch 5 [18/172] - loss: 0.0272
Epoch 5 [19/172] - loss: 0.0680
Epoch 5 [20/172] - loss: 0.0660, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1013
Epoch 5 [22/172] - loss: 0.3326
Epoch 5 [23/172] - loss: 0.0294
Epoch 5 [24/172] - loss: 0.0489
Epoch 5 [25/172] - loss: 0.0459
Epoch 5 [26/172] - loss: 0.1547
Epoch 5 [27/172] - loss: 0.0473
Epoch 5 [28/172] - loss: 0.0559
Epoch 5 [29/172] - loss: 0.0707
Epoch 5 [30/172] - loss: 0.0459, acc: 0.9688
Epoch 5 [31/172] - loss: 0.0376
Epoch 5 [32/172] - loss: 0.0259
Epoch 5 [33/172] - loss: 0.0290
Epoch 5 [34/172] - loss: 0.0623
Epoch 5 [35/172] - loss: 0.0227
Epoch 5 [36/172] - loss: 0.0489
Epoch 5 [37/172] - loss: 0.0260
Epoch 5 [38/172] - loss: 0.0227
Epoch 5 [39/172] - loss: 0.1156
Epoch 5 [40/172] - loss: 0.0569, acc: 0.9375
Epoch 5 [41/172] - loss: 0.0471
Epoch 5 [42/172] - loss: 0.0796
Epoch 5 [43/172] - loss: 0.1510
Epoch 5 [44/172] - loss: 0.0892
Epoch 5 [45/172] - loss: 0.0204
Epoch 5 [46/172] - loss: 0.1229
Epoch 5 [47/172] - loss: 0.0324
Epoch 5 [48/172] - loss: 0.0325
Epoch 5 [49/172] - loss: 0.0286
Epoch 5 [50/172] - loss: 0.0412, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0423
Epoch 5 [52/172] - loss: 0.0288
Epoch 5 [53/172] - loss: 0.0430
Epoch 5 [54/172] - loss: 0.0672
Epoch 5 [55/172] - loss: 0.0340
Epoch 5 [56/172] - loss: 0.0669
Epoch 5 [57/172] - loss: 0.0400
Epoch 5 [58/172] - loss: 0.0294
Epoch 5 [59/172] - loss: 0.0503
Epoch 5 [60/172] - loss: 0.0732, acc: 0.9688
Epoch 5 [61/172] - loss: 0.0319
Epoch 5 [62/172] - loss: 0.0377
Epoch 5 [63/172] - loss: 0.1001
Epoch 5 [64/172] - loss: 0.0463
Epoch 5 [65/172] - loss: 0.0312
Epoch 5 [66/172] - loss: 0.0212
Epoch 5 [67/172] - loss: 0.0228
Epoch 5 [68/172] - loss: 0.0264
Epoch 5 [69/172] - loss: 0.0430
Epoch 5 [70/172] - loss: 0.0548, acc: 0.9688
Epoch 5 [71/172] - loss: 0.0559
Epoch 5 [72/172] - loss: 0.0742
Epoch 5 [73/172] - loss: 0.0650
Epoch 5 [74/172] - loss: 0.0386
Epoch 5 [75/172] - loss: 0.0254
Epoch 5 [76/172] - loss: 0.0326
Epoch 5 [77/172] - loss: 0.0241
Epoch 5 [78/172] - loss: 0.0376
Epoch 5 [79/172] - loss: 0.0276
Epoch 5 [80/172] - loss: 0.0300, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1595
Epoch 5 [82/172] - loss: 0.1387
Epoch 5 [83/172] - loss: 0.0242
Epoch 5 [84/172] - loss: 0.0246
Epoch 5 [85/172] - loss: 0.0873
Epoch 5 [86/172] - loss: 0.0487
Epoch 5 [87/172] - loss: 0.0935
Epoch 5 [88/172] - loss: 0.1126
Epoch 5 [89/172] - loss: 0.0258
Epoch 5 [90/172] - loss: 0.2658, acc: 0.9375
Epoch 5 [91/172] - loss: 0.0769
Epoch 5 [92/172] - loss: 0.0247
Epoch 5 [93/172] - loss: 0.0285
Epoch 5 [94/172] - loss: 0.0319
Epoch 5 [95/172] - loss: 0.0350
Epoch 5 [96/172] - loss: 0.0447
Epoch 5 [97/172] - loss: 0.0531
Epoch 5 [98/172] - loss: 0.0387
Epoch 5 [99/172] - loss: 0.1142
Epoch 5 [100/172] - loss: 0.0283, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0308
Epoch 5 [102/172] - loss: 0.0409
Epoch 5 [103/172] - loss: 0.0567
Epoch 5 [104/172] - loss: 0.1178
Epoch 5 [105/172] - loss: 0.1708
Epoch 5 [106/172] - loss: 0.0477
Epoch 5 [107/172] - loss: 0.0406
Epoch 5 [108/172] - loss: 0.1897
Epoch 5 [109/172] - loss: 0.0366
Epoch 5 [110/172] - loss: 0.0211, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0338
Epoch 5 [112/172] - loss: 0.0307

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.3031, log_difficulty=0.2647, weight=2.3236
neutral: count=7825.0, difficulty=0.2354, log_difficulty=0.2114, weight=2.0568
negative: count=8780.0, difficulty=0.3027, log_difficulty=0.2644, weight=2.3221

当前batch的pt分布：
positive: min=0.3414, max=0.9673, mean=0.7767
neutral: min=0.8132, max=0.9718, mean=0.9311
negative: min=0.9647, max=0.9953, mean=0.9787

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1752
焦点损失: 0.0280
边界损失: 0.2128
总损失: 0.0798
Epoch 5 [113/172] - loss: 0.0798
Epoch 5 [114/172] - loss: 0.1321
Epoch 5 [115/172] - loss: 0.0335
Epoch 5 [116/172] - loss: 0.0221
Epoch 5 [117/172] - loss: 0.0540
Epoch 5 [118/172] - loss: 0.0265
Epoch 5 [119/172] - loss: 0.0296
Epoch 5 [120/172] - loss: 0.0421, acc: 0.9688
Epoch 5 [121/172] - loss: 0.0844
Epoch 5 [122/172] - loss: 0.0236
Epoch 5 [123/172] - loss: 0.0302
Epoch 5 [124/172] - loss: 0.0298
Epoch 5 [125/172] - loss: 0.0296
Epoch 5 [126/172] - loss: 0.0435
Epoch 5 [127/172] - loss: 0.0453
Epoch 5 [128/172] - loss: 0.0330
Epoch 5 [129/172] - loss: 0.0876
Epoch 5 [130/172] - loss: 0.0219, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0267
Epoch 5 [132/172] - loss: 0.1116
Epoch 5 [133/172] - loss: 0.0642
Epoch 5 [134/172] - loss: 0.0309
Epoch 5 [135/172] - loss: 0.0242
Epoch 5 [136/172] - loss: 0.0203
Epoch 5 [137/172] - loss: 0.0291
Epoch 5 [138/172] - loss: 0.0764
Epoch 5 [139/172] - loss: 0.2073
Epoch 5 [140/172] - loss: 0.0798, acc: 0.9375
Epoch 5 [141/172] - loss: 0.0698
Epoch 5 [142/172] - loss: 0.0381
Epoch 5 [143/172] - loss: 0.0234
Epoch 5 [144/172] - loss: 0.0222
Epoch 5 [145/172] - loss: 0.0385
Epoch 5 [146/172] - loss: 0.0360
Epoch 5 [147/172] - loss: 0.0846
Epoch 5 [148/172] - loss: 0.0264
Epoch 5 [149/172] - loss: 0.0273
Epoch 5 [150/172] - loss: 0.0809, acc: 0.9375
Epoch 5 [151/172] - loss: 0.0200
Epoch 5 [152/172] - loss: 0.0262
Epoch 5 [153/172] - loss: 0.0233
Epoch 5 [154/172] - loss: 0.0224
Epoch 5 [155/172] - loss: 0.0297
Epoch 5 [156/172] - loss: 0.0316
Epoch 5 [157/172] - loss: 0.0314
Epoch 5 [158/172] - loss: 0.0267
Epoch 5 [159/172] - loss: 0.0260
Epoch 5 [160/172] - loss: 0.0282, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0334
Epoch 5 [162/172] - loss: 0.0450
Epoch 5 [163/172] - loss: 0.0851
Epoch 5 [164/172] - loss: 0.0226
Epoch 5 [165/172] - loss: 0.0740
Epoch 5 [166/172] - loss: 0.0418
Epoch 5 [167/172] - loss: 0.0948
Epoch 5 [168/172] - loss: 0.0231
Epoch 5 [169/172] - loss: 0.0245
Epoch 5 [170/172] - loss: 0.0282, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0332
Epoch 5 [172/172] - loss: 0.0345

类别准确率:
positive: 0.8137 (380/467)
neutral: 0.3012 (25/83)
negative: 0.7280 (182/250)

Epoch 5/10
Train Loss: 0.0408, Train Acc: 0.9838
Val Loss: 0.7032, Val Acc: 0.7338
Epoch 6 [1/172] - loss: 0.0444, acc: 1.0000
Epoch 6 [2/172] - loss: 0.0511
Epoch 6 [3/172] - loss: 0.0348
Epoch 6 [4/172] - loss: 0.1464
Epoch 6 [5/172] - loss: 0.0489
Epoch 6 [6/172] - loss: 0.0675
Epoch 6 [7/172] - loss: 0.1185
Epoch 6 [8/172] - loss: 0.0549
Epoch 6 [9/172] - loss: 0.0269
Epoch 6 [10/172] - loss: 0.0201, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0305
Epoch 6 [12/172] - loss: 0.0235
Epoch 6 [13/172] - loss: 0.0718
Epoch 6 [14/172] - loss: 0.0198
Epoch 6 [15/172] - loss: 0.0254
Epoch 6 [16/172] - loss: 0.2847
Epoch 6 [17/172] - loss: 0.0278
Epoch 6 [18/172] - loss: 0.0255
Epoch 6 [19/172] - loss: 0.0274
Epoch 6 [20/172] - loss: 0.0214, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0330
Epoch 6 [22/172] - loss: 0.0312
Epoch 6 [23/172] - loss: 0.0255
Epoch 6 [24/172] - loss: 0.0954
Epoch 6 [25/172] - loss: 0.0312
Epoch 6 [26/172] - loss: 0.0468
Epoch 6 [27/172] - loss: 0.0408
Epoch 6 [28/172] - loss: 0.0418
Epoch 6 [29/172] - loss: 0.0303
Epoch 6 [30/172] - loss: 0.0204, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0200
Epoch 6 [32/172] - loss: 0.0233
Epoch 6 [33/172] - loss: 0.0240
Epoch 6 [34/172] - loss: 0.1151
Epoch 6 [35/172] - loss: 0.0188
Epoch 6 [36/172] - loss: 0.0183
Epoch 6 [37/172] - loss: 0.0309
Epoch 6 [38/172] - loss: 0.0249
Epoch 6 [39/172] - loss: 0.0313
Epoch 6 [40/172] - loss: 0.0754, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2825, log_difficulty=0.2488, weight=2.2441
neutral: count=8815.0, difficulty=0.2191, log_difficulty=0.1981, weight=1.9907
negative: count=9870.0, difficulty=0.2823, log_difficulty=0.2487, weight=2.2433

当前batch的pt分布：
positive: min=0.2582, max=0.9889, mean=0.8976
neutral: min=0.8932, max=0.9868, mean=0.9520
negative: min=0.5310, max=0.9677, mean=0.8684

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1231
焦点损失: 0.0259
边界损失: 0.1803
总损失: 0.0704
Epoch 6 [41/172] - loss: 0.0704
Epoch 6 [42/172] - loss: 0.0207
Epoch 6 [43/172] - loss: 0.0726
Epoch 6 [44/172] - loss: 0.0203
Epoch 6 [45/172] - loss: 0.0679
Epoch 6 [46/172] - loss: 0.0548
Epoch 6 [47/172] - loss: 0.0211
Epoch 6 [48/172] - loss: 0.0451
Epoch 6 [49/172] - loss: 0.0292
Epoch 6 [50/172] - loss: 0.0593, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0704
Epoch 6 [52/172] - loss: 0.0378
Epoch 6 [53/172] - loss: 0.0304
Epoch 6 [54/172] - loss: 0.0791
Epoch 6 [55/172] - loss: 0.1013
Epoch 6 [56/172] - loss: 0.0400
Epoch 6 [57/172] - loss: 0.0258
Epoch 6 [58/172] - loss: 0.0227
Epoch 6 [59/172] - loss: 0.0332
Epoch 6 [60/172] - loss: 0.0256, acc: 1.0000
Epoch 6 [61/172] - loss: 0.0233
Epoch 6 [62/172] - loss: 0.0313
Epoch 6 [63/172] - loss: 0.0639
Epoch 6 [64/172] - loss: 0.1363
Epoch 6 [65/172] - loss: 0.1311
Epoch 6 [66/172] - loss: 0.0270
Epoch 6 [67/172] - loss: 0.0189
Epoch 6 [68/172] - loss: 0.0849
Epoch 6 [69/172] - loss: 0.0425
Epoch 6 [70/172] - loss: 0.0271, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0243
Epoch 6 [72/172] - loss: 0.0375
Epoch 6 [73/172] - loss: 0.0857
Epoch 6 [74/172] - loss: 0.0203
Epoch 6 [75/172] - loss: 0.0298
Epoch 6 [76/172] - loss: 0.0249
Epoch 6 [77/172] - loss: 0.0289
Epoch 6 [78/172] - loss: 0.0304
Epoch 6 [79/172] - loss: 0.0194
Epoch 6 [80/172] - loss: 0.0542, acc: 0.9688
Epoch 6 [81/172] - loss: 0.0296
Epoch 6 [82/172] - loss: 0.0638
Epoch 6 [83/172] - loss: 0.0265
Epoch 6 [84/172] - loss: 0.0217
Epoch 6 [85/172] - loss: 0.0556
Epoch 6 [86/172] - loss: 0.0277
Epoch 6 [87/172] - loss: 0.0260
Epoch 6 [88/172] - loss: 0.0875
Epoch 6 [89/172] - loss: 0.0198
Epoch 6 [90/172] - loss: 0.0220, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0205
Epoch 6 [92/172] - loss: 0.0267
Epoch 6 [93/172] - loss: 0.0229
Epoch 6 [94/172] - loss: 0.0721
Epoch 6 [95/172] - loss: 0.0256
Epoch 6 [96/172] - loss: 0.0196
Epoch 6 [97/172] - loss: 0.0432
Epoch 6 [98/172] - loss: 0.0626
Epoch 6 [99/172] - loss: 0.0241
Epoch 6 [100/172] - loss: 0.0382, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1063
Epoch 6 [102/172] - loss: 0.0239
Epoch 6 [103/172] - loss: 0.0271
Epoch 6 [104/172] - loss: 0.0843
Epoch 6 [105/172] - loss: 0.0500
Epoch 6 [106/172] - loss: 0.0453
Epoch 6 [107/172] - loss: 0.0215
Epoch 6 [108/172] - loss: 0.0222
Epoch 6 [109/172] - loss: 0.0576
Epoch 6 [110/172] - loss: 0.0263, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0379
Epoch 6 [112/172] - loss: 0.0184
Epoch 6 [113/172] - loss: 0.0237
Epoch 6 [114/172] - loss: 0.0191
Epoch 6 [115/172] - loss: 0.0308
Epoch 6 [116/172] - loss: 0.1263
Epoch 6 [117/172] - loss: 0.0242
Epoch 6 [118/172] - loss: 0.0203
Epoch 6 [119/172] - loss: 0.1963
Epoch 6 [120/172] - loss: 0.0238, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0236
Epoch 6 [122/172] - loss: 0.0472
Epoch 6 [123/172] - loss: 0.0225
Epoch 6 [124/172] - loss: 0.0451
Epoch 6 [125/172] - loss: 0.0341
Epoch 6 [126/172] - loss: 0.0616
Epoch 6 [127/172] - loss: 0.1603
Epoch 6 [128/172] - loss: 0.0230
Epoch 6 [129/172] - loss: 0.0299
Epoch 6 [130/172] - loss: 0.1999, acc: 0.9688
Epoch 6 [131/172] - loss: 0.0795
Epoch 6 [132/172] - loss: 0.0602
Epoch 6 [133/172] - loss: 0.0286
Epoch 6 [134/172] - loss: 0.0244
Epoch 6 [135/172] - loss: 0.0460
Epoch 6 [136/172] - loss: 0.0189
Epoch 6 [137/172] - loss: 0.0345
Epoch 6 [138/172] - loss: 0.0389
Epoch 6 [139/172] - loss: 0.0231
Epoch 6 [140/172] - loss: 0.0305, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2653, log_difficulty=0.2353, weight=2.1765
neutral: count=9796.0, difficulty=0.2048, log_difficulty=0.1863, weight=1.9317
negative: count=10972.0, difficulty=0.2651, log_difficulty=0.2351, weight=2.1756

当前batch的pt分布：
positive: min=0.8620, max=0.9926, mean=0.9510
neutral: min=0.8907, max=0.9834, mean=0.9510
negative: min=0.7144, max=0.9512, mean=0.8810

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0830
焦点损失: 0.0014
边界损失: 0.1780
总损失: 0.0205
Epoch 6 [141/172] - loss: 0.0205
Epoch 6 [142/172] - loss: 0.0217
Epoch 6 [143/172] - loss: 0.0286
Epoch 6 [144/172] - loss: 0.0304
Epoch 6 [145/172] - loss: 0.0206
Epoch 6 [146/172] - loss: 0.0210
Epoch 6 [147/172] - loss: 0.0507
Epoch 6 [148/172] - loss: 0.0285
Epoch 6 [149/172] - loss: 0.0268
Epoch 6 [150/172] - loss: 0.0179, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0267
Epoch 6 [152/172] - loss: 0.0464
Epoch 6 [153/172] - loss: 0.0180
Epoch 6 [154/172] - loss: 0.0185
Epoch 6 [155/172] - loss: 0.0427
Epoch 6 [156/172] - loss: 0.1219
Epoch 6 [157/172] - loss: 0.0183
Epoch 6 [158/172] - loss: 0.0426
Epoch 6 [159/172] - loss: 0.0544
Epoch 6 [160/172] - loss: 0.1259, acc: 0.9688
Epoch 6 [161/172] - loss: 0.0243
Epoch 6 [162/172] - loss: 0.0299
Epoch 6 [163/172] - loss: 0.0301
Epoch 6 [164/172] - loss: 0.0395
Epoch 6 [165/172] - loss: 0.2584
Epoch 6 [166/172] - loss: 0.0291
Epoch 6 [167/172] - loss: 0.0200
Epoch 6 [168/172] - loss: 0.0333
Epoch 6 [169/172] - loss: 0.0440
Epoch 6 [170/172] - loss: 0.0181, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0305
Epoch 6 [172/172] - loss: 0.0228

类别准确率:
positive: 0.8951 (418/467)
neutral: 0.2771 (23/83)
negative: 0.5480 (137/250)

Epoch 6/10
Train Loss: 0.0513, Train Acc: 0.9879
Val Loss: 0.7737, Val Acc: 0.7225
Epoch 7 [1/172] - loss: 0.0192, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0184
Epoch 7 [3/172] - loss: 0.0209
Epoch 7 [4/172] - loss: 0.0218
Epoch 7 [5/172] - loss: 0.0218
Epoch 7 [6/172] - loss: 0.0409
Epoch 7 [7/172] - loss: 0.0319
Epoch 7 [8/172] - loss: 0.0546
Epoch 7 [9/172] - loss: 0.0183
Epoch 7 [10/172] - loss: 0.0196, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0182
Epoch 7 [12/172] - loss: 0.0658
Epoch 7 [13/172] - loss: 0.0217
Epoch 7 [14/172] - loss: 0.0215
Epoch 7 [15/172] - loss: 0.0572
Epoch 7 [16/172] - loss: 0.0593
Epoch 7 [17/172] - loss: 0.0334
Epoch 7 [18/172] - loss: 0.0232
Epoch 7 [19/172] - loss: 0.0218
Epoch 7 [20/172] - loss: 0.0315, acc: 0.9688
Epoch 7 [21/172] - loss: 0.0292
Epoch 7 [22/172] - loss: 0.0254
Epoch 7 [23/172] - loss: 0.0200
Epoch 7 [24/172] - loss: 0.0213
Epoch 7 [25/172] - loss: 0.0315
Epoch 7 [26/172] - loss: 0.0425
Epoch 7 [27/172] - loss: 0.0224
Epoch 7 [28/172] - loss: 0.0781
Epoch 7 [29/172] - loss: 0.0198
Epoch 7 [30/172] - loss: 0.0779, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0206
Epoch 7 [32/172] - loss: 0.0179
Epoch 7 [33/172] - loss: 0.0653
Epoch 7 [34/172] - loss: 0.0214
Epoch 7 [35/172] - loss: 0.0182
Epoch 7 [36/172] - loss: 0.1500
Epoch 7 [37/172] - loss: 0.0194
Epoch 7 [38/172] - loss: 0.0194
Epoch 7 [39/172] - loss: 0.0257
Epoch 7 [40/172] - loss: 0.0181, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0246
Epoch 7 [42/172] - loss: 0.0196
Epoch 7 [43/172] - loss: 0.0285
Epoch 7 [44/172] - loss: 0.0462
Epoch 7 [45/172] - loss: 0.0204
Epoch 7 [46/172] - loss: 0.0413
Epoch 7 [47/172] - loss: 0.0623
Epoch 7 [48/172] - loss: 0.0192
Epoch 7 [49/172] - loss: 0.0290
Epoch 7 [50/172] - loss: 0.0186, acc: 1.0000
Epoch 7 [51/172] - loss: 0.0569
Epoch 7 [52/172] - loss: 0.0284
Epoch 7 [53/172] - loss: 0.0173
Epoch 7 [54/172] - loss: 0.0191
Epoch 7 [55/172] - loss: 0.0205
Epoch 7 [56/172] - loss: 0.0291
Epoch 7 [57/172] - loss: 0.0994
Epoch 7 [58/172] - loss: 0.0532
Epoch 7 [59/172] - loss: 0.0204
Epoch 7 [60/172] - loss: 0.0309, acc: 1.0000
Epoch 7 [61/172] - loss: 0.0262
Epoch 7 [62/172] - loss: 0.0350
Epoch 7 [63/172] - loss: 0.0897
Epoch 7 [64/172] - loss: 0.0243
Epoch 7 [65/172] - loss: 0.0886
Epoch 7 [66/172] - loss: 0.0181
Epoch 7 [67/172] - loss: 0.0230
Epoch 7 [68/172] - loss: 0.0223

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.2494, log_difficulty=0.2227, weight=2.1134
neutral: count=10756.0, difficulty=0.1926, log_difficulty=0.1761, weight=1.8807
negative: count=12072.0, difficulty=0.2503, log_difficulty=0.2234, weight=2.1168

当前batch的pt分布：
positive: min=0.8773, max=0.9831, mean=0.9513
neutral: min=0.9652, max=0.9938, mean=0.9765
negative: min=0.7737, max=0.9464, mean=0.8764

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0802
焦点损失: 0.0011
边界损失: 0.1748
总损失: 0.0196
Epoch 7 [69/172] - loss: 0.0196
Epoch 7 [70/172] - loss: 0.0444, acc: 0.9688
Epoch 7 [71/172] - loss: 0.0194
Epoch 7 [72/172] - loss: 0.0623
Epoch 7 [73/172] - loss: 0.0277
Epoch 7 [74/172] - loss: 0.0204
Epoch 7 [75/172] - loss: 0.0270
Epoch 7 [76/172] - loss: 0.0315
Epoch 7 [77/172] - loss: 0.0268
Epoch 7 [78/172] - loss: 0.0177
Epoch 7 [79/172] - loss: 0.0648
Epoch 7 [80/172] - loss: 0.0527, acc: 0.9688
Epoch 7 [81/172] - loss: 0.0194
Epoch 7 [82/172] - loss: 0.0244
Epoch 7 [83/172] - loss: 0.0342
Epoch 7 [84/172] - loss: 0.0212
Epoch 7 [85/172] - loss: 0.0194
Epoch 7 [86/172] - loss: 0.0258
Epoch 7 [87/172] - loss: 0.0220
Epoch 7 [88/172] - loss: 0.0189
Epoch 7 [89/172] - loss: 0.0206
Epoch 7 [90/172] - loss: 0.0249, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0222
Epoch 7 [92/172] - loss: 0.0457
Epoch 7 [93/172] - loss: 0.0240
Epoch 7 [94/172] - loss: 0.0177
Epoch 7 [95/172] - loss: 0.0193
Epoch 7 [96/172] - loss: 0.0443
Epoch 7 [97/172] - loss: 0.0298
Epoch 7 [98/172] - loss: 0.0827
Epoch 7 [99/172] - loss: 0.0175
Epoch 7 [100/172] - loss: 0.0163, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0303
Epoch 7 [102/172] - loss: 0.0259
Epoch 7 [103/172] - loss: 0.0294
Epoch 7 [104/172] - loss: 0.0236
Epoch 7 [105/172] - loss: 0.0439
Epoch 7 [106/172] - loss: 0.0449
Epoch 7 [107/172] - loss: 0.0191
Epoch 7 [108/172] - loss: 0.0218
Epoch 7 [109/172] - loss: 0.0365
Epoch 7 [110/172] - loss: 0.0333, acc: 1.0000
Epoch 7 [111/172] - loss: 0.0348
Epoch 7 [112/172] - loss: 0.0247
Epoch 7 [113/172] - loss: 0.0175
Epoch 7 [114/172] - loss: 0.0190
Epoch 7 [115/172] - loss: 0.0263
Epoch 7 [116/172] - loss: 0.0767
Epoch 7 [117/172] - loss: 0.0245
Epoch 7 [118/172] - loss: 0.0594
Epoch 7 [119/172] - loss: 0.0217
Epoch 7 [120/172] - loss: 0.0215, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0249
Epoch 7 [122/172] - loss: 0.0222
Epoch 7 [123/172] - loss: 0.0236
Epoch 7 [124/172] - loss: 0.0297
Epoch 7 [125/172] - loss: 0.0173
Epoch 7 [126/172] - loss: 0.0194
Epoch 7 [127/172] - loss: 0.0306
Epoch 7 [128/172] - loss: 0.0208
Epoch 7 [129/172] - loss: 0.0230
Epoch 7 [130/172] - loss: 0.0207, acc: 1.0000
Epoch 7 [131/172] - loss: 0.0742
Epoch 7 [132/172] - loss: 0.1658
Epoch 7 [133/172] - loss: 0.0176
Epoch 7 [134/172] - loss: 0.0290
Epoch 7 [135/172] - loss: 0.0239
Epoch 7 [136/172] - loss: 0.0170
Epoch 7 [137/172] - loss: 0.0249
Epoch 7 [138/172] - loss: 0.0168
Epoch 7 [139/172] - loss: 0.0695
Epoch 7 [140/172] - loss: 0.0267, acc: 1.0000
Epoch 7 [141/172] - loss: 0.1199
Epoch 7 [142/172] - loss: 0.0241
Epoch 7 [143/172] - loss: 0.0248
Epoch 7 [144/172] - loss: 0.0190
Epoch 7 [145/172] - loss: 0.0438
Epoch 7 [146/172] - loss: 0.0716
Epoch 7 [147/172] - loss: 0.0200
Epoch 7 [148/172] - loss: 0.0637
Epoch 7 [149/172] - loss: 0.0187
Epoch 7 [150/172] - loss: 0.0201, acc: 1.0000
Epoch 7 [151/172] - loss: 0.0515
Epoch 7 [152/172] - loss: 0.0196
Epoch 7 [153/172] - loss: 0.0190
Epoch 7 [154/172] - loss: 0.0465
Epoch 7 [155/172] - loss: 0.0189
Epoch 7 [156/172] - loss: 0.1100
Epoch 7 [157/172] - loss: 0.0232
Epoch 7 [158/172] - loss: 0.0257
Epoch 7 [159/172] - loss: 0.0183
Epoch 7 [160/172] - loss: 0.0202, acc: 1.0000
Epoch 7 [161/172] - loss: 0.0202
Epoch 7 [162/172] - loss: 0.0228
Epoch 7 [163/172] - loss: 0.0226
Epoch 7 [164/172] - loss: 0.0257
Epoch 7 [165/172] - loss: 0.0309
Epoch 7 [166/172] - loss: 0.0207
Epoch 7 [167/172] - loss: 0.0482
Epoch 7 [168/172] - loss: 0.0220

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.2357, log_difficulty=0.2117, weight=2.0584
neutral: count=11731.0, difficulty=0.1823, log_difficulty=0.1675, weight=1.8374
negative: count=13173.0, difficulty=0.2375, log_difficulty=0.2131, weight=2.0656

当前batch的pt分布：
positive: min=0.8273, max=0.9912, mean=0.9543
neutral: min=0.7161, max=0.9934, mean=0.9412
negative: min=0.8443, max=0.9916, mean=0.9078

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0715
焦点损失: 0.0014
边界损失: 0.1700
总损失: 0.0195
Epoch 7 [169/172] - loss: 0.0195
Epoch 7 [170/172] - loss: 0.0446, acc: 0.9688
Epoch 7 [171/172] - loss: 0.0172
Epoch 7 [172/172] - loss: 0.0182

类别准确率:
positive: 0.8929 (417/467)
neutral: 0.2651 (22/83)
negative: 0.5880 (147/250)

Epoch 7/10
Train Loss: 0.0250, Train Acc: 0.9960
Val Loss: 0.7638, Val Acc: 0.7325
Early stopping triggered!
Best validation accuracy: 0.7388

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_130838-k4dubzda
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.3_Multimodal_iterations_20250118_130837
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/k4dubzda
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇███
wandb:  train_acc ▁▁▄▃▄▅▅█▅▇██▇█▇██▇▇█▇█████▇█████████████
wandb: train_loss █▇▆▅▅▅▃▄▄▃▃▂▂▂▁▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 0.96875
wandb: train_loss 0.04462
wandb: 
wandb: 🚀 View run loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.3_Multimodal_iterations_20250118_130837 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/k4dubzda
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_130838-k4dubzda/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_131926-wnfl873h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.3_Multimodal_epochs_20250118_131926
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/wnfl873h
wandb: uploading history steps 0-0, summary; updating run config; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▅▇▇███
wandb: train_loss █▄▂▂▁▁▁
wandb:    val_acc ▁▇▇██▇█
wandb:   val_loss █▁▁▁▂▅▄
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.99596
wandb: train_loss 0.025
wandb:    val_acc 0.7325
wandb:   val_loss 0.76376
wandb: 
wandb: 🚀 View run loss_focal_alpha0.9_beta0.09999999999999998_weight0.5_dropout0.3_Multimodal_epochs_20250118_131926 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/wnfl873h
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_131926-wnfl873h/logs

