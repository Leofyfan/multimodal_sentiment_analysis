=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 0.5 --dropout 0.15 --name loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.15 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.15
text_dim: 128
image_dim: 256
dropout: 0.15
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 0.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6805, log_difficulty=0.5191, weight=3.5955
neutral: count=7.0, difficulty=0.6554, log_difficulty=0.5040, weight=3.5201
negative: count=13.0, difficulty=0.6173, log_difficulty=0.4807, weight=3.4037

当前batch的pt分布：
positive: min=0.1232, max=0.4083, mean=0.3195
neutral: min=0.2497, max=0.4347, mean=0.3446
negative: min=0.2486, max=0.7650, mean=0.3827

当前batch准确率：
整体准确率: 0.4062
positive 准确率: 0.2500
neutral 准确率: 0.4286
negative 准确率: 0.5385

损失分量：
基础交叉熵: 1.0881
焦点损失: 0.3504
边界损失: 0.8372
总损失: 1.0343
Epoch 1 [1/172] - loss: 1.0343, acc: 0.4062
Epoch 1 [2/172] - loss: 1.1321
Epoch 1 [3/172] - loss: 0.9825
Epoch 1 [4/172] - loss: 0.9971
Epoch 1 [5/172] - loss: 0.9141
Epoch 1 [6/172] - loss: 1.3078
Epoch 1 [7/172] - loss: 0.9578
Epoch 1 [8/172] - loss: 1.0745
Epoch 1 [9/172] - loss: 0.9691
Epoch 1 [10/172] - loss: 1.1041, acc: 0.4062
Epoch 1 [11/172] - loss: 0.9446
Epoch 1 [12/172] - loss: 0.9876
Epoch 1 [13/172] - loss: 0.8957
Epoch 1 [14/172] - loss: 1.1687
Epoch 1 [15/172] - loss: 0.9357
Epoch 1 [16/172] - loss: 0.9062
Epoch 1 [17/172] - loss: 0.9664
Epoch 1 [18/172] - loss: 0.8846
Epoch 1 [19/172] - loss: 0.8708
Epoch 1 [20/172] - loss: 0.8920, acc: 0.5312
Epoch 1 [21/172] - loss: 0.8335
Epoch 1 [22/172] - loss: 0.7047
Epoch 1 [23/172] - loss: 0.8895
Epoch 1 [24/172] - loss: 0.9931
Epoch 1 [25/172] - loss: 0.7081
Epoch 1 [26/172] - loss: 0.8865
Epoch 1 [27/172] - loss: 0.8621
Epoch 1 [28/172] - loss: 0.6305
Epoch 1 [29/172] - loss: 0.8835
Epoch 1 [30/172] - loss: 0.7093, acc: 0.6875
Epoch 1 [31/172] - loss: 0.7919
Epoch 1 [32/172] - loss: 0.8848
Epoch 1 [33/172] - loss: 0.8261
Epoch 1 [34/172] - loss: 0.8163
Epoch 1 [35/172] - loss: 0.9616
Epoch 1 [36/172] - loss: 0.6857
Epoch 1 [37/172] - loss: 0.6969
Epoch 1 [38/172] - loss: 0.6701
Epoch 1 [39/172] - loss: 0.6392
Epoch 1 [40/172] - loss: 0.7878, acc: 0.5938
Epoch 1 [41/172] - loss: 0.6433
Epoch 1 [42/172] - loss: 0.6066
Epoch 1 [43/172] - loss: 0.7972
Epoch 1 [44/172] - loss: 0.9842
Epoch 1 [45/172] - loss: 1.0753
Epoch 1 [46/172] - loss: 0.7033
Epoch 1 [47/172] - loss: 0.6365
Epoch 1 [48/172] - loss: 0.7399
Epoch 1 [49/172] - loss: 0.8552
Epoch 1 [50/172] - loss: 0.8734, acc: 0.5625
Epoch 1 [51/172] - loss: 0.8671
Epoch 1 [52/172] - loss: 0.8227
Epoch 1 [53/172] - loss: 0.8135
Epoch 1 [54/172] - loss: 0.8418
Epoch 1 [55/172] - loss: 0.6638
Epoch 1 [56/172] - loss: 0.6886
Epoch 1 [57/172] - loss: 0.8901
Epoch 1 [58/172] - loss: 0.5055
Epoch 1 [59/172] - loss: 0.7746
Epoch 1 [60/172] - loss: 0.6909, acc: 0.6875
Epoch 1 [61/172] - loss: 0.7108
Epoch 1 [62/172] - loss: 0.5399
Epoch 1 [63/172] - loss: 0.5521
Epoch 1 [64/172] - loss: 0.3753
Epoch 1 [65/172] - loss: 0.8024
Epoch 1 [66/172] - loss: 0.8211
Epoch 1 [67/172] - loss: 0.7234
Epoch 1 [68/172] - loss: 0.7266
Epoch 1 [69/172] - loss: 1.0438
Epoch 1 [70/172] - loss: 0.8190, acc: 0.6250
Epoch 1 [71/172] - loss: 0.5118
Epoch 1 [72/172] - loss: 0.6479
Epoch 1 [73/172] - loss: 0.5290
Epoch 1 [74/172] - loss: 0.8057
Epoch 1 [75/172] - loss: 0.4577
Epoch 1 [76/172] - loss: 0.5789
Epoch 1 [77/172] - loss: 0.6938
Epoch 1 [78/172] - loss: 0.7183
Epoch 1 [79/172] - loss: 0.7410
Epoch 1 [80/172] - loss: 0.5117, acc: 0.7500
Epoch 1 [81/172] - loss: 0.6015
Epoch 1 [82/172] - loss: 0.7198
Epoch 1 [83/172] - loss: 0.7244
Epoch 1 [84/172] - loss: 0.5225
Epoch 1 [85/172] - loss: 0.5148
Epoch 1 [86/172] - loss: 0.8039
Epoch 1 [87/172] - loss: 0.6152
Epoch 1 [88/172] - loss: 0.6437
Epoch 1 [89/172] - loss: 0.7440
Epoch 1 [90/172] - loss: 0.5132, acc: 0.7812
Epoch 1 [91/172] - loss: 0.4857
Epoch 1 [92/172] - loss: 0.5801
Epoch 1 [93/172] - loss: 0.5179
Epoch 1 [94/172] - loss: 0.3517
Epoch 1 [95/172] - loss: 0.5556
Epoch 1 [96/172] - loss: 0.4713
Epoch 1 [97/172] - loss: 0.5078
Epoch 1 [98/172] - loss: 0.4249
Epoch 1 [99/172] - loss: 0.7423
Epoch 1 [100/172] - loss: 0.5585, acc: 0.7500

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5464, log_difficulty=0.4359, weight=3.1797
neutral: count=983.0, difficulty=0.5062, log_difficulty=0.4096, weight=3.0480
negative: count=1119.0, difficulty=0.5224, log_difficulty=0.4203, weight=3.1015

当前batch的pt分布：
positive: min=0.0511, max=0.8477, mean=0.4206
neutral: min=0.4860, max=0.9824, mean=0.7288
negative: min=0.0785, max=0.7661, mean=0.4388

当前batch准确率：
整体准确率: 0.5000
positive 准确率: 0.4167
neutral 准确率: 1.0000
negative 准确率: 0.4375

损失分量：
基础交叉熵: 0.9224
焦点损失: 0.3722
边界损失: 0.4918
总损失: 0.8308
Epoch 1 [101/172] - loss: 0.8308
Epoch 1 [102/172] - loss: 0.5579
Epoch 1 [103/172] - loss: 0.5177
Epoch 1 [104/172] - loss: 0.4665
Epoch 1 [105/172] - loss: 0.6665
Epoch 1 [106/172] - loss: 0.8102
Epoch 1 [107/172] - loss: 0.4393
Epoch 1 [108/172] - loss: 0.7392
Epoch 1 [109/172] - loss: 0.6316
Epoch 1 [110/172] - loss: 0.5930, acc: 0.7188
Epoch 1 [111/172] - loss: 0.7146
Epoch 1 [112/172] - loss: 0.4204
Epoch 1 [113/172] - loss: 0.3819
Epoch 1 [114/172] - loss: 0.4856
Epoch 1 [115/172] - loss: 0.5606
Epoch 1 [116/172] - loss: 0.7146
Epoch 1 [117/172] - loss: 0.5422
Epoch 1 [118/172] - loss: 0.5209
Epoch 1 [119/172] - loss: 0.4695
Epoch 1 [120/172] - loss: 0.4110, acc: 0.7500
Epoch 1 [121/172] - loss: 0.4889
Epoch 1 [122/172] - loss: 0.5825
Epoch 1 [123/172] - loss: 0.3785
Epoch 1 [124/172] - loss: 0.5721
Epoch 1 [125/172] - loss: 0.2833
Epoch 1 [126/172] - loss: 0.7139
Epoch 1 [127/172] - loss: 0.2882
Epoch 1 [128/172] - loss: 0.3255
Epoch 1 [129/172] - loss: 0.4722
Epoch 1 [130/172] - loss: 0.4572, acc: 0.7188
Epoch 1 [131/172] - loss: 0.2213
Epoch 1 [132/172] - loss: 0.3643
Epoch 1 [133/172] - loss: 0.4830
Epoch 1 [134/172] - loss: 0.4498
Epoch 1 [135/172] - loss: 0.4552
Epoch 1 [136/172] - loss: 0.4377
Epoch 1 [137/172] - loss: 0.4436
Epoch 1 [138/172] - loss: 0.3438
Epoch 1 [139/172] - loss: 0.3889
Epoch 1 [140/172] - loss: 0.3077, acc: 0.7812
Epoch 1 [141/172] - loss: 0.4144
Epoch 1 [142/172] - loss: 0.4891
Epoch 1 [143/172] - loss: 0.4392
Epoch 1 [144/172] - loss: 0.3702
Epoch 1 [145/172] - loss: 0.4705
Epoch 1 [146/172] - loss: 0.5795
Epoch 1 [147/172] - loss: 0.4734
Epoch 1 [148/172] - loss: 0.3389
Epoch 1 [149/172] - loss: 0.3357
Epoch 1 [150/172] - loss: 0.4523, acc: 0.7500
Epoch 1 [151/172] - loss: 0.6601
Epoch 1 [152/172] - loss: 0.4440
Epoch 1 [153/172] - loss: 0.3442
Epoch 1 [154/172] - loss: 0.4308
Epoch 1 [155/172] - loss: 0.5335
Epoch 1 [156/172] - loss: 0.7181
Epoch 1 [157/172] - loss: 0.4935
Epoch 1 [158/172] - loss: 0.3300
Epoch 1 [159/172] - loss: 0.6298
Epoch 1 [160/172] - loss: 0.3149, acc: 0.9062
Epoch 1 [161/172] - loss: 0.3422
Epoch 1 [162/172] - loss: 0.3551
Epoch 1 [163/172] - loss: 0.3845
Epoch 1 [164/172] - loss: 0.5211
Epoch 1 [165/172] - loss: 0.3543
Epoch 1 [166/172] - loss: 0.3368
Epoch 1 [167/172] - loss: 0.3510
Epoch 1 [168/172] - loss: 0.3719
Epoch 1 [169/172] - loss: 0.3968
Epoch 1 [170/172] - loss: 0.4111, acc: 0.8125
Epoch 1 [171/172] - loss: 0.3541
Epoch 1 [172/172] - loss: 0.4207

类别准确率:
positive: 0.6981 (326/467)
neutral: 0.4096 (34/83)
negative: 0.8120 (203/250)

Epoch 1/10
Train Loss: 0.3980, Train Acc: 0.8141
Val Loss: 0.6995, Val Acc: 0.7037
Epoch 2 [1/172] - loss: 0.2375, acc: 0.9375
Epoch 2 [2/172] - loss: 0.2286
Epoch 2 [3/172] - loss: 0.1949
Epoch 2 [4/172] - loss: 0.3202
Epoch 2 [5/172] - loss: 0.4294
Epoch 2 [6/172] - loss: 0.3606
Epoch 2 [7/172] - loss: 0.3148
Epoch 2 [8/172] - loss: 0.4257
Epoch 2 [9/172] - loss: 0.2534
Epoch 2 [10/172] - loss: 0.2620, acc: 0.9062
Epoch 2 [11/172] - loss: 0.2651
Epoch 2 [12/172] - loss: 0.2032
Epoch 2 [13/172] - loss: 0.4173
Epoch 2 [14/172] - loss: 0.2505
Epoch 2 [15/172] - loss: 0.3797
Epoch 2 [16/172] - loss: 0.3953
Epoch 2 [17/172] - loss: 0.3472
Epoch 2 [18/172] - loss: 0.4932
Epoch 2 [19/172] - loss: 0.2668
Epoch 2 [20/172] - loss: 0.2860, acc: 0.8125
Epoch 2 [21/172] - loss: 0.2454
Epoch 2 [22/172] - loss: 0.3646
Epoch 2 [23/172] - loss: 0.1460
Epoch 2 [24/172] - loss: 0.4543
Epoch 2 [25/172] - loss: 0.3476
Epoch 2 [26/172] - loss: 0.1810
Epoch 2 [27/172] - loss: 0.2846
Epoch 2 [28/172] - loss: 0.3627

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4700, log_difficulty=0.3853, weight=2.9265
neutral: count=1952.0, difficulty=0.3915, log_difficulty=0.3304, weight=2.6520
negative: count=2216.0, difficulty=0.4442, log_difficulty=0.3675, weight=2.8376

当前batch的pt分布：
positive: min=0.4644, max=0.9477, mean=0.7432
neutral: min=0.2799, max=0.9662, mean=0.7861
negative: min=0.0349, max=0.9288, mean=0.6580

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 1.0000
neutral 准确率: 0.8182
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.4317
焦点损失: 0.1558
边界损失: 0.2919
总损失: 0.3646
Epoch 2 [29/172] - loss: 0.3646
Epoch 2 [30/172] - loss: 0.2548, acc: 0.9062
Epoch 2 [31/172] - loss: 0.3811
Epoch 2 [32/172] - loss: 0.2720
Epoch 2 [33/172] - loss: 0.2101
Epoch 2 [34/172] - loss: 0.4680
Epoch 2 [35/172] - loss: 0.1918
Epoch 2 [36/172] - loss: 0.3621
Epoch 2 [37/172] - loss: 0.1710
Epoch 2 [38/172] - loss: 0.3025
Epoch 2 [39/172] - loss: 0.3244
Epoch 2 [40/172] - loss: 0.2403, acc: 0.8438
Epoch 2 [41/172] - loss: 0.2564
Epoch 2 [42/172] - loss: 0.1661
Epoch 2 [43/172] - loss: 0.1916
Epoch 2 [44/172] - loss: 0.3472
Epoch 2 [45/172] - loss: 0.2094
Epoch 2 [46/172] - loss: 0.2188
Epoch 2 [47/172] - loss: 0.4019
Epoch 2 [48/172] - loss: 0.3610
Epoch 2 [49/172] - loss: 0.2354
Epoch 2 [50/172] - loss: 0.3920, acc: 0.7812
Epoch 2 [51/172] - loss: 0.3236
Epoch 2 [52/172] - loss: 0.2205
Epoch 2 [53/172] - loss: 0.2431
Epoch 2 [54/172] - loss: 0.3137
Epoch 2 [55/172] - loss: 0.2923
Epoch 2 [56/172] - loss: 0.1851
Epoch 2 [57/172] - loss: 0.2367
Epoch 2 [58/172] - loss: 0.2879
Epoch 2 [59/172] - loss: 0.3407
Epoch 2 [60/172] - loss: 0.2684, acc: 0.8438
Epoch 2 [61/172] - loss: 0.1468
Epoch 2 [62/172] - loss: 0.1578
Epoch 2 [63/172] - loss: 0.3247
Epoch 2 [64/172] - loss: 0.2763
Epoch 2 [65/172] - loss: 0.2190
Epoch 2 [66/172] - loss: 0.2049
Epoch 2 [67/172] - loss: 0.1346
Epoch 2 [68/172] - loss: 0.2744
Epoch 2 [69/172] - loss: 0.2407
Epoch 2 [70/172] - loss: 0.2928, acc: 0.8750
Epoch 2 [71/172] - loss: 0.2812
Epoch 2 [72/172] - loss: 0.1981
Epoch 2 [73/172] - loss: 0.2397
Epoch 2 [74/172] - loss: 0.2636
Epoch 2 [75/172] - loss: 0.1999
Epoch 2 [76/172] - loss: 0.2280
Epoch 2 [77/172] - loss: 0.2808
Epoch 2 [78/172] - loss: 0.2938
Epoch 2 [79/172] - loss: 0.2868
Epoch 2 [80/172] - loss: 0.1407, acc: 0.9688
Epoch 2 [81/172] - loss: 0.1517
Epoch 2 [82/172] - loss: 0.2144
Epoch 2 [83/172] - loss: 0.1863
Epoch 2 [84/172] - loss: 0.2273
Epoch 2 [85/172] - loss: 0.1552
Epoch 2 [86/172] - loss: 0.2270
Epoch 2 [87/172] - loss: 0.6164
Epoch 2 [88/172] - loss: 0.1875
Epoch 2 [89/172] - loss: 0.1599
Epoch 2 [90/172] - loss: 0.2835, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1506
Epoch 2 [92/172] - loss: 0.2759
Epoch 2 [93/172] - loss: 0.2290
Epoch 2 [94/172] - loss: 0.1976
Epoch 2 [95/172] - loss: 0.2644
Epoch 2 [96/172] - loss: 0.1269
Epoch 2 [97/172] - loss: 0.2307
Epoch 2 [98/172] - loss: 0.2475
Epoch 2 [99/172] - loss: 0.1414
Epoch 2 [100/172] - loss: 0.2293, acc: 0.8750
Epoch 2 [101/172] - loss: 0.2157
Epoch 2 [102/172] - loss: 0.1280
Epoch 2 [103/172] - loss: 0.1968
Epoch 2 [104/172] - loss: 0.2388
Epoch 2 [105/172] - loss: 0.1857
Epoch 2 [106/172] - loss: 0.1774
Epoch 2 [107/172] - loss: 0.1452
Epoch 2 [108/172] - loss: 0.3449
Epoch 2 [109/172] - loss: 0.1757
Epoch 2 [110/172] - loss: 0.2335, acc: 0.9375
Epoch 2 [111/172] - loss: 0.1808
Epoch 2 [112/172] - loss: 0.1415
Epoch 2 [113/172] - loss: 0.1413
Epoch 2 [114/172] - loss: 0.1965
Epoch 2 [115/172] - loss: 0.3126
Epoch 2 [116/172] - loss: 0.2927
Epoch 2 [117/172] - loss: 0.4131
Epoch 2 [118/172] - loss: 0.1673
Epoch 2 [119/172] - loss: 0.2148
Epoch 2 [120/172] - loss: 0.1538, acc: 0.9688
Epoch 2 [121/172] - loss: 0.3171
Epoch 2 [122/172] - loss: 0.5199
Epoch 2 [123/172] - loss: 0.2412
Epoch 2 [124/172] - loss: 0.1384
Epoch 2 [125/172] - loss: 0.1524
Epoch 2 [126/172] - loss: 0.1429
Epoch 2 [127/172] - loss: 0.2768
Epoch 2 [128/172] - loss: 0.1435

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3982, log_difficulty=0.3352, weight=2.6759
neutral: count=2949.0, difficulty=0.3085, log_difficulty=0.2689, weight=2.3445
negative: count=3294.0, difficulty=0.3833, log_difficulty=0.3245, weight=2.6223

当前batch的pt分布：
positive: min=0.5853, max=0.9571, mean=0.8559
neutral: min=0.4494, max=0.9827, mean=0.7793
negative: min=0.1895, max=0.9890, mean=0.7854

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.2710
焦点损失: 0.0689
边界损失: 0.2390
总损失: 0.2080
Epoch 2 [129/172] - loss: 0.2080
Epoch 2 [130/172] - loss: 0.2306, acc: 0.9062
Epoch 2 [131/172] - loss: 0.1943
Epoch 2 [132/172] - loss: 0.2996
Epoch 2 [133/172] - loss: 0.2080
Epoch 2 [134/172] - loss: 0.2863
Epoch 2 [135/172] - loss: 0.3326
Epoch 2 [136/172] - loss: 0.1266
Epoch 2 [137/172] - loss: 0.1652
Epoch 2 [138/172] - loss: 0.1858
Epoch 2 [139/172] - loss: 0.1927
Epoch 2 [140/172] - loss: 0.1531, acc: 0.9688
Epoch 2 [141/172] - loss: 0.1562
Epoch 2 [142/172] - loss: 0.2372
Epoch 2 [143/172] - loss: 0.1702
Epoch 2 [144/172] - loss: 0.1675
Epoch 2 [145/172] - loss: 0.4830
Epoch 2 [146/172] - loss: 0.1327
Epoch 2 [147/172] - loss: 0.1930
Epoch 2 [148/172] - loss: 0.1982
Epoch 2 [149/172] - loss: 0.2943
Epoch 2 [150/172] - loss: 0.1787, acc: 0.9688
Epoch 2 [151/172] - loss: 0.2217
Epoch 2 [152/172] - loss: 0.1898
Epoch 2 [153/172] - loss: 0.1688
Epoch 2 [154/172] - loss: 0.1719
Epoch 2 [155/172] - loss: 0.1901
Epoch 2 [156/172] - loss: 0.1423
Epoch 2 [157/172] - loss: 0.1491
Epoch 2 [158/172] - loss: 0.1942
Epoch 2 [159/172] - loss: 0.1633
Epoch 2 [160/172] - loss: 0.1891, acc: 0.9688
Epoch 2 [161/172] - loss: 0.1435
Epoch 2 [162/172] - loss: 0.1573
Epoch 2 [163/172] - loss: 0.3217
Epoch 2 [164/172] - loss: 0.1718
Epoch 2 [165/172] - loss: 0.4840
Epoch 2 [166/172] - loss: 0.3352
Epoch 2 [167/172] - loss: 0.3200
Epoch 2 [168/172] - loss: 0.1529
Epoch 2 [169/172] - loss: 0.1087
Epoch 2 [170/172] - loss: 0.1841, acc: 0.8750
Epoch 2 [171/172] - loss: 0.2356
Epoch 2 [172/172] - loss: 0.6934

类别准确率:
positive: 0.6467 (302/467)
neutral: 0.5060 (42/83)
negative: 0.7160 (179/250)

Epoch 2/10
Train Loss: 0.2502, Train Acc: 0.9232
Val Loss: 0.8570, Val Acc: 0.6538
Epoch 3 [1/172] - loss: 0.2066, acc: 0.8750
Epoch 3 [2/172] - loss: 0.1636
Epoch 3 [3/172] - loss: 0.1184
Epoch 3 [4/172] - loss: 0.1350
Epoch 3 [5/172] - loss: 0.2173
Epoch 3 [6/172] - loss: 0.1318
Epoch 3 [7/172] - loss: 0.1265
Epoch 3 [8/172] - loss: 0.1917
Epoch 3 [9/172] - loss: 0.2807
Epoch 3 [10/172] - loss: 0.1363, acc: 0.9375
Epoch 3 [11/172] - loss: 0.1128
Epoch 3 [12/172] - loss: 0.0995
Epoch 3 [13/172] - loss: 0.1183
Epoch 3 [14/172] - loss: 0.1150
Epoch 3 [15/172] - loss: 0.1214
Epoch 3 [16/172] - loss: 0.2483
Epoch 3 [17/172] - loss: 0.2040
Epoch 3 [18/172] - loss: 0.1752
Epoch 3 [19/172] - loss: 0.1100
Epoch 3 [20/172] - loss: 0.1206, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1419
Epoch 3 [22/172] - loss: 0.1761
Epoch 3 [23/172] - loss: 0.1435
Epoch 3 [24/172] - loss: 0.1634
Epoch 3 [25/172] - loss: 0.1748
Epoch 3 [26/172] - loss: 0.1586
Epoch 3 [27/172] - loss: 0.1109
Epoch 3 [28/172] - loss: 0.1266
Epoch 3 [29/172] - loss: 0.2548
Epoch 3 [30/172] - loss: 0.1671, acc: 0.9375
Epoch 3 [31/172] - loss: 0.1010
Epoch 3 [32/172] - loss: 0.1433
Epoch 3 [33/172] - loss: 0.1614
Epoch 3 [34/172] - loss: 0.1651
Epoch 3 [35/172] - loss: 0.3126
Epoch 3 [36/172] - loss: 0.1216
Epoch 3 [37/172] - loss: 0.1800
Epoch 3 [38/172] - loss: 0.0971
Epoch 3 [39/172] - loss: 0.1206
Epoch 3 [40/172] - loss: 0.2544, acc: 0.9062
Epoch 3 [41/172] - loss: 0.1437
Epoch 3 [42/172] - loss: 0.1381
Epoch 3 [43/172] - loss: 0.1091
Epoch 3 [44/172] - loss: 0.1063
Epoch 3 [45/172] - loss: 0.1242
Epoch 3 [46/172] - loss: 0.1343
Epoch 3 [47/172] - loss: 0.0871
Epoch 3 [48/172] - loss: 0.1694
Epoch 3 [49/172] - loss: 0.0936
Epoch 3 [50/172] - loss: 0.0896, acc: 1.0000
Epoch 3 [51/172] - loss: 0.2142
Epoch 3 [52/172] - loss: 0.0991
Epoch 3 [53/172] - loss: 0.1542
Epoch 3 [54/172] - loss: 0.1145
Epoch 3 [55/172] - loss: 0.1368
Epoch 3 [56/172] - loss: 0.1082

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3438, log_difficulty=0.2955, weight=2.4775
neutral: count=3923.0, difficulty=0.2601, log_difficulty=0.2312, weight=2.1561
negative: count=4382.0, difficulty=0.3304, log_difficulty=0.2855, weight=2.4275

当前batch的pt分布：
positive: min=0.6137, max=0.9888, mean=0.8855
neutral: min=0.0617, max=0.9896, mean=0.7423
negative: min=0.9696, max=0.9936, mean=0.9832

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 1.0000
neutral 准确率: 0.8125
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2717
焦点损失: 0.1129
边界损失: 0.2196
总损失: 0.2318
Epoch 3 [57/172] - loss: 0.2318
Epoch 3 [58/172] - loss: 0.1330
Epoch 3 [59/172] - loss: 0.0985
Epoch 3 [60/172] - loss: 0.0971, acc: 1.0000
Epoch 3 [61/172] - loss: 0.1210
Epoch 3 [62/172] - loss: 0.1086
Epoch 3 [63/172] - loss: 0.1508
Epoch 3 [64/172] - loss: 0.2461
Epoch 3 [65/172] - loss: 0.1036
Epoch 3 [66/172] - loss: 0.1755
Epoch 3 [67/172] - loss: 0.1102
Epoch 3 [68/172] - loss: 0.1359
Epoch 3 [69/172] - loss: 0.1598
Epoch 3 [70/172] - loss: 0.0873, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1627
Epoch 3 [72/172] - loss: 0.1253
Epoch 3 [73/172] - loss: 0.1177
Epoch 3 [74/172] - loss: 0.1746
Epoch 3 [75/172] - loss: 0.1325
Epoch 3 [76/172] - loss: 0.1030
Epoch 3 [77/172] - loss: 0.0912
Epoch 3 [78/172] - loss: 0.2037
Epoch 3 [79/172] - loss: 0.0917
Epoch 3 [80/172] - loss: 0.1232, acc: 0.9688
Epoch 3 [81/172] - loss: 0.0952
Epoch 3 [82/172] - loss: 0.2600
Epoch 3 [83/172] - loss: 0.1203
Epoch 3 [84/172] - loss: 0.0926
Epoch 3 [85/172] - loss: 0.0937
Epoch 3 [86/172] - loss: 0.0945
Epoch 3 [87/172] - loss: 0.2728
Epoch 3 [88/172] - loss: 0.1204
Epoch 3 [89/172] - loss: 0.1049
Epoch 3 [90/172] - loss: 0.1449, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1019
Epoch 3 [92/172] - loss: 0.1348
Epoch 3 [93/172] - loss: 0.1838
Epoch 3 [94/172] - loss: 0.2223
Epoch 3 [95/172] - loss: 0.0974
Epoch 3 [96/172] - loss: 0.1234
Epoch 3 [97/172] - loss: 0.1101
Epoch 3 [98/172] - loss: 0.1152
Epoch 3 [99/172] - loss: 0.0977
Epoch 3 [100/172] - loss: 0.1487, acc: 0.9062
Epoch 3 [101/172] - loss: 0.1989
Epoch 3 [102/172] - loss: 0.0894
Epoch 3 [103/172] - loss: 0.1753
Epoch 3 [104/172] - loss: 0.0961
Epoch 3 [105/172] - loss: 0.0910
Epoch 3 [106/172] - loss: 0.1854
Epoch 3 [107/172] - loss: 0.1297
Epoch 3 [108/172] - loss: 0.1547
Epoch 3 [109/172] - loss: 0.1122
Epoch 3 [110/172] - loss: 0.1436, acc: 0.9375
Epoch 3 [111/172] - loss: 0.1783
Epoch 3 [112/172] - loss: 0.0990
Epoch 3 [113/172] - loss: 0.0871
Epoch 3 [114/172] - loss: 0.1699
Epoch 3 [115/172] - loss: 0.1128
Epoch 3 [116/172] - loss: 0.0902
Epoch 3 [117/172] - loss: 0.0971
Epoch 3 [118/172] - loss: 0.1060
Epoch 3 [119/172] - loss: 0.1549
Epoch 3 [120/172] - loss: 0.1928, acc: 0.9688
Epoch 3 [121/172] - loss: 0.2451
Epoch 3 [122/172] - loss: 0.0985
Epoch 3 [123/172] - loss: 0.1968
Epoch 3 [124/172] - loss: 0.0939
Epoch 3 [125/172] - loss: 0.1836
Epoch 3 [126/172] - loss: 0.1420
Epoch 3 [127/172] - loss: 0.1758
Epoch 3 [128/172] - loss: 0.0890
Epoch 3 [129/172] - loss: 0.1204
Epoch 3 [130/172] - loss: 0.1879, acc: 0.9375
Epoch 3 [131/172] - loss: 0.1223
Epoch 3 [132/172] - loss: 0.0939
Epoch 3 [133/172] - loss: 0.1938
Epoch 3 [134/172] - loss: 0.1010
Epoch 3 [135/172] - loss: 0.1670
Epoch 3 [136/172] - loss: 0.1422
Epoch 3 [137/172] - loss: 0.1014
Epoch 3 [138/172] - loss: 0.1271
Epoch 3 [139/172] - loss: 0.1172
Epoch 3 [140/172] - loss: 0.1354, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1220
Epoch 3 [142/172] - loss: 0.2124
Epoch 3 [143/172] - loss: 0.1437
Epoch 3 [144/172] - loss: 0.3207
Epoch 3 [145/172] - loss: 0.1888
Epoch 3 [146/172] - loss: 0.1360
Epoch 3 [147/172] - loss: 0.1671
Epoch 3 [148/172] - loss: 0.0958
Epoch 3 [149/172] - loss: 0.1993
Epoch 3 [150/172] - loss: 0.1206, acc: 0.9688
Epoch 3 [151/172] - loss: 0.1416
Epoch 3 [152/172] - loss: 0.2313
Epoch 3 [153/172] - loss: 0.0955
Epoch 3 [154/172] - loss: 0.2275
Epoch 3 [155/172] - loss: 0.0832
Epoch 3 [156/172] - loss: 0.1229

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3009, log_difficulty=0.2631, weight=2.3155
neutral: count=4903.0, difficulty=0.2238, log_difficulty=0.2020, weight=2.0098
negative: count=5500.0, difficulty=0.2885, log_difficulty=0.2535, weight=2.2674

当前batch的pt分布：
positive: min=0.2469, max=0.9957, mean=0.8881
neutral: min=0.9007, max=0.9934, mean=0.9607
negative: min=0.6046, max=0.9877, mean=0.9215

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1014
焦点损失: 0.0249
边界损失: 0.1697
总损失: 0.1136
Epoch 3 [157/172] - loss: 0.1136
Epoch 3 [158/172] - loss: 0.1392
Epoch 3 [159/172] - loss: 0.1454
Epoch 3 [160/172] - loss: 0.2387, acc: 0.8750
Epoch 3 [161/172] - loss: 0.3346
Epoch 3 [162/172] - loss: 0.1103
Epoch 3 [163/172] - loss: 0.1048
Epoch 3 [164/172] - loss: 0.0946
Epoch 3 [165/172] - loss: 0.1703
Epoch 3 [166/172] - loss: 0.1220
Epoch 3 [167/172] - loss: 0.1150
Epoch 3 [168/172] - loss: 0.1159
Epoch 3 [169/172] - loss: 0.1068
Epoch 3 [170/172] - loss: 0.2152, acc: 0.9062
Epoch 3 [171/172] - loss: 0.1213
Epoch 3 [172/172] - loss: 0.1130

类别准确率:
positive: 0.8844 (413/467)
neutral: 0.3494 (29/83)
negative: 0.5480 (137/250)

Epoch 3/10
Train Loss: 0.1476, Train Acc: 0.9515
Val Loss: 0.7477, Val Acc: 0.7238
Epoch 4 [1/172] - loss: 0.0847, acc: 1.0000
Epoch 4 [2/172] - loss: 0.0935
Epoch 4 [3/172] - loss: 0.1006
Epoch 4 [4/172] - loss: 0.0878
Epoch 4 [5/172] - loss: 0.1001
Epoch 4 [6/172] - loss: 0.0855
Epoch 4 [7/172] - loss: 0.1199
Epoch 4 [8/172] - loss: 0.1006
Epoch 4 [9/172] - loss: 0.1412
Epoch 4 [10/172] - loss: 0.1559, acc: 0.9375
Epoch 4 [11/172] - loss: 0.0860
Epoch 4 [12/172] - loss: 0.1180
Epoch 4 [13/172] - loss: 0.1189
Epoch 4 [14/172] - loss: 0.1129
Epoch 4 [15/172] - loss: 0.0981
Epoch 4 [16/172] - loss: 0.1095
Epoch 4 [17/172] - loss: 0.0902
Epoch 4 [18/172] - loss: 0.0913
Epoch 4 [19/172] - loss: 0.0880
Epoch 4 [20/172] - loss: 0.0939, acc: 1.0000
Epoch 4 [21/172] - loss: 0.2582
Epoch 4 [22/172] - loss: 0.0905
Epoch 4 [23/172] - loss: 0.1429
Epoch 4 [24/172] - loss: 0.0809
Epoch 4 [25/172] - loss: 0.0838
Epoch 4 [26/172] - loss: 0.1737
Epoch 4 [27/172] - loss: 0.0849
Epoch 4 [28/172] - loss: 0.1940
Epoch 4 [29/172] - loss: 0.1196
Epoch 4 [30/172] - loss: 0.2171, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1699
Epoch 4 [32/172] - loss: 0.0805
Epoch 4 [33/172] - loss: 0.0926
Epoch 4 [34/172] - loss: 0.0854
Epoch 4 [35/172] - loss: 0.1448
Epoch 4 [36/172] - loss: 0.1006
Epoch 4 [37/172] - loss: 0.0824
Epoch 4 [38/172] - loss: 0.0793
Epoch 4 [39/172] - loss: 0.1629
Epoch 4 [40/172] - loss: 0.1973, acc: 0.9062
Epoch 4 [41/172] - loss: 0.0983
Epoch 4 [42/172] - loss: 0.2617
Epoch 4 [43/172] - loss: 0.2235
Epoch 4 [44/172] - loss: 0.0986
Epoch 4 [45/172] - loss: 0.0801
Epoch 4 [46/172] - loss: 0.0839
Epoch 4 [47/172] - loss: 0.1001
Epoch 4 [48/172] - loss: 0.1056
Epoch 4 [49/172] - loss: 0.1023
Epoch 4 [50/172] - loss: 0.1018, acc: 1.0000
Epoch 4 [51/172] - loss: 0.0817
Epoch 4 [52/172] - loss: 0.1708
Epoch 4 [53/172] - loss: 0.0810
Epoch 4 [54/172] - loss: 0.1351
Epoch 4 [55/172] - loss: 0.2740
Epoch 4 [56/172] - loss: 0.1021
Epoch 4 [57/172] - loss: 0.0973
Epoch 4 [58/172] - loss: 0.0919
Epoch 4 [59/172] - loss: 0.0838
Epoch 4 [60/172] - loss: 0.0851, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1270
Epoch 4 [62/172] - loss: 0.1088
Epoch 4 [63/172] - loss: 0.0946
Epoch 4 [64/172] - loss: 0.0805
Epoch 4 [65/172] - loss: 0.1964
Epoch 4 [66/172] - loss: 0.0928
Epoch 4 [67/172] - loss: 0.0914
Epoch 4 [68/172] - loss: 0.0838
Epoch 4 [69/172] - loss: 0.0920
Epoch 4 [70/172] - loss: 0.0845, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0995
Epoch 4 [72/172] - loss: 0.0914
Epoch 4 [73/172] - loss: 0.0890
Epoch 4 [74/172] - loss: 0.3722
Epoch 4 [75/172] - loss: 0.0833
Epoch 4 [76/172] - loss: 0.0784
Epoch 4 [77/172] - loss: 0.1062
Epoch 4 [78/172] - loss: 0.0781
Epoch 4 [79/172] - loss: 0.0806
Epoch 4 [80/172] - loss: 0.0887, acc: 0.9688
Epoch 4 [81/172] - loss: 0.1401
Epoch 4 [82/172] - loss: 0.0928
Epoch 4 [83/172] - loss: 0.0802
Epoch 4 [84/172] - loss: 0.1064

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2670, log_difficulty=0.2366, weight=2.1832
neutral: count=5865.0, difficulty=0.1992, log_difficulty=0.1817, weight=1.9084
negative: count=6629.0, difficulty=0.2553, log_difficulty=0.2273, weight=2.1367

当前batch的pt分布：
positive: min=0.4387, max=0.9776, mean=0.8696
neutral: min=0.8403, max=0.9992, mean=0.9719
negative: min=0.9095, max=0.9953, mean=0.9713

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0929
焦点损失: 0.0087
边界损失: 0.1768
总损失: 0.0979
Epoch 4 [85/172] - loss: 0.0979
Epoch 4 [86/172] - loss: 0.1025
Epoch 4 [87/172] - loss: 0.0824
Epoch 4 [88/172] - loss: 0.0825
Epoch 4 [89/172] - loss: 0.0913
Epoch 4 [90/172] - loss: 0.0797, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1597
Epoch 4 [92/172] - loss: 0.2357
Epoch 4 [93/172] - loss: 0.0918
Epoch 4 [94/172] - loss: 0.0778
Epoch 4 [95/172] - loss: 0.0991
Epoch 4 [96/172] - loss: 0.1295
Epoch 4 [97/172] - loss: 0.1232
Epoch 4 [98/172] - loss: 0.0876
Epoch 4 [99/172] - loss: 0.0804
Epoch 4 [100/172] - loss: 0.1136, acc: 0.9688
Epoch 4 [101/172] - loss: 0.0963
Epoch 4 [102/172] - loss: 0.1063
Epoch 4 [103/172] - loss: 0.0879
Epoch 4 [104/172] - loss: 0.0884
Epoch 4 [105/172] - loss: 0.0896
Epoch 4 [106/172] - loss: 0.0792
Epoch 4 [107/172] - loss: 0.0983
Epoch 4 [108/172] - loss: 0.1079
Epoch 4 [109/172] - loss: 0.0798
Epoch 4 [110/172] - loss: 0.1942, acc: 0.9062
Epoch 4 [111/172] - loss: 0.0765
Epoch 4 [112/172] - loss: 0.0840
Epoch 4 [113/172] - loss: 0.0798
Epoch 4 [114/172] - loss: 0.0885
Epoch 4 [115/172] - loss: 0.1305
Epoch 4 [116/172] - loss: 0.1178
Epoch 4 [117/172] - loss: 0.1094
Epoch 4 [118/172] - loss: 0.0941
Epoch 4 [119/172] - loss: 0.0900
Epoch 4 [120/172] - loss: 0.0831, acc: 1.0000
Epoch 4 [121/172] - loss: 0.2033
Epoch 4 [122/172] - loss: 0.1503
Epoch 4 [123/172] - loss: 0.0820
Epoch 4 [124/172] - loss: 0.0823
Epoch 4 [125/172] - loss: 0.2045
Epoch 4 [126/172] - loss: 0.1979
Epoch 4 [127/172] - loss: 0.1318
Epoch 4 [128/172] - loss: 0.0859
Epoch 4 [129/172] - loss: 0.0766
Epoch 4 [130/172] - loss: 0.0770, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0848
Epoch 4 [132/172] - loss: 0.0823
Epoch 4 [133/172] - loss: 0.1294
Epoch 4 [134/172] - loss: 0.1165
Epoch 4 [135/172] - loss: 0.1089
Epoch 4 [136/172] - loss: 0.1138
Epoch 4 [137/172] - loss: 0.1059
Epoch 4 [138/172] - loss: 0.0773
Epoch 4 [139/172] - loss: 0.0826
Epoch 4 [140/172] - loss: 0.0798, acc: 1.0000
Epoch 4 [141/172] - loss: 0.1673
Epoch 4 [142/172] - loss: 0.0927
Epoch 4 [143/172] - loss: 0.0973
Epoch 4 [144/172] - loss: 0.0958
Epoch 4 [145/172] - loss: 0.1854
Epoch 4 [146/172] - loss: 0.0854
Epoch 4 [147/172] - loss: 0.1183
Epoch 4 [148/172] - loss: 0.0897
Epoch 4 [149/172] - loss: 0.0781
Epoch 4 [150/172] - loss: 0.1167, acc: 0.9688
Epoch 4 [151/172] - loss: 0.2169
Epoch 4 [152/172] - loss: 0.0770
Epoch 4 [153/172] - loss: 0.0788
Epoch 4 [154/172] - loss: 0.1190
Epoch 4 [155/172] - loss: 0.0979
Epoch 4 [156/172] - loss: 0.0889
Epoch 4 [157/172] - loss: 0.1813
Epoch 4 [158/172] - loss: 0.0772
Epoch 4 [159/172] - loss: 0.0827
Epoch 4 [160/172] - loss: 0.0794, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1077
Epoch 4 [162/172] - loss: 0.0904
Epoch 4 [163/172] - loss: 0.1268
Epoch 4 [164/172] - loss: 0.0825
Epoch 4 [165/172] - loss: 0.1442
Epoch 4 [166/172] - loss: 0.0808
Epoch 4 [167/172] - loss: 0.2243
Epoch 4 [168/172] - loss: 0.1126
Epoch 4 [169/172] - loss: 0.1668
Epoch 4 [170/172] - loss: 0.1944, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0864
Epoch 4 [172/172] - loss: 0.0937

类别准确率:
positive: 0.8758 (409/467)
neutral: 0.2048 (17/83)
negative: 0.6240 (156/250)

Epoch 4/10
Train Loss: 0.1207, Train Acc: 0.9798
Val Loss: 0.8396, Val Acc: 0.7275
Epoch 5 [1/172] - loss: 0.0779, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0852
Epoch 5 [3/172] - loss: 0.0761
Epoch 5 [4/172] - loss: 0.1396
Epoch 5 [5/172] - loss: 0.0836
Epoch 5 [6/172] - loss: 0.0908
Epoch 5 [7/172] - loss: 0.1032
Epoch 5 [8/172] - loss: 0.0846
Epoch 5 [9/172] - loss: 0.1223
Epoch 5 [10/172] - loss: 0.0790, acc: 1.0000
Epoch 5 [11/172] - loss: 0.0896
Epoch 5 [12/172] - loss: 0.0762

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2395, log_difficulty=0.2147, weight=2.0736
neutral: count=6845.0, difficulty=0.1783, log_difficulty=0.1641, weight=1.8205
negative: count=7694.0, difficulty=0.2301, log_difficulty=0.2071, weight=2.0356

当前batch的pt分布：
positive: min=0.1057, max=0.9964, mean=0.8764
neutral: min=0.9779, max=0.9977, mean=0.9897
negative: min=0.9327, max=0.9979, mean=0.9693

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1111
焦点损失: 0.0557
边界损失: 0.1633
总损失: 0.1393
Epoch 5 [13/172] - loss: 0.1393
Epoch 5 [14/172] - loss: 0.1261
Epoch 5 [15/172] - loss: 0.0816
Epoch 5 [16/172] - loss: 0.0904
Epoch 5 [17/172] - loss: 0.0964
Epoch 5 [18/172] - loss: 0.0816
Epoch 5 [19/172] - loss: 0.0837
Epoch 5 [20/172] - loss: 0.0981, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1301
Epoch 5 [22/172] - loss: 0.2855
Epoch 5 [23/172] - loss: 0.0764
Epoch 5 [24/172] - loss: 0.1431
Epoch 5 [25/172] - loss: 0.0761
Epoch 5 [26/172] - loss: 0.1366
Epoch 5 [27/172] - loss: 0.0758
Epoch 5 [28/172] - loss: 0.0838
Epoch 5 [29/172] - loss: 0.0826
Epoch 5 [30/172] - loss: 0.0898, acc: 1.0000
Epoch 5 [31/172] - loss: 0.0991
Epoch 5 [32/172] - loss: 0.0911
Epoch 5 [33/172] - loss: 0.1370
Epoch 5 [34/172] - loss: 0.0759
Epoch 5 [35/172] - loss: 0.0765
Epoch 5 [36/172] - loss: 0.0747
Epoch 5 [37/172] - loss: 0.0782
Epoch 5 [38/172] - loss: 0.0768
Epoch 5 [39/172] - loss: 0.1034
Epoch 5 [40/172] - loss: 0.0811, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1207
Epoch 5 [42/172] - loss: 0.0767
Epoch 5 [43/172] - loss: 0.1365
Epoch 5 [44/172] - loss: 0.0947
Epoch 5 [45/172] - loss: 0.0779
Epoch 5 [46/172] - loss: 0.1013
Epoch 5 [47/172] - loss: 0.0793
Epoch 5 [48/172] - loss: 0.1135
Epoch 5 [49/172] - loss: 0.1036
Epoch 5 [50/172] - loss: 0.1018, acc: 0.9688
Epoch 5 [51/172] - loss: 0.0897
Epoch 5 [52/172] - loss: 0.0835
Epoch 5 [53/172] - loss: 0.0914
Epoch 5 [54/172] - loss: 0.0777
Epoch 5 [55/172] - loss: 0.1471
Epoch 5 [56/172] - loss: 0.0832
Epoch 5 [57/172] - loss: 0.0822
Epoch 5 [58/172] - loss: 0.0761
Epoch 5 [59/172] - loss: 0.1157
Epoch 5 [60/172] - loss: 0.0846, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0788
Epoch 5 [62/172] - loss: 0.0923
Epoch 5 [63/172] - loss: 0.1096
Epoch 5 [64/172] - loss: 0.0811
Epoch 5 [65/172] - loss: 0.0828
Epoch 5 [66/172] - loss: 0.0851
Epoch 5 [67/172] - loss: 0.0753
Epoch 5 [68/172] - loss: 0.0914
Epoch 5 [69/172] - loss: 0.0894
Epoch 5 [70/172] - loss: 0.0828, acc: 1.0000
Epoch 5 [71/172] - loss: 0.0855
Epoch 5 [72/172] - loss: 0.0771
Epoch 5 [73/172] - loss: 0.0814
Epoch 5 [74/172] - loss: 0.2022
Epoch 5 [75/172] - loss: 0.0790
Epoch 5 [76/172] - loss: 0.1316
Epoch 5 [77/172] - loss: 0.0873
Epoch 5 [78/172] - loss: 0.0800
Epoch 5 [79/172] - loss: 0.0823
Epoch 5 [80/172] - loss: 0.0971, acc: 0.9688
Epoch 5 [81/172] - loss: 0.1103
Epoch 5 [82/172] - loss: 0.1092
Epoch 5 [83/172] - loss: 0.1423
Epoch 5 [84/172] - loss: 0.0778
Epoch 5 [85/172] - loss: 0.1848
Epoch 5 [86/172] - loss: 0.0807
Epoch 5 [87/172] - loss: 0.1114
Epoch 5 [88/172] - loss: 0.1083
Epoch 5 [89/172] - loss: 0.0762
Epoch 5 [90/172] - loss: 0.1336, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0762
Epoch 5 [92/172] - loss: 0.0791
Epoch 5 [93/172] - loss: 0.0883
Epoch 5 [94/172] - loss: 0.0746
Epoch 5 [95/172] - loss: 0.0786
Epoch 5 [96/172] - loss: 0.1030
Epoch 5 [97/172] - loss: 0.0862
Epoch 5 [98/172] - loss: 0.0747
Epoch 5 [99/172] - loss: 0.1525
Epoch 5 [100/172] - loss: 0.0949, acc: 0.9688
Epoch 5 [101/172] - loss: 0.0828
Epoch 5 [102/172] - loss: 0.0786
Epoch 5 [103/172] - loss: 0.0807
Epoch 5 [104/172] - loss: 0.1041
Epoch 5 [105/172] - loss: 0.2683
Epoch 5 [106/172] - loss: 0.0751
Epoch 5 [107/172] - loss: 0.0834
Epoch 5 [108/172] - loss: 0.1177
Epoch 5 [109/172] - loss: 0.0739
Epoch 5 [110/172] - loss: 0.0768, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0786
Epoch 5 [112/172] - loss: 0.0809

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2167, log_difficulty=0.1962, weight=1.9809
neutral: count=7825.0, difficulty=0.1621, log_difficulty=0.1502, weight=1.7510
negative: count=8780.0, difficulty=0.2096, log_difficulty=0.1903, weight=1.9513

当前batch的pt分布：
positive: min=0.0481, max=0.9937, mean=0.8650
neutral: min=0.8821, max=0.9945, mean=0.9648
negative: min=0.9924, max=0.9980, mean=0.9959

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1493
焦点损失: 0.0869
边界损失: 0.1628
总损失: 0.1674
Epoch 5 [113/172] - loss: 0.1674
Epoch 5 [114/172] - loss: 0.1164
Epoch 5 [115/172] - loss: 0.0978
Epoch 5 [116/172] - loss: 0.0770
Epoch 5 [117/172] - loss: 0.0788
Epoch 5 [118/172] - loss: 0.0850
Epoch 5 [119/172] - loss: 0.0781
Epoch 5 [120/172] - loss: 0.0792, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0863
Epoch 5 [122/172] - loss: 0.0843
Epoch 5 [123/172] - loss: 0.1119
Epoch 5 [124/172] - loss: 0.0767
Epoch 5 [125/172] - loss: 0.0790
Epoch 5 [126/172] - loss: 0.0776
Epoch 5 [127/172] - loss: 0.0790
Epoch 5 [128/172] - loss: 0.0751
Epoch 5 [129/172] - loss: 0.1535
Epoch 5 [130/172] - loss: 0.1120, acc: 0.9688
Epoch 5 [131/172] - loss: 0.0800
Epoch 5 [132/172] - loss: 0.1038
Epoch 5 [133/172] - loss: 0.1361
Epoch 5 [134/172] - loss: 0.1966
Epoch 5 [135/172] - loss: 0.0978
Epoch 5 [136/172] - loss: 0.0757
Epoch 5 [137/172] - loss: 0.0978
Epoch 5 [138/172] - loss: 0.1442
Epoch 5 [139/172] - loss: 0.3278
Epoch 5 [140/172] - loss: 0.1564, acc: 0.9062
Epoch 5 [141/172] - loss: 0.0781
Epoch 5 [142/172] - loss: 0.0852
Epoch 5 [143/172] - loss: 0.0735
Epoch 5 [144/172] - loss: 0.0780
Epoch 5 [145/172] - loss: 0.0877
Epoch 5 [146/172] - loss: 0.0833
Epoch 5 [147/172] - loss: 0.0866
Epoch 5 [148/172] - loss: 0.0760
Epoch 5 [149/172] - loss: 0.0746
Epoch 5 [150/172] - loss: 0.1066, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0846
Epoch 5 [152/172] - loss: 0.0807
Epoch 5 [153/172] - loss: 0.0786
Epoch 5 [154/172] - loss: 0.1242
Epoch 5 [155/172] - loss: 0.1024
Epoch 5 [156/172] - loss: 0.0916
Epoch 5 [157/172] - loss: 0.0789
Epoch 5 [158/172] - loss: 0.0756
Epoch 5 [159/172] - loss: 0.0798
Epoch 5 [160/172] - loss: 0.0860, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0972
Epoch 5 [162/172] - loss: 0.0851
Epoch 5 [163/172] - loss: 0.1567
Epoch 5 [164/172] - loss: 0.0802
Epoch 5 [165/172] - loss: 0.1075
Epoch 5 [166/172] - loss: 0.0941
Epoch 5 [167/172] - loss: 0.1128
Epoch 5 [168/172] - loss: 0.0873
Epoch 5 [169/172] - loss: 0.0790
Epoch 5 [170/172] - loss: 0.0787, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1368
Epoch 5 [172/172] - loss: 0.1120

类别准确率:
positive: 0.8865 (414/467)
neutral: 0.2289 (19/83)
negative: 0.5920 (148/250)

Epoch 5/10
Train Loss: 0.0967, Train Acc: 0.9838
Val Loss: 0.8609, Val Acc: 0.7262
Epoch 6 [1/172] - loss: 0.1163, acc: 0.9688
Epoch 6 [2/172] - loss: 0.0938
Epoch 6 [3/172] - loss: 0.0960
Epoch 6 [4/172] - loss: 0.0832
Epoch 6 [5/172] - loss: 0.1853
Epoch 6 [6/172] - loss: 0.0787
Epoch 6 [7/172] - loss: 0.1023
Epoch 6 [8/172] - loss: 0.1146
Epoch 6 [9/172] - loss: 0.0770
Epoch 6 [10/172] - loss: 0.0752, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0830
Epoch 6 [12/172] - loss: 0.0744
Epoch 6 [13/172] - loss: 0.1137
Epoch 6 [14/172] - loss: 0.0946
Epoch 6 [15/172] - loss: 0.0848
Epoch 6 [16/172] - loss: 0.1350
Epoch 6 [17/172] - loss: 0.0816
Epoch 6 [18/172] - loss: 0.0897
Epoch 6 [19/172] - loss: 0.1170
Epoch 6 [20/172] - loss: 0.0815, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0800
Epoch 6 [22/172] - loss: 0.0810
Epoch 6 [23/172] - loss: 0.1056
Epoch 6 [24/172] - loss: 0.0834
Epoch 6 [25/172] - loss: 0.1074
Epoch 6 [26/172] - loss: 0.0796
Epoch 6 [27/172] - loss: 0.0833
Epoch 6 [28/172] - loss: 0.1192
Epoch 6 [29/172] - loss: 0.0771
Epoch 6 [30/172] - loss: 0.0730, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0741
Epoch 6 [32/172] - loss: 0.0810
Epoch 6 [33/172] - loss: 0.0778
Epoch 6 [34/172] - loss: 0.0759
Epoch 6 [35/172] - loss: 0.0775
Epoch 6 [36/172] - loss: 0.0866
Epoch 6 [37/172] - loss: 0.0763
Epoch 6 [38/172] - loss: 0.1107
Epoch 6 [39/172] - loss: 0.0788
Epoch 6 [40/172] - loss: 0.1044, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1993, log_difficulty=0.1817, weight=1.9085
neutral: count=8815.0, difficulty=0.1496, log_difficulty=0.1394, weight=1.6972
negative: count=9870.0, difficulty=0.1929, log_difficulty=0.1764, weight=1.8820

当前batch的pt分布：
positive: min=0.0601, max=0.9964, mean=0.8998
neutral: min=0.9487, max=0.9957, mean=0.9847
negative: min=0.7123, max=0.9964, mean=0.9379

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1214
焦点损失: 0.0784
边界损失: 0.1521
总损失: 0.1509
Epoch 6 [41/172] - loss: 0.1509
Epoch 6 [42/172] - loss: 0.0860
Epoch 6 [43/172] - loss: 0.1180
Epoch 6 [44/172] - loss: 0.0725
Epoch 6 [45/172] - loss: 0.0832
Epoch 6 [46/172] - loss: 0.1005
Epoch 6 [47/172] - loss: 0.0981
Epoch 6 [48/172] - loss: 0.0731
Epoch 6 [49/172] - loss: 0.0789
Epoch 6 [50/172] - loss: 0.0956, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0813
Epoch 6 [52/172] - loss: 0.0877
Epoch 6 [53/172] - loss: 0.0768
Epoch 6 [54/172] - loss: 0.1807
Epoch 6 [55/172] - loss: 0.0821
Epoch 6 [56/172] - loss: 0.0773
Epoch 6 [57/172] - loss: 0.0767
Epoch 6 [58/172] - loss: 0.0746
Epoch 6 [59/172] - loss: 0.0799
Epoch 6 [60/172] - loss: 0.0907, acc: 1.0000
Epoch 6 [61/172] - loss: 0.0788
Epoch 6 [62/172] - loss: 0.0889
Epoch 6 [63/172] - loss: 0.0844
Epoch 6 [64/172] - loss: 0.1737
Epoch 6 [65/172] - loss: 0.0770
Epoch 6 [66/172] - loss: 0.0765
Epoch 6 [67/172] - loss: 0.0739
Epoch 6 [68/172] - loss: 0.1579
Epoch 6 [69/172] - loss: 0.1137
Epoch 6 [70/172] - loss: 0.0796, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0791
Epoch 6 [72/172] - loss: 0.1102
Epoch 6 [73/172] - loss: 0.0979
Epoch 6 [74/172] - loss: 0.0743
Epoch 6 [75/172] - loss: 0.0844
Epoch 6 [76/172] - loss: 0.0739
Epoch 6 [77/172] - loss: 0.0962
Epoch 6 [78/172] - loss: 0.0959
Epoch 6 [79/172] - loss: 0.0732
Epoch 6 [80/172] - loss: 0.1126, acc: 0.9688
Epoch 6 [81/172] - loss: 0.0909
Epoch 6 [82/172] - loss: 0.0748
Epoch 6 [83/172] - loss: 0.0746
Epoch 6 [84/172] - loss: 0.0804
Epoch 6 [85/172] - loss: 0.0998
Epoch 6 [86/172] - loss: 0.1070
Epoch 6 [87/172] - loss: 0.0775
Epoch 6 [88/172] - loss: 0.1056
Epoch 6 [89/172] - loss: 0.0750
Epoch 6 [90/172] - loss: 0.0782, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0743
Epoch 6 [92/172] - loss: 0.0775
Epoch 6 [93/172] - loss: 0.0747
Epoch 6 [94/172] - loss: 0.1103
Epoch 6 [95/172] - loss: 0.0765
Epoch 6 [96/172] - loss: 0.0716
Epoch 6 [97/172] - loss: 0.0784
Epoch 6 [98/172] - loss: 0.0889
Epoch 6 [99/172] - loss: 0.0738
Epoch 6 [100/172] - loss: 0.0734, acc: 1.0000
Epoch 6 [101/172] - loss: 0.0969
Epoch 6 [102/172] - loss: 0.0825
Epoch 6 [103/172] - loss: 0.0747
Epoch 6 [104/172] - loss: 0.1132
Epoch 6 [105/172] - loss: 0.0793
Epoch 6 [106/172] - loss: 0.0796
Epoch 6 [107/172] - loss: 0.0776
Epoch 6 [108/172] - loss: 0.0752
Epoch 6 [109/172] - loss: 0.1401
Epoch 6 [110/172] - loss: 0.0758, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0794
Epoch 6 [112/172] - loss: 0.0753
Epoch 6 [113/172] - loss: 0.0780
Epoch 6 [114/172] - loss: 0.0726
Epoch 6 [115/172] - loss: 0.0790
Epoch 6 [116/172] - loss: 0.2325
Epoch 6 [117/172] - loss: 0.0759
Epoch 6 [118/172] - loss: 0.0723
Epoch 6 [119/172] - loss: 0.1886
Epoch 6 [120/172] - loss: 0.0738, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0989
Epoch 6 [122/172] - loss: 0.1135
Epoch 6 [123/172] - loss: 0.0788
Epoch 6 [124/172] - loss: 0.0722
Epoch 6 [125/172] - loss: 0.0773
Epoch 6 [126/172] - loss: 0.0990
Epoch 6 [127/172] - loss: 0.1349
Epoch 6 [128/172] - loss: 0.1674
Epoch 6 [129/172] - loss: 0.0740
Epoch 6 [130/172] - loss: 0.1040, acc: 0.9688
Epoch 6 [131/172] - loss: 0.0842
Epoch 6 [132/172] - loss: 0.0824
Epoch 6 [133/172] - loss: 0.0769
Epoch 6 [134/172] - loss: 0.0780
Epoch 6 [135/172] - loss: 0.0884
Epoch 6 [136/172] - loss: 0.0772
Epoch 6 [137/172] - loss: 0.0791
Epoch 6 [138/172] - loss: 0.0961
Epoch 6 [139/172] - loss: 0.1009
Epoch 6 [140/172] - loss: 0.0866, acc: 0.9688

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1841, log_difficulty=0.1690, weight=1.8450
neutral: count=9796.0, difficulty=0.1382, log_difficulty=0.1295, weight=1.6473
negative: count=10972.0, difficulty=0.1789, log_difficulty=0.1646, weight=1.8230

当前batch的pt分布：
positive: min=0.9332, max=0.9996, mean=0.9860
neutral: min=0.9204, max=0.9975, mean=0.9807
negative: min=0.8159, max=0.9949, mean=0.9635

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0257
焦点损失: 0.0003
边界损失: 0.1473
总损失: 0.0739
Epoch 6 [141/172] - loss: 0.0739
Epoch 6 [142/172] - loss: 0.0773
Epoch 6 [143/172] - loss: 0.0846
Epoch 6 [144/172] - loss: 0.0760
Epoch 6 [145/172] - loss: 0.0741
Epoch 6 [146/172] - loss: 0.0753
Epoch 6 [147/172] - loss: 0.0788
Epoch 6 [148/172] - loss: 0.1123
Epoch 6 [149/172] - loss: 0.0752
Epoch 6 [150/172] - loss: 0.0744, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0933
Epoch 6 [152/172] - loss: 0.0928
Epoch 6 [153/172] - loss: 0.0827
Epoch 6 [154/172] - loss: 0.0747
Epoch 6 [155/172] - loss: 0.1277
Epoch 6 [156/172] - loss: 0.1890
Epoch 6 [157/172] - loss: 0.0768
Epoch 6 [158/172] - loss: 0.1451
Epoch 6 [159/172] - loss: 0.1434
Epoch 6 [160/172] - loss: 0.1146, acc: 0.9688
Epoch 6 [161/172] - loss: 0.0812
Epoch 6 [162/172] - loss: 0.0795
Epoch 6 [163/172] - loss: 0.0828
Epoch 6 [164/172] - loss: 0.1070
Epoch 6 [165/172] - loss: 0.3999
Epoch 6 [166/172] - loss: 0.0995
Epoch 6 [167/172] - loss: 0.0821
Epoch 6 [168/172] - loss: 0.1047
Epoch 6 [169/172] - loss: 0.1456
Epoch 6 [170/172] - loss: 0.0804, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1007
Epoch 6 [172/172] - loss: 0.1437

类别准确率:
positive: 0.8030 (375/467)
neutral: 0.3373 (28/83)
negative: 0.6560 (164/250)

Epoch 6/10
Train Loss: 0.1242, Train Acc: 0.9677
Val Loss: 0.8004, Val Acc: 0.7087
Epoch 7 [1/172] - loss: 0.0846, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0764
Epoch 7 [3/172] - loss: 0.0860
Epoch 7 [4/172] - loss: 0.0985
Epoch 7 [5/172] - loss: 0.0787
Epoch 7 [6/172] - loss: 0.0812
Epoch 7 [7/172] - loss: 0.0788
Epoch 7 [8/172] - loss: 0.0865
Epoch 7 [9/172] - loss: 0.0750
Epoch 7 [10/172] - loss: 0.0737, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0868
Epoch 7 [12/172] - loss: 0.1211
Epoch 7 [13/172] - loss: 0.0921
Epoch 7 [14/172] - loss: 0.0827
Epoch 7 [15/172] - loss: 0.0937
Epoch 7 [16/172] - loss: 0.0778
Epoch 7 [17/172] - loss: 0.0877
Epoch 7 [18/172] - loss: 0.0787
Epoch 7 [19/172] - loss: 0.0783
Epoch 7 [20/172] - loss: 0.0787, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0970
Epoch 7 [22/172] - loss: 0.0890
Epoch 7 [23/172] - loss: 0.0736
Epoch 7 [24/172] - loss: 0.1023
Epoch 7 [25/172] - loss: 0.0920
Epoch 7 [26/172] - loss: 0.0935
Epoch 7 [27/172] - loss: 0.0806
Epoch 7 [28/172] - loss: 0.0921
Epoch 7 [29/172] - loss: 0.0855
Epoch 7 [30/172] - loss: 0.1068, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0788
Epoch 7 [32/172] - loss: 0.0753
Epoch 7 [33/172] - loss: 0.0885
Epoch 7 [34/172] - loss: 0.0830
Epoch 7 [35/172] - loss: 0.0739
Epoch 7 [36/172] - loss: 0.1409
Epoch 7 [37/172] - loss: 0.0782
Epoch 7 [38/172] - loss: 0.0738
Epoch 7 [39/172] - loss: 0.0766
Epoch 7 [40/172] - loss: 0.0754, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0767
Epoch 7 [42/172] - loss: 0.0776
Epoch 7 [43/172] - loss: 0.0800
Epoch 7 [44/172] - loss: 0.0957
Epoch 7 [45/172] - loss: 0.0843
Epoch 7 [46/172] - loss: 0.1172
Epoch 7 [47/172] - loss: 0.1891
Epoch 7 [48/172] - loss: 0.0808
Epoch 7 [49/172] - loss: 0.0779
Epoch 7 [50/172] - loss: 0.0773, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1117
Epoch 7 [52/172] - loss: 0.0755
Epoch 7 [53/172] - loss: 0.0746
Epoch 7 [54/172] - loss: 0.0807
Epoch 7 [55/172] - loss: 0.0826
Epoch 7 [56/172] - loss: 0.0761
Epoch 7 [57/172] - loss: 0.2108
Epoch 7 [58/172] - loss: 0.0835
Epoch 7 [59/172] - loss: 0.0725
Epoch 7 [60/172] - loss: 0.0917, acc: 0.9688
Epoch 7 [61/172] - loss: 0.0837
Epoch 7 [62/172] - loss: 0.0898
Epoch 7 [63/172] - loss: 0.1283
Epoch 7 [64/172] - loss: 0.0769
Epoch 7 [65/172] - loss: 0.1050
Epoch 7 [66/172] - loss: 0.0959
Epoch 7 [67/172] - loss: 0.0787
Epoch 7 [68/172] - loss: 0.1035

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1731, log_difficulty=0.1597, weight=1.7984
neutral: count=10756.0, difficulty=0.1285, log_difficulty=0.1209, weight=1.6043
negative: count=12072.0, difficulty=0.1680, log_difficulty=0.1553, weight=1.7767

当前batch的pt分布：
positive: min=0.9554, max=0.9984, mean=0.9811
neutral: min=0.9744, max=0.9968, mean=0.9918
negative: min=0.8929, max=0.9883, mean=0.9564

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0278
焦点损失: 0.0001
边界损失: 0.1482
总损失: 0.0742
Epoch 7 [69/172] - loss: 0.0742
Epoch 7 [70/172] - loss: 0.1012, acc: 0.9688
Epoch 7 [71/172] - loss: 0.0769
Epoch 7 [72/172] - loss: 0.0881
Epoch 7 [73/172] - loss: 0.0965
Epoch 7 [74/172] - loss: 0.0751
Epoch 7 [75/172] - loss: 0.0729
Epoch 7 [76/172] - loss: 0.0782
Epoch 7 [77/172] - loss: 0.0802
Epoch 7 [78/172] - loss: 0.0861
Epoch 7 [79/172] - loss: 0.0887
Epoch 7 [80/172] - loss: 0.1141, acc: 0.9688
Epoch 7 [81/172] - loss: 0.0745
Epoch 7 [82/172] - loss: 0.0765
Epoch 7 [83/172] - loss: 0.0937
Epoch 7 [84/172] - loss: 0.0736
Epoch 7 [85/172] - loss: 0.0770
Epoch 7 [86/172] - loss: 0.0745
Epoch 7 [87/172] - loss: 0.0837
Epoch 7 [88/172] - loss: 0.0727
Epoch 7 [89/172] - loss: 0.0741
Epoch 7 [90/172] - loss: 0.0786, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0765
Epoch 7 [92/172] - loss: 0.0777
Epoch 7 [93/172] - loss: 0.0895
Epoch 7 [94/172] - loss: 0.0747
Epoch 7 [95/172] - loss: 0.0757
Epoch 7 [96/172] - loss: 0.0837
Epoch 7 [97/172] - loss: 0.0889
Epoch 7 [98/172] - loss: 0.0989
Epoch 7 [99/172] - loss: 0.0749
Epoch 7 [100/172] - loss: 0.0755, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0730
Epoch 7 [102/172] - loss: 0.0759
Epoch 7 [103/172] - loss: 0.0735
Epoch 7 [104/172] - loss: 0.0755
Epoch 7 [105/172] - loss: 0.0835
Epoch 7 [106/172] - loss: 0.0912
Epoch 7 [107/172] - loss: 0.0737
Epoch 7 [108/172] - loss: 0.0735
Epoch 7 [109/172] - loss: 0.1411
Epoch 7 [110/172] - loss: 0.0963, acc: 0.9688
Epoch 7 [111/172] - loss: 0.0756
Epoch 7 [112/172] - loss: 0.1894
Epoch 7 [113/172] - loss: 0.0823
Epoch 7 [114/172] - loss: 0.0823
Epoch 7 [115/172] - loss: 0.0732
Epoch 7 [116/172] - loss: 0.1260
Epoch 7 [117/172] - loss: 0.0802
Epoch 7 [118/172] - loss: 0.0824
Epoch 7 [119/172] - loss: 0.0844
Epoch 7 [120/172] - loss: 0.0822, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0859
Epoch 7 [122/172] - loss: 0.0774
Epoch 7 [123/172] - loss: 0.0745
Epoch 7 [124/172] - loss: 0.0834
Epoch 7 [125/172] - loss: 0.0727
Epoch 7 [126/172] - loss: 0.0769
Epoch 7 [127/172] - loss: 0.0793
Epoch 7 [128/172] - loss: 0.0762
Epoch 7 [129/172] - loss: 0.0773
Epoch 7 [130/172] - loss: 0.0746, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1053
Epoch 7 [132/172] - loss: 0.1535
Epoch 7 [133/172] - loss: 0.0757
Epoch 7 [134/172] - loss: 0.0848
Epoch 7 [135/172] - loss: 0.0762
Epoch 7 [136/172] - loss: 0.0748
Epoch 7 [137/172] - loss: 0.0855
Epoch 7 [138/172] - loss: 0.0729
Epoch 7 [139/172] - loss: 0.1161
Epoch 7 [140/172] - loss: 0.0811, acc: 1.0000
Epoch 7 [141/172] - loss: 0.1339
Epoch 7 [142/172] - loss: 0.0810
Epoch 7 [143/172] - loss: 0.0812
Epoch 7 [144/172] - loss: 0.0764
Epoch 7 [145/172] - loss: 0.0820
Epoch 7 [146/172] - loss: 0.0897
Epoch 7 [147/172] - loss: 0.0845
Epoch 7 [148/172] - loss: 0.0824
Epoch 7 [149/172] - loss: 0.0789
Epoch 7 [150/172] - loss: 0.0740, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1081
Epoch 7 [152/172] - loss: 0.0835
Epoch 7 [153/172] - loss: 0.0715
Epoch 7 [154/172] - loss: 0.0899
Epoch 7 [155/172] - loss: 0.0732
Epoch 7 [156/172] - loss: 0.0900
Epoch 7 [157/172] - loss: 0.0781
Epoch 7 [158/172] - loss: 0.0776
Epoch 7 [159/172] - loss: 0.0725
Epoch 7 [160/172] - loss: 0.0857, acc: 0.9688
Epoch 7 [161/172] - loss: 0.0788
Epoch 7 [162/172] - loss: 0.0779
Epoch 7 [163/172] - loss: 0.0747
Epoch 7 [164/172] - loss: 0.0944
Epoch 7 [165/172] - loss: 0.0925
Epoch 7 [166/172] - loss: 0.0755
Epoch 7 [167/172] - loss: 0.0918
Epoch 7 [168/172] - loss: 0.0747

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1624, log_difficulty=0.1505, weight=1.7523
neutral: count=11731.0, difficulty=0.1204, log_difficulty=0.1137, weight=1.5683
negative: count=13173.0, difficulty=0.1578, log_difficulty=0.1465, weight=1.7326

当前batch的pt分布：
positive: min=0.9522, max=0.9980, mean=0.9804
neutral: min=0.9795, max=0.9983, mean=0.9918
negative: min=0.8997, max=0.9961, mean=0.9716

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0201
焦点损失: 0.0001
边界损失: 0.1446
总损失: 0.0724
Epoch 7 [169/172] - loss: 0.0724
Epoch 7 [170/172] - loss: 0.0797, acc: 1.0000
Epoch 7 [171/172] - loss: 0.0742
Epoch 7 [172/172] - loss: 0.0722

类别准确率:
positive: 0.8887 (415/467)
neutral: 0.2289 (19/83)
negative: 0.5920 (148/250)

Epoch 7/10
Train Loss: 0.0795, Train Acc: 0.9919
Val Loss: 0.9216, Val Acc: 0.7275
Early stopping triggered!
Best validation accuracy: 0.7275

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_070455-7xheb0qp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.15_Multimodal_iterations_20250118_070453
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/7xheb0qp
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▇▇▇▇▇▇▇██
wandb:  train_acc ▁▁▄▃▄▅▇▆▇▆▆▇██▇███▇▇████████████████████
wandb: train_loss ██▇▅▅▅▄▃▂▂▁▂▂▂▁▂▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 1
wandb: train_loss 0.07972
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.15_Multimodal_iterations_20250118_070453 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/7xheb0qp
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_070455-7xheb0qp/logs
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_071532-888ea9w7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.15_Multimodal_epochs_20250118_071532
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/888ea9w7
wandb: uploading history steps 0-0, summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▅▆██▇█
wandb: train_loss █▅▂▂▁▂▁
wandb:    val_acc ▆▁███▆█
wandb:   val_loss ▁▆▃▅▆▄█
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.99192
wandb: train_loss 0.07955
wandb:    val_acc 0.7275
wandb:   val_loss 0.9216
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight0.5_dropout0.15_Multimodal_epochs_20250118_071532 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/888ea9w7
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_071532-888ea9w7/logs

