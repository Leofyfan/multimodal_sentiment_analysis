=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 1.5 --dropout 0.25 --name loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.25 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.25
text_dim: 128
image_dim: 256
dropout: 0.25
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6945, log_difficulty=0.5274, weight=3.6369
neutral: count=7.0, difficulty=0.7070, log_difficulty=0.5347, weight=3.6736
negative: count=13.0, difficulty=0.6762, log_difficulty=0.5165, weight=3.5826

当前batch的pt分布：
positive: min=0.1736, max=0.5010, mean=0.3055
neutral: min=0.1555, max=0.3772, mean=0.2930
negative: min=0.2315, max=0.4146, mean=0.3238

当前batch准确率：
整体准确率: 0.1875
positive 准确率: 0.1667
neutral 准确率: 0.1429
negative 准确率: 0.2308

损失分量：
基础交叉熵: 1.2084
焦点损失: 0.4366
边界损失: 0.7742
总损失: 1.1789
Epoch 1 [1/172] - loss: 1.1789, acc: 0.1875
Epoch 1 [2/172] - loss: 1.0797
Epoch 1 [3/172] - loss: 1.0216
Epoch 1 [4/172] - loss: 1.0665
Epoch 1 [5/172] - loss: 0.9973
Epoch 1 [6/172] - loss: 1.3813
Epoch 1 [7/172] - loss: 1.0779
Epoch 1 [8/172] - loss: 0.9884
Epoch 1 [9/172] - loss: 0.9800
Epoch 1 [10/172] - loss: 1.0333, acc: 0.3125
Epoch 1 [11/172] - loss: 1.1074
Epoch 1 [12/172] - loss: 0.9295
Epoch 1 [13/172] - loss: 0.8290
Epoch 1 [14/172] - loss: 1.1231
Epoch 1 [15/172] - loss: 1.0661
Epoch 1 [16/172] - loss: 0.9975
Epoch 1 [17/172] - loss: 0.8991
Epoch 1 [18/172] - loss: 1.0150
Epoch 1 [19/172] - loss: 0.8818
Epoch 1 [20/172] - loss: 0.9282, acc: 0.5312
Epoch 1 [21/172] - loss: 0.8581
Epoch 1 [22/172] - loss: 0.9146
Epoch 1 [23/172] - loss: 1.2244
Epoch 1 [24/172] - loss: 0.8281
Epoch 1 [25/172] - loss: 0.8452
Epoch 1 [26/172] - loss: 0.9081
Epoch 1 [27/172] - loss: 1.1902
Epoch 1 [28/172] - loss: 0.7975
Epoch 1 [29/172] - loss: 1.0081
Epoch 1 [30/172] - loss: 0.7201, acc: 0.5625
Epoch 1 [31/172] - loss: 0.8589
Epoch 1 [32/172] - loss: 0.9473
Epoch 1 [33/172] - loss: 0.8758
Epoch 1 [34/172] - loss: 0.7580
Epoch 1 [35/172] - loss: 0.9259
Epoch 1 [36/172] - loss: 0.6949
Epoch 1 [37/172] - loss: 0.7607
Epoch 1 [38/172] - loss: 1.0068
Epoch 1 [39/172] - loss: 0.5879
Epoch 1 [40/172] - loss: 0.9375, acc: 0.4688
Epoch 1 [41/172] - loss: 1.0021
Epoch 1 [42/172] - loss: 0.7618
Epoch 1 [43/172] - loss: 0.7856
Epoch 1 [44/172] - loss: 0.9918
Epoch 1 [45/172] - loss: 1.0366
Epoch 1 [46/172] - loss: 0.8886
Epoch 1 [47/172] - loss: 0.7298
Epoch 1 [48/172] - loss: 0.9111
Epoch 1 [49/172] - loss: 0.8483
Epoch 1 [50/172] - loss: 0.6009, acc: 0.7188
Epoch 1 [51/172] - loss: 0.9178
Epoch 1 [52/172] - loss: 0.7241
Epoch 1 [53/172] - loss: 0.6721
Epoch 1 [54/172] - loss: 1.0711
Epoch 1 [55/172] - loss: 0.6659
Epoch 1 [56/172] - loss: 0.7830
Epoch 1 [57/172] - loss: 0.9578
Epoch 1 [58/172] - loss: 0.7427
Epoch 1 [59/172] - loss: 0.9126
Epoch 1 [60/172] - loss: 0.5169, acc: 0.7500
Epoch 1 [61/172] - loss: 0.6550
Epoch 1 [62/172] - loss: 0.5931
Epoch 1 [63/172] - loss: 0.5967
Epoch 1 [64/172] - loss: 0.5206
Epoch 1 [65/172] - loss: 0.8012
Epoch 1 [66/172] - loss: 0.8874
Epoch 1 [67/172] - loss: 0.8443
Epoch 1 [68/172] - loss: 0.8309
Epoch 1 [69/172] - loss: 0.9119
Epoch 1 [70/172] - loss: 0.7952, acc: 0.5625
Epoch 1 [71/172] - loss: 0.5876
Epoch 1 [72/172] - loss: 0.6910
Epoch 1 [73/172] - loss: 0.7150
Epoch 1 [74/172] - loss: 0.6661
Epoch 1 [75/172] - loss: 0.4222
Epoch 1 [76/172] - loss: 0.5065
Epoch 1 [77/172] - loss: 0.7041
Epoch 1 [78/172] - loss: 0.7542
Epoch 1 [79/172] - loss: 0.6942
Epoch 1 [80/172] - loss: 0.4920, acc: 0.7188
Epoch 1 [81/172] - loss: 0.8070
Epoch 1 [82/172] - loss: 0.8449
Epoch 1 [83/172] - loss: 0.7132
Epoch 1 [84/172] - loss: 0.5947
Epoch 1 [85/172] - loss: 0.5289
Epoch 1 [86/172] - loss: 0.7441
Epoch 1 [87/172] - loss: 0.4585
Epoch 1 [88/172] - loss: 0.9405
Epoch 1 [89/172] - loss: 1.0528
Epoch 1 [90/172] - loss: 0.5389, acc: 0.7188
Epoch 1 [91/172] - loss: 0.5651
Epoch 1 [92/172] - loss: 0.4769
Epoch 1 [93/172] - loss: 0.5843
Epoch 1 [94/172] - loss: 0.3745
Epoch 1 [95/172] - loss: 0.6175
Epoch 1 [96/172] - loss: 0.5304
Epoch 1 [97/172] - loss: 0.6575
Epoch 1 [98/172] - loss: 0.5073
Epoch 1 [99/172] - loss: 0.7372
Epoch 1 [100/172] - loss: 0.6467, acc: 0.7500

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5508, log_difficulty=0.4388, weight=3.1939
neutral: count=983.0, difficulty=0.5294, log_difficulty=0.4249, weight=3.1244
negative: count=1119.0, difficulty=0.5355, log_difficulty=0.4288, weight=3.1442

当前batch的pt分布：
positive: min=0.1412, max=0.9649, mean=0.4571
neutral: min=0.5268, max=0.9679, mean=0.7096
negative: min=0.0863, max=0.7947, mean=0.3868

当前batch准确率：
整体准确率: 0.5312
positive 准确率: 0.5000
neutral 准确率: 1.0000
negative 准确率: 0.4375

损失分量：
基础交叉熵: 0.9321
焦点损失: 0.3579
边界损失: 0.5153
总损失: 0.8236
Epoch 1 [101/172] - loss: 0.8236
Epoch 1 [102/172] - loss: 0.6157
Epoch 1 [103/172] - loss: 0.5187
Epoch 1 [104/172] - loss: 0.4009
Epoch 1 [105/172] - loss: 0.6963
Epoch 1 [106/172] - loss: 0.9179
Epoch 1 [107/172] - loss: 0.4833
Epoch 1 [108/172] - loss: 0.8045
Epoch 1 [109/172] - loss: 0.3369
Epoch 1 [110/172] - loss: 0.7051, acc: 0.6250
Epoch 1 [111/172] - loss: 0.5767
Epoch 1 [112/172] - loss: 0.5283
Epoch 1 [113/172] - loss: 0.2842
Epoch 1 [114/172] - loss: 0.5603
Epoch 1 [115/172] - loss: 0.5096
Epoch 1 [116/172] - loss: 0.5045
Epoch 1 [117/172] - loss: 0.4741
Epoch 1 [118/172] - loss: 0.4048
Epoch 1 [119/172] - loss: 0.6557
Epoch 1 [120/172] - loss: 0.5488, acc: 0.7188
Epoch 1 [121/172] - loss: 0.4888
Epoch 1 [122/172] - loss: 0.5448
Epoch 1 [123/172] - loss: 0.4208
Epoch 1 [124/172] - loss: 0.4887
Epoch 1 [125/172] - loss: 0.6146
Epoch 1 [126/172] - loss: 0.8206
Epoch 1 [127/172] - loss: 0.4226
Epoch 1 [128/172] - loss: 0.4633
Epoch 1 [129/172] - loss: 0.5557
Epoch 1 [130/172] - loss: 0.3954, acc: 0.7812
Epoch 1 [131/172] - loss: 0.2872
Epoch 1 [132/172] - loss: 0.5824
Epoch 1 [133/172] - loss: 0.5062
Epoch 1 [134/172] - loss: 0.5368
Epoch 1 [135/172] - loss: 0.5180
Epoch 1 [136/172] - loss: 0.4264
Epoch 1 [137/172] - loss: 0.5430
Epoch 1 [138/172] - loss: 0.5187
Epoch 1 [139/172] - loss: 0.3031
Epoch 1 [140/172] - loss: 0.4021, acc: 0.9062
Epoch 1 [141/172] - loss: 0.4597
Epoch 1 [142/172] - loss: 0.4411
Epoch 1 [143/172] - loss: 0.5464
Epoch 1 [144/172] - loss: 0.2911
Epoch 1 [145/172] - loss: 0.4998
Epoch 1 [146/172] - loss: 0.6850
Epoch 1 [147/172] - loss: 0.7222
Epoch 1 [148/172] - loss: 0.4828
Epoch 1 [149/172] - loss: 0.3260
Epoch 1 [150/172] - loss: 0.4643, acc: 0.7500
Epoch 1 [151/172] - loss: 0.5713
Epoch 1 [152/172] - loss: 0.4758
Epoch 1 [153/172] - loss: 0.4299
Epoch 1 [154/172] - loss: 0.3403
Epoch 1 [155/172] - loss: 0.4698
Epoch 1 [156/172] - loss: 0.5909
Epoch 1 [157/172] - loss: 0.4701
Epoch 1 [158/172] - loss: 0.4146
Epoch 1 [159/172] - loss: 0.5619
Epoch 1 [160/172] - loss: 0.2266, acc: 0.9688
Epoch 1 [161/172] - loss: 0.3330
Epoch 1 [162/172] - loss: 0.3155
Epoch 1 [163/172] - loss: 0.4332
Epoch 1 [164/172] - loss: 0.6013
Epoch 1 [165/172] - loss: 0.5369
Epoch 1 [166/172] - loss: 0.3739
Epoch 1 [167/172] - loss: 0.3895
Epoch 1 [168/172] - loss: 0.4951
Epoch 1 [169/172] - loss: 0.3026
Epoch 1 [170/172] - loss: 0.4084, acc: 0.8125
Epoch 1 [171/172] - loss: 0.3040
Epoch 1 [172/172] - loss: 0.3932

类别准确率:
positive: 0.6595 (308/467)
neutral: 0.4217 (35/83)
negative: 0.7280 (182/250)

Epoch 1/10
Train Loss: 0.4100, Train Acc: 0.8121
Val Loss: 0.7224, Val Acc: 0.6562
Epoch 2 [1/172] - loss: 0.2966, acc: 0.8750
Epoch 2 [2/172] - loss: 0.3293
Epoch 2 [3/172] - loss: 0.2444
Epoch 2 [4/172] - loss: 0.2930
Epoch 2 [5/172] - loss: 0.5349
Epoch 2 [6/172] - loss: 0.3829
Epoch 2 [7/172] - loss: 0.2860
Epoch 2 [8/172] - loss: 0.2404
Epoch 2 [9/172] - loss: 0.1956
Epoch 2 [10/172] - loss: 0.3585, acc: 0.8438
Epoch 2 [11/172] - loss: 0.3625
Epoch 2 [12/172] - loss: 0.2289
Epoch 2 [13/172] - loss: 0.4768
Epoch 2 [14/172] - loss: 0.2309
Epoch 2 [15/172] - loss: 0.4412
Epoch 2 [16/172] - loss: 0.3317
Epoch 2 [17/172] - loss: 0.3116
Epoch 2 [18/172] - loss: 0.3859
Epoch 2 [19/172] - loss: 0.2094
Epoch 2 [20/172] - loss: 0.2981, acc: 0.8438
Epoch 2 [21/172] - loss: 0.3686
Epoch 2 [22/172] - loss: 0.2256
Epoch 2 [23/172] - loss: 0.1727
Epoch 2 [24/172] - loss: 0.4845
Epoch 2 [25/172] - loss: 0.3668
Epoch 2 [26/172] - loss: 0.2038
Epoch 2 [27/172] - loss: 0.3459
Epoch 2 [28/172] - loss: 0.3201

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4678, log_difficulty=0.3837, weight=2.9187
neutral: count=1952.0, difficulty=0.4106, log_difficulty=0.3440, weight=2.7200
negative: count=2216.0, difficulty=0.4663, log_difficulty=0.3828, weight=2.9138

当前batch的pt分布：
positive: min=0.4846, max=0.9310, mean=0.7576
neutral: min=0.3242, max=0.9627, mean=0.8042
negative: min=0.0665, max=0.9155, mean=0.6786

当前batch准确率：
整体准确率: 0.8438
positive 准确率: 1.0000
neutral 准确率: 0.8182
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.3991
焦点损失: 0.1397
边界损失: 0.2777
总损失: 0.3402
Epoch 2 [29/172] - loss: 0.3402
Epoch 2 [30/172] - loss: 0.2296, acc: 0.9688
Epoch 2 [31/172] - loss: 0.5234
Epoch 2 [32/172] - loss: 0.2800
Epoch 2 [33/172] - loss: 0.2254
Epoch 2 [34/172] - loss: 0.2268
Epoch 2 [35/172] - loss: 0.2449
Epoch 2 [36/172] - loss: 0.6303
Epoch 2 [37/172] - loss: 0.2439
Epoch 2 [38/172] - loss: 0.2777
Epoch 2 [39/172] - loss: 0.3571
Epoch 2 [40/172] - loss: 0.2986, acc: 0.8438
Epoch 2 [41/172] - loss: 0.2964
Epoch 2 [42/172] - loss: 0.1889
Epoch 2 [43/172] - loss: 0.1358
Epoch 2 [44/172] - loss: 0.3982
Epoch 2 [45/172] - loss: 0.2028
Epoch 2 [46/172] - loss: 0.2097
Epoch 2 [47/172] - loss: 0.3520
Epoch 2 [48/172] - loss: 0.2599
Epoch 2 [49/172] - loss: 0.2158
Epoch 2 [50/172] - loss: 0.3784, acc: 0.7188
Epoch 2 [51/172] - loss: 0.3669
Epoch 2 [52/172] - loss: 0.2365
Epoch 2 [53/172] - loss: 0.2167
Epoch 2 [54/172] - loss: 0.2685
Epoch 2 [55/172] - loss: 0.3214
Epoch 2 [56/172] - loss: 0.2330
Epoch 2 [57/172] - loss: 0.2402
Epoch 2 [58/172] - loss: 0.3112
Epoch 2 [59/172] - loss: 0.4256
Epoch 2 [60/172] - loss: 0.3319, acc: 0.8750
Epoch 2 [61/172] - loss: 0.1721
Epoch 2 [62/172] - loss: 0.2514
Epoch 2 [63/172] - loss: 0.2403
Epoch 2 [64/172] - loss: 0.3739
Epoch 2 [65/172] - loss: 0.2260
Epoch 2 [66/172] - loss: 0.2138
Epoch 2 [67/172] - loss: 0.1560
Epoch 2 [68/172] - loss: 0.3315
Epoch 2 [69/172] - loss: 0.2017
Epoch 2 [70/172] - loss: 0.3553, acc: 0.8125
Epoch 2 [71/172] - loss: 0.3157
Epoch 2 [72/172] - loss: 0.3454
Epoch 2 [73/172] - loss: 0.2339
Epoch 2 [74/172] - loss: 0.2044
Epoch 2 [75/172] - loss: 0.2762
Epoch 2 [76/172] - loss: 0.2481
Epoch 2 [77/172] - loss: 0.3000
Epoch 2 [78/172] - loss: 0.3572
Epoch 2 [79/172] - loss: 0.2723
Epoch 2 [80/172] - loss: 0.2332, acc: 0.9375
Epoch 2 [81/172] - loss: 0.1525
Epoch 2 [82/172] - loss: 0.1877
Epoch 2 [83/172] - loss: 0.2293
Epoch 2 [84/172] - loss: 0.3035
Epoch 2 [85/172] - loss: 0.2436
Epoch 2 [86/172] - loss: 0.2404
Epoch 2 [87/172] - loss: 0.6259
Epoch 2 [88/172] - loss: 0.1831
Epoch 2 [89/172] - loss: 0.1893
Epoch 2 [90/172] - loss: 0.2587, acc: 0.8438
Epoch 2 [91/172] - loss: 0.1911
Epoch 2 [92/172] - loss: 0.2577
Epoch 2 [93/172] - loss: 0.2277
Epoch 2 [94/172] - loss: 0.1874
Epoch 2 [95/172] - loss: 0.4088
Epoch 2 [96/172] - loss: 0.1704
Epoch 2 [97/172] - loss: 0.3395
Epoch 2 [98/172] - loss: 0.1479
Epoch 2 [99/172] - loss: 0.1257
Epoch 2 [100/172] - loss: 0.2158, acc: 0.8438
Epoch 2 [101/172] - loss: 0.2267
Epoch 2 [102/172] - loss: 0.1628
Epoch 2 [103/172] - loss: 0.2436
Epoch 2 [104/172] - loss: 0.2221
Epoch 2 [105/172] - loss: 0.1783
Epoch 2 [106/172] - loss: 0.2043
Epoch 2 [107/172] - loss: 0.2077
Epoch 2 [108/172] - loss: 0.3251
Epoch 2 [109/172] - loss: 0.2340
Epoch 2 [110/172] - loss: 0.2360, acc: 0.9375
Epoch 2 [111/172] - loss: 0.2247
Epoch 2 [112/172] - loss: 0.1373
Epoch 2 [113/172] - loss: 0.1169
Epoch 2 [114/172] - loss: 0.2083
Epoch 2 [115/172] - loss: 0.2209
Epoch 2 [116/172] - loss: 0.2251
Epoch 2 [117/172] - loss: 0.2379
Epoch 2 [118/172] - loss: 0.1560
Epoch 2 [119/172] - loss: 0.2821
Epoch 2 [120/172] - loss: 0.2732, acc: 0.8750
Epoch 2 [121/172] - loss: 0.2349
Epoch 2 [122/172] - loss: 0.3511
Epoch 2 [123/172] - loss: 0.2196
Epoch 2 [124/172] - loss: 0.2057
Epoch 2 [125/172] - loss: 0.1541
Epoch 2 [126/172] - loss: 0.2686
Epoch 2 [127/172] - loss: 0.1860
Epoch 2 [128/172] - loss: 0.2821

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4013, log_difficulty=0.3374, weight=2.6870
neutral: count=2949.0, difficulty=0.3219, log_difficulty=0.2791, weight=2.3953
negative: count=3294.0, difficulty=0.4028, log_difficulty=0.3385, weight=2.6923

当前batch的pt分布：
positive: min=0.3182, max=0.9918, mean=0.7617
neutral: min=0.5119, max=0.9927, mean=0.8626
negative: min=0.1235, max=0.9484, mean=0.7074

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.3274
焦点损失: 0.0978
边界损失: 0.2554
总损失: 0.2585
Epoch 2 [129/172] - loss: 0.2585
Epoch 2 [130/172] - loss: 0.3315, acc: 0.9062
Epoch 2 [131/172] - loss: 0.1523
Epoch 2 [132/172] - loss: 0.2627
Epoch 2 [133/172] - loss: 0.1871
Epoch 2 [134/172] - loss: 0.2069
Epoch 2 [135/172] - loss: 0.3484
Epoch 2 [136/172] - loss: 0.1742
Epoch 2 [137/172] - loss: 0.2115
Epoch 2 [138/172] - loss: 0.2000
Epoch 2 [139/172] - loss: 0.1393
Epoch 2 [140/172] - loss: 0.2638, acc: 0.9062
Epoch 2 [141/172] - loss: 0.2525
Epoch 2 [142/172] - loss: 0.1912
Epoch 2 [143/172] - loss: 0.2677
Epoch 2 [144/172] - loss: 0.1639
Epoch 2 [145/172] - loss: 0.4795
Epoch 2 [146/172] - loss: 0.2028
Epoch 2 [147/172] - loss: 0.2610
Epoch 2 [148/172] - loss: 0.1832
Epoch 2 [149/172] - loss: 0.2477
Epoch 2 [150/172] - loss: 0.2976, acc: 0.9688
Epoch 2 [151/172] - loss: 0.1660
Epoch 2 [152/172] - loss: 0.2035
Epoch 2 [153/172] - loss: 0.1960
Epoch 2 [154/172] - loss: 0.1506
Epoch 2 [155/172] - loss: 0.2623
Epoch 2 [156/172] - loss: 0.1626
Epoch 2 [157/172] - loss: 0.1344
Epoch 2 [158/172] - loss: 0.2310
Epoch 2 [159/172] - loss: 0.2373
Epoch 2 [160/172] - loss: 0.1578, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1860
Epoch 2 [162/172] - loss: 0.2179
Epoch 2 [163/172] - loss: 0.2659
Epoch 2 [164/172] - loss: 0.2130
Epoch 2 [165/172] - loss: 0.2535
Epoch 2 [166/172] - loss: 0.2221
Epoch 2 [167/172] - loss: 0.2380
Epoch 2 [168/172] - loss: 0.1416
Epoch 2 [169/172] - loss: 0.1226
Epoch 2 [170/172] - loss: 0.1853, acc: 0.9375
Epoch 2 [171/172] - loss: 0.3133
Epoch 2 [172/172] - loss: 0.6259

类别准确率:
positive: 0.8908 (416/467)
neutral: 0.2048 (17/83)
negative: 0.5640 (141/250)

Epoch 2/10
Train Loss: 0.2341, Train Acc: 0.9091
Val Loss: 0.7089, Val Acc: 0.7175
Epoch 3 [1/172] - loss: 0.1314, acc: 1.0000
Epoch 3 [2/172] - loss: 0.1458
Epoch 3 [3/172] - loss: 0.0979
Epoch 3 [4/172] - loss: 0.1151
Epoch 3 [5/172] - loss: 0.1863
Epoch 3 [6/172] - loss: 0.1084
Epoch 3 [7/172] - loss: 0.1392
Epoch 3 [8/172] - loss: 0.1783
Epoch 3 [9/172] - loss: 0.1798
Epoch 3 [10/172] - loss: 0.1117, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1388
Epoch 3 [12/172] - loss: 0.1280
Epoch 3 [13/172] - loss: 0.1046
Epoch 3 [14/172] - loss: 0.0941
Epoch 3 [15/172] - loss: 0.1857
Epoch 3 [16/172] - loss: 0.2021
Epoch 3 [17/172] - loss: 0.3578
Epoch 3 [18/172] - loss: 0.2143
Epoch 3 [19/172] - loss: 0.2071
Epoch 3 [20/172] - loss: 0.0952, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1588
Epoch 3 [22/172] - loss: 0.1897
Epoch 3 [23/172] - loss: 0.1091
Epoch 3 [24/172] - loss: 0.1153
Epoch 3 [25/172] - loss: 0.1245
Epoch 3 [26/172] - loss: 0.1796
Epoch 3 [27/172] - loss: 0.1523
Epoch 3 [28/172] - loss: 0.1586
Epoch 3 [29/172] - loss: 0.2715
Epoch 3 [30/172] - loss: 0.2174, acc: 0.8750
Epoch 3 [31/172] - loss: 0.1550
Epoch 3 [32/172] - loss: 0.2830
Epoch 3 [33/172] - loss: 0.1238
Epoch 3 [34/172] - loss: 0.1759
Epoch 3 [35/172] - loss: 0.1314
Epoch 3 [36/172] - loss: 0.1281
Epoch 3 [37/172] - loss: 0.1499
Epoch 3 [38/172] - loss: 0.0960
Epoch 3 [39/172] - loss: 0.1069
Epoch 3 [40/172] - loss: 0.1460, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1284
Epoch 3 [42/172] - loss: 0.2482
Epoch 3 [43/172] - loss: 0.1129
Epoch 3 [44/172] - loss: 0.1070
Epoch 3 [45/172] - loss: 0.1812
Epoch 3 [46/172] - loss: 0.1169
Epoch 3 [47/172] - loss: 0.1177
Epoch 3 [48/172] - loss: 0.1263
Epoch 3 [49/172] - loss: 0.1113
Epoch 3 [50/172] - loss: 0.1468, acc: 0.9375
Epoch 3 [51/172] - loss: 0.2147
Epoch 3 [52/172] - loss: 0.2796
Epoch 3 [53/172] - loss: 0.1252
Epoch 3 [54/172] - loss: 0.1904
Epoch 3 [55/172] - loss: 0.1380
Epoch 3 [56/172] - loss: 0.1521

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3475, log_difficulty=0.2983, weight=2.4913
neutral: count=3923.0, difficulty=0.2728, log_difficulty=0.2412, weight=2.2060
negative: count=4382.0, difficulty=0.3488, log_difficulty=0.2992, weight=2.4960

当前batch的pt分布：
positive: min=0.5116, max=0.9913, mean=0.8554
neutral: min=0.0019, max=0.9765, mean=0.7464
negative: min=0.9680, max=0.9917, mean=0.9803

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.4102
焦点损失: 0.2618
边界损失: 0.2077
总损失: 0.3936
Epoch 3 [57/172] - loss: 0.3936
Epoch 3 [58/172] - loss: 0.1842
Epoch 3 [59/172] - loss: 0.2336
Epoch 3 [60/172] - loss: 0.1463, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1335
Epoch 3 [62/172] - loss: 0.1311
Epoch 3 [63/172] - loss: 0.1146
Epoch 3 [64/172] - loss: 0.1266
Epoch 3 [65/172] - loss: 0.1059
Epoch 3 [66/172] - loss: 0.1951
Epoch 3 [67/172] - loss: 0.1256
Epoch 3 [68/172] - loss: 0.1142
Epoch 3 [69/172] - loss: 0.2228
Epoch 3 [70/172] - loss: 0.1773, acc: 0.9062
Epoch 3 [71/172] - loss: 0.1291
Epoch 3 [72/172] - loss: 0.2211
Epoch 3 [73/172] - loss: 0.1078
Epoch 3 [74/172] - loss: 0.1867
Epoch 3 [75/172] - loss: 0.2064
Epoch 3 [76/172] - loss: 0.1150
Epoch 3 [77/172] - loss: 0.1279
Epoch 3 [78/172] - loss: 0.1428
Epoch 3 [79/172] - loss: 0.1301
Epoch 3 [80/172] - loss: 0.1562, acc: 0.9375
Epoch 3 [81/172] - loss: 0.1561
Epoch 3 [82/172] - loss: 0.1383
Epoch 3 [83/172] - loss: 0.1036
Epoch 3 [84/172] - loss: 0.1308
Epoch 3 [85/172] - loss: 0.1298
Epoch 3 [86/172] - loss: 0.1050
Epoch 3 [87/172] - loss: 0.1464
Epoch 3 [88/172] - loss: 0.1923
Epoch 3 [89/172] - loss: 0.1231
Epoch 3 [90/172] - loss: 0.0930, acc: 1.0000
Epoch 3 [91/172] - loss: 0.2211
Epoch 3 [92/172] - loss: 0.1483
Epoch 3 [93/172] - loss: 0.2493
Epoch 3 [94/172] - loss: 0.1397
Epoch 3 [95/172] - loss: 0.1447
Epoch 3 [96/172] - loss: 0.1685
Epoch 3 [97/172] - loss: 0.1223
Epoch 3 [98/172] - loss: 0.0972
Epoch 3 [99/172] - loss: 0.0999
Epoch 3 [100/172] - loss: 0.2126, acc: 0.9688
Epoch 3 [101/172] - loss: 0.2796
Epoch 3 [102/172] - loss: 0.0878
Epoch 3 [103/172] - loss: 0.1446
Epoch 3 [104/172] - loss: 0.1382
Epoch 3 [105/172] - loss: 0.1301
Epoch 3 [106/172] - loss: 0.1750
Epoch 3 [107/172] - loss: 0.1546
Epoch 3 [108/172] - loss: 0.1140
Epoch 3 [109/172] - loss: 0.1679
Epoch 3 [110/172] - loss: 0.1949, acc: 0.9062
Epoch 3 [111/172] - loss: 0.2089
Epoch 3 [112/172] - loss: 0.0988
Epoch 3 [113/172] - loss: 0.0981
Epoch 3 [114/172] - loss: 0.1212
Epoch 3 [115/172] - loss: 0.1007
Epoch 3 [116/172] - loss: 0.1248
Epoch 3 [117/172] - loss: 0.1771
Epoch 3 [118/172] - loss: 0.1215
Epoch 3 [119/172] - loss: 0.1767
Epoch 3 [120/172] - loss: 0.1582, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1229
Epoch 3 [122/172] - loss: 0.1094
Epoch 3 [123/172] - loss: 0.1810
Epoch 3 [124/172] - loss: 0.2078
Epoch 3 [125/172] - loss: 0.1075
Epoch 3 [126/172] - loss: 0.2890
Epoch 3 [127/172] - loss: 0.1412
Epoch 3 [128/172] - loss: 0.0921
Epoch 3 [129/172] - loss: 0.1216
Epoch 3 [130/172] - loss: 0.1541, acc: 0.9375
Epoch 3 [131/172] - loss: 0.2389
Epoch 3 [132/172] - loss: 0.0904
Epoch 3 [133/172] - loss: 0.1279
Epoch 3 [134/172] - loss: 0.1069
Epoch 3 [135/172] - loss: 0.1078
Epoch 3 [136/172] - loss: 0.1574
Epoch 3 [137/172] - loss: 0.0953
Epoch 3 [138/172] - loss: 0.1367
Epoch 3 [139/172] - loss: 0.1239
Epoch 3 [140/172] - loss: 0.1040, acc: 1.0000
Epoch 3 [141/172] - loss: 0.1619
Epoch 3 [142/172] - loss: 0.1366
Epoch 3 [143/172] - loss: 0.1195
Epoch 3 [144/172] - loss: 0.1494
Epoch 3 [145/172] - loss: 0.1732
Epoch 3 [146/172] - loss: 0.1139
Epoch 3 [147/172] - loss: 0.1164
Epoch 3 [148/172] - loss: 0.1253
Epoch 3 [149/172] - loss: 0.1395
Epoch 3 [150/172] - loss: 0.1314, acc: 0.9688
Epoch 3 [151/172] - loss: 0.2007
Epoch 3 [152/172] - loss: 0.2244
Epoch 3 [153/172] - loss: 0.1117
Epoch 3 [154/172] - loss: 0.1230
Epoch 3 [155/172] - loss: 0.0895
Epoch 3 [156/172] - loss: 0.1015

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3053, log_difficulty=0.2664, weight=2.3321
neutral: count=4903.0, difficulty=0.2360, log_difficulty=0.2119, weight=2.0595
negative: count=5500.0, difficulty=0.3069, log_difficulty=0.2677, weight=2.3384

当前batch的pt分布：
positive: min=0.8525, max=0.9941, mean=0.9370
neutral: min=0.7926, max=0.9986, mean=0.9404
negative: min=0.4239, max=0.9925, mean=0.8535

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1029
焦点损失: 0.0093
边界损失: 0.1848
总损失: 0.1033
Epoch 3 [157/172] - loss: 0.1033
Epoch 3 [158/172] - loss: 0.1634
Epoch 3 [159/172] - loss: 0.1281
Epoch 3 [160/172] - loss: 0.1809, acc: 0.9688
Epoch 3 [161/172] - loss: 0.1217
Epoch 3 [162/172] - loss: 0.1325
Epoch 3 [163/172] - loss: 0.1033
Epoch 3 [164/172] - loss: 0.0930
Epoch 3 [165/172] - loss: 0.1194
Epoch 3 [166/172] - loss: 0.1812
Epoch 3 [167/172] - loss: 0.1070
Epoch 3 [168/172] - loss: 0.1316
Epoch 3 [169/172] - loss: 0.0933
Epoch 3 [170/172] - loss: 0.2642, acc: 0.9062
Epoch 3 [171/172] - loss: 0.1746
Epoch 3 [172/172] - loss: 0.0899

类别准确率:
positive: 0.8779 (410/467)
neutral: 0.2892 (24/83)
negative: 0.6000 (150/250)

Epoch 3/10
Train Loss: 0.1367, Train Acc: 0.9556
Val Loss: 0.7415, Val Acc: 0.7300
Epoch 4 [1/172] - loss: 0.0843, acc: 1.0000
Epoch 4 [2/172] - loss: 0.0830
Epoch 4 [3/172] - loss: 0.1123
Epoch 4 [4/172] - loss: 0.0880
Epoch 4 [5/172] - loss: 0.1085
Epoch 4 [6/172] - loss: 0.0913
Epoch 4 [7/172] - loss: 0.1061
Epoch 4 [8/172] - loss: 0.0930
Epoch 4 [9/172] - loss: 0.1280
Epoch 4 [10/172] - loss: 0.1076, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0862
Epoch 4 [12/172] - loss: 0.0980
Epoch 4 [13/172] - loss: 0.1164
Epoch 4 [14/172] - loss: 0.1388
Epoch 4 [15/172] - loss: 0.1045
Epoch 4 [16/172] - loss: 0.0866
Epoch 4 [17/172] - loss: 0.1034
Epoch 4 [18/172] - loss: 0.0985
Epoch 4 [19/172] - loss: 0.1874
Epoch 4 [20/172] - loss: 0.1140, acc: 0.9688
Epoch 4 [21/172] - loss: 0.1275
Epoch 4 [22/172] - loss: 0.0845
Epoch 4 [23/172] - loss: 0.1152
Epoch 4 [24/172] - loss: 0.0850
Epoch 4 [25/172] - loss: 0.1036
Epoch 4 [26/172] - loss: 0.3109
Epoch 4 [27/172] - loss: 0.0854
Epoch 4 [28/172] - loss: 0.0915
Epoch 4 [29/172] - loss: 0.1064
Epoch 4 [30/172] - loss: 0.1643, acc: 0.9375
Epoch 4 [31/172] - loss: 0.1325
Epoch 4 [32/172] - loss: 0.0802
Epoch 4 [33/172] - loss: 0.1986
Epoch 4 [34/172] - loss: 0.1564
Epoch 4 [35/172] - loss: 0.1236
Epoch 4 [36/172] - loss: 0.0960
Epoch 4 [37/172] - loss: 0.0863
Epoch 4 [38/172] - loss: 0.1143
Epoch 4 [39/172] - loss: 0.1240
Epoch 4 [40/172] - loss: 0.1516, acc: 0.9375
Epoch 4 [41/172] - loss: 0.0978
Epoch 4 [42/172] - loss: 0.1411
Epoch 4 [43/172] - loss: 0.1181
Epoch 4 [44/172] - loss: 0.1203
Epoch 4 [45/172] - loss: 0.0847
Epoch 4 [46/172] - loss: 0.0785
Epoch 4 [47/172] - loss: 0.1137
Epoch 4 [48/172] - loss: 0.1021
Epoch 4 [49/172] - loss: 0.1349
Epoch 4 [50/172] - loss: 0.1521, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0845
Epoch 4 [52/172] - loss: 0.2256
Epoch 4 [53/172] - loss: 0.0795
Epoch 4 [54/172] - loss: 0.1435
Epoch 4 [55/172] - loss: 0.2285
Epoch 4 [56/172] - loss: 0.0847
Epoch 4 [57/172] - loss: 0.0879
Epoch 4 [58/172] - loss: 0.0915
Epoch 4 [59/172] - loss: 0.0812
Epoch 4 [60/172] - loss: 0.0863, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1091
Epoch 4 [62/172] - loss: 0.1473
Epoch 4 [63/172] - loss: 0.0884
Epoch 4 [64/172] - loss: 0.0861
Epoch 4 [65/172] - loss: 0.1021
Epoch 4 [66/172] - loss: 0.0869
Epoch 4 [67/172] - loss: 0.1341
Epoch 4 [68/172] - loss: 0.0822
Epoch 4 [69/172] - loss: 0.0896
Epoch 4 [70/172] - loss: 0.0905, acc: 1.0000
Epoch 4 [71/172] - loss: 0.0892
Epoch 4 [72/172] - loss: 0.0845
Epoch 4 [73/172] - loss: 0.1113
Epoch 4 [74/172] - loss: 0.2326
Epoch 4 [75/172] - loss: 0.0840
Epoch 4 [76/172] - loss: 0.0784
Epoch 4 [77/172] - loss: 0.0992
Epoch 4 [78/172] - loss: 0.0797
Epoch 4 [79/172] - loss: 0.0835
Epoch 4 [80/172] - loss: 0.1843, acc: 0.9688
Epoch 4 [81/172] - loss: 0.1241
Epoch 4 [82/172] - loss: 0.0854
Epoch 4 [83/172] - loss: 0.1327
Epoch 4 [84/172] - loss: 0.0916

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2706, log_difficulty=0.2395, weight=2.1973
neutral: count=5865.0, difficulty=0.2080, log_difficulty=0.1890, weight=1.9448
negative: count=6629.0, difficulty=0.2722, log_difficulty=0.2408, weight=2.2039

当前batch的pt分布：
positive: min=0.5815, max=0.9836, mean=0.8701
neutral: min=0.8973, max=0.9998, mean=0.9788
negative: min=0.6599, max=0.9963, mean=0.9250

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1045
焦点损失: 0.0068
边界损失: 0.1877
总损失: 0.1013
Epoch 4 [85/172] - loss: 0.1013
Epoch 4 [86/172] - loss: 0.1121
Epoch 4 [87/172] - loss: 0.1319
Epoch 4 [88/172] - loss: 0.0792
Epoch 4 [89/172] - loss: 0.0853
Epoch 4 [90/172] - loss: 0.0971, acc: 0.9688
Epoch 4 [91/172] - loss: 0.1684
Epoch 4 [92/172] - loss: 0.2887
Epoch 4 [93/172] - loss: 0.0957
Epoch 4 [94/172] - loss: 0.0919
Epoch 4 [95/172] - loss: 0.1061
Epoch 4 [96/172] - loss: 0.1062
Epoch 4 [97/172] - loss: 0.0806
Epoch 4 [98/172] - loss: 0.0836
Epoch 4 [99/172] - loss: 0.0973
Epoch 4 [100/172] - loss: 0.0988, acc: 0.9688
Epoch 4 [101/172] - loss: 0.1306
Epoch 4 [102/172] - loss: 0.1294
Epoch 4 [103/172] - loss: 0.0850
Epoch 4 [104/172] - loss: 0.1030
Epoch 4 [105/172] - loss: 0.0919
Epoch 4 [106/172] - loss: 0.0922
Epoch 4 [107/172] - loss: 0.0912
Epoch 4 [108/172] - loss: 0.0954
Epoch 4 [109/172] - loss: 0.0929
Epoch 4 [110/172] - loss: 0.1546, acc: 0.9375
Epoch 4 [111/172] - loss: 0.0839
Epoch 4 [112/172] - loss: 0.0918
Epoch 4 [113/172] - loss: 0.0858
Epoch 4 [114/172] - loss: 0.1053
Epoch 4 [115/172] - loss: 0.1063
Epoch 4 [116/172] - loss: 0.0889
Epoch 4 [117/172] - loss: 0.0837
Epoch 4 [118/172] - loss: 0.1208
Epoch 4 [119/172] - loss: 0.0879
Epoch 4 [120/172] - loss: 0.0943, acc: 1.0000
Epoch 4 [121/172] - loss: 0.0962
Epoch 4 [122/172] - loss: 0.1771
Epoch 4 [123/172] - loss: 0.0814
Epoch 4 [124/172] - loss: 0.0848
Epoch 4 [125/172] - loss: 0.0991
Epoch 4 [126/172] - loss: 0.2487
Epoch 4 [127/172] - loss: 0.1345
Epoch 4 [128/172] - loss: 0.0787
Epoch 4 [129/172] - loss: 0.0841
Epoch 4 [130/172] - loss: 0.0741, acc: 1.0000
Epoch 4 [131/172] - loss: 0.0779
Epoch 4 [132/172] - loss: 0.0811
Epoch 4 [133/172] - loss: 0.1239
Epoch 4 [134/172] - loss: 0.0818
Epoch 4 [135/172] - loss: 0.0867
Epoch 4 [136/172] - loss: 0.1014
Epoch 4 [137/172] - loss: 0.1277
Epoch 4 [138/172] - loss: 0.0908
Epoch 4 [139/172] - loss: 0.0858
Epoch 4 [140/172] - loss: 0.1417, acc: 0.9375
Epoch 4 [141/172] - loss: 0.0883
Epoch 4 [142/172] - loss: 0.1181
Epoch 4 [143/172] - loss: 0.1702
Epoch 4 [144/172] - loss: 0.0918
Epoch 4 [145/172] - loss: 0.2328
Epoch 4 [146/172] - loss: 0.0853
Epoch 4 [147/172] - loss: 0.1068
Epoch 4 [148/172] - loss: 0.1019
Epoch 4 [149/172] - loss: 0.0925
Epoch 4 [150/172] - loss: 0.1466, acc: 0.9688
Epoch 4 [151/172] - loss: 0.2033
Epoch 4 [152/172] - loss: 0.0783
Epoch 4 [153/172] - loss: 0.0819
Epoch 4 [154/172] - loss: 0.1169
Epoch 4 [155/172] - loss: 0.0893
Epoch 4 [156/172] - loss: 0.1442
Epoch 4 [157/172] - loss: 0.2409
Epoch 4 [158/172] - loss: 0.0765
Epoch 4 [159/172] - loss: 0.0928
Epoch 4 [160/172] - loss: 0.0950, acc: 0.9688
Epoch 4 [161/172] - loss: 0.1003
Epoch 4 [162/172] - loss: 0.0849
Epoch 4 [163/172] - loss: 0.0905
Epoch 4 [164/172] - loss: 0.0858
Epoch 4 [165/172] - loss: 0.1150
Epoch 4 [166/172] - loss: 0.0836
Epoch 4 [167/172] - loss: 0.1186
Epoch 4 [168/172] - loss: 0.1372
Epoch 4 [169/172] - loss: 0.1299
Epoch 4 [170/172] - loss: 0.1047, acc: 0.9688
Epoch 4 [171/172] - loss: 0.0981
Epoch 4 [172/172] - loss: 0.0861

类别准确率:
positive: 0.8758 (409/467)
neutral: 0.2048 (17/83)
negative: 0.6440 (161/250)

Epoch 4/10
Train Loss: 0.1087, Train Acc: 0.9758
Val Loss: 0.7747, Val Acc: 0.7338
Epoch 5 [1/172] - loss: 0.0848, acc: 1.0000
Epoch 5 [2/172] - loss: 0.0915
Epoch 5 [3/172] - loss: 0.0801
Epoch 5 [4/172] - loss: 0.0823
Epoch 5 [5/172] - loss: 0.0816
Epoch 5 [6/172] - loss: 0.0922
Epoch 5 [7/172] - loss: 0.1088
Epoch 5 [8/172] - loss: 0.1123
Epoch 5 [9/172] - loss: 0.1492
Epoch 5 [10/172] - loss: 0.0935, acc: 0.9688
Epoch 5 [11/172] - loss: 0.1019
Epoch 5 [12/172] - loss: 0.0797

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2434, log_difficulty=0.2179, weight=2.0894
neutral: count=6845.0, difficulty=0.1865, log_difficulty=0.1710, weight=1.8550
negative: count=7694.0, difficulty=0.2454, log_difficulty=0.2194, weight=2.0971

当前batch的pt分布：
positive: min=0.6004, max=0.9910, mean=0.9208
neutral: min=0.8957, max=0.9990, mean=0.9796
negative: min=0.8166, max=0.9982, mean=0.9453

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0635
焦点损失: 0.0026
边界损失: 0.1666
总损失: 0.0860
Epoch 5 [13/172] - loss: 0.0860
Epoch 5 [14/172] - loss: 0.1141
Epoch 5 [15/172] - loss: 0.0853
Epoch 5 [16/172] - loss: 0.0853
Epoch 5 [17/172] - loss: 0.0935
Epoch 5 [18/172] - loss: 0.1168
Epoch 5 [19/172] - loss: 0.1454
Epoch 5 [20/172] - loss: 0.1671, acc: 0.9375
Epoch 5 [21/172] - loss: 0.1579
Epoch 5 [22/172] - loss: 0.1863
Epoch 5 [23/172] - loss: 0.0813
Epoch 5 [24/172] - loss: 0.0780
Epoch 5 [25/172] - loss: 0.0826
Epoch 5 [26/172] - loss: 0.1063
Epoch 5 [27/172] - loss: 0.0793
Epoch 5 [28/172] - loss: 0.0859
Epoch 5 [29/172] - loss: 0.1402
Epoch 5 [30/172] - loss: 0.1075, acc: 0.9688
Epoch 5 [31/172] - loss: 0.0891
Epoch 5 [32/172] - loss: 0.0803
Epoch 5 [33/172] - loss: 0.0833
Epoch 5 [34/172] - loss: 0.0848
Epoch 5 [35/172] - loss: 0.0787
Epoch 5 [36/172] - loss: 0.0789
Epoch 5 [37/172] - loss: 0.1125
Epoch 5 [38/172] - loss: 0.0765
Epoch 5 [39/172] - loss: 0.1768
Epoch 5 [40/172] - loss: 0.1000, acc: 0.9688
Epoch 5 [41/172] - loss: 0.0777
Epoch 5 [42/172] - loss: 0.0864
Epoch 5 [43/172] - loss: 0.1854
Epoch 5 [44/172] - loss: 0.0934
Epoch 5 [45/172] - loss: 0.0857
Epoch 5 [46/172] - loss: 0.2175
Epoch 5 [47/172] - loss: 0.0859
Epoch 5 [48/172] - loss: 0.0824
Epoch 5 [49/172] - loss: 0.0777
Epoch 5 [50/172] - loss: 0.0993, acc: 1.0000
Epoch 5 [51/172] - loss: 0.0968
Epoch 5 [52/172] - loss: 0.0857
Epoch 5 [53/172] - loss: 0.1101
Epoch 5 [54/172] - loss: 0.1094
Epoch 5 [55/172] - loss: 0.1982
Epoch 5 [56/172] - loss: 0.0862
Epoch 5 [57/172] - loss: 0.1274
Epoch 5 [58/172] - loss: 0.0765
Epoch 5 [59/172] - loss: 0.0958
Epoch 5 [60/172] - loss: 0.0773, acc: 1.0000
Epoch 5 [61/172] - loss: 0.0801
Epoch 5 [62/172] - loss: 0.0822
Epoch 5 [63/172] - loss: 0.0915
Epoch 5 [64/172] - loss: 0.0868
Epoch 5 [65/172] - loss: 0.0796
Epoch 5 [66/172] - loss: 0.0852
Epoch 5 [67/172] - loss: 0.0839
Epoch 5 [68/172] - loss: 0.1042
Epoch 5 [69/172] - loss: 0.1091
Epoch 5 [70/172] - loss: 0.0799, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1018
Epoch 5 [72/172] - loss: 0.0961
Epoch 5 [73/172] - loss: 0.1173
Epoch 5 [74/172] - loss: 0.0868
Epoch 5 [75/172] - loss: 0.0842
Epoch 5 [76/172] - loss: 0.0825
Epoch 5 [77/172] - loss: 0.0878
Epoch 5 [78/172] - loss: 0.0922
Epoch 5 [79/172] - loss: 0.0808
Epoch 5 [80/172] - loss: 0.0774, acc: 1.0000
Epoch 5 [81/172] - loss: 0.0944
Epoch 5 [82/172] - loss: 0.1055
Epoch 5 [83/172] - loss: 0.0794
Epoch 5 [84/172] - loss: 0.0955
Epoch 5 [85/172] - loss: 0.1311
Epoch 5 [86/172] - loss: 0.0802
Epoch 5 [87/172] - loss: 0.0864
Epoch 5 [88/172] - loss: 0.1168
Epoch 5 [89/172] - loss: 0.0771
Epoch 5 [90/172] - loss: 0.1765, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0837
Epoch 5 [92/172] - loss: 0.0785
Epoch 5 [93/172] - loss: 0.0823
Epoch 5 [94/172] - loss: 0.0775
Epoch 5 [95/172] - loss: 0.0819
Epoch 5 [96/172] - loss: 0.0785
Epoch 5 [97/172] - loss: 0.0956
Epoch 5 [98/172] - loss: 0.0742
Epoch 5 [99/172] - loss: 0.1409
Epoch 5 [100/172] - loss: 0.0769, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1078
Epoch 5 [102/172] - loss: 0.0791
Epoch 5 [103/172] - loss: 0.0805
Epoch 5 [104/172] - loss: 0.1291
Epoch 5 [105/172] - loss: 0.1875
Epoch 5 [106/172] - loss: 0.0737
Epoch 5 [107/172] - loss: 0.0921
Epoch 5 [108/172] - loss: 0.1102
Epoch 5 [109/172] - loss: 0.0770
Epoch 5 [110/172] - loss: 0.0927, acc: 0.9688
Epoch 5 [111/172] - loss: 0.0817
Epoch 5 [112/172] - loss: 0.0752

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2203, log_difficulty=0.1991, weight=1.9954
neutral: count=7825.0, difficulty=0.1692, log_difficulty=0.1564, weight=1.7818
negative: count=8780.0, difficulty=0.2236, log_difficulty=0.2018, weight=2.0090

当前batch的pt分布：
positive: min=0.2405, max=0.9795, mean=0.8706
neutral: min=0.9573, max=0.9957, mean=0.9789
negative: min=0.9934, max=0.9998, mean=0.9974

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0973
焦点损失: 0.0267
边界损失: 0.1663
总损失: 0.1098
Epoch 5 [113/172] - loss: 0.1098
Epoch 5 [114/172] - loss: 0.1580
Epoch 5 [115/172] - loss: 0.0781
Epoch 5 [116/172] - loss: 0.0762
Epoch 5 [117/172] - loss: 0.0925
Epoch 5 [118/172] - loss: 0.1259
Epoch 5 [119/172] - loss: 0.0753
Epoch 5 [120/172] - loss: 0.0854, acc: 1.0000
Epoch 5 [121/172] - loss: 0.0909
Epoch 5 [122/172] - loss: 0.0864
Epoch 5 [123/172] - loss: 0.1200
Epoch 5 [124/172] - loss: 0.1241
Epoch 5 [125/172] - loss: 0.1209
Epoch 5 [126/172] - loss: 0.0794
Epoch 5 [127/172] - loss: 0.0788
Epoch 5 [128/172] - loss: 0.0796
Epoch 5 [129/172] - loss: 0.1780
Epoch 5 [130/172] - loss: 0.0792, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0952
Epoch 5 [132/172] - loss: 0.1602
Epoch 5 [133/172] - loss: 0.0846
Epoch 5 [134/172] - loss: 0.1750
Epoch 5 [135/172] - loss: 0.0748
Epoch 5 [136/172] - loss: 0.0806
Epoch 5 [137/172] - loss: 0.0800
Epoch 5 [138/172] - loss: 0.1271
Epoch 5 [139/172] - loss: 0.1338
Epoch 5 [140/172] - loss: 0.1565, acc: 0.9375
Epoch 5 [141/172] - loss: 0.0785
Epoch 5 [142/172] - loss: 0.0860
Epoch 5 [143/172] - loss: 0.0776
Epoch 5 [144/172] - loss: 0.0783
Epoch 5 [145/172] - loss: 0.1424
Epoch 5 [146/172] - loss: 0.0976
Epoch 5 [147/172] - loss: 0.0873
Epoch 5 [148/172] - loss: 0.0860
Epoch 5 [149/172] - loss: 0.0786
Epoch 5 [150/172] - loss: 0.1345, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0818
Epoch 5 [152/172] - loss: 0.0749
Epoch 5 [153/172] - loss: 0.0821
Epoch 5 [154/172] - loss: 0.0787
Epoch 5 [155/172] - loss: 0.0779
Epoch 5 [156/172] - loss: 0.0842
Epoch 5 [157/172] - loss: 0.0835
Epoch 5 [158/172] - loss: 0.0812
Epoch 5 [159/172] - loss: 0.0751
Epoch 5 [160/172] - loss: 0.0836, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0783
Epoch 5 [162/172] - loss: 0.1102
Epoch 5 [163/172] - loss: 0.2141
Epoch 5 [164/172] - loss: 0.0742
Epoch 5 [165/172] - loss: 0.2099
Epoch 5 [166/172] - loss: 0.0835
Epoch 5 [167/172] - loss: 0.0823
Epoch 5 [168/172] - loss: 0.0757
Epoch 5 [169/172] - loss: 0.0759
Epoch 5 [170/172] - loss: 0.0905, acc: 0.9688
Epoch 5 [171/172] - loss: 0.0766
Epoch 5 [172/172] - loss: 0.0987

类别准确率:
positive: 0.8587 (401/467)
neutral: 0.3012 (25/83)
negative: 0.6360 (159/250)

Epoch 5/10
Train Loss: 0.0996, Train Acc: 0.9899
Val Loss: 0.8291, Val Acc: 0.7312
Epoch 6 [1/172] - loss: 0.1023, acc: 1.0000
Epoch 6 [2/172] - loss: 0.1093
Epoch 6 [3/172] - loss: 0.0777
Epoch 6 [4/172] - loss: 0.0768
Epoch 6 [5/172] - loss: 0.0911
Epoch 6 [6/172] - loss: 0.0767
Epoch 6 [7/172] - loss: 0.0803
Epoch 6 [8/172] - loss: 0.0840
Epoch 6 [9/172] - loss: 0.0769
Epoch 6 [10/172] - loss: 0.0739, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0732
Epoch 6 [12/172] - loss: 0.0734
Epoch 6 [13/172] - loss: 0.0908
Epoch 6 [14/172] - loss: 0.0806
Epoch 6 [15/172] - loss: 0.0738
Epoch 6 [16/172] - loss: 0.1302
Epoch 6 [17/172] - loss: 0.0785
Epoch 6 [18/172] - loss: 0.0795
Epoch 6 [19/172] - loss: 0.0772
Epoch 6 [20/172] - loss: 0.0747, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0796
Epoch 6 [22/172] - loss: 0.0763
Epoch 6 [23/172] - loss: 0.0774
Epoch 6 [24/172] - loss: 0.0800
Epoch 6 [25/172] - loss: 0.0904
Epoch 6 [26/172] - loss: 0.0870
Epoch 6 [27/172] - loss: 0.0840
Epoch 6 [28/172] - loss: 0.0827
Epoch 6 [29/172] - loss: 0.1250
Epoch 6 [30/172] - loss: 0.0783, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0746
Epoch 6 [32/172] - loss: 0.0743
Epoch 6 [33/172] - loss: 0.0819
Epoch 6 [34/172] - loss: 0.0750
Epoch 6 [35/172] - loss: 0.0743
Epoch 6 [36/172] - loss: 0.0766
Epoch 6 [37/172] - loss: 0.0768
Epoch 6 [38/172] - loss: 0.0786
Epoch 6 [39/172] - loss: 0.0870
Epoch 6 [40/172] - loss: 0.1164, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2017, log_difficulty=0.1837, weight=1.9187
neutral: count=8815.0, difficulty=0.1552, log_difficulty=0.1443, weight=1.7213
negative: count=9870.0, difficulty=0.2049, log_difficulty=0.1864, weight=1.9318

当前batch的pt分布：
positive: min=0.0549, max=0.9982, mean=0.8907
neutral: min=0.8934, max=0.9974, mean=0.9720
negative: min=0.8780, max=0.9980, mean=0.9576

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1232
焦点损失: 0.0810
边界损失: 0.1512
总损失: 0.1533
Epoch 6 [41/172] - loss: 0.1533
Epoch 6 [42/172] - loss: 0.0755
Epoch 6 [43/172] - loss: 0.1262
Epoch 6 [44/172] - loss: 0.0753
Epoch 6 [45/172] - loss: 0.0901
Epoch 6 [46/172] - loss: 0.0941
Epoch 6 [47/172] - loss: 0.0799
Epoch 6 [48/172] - loss: 0.0811
Epoch 6 [49/172] - loss: 0.0769
Epoch 6 [50/172] - loss: 0.1894, acc: 0.9688
Epoch 6 [51/172] - loss: 0.0802
Epoch 6 [52/172] - loss: 0.0846
Epoch 6 [53/172] - loss: 0.0770
Epoch 6 [54/172] - loss: 0.1913
Epoch 6 [55/172] - loss: 0.0821
Epoch 6 [56/172] - loss: 0.0779
Epoch 6 [57/172] - loss: 0.0762
Epoch 6 [58/172] - loss: 0.0758
Epoch 6 [59/172] - loss: 0.0875
Epoch 6 [60/172] - loss: 0.0837, acc: 1.0000
Epoch 6 [61/172] - loss: 0.1001
Epoch 6 [62/172] - loss: 0.0991
Epoch 6 [63/172] - loss: 0.0821
Epoch 6 [64/172] - loss: 0.1764
Epoch 6 [65/172] - loss: 0.0791
Epoch 6 [66/172] - loss: 0.0951
Epoch 6 [67/172] - loss: 0.0749
Epoch 6 [68/172] - loss: 0.1661
Epoch 6 [69/172] - loss: 0.1016
Epoch 6 [70/172] - loss: 0.0765, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0769
Epoch 6 [72/172] - loss: 0.0879
Epoch 6 [73/172] - loss: 0.0822
Epoch 6 [74/172] - loss: 0.0719
Epoch 6 [75/172] - loss: 0.0816
Epoch 6 [76/172] - loss: 0.0749
Epoch 6 [77/172] - loss: 0.1005
Epoch 6 [78/172] - loss: 0.0850
Epoch 6 [79/172] - loss: 0.0730
Epoch 6 [80/172] - loss: 0.2191, acc: 0.9375
Epoch 6 [81/172] - loss: 0.0839
Epoch 6 [82/172] - loss: 0.0796
Epoch 6 [83/172] - loss: 0.0753
Epoch 6 [84/172] - loss: 0.0763
Epoch 6 [85/172] - loss: 0.1043
Epoch 6 [86/172] - loss: 0.0844
Epoch 6 [87/172] - loss: 0.0802
Epoch 6 [88/172] - loss: 0.0914
Epoch 6 [89/172] - loss: 0.0826
Epoch 6 [90/172] - loss: 0.0740, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0735
Epoch 6 [92/172] - loss: 0.0802
Epoch 6 [93/172] - loss: 0.0744
Epoch 6 [94/172] - loss: 0.0815
Epoch 6 [95/172] - loss: 0.1146
Epoch 6 [96/172] - loss: 0.0769
Epoch 6 [97/172] - loss: 0.0773
Epoch 6 [98/172] - loss: 0.0846
Epoch 6 [99/172] - loss: 0.0780
Epoch 6 [100/172] - loss: 0.0750, acc: 1.0000
Epoch 6 [101/172] - loss: 0.0997
Epoch 6 [102/172] - loss: 0.0758
Epoch 6 [103/172] - loss: 0.1009
Epoch 6 [104/172] - loss: 0.1049
Epoch 6 [105/172] - loss: 0.0754
Epoch 6 [106/172] - loss: 0.0883
Epoch 6 [107/172] - loss: 0.0766
Epoch 6 [108/172] - loss: 0.0755
Epoch 6 [109/172] - loss: 0.1267
Epoch 6 [110/172] - loss: 0.0775, acc: 1.0000
Epoch 6 [111/172] - loss: 0.0776
Epoch 6 [112/172] - loss: 0.0746
Epoch 6 [113/172] - loss: 0.0926
Epoch 6 [114/172] - loss: 0.0881
Epoch 6 [115/172] - loss: 0.0829
Epoch 6 [116/172] - loss: 0.1827
Epoch 6 [117/172] - loss: 0.0789
Epoch 6 [118/172] - loss: 0.0749
Epoch 6 [119/172] - loss: 0.1994
Epoch 6 [120/172] - loss: 0.0754, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0820
Epoch 6 [122/172] - loss: 0.0888
Epoch 6 [123/172] - loss: 0.0844
Epoch 6 [124/172] - loss: 0.0737
Epoch 6 [125/172] - loss: 0.0849
Epoch 6 [126/172] - loss: 0.2067
Epoch 6 [127/172] - loss: 0.1092
Epoch 6 [128/172] - loss: 0.0929
Epoch 6 [129/172] - loss: 0.0834
Epoch 6 [130/172] - loss: 0.1201, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1023
Epoch 6 [132/172] - loss: 0.1185
Epoch 6 [133/172] - loss: 0.1006
Epoch 6 [134/172] - loss: 0.1020
Epoch 6 [135/172] - loss: 0.0750
Epoch 6 [136/172] - loss: 0.0774
Epoch 6 [137/172] - loss: 0.0767
Epoch 6 [138/172] - loss: 0.0948
Epoch 6 [139/172] - loss: 0.0783
Epoch 6 [140/172] - loss: 0.0917, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1864, log_difficulty=0.1710, weight=1.8548
neutral: count=9796.0, difficulty=0.1438, log_difficulty=0.1344, weight=1.6720
negative: count=10972.0, difficulty=0.1899, log_difficulty=0.1739, weight=1.8693

当前batch的pt分布：
positive: min=0.9709, max=0.9988, mean=0.9877
neutral: min=0.9089, max=0.9976, mean=0.9773
negative: min=0.8510, max=0.9941, mean=0.9564

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0293
焦点损失: 0.0002
边界损失: 0.1493
总损失: 0.0748
Epoch 6 [141/172] - loss: 0.0748
Epoch 6 [142/172] - loss: 0.0743
Epoch 6 [143/172] - loss: 0.0960
Epoch 6 [144/172] - loss: 0.1038
Epoch 6 [145/172] - loss: 0.0791
Epoch 6 [146/172] - loss: 0.0740
Epoch 6 [147/172] - loss: 0.0824
Epoch 6 [148/172] - loss: 0.1148
Epoch 6 [149/172] - loss: 0.0770
Epoch 6 [150/172] - loss: 0.0745, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0759
Epoch 6 [152/172] - loss: 0.0931
Epoch 6 [153/172] - loss: 0.0763
Epoch 6 [154/172] - loss: 0.0744
Epoch 6 [155/172] - loss: 0.0897
Epoch 6 [156/172] - loss: 0.0895
Epoch 6 [157/172] - loss: 0.0760
Epoch 6 [158/172] - loss: 0.0936
Epoch 6 [159/172] - loss: 0.1186
Epoch 6 [160/172] - loss: 0.1235, acc: 0.9688
Epoch 6 [161/172] - loss: 0.0742
Epoch 6 [162/172] - loss: 0.0791
Epoch 6 [163/172] - loss: 0.0875
Epoch 6 [164/172] - loss: 0.0932
Epoch 6 [165/172] - loss: 0.2523
Epoch 6 [166/172] - loss: 0.0840
Epoch 6 [167/172] - loss: 0.0790
Epoch 6 [168/172] - loss: 0.0789
Epoch 6 [169/172] - loss: 0.0966
Epoch 6 [170/172] - loss: 0.0820, acc: 1.0000
Epoch 6 [171/172] - loss: 0.0748
Epoch 6 [172/172] - loss: 0.0856

类别准确率:
positive: 0.9315 (435/467)
neutral: 0.1325 (11/83)
negative: 0.4320 (108/250)

Epoch 6/10
Train Loss: 0.0987, Train Acc: 0.9818
Val Loss: 1.1555, Val Acc: 0.6925
Epoch 7 [1/172] - loss: 0.0762, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0741
Epoch 7 [3/172] - loss: 0.0784
Epoch 7 [4/172] - loss: 0.0821
Epoch 7 [5/172] - loss: 0.0741
Epoch 7 [6/172] - loss: 0.0746
Epoch 7 [7/172] - loss: 0.0921
Epoch 7 [8/172] - loss: 0.1508
Epoch 7 [9/172] - loss: 0.0765
Epoch 7 [10/172] - loss: 0.0738, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0756
Epoch 7 [12/172] - loss: 0.1216
Epoch 7 [13/172] - loss: 0.0760
Epoch 7 [14/172] - loss: 0.0783
Epoch 7 [15/172] - loss: 0.1066
Epoch 7 [16/172] - loss: 0.0804
Epoch 7 [17/172] - loss: 0.1148
Epoch 7 [18/172] - loss: 0.1134
Epoch 7 [19/172] - loss: 0.0767
Epoch 7 [20/172] - loss: 0.0738, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0816
Epoch 7 [22/172] - loss: 0.0737
Epoch 7 [23/172] - loss: 0.0852
Epoch 7 [24/172] - loss: 0.1267
Epoch 7 [25/172] - loss: 0.0863
Epoch 7 [26/172] - loss: 0.0963
Epoch 7 [27/172] - loss: 0.0761
Epoch 7 [28/172] - loss: 0.0836
Epoch 7 [29/172] - loss: 0.0828
Epoch 7 [30/172] - loss: 0.1376, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0732
Epoch 7 [32/172] - loss: 0.0803
Epoch 7 [33/172] - loss: 0.1329
Epoch 7 [34/172] - loss: 0.0908
Epoch 7 [35/172] - loss: 0.0754
Epoch 7 [36/172] - loss: 0.1483
Epoch 7 [37/172] - loss: 0.0749
Epoch 7 [38/172] - loss: 0.0726
Epoch 7 [39/172] - loss: 0.0740
Epoch 7 [40/172] - loss: 0.0720, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0742
Epoch 7 [42/172] - loss: 0.0745
Epoch 7 [43/172] - loss: 0.0750
Epoch 7 [44/172] - loss: 0.1034
Epoch 7 [45/172] - loss: 0.0760
Epoch 7 [46/172] - loss: 0.1387
Epoch 7 [47/172] - loss: 0.0872
Epoch 7 [48/172] - loss: 0.0728
Epoch 7 [49/172] - loss: 0.0732
Epoch 7 [50/172] - loss: 0.0739, acc: 1.0000
Epoch 7 [51/172] - loss: 0.0936
Epoch 7 [52/172] - loss: 0.0759
Epoch 7 [53/172] - loss: 0.0745
Epoch 7 [54/172] - loss: 0.0751
Epoch 7 [55/172] - loss: 0.0732
Epoch 7 [56/172] - loss: 0.0826
Epoch 7 [57/172] - loss: 0.1416
Epoch 7 [58/172] - loss: 0.0864
Epoch 7 [59/172] - loss: 0.0741
Epoch 7 [60/172] - loss: 0.0824, acc: 1.0000
Epoch 7 [61/172] - loss: 0.0841
Epoch 7 [62/172] - loss: 0.0874
Epoch 7 [63/172] - loss: 0.1987
Epoch 7 [64/172] - loss: 0.0781
Epoch 7 [65/172] - loss: 0.0968
Epoch 7 [66/172] - loss: 0.1185
Epoch 7 [67/172] - loss: 0.0851
Epoch 7 [68/172] - loss: 0.0813

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1735, log_difficulty=0.1600, weight=1.8002
neutral: count=10756.0, difficulty=0.1343, log_difficulty=0.1260, weight=1.6299
negative: count=12072.0, difficulty=0.1773, log_difficulty=0.1633, weight=1.8163

当前batch的pt分布：
positive: min=0.9549, max=0.9954, mean=0.9856
neutral: min=0.9528, max=0.9994, mean=0.9860
negative: min=0.6641, max=0.9915, mean=0.9368

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0386
焦点损失: 0.0015
边界损失: 0.1521
总损失: 0.0775
Epoch 7 [69/172] - loss: 0.0775
Epoch 7 [70/172] - loss: 0.0764, acc: 1.0000
Epoch 7 [71/172] - loss: 0.0802
Epoch 7 [72/172] - loss: 0.0826
Epoch 7 [73/172] - loss: 0.0811
Epoch 7 [74/172] - loss: 0.0733
Epoch 7 [75/172] - loss: 0.0765
Epoch 7 [76/172] - loss: 0.0768
Epoch 7 [77/172] - loss: 0.0771
Epoch 7 [78/172] - loss: 0.0749
Epoch 7 [79/172] - loss: 0.0931
Epoch 7 [80/172] - loss: 0.0923, acc: 1.0000
Epoch 7 [81/172] - loss: 0.0725
Epoch 7 [82/172] - loss: 0.0746
Epoch 7 [83/172] - loss: 0.0970
Epoch 7 [84/172] - loss: 0.0746
Epoch 7 [85/172] - loss: 0.0842
Epoch 7 [86/172] - loss: 0.0749
Epoch 7 [87/172] - loss: 0.0765
Epoch 7 [88/172] - loss: 0.0736
Epoch 7 [89/172] - loss: 0.0752
Epoch 7 [90/172] - loss: 0.0809, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0742
Epoch 7 [92/172] - loss: 0.0776
Epoch 7 [93/172] - loss: 0.0980
Epoch 7 [94/172] - loss: 0.0772
Epoch 7 [95/172] - loss: 0.0740
Epoch 7 [96/172] - loss: 0.0827
Epoch 7 [97/172] - loss: 0.0918
Epoch 7 [98/172] - loss: 0.0922
Epoch 7 [99/172] - loss: 0.0718
Epoch 7 [100/172] - loss: 0.0749, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0720
Epoch 7 [102/172] - loss: 0.1065
Epoch 7 [103/172] - loss: 0.0737
Epoch 7 [104/172] - loss: 0.0765
Epoch 7 [105/172] - loss: 0.0828
Epoch 7 [106/172] - loss: 0.0971
Epoch 7 [107/172] - loss: 0.0740
Epoch 7 [108/172] - loss: 0.0723
Epoch 7 [109/172] - loss: 0.0870
Epoch 7 [110/172] - loss: 0.0879, acc: 0.9688
Epoch 7 [111/172] - loss: 0.0753
Epoch 7 [112/172] - loss: 0.0790
Epoch 7 [113/172] - loss: 0.0728
Epoch 7 [114/172] - loss: 0.0719
Epoch 7 [115/172] - loss: 0.0741
Epoch 7 [116/172] - loss: 0.0833
Epoch 7 [117/172] - loss: 0.0777
Epoch 7 [118/172] - loss: 0.0829
Epoch 7 [119/172] - loss: 0.0762
Epoch 7 [120/172] - loss: 0.1936, acc: 0.9375
Epoch 7 [121/172] - loss: 0.0801
Epoch 7 [122/172] - loss: 0.0835
Epoch 7 [123/172] - loss: 0.0743
Epoch 7 [124/172] - loss: 0.0917
Epoch 7 [125/172] - loss: 0.0731
Epoch 7 [126/172] - loss: 0.0752
Epoch 7 [127/172] - loss: 0.0758
Epoch 7 [128/172] - loss: 0.0739
Epoch 7 [129/172] - loss: 0.0769
Epoch 7 [130/172] - loss: 0.0824, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1161
Epoch 7 [132/172] - loss: 0.1480
Epoch 7 [133/172] - loss: 0.0725
Epoch 7 [134/172] - loss: 0.0808
Epoch 7 [135/172] - loss: 0.0769
Epoch 7 [136/172] - loss: 0.0824
Epoch 7 [137/172] - loss: 0.0853
Epoch 7 [138/172] - loss: 0.0716
Epoch 7 [139/172] - loss: 0.0985
Epoch 7 [140/172] - loss: 0.0832, acc: 0.9688
Epoch 7 [141/172] - loss: 0.1127
Epoch 7 [142/172] - loss: 0.0738
Epoch 7 [143/172] - loss: 0.0825
Epoch 7 [144/172] - loss: 0.0793
Epoch 7 [145/172] - loss: 0.1052
Epoch 7 [146/172] - loss: 0.1063
Epoch 7 [147/172] - loss: 0.0798
Epoch 7 [148/172] - loss: 0.0798
Epoch 7 [149/172] - loss: 0.0781
Epoch 7 [150/172] - loss: 0.0746, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1054
Epoch 7 [152/172] - loss: 0.0729
Epoch 7 [153/172] - loss: 0.0717
Epoch 7 [154/172] - loss: 0.0977
Epoch 7 [155/172] - loss: 0.0739
Epoch 7 [156/172] - loss: 0.1339
Epoch 7 [157/172] - loss: 0.0779
Epoch 7 [158/172] - loss: 0.0788
Epoch 7 [159/172] - loss: 0.0719
Epoch 7 [160/172] - loss: 0.0735, acc: 1.0000
Epoch 7 [161/172] - loss: 0.0770
Epoch 7 [162/172] - loss: 0.0745
Epoch 7 [163/172] - loss: 0.0750
Epoch 7 [164/172] - loss: 0.0820
Epoch 7 [165/172] - loss: 0.0898
Epoch 7 [166/172] - loss: 0.0743
Epoch 7 [167/172] - loss: 0.0873
Epoch 7 [168/172] - loss: 0.0838

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1622, log_difficulty=0.1504, weight=1.7518
neutral: count=11731.0, difficulty=0.1261, log_difficulty=0.1188, weight=1.5938
negative: count=13173.0, difficulty=0.1659, log_difficulty=0.1535, weight=1.7675

当前batch的pt分布：
positive: min=0.9463, max=0.9965, mean=0.9836
neutral: min=0.9843, max=0.9960, mean=0.9919
negative: min=0.9439, max=0.9950, mean=0.9784

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0162
焦点损失: 0.0000
边界损失: 0.1428
总损失: 0.0714
Epoch 7 [169/172] - loss: 0.0714
Epoch 7 [170/172] - loss: 0.0856, acc: 1.0000
Epoch 7 [171/172] - loss: 0.0723
Epoch 7 [172/172] - loss: 0.0721

类别准确率:
positive: 0.8608 (402/467)
neutral: 0.2530 (21/83)
negative: 0.5920 (148/250)

Epoch 7/10
Train Loss: 0.0780, Train Acc: 0.9960
Val Loss: 0.9499, Val Acc: 0.7137
Early stopping triggered!
Best validation accuracy: 0.7338

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_091652-bkk3mjob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.25_Multimodal_iterations_20250118_091650
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/bkk3mjob
wandb: uploading wandb-summary.json; uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇██
wandb:  train_acc ▁▂▃▄▆▆▇▇▇▆▆▇▇▇██▇▇██▇███████████████████
wandb: train_loss █▄▆▅▄▄▃▃▃▃▃▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 1
wandb: train_loss 0.0856
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.25_Multimodal_iterations_20250118_091650 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/bkk3mjob
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_091652-bkk3mjob/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_092732-ar7bdz69
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.25_Multimodal_epochs_20250118_092732
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/ar7bdz69
wandb: uploading history steps 0-0, summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▅▆▇█▇█
wandb: train_loss █▄▂▂▁▁▁
wandb:    val_acc ▁▇███▄▆
wandb:   val_loss ▁▁▂▂▃█▅
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.99596
wandb: train_loss 0.07795
wandb:    val_acc 0.71375
wandb:   val_loss 0.94987
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.5_dropout0.25_Multimodal_epochs_20250118_092732 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/ar7bdz69
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_092732-ar7bdz69/logs

