=== 命令 ===
python main.py --loss_type focal --alpha 0.5 --beta 0.5 --neural_init_weight 1.0 --dropout 0.35 --name loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.35 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.35
text_dim: 128
image_dim: 256
dropout: 0.35
loss_type: focal
alpha: 0.5
beta: 0.5
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6831, log_difficulty=0.5206, weight=3.6032
neutral: count=7.0, difficulty=0.7071, log_difficulty=0.5348, weight=3.6739
negative: count=13.0, difficulty=0.6624, log_difficulty=0.5082, weight=3.5412

当前batch的pt分布：
positive: min=0.1652, max=0.5562, mean=0.3169
neutral: min=0.1996, max=0.3918, mean=0.2929
negative: min=0.0829, max=0.5339, mean=0.3376

当前batch准确率：
整体准确率: 0.3750
positive 准确率: 0.3333
neutral 准确率: 0.1429
negative 准确率: 0.5385

损失分量：
基础交叉熵: 1.1966
焦点损失: 0.4434
边界损失: 0.7736
总损失: 1.1837
Epoch 1 [1/172] - loss: 1.1837, acc: 0.3750
Epoch 1 [2/172] - loss: 1.1068
Epoch 1 [3/172] - loss: 1.1651
Epoch 1 [4/172] - loss: 1.0257
Epoch 1 [5/172] - loss: 1.1848
Epoch 1 [6/172] - loss: 1.4122
Epoch 1 [7/172] - loss: 1.0701
Epoch 1 [8/172] - loss: 1.3031
Epoch 1 [9/172] - loss: 1.0994
Epoch 1 [10/172] - loss: 1.0100, acc: 0.4375
Epoch 1 [11/172] - loss: 1.0656
Epoch 1 [12/172] - loss: 1.0992
Epoch 1 [13/172] - loss: 1.2209
Epoch 1 [14/172] - loss: 1.2473
Epoch 1 [15/172] - loss: 1.1482
Epoch 1 [16/172] - loss: 1.0236
Epoch 1 [17/172] - loss: 1.0843
Epoch 1 [18/172] - loss: 1.0319
Epoch 1 [19/172] - loss: 1.1249
Epoch 1 [20/172] - loss: 1.0403, acc: 0.3750
Epoch 1 [21/172] - loss: 1.0752
Epoch 1 [22/172] - loss: 0.9289
Epoch 1 [23/172] - loss: 1.1374
Epoch 1 [24/172] - loss: 1.3308
Epoch 1 [25/172] - loss: 0.7884
Epoch 1 [26/172] - loss: 1.2599
Epoch 1 [27/172] - loss: 1.1438
Epoch 1 [28/172] - loss: 0.9918
Epoch 1 [29/172] - loss: 1.0027
Epoch 1 [30/172] - loss: 1.1788, acc: 0.4062
Epoch 1 [31/172] - loss: 1.1045
Epoch 1 [32/172] - loss: 1.0702
Epoch 1 [33/172] - loss: 1.1849
Epoch 1 [34/172] - loss: 0.9741
Epoch 1 [35/172] - loss: 0.9735
Epoch 1 [36/172] - loss: 0.8323
Epoch 1 [37/172] - loss: 0.8322
Epoch 1 [38/172] - loss: 1.0115
Epoch 1 [39/172] - loss: 0.8554
Epoch 1 [40/172] - loss: 0.8983, acc: 0.5312
Epoch 1 [41/172] - loss: 0.8938
Epoch 1 [42/172] - loss: 0.7400
Epoch 1 [43/172] - loss: 0.9795
Epoch 1 [44/172] - loss: 1.0906
Epoch 1 [45/172] - loss: 1.1871
Epoch 1 [46/172] - loss: 0.7844
Epoch 1 [47/172] - loss: 1.0333
Epoch 1 [48/172] - loss: 1.0345
Epoch 1 [49/172] - loss: 1.1125
Epoch 1 [50/172] - loss: 0.8923, acc: 0.5312
Epoch 1 [51/172] - loss: 0.8403
Epoch 1 [52/172] - loss: 0.9022
Epoch 1 [53/172] - loss: 1.0860
Epoch 1 [54/172] - loss: 0.8331
Epoch 1 [55/172] - loss: 0.7573
Epoch 1 [56/172] - loss: 0.8152
Epoch 1 [57/172] - loss: 1.0163
Epoch 1 [58/172] - loss: 0.6242
Epoch 1 [59/172] - loss: 0.8217
Epoch 1 [60/172] - loss: 0.6548, acc: 0.6875
Epoch 1 [61/172] - loss: 0.7521
Epoch 1 [62/172] - loss: 0.6707
Epoch 1 [63/172] - loss: 0.8200
Epoch 1 [64/172] - loss: 0.5653
Epoch 1 [65/172] - loss: 1.0082
Epoch 1 [66/172] - loss: 0.7969
Epoch 1 [67/172] - loss: 0.7244
Epoch 1 [68/172] - loss: 0.7907
Epoch 1 [69/172] - loss: 1.0266
Epoch 1 [70/172] - loss: 0.7970, acc: 0.5000
Epoch 1 [71/172] - loss: 0.8763
Epoch 1 [72/172] - loss: 0.7307
Epoch 1 [73/172] - loss: 0.7747
Epoch 1 [74/172] - loss: 0.8250
Epoch 1 [75/172] - loss: 0.6211
Epoch 1 [76/172] - loss: 0.9473
Epoch 1 [77/172] - loss: 0.7575
Epoch 1 [78/172] - loss: 0.6367
Epoch 1 [79/172] - loss: 0.6022
Epoch 1 [80/172] - loss: 0.5842, acc: 0.7188
Epoch 1 [81/172] - loss: 0.5343
Epoch 1 [82/172] - loss: 0.9429
Epoch 1 [83/172] - loss: 0.6195
Epoch 1 [84/172] - loss: 0.7101
Epoch 1 [85/172] - loss: 0.8858
Epoch 1 [86/172] - loss: 0.8880
Epoch 1 [87/172] - loss: 0.5538
Epoch 1 [88/172] - loss: 0.8957
Epoch 1 [89/172] - loss: 1.0980
Epoch 1 [90/172] - loss: 0.9637, acc: 0.5312
Epoch 1 [91/172] - loss: 0.8249
Epoch 1 [92/172] - loss: 0.7399
Epoch 1 [93/172] - loss: 0.7263
Epoch 1 [94/172] - loss: 0.5671
Epoch 1 [95/172] - loss: 0.5250
Epoch 1 [96/172] - loss: 0.5745
Epoch 1 [97/172] - loss: 0.6349
Epoch 1 [98/172] - loss: 0.8179
Epoch 1 [99/172] - loss: 0.7907
Epoch 1 [100/172] - loss: 0.6529, acc: 0.8125

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5819, log_difficulty=0.4586, weight=3.2930
neutral: count=983.0, difficulty=0.5886, log_difficulty=0.4628, weight=3.3141
negative: count=1119.0, difficulty=0.5678, log_difficulty=0.4497, weight=3.2483

当前batch的pt分布：
positive: min=0.0570, max=0.8925, mean=0.4092
neutral: min=0.3933, max=0.9525, mean=0.6261
negative: min=0.0679, max=0.5766, mean=0.3604

当前batch准确率：
整体准确率: 0.5000
positive 准确率: 0.5000
neutral 准确率: 0.7500
negative 准确率: 0.4375

损失分量：
基础交叉熵: 1.0834
焦点损失: 0.4935
边界损失: 0.5164
总损失: 1.0653
Epoch 1 [101/172] - loss: 1.0653
Epoch 1 [102/172] - loss: 0.7375
Epoch 1 [103/172] - loss: 0.7170
Epoch 1 [104/172] - loss: 0.5852
Epoch 1 [105/172] - loss: 0.8011
Epoch 1 [106/172] - loss: 0.8976
Epoch 1 [107/172] - loss: 0.5355
Epoch 1 [108/172] - loss: 1.1247
Epoch 1 [109/172] - loss: 0.6955
Epoch 1 [110/172] - loss: 0.6850, acc: 0.7188
Epoch 1 [111/172] - loss: 0.6020
Epoch 1 [112/172] - loss: 0.5093
Epoch 1 [113/172] - loss: 0.4296
Epoch 1 [114/172] - loss: 0.6182
Epoch 1 [115/172] - loss: 0.6529
Epoch 1 [116/172] - loss: 0.6619
Epoch 1 [117/172] - loss: 0.7972
Epoch 1 [118/172] - loss: 0.5377
Epoch 1 [119/172] - loss: 1.0474
Epoch 1 [120/172] - loss: 0.5889, acc: 0.7188
Epoch 1 [121/172] - loss: 0.5300
Epoch 1 [122/172] - loss: 0.6423
Epoch 1 [123/172] - loss: 0.5510
Epoch 1 [124/172] - loss: 0.5918
Epoch 1 [125/172] - loss: 0.5894
Epoch 1 [126/172] - loss: 0.6993
Epoch 1 [127/172] - loss: 0.4854
Epoch 1 [128/172] - loss: 0.4809
Epoch 1 [129/172] - loss: 0.6094
Epoch 1 [130/172] - loss: 0.5218, acc: 0.7500
Epoch 1 [131/172] - loss: 0.4378
Epoch 1 [132/172] - loss: 0.6882
Epoch 1 [133/172] - loss: 0.6497
Epoch 1 [134/172] - loss: 0.6128
Epoch 1 [135/172] - loss: 0.6597
Epoch 1 [136/172] - loss: 0.4935
Epoch 1 [137/172] - loss: 0.7794
Epoch 1 [138/172] - loss: 0.6373
Epoch 1 [139/172] - loss: 0.5221
Epoch 1 [140/172] - loss: 0.5361, acc: 0.6250
Epoch 1 [141/172] - loss: 0.6361
Epoch 1 [142/172] - loss: 0.6250
Epoch 1 [143/172] - loss: 0.6737
Epoch 1 [144/172] - loss: 0.4961
Epoch 1 [145/172] - loss: 0.7023
Epoch 1 [146/172] - loss: 0.6638
Epoch 1 [147/172] - loss: 0.6730
Epoch 1 [148/172] - loss: 0.4895
Epoch 1 [149/172] - loss: 0.3586
Epoch 1 [150/172] - loss: 0.6363, acc: 0.5625
Epoch 1 [151/172] - loss: 0.6179
Epoch 1 [152/172] - loss: 0.5768
Epoch 1 [153/172] - loss: 0.7149
Epoch 1 [154/172] - loss: 0.5049
Epoch 1 [155/172] - loss: 0.4688
Epoch 1 [156/172] - loss: 0.6036
Epoch 1 [157/172] - loss: 0.6053
Epoch 1 [158/172] - loss: 0.4637
Epoch 1 [159/172] - loss: 0.8061
Epoch 1 [160/172] - loss: 0.4752, acc: 0.8125
Epoch 1 [161/172] - loss: 0.3222
Epoch 1 [162/172] - loss: 0.4551
Epoch 1 [163/172] - loss: 0.7040
Epoch 1 [164/172] - loss: 0.4910
Epoch 1 [165/172] - loss: 0.5958
Epoch 1 [166/172] - loss: 0.6124
Epoch 1 [167/172] - loss: 0.3751
Epoch 1 [168/172] - loss: 0.7275
Epoch 1 [169/172] - loss: 0.8325
Epoch 1 [170/172] - loss: 0.4190, acc: 0.7812
Epoch 1 [171/172] - loss: 0.3671
Epoch 1 [172/172] - loss: 0.5485

类别准确率:
positive: 0.7602 (355/467)
neutral: 0.4699 (39/83)
negative: 0.5960 (149/250)

Epoch 1/10
Train Loss: 0.5500, Train Acc: 0.7576
Val Loss: 0.7103, Val Acc: 0.6787
Epoch 2 [1/172] - loss: 0.4570, acc: 0.7188
Epoch 2 [2/172] - loss: 0.3683
Epoch 2 [3/172] - loss: 0.3441
Epoch 2 [4/172] - loss: 0.5031
Epoch 2 [5/172] - loss: 0.5015
Epoch 2 [6/172] - loss: 0.3768
Epoch 2 [7/172] - loss: 0.5776
Epoch 2 [8/172] - loss: 0.5962
Epoch 2 [9/172] - loss: 0.2998
Epoch 2 [10/172] - loss: 0.3850, acc: 0.8438
Epoch 2 [11/172] - loss: 0.3925
Epoch 2 [12/172] - loss: 0.3805
Epoch 2 [13/172] - loss: 0.5322
Epoch 2 [14/172] - loss: 0.4369
Epoch 2 [15/172] - loss: 0.4077
Epoch 2 [16/172] - loss: 0.3770
Epoch 2 [17/172] - loss: 0.4322
Epoch 2 [18/172] - loss: 0.6351
Epoch 2 [19/172] - loss: 0.4366
Epoch 2 [20/172] - loss: 0.4128, acc: 0.8750
Epoch 2 [21/172] - loss: 0.2904
Epoch 2 [22/172] - loss: 0.4172
Epoch 2 [23/172] - loss: 0.3253
Epoch 2 [24/172] - loss: 0.6823
Epoch 2 [25/172] - loss: 0.4233
Epoch 2 [26/172] - loss: 0.3181
Epoch 2 [27/172] - loss: 0.2753
Epoch 2 [28/172] - loss: 0.2851

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.5145, log_difficulty=0.4151, weight=3.0755
neutral: count=1952.0, difficulty=0.4770, log_difficulty=0.3900, weight=2.9502
negative: count=2216.0, difficulty=0.5054, log_difficulty=0.4091, weight=3.0453

当前batch的pt分布：
positive: min=0.1851, max=0.9319, mean=0.6375
neutral: min=0.3703, max=0.9508, mean=0.7847
negative: min=0.0408, max=0.9769, mean=0.6417

当前batch准确率：
整体准确率: 0.8125
positive 准确率: 0.6667
neutral 准确率: 0.9091
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.5066
焦点损失: 0.1944
边界损失: 0.3033
总损失: 0.4480
Epoch 2 [29/172] - loss: 0.4480
Epoch 2 [30/172] - loss: 0.4779, acc: 0.8125
Epoch 2 [31/172] - loss: 0.5531
Epoch 2 [32/172] - loss: 0.2771
Epoch 2 [33/172] - loss: 0.2713
Epoch 2 [34/172] - loss: 0.3839
Epoch 2 [35/172] - loss: 0.2974
Epoch 2 [36/172] - loss: 0.4995
Epoch 2 [37/172] - loss: 0.2961
Epoch 2 [38/172] - loss: 0.3510
Epoch 2 [39/172] - loss: 0.4353
Epoch 2 [40/172] - loss: 0.4025, acc: 0.7812
Epoch 2 [41/172] - loss: 0.3965
Epoch 2 [42/172] - loss: 0.2293
Epoch 2 [43/172] - loss: 0.2632
Epoch 2 [44/172] - loss: 0.3989
Epoch 2 [45/172] - loss: 0.3118
Epoch 2 [46/172] - loss: 0.3541
Epoch 2 [47/172] - loss: 0.4057
Epoch 2 [48/172] - loss: 0.4637
Epoch 2 [49/172] - loss: 0.4145
Epoch 2 [50/172] - loss: 0.4498, acc: 0.7188
Epoch 2 [51/172] - loss: 0.3929
Epoch 2 [52/172] - loss: 0.3994
Epoch 2 [53/172] - loss: 0.2881
Epoch 2 [54/172] - loss: 0.2519
Epoch 2 [55/172] - loss: 0.3055
Epoch 2 [56/172] - loss: 0.2565
Epoch 2 [57/172] - loss: 0.2473
Epoch 2 [58/172] - loss: 0.2598
Epoch 2 [59/172] - loss: 0.4203
Epoch 2 [60/172] - loss: 0.2678, acc: 0.8438
Epoch 2 [61/172] - loss: 0.1974
Epoch 2 [62/172] - loss: 0.1711
Epoch 2 [63/172] - loss: 0.3190
Epoch 2 [64/172] - loss: 0.2564
Epoch 2 [65/172] - loss: 0.3565
Epoch 2 [66/172] - loss: 0.2237
Epoch 2 [67/172] - loss: 0.2075
Epoch 2 [68/172] - loss: 0.3325
Epoch 2 [69/172] - loss: 0.2162
Epoch 2 [70/172] - loss: 0.4192, acc: 0.8125
Epoch 2 [71/172] - loss: 0.4250
Epoch 2 [72/172] - loss: 0.3112
Epoch 2 [73/172] - loss: 0.2939
Epoch 2 [74/172] - loss: 0.2192
Epoch 2 [75/172] - loss: 0.2456
Epoch 2 [76/172] - loss: 0.4272
Epoch 2 [77/172] - loss: 0.4934
Epoch 2 [78/172] - loss: 0.3020
Epoch 2 [79/172] - loss: 0.3088
Epoch 2 [80/172] - loss: 0.1990, acc: 0.9062
Epoch 2 [81/172] - loss: 0.2734
Epoch 2 [82/172] - loss: 0.2130
Epoch 2 [83/172] - loss: 0.2979
Epoch 2 [84/172] - loss: 0.3814
Epoch 2 [85/172] - loss: 0.3260
Epoch 2 [86/172] - loss: 0.3026
Epoch 2 [87/172] - loss: 0.5800
Epoch 2 [88/172] - loss: 0.2926
Epoch 2 [89/172] - loss: 0.2514
Epoch 2 [90/172] - loss: 0.3332, acc: 0.8125
Epoch 2 [91/172] - loss: 0.1702
Epoch 2 [92/172] - loss: 0.3144
Epoch 2 [93/172] - loss: 0.2066
Epoch 2 [94/172] - loss: 0.2428
Epoch 2 [95/172] - loss: 0.5511
Epoch 2 [96/172] - loss: 0.3413
Epoch 2 [97/172] - loss: 0.2067
Epoch 2 [98/172] - loss: 0.3449
Epoch 2 [99/172] - loss: 0.1311
Epoch 2 [100/172] - loss: 0.3058, acc: 0.8125
Epoch 2 [101/172] - loss: 0.2358
Epoch 2 [102/172] - loss: 0.1723
Epoch 2 [103/172] - loss: 0.2731
Epoch 2 [104/172] - loss: 0.2853
Epoch 2 [105/172] - loss: 0.3178
Epoch 2 [106/172] - loss: 0.2758
Epoch 2 [107/172] - loss: 0.2278
Epoch 2 [108/172] - loss: 0.5168
Epoch 2 [109/172] - loss: 0.1786
Epoch 2 [110/172] - loss: 0.2474, acc: 0.8125
Epoch 2 [111/172] - loss: 0.1685
Epoch 2 [112/172] - loss: 0.1720
Epoch 2 [113/172] - loss: 0.1824
Epoch 2 [114/172] - loss: 0.2768
Epoch 2 [115/172] - loss: 0.2010
Epoch 2 [116/172] - loss: 0.3808
Epoch 2 [117/172] - loss: 0.3600
Epoch 2 [118/172] - loss: 0.1805
Epoch 2 [119/172] - loss: 0.2428
Epoch 2 [120/172] - loss: 0.1954, acc: 0.9688
Epoch 2 [121/172] - loss: 0.3033
Epoch 2 [122/172] - loss: 0.5898
Epoch 2 [123/172] - loss: 0.1894
Epoch 2 [124/172] - loss: 0.2707
Epoch 2 [125/172] - loss: 0.1641
Epoch 2 [126/172] - loss: 0.2155
Epoch 2 [127/172] - loss: 0.2151
Epoch 2 [128/172] - loss: 0.2450

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4500, log_difficulty=0.3715, weight=2.8577
neutral: count=2949.0, difficulty=0.3791, log_difficulty=0.3215, weight=2.6073
negative: count=3294.0, difficulty=0.4396, log_difficulty=0.3644, weight=2.8220

当前batch的pt分布：
positive: min=0.2446, max=0.9750, mean=0.6589
neutral: min=0.4393, max=0.9795, mean=0.8438
negative: min=0.0966, max=0.9359, mean=0.6765

当前batch准确率：
整体准确率: 0.8125
positive 准确率: 0.7000
neutral 准确率: 0.9091
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.4125
焦点损失: 0.1288
边界损失: 0.2819
总损失: 0.3227
Epoch 2 [129/172] - loss: 0.3227
Epoch 2 [130/172] - loss: 0.3118, acc: 0.9375
Epoch 2 [131/172] - loss: 0.1682
Epoch 2 [132/172] - loss: 0.2740
Epoch 2 [133/172] - loss: 0.2663
Epoch 2 [134/172] - loss: 0.2485
Epoch 2 [135/172] - loss: 0.3789
Epoch 2 [136/172] - loss: 0.2614
Epoch 2 [137/172] - loss: 0.1789
Epoch 2 [138/172] - loss: 0.2453
Epoch 2 [139/172] - loss: 0.3651
Epoch 2 [140/172] - loss: 0.4164, acc: 0.7812
Epoch 2 [141/172] - loss: 0.4006
Epoch 2 [142/172] - loss: 0.2946
Epoch 2 [143/172] - loss: 0.3393
Epoch 2 [144/172] - loss: 0.1950
Epoch 2 [145/172] - loss: 0.6547
Epoch 2 [146/172] - loss: 0.2804
Epoch 2 [147/172] - loss: 0.2231
Epoch 2 [148/172] - loss: 0.3418
Epoch 2 [149/172] - loss: 0.2063
Epoch 2 [150/172] - loss: 0.2427, acc: 0.9062
Epoch 2 [151/172] - loss: 0.3763
Epoch 2 [152/172] - loss: 0.2263
Epoch 2 [153/172] - loss: 0.2279
Epoch 2 [154/172] - loss: 0.2248
Epoch 2 [155/172] - loss: 0.2531
Epoch 2 [156/172] - loss: 0.2890
Epoch 2 [157/172] - loss: 0.1597
Epoch 2 [158/172] - loss: 0.2720
Epoch 2 [159/172] - loss: 0.3270
Epoch 2 [160/172] - loss: 0.1453, acc: 0.9688
Epoch 2 [161/172] - loss: 0.2686
Epoch 2 [162/172] - loss: 0.1781
Epoch 2 [163/172] - loss: 0.3809
Epoch 2 [164/172] - loss: 0.3008
Epoch 2 [165/172] - loss: 0.4296
Epoch 2 [166/172] - loss: 0.5129
Epoch 2 [167/172] - loss: 0.4686
Epoch 2 [168/172] - loss: 0.1935
Epoch 2 [169/172] - loss: 0.1776
Epoch 2 [170/172] - loss: 0.2369, acc: 0.9062
Epoch 2 [171/172] - loss: 0.3873
Epoch 2 [172/172] - loss: 0.8002

类别准确率:
positive: 0.8480 (396/467)
neutral: 0.3373 (28/83)
negative: 0.5560 (139/250)

Epoch 2/10
Train Loss: 0.3274, Train Acc: 0.8869
Val Loss: 0.6861, Val Acc: 0.7037
Epoch 3 [1/172] - loss: 0.1961, acc: 0.8750
Epoch 3 [2/172] - loss: 0.2757
Epoch 3 [3/172] - loss: 0.1260
Epoch 3 [4/172] - loss: 0.1734
Epoch 3 [5/172] - loss: 0.1723
Epoch 3 [6/172] - loss: 0.1809
Epoch 3 [7/172] - loss: 0.1883
Epoch 3 [8/172] - loss: 0.2286
Epoch 3 [9/172] - loss: 0.1756
Epoch 3 [10/172] - loss: 0.1269, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1339
Epoch 3 [12/172] - loss: 0.1346
Epoch 3 [13/172] - loss: 0.1532
Epoch 3 [14/172] - loss: 0.1051
Epoch 3 [15/172] - loss: 0.1111
Epoch 3 [16/172] - loss: 0.3123
Epoch 3 [17/172] - loss: 0.2280
Epoch 3 [18/172] - loss: 0.2171
Epoch 3 [19/172] - loss: 0.1701
Epoch 3 [20/172] - loss: 0.1290, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1374
Epoch 3 [22/172] - loss: 0.1688
Epoch 3 [23/172] - loss: 0.1534
Epoch 3 [24/172] - loss: 0.2318
Epoch 3 [25/172] - loss: 0.1292
Epoch 3 [26/172] - loss: 0.1291
Epoch 3 [27/172] - loss: 0.1297
Epoch 3 [28/172] - loss: 0.1385
Epoch 3 [29/172] - loss: 0.2669
Epoch 3 [30/172] - loss: 0.1679, acc: 0.9375
Epoch 3 [31/172] - loss: 0.1583
Epoch 3 [32/172] - loss: 0.1719
Epoch 3 [33/172] - loss: 0.1844
Epoch 3 [34/172] - loss: 0.1402
Epoch 3 [35/172] - loss: 0.1603
Epoch 3 [36/172] - loss: 0.1423
Epoch 3 [37/172] - loss: 0.2551
Epoch 3 [38/172] - loss: 0.1779
Epoch 3 [39/172] - loss: 0.1283
Epoch 3 [40/172] - loss: 0.1334, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1706
Epoch 3 [42/172] - loss: 0.1211
Epoch 3 [43/172] - loss: 0.1306
Epoch 3 [44/172] - loss: 0.0998
Epoch 3 [45/172] - loss: 0.1279
Epoch 3 [46/172] - loss: 0.1515
Epoch 3 [47/172] - loss: 0.1010
Epoch 3 [48/172] - loss: 0.1359
Epoch 3 [49/172] - loss: 0.1211
Epoch 3 [50/172] - loss: 0.1832, acc: 0.9375
Epoch 3 [51/172] - loss: 0.2143
Epoch 3 [52/172] - loss: 0.2229
Epoch 3 [53/172] - loss: 0.1525
Epoch 3 [54/172] - loss: 0.1777
Epoch 3 [55/172] - loss: 0.1928
Epoch 3 [56/172] - loss: 0.1183

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3918, log_difficulty=0.3306, weight=2.6529
neutral: count=3923.0, difficulty=0.3235, log_difficulty=0.2803, weight=2.4013
negative: count=4382.0, difficulty=0.3848, log_difficulty=0.3256, weight=2.6279

当前batch的pt分布：
positive: min=0.3070, max=0.9765, mean=0.8100
neutral: min=0.0232, max=0.9921, mean=0.7221
negative: min=0.9624, max=0.9910, mean=0.9811

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9091
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3467
焦点损失: 0.1476
边界损失: 0.2426
总损失: 0.3013
Epoch 3 [57/172] - loss: 0.3013
Epoch 3 [58/172] - loss: 0.1723
Epoch 3 [59/172] - loss: 0.1299
Epoch 3 [60/172] - loss: 0.2240, acc: 0.9375
Epoch 3 [61/172] - loss: 0.2682
Epoch 3 [62/172] - loss: 0.1236
Epoch 3 [63/172] - loss: 0.1103
Epoch 3 [64/172] - loss: 0.1944
Epoch 3 [65/172] - loss: 0.1831
Epoch 3 [66/172] - loss: 0.2863
Epoch 3 [67/172] - loss: 0.1746
Epoch 3 [68/172] - loss: 0.1393
Epoch 3 [69/172] - loss: 0.2597
Epoch 3 [70/172] - loss: 0.1247, acc: 0.9375
Epoch 3 [71/172] - loss: 0.1594
Epoch 3 [72/172] - loss: 0.1517
Epoch 3 [73/172] - loss: 0.1393
Epoch 3 [74/172] - loss: 0.1986
Epoch 3 [75/172] - loss: 0.1323
Epoch 3 [76/172] - loss: 0.2214
Epoch 3 [77/172] - loss: 0.1418
Epoch 3 [78/172] - loss: 0.2831
Epoch 3 [79/172] - loss: 0.1251
Epoch 3 [80/172] - loss: 0.2973, acc: 0.8125
Epoch 3 [81/172] - loss: 0.1558
Epoch 3 [82/172] - loss: 0.1422
Epoch 3 [83/172] - loss: 0.1590
Epoch 3 [84/172] - loss: 0.0958
Epoch 3 [85/172] - loss: 0.1552
Epoch 3 [86/172] - loss: 0.1075
Epoch 3 [87/172] - loss: 0.1465
Epoch 3 [88/172] - loss: 0.1308
Epoch 3 [89/172] - loss: 0.1235
Epoch 3 [90/172] - loss: 0.1182, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1900
Epoch 3 [92/172] - loss: 0.2514
Epoch 3 [93/172] - loss: 0.2002
Epoch 3 [94/172] - loss: 0.1567
Epoch 3 [95/172] - loss: 0.0995
Epoch 3 [96/172] - loss: 0.1547
Epoch 3 [97/172] - loss: 0.1692
Epoch 3 [98/172] - loss: 0.0986
Epoch 3 [99/172] - loss: 0.1107
Epoch 3 [100/172] - loss: 0.1592, acc: 0.9375
Epoch 3 [101/172] - loss: 0.1456
Epoch 3 [102/172] - loss: 0.0981
Epoch 3 [103/172] - loss: 0.2358
Epoch 3 [104/172] - loss: 0.1950
Epoch 3 [105/172] - loss: 0.1122
Epoch 3 [106/172] - loss: 0.1308
Epoch 3 [107/172] - loss: 0.1143
Epoch 3 [108/172] - loss: 0.1091
Epoch 3 [109/172] - loss: 0.0930
Epoch 3 [110/172] - loss: 0.1219, acc: 1.0000
Epoch 3 [111/172] - loss: 0.1805
Epoch 3 [112/172] - loss: 0.1086
Epoch 3 [113/172] - loss: 0.1106
Epoch 3 [114/172] - loss: 0.1686
Epoch 3 [115/172] - loss: 0.1804
Epoch 3 [116/172] - loss: 0.1193
Epoch 3 [117/172] - loss: 0.1116
Epoch 3 [118/172] - loss: 0.1040
Epoch 3 [119/172] - loss: 0.1276
Epoch 3 [120/172] - loss: 0.2418, acc: 0.9375
Epoch 3 [121/172] - loss: 0.2119
Epoch 3 [122/172] - loss: 0.2151
Epoch 3 [123/172] - loss: 0.2933
Epoch 3 [124/172] - loss: 0.1475
Epoch 3 [125/172] - loss: 0.1151
Epoch 3 [126/172] - loss: 0.3883
Epoch 3 [127/172] - loss: 0.1157
Epoch 3 [128/172] - loss: 0.1163
Epoch 3 [129/172] - loss: 0.1293
Epoch 3 [130/172] - loss: 0.1368, acc: 0.9375
Epoch 3 [131/172] - loss: 0.2416
Epoch 3 [132/172] - loss: 0.1054
Epoch 3 [133/172] - loss: 0.1506
Epoch 3 [134/172] - loss: 0.1019
Epoch 3 [135/172] - loss: 0.1418
Epoch 3 [136/172] - loss: 0.1855
Epoch 3 [137/172] - loss: 0.1108
Epoch 3 [138/172] - loss: 0.1212
Epoch 3 [139/172] - loss: 0.1570
Epoch 3 [140/172] - loss: 0.1255, acc: 1.0000
Epoch 3 [141/172] - loss: 0.2951
Epoch 3 [142/172] - loss: 0.1787
Epoch 3 [143/172] - loss: 0.1371
Epoch 3 [144/172] - loss: 0.2903
Epoch 3 [145/172] - loss: 0.1434
Epoch 3 [146/172] - loss: 0.1134
Epoch 3 [147/172] - loss: 0.1361
Epoch 3 [148/172] - loss: 0.2282
Epoch 3 [149/172] - loss: 0.1594
Epoch 3 [150/172] - loss: 0.1945, acc: 0.9375
Epoch 3 [151/172] - loss: 0.2696
Epoch 3 [152/172] - loss: 0.2611
Epoch 3 [153/172] - loss: 0.1353
Epoch 3 [154/172] - loss: 0.2414
Epoch 3 [155/172] - loss: 0.1218
Epoch 3 [156/172] - loss: 0.1240

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.3450, log_difficulty=0.2964, weight=2.4819
neutral: count=4903.0, difficulty=0.2781, log_difficulty=0.2453, weight=2.2267
negative: count=5500.0, difficulty=0.3403, log_difficulty=0.2929, weight=2.4645

当前batch的pt分布：
positive: min=0.5865, max=0.9801, mean=0.8703
neutral: min=0.8815, max=0.9860, mean=0.9578
negative: min=0.3096, max=0.9981, mean=0.8022

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1496
焦点损失: 0.0206
边界损失: 0.2031
总损失: 0.1269
Epoch 3 [157/172] - loss: 0.1269
Epoch 3 [158/172] - loss: 0.1751
Epoch 3 [159/172] - loss: 0.2191
Epoch 3 [160/172] - loss: 0.2131, acc: 0.9062
Epoch 3 [161/172] - loss: 0.4491
Epoch 3 [162/172] - loss: 0.1916
Epoch 3 [163/172] - loss: 0.2273
Epoch 3 [164/172] - loss: 0.0918
Epoch 3 [165/172] - loss: 0.1062
Epoch 3 [166/172] - loss: 0.1507
Epoch 3 [167/172] - loss: 0.1657
Epoch 3 [168/172] - loss: 0.1395
Epoch 3 [169/172] - loss: 0.1009
Epoch 3 [170/172] - loss: 0.1232, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1334
Epoch 3 [172/172] - loss: 0.0871

类别准确率:
positive: 0.7880 (368/467)
neutral: 0.2048 (17/83)
negative: 0.6800 (170/250)

Epoch 3/10
Train Loss: 0.1688, Train Acc: 0.9475
Val Loss: 0.7692, Val Acc: 0.6937
Epoch 4 [1/172] - loss: 0.0950, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1125
Epoch 4 [3/172] - loss: 0.1147
Epoch 4 [4/172] - loss: 0.1152
Epoch 4 [5/172] - loss: 0.1196
Epoch 4 [6/172] - loss: 0.0866
Epoch 4 [7/172] - loss: 0.1196
Epoch 4 [8/172] - loss: 0.0865
Epoch 4 [9/172] - loss: 0.1804
Epoch 4 [10/172] - loss: 0.1294, acc: 0.9688
Epoch 4 [11/172] - loss: 0.0873
Epoch 4 [12/172] - loss: 0.0984
Epoch 4 [13/172] - loss: 0.1349
Epoch 4 [14/172] - loss: 0.1469
Epoch 4 [15/172] - loss: 0.1833
Epoch 4 [16/172] - loss: 0.1155
Epoch 4 [17/172] - loss: 0.1529
Epoch 4 [18/172] - loss: 0.2049
Epoch 4 [19/172] - loss: 0.0906
Epoch 4 [20/172] - loss: 0.1017, acc: 0.9688
Epoch 4 [21/172] - loss: 0.1601
Epoch 4 [22/172] - loss: 0.0935
Epoch 4 [23/172] - loss: 0.1162
Epoch 4 [24/172] - loss: 0.0864
Epoch 4 [25/172] - loss: 0.0907
Epoch 4 [26/172] - loss: 0.3536
Epoch 4 [27/172] - loss: 0.0835
Epoch 4 [28/172] - loss: 0.1163
Epoch 4 [29/172] - loss: 0.0883
Epoch 4 [30/172] - loss: 0.1443, acc: 0.9375
Epoch 4 [31/172] - loss: 0.1955
Epoch 4 [32/172] - loss: 0.1359
Epoch 4 [33/172] - loss: 0.1221
Epoch 4 [34/172] - loss: 0.1167
Epoch 4 [35/172] - loss: 0.1026
Epoch 4 [36/172] - loss: 0.1017
Epoch 4 [37/172] - loss: 0.0838
Epoch 4 [38/172] - loss: 0.1028
Epoch 4 [39/172] - loss: 0.1531
Epoch 4 [40/172] - loss: 0.1903, acc: 0.9062
Epoch 4 [41/172] - loss: 0.1200
Epoch 4 [42/172] - loss: 0.1313
Epoch 4 [43/172] - loss: 0.1486
Epoch 4 [44/172] - loss: 0.1175
Epoch 4 [45/172] - loss: 0.0872
Epoch 4 [46/172] - loss: 0.0890
Epoch 4 [47/172] - loss: 0.1401
Epoch 4 [48/172] - loss: 0.2310
Epoch 4 [49/172] - loss: 0.0887
Epoch 4 [50/172] - loss: 0.2025, acc: 0.9688
Epoch 4 [51/172] - loss: 0.0867
Epoch 4 [52/172] - loss: 0.1114
Epoch 4 [53/172] - loss: 0.0863
Epoch 4 [54/172] - loss: 0.1228
Epoch 4 [55/172] - loss: 0.2365
Epoch 4 [56/172] - loss: 0.0999
Epoch 4 [57/172] - loss: 0.0997
Epoch 4 [58/172] - loss: 0.1041
Epoch 4 [59/172] - loss: 0.1088
Epoch 4 [60/172] - loss: 0.0967, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1008
Epoch 4 [62/172] - loss: 0.1223
Epoch 4 [63/172] - loss: 0.0965
Epoch 4 [64/172] - loss: 0.0881
Epoch 4 [65/172] - loss: 0.1312
Epoch 4 [66/172] - loss: 0.0892
Epoch 4 [67/172] - loss: 0.0945
Epoch 4 [68/172] - loss: 0.1043
Epoch 4 [69/172] - loss: 0.0893
Epoch 4 [70/172] - loss: 0.0875, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1150
Epoch 4 [72/172] - loss: 0.0860
Epoch 4 [73/172] - loss: 0.0912
Epoch 4 [74/172] - loss: 0.2512
Epoch 4 [75/172] - loss: 0.1542
Epoch 4 [76/172] - loss: 0.0865
Epoch 4 [77/172] - loss: 0.1046
Epoch 4 [78/172] - loss: 0.1065
Epoch 4 [79/172] - loss: 0.0870
Epoch 4 [80/172] - loss: 0.0875, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1129
Epoch 4 [82/172] - loss: 0.1062
Epoch 4 [83/172] - loss: 0.0910
Epoch 4 [84/172] - loss: 0.0852

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.3073, log_difficulty=0.2680, weight=2.3398
neutral: count=5865.0, difficulty=0.2454, log_difficulty=0.2195, weight=2.0973
negative: count=6629.0, difficulty=0.3023, log_difficulty=0.2642, weight=2.3208

当前batch的pt分布：
positive: min=0.3773, max=0.9753, mean=0.8105
neutral: min=0.9799, max=0.9989, mean=0.9903
negative: min=0.6517, max=0.9965, mean=0.9349

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1436
焦点损失: 0.0193
边界损失: 0.2004
总损失: 0.1228
Epoch 4 [85/172] - loss: 0.1228
Epoch 4 [86/172] - loss: 0.1619
Epoch 4 [87/172] - loss: 0.0890
Epoch 4 [88/172] - loss: 0.0806
Epoch 4 [89/172] - loss: 0.0979
Epoch 4 [90/172] - loss: 0.0887, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1862
Epoch 4 [92/172] - loss: 0.1535
Epoch 4 [93/172] - loss: 0.0802
Epoch 4 [94/172] - loss: 0.0977
Epoch 4 [95/172] - loss: 0.1978
Epoch 4 [96/172] - loss: 0.0970
Epoch 4 [97/172] - loss: 0.0962
Epoch 4 [98/172] - loss: 0.1061
Epoch 4 [99/172] - loss: 0.0863
Epoch 4 [100/172] - loss: 0.0837, acc: 1.0000
Epoch 4 [101/172] - loss: 0.0801
Epoch 4 [102/172] - loss: 0.0816
Epoch 4 [103/172] - loss: 0.2036
Epoch 4 [104/172] - loss: 0.2133
Epoch 4 [105/172] - loss: 0.1782
Epoch 4 [106/172] - loss: 0.1392
Epoch 4 [107/172] - loss: 0.0898
Epoch 4 [108/172] - loss: 0.1538
Epoch 4 [109/172] - loss: 0.1136
Epoch 4 [110/172] - loss: 0.2578, acc: 0.9062
Epoch 4 [111/172] - loss: 0.2328
Epoch 4 [112/172] - loss: 0.0945
Epoch 4 [113/172] - loss: 0.1120
Epoch 4 [114/172] - loss: 0.0919
Epoch 4 [115/172] - loss: 0.0987
Epoch 4 [116/172] - loss: 0.1355
Epoch 4 [117/172] - loss: 0.0901
Epoch 4 [118/172] - loss: 0.1066
Epoch 4 [119/172] - loss: 0.0968
Epoch 4 [120/172] - loss: 0.1067, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1243
Epoch 4 [122/172] - loss: 0.1700
Epoch 4 [123/172] - loss: 0.1009
Epoch 4 [124/172] - loss: 0.0980
Epoch 4 [125/172] - loss: 0.1559
Epoch 4 [126/172] - loss: 0.1778
Epoch 4 [127/172] - loss: 0.1784
Epoch 4 [128/172] - loss: 0.1088
Epoch 4 [129/172] - loss: 0.0969
Epoch 4 [130/172] - loss: 0.1279, acc: 0.9688
Epoch 4 [131/172] - loss: 0.1050
Epoch 4 [132/172] - loss: 0.0878
Epoch 4 [133/172] - loss: 0.1309
Epoch 4 [134/172] - loss: 0.0930
Epoch 4 [135/172] - loss: 0.1371
Epoch 4 [136/172] - loss: 0.1711
Epoch 4 [137/172] - loss: 0.2010
Epoch 4 [138/172] - loss: 0.0885
Epoch 4 [139/172] - loss: 0.0962
Epoch 4 [140/172] - loss: 0.0890, acc: 1.0000
Epoch 4 [141/172] - loss: 0.0897
Epoch 4 [142/172] - loss: 0.1363
Epoch 4 [143/172] - loss: 0.1135
Epoch 4 [144/172] - loss: 0.0964
Epoch 4 [145/172] - loss: 0.1765
Epoch 4 [146/172] - loss: 0.1456
Epoch 4 [147/172] - loss: 0.1948
Epoch 4 [148/172] - loss: 0.1043
Epoch 4 [149/172] - loss: 0.1175
Epoch 4 [150/172] - loss: 0.1726, acc: 0.9375
Epoch 4 [151/172] - loss: 0.2377
Epoch 4 [152/172] - loss: 0.1541
Epoch 4 [153/172] - loss: 0.0879
Epoch 4 [154/172] - loss: 0.1866
Epoch 4 [155/172] - loss: 0.1291
Epoch 4 [156/172] - loss: 0.1174
Epoch 4 [157/172] - loss: 0.1768
Epoch 4 [158/172] - loss: 0.1549
Epoch 4 [159/172] - loss: 0.0840
Epoch 4 [160/172] - loss: 0.1037, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1680
Epoch 4 [162/172] - loss: 0.1571
Epoch 4 [163/172] - loss: 0.1215
Epoch 4 [164/172] - loss: 0.1089
Epoch 4 [165/172] - loss: 0.1545
Epoch 4 [166/172] - loss: 0.0977
Epoch 4 [167/172] - loss: 0.1365
Epoch 4 [168/172] - loss: 0.1022
Epoch 4 [169/172] - loss: 0.2032
Epoch 4 [170/172] - loss: 0.1116, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1183
Epoch 4 [172/172] - loss: 0.1081

类别准确率:
positive: 0.6852 (320/467)
neutral: 0.5060 (42/83)
negative: 0.7480 (187/250)

Epoch 4/10
Train Loss: 0.1317, Train Acc: 0.9596
Val Loss: 0.8427, Val Acc: 0.6863
Epoch 5 [1/172] - loss: 0.1189, acc: 0.9688
Epoch 5 [2/172] - loss: 0.1078
Epoch 5 [3/172] - loss: 0.0874
Epoch 5 [4/172] - loss: 0.1079
Epoch 5 [5/172] - loss: 0.0892
Epoch 5 [6/172] - loss: 0.1578
Epoch 5 [7/172] - loss: 0.1299
Epoch 5 [8/172] - loss: 0.1117
Epoch 5 [9/172] - loss: 0.1977
Epoch 5 [10/172] - loss: 0.0854, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1604
Epoch 5 [12/172] - loss: 0.0793

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2788, log_difficulty=0.2460, weight=2.2298
neutral: count=6845.0, difficulty=0.2200, log_difficulty=0.1989, weight=1.9944
negative: count=7694.0, difficulty=0.2769, log_difficulty=0.2444, weight=2.2221

当前batch的pt分布：
positive: min=0.3758, max=0.9989, mean=0.8827
neutral: min=0.9051, max=0.9984, mean=0.9784
negative: min=0.8340, max=0.9860, mean=0.9317

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0942
焦点损失: 0.0113
边界损失: 0.1744
总损失: 0.0998
Epoch 5 [13/172] - loss: 0.0998
Epoch 5 [14/172] - loss: 0.1589
Epoch 5 [15/172] - loss: 0.0817
Epoch 5 [16/172] - loss: 0.0859
Epoch 5 [17/172] - loss: 0.1441
Epoch 5 [18/172] - loss: 0.1061
Epoch 5 [19/172] - loss: 0.1001
Epoch 5 [20/172] - loss: 0.1571, acc: 0.9375
Epoch 5 [21/172] - loss: 0.1150
Epoch 5 [22/172] - loss: 0.1009
Epoch 5 [23/172] - loss: 0.0975
Epoch 5 [24/172] - loss: 0.0956
Epoch 5 [25/172] - loss: 0.0827
Epoch 5 [26/172] - loss: 0.0973
Epoch 5 [27/172] - loss: 0.0870
Epoch 5 [28/172] - loss: 0.0812
Epoch 5 [29/172] - loss: 0.0915
Epoch 5 [30/172] - loss: 0.1341, acc: 0.9688
Epoch 5 [31/172] - loss: 0.0877
Epoch 5 [32/172] - loss: 0.0840
Epoch 5 [33/172] - loss: 0.0934
Epoch 5 [34/172] - loss: 0.0835
Epoch 5 [35/172] - loss: 0.0829
Epoch 5 [36/172] - loss: 0.0837
Epoch 5 [37/172] - loss: 0.0841
Epoch 5 [38/172] - loss: 0.0838
Epoch 5 [39/172] - loss: 0.1382
Epoch 5 [40/172] - loss: 0.0906, acc: 1.0000
Epoch 5 [41/172] - loss: 0.0903
Epoch 5 [42/172] - loss: 0.0871
Epoch 5 [43/172] - loss: 0.1184
Epoch 5 [44/172] - loss: 0.0972
Epoch 5 [45/172] - loss: 0.0809
Epoch 5 [46/172] - loss: 0.1107
Epoch 5 [47/172] - loss: 0.0823
Epoch 5 [48/172] - loss: 0.1041
Epoch 5 [49/172] - loss: 0.0850
Epoch 5 [50/172] - loss: 0.1331, acc: 0.9688
Epoch 5 [51/172] - loss: 0.1070
Epoch 5 [52/172] - loss: 0.0873
Epoch 5 [53/172] - loss: 0.1118
Epoch 5 [54/172] - loss: 0.0883
Epoch 5 [55/172] - loss: 0.1034
Epoch 5 [56/172] - loss: 0.1228
Epoch 5 [57/172] - loss: 0.0921
Epoch 5 [58/172] - loss: 0.0801
Epoch 5 [59/172] - loss: 0.1044
Epoch 5 [60/172] - loss: 0.1501, acc: 0.9688
Epoch 5 [61/172] - loss: 0.0976
Epoch 5 [62/172] - loss: 0.0855
Epoch 5 [63/172] - loss: 0.1178
Epoch 5 [64/172] - loss: 0.0917
Epoch 5 [65/172] - loss: 0.0845
Epoch 5 [66/172] - loss: 0.0833
Epoch 5 [67/172] - loss: 0.0804
Epoch 5 [68/172] - loss: 0.0901
Epoch 5 [69/172] - loss: 0.0817
Epoch 5 [70/172] - loss: 0.0782, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1273
Epoch 5 [72/172] - loss: 0.1061
Epoch 5 [73/172] - loss: 0.0837
Epoch 5 [74/172] - loss: 0.1096
Epoch 5 [75/172] - loss: 0.0837
Epoch 5 [76/172] - loss: 0.0796
Epoch 5 [77/172] - loss: 0.0943
Epoch 5 [78/172] - loss: 0.1565
Epoch 5 [79/172] - loss: 0.0810
Epoch 5 [80/172] - loss: 0.0853, acc: 1.0000
Epoch 5 [81/172] - loss: 0.0956
Epoch 5 [82/172] - loss: 0.1173
Epoch 5 [83/172] - loss: 0.0853
Epoch 5 [84/172] - loss: 0.0791
Epoch 5 [85/172] - loss: 0.1357
Epoch 5 [86/172] - loss: 0.0838
Epoch 5 [87/172] - loss: 0.1384
Epoch 5 [88/172] - loss: 0.1103
Epoch 5 [89/172] - loss: 0.0904
Epoch 5 [90/172] - loss: 0.1226, acc: 0.9688
Epoch 5 [91/172] - loss: 0.0891
Epoch 5 [92/172] - loss: 0.0802
Epoch 5 [93/172] - loss: 0.0817
Epoch 5 [94/172] - loss: 0.0777
Epoch 5 [95/172] - loss: 0.0911
Epoch 5 [96/172] - loss: 0.0960
Epoch 5 [97/172] - loss: 0.1101
Epoch 5 [98/172] - loss: 0.0968
Epoch 5 [99/172] - loss: 0.2128
Epoch 5 [100/172] - loss: 0.0852, acc: 1.0000
Epoch 5 [101/172] - loss: 0.0973
Epoch 5 [102/172] - loss: 0.0840
Epoch 5 [103/172] - loss: 0.0852
Epoch 5 [104/172] - loss: 0.1095
Epoch 5 [105/172] - loss: 0.1728
Epoch 5 [106/172] - loss: 0.0879
Epoch 5 [107/172] - loss: 0.0838
Epoch 5 [108/172] - loss: 0.0990
Epoch 5 [109/172] - loss: 0.0835
Epoch 5 [110/172] - loss: 0.0808, acc: 1.0000
Epoch 5 [111/172] - loss: 0.0866
Epoch 5 [112/172] - loss: 0.0810

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2526, log_difficulty=0.2252, weight=2.1261
neutral: count=7825.0, difficulty=0.1998, log_difficulty=0.1822, weight=1.9108
negative: count=8780.0, difficulty=0.2531, log_difficulty=0.2256, weight=2.1281

当前batch的pt分布：
positive: min=0.4806, max=0.9809, mean=0.8734
neutral: min=0.8103, max=0.9967, mean=0.9312
negative: min=0.9930, max=0.9990, mean=0.9967

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1007
焦点损失: 0.0079
边界损失: 0.1843
总损失: 0.1005
Epoch 5 [113/172] - loss: 0.1005
Epoch 5 [114/172] - loss: 0.0840
Epoch 5 [115/172] - loss: 0.1328
Epoch 5 [116/172] - loss: 0.0829
Epoch 5 [117/172] - loss: 0.0801
Epoch 5 [118/172] - loss: 0.0771
Epoch 5 [119/172] - loss: 0.0851
Epoch 5 [120/172] - loss: 0.0791, acc: 1.0000
Epoch 5 [121/172] - loss: 0.1039
Epoch 5 [122/172] - loss: 0.0799
Epoch 5 [123/172] - loss: 0.0932
Epoch 5 [124/172] - loss: 0.0810
Epoch 5 [125/172] - loss: 0.0980
Epoch 5 [126/172] - loss: 0.0787
Epoch 5 [127/172] - loss: 0.0876
Epoch 5 [128/172] - loss: 0.0782
Epoch 5 [129/172] - loss: 0.1287
Epoch 5 [130/172] - loss: 0.0787, acc: 1.0000
Epoch 5 [131/172] - loss: 0.0950
Epoch 5 [132/172] - loss: 0.1071
Epoch 5 [133/172] - loss: 0.1800
Epoch 5 [134/172] - loss: 0.2633
Epoch 5 [135/172] - loss: 0.0820
Epoch 5 [136/172] - loss: 0.0807
Epoch 5 [137/172] - loss: 0.1088
Epoch 5 [138/172] - loss: 0.1107
Epoch 5 [139/172] - loss: 0.2029
Epoch 5 [140/172] - loss: 0.1080, acc: 0.9688
Epoch 5 [141/172] - loss: 0.1405
Epoch 5 [142/172] - loss: 0.0863
Epoch 5 [143/172] - loss: 0.0772
Epoch 5 [144/172] - loss: 0.0799
Epoch 5 [145/172] - loss: 0.0865
Epoch 5 [146/172] - loss: 0.0800
Epoch 5 [147/172] - loss: 0.1115
Epoch 5 [148/172] - loss: 0.0796
Epoch 5 [149/172] - loss: 0.0924
Epoch 5 [150/172] - loss: 0.1264, acc: 0.9688
Epoch 5 [151/172] - loss: 0.0791
Epoch 5 [152/172] - loss: 0.0768
Epoch 5 [153/172] - loss: 0.0790
Epoch 5 [154/172] - loss: 0.0878
Epoch 5 [155/172] - loss: 0.1052
Epoch 5 [156/172] - loss: 0.0875
Epoch 5 [157/172] - loss: 0.0789
Epoch 5 [158/172] - loss: 0.0874
Epoch 5 [159/172] - loss: 0.0931
Epoch 5 [160/172] - loss: 0.0808, acc: 1.0000
Epoch 5 [161/172] - loss: 0.0868
Epoch 5 [162/172] - loss: 0.1096
Epoch 5 [163/172] - loss: 0.1402
Epoch 5 [164/172] - loss: 0.0769
Epoch 5 [165/172] - loss: 0.1298
Epoch 5 [166/172] - loss: 0.0858
Epoch 5 [167/172] - loss: 0.0971
Epoch 5 [168/172] - loss: 0.0780
Epoch 5 [169/172] - loss: 0.0826
Epoch 5 [170/172] - loss: 0.0803, acc: 1.0000
Epoch 5 [171/172] - loss: 0.0827
Epoch 5 [172/172] - loss: 0.0951

类别准确率:
positive: 0.8480 (396/467)
neutral: 0.2651 (22/83)
negative: 0.6160 (154/250)

Epoch 5/10
Train Loss: 0.0928, Train Acc: 0.9899
Val Loss: 0.7864, Val Acc: 0.7150
Epoch 6 [1/172] - loss: 0.1072, acc: 1.0000
Epoch 6 [2/172] - loss: 0.0979
Epoch 6 [3/172] - loss: 0.0766
Epoch 6 [4/172] - loss: 0.0828
Epoch 6 [5/172] - loss: 0.0828
Epoch 6 [6/172] - loss: 0.0788
Epoch 6 [7/172] - loss: 0.0835
Epoch 6 [8/172] - loss: 0.0855
Epoch 6 [9/172] - loss: 0.0761
Epoch 6 [10/172] - loss: 0.0832, acc: 1.0000
Epoch 6 [11/172] - loss: 0.0775
Epoch 6 [12/172] - loss: 0.0758
Epoch 6 [13/172] - loss: 0.0844
Epoch 6 [14/172] - loss: 0.0767
Epoch 6 [15/172] - loss: 0.0830
Epoch 6 [16/172] - loss: 0.0878
Epoch 6 [17/172] - loss: 0.0772
Epoch 6 [18/172] - loss: 0.0778
Epoch 6 [19/172] - loss: 0.0798
Epoch 6 [20/172] - loss: 0.0802, acc: 1.0000
Epoch 6 [21/172] - loss: 0.0946
Epoch 6 [22/172] - loss: 0.0979
Epoch 6 [23/172] - loss: 0.0811
Epoch 6 [24/172] - loss: 0.0877
Epoch 6 [25/172] - loss: 0.0784
Epoch 6 [26/172] - loss: 0.1288
Epoch 6 [27/172] - loss: 0.0933
Epoch 6 [28/172] - loss: 0.0808
Epoch 6 [29/172] - loss: 0.0762
Epoch 6 [30/172] - loss: 0.0789, acc: 1.0000
Epoch 6 [31/172] - loss: 0.0755
Epoch 6 [32/172] - loss: 0.0755
Epoch 6 [33/172] - loss: 0.0837
Epoch 6 [34/172] - loss: 0.0816
Epoch 6 [35/172] - loss: 0.0768
Epoch 6 [36/172] - loss: 0.0906
Epoch 6 [37/172] - loss: 0.0820
Epoch 6 [38/172] - loss: 0.0772
Epoch 6 [39/172] - loss: 0.0820
Epoch 6 [40/172] - loss: 0.1179, acc: 0.9375

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.2310, log_difficulty=0.2078, weight=2.0390
neutral: count=8815.0, difficulty=0.1835, log_difficulty=0.1684, weight=1.8422
negative: count=9870.0, difficulty=0.2320, log_difficulty=0.2086, weight=2.0431

当前batch的pt分布：
positive: min=0.3608, max=0.9966, mean=0.9246
neutral: min=0.8806, max=0.9935, mean=0.9708
negative: min=0.9102, max=0.9925, mean=0.9693

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0581
焦点损失: 0.0124
边界损失: 0.1544
总损失: 0.0898
Epoch 6 [41/172] - loss: 0.0898
Epoch 6 [42/172] - loss: 0.0863
Epoch 6 [43/172] - loss: 0.1598
Epoch 6 [44/172] - loss: 0.0823
Epoch 6 [45/172] - loss: 0.0854
Epoch 6 [46/172] - loss: 0.1147
Epoch 6 [47/172] - loss: 0.0758
Epoch 6 [48/172] - loss: 0.0805
Epoch 6 [49/172] - loss: 0.0827
Epoch 6 [50/172] - loss: 0.0915, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1291
Epoch 6 [52/172] - loss: 0.0880
Epoch 6 [53/172] - loss: 0.0791
Epoch 6 [54/172] - loss: 0.0992
Epoch 6 [55/172] - loss: 0.0801
Epoch 6 [56/172] - loss: 0.0826
Epoch 6 [57/172] - loss: 0.0815
Epoch 6 [58/172] - loss: 0.0782
Epoch 6 [59/172] - loss: 0.0836
Epoch 6 [60/172] - loss: 0.0876, acc: 1.0000
Epoch 6 [61/172] - loss: 0.0789
Epoch 6 [62/172] - loss: 0.1046
Epoch 6 [63/172] - loss: 0.0817
Epoch 6 [64/172] - loss: 0.1448
Epoch 6 [65/172] - loss: 0.1086
Epoch 6 [66/172] - loss: 0.0794
Epoch 6 [67/172] - loss: 0.0764
Epoch 6 [68/172] - loss: 0.0995
Epoch 6 [69/172] - loss: 0.0890
Epoch 6 [70/172] - loss: 0.0770, acc: 1.0000
Epoch 6 [71/172] - loss: 0.0789
Epoch 6 [72/172] - loss: 0.0832
Epoch 6 [73/172] - loss: 0.0944
Epoch 6 [74/172] - loss: 0.0778
Epoch 6 [75/172] - loss: 0.0883
Epoch 6 [76/172] - loss: 0.0817
Epoch 6 [77/172] - loss: 0.0921
Epoch 6 [78/172] - loss: 0.0909
Epoch 6 [79/172] - loss: 0.0757
Epoch 6 [80/172] - loss: 0.1053, acc: 0.9688
Epoch 6 [81/172] - loss: 0.0904
Epoch 6 [82/172] - loss: 0.1486
Epoch 6 [83/172] - loss: 0.0798
Epoch 6 [84/172] - loss: 0.0763
Epoch 6 [85/172] - loss: 0.0818
Epoch 6 [86/172] - loss: 0.0954
Epoch 6 [87/172] - loss: 0.0861
Epoch 6 [88/172] - loss: 0.1019
Epoch 6 [89/172] - loss: 0.0785
Epoch 6 [90/172] - loss: 0.0763, acc: 1.0000
Epoch 6 [91/172] - loss: 0.0798
Epoch 6 [92/172] - loss: 0.0845
Epoch 6 [93/172] - loss: 0.0790
Epoch 6 [94/172] - loss: 0.0918
Epoch 6 [95/172] - loss: 0.0818
Epoch 6 [96/172] - loss: 0.0769
Epoch 6 [97/172] - loss: 0.0832
Epoch 6 [98/172] - loss: 0.0818
Epoch 6 [99/172] - loss: 0.0837
Epoch 6 [100/172] - loss: 0.0781, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1006
Epoch 6 [102/172] - loss: 0.0806
Epoch 6 [103/172] - loss: 0.0792
Epoch 6 [104/172] - loss: 0.0981
Epoch 6 [105/172] - loss: 0.0831
Epoch 6 [106/172] - loss: 0.0877
Epoch 6 [107/172] - loss: 0.0755
Epoch 6 [108/172] - loss: 0.0756
Epoch 6 [109/172] - loss: 0.0980
Epoch 6 [110/172] - loss: 0.0955, acc: 0.9688
Epoch 6 [111/172] - loss: 0.0784
Epoch 6 [112/172] - loss: 0.0789
Epoch 6 [113/172] - loss: 0.0945
Epoch 6 [114/172] - loss: 0.0770
Epoch 6 [115/172] - loss: 0.1050
Epoch 6 [116/172] - loss: 0.1446
Epoch 6 [117/172] - loss: 0.0776
Epoch 6 [118/172] - loss: 0.0814
Epoch 6 [119/172] - loss: 0.1618
Epoch 6 [120/172] - loss: 0.0793, acc: 1.0000
Epoch 6 [121/172] - loss: 0.0791
Epoch 6 [122/172] - loss: 0.1008
Epoch 6 [123/172] - loss: 0.0816
Epoch 6 [124/172] - loss: 0.0821
Epoch 6 [125/172] - loss: 0.0896
Epoch 6 [126/172] - loss: 0.1280
Epoch 6 [127/172] - loss: 0.1001
Epoch 6 [128/172] - loss: 0.0983
Epoch 6 [129/172] - loss: 0.0834
Epoch 6 [130/172] - loss: 0.0915, acc: 0.9688
Epoch 6 [131/172] - loss: 0.0815
Epoch 6 [132/172] - loss: 0.2210
Epoch 6 [133/172] - loss: 0.0775
Epoch 6 [134/172] - loss: 0.0748
Epoch 6 [135/172] - loss: 0.0768
Epoch 6 [136/172] - loss: 0.0747
Epoch 6 [137/172] - loss: 0.0771
Epoch 6 [138/172] - loss: 0.0782
Epoch 6 [139/172] - loss: 0.0792
Epoch 6 [140/172] - loss: 0.0933, acc: 0.9688

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.2134, log_difficulty=0.1934, weight=1.9671
neutral: count=9796.0, difficulty=0.1701, log_difficulty=0.1571, weight=1.7854
negative: count=10972.0, difficulty=0.2148, log_difficulty=0.1946, weight=1.9729

当前batch的pt分布：
positive: min=0.9781, max=0.9962, mean=0.9891
neutral: min=0.9372, max=0.9952, mean=0.9757
negative: min=0.8690, max=0.9832, mean=0.9453

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0340
焦点损失: 0.0002
边界损失: 0.1519
总损失: 0.0761
Epoch 6 [141/172] - loss: 0.0761
Epoch 6 [142/172] - loss: 0.0813
Epoch 6 [143/172] - loss: 0.0811
Epoch 6 [144/172] - loss: 0.0761
Epoch 6 [145/172] - loss: 0.0790
Epoch 6 [146/172] - loss: 0.0762
Epoch 6 [147/172] - loss: 0.1036
Epoch 6 [148/172] - loss: 0.0851
Epoch 6 [149/172] - loss: 0.0792
Epoch 6 [150/172] - loss: 0.0764, acc: 1.0000
Epoch 6 [151/172] - loss: 0.0786
Epoch 6 [152/172] - loss: 0.0898
Epoch 6 [153/172] - loss: 0.0830
Epoch 6 [154/172] - loss: 0.0753
Epoch 6 [155/172] - loss: 0.0890
Epoch 6 [156/172] - loss: 0.1027
Epoch 6 [157/172] - loss: 0.0752
Epoch 6 [158/172] - loss: 0.0840
Epoch 6 [159/172] - loss: 0.0947
Epoch 6 [160/172] - loss: 0.0978, acc: 0.9688
Epoch 6 [161/172] - loss: 0.0775
Epoch 6 [162/172] - loss: 0.0877
Epoch 6 [163/172] - loss: 0.0843
Epoch 6 [164/172] - loss: 0.0878
Epoch 6 [165/172] - loss: 0.2274
Epoch 6 [166/172] - loss: 0.0848
Epoch 6 [167/172] - loss: 0.0770
Epoch 6 [168/172] - loss: 0.0842
Epoch 6 [169/172] - loss: 0.1402
Epoch 6 [170/172] - loss: 0.0746, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1294
Epoch 6 [172/172] - loss: 0.0802

类别准确率:
positive: 0.8351 (390/467)
neutral: 0.2892 (24/83)
negative: 0.6160 (154/250)

Epoch 6/10
Train Loss: 0.0992, Train Acc: 0.9859
Val Loss: 0.8471, Val Acc: 0.7100
Epoch 7 [1/172] - loss: 0.0775, acc: 1.0000
Epoch 7 [2/172] - loss: 0.0759
Epoch 7 [3/172] - loss: 0.0750
Epoch 7 [4/172] - loss: 0.0812
Epoch 7 [5/172] - loss: 0.0772
Epoch 7 [6/172] - loss: 0.0772
Epoch 7 [7/172] - loss: 0.0766
Epoch 7 [8/172] - loss: 0.0973
Epoch 7 [9/172] - loss: 0.0754
Epoch 7 [10/172] - loss: 0.0764, acc: 1.0000
Epoch 7 [11/172] - loss: 0.0758
Epoch 7 [12/172] - loss: 0.1058
Epoch 7 [13/172] - loss: 0.0807
Epoch 7 [14/172] - loss: 0.0784
Epoch 7 [15/172] - loss: 0.0950
Epoch 7 [16/172] - loss: 0.0877
Epoch 7 [17/172] - loss: 0.0968
Epoch 7 [18/172] - loss: 0.0774
Epoch 7 [19/172] - loss: 0.0770
Epoch 7 [20/172] - loss: 0.0766, acc: 1.0000
Epoch 7 [21/172] - loss: 0.0869
Epoch 7 [22/172] - loss: 0.0890
Epoch 7 [23/172] - loss: 0.0763
Epoch 7 [24/172] - loss: 0.0789
Epoch 7 [25/172] - loss: 0.0756
Epoch 7 [26/172] - loss: 0.0992
Epoch 7 [27/172] - loss: 0.0789
Epoch 7 [28/172] - loss: 0.0828
Epoch 7 [29/172] - loss: 0.0791
Epoch 7 [30/172] - loss: 0.1204, acc: 0.9688
Epoch 7 [31/172] - loss: 0.0818
Epoch 7 [32/172] - loss: 0.0797
Epoch 7 [33/172] - loss: 0.0795
Epoch 7 [34/172] - loss: 0.0767
Epoch 7 [35/172] - loss: 0.0742
Epoch 7 [36/172] - loss: 0.1424
Epoch 7 [37/172] - loss: 0.0783
Epoch 7 [38/172] - loss: 0.0737
Epoch 7 [39/172] - loss: 0.0787
Epoch 7 [40/172] - loss: 0.0766, acc: 1.0000
Epoch 7 [41/172] - loss: 0.0780
Epoch 7 [42/172] - loss: 0.0759
Epoch 7 [43/172] - loss: 0.0893
Epoch 7 [44/172] - loss: 0.0777
Epoch 7 [45/172] - loss: 0.1042
Epoch 7 [46/172] - loss: 0.0898
Epoch 7 [47/172] - loss: 0.0955
Epoch 7 [48/172] - loss: 0.0741
Epoch 7 [49/172] - loss: 0.0747
Epoch 7 [50/172] - loss: 0.0752, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1412
Epoch 7 [52/172] - loss: 0.0803
Epoch 7 [53/172] - loss: 0.0740
Epoch 7 [54/172] - loss: 0.1101
Epoch 7 [55/172] - loss: 0.0831
Epoch 7 [56/172] - loss: 0.0771
Epoch 7 [57/172] - loss: 0.0833
Epoch 7 [58/172] - loss: 0.0912
Epoch 7 [59/172] - loss: 0.0763
Epoch 7 [60/172] - loss: 0.0869, acc: 1.0000
Epoch 7 [61/172] - loss: 0.0790
Epoch 7 [62/172] - loss: 0.1453
Epoch 7 [63/172] - loss: 0.0883
Epoch 7 [64/172] - loss: 0.0796
Epoch 7 [65/172] - loss: 0.1098
Epoch 7 [66/172] - loss: 0.0761
Epoch 7 [67/172] - loss: 0.0776
Epoch 7 [68/172] - loss: 0.0806

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1985, log_difficulty=0.1811, weight=1.9056
neutral: count=10756.0, difficulty=0.1584, log_difficulty=0.1470, weight=1.7351
negative: count=12072.0, difficulty=0.2003, log_difficulty=0.1826, weight=1.9130

当前batch的pt分布：
positive: min=0.9563, max=0.9952, mean=0.9821
neutral: min=0.9708, max=0.9990, mean=0.9883
negative: min=0.8703, max=0.9774, mean=0.9416

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0352
焦点损失: 0.0002
边界损失: 0.1520
总损失: 0.0762
Epoch 7 [69/172] - loss: 0.0762
Epoch 7 [70/172] - loss: 0.0950, acc: 1.0000
Epoch 7 [71/172] - loss: 0.0817
Epoch 7 [72/172] - loss: 0.0874
Epoch 7 [73/172] - loss: 0.0825
Epoch 7 [74/172] - loss: 0.0767
Epoch 7 [75/172] - loss: 0.0754
Epoch 7 [76/172] - loss: 0.0963
Epoch 7 [77/172] - loss: 0.0841
Epoch 7 [78/172] - loss: 0.0746
Epoch 7 [79/172] - loss: 0.0888
Epoch 7 [80/172] - loss: 0.1040, acc: 0.9688
Epoch 7 [81/172] - loss: 0.0744
Epoch 7 [82/172] - loss: 0.0765
Epoch 7 [83/172] - loss: 0.1202
Epoch 7 [84/172] - loss: 0.0787
Epoch 7 [85/172] - loss: 0.1512
Epoch 7 [86/172] - loss: 0.0782
Epoch 7 [87/172] - loss: 0.0789
Epoch 7 [88/172] - loss: 0.0761
Epoch 7 [89/172] - loss: 0.0747
Epoch 7 [90/172] - loss: 0.0752, acc: 1.0000
Epoch 7 [91/172] - loss: 0.0776
Epoch 7 [92/172] - loss: 0.0779
Epoch 7 [93/172] - loss: 0.1076
Epoch 7 [94/172] - loss: 0.0755
Epoch 7 [95/172] - loss: 0.0747
Epoch 7 [96/172] - loss: 0.0851
Epoch 7 [97/172] - loss: 0.0808
Epoch 7 [98/172] - loss: 0.1088
Epoch 7 [99/172] - loss: 0.0772
Epoch 7 [100/172] - loss: 0.0799, acc: 1.0000
Epoch 7 [101/172] - loss: 0.0910
Epoch 7 [102/172] - loss: 0.0792
Epoch 7 [103/172] - loss: 0.0778
Epoch 7 [104/172] - loss: 0.0760
Epoch 7 [105/172] - loss: 0.1023
Epoch 7 [106/172] - loss: 0.1001
Epoch 7 [107/172] - loss: 0.0787
Epoch 7 [108/172] - loss: 0.0736
Epoch 7 [109/172] - loss: 0.1101
Epoch 7 [110/172] - loss: 0.0778, acc: 1.0000
Epoch 7 [111/172] - loss: 0.0818
Epoch 7 [112/172] - loss: 0.0814
Epoch 7 [113/172] - loss: 0.0773
Epoch 7 [114/172] - loss: 0.0754
Epoch 7 [115/172] - loss: 0.0776
Epoch 7 [116/172] - loss: 0.0943
Epoch 7 [117/172] - loss: 0.0839
Epoch 7 [118/172] - loss: 0.0823
Epoch 7 [119/172] - loss: 0.0785
Epoch 7 [120/172] - loss: 0.0810, acc: 1.0000
Epoch 7 [121/172] - loss: 0.0811
Epoch 7 [122/172] - loss: 0.0768
Epoch 7 [123/172] - loss: 0.0736
Epoch 7 [124/172] - loss: 0.0856
Epoch 7 [125/172] - loss: 0.0818
Epoch 7 [126/172] - loss: 0.0736
Epoch 7 [127/172] - loss: 0.0830
Epoch 7 [128/172] - loss: 0.0765
Epoch 7 [129/172] - loss: 0.0767
Epoch 7 [130/172] - loss: 0.0784, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1256
Epoch 7 [132/172] - loss: 0.1434
Epoch 7 [133/172] - loss: 0.0749
Epoch 7 [134/172] - loss: 0.0829
Epoch 7 [135/172] - loss: 0.0801
Epoch 7 [136/172] - loss: 0.0745
Epoch 7 [137/172] - loss: 0.0957
Epoch 7 [138/172] - loss: 0.0764
Epoch 7 [139/172] - loss: 0.1253
Epoch 7 [140/172] - loss: 0.0797, acc: 1.0000
Epoch 7 [141/172] - loss: 0.0927
Epoch 7 [142/172] - loss: 0.0797
Epoch 7 [143/172] - loss: 0.0807
Epoch 7 [144/172] - loss: 0.0762
Epoch 7 [145/172] - loss: 0.0872
Epoch 7 [146/172] - loss: 0.1626
Epoch 7 [147/172] - loss: 0.0953
Epoch 7 [148/172] - loss: 0.0797
Epoch 7 [149/172] - loss: 0.0764
Epoch 7 [150/172] - loss: 0.0817, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1343
Epoch 7 [152/172] - loss: 0.0744
Epoch 7 [153/172] - loss: 0.0736
Epoch 7 [154/172] - loss: 0.1092
Epoch 7 [155/172] - loss: 0.0749
Epoch 7 [156/172] - loss: 0.1263
Epoch 7 [157/172] - loss: 0.0832
Epoch 7 [158/172] - loss: 0.0793
Epoch 7 [159/172] - loss: 0.0750
Epoch 7 [160/172] - loss: 0.0897, acc: 0.9688
Epoch 7 [161/172] - loss: 0.0745
Epoch 7 [162/172] - loss: 0.0821
Epoch 7 [163/172] - loss: 0.1024
Epoch 7 [164/172] - loss: 0.0958
Epoch 7 [165/172] - loss: 0.1107
Epoch 7 [166/172] - loss: 0.0764
Epoch 7 [167/172] - loss: 0.0843
Epoch 7 [168/172] - loss: 0.0787

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1860, log_difficulty=0.1706, weight=1.8530
neutral: count=11731.0, difficulty=0.1489, log_difficulty=0.1388, weight=1.6942
negative: count=13173.0, difficulty=0.1879, log_difficulty=0.1722, weight=1.8608

当前batch的pt分布：
positive: min=0.8251, max=0.9973, mean=0.9603
neutral: min=0.9327, max=0.9968, mean=0.9764
negative: min=0.8816, max=0.9880, mean=0.9498

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0409
焦点损失: 0.0004
边界损失: 0.1552
总损失: 0.0780
Epoch 7 [169/172] - loss: 0.0780
Epoch 7 [170/172] - loss: 0.0911, acc: 1.0000
Epoch 7 [171/172] - loss: 0.0752
Epoch 7 [172/172] - loss: 0.0731

类别准确率:
positive: 0.8180 (382/467)
neutral: 0.3253 (27/83)
negative: 0.6160 (154/250)

Epoch 7/10
Train Loss: 0.0843, Train Acc: 0.9939
Val Loss: 0.8811, Val Acc: 0.7037
Epoch 8 [1/172] - loss: 0.0763, acc: 1.0000
Epoch 8 [2/172] - loss: 0.0986
Epoch 8 [3/172] - loss: 0.0767
Epoch 8 [4/172] - loss: 0.0745
Epoch 8 [5/172] - loss: 0.0802
Epoch 8 [6/172] - loss: 0.1271
Epoch 8 [7/172] - loss: 0.0753
Epoch 8 [8/172] - loss: 0.0752
Epoch 8 [9/172] - loss: 0.0886
Epoch 8 [10/172] - loss: 0.1056, acc: 0.9688
Epoch 8 [11/172] - loss: 0.0872
Epoch 8 [12/172] - loss: 0.0944
Epoch 8 [13/172] - loss: 0.0749
Epoch 8 [14/172] - loss: 0.0757
Epoch 8 [15/172] - loss: 0.0829
Epoch 8 [16/172] - loss: 0.0787
Epoch 8 [17/172] - loss: 0.0755
Epoch 8 [18/172] - loss: 0.0725
Epoch 8 [19/172] - loss: 0.0828
Epoch 8 [20/172] - loss: 0.0742, acc: 1.0000
Epoch 8 [21/172] - loss: 0.0870
Epoch 8 [22/172] - loss: 0.0892
Epoch 8 [23/172] - loss: 0.0856
Epoch 8 [24/172] - loss: 0.0852
Epoch 8 [25/172] - loss: 0.0764
Epoch 8 [26/172] - loss: 0.0796
Epoch 8 [27/172] - loss: 0.1087
Epoch 8 [28/172] - loss: 0.0936
Epoch 8 [29/172] - loss: 0.0877
Epoch 8 [30/172] - loss: 0.0735, acc: 1.0000
Epoch 8 [31/172] - loss: 0.0743
Epoch 8 [32/172] - loss: 0.0753
Epoch 8 [33/172] - loss: 0.0809
Epoch 8 [34/172] - loss: 0.0807
Epoch 8 [35/172] - loss: 0.0795
Epoch 8 [36/172] - loss: 0.0808
Epoch 8 [37/172] - loss: 0.0876
Epoch 8 [38/172] - loss: 0.0892
Epoch 8 [39/172] - loss: 0.0950
Epoch 8 [40/172] - loss: 0.0783, acc: 1.0000
Epoch 8 [41/172] - loss: 0.0798
Epoch 8 [42/172] - loss: 0.0879
Epoch 8 [43/172] - loss: 0.1008
Epoch 8 [44/172] - loss: 0.0772
Epoch 8 [45/172] - loss: 0.0772
Epoch 8 [46/172] - loss: 0.0762
Epoch 8 [47/172] - loss: 0.0737
Epoch 8 [48/172] - loss: 0.1076
Epoch 8 [49/172] - loss: 0.0742
Epoch 8 [50/172] - loss: 0.0868, acc: 0.9688
Epoch 8 [51/172] - loss: 0.0764
Epoch 8 [52/172] - loss: 0.0849
Epoch 8 [53/172] - loss: 0.0829
Epoch 8 [54/172] - loss: 0.1124
Epoch 8 [55/172] - loss: 0.0762
Epoch 8 [56/172] - loss: 0.0825
Epoch 8 [57/172] - loss: 0.0850
Epoch 8 [58/172] - loss: 0.0799
Epoch 8 [59/172] - loss: 0.0758
Epoch 8 [60/172] - loss: 0.0762, acc: 1.0000
Epoch 8 [61/172] - loss: 0.0879
Epoch 8 [62/172] - loss: 0.0809
Epoch 8 [63/172] - loss: 0.0741
Epoch 8 [64/172] - loss: 0.0739
Epoch 8 [65/172] - loss: 0.0747
Epoch 8 [66/172] - loss: 0.0850
Epoch 8 [67/172] - loss: 0.0760
Epoch 8 [68/172] - loss: 0.0749
Epoch 8 [69/172] - loss: 0.0777
Epoch 8 [70/172] - loss: 0.0741, acc: 1.0000
Epoch 8 [71/172] - loss: 0.0994
Epoch 8 [72/172] - loss: 0.0770
Epoch 8 [73/172] - loss: 0.0892
Epoch 8 [74/172] - loss: 0.0762
Epoch 8 [75/172] - loss: 0.0753
Epoch 8 [76/172] - loss: 0.1254
Epoch 8 [77/172] - loss: 0.0736
Epoch 8 [78/172] - loss: 0.1205
Epoch 8 [79/172] - loss: 0.0808
Epoch 8 [80/172] - loss: 0.0782, acc: 1.0000
Epoch 8 [81/172] - loss: 0.0840
Epoch 8 [82/172] - loss: 0.0758
Epoch 8 [83/172] - loss: 0.0740
Epoch 8 [84/172] - loss: 0.0739
Epoch 8 [85/172] - loss: 0.0766
Epoch 8 [86/172] - loss: 0.0892
Epoch 8 [87/172] - loss: 0.0735
Epoch 8 [88/172] - loss: 0.0868
Epoch 8 [89/172] - loss: 0.0765
Epoch 8 [90/172] - loss: 0.0770, acc: 1.0000
Epoch 8 [91/172] - loss: 0.1218
Epoch 8 [92/172] - loss: 0.0881
Epoch 8 [93/172] - loss: 0.0730
Epoch 8 [94/172] - loss: 0.0804
Epoch 8 [95/172] - loss: 0.0758
Epoch 8 [96/172] - loss: 0.0782

=== 第 1301 次迭代调试信息 ===
当前类别统计：
positive: count=14487.0, difficulty=0.1751, log_difficulty=0.1613, weight=1.8067
neutral: count=12738.0, difficulty=0.1406, log_difficulty=0.1316, weight=1.6578
negative: count=14288.0, difficulty=0.1769, log_difficulty=0.1629, weight=1.8144

当前batch的pt分布：
positive: min=0.8835, max=0.9967, mean=0.9647
neutral: min=0.3438, max=0.9961, mean=0.8891
negative: min=0.8356, max=0.9986, mean=0.9698

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 0.9333
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0853
焦点损失: 0.0159
边界损失: 0.1676
总损失: 0.0970
Epoch 8 [97/172] - loss: 0.0970
Epoch 8 [98/172] - loss: 0.0916
Epoch 8 [99/172] - loss: 0.0772
Epoch 8 [100/172] - loss: 0.0747, acc: 1.0000
Epoch 8 [101/172] - loss: 0.0808
Epoch 8 [102/172] - loss: 0.0862
Epoch 8 [103/172] - loss: 0.1112
Epoch 8 [104/172] - loss: 0.0816
Epoch 8 [105/172] - loss: 0.0781
Epoch 8 [106/172] - loss: 0.0804
Epoch 8 [107/172] - loss: 0.0815
Epoch 8 [108/172] - loss: 0.0814
Epoch 8 [109/172] - loss: 0.0891
Epoch 8 [110/172] - loss: 0.0814, acc: 1.0000
Epoch 8 [111/172] - loss: 0.1149
Epoch 8 [112/172] - loss: 0.1028
Epoch 8 [113/172] - loss: 0.0760
Epoch 8 [114/172] - loss: 0.0760
Epoch 8 [115/172] - loss: 0.0741
Epoch 8 [116/172] - loss: 0.0747
Epoch 8 [117/172] - loss: 0.0755
Epoch 8 [118/172] - loss: 0.0755
Epoch 8 [119/172] - loss: 0.0746
Epoch 8 [120/172] - loss: 0.0770, acc: 1.0000
Epoch 8 [121/172] - loss: 0.1318
Epoch 8 [122/172] - loss: 0.0792
Epoch 8 [123/172] - loss: 0.0754
Epoch 8 [124/172] - loss: 0.0771
Epoch 8 [125/172] - loss: 0.0808
Epoch 8 [126/172] - loss: 0.0787
Epoch 8 [127/172] - loss: 0.0897
Epoch 8 [128/172] - loss: 0.0871
Epoch 8 [129/172] - loss: 0.0779
Epoch 8 [130/172] - loss: 0.0762, acc: 1.0000
Epoch 8 [131/172] - loss: 0.0843
Epoch 8 [132/172] - loss: 0.0736
Epoch 8 [133/172] - loss: 0.0766
Epoch 8 [134/172] - loss: 0.0785
Epoch 8 [135/172] - loss: 0.0754
Epoch 8 [136/172] - loss: 0.0779
Epoch 8 [137/172] - loss: 0.0766
Epoch 8 [138/172] - loss: 0.0883
Epoch 8 [139/172] - loss: 0.0877
Epoch 8 [140/172] - loss: 0.0732, acc: 1.0000
Epoch 8 [141/172] - loss: 0.0730
Epoch 8 [142/172] - loss: 0.0800
Epoch 8 [143/172] - loss: 0.0831
Epoch 8 [144/172] - loss: 0.0849
Epoch 8 [145/172] - loss: 0.0758
Epoch 8 [146/172] - loss: 0.0733
Epoch 8 [147/172] - loss: 0.0732
Epoch 8 [148/172] - loss: 0.0766
Epoch 8 [149/172] - loss: 0.0744
Epoch 8 [150/172] - loss: 0.0792, acc: 1.0000
Epoch 8 [151/172] - loss: 0.0877
Epoch 8 [152/172] - loss: 0.0864
Epoch 8 [153/172] - loss: 0.0779
Epoch 8 [154/172] - loss: 0.1100
Epoch 8 [155/172] - loss: 0.0757
Epoch 8 [156/172] - loss: 0.0783
Epoch 8 [157/172] - loss: 0.0880
Epoch 8 [158/172] - loss: 0.0773
Epoch 8 [159/172] - loss: 0.0879
Epoch 8 [160/172] - loss: 0.0790, acc: 1.0000
Epoch 8 [161/172] - loss: 0.0761
Epoch 8 [162/172] - loss: 0.0910
Epoch 8 [163/172] - loss: 0.0767
Epoch 8 [164/172] - loss: 0.0788
Epoch 8 [165/172] - loss: 0.0728
Epoch 8 [166/172] - loss: 0.0811
Epoch 8 [167/172] - loss: 0.0733
Epoch 8 [168/172] - loss: 0.0763
Epoch 8 [169/172] - loss: 0.0799
Epoch 8 [170/172] - loss: 0.0802, acc: 1.0000
Epoch 8 [171/172] - loss: 0.0782
Epoch 8 [172/172] - loss: 0.0757

类别准确率:
positive: 0.8480 (396/467)
neutral: 0.2892 (24/83)
negative: 0.5840 (146/250)

Epoch 8/10
Train Loss: 0.0795, Train Acc: 0.9980
Val Loss: 0.8815, Val Acc: 0.7075
Early stopping triggered!
Best validation accuracy: 0.7150

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_084523-mabijx1j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.35_Multimodal_iterations_20250118_084521
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/mabijx1j
wandb: uploading wandb-summary.json; uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███
wandb:  train_acc ▁▂▁▃▆▆▆██▇▆▇██████▇█████████████████████
wandb: train_loss █▆▅▅▅▄▃▂▃▂▂▂▁▂▁▂▁▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1374
wandb:  train_acc 1
wandb: train_loss 0.08022
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.35_Multimodal_iterations_20250118_084521 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/mabijx1j
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_084523-mabijx1j/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_085655-autjv8xg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.35_Multimodal_epochs_20250118_085655
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/autjv8xg
wandb: uploading history steps 0-0, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▄▅▆▇█
wandb:  train_acc ▁▅▇▇████
wandb: train_loss █▅▂▂▁▁▁▁
wandb:    val_acc ▁▆▄▂█▇▆▇
wandb:   val_loss ▂▁▄▇▅▇██
wandb: 
wandb: Run summary:
wandb:      epoch 8
wandb:  train_acc 0.99798
wandb: train_loss 0.07951
wandb:    val_acc 0.7075
wandb:   val_loss 0.88147
wandb: 
wandb: 🚀 View run loss_focal_alpha0.5_beta0.5_weight1.0_dropout0.35_Multimodal_epochs_20250118_085655 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/autjv8xg
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_085655-autjv8xg/logs

