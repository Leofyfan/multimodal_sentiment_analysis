=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 1.5 --dropout 0.2 --name loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.2 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.2
text_dim: 128
image_dim: 256
dropout: 0.2
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6990, log_difficulty=0.5300, weight=3.6502
neutral: count=7.0, difficulty=0.6864, log_difficulty=0.5226, weight=3.6131
negative: count=13.0, difficulty=0.6567, log_difficulty=0.5048, weight=3.5242

当前batch的pt分布：
positive: min=0.1761, max=0.4892, mean=0.3010
neutral: min=0.1754, max=0.4694, mean=0.3136
negative: min=0.1724, max=0.7210, mean=0.3433

当前batch准确率：
整体准确率: 0.2812
positive 准确率: 0.1667
neutral 准确率: 0.4286
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1874
焦点损失: 0.4309
边界损失: 0.7522
总损失: 0.9514
Epoch 1 [1/172] - loss: 0.9514, acc: 0.2812
Epoch 1 [2/172] - loss: 0.9487
Epoch 1 [3/172] - loss: 1.0076
Epoch 1 [4/172] - loss: 0.8151
Epoch 1 [5/172] - loss: 0.9210
Epoch 1 [6/172] - loss: 1.0104
Epoch 1 [7/172] - loss: 0.9118
Epoch 1 [8/172] - loss: 0.8339
Epoch 1 [9/172] - loss: 0.8981
Epoch 1 [10/172] - loss: 0.9019, acc: 0.3438
Epoch 1 [11/172] - loss: 0.8815
Epoch 1 [12/172] - loss: 0.9268
Epoch 1 [13/172] - loss: 0.6825
Epoch 1 [14/172] - loss: 0.8184
Epoch 1 [15/172] - loss: 0.8564
Epoch 1 [16/172] - loss: 0.8719
Epoch 1 [17/172] - loss: 0.9613
Epoch 1 [18/172] - loss: 0.8227
Epoch 1 [19/172] - loss: 0.8553
Epoch 1 [20/172] - loss: 0.9570, acc: 0.1562
Epoch 1 [21/172] - loss: 0.7754
Epoch 1 [22/172] - loss: 0.7374
Epoch 1 [23/172] - loss: 0.8725
Epoch 1 [24/172] - loss: 0.7326
Epoch 1 [25/172] - loss: 0.8362
Epoch 1 [26/172] - loss: 0.8330
Epoch 1 [27/172] - loss: 0.8716
Epoch 1 [28/172] - loss: 0.7182
Epoch 1 [29/172] - loss: 0.7944
Epoch 1 [30/172] - loss: 0.7281, acc: 0.5000
Epoch 1 [31/172] - loss: 0.8384
Epoch 1 [32/172] - loss: 0.6612
Epoch 1 [33/172] - loss: 0.7693
Epoch 1 [34/172] - loss: 0.7453
Epoch 1 [35/172] - loss: 0.9273
Epoch 1 [36/172] - loss: 0.6596
Epoch 1 [37/172] - loss: 0.7330
Epoch 1 [38/172] - loss: 0.7031
Epoch 1 [39/172] - loss: 0.6141
Epoch 1 [40/172] - loss: 0.7017, acc: 0.6250
Epoch 1 [41/172] - loss: 0.5956
Epoch 1 [42/172] - loss: 0.5127
Epoch 1 [43/172] - loss: 0.6979
Epoch 1 [44/172] - loss: 0.7740
Epoch 1 [45/172] - loss: 0.8239
Epoch 1 [46/172] - loss: 0.6055
Epoch 1 [47/172] - loss: 0.7547
Epoch 1 [48/172] - loss: 0.6967
Epoch 1 [49/172] - loss: 0.7030
Epoch 1 [50/172] - loss: 0.5826, acc: 0.6250
Epoch 1 [51/172] - loss: 0.5735
Epoch 1 [52/172] - loss: 0.6277
Epoch 1 [53/172] - loss: 0.6489
Epoch 1 [54/172] - loss: 0.6985
Epoch 1 [55/172] - loss: 0.5364
Epoch 1 [56/172] - loss: 0.5692
Epoch 1 [57/172] - loss: 0.8631
Epoch 1 [58/172] - loss: 0.4112
Epoch 1 [59/172] - loss: 0.7548
Epoch 1 [60/172] - loss: 0.6078, acc: 0.6250
Epoch 1 [61/172] - loss: 0.7270
Epoch 1 [62/172] - loss: 0.5340
Epoch 1 [63/172] - loss: 0.5728
Epoch 1 [64/172] - loss: 0.4396
Epoch 1 [65/172] - loss: 0.6020
Epoch 1 [66/172] - loss: 0.7043
Epoch 1 [67/172] - loss: 0.5901
Epoch 1 [68/172] - loss: 0.6736
Epoch 1 [69/172] - loss: 0.8844
Epoch 1 [70/172] - loss: 0.5095, acc: 0.7500
Epoch 1 [71/172] - loss: 0.4609
Epoch 1 [72/172] - loss: 0.5850
Epoch 1 [73/172] - loss: 0.5835
Epoch 1 [74/172] - loss: 0.5899
Epoch 1 [75/172] - loss: 0.4351
Epoch 1 [76/172] - loss: 0.6061
Epoch 1 [77/172] - loss: 0.4628
Epoch 1 [78/172] - loss: 0.5968
Epoch 1 [79/172] - loss: 0.6487
Epoch 1 [80/172] - loss: 0.4693, acc: 0.7500
Epoch 1 [81/172] - loss: 0.5038
Epoch 1 [82/172] - loss: 0.6885
Epoch 1 [83/172] - loss: 0.5256
Epoch 1 [84/172] - loss: 0.4486
Epoch 1 [85/172] - loss: 0.5202
Epoch 1 [86/172] - loss: 0.7260
Epoch 1 [87/172] - loss: 0.3626
Epoch 1 [88/172] - loss: 0.6402
Epoch 1 [89/172] - loss: 0.6497
Epoch 1 [90/172] - loss: 0.6850, acc: 0.5938
Epoch 1 [91/172] - loss: 0.5371
Epoch 1 [92/172] - loss: 0.5258
Epoch 1 [93/172] - loss: 0.4711
Epoch 1 [94/172] - loss: 0.3227
Epoch 1 [95/172] - loss: 0.4821
Epoch 1 [96/172] - loss: 0.4516
Epoch 1 [97/172] - loss: 0.4616
Epoch 1 [98/172] - loss: 0.4834
Epoch 1 [99/172] - loss: 0.5584
Epoch 1 [100/172] - loss: 0.5324, acc: 0.7188

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5596, log_difficulty=0.4444, weight=3.2222
neutral: count=983.0, difficulty=0.4888, log_difficulty=0.3980, weight=2.9898
negative: count=1119.0, difficulty=0.5036, log_difficulty=0.4079, weight=3.0394

当前batch的pt分布：
positive: min=0.0776, max=0.9665, mean=0.5121
neutral: min=0.1719, max=0.9949, mean=0.7330
negative: min=0.0307, max=0.9202, mean=0.5276

当前batch准确率：
整体准确率: 0.5938
positive 准确率: 0.5833
neutral 准确率: 0.7500
negative 准确率: 0.5625

损失分量：
基础交叉熵: 0.8816
焦点损失: 0.4683
边界损失: 0.3439
总损失: 0.6220
Epoch 1 [101/172] - loss: 0.6220
Epoch 1 [102/172] - loss: 0.4973
Epoch 1 [103/172] - loss: 0.4796
Epoch 1 [104/172] - loss: 0.3634
Epoch 1 [105/172] - loss: 0.6356
Epoch 1 [106/172] - loss: 0.6090
Epoch 1 [107/172] - loss: 0.4949
Epoch 1 [108/172] - loss: 0.7146
Epoch 1 [109/172] - loss: 0.4785
Epoch 1 [110/172] - loss: 0.6916, acc: 0.6250
Epoch 1 [111/172] - loss: 0.4714
Epoch 1 [112/172] - loss: 0.3435
Epoch 1 [113/172] - loss: 0.3240
Epoch 1 [114/172] - loss: 0.3909
Epoch 1 [115/172] - loss: 0.4449
Epoch 1 [116/172] - loss: 0.4367
Epoch 1 [117/172] - loss: 0.4794
Epoch 1 [118/172] - loss: 0.3852
Epoch 1 [119/172] - loss: 0.4122
Epoch 1 [120/172] - loss: 0.4546, acc: 0.7500
Epoch 1 [121/172] - loss: 0.3639
Epoch 1 [122/172] - loss: 0.5077
Epoch 1 [123/172] - loss: 0.3500
Epoch 1 [124/172] - loss: 0.4537
Epoch 1 [125/172] - loss: 0.3779
Epoch 1 [126/172] - loss: 0.6628
Epoch 1 [127/172] - loss: 0.3085
Epoch 1 [128/172] - loss: 0.3636
Epoch 1 [129/172] - loss: 0.5257
Epoch 1 [130/172] - loss: 0.4021, acc: 0.7188
Epoch 1 [131/172] - loss: 0.2575
Epoch 1 [132/172] - loss: 0.5220
Epoch 1 [133/172] - loss: 0.5591
Epoch 1 [134/172] - loss: 0.2909
Epoch 1 [135/172] - loss: 0.3798
Epoch 1 [136/172] - loss: 0.3694
Epoch 1 [137/172] - loss: 0.4486
Epoch 1 [138/172] - loss: 0.3113
Epoch 1 [139/172] - loss: 0.3179
Epoch 1 [140/172] - loss: 0.3872, acc: 0.8125
Epoch 1 [141/172] - loss: 0.3412
Epoch 1 [142/172] - loss: 0.3572
Epoch 1 [143/172] - loss: 0.4502
Epoch 1 [144/172] - loss: 0.2764
Epoch 1 [145/172] - loss: 0.3438
Epoch 1 [146/172] - loss: 0.4644
Epoch 1 [147/172] - loss: 0.4619
Epoch 1 [148/172] - loss: 0.3436
Epoch 1 [149/172] - loss: 0.2930
Epoch 1 [150/172] - loss: 0.4819, acc: 0.6562
Epoch 1 [151/172] - loss: 0.5319
Epoch 1 [152/172] - loss: 0.4213
Epoch 1 [153/172] - loss: 0.4386
Epoch 1 [154/172] - loss: 0.3695
Epoch 1 [155/172] - loss: 0.3733
Epoch 1 [156/172] - loss: 0.5463
Epoch 1 [157/172] - loss: 0.4326
Epoch 1 [158/172] - loss: 0.3195
Epoch 1 [159/172] - loss: 0.5306
Epoch 1 [160/172] - loss: 0.3681, acc: 0.8125
Epoch 1 [161/172] - loss: 0.3107
Epoch 1 [162/172] - loss: 0.3508
Epoch 1 [163/172] - loss: 0.4772
Epoch 1 [164/172] - loss: 0.5047
Epoch 1 [165/172] - loss: 0.3302
Epoch 1 [166/172] - loss: 0.3039
Epoch 1 [167/172] - loss: 0.2817
Epoch 1 [168/172] - loss: 0.4923
Epoch 1 [169/172] - loss: 0.3634
Epoch 1 [170/172] - loss: 0.3477, acc: 0.8438
Epoch 1 [171/172] - loss: 0.2333
Epoch 1 [172/172] - loss: 0.3469

类别准确率:
positive: 0.6938 (324/467)
neutral: 0.3373 (28/83)
negative: 0.8160 (204/250)

Epoch 1/10
Train Loss: 0.3746, Train Acc: 0.7838
Val Loss: 0.7045, Val Acc: 0.6950
Epoch 2 [1/172] - loss: 0.3191, acc: 0.9062
Epoch 2 [2/172] - loss: 0.3015
Epoch 2 [3/172] - loss: 0.2470
Epoch 2 [4/172] - loss: 0.3570
Epoch 2 [5/172] - loss: 0.4284
Epoch 2 [6/172] - loss: 0.2834
Epoch 2 [7/172] - loss: 0.3486
Epoch 2 [8/172] - loss: 0.3360
Epoch 2 [9/172] - loss: 0.2850
Epoch 2 [10/172] - loss: 0.2808, acc: 0.9062
Epoch 2 [11/172] - loss: 0.2288
Epoch 2 [12/172] - loss: 0.1957
Epoch 2 [13/172] - loss: 0.2440
Epoch 2 [14/172] - loss: 0.2271
Epoch 2 [15/172] - loss: 0.3179
Epoch 2 [16/172] - loss: 0.3321
Epoch 2 [17/172] - loss: 0.2500
Epoch 2 [18/172] - loss: 0.3825
Epoch 2 [19/172] - loss: 0.2630
Epoch 2 [20/172] - loss: 0.2451, acc: 0.9062
Epoch 2 [21/172] - loss: 0.2388
Epoch 2 [22/172] - loss: 0.2345
Epoch 2 [23/172] - loss: 0.1745
Epoch 2 [24/172] - loss: 0.4751
Epoch 2 [25/172] - loss: 0.2900
Epoch 2 [26/172] - loss: 0.1899
Epoch 2 [27/172] - loss: 0.2033
Epoch 2 [28/172] - loss: 0.2503

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4558, log_difficulty=0.3756, weight=2.8779
neutral: count=1952.0, difficulty=0.3618, log_difficulty=0.3088, weight=2.5441
negative: count=2216.0, difficulty=0.4153, log_difficulty=0.3474, weight=2.7368

当前batch的pt分布：
positive: min=0.1934, max=0.9752, mean=0.7965
neutral: min=0.2239, max=0.9866, mean=0.8335
negative: min=0.0277, max=0.9880, mean=0.6523

当前batch准确率：
整体准确率: 0.8125
positive 准确率: 0.8889
neutral 准确率: 0.9091
negative 准确率: 0.6667

损失分量：
基础交叉熵: 0.5033
焦点损失: 0.3053
边界损失: 0.2094
总损失: 0.3657
Epoch 2 [29/172] - loss: 0.3657
Epoch 2 [30/172] - loss: 0.3065, acc: 0.9062
Epoch 2 [31/172] - loss: 0.2821
Epoch 2 [32/172] - loss: 0.2210
Epoch 2 [33/172] - loss: 0.3244
Epoch 2 [34/172] - loss: 0.3657
Epoch 2 [35/172] - loss: 0.1977
Epoch 2 [36/172] - loss: 0.2933
Epoch 2 [37/172] - loss: 0.1895
Epoch 2 [38/172] - loss: 0.2679
Epoch 2 [39/172] - loss: 0.2864
Epoch 2 [40/172] - loss: 0.3053, acc: 0.8438
Epoch 2 [41/172] - loss: 0.2320
Epoch 2 [42/172] - loss: 0.1828
Epoch 2 [43/172] - loss: 0.1536
Epoch 2 [44/172] - loss: 0.3046
Epoch 2 [45/172] - loss: 0.1978
Epoch 2 [46/172] - loss: 0.2728
Epoch 2 [47/172] - loss: 0.3686
Epoch 2 [48/172] - loss: 0.2752
Epoch 2 [49/172] - loss: 0.2661
Epoch 2 [50/172] - loss: 0.3189, acc: 0.8438
Epoch 2 [51/172] - loss: 0.3078
Epoch 2 [52/172] - loss: 0.2354
Epoch 2 [53/172] - loss: 0.2217
Epoch 2 [54/172] - loss: 0.2269
Epoch 2 [55/172] - loss: 0.2710
Epoch 2 [56/172] - loss: 0.2266
Epoch 2 [57/172] - loss: 0.2789
Epoch 2 [58/172] - loss: 0.1974
Epoch 2 [59/172] - loss: 0.3624
Epoch 2 [60/172] - loss: 0.2213, acc: 0.9375
Epoch 2 [61/172] - loss: 0.1528
Epoch 2 [62/172] - loss: 0.1908
Epoch 2 [63/172] - loss: 0.3232
Epoch 2 [64/172] - loss: 0.2605
Epoch 2 [65/172] - loss: 0.2610
Epoch 2 [66/172] - loss: 0.2128
Epoch 2 [67/172] - loss: 0.2130
Epoch 2 [68/172] - loss: 0.3220
Epoch 2 [69/172] - loss: 0.2356
Epoch 2 [70/172] - loss: 0.3470, acc: 0.8438
Epoch 2 [71/172] - loss: 0.2858
Epoch 2 [72/172] - loss: 0.2461
Epoch 2 [73/172] - loss: 0.2011
Epoch 2 [74/172] - loss: 0.2269
Epoch 2 [75/172] - loss: 0.2809
Epoch 2 [76/172] - loss: 0.2253
Epoch 2 [77/172] - loss: 0.3074
Epoch 2 [78/172] - loss: 0.2594
Epoch 2 [79/172] - loss: 0.2333
Epoch 2 [80/172] - loss: 0.1878, acc: 0.9375
Epoch 2 [81/172] - loss: 0.2089
Epoch 2 [82/172] - loss: 0.2024
Epoch 2 [83/172] - loss: 0.2187
Epoch 2 [84/172] - loss: 0.1770
Epoch 2 [85/172] - loss: 0.2341
Epoch 2 [86/172] - loss: 0.2486
Epoch 2 [87/172] - loss: 0.4468
Epoch 2 [88/172] - loss: 0.1619
Epoch 2 [89/172] - loss: 0.1697
Epoch 2 [90/172] - loss: 0.1863, acc: 1.0000
Epoch 2 [91/172] - loss: 0.1304
Epoch 2 [92/172] - loss: 0.2493
Epoch 2 [93/172] - loss: 0.1672
Epoch 2 [94/172] - loss: 0.1990
Epoch 2 [95/172] - loss: 0.2956
Epoch 2 [96/172] - loss: 0.1759
Epoch 2 [97/172] - loss: 0.1907
Epoch 2 [98/172] - loss: 0.2277
Epoch 2 [99/172] - loss: 0.1544
Epoch 2 [100/172] - loss: 0.2938, acc: 0.8750
Epoch 2 [101/172] - loss: 0.1657
Epoch 2 [102/172] - loss: 0.1590
Epoch 2 [103/172] - loss: 0.3314
Epoch 2 [104/172] - loss: 0.2651
Epoch 2 [105/172] - loss: 0.1744
Epoch 2 [106/172] - loss: 0.1581
Epoch 2 [107/172] - loss: 0.2021
Epoch 2 [108/172] - loss: 0.3590
Epoch 2 [109/172] - loss: 0.1957
Epoch 2 [110/172] - loss: 0.2156, acc: 0.9062
Epoch 2 [111/172] - loss: 0.2249
Epoch 2 [112/172] - loss: 0.1484
Epoch 2 [113/172] - loss: 0.1487
Epoch 2 [114/172] - loss: 0.2047
Epoch 2 [115/172] - loss: 0.2186
Epoch 2 [116/172] - loss: 0.2378
Epoch 2 [117/172] - loss: 0.2645
Epoch 2 [118/172] - loss: 0.1425
Epoch 2 [119/172] - loss: 0.2125
Epoch 2 [120/172] - loss: 0.1640, acc: 0.9688
Epoch 2 [121/172] - loss: 0.1625
Epoch 2 [122/172] - loss: 0.2399
Epoch 2 [123/172] - loss: 0.2259
Epoch 2 [124/172] - loss: 0.3435
Epoch 2 [125/172] - loss: 0.1428
Epoch 2 [126/172] - loss: 0.2119
Epoch 2 [127/172] - loss: 0.1625
Epoch 2 [128/172] - loss: 0.1986

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3759, log_difficulty=0.3191, weight=2.5954
neutral: count=2949.0, difficulty=0.2776, log_difficulty=0.2450, weight=2.2248
negative: count=3294.0, difficulty=0.3447, log_difficulty=0.2962, weight=2.4809

当前batch的pt分布：
positive: min=0.3939, max=0.9885, mean=0.8693
neutral: min=0.2991, max=0.9995, mean=0.8362
negative: min=0.0827, max=0.9898, mean=0.7905

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.9000
neutral 准确率: 0.9091
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.2903
焦点损失: 0.1389
边界损失: 0.1985
总损失: 0.2341
Epoch 2 [129/172] - loss: 0.2341
Epoch 2 [130/172] - loss: 0.3126, acc: 0.9062
Epoch 2 [131/172] - loss: 0.2196
Epoch 2 [132/172] - loss: 0.2329
Epoch 2 [133/172] - loss: 0.1940
Epoch 2 [134/172] - loss: 0.2247
Epoch 2 [135/172] - loss: 0.3907
Epoch 2 [136/172] - loss: 0.1606
Epoch 2 [137/172] - loss: 0.1969
Epoch 2 [138/172] - loss: 0.1837
Epoch 2 [139/172] - loss: 0.2417
Epoch 2 [140/172] - loss: 0.2575, acc: 0.8750
Epoch 2 [141/172] - loss: 0.2633
Epoch 2 [142/172] - loss: 0.1965
Epoch 2 [143/172] - loss: 0.2195
Epoch 2 [144/172] - loss: 0.1888
Epoch 2 [145/172] - loss: 0.3548
Epoch 2 [146/172] - loss: 0.1999
Epoch 2 [147/172] - loss: 0.1443
Epoch 2 [148/172] - loss: 0.1808
Epoch 2 [149/172] - loss: 0.2972
Epoch 2 [150/172] - loss: 0.2179, acc: 0.9688
Epoch 2 [151/172] - loss: 0.2980
Epoch 2 [152/172] - loss: 0.2610
Epoch 2 [153/172] - loss: 0.2703
Epoch 2 [154/172] - loss: 0.1911
Epoch 2 [155/172] - loss: 0.2497
Epoch 2 [156/172] - loss: 0.1874
Epoch 2 [157/172] - loss: 0.1722
Epoch 2 [158/172] - loss: 0.2265
Epoch 2 [159/172] - loss: 0.2840
Epoch 2 [160/172] - loss: 0.1702, acc: 0.9375
Epoch 2 [161/172] - loss: 0.2017
Epoch 2 [162/172] - loss: 0.1403
Epoch 2 [163/172] - loss: 0.3361
Epoch 2 [164/172] - loss: 0.3476
Epoch 2 [165/172] - loss: 0.2090
Epoch 2 [166/172] - loss: 0.2712
Epoch 2 [167/172] - loss: 0.2804
Epoch 2 [168/172] - loss: 0.1505
Epoch 2 [169/172] - loss: 0.1610
Epoch 2 [170/172] - loss: 0.1600, acc: 0.9375
Epoch 2 [171/172] - loss: 0.2711
Epoch 2 [172/172] - loss: 0.4552

类别准确率:
positive: 0.7901 (369/467)
neutral: 0.3976 (33/83)
negative: 0.6920 (173/250)

Epoch 2/10
Train Loss: 0.2398, Train Acc: 0.9091
Val Loss: 0.7387, Val Acc: 0.7188
Epoch 3 [1/172] - loss: 0.1521, acc: 1.0000
Epoch 3 [2/172] - loss: 0.2576
Epoch 3 [3/172] - loss: 0.1262
Epoch 3 [4/172] - loss: 0.1426
Epoch 3 [5/172] - loss: 0.1650
Epoch 3 [6/172] - loss: 0.1644
Epoch 3 [7/172] - loss: 0.1640
Epoch 3 [8/172] - loss: 0.2117
Epoch 3 [9/172] - loss: 0.1716
Epoch 3 [10/172] - loss: 0.1303, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1569
Epoch 3 [12/172] - loss: 0.1249
Epoch 3 [13/172] - loss: 0.1525
Epoch 3 [14/172] - loss: 0.1366
Epoch 3 [15/172] - loss: 0.1516
Epoch 3 [16/172] - loss: 0.2208
Epoch 3 [17/172] - loss: 0.1529
Epoch 3 [18/172] - loss: 0.1668
Epoch 3 [19/172] - loss: 0.1305
Epoch 3 [20/172] - loss: 0.1303, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1961
Epoch 3 [22/172] - loss: 0.2133
Epoch 3 [23/172] - loss: 0.1297
Epoch 3 [24/172] - loss: 0.1693
Epoch 3 [25/172] - loss: 0.1584
Epoch 3 [26/172] - loss: 0.1230
Epoch 3 [27/172] - loss: 0.1417
Epoch 3 [28/172] - loss: 0.1234
Epoch 3 [29/172] - loss: 0.1820
Epoch 3 [30/172] - loss: 0.1852, acc: 0.9062
Epoch 3 [31/172] - loss: 0.1416
Epoch 3 [32/172] - loss: 0.1478
Epoch 3 [33/172] - loss: 0.1272
Epoch 3 [34/172] - loss: 0.1501
Epoch 3 [35/172] - loss: 0.1515
Epoch 3 [36/172] - loss: 0.1662
Epoch 3 [37/172] - loss: 0.1569
Epoch 3 [38/172] - loss: 0.1275
Epoch 3 [39/172] - loss: 0.1231
Epoch 3 [40/172] - loss: 0.1857, acc: 0.9375
Epoch 3 [41/172] - loss: 0.1281
Epoch 3 [42/172] - loss: 0.1292
Epoch 3 [43/172] - loss: 0.1224
Epoch 3 [44/172] - loss: 0.1213
Epoch 3 [45/172] - loss: 0.1777
Epoch 3 [46/172] - loss: 0.1259
Epoch 3 [47/172] - loss: 0.1481
Epoch 3 [48/172] - loss: 0.1614
Epoch 3 [49/172] - loss: 0.1139
Epoch 3 [50/172] - loss: 0.2032, acc: 0.9375
Epoch 3 [51/172] - loss: 0.2174
Epoch 3 [52/172] - loss: 0.2145
Epoch 3 [53/172] - loss: 0.1838
Epoch 3 [54/172] - loss: 0.1932
Epoch 3 [55/172] - loss: 0.1327
Epoch 3 [56/172] - loss: 0.1292

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3179, log_difficulty=0.2760, weight=2.3801
neutral: count=3923.0, difficulty=0.2291, log_difficulty=0.2063, weight=2.0313
negative: count=4382.0, difficulty=0.2939, log_difficulty=0.2577, weight=2.2884

当前batch的pt分布：
positive: min=0.2649, max=0.9955, mean=0.8905
neutral: min=0.0020, max=0.9883, mean=0.8572
negative: min=0.9919, max=0.9974, mean=0.9954

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9091
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2959
焦点损失: 0.2152
边界损失: 0.1689
总损失: 0.2377
Epoch 3 [57/172] - loss: 0.2377
Epoch 3 [58/172] - loss: 0.1965
Epoch 3 [59/172] - loss: 0.1438
Epoch 3 [60/172] - loss: 0.1327, acc: 1.0000
Epoch 3 [61/172] - loss: 0.1286
Epoch 3 [62/172] - loss: 0.1362
Epoch 3 [63/172] - loss: 0.1268
Epoch 3 [64/172] - loss: 0.1775
Epoch 3 [65/172] - loss: 0.1341
Epoch 3 [66/172] - loss: 0.1573
Epoch 3 [67/172] - loss: 0.1313
Epoch 3 [68/172] - loss: 0.1525
Epoch 3 [69/172] - loss: 0.1791
Epoch 3 [70/172] - loss: 0.1280, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1902
Epoch 3 [72/172] - loss: 0.2001
Epoch 3 [73/172] - loss: 0.1222
Epoch 3 [74/172] - loss: 0.1988
Epoch 3 [75/172] - loss: 0.1327
Epoch 3 [76/172] - loss: 0.1213
Epoch 3 [77/172] - loss: 0.1296
Epoch 3 [78/172] - loss: 0.1939
Epoch 3 [79/172] - loss: 0.1310
Epoch 3 [80/172] - loss: 0.2366, acc: 0.9062
Epoch 3 [81/172] - loss: 0.1592
Epoch 3 [82/172] - loss: 0.1725
Epoch 3 [83/172] - loss: 0.1307
Epoch 3 [84/172] - loss: 0.1264
Epoch 3 [85/172] - loss: 0.1427
Epoch 3 [86/172] - loss: 0.1193
Epoch 3 [87/172] - loss: 0.2011
Epoch 3 [88/172] - loss: 0.1540
Epoch 3 [89/172] - loss: 0.1250
Epoch 3 [90/172] - loss: 0.1427, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1553
Epoch 3 [92/172] - loss: 0.2224
Epoch 3 [93/172] - loss: 0.1827
Epoch 3 [94/172] - loss: 0.1553
Epoch 3 [95/172] - loss: 0.1362
Epoch 3 [96/172] - loss: 0.1690
Epoch 3 [97/172] - loss: 0.1315
Epoch 3 [98/172] - loss: 0.1382
Epoch 3 [99/172] - loss: 0.1321
Epoch 3 [100/172] - loss: 0.2150, acc: 0.9062
Epoch 3 [101/172] - loss: 0.2147
Epoch 3 [102/172] - loss: 0.1461
Epoch 3 [103/172] - loss: 0.1686
Epoch 3 [104/172] - loss: 0.1850
Epoch 3 [105/172] - loss: 0.1343
Epoch 3 [106/172] - loss: 0.2017
Epoch 3 [107/172] - loss: 0.1210
Epoch 3 [108/172] - loss: 0.1311
Epoch 3 [109/172] - loss: 0.1125
Epoch 3 [110/172] - loss: 0.1314, acc: 1.0000
Epoch 3 [111/172] - loss: 0.1802
Epoch 3 [112/172] - loss: 0.1273
Epoch 3 [113/172] - loss: 0.1427
Epoch 3 [114/172] - loss: 0.1363
Epoch 3 [115/172] - loss: 0.1268
Epoch 3 [116/172] - loss: 0.1941
Epoch 3 [117/172] - loss: 0.1794
Epoch 3 [118/172] - loss: 0.1295
Epoch 3 [119/172] - loss: 0.1391
Epoch 3 [120/172] - loss: 0.1991, acc: 0.9375
Epoch 3 [121/172] - loss: 0.1690
Epoch 3 [122/172] - loss: 0.2014
Epoch 3 [123/172] - loss: 0.1498
Epoch 3 [124/172] - loss: 0.1569
Epoch 3 [125/172] - loss: 0.1138
Epoch 3 [126/172] - loss: 0.2707
Epoch 3 [127/172] - loss: 0.1688
Epoch 3 [128/172] - loss: 0.1154
Epoch 3 [129/172] - loss: 0.1548
Epoch 3 [130/172] - loss: 0.1248, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1523
Epoch 3 [132/172] - loss: 0.1199
Epoch 3 [133/172] - loss: 0.1408
Epoch 3 [134/172] - loss: 0.1344
Epoch 3 [135/172] - loss: 0.1259
Epoch 3 [136/172] - loss: 0.1442
Epoch 3 [137/172] - loss: 0.1185
Epoch 3 [138/172] - loss: 0.1514
Epoch 3 [139/172] - loss: 0.1516
Epoch 3 [140/172] - loss: 0.1521, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1506
Epoch 3 [142/172] - loss: 0.1845
Epoch 3 [143/172] - loss: 0.1567
Epoch 3 [144/172] - loss: 0.1693
Epoch 3 [145/172] - loss: 0.1401
Epoch 3 [146/172] - loss: 0.1382
Epoch 3 [147/172] - loss: 0.1495
Epoch 3 [148/172] - loss: 0.1447
Epoch 3 [149/172] - loss: 0.1963
Epoch 3 [150/172] - loss: 0.1952, acc: 0.9375
Epoch 3 [151/172] - loss: 0.2463
Epoch 3 [152/172] - loss: 0.1686
Epoch 3 [153/172] - loss: 0.1415
Epoch 3 [154/172] - loss: 0.1471
Epoch 3 [155/172] - loss: 0.1167
Epoch 3 [156/172] - loss: 0.1196

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2738, log_difficulty=0.2420, weight=2.2099
neutral: count=4903.0, difficulty=0.1954, log_difficulty=0.1785, weight=1.8925
negative: count=5500.0, difficulty=0.2525, log_difficulty=0.2252, weight=2.1258

当前batch的pt分布：
positive: min=0.8494, max=0.9992, mean=0.9597
neutral: min=0.9378, max=0.9990, mean=0.9759
negative: min=0.6623, max=0.9996, mean=0.9014

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0592
焦点损失: 0.0027
边界损失: 0.1640
总损失: 0.1244
Epoch 3 [157/172] - loss: 0.1244
Epoch 3 [158/172] - loss: 0.1401
Epoch 3 [159/172] - loss: 0.1380
Epoch 3 [160/172] - loss: 0.2800, acc: 0.9062
Epoch 3 [161/172] - loss: 0.1916
Epoch 3 [162/172] - loss: 0.1722
Epoch 3 [163/172] - loss: 0.1879
Epoch 3 [164/172] - loss: 0.1907
Epoch 3 [165/172] - loss: 0.1360
Epoch 3 [166/172] - loss: 0.1214
Epoch 3 [167/172] - loss: 0.1752
Epoch 3 [168/172] - loss: 0.1237
Epoch 3 [169/172] - loss: 0.1187
Epoch 3 [170/172] - loss: 0.1550, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1657
Epoch 3 [172/172] - loss: 0.1316

类别准确率:
positive: 0.8758 (409/467)
neutral: 0.1928 (16/83)
negative: 0.5960 (149/250)

Epoch 3/10
Train Loss: 0.1595, Train Acc: 0.9596
Val Loss: 0.9002, Val Acc: 0.7175
Epoch 4 [1/172] - loss: 0.1310, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1326
Epoch 4 [3/172] - loss: 0.1503
Epoch 4 [4/172] - loss: 0.1470
Epoch 4 [5/172] - loss: 0.1326
Epoch 4 [6/172] - loss: 0.1180
Epoch 4 [7/172] - loss: 0.1341
Epoch 4 [8/172] - loss: 0.1159
Epoch 4 [9/172] - loss: 0.1360
Epoch 4 [10/172] - loss: 0.1357, acc: 0.9688
Epoch 4 [11/172] - loss: 0.1209
Epoch 4 [12/172] - loss: 0.1345
Epoch 4 [13/172] - loss: 0.1582
Epoch 4 [14/172] - loss: 0.1706
Epoch 4 [15/172] - loss: 0.1188
Epoch 4 [16/172] - loss: 0.1146
Epoch 4 [17/172] - loss: 0.1264
Epoch 4 [18/172] - loss: 0.1301
Epoch 4 [19/172] - loss: 0.1287
Epoch 4 [20/172] - loss: 0.1378, acc: 0.9688
Epoch 4 [21/172] - loss: 0.2232
Epoch 4 [22/172] - loss: 0.1210
Epoch 4 [23/172] - loss: 0.1546
Epoch 4 [24/172] - loss: 0.1234
Epoch 4 [25/172] - loss: 0.1139
Epoch 4 [26/172] - loss: 0.2038
Epoch 4 [27/172] - loss: 0.1123
Epoch 4 [28/172] - loss: 0.1411
Epoch 4 [29/172] - loss: 0.1284
Epoch 4 [30/172] - loss: 0.1841, acc: 0.9375
Epoch 4 [31/172] - loss: 0.2115
Epoch 4 [32/172] - loss: 0.1161
Epoch 4 [33/172] - loss: 0.1154
Epoch 4 [34/172] - loss: 0.1156
Epoch 4 [35/172] - loss: 0.1201
Epoch 4 [36/172] - loss: 0.1223
Epoch 4 [37/172] - loss: 0.1118
Epoch 4 [38/172] - loss: 0.1092
Epoch 4 [39/172] - loss: 0.1435
Epoch 4 [40/172] - loss: 0.1884, acc: 0.9375
Epoch 4 [41/172] - loss: 0.1166
Epoch 4 [42/172] - loss: 0.1963
Epoch 4 [43/172] - loss: 0.1357
Epoch 4 [44/172] - loss: 0.1144
Epoch 4 [45/172] - loss: 0.1189
Epoch 4 [46/172] - loss: 0.1104
Epoch 4 [47/172] - loss: 0.1241
Epoch 4 [48/172] - loss: 0.1222
Epoch 4 [49/172] - loss: 0.1193
Epoch 4 [50/172] - loss: 0.1169, acc: 1.0000
Epoch 4 [51/172] - loss: 0.1097
Epoch 4 [52/172] - loss: 0.1225
Epoch 4 [53/172] - loss: 0.1108
Epoch 4 [54/172] - loss: 0.1182
Epoch 4 [55/172] - loss: 0.1494
Epoch 4 [56/172] - loss: 0.1205
Epoch 4 [57/172] - loss: 0.1208
Epoch 4 [58/172] - loss: 0.1334
Epoch 4 [59/172] - loss: 0.1094
Epoch 4 [60/172] - loss: 0.1129, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1271
Epoch 4 [62/172] - loss: 0.1412
Epoch 4 [63/172] - loss: 0.1190
Epoch 4 [64/172] - loss: 0.1138
Epoch 4 [65/172] - loss: 0.1394
Epoch 4 [66/172] - loss: 0.1116
Epoch 4 [67/172] - loss: 0.1232
Epoch 4 [68/172] - loss: 0.1124
Epoch 4 [69/172] - loss: 0.1346
Epoch 4 [70/172] - loss: 0.1126, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1193
Epoch 4 [72/172] - loss: 0.1134
Epoch 4 [73/172] - loss: 0.1148
Epoch 4 [74/172] - loss: 0.2140
Epoch 4 [75/172] - loss: 0.1171
Epoch 4 [76/172] - loss: 0.1076
Epoch 4 [77/172] - loss: 0.1446
Epoch 4 [78/172] - loss: 0.1227
Epoch 4 [79/172] - loss: 0.1118
Epoch 4 [80/172] - loss: 0.1141, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1243
Epoch 4 [82/172] - loss: 0.1102
Epoch 4 [83/172] - loss: 0.1110
Epoch 4 [84/172] - loss: 0.1502

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2394, log_difficulty=0.2146, weight=2.0731
neutral: count=5865.0, difficulty=0.1708, log_difficulty=0.1577, weight=1.7885
negative: count=6629.0, difficulty=0.2207, log_difficulty=0.1995, weight=1.9973

当前batch的pt分布：
positive: min=0.7354, max=0.9936, mean=0.9175
neutral: min=0.9346, max=0.9999, mean=0.9887
negative: min=0.0399, max=0.9992, mean=0.8879

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.1494
焦点损失: 0.0935
边界损失: 0.1585
总损失: 0.1656
Epoch 4 [85/172] - loss: 0.1656
Epoch 4 [86/172] - loss: 0.1381
Epoch 4 [87/172] - loss: 0.1166
Epoch 4 [88/172] - loss: 0.1390
Epoch 4 [89/172] - loss: 0.1114
Epoch 4 [90/172] - loss: 0.1108, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1612
Epoch 4 [92/172] - loss: 0.1705
Epoch 4 [93/172] - loss: 0.1094
Epoch 4 [94/172] - loss: 0.1094
Epoch 4 [95/172] - loss: 0.1553
Epoch 4 [96/172] - loss: 0.1150
Epoch 4 [97/172] - loss: 0.1333
Epoch 4 [98/172] - loss: 0.1142
Epoch 4 [99/172] - loss: 0.1151
Epoch 4 [100/172] - loss: 0.1297, acc: 0.9688
Epoch 4 [101/172] - loss: 0.1225
Epoch 4 [102/172] - loss: 0.1687
Epoch 4 [103/172] - loss: 0.1159
Epoch 4 [104/172] - loss: 0.1156
Epoch 4 [105/172] - loss: 0.1383
Epoch 4 [106/172] - loss: 0.1254
Epoch 4 [107/172] - loss: 0.1082
Epoch 4 [108/172] - loss: 0.1435
Epoch 4 [109/172] - loss: 0.1112
Epoch 4 [110/172] - loss: 0.1531, acc: 0.9375
Epoch 4 [111/172] - loss: 0.1099
Epoch 4 [112/172] - loss: 0.1109
Epoch 4 [113/172] - loss: 0.1108
Epoch 4 [114/172] - loss: 0.1180
Epoch 4 [115/172] - loss: 0.1482
Epoch 4 [116/172] - loss: 0.1453
Epoch 4 [117/172] - loss: 0.1092
Epoch 4 [118/172] - loss: 0.1255
Epoch 4 [119/172] - loss: 0.1094
Epoch 4 [120/172] - loss: 0.1126, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1782
Epoch 4 [122/172] - loss: 0.2213
Epoch 4 [123/172] - loss: 0.1106
Epoch 4 [124/172] - loss: 0.1176
Epoch 4 [125/172] - loss: 0.1486
Epoch 4 [126/172] - loss: 0.1664
Epoch 4 [127/172] - loss: 0.1265
Epoch 4 [128/172] - loss: 0.1226
Epoch 4 [129/172] - loss: 0.1115
Epoch 4 [130/172] - loss: 0.1072, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1119
Epoch 4 [132/172] - loss: 0.1129
Epoch 4 [133/172] - loss: 0.1244
Epoch 4 [134/172] - loss: 0.1120
Epoch 4 [135/172] - loss: 0.1389
Epoch 4 [136/172] - loss: 0.1349
Epoch 4 [137/172] - loss: 0.1178
Epoch 4 [138/172] - loss: 0.1074
Epoch 4 [139/172] - loss: 0.1081
Epoch 4 [140/172] - loss: 0.1244, acc: 0.9688
Epoch 4 [141/172] - loss: 0.1237
Epoch 4 [142/172] - loss: 0.1327
Epoch 4 [143/172] - loss: 0.1136
Epoch 4 [144/172] - loss: 0.1340
Epoch 4 [145/172] - loss: 0.2245
Epoch 4 [146/172] - loss: 0.1120
Epoch 4 [147/172] - loss: 0.1132
Epoch 4 [148/172] - loss: 0.1293
Epoch 4 [149/172] - loss: 0.1165
Epoch 4 [150/172] - loss: 0.1434, acc: 0.9688
Epoch 4 [151/172] - loss: 0.1931
Epoch 4 [152/172] - loss: 0.1106
Epoch 4 [153/172] - loss: 0.1121
Epoch 4 [154/172] - loss: 0.1499
Epoch 4 [155/172] - loss: 0.1252
Epoch 4 [156/172] - loss: 0.1123
Epoch 4 [157/172] - loss: 0.2710
Epoch 4 [158/172] - loss: 0.1102
Epoch 4 [159/172] - loss: 0.1117
Epoch 4 [160/172] - loss: 0.1138, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1182
Epoch 4 [162/172] - loss: 0.1093
Epoch 4 [163/172] - loss: 0.1250
Epoch 4 [164/172] - loss: 0.1102
Epoch 4 [165/172] - loss: 0.2218
Epoch 4 [166/172] - loss: 0.1283
Epoch 4 [167/172] - loss: 0.1367
Epoch 4 [168/172] - loss: 0.1113
Epoch 4 [169/172] - loss: 0.1671
Epoch 4 [170/172] - loss: 0.1331, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1160
Epoch 4 [172/172] - loss: 0.1260

类别准确率:
positive: 0.8630 (403/467)
neutral: 0.2289 (19/83)
negative: 0.6120 (153/250)

Epoch 4/10
Train Loss: 0.1381, Train Acc: 0.9758
Val Loss: 0.9489, Val Acc: 0.7188
Epoch 5 [1/172] - loss: 0.1079, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1306
Epoch 5 [3/172] - loss: 0.1087
Epoch 5 [4/172] - loss: 0.1160
Epoch 5 [5/172] - loss: 0.1094
Epoch 5 [6/172] - loss: 0.1173
Epoch 5 [7/172] - loss: 0.1203
Epoch 5 [8/172] - loss: 0.1258
Epoch 5 [9/172] - loss: 0.1450
Epoch 5 [10/172] - loss: 0.1130, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1211
Epoch 5 [12/172] - loss: 0.1124

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2127, log_difficulty=0.1929, weight=1.9644
neutral: count=6845.0, difficulty=0.1511, log_difficulty=0.1408, weight=1.7038
negative: count=7694.0, difficulty=0.1971, log_difficulty=0.1799, weight=1.8995

当前batch的pt分布：
positive: min=0.0172, max=0.9963, mean=0.9023
neutral: min=0.9791, max=0.9998, mean=0.9957
negative: min=0.8879, max=0.9969, mean=0.9740

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1496
焦点损失: 0.1226
边界损失: 0.1462
总损失: 0.1698
Epoch 5 [13/172] - loss: 0.1698
Epoch 5 [14/172] - loss: 0.1618
Epoch 5 [15/172] - loss: 0.1076
Epoch 5 [16/172] - loss: 0.1073
Epoch 5 [17/172] - loss: 0.1288
Epoch 5 [18/172] - loss: 0.1057
Epoch 5 [19/172] - loss: 0.1432
Epoch 5 [20/172] - loss: 0.1195, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1196
Epoch 5 [22/172] - loss: 0.1448
Epoch 5 [23/172] - loss: 0.1136
Epoch 5 [24/172] - loss: 0.1131
Epoch 5 [25/172] - loss: 0.1068
Epoch 5 [26/172] - loss: 0.1281
Epoch 5 [27/172] - loss: 0.1084
Epoch 5 [28/172] - loss: 0.1059
Epoch 5 [29/172] - loss: 0.1291
Epoch 5 [30/172] - loss: 0.1174, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1113
Epoch 5 [32/172] - loss: 0.1088
Epoch 5 [33/172] - loss: 0.1116
Epoch 5 [34/172] - loss: 0.1135
Epoch 5 [35/172] - loss: 0.1073
Epoch 5 [36/172] - loss: 0.1071
Epoch 5 [37/172] - loss: 0.1089
Epoch 5 [38/172] - loss: 0.1096
Epoch 5 [39/172] - loss: 0.1205
Epoch 5 [40/172] - loss: 0.1115, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1088
Epoch 5 [42/172] - loss: 0.1139
Epoch 5 [43/172] - loss: 0.1633
Epoch 5 [44/172] - loss: 0.1179
Epoch 5 [45/172] - loss: 0.1094
Epoch 5 [46/172] - loss: 0.1120
Epoch 5 [47/172] - loss: 0.1126
Epoch 5 [48/172] - loss: 0.1173
Epoch 5 [49/172] - loss: 0.1183
Epoch 5 [50/172] - loss: 0.1171, acc: 1.0000
Epoch 5 [51/172] - loss: 0.1265
Epoch 5 [52/172] - loss: 0.1451
Epoch 5 [53/172] - loss: 0.1210
Epoch 5 [54/172] - loss: 0.1087
Epoch 5 [55/172] - loss: 0.1145
Epoch 5 [56/172] - loss: 0.1188
Epoch 5 [57/172] - loss: 0.1072
Epoch 5 [58/172] - loss: 0.1099
Epoch 5 [59/172] - loss: 0.1297
Epoch 5 [60/172] - loss: 0.1102, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1120
Epoch 5 [62/172] - loss: 0.1119
Epoch 5 [63/172] - loss: 0.1626
Epoch 5 [64/172] - loss: 0.1174
Epoch 5 [65/172] - loss: 0.1107
Epoch 5 [66/172] - loss: 0.1085
Epoch 5 [67/172] - loss: 0.1073
Epoch 5 [68/172] - loss: 0.1226
Epoch 5 [69/172] - loss: 0.1089
Epoch 5 [70/172] - loss: 0.1069, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1153
Epoch 5 [72/172] - loss: 0.1078
Epoch 5 [73/172] - loss: 0.1096
Epoch 5 [74/172] - loss: 0.1192
Epoch 5 [75/172] - loss: 0.1080
Epoch 5 [76/172] - loss: 0.1319
Epoch 5 [77/172] - loss: 0.1089
Epoch 5 [78/172] - loss: 0.1520
Epoch 5 [79/172] - loss: 0.1067
Epoch 5 [80/172] - loss: 0.1078, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1486
Epoch 5 [82/172] - loss: 0.1158
Epoch 5 [83/172] - loss: 0.1085
Epoch 5 [84/172] - loss: 0.1069
Epoch 5 [85/172] - loss: 0.1628
Epoch 5 [86/172] - loss: 0.1115
Epoch 5 [87/172] - loss: 0.1236
Epoch 5 [88/172] - loss: 0.1308
Epoch 5 [89/172] - loss: 0.1074
Epoch 5 [90/172] - loss: 0.1258, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1085
Epoch 5 [92/172] - loss: 0.1087
Epoch 5 [93/172] - loss: 0.1092
Epoch 5 [94/172] - loss: 0.1056
Epoch 5 [95/172] - loss: 0.1137
Epoch 5 [96/172] - loss: 0.1089
Epoch 5 [97/172] - loss: 0.1179
Epoch 5 [98/172] - loss: 0.1112
Epoch 5 [99/172] - loss: 0.1728
Epoch 5 [100/172] - loss: 0.1131, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1140
Epoch 5 [102/172] - loss: 0.1136
Epoch 5 [103/172] - loss: 0.1180
Epoch 5 [104/172] - loss: 0.1333
Epoch 5 [105/172] - loss: 0.2119
Epoch 5 [106/172] - loss: 0.1133
Epoch 5 [107/172] - loss: 0.1096
Epoch 5 [108/172] - loss: 0.1268
Epoch 5 [109/172] - loss: 0.1059
Epoch 5 [110/172] - loss: 0.1082, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1127
Epoch 5 [112/172] - loss: 0.1069

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.1896, log_difficulty=0.1736, weight=1.8682
neutral: count=7825.0, difficulty=0.1355, log_difficulty=0.1271, weight=1.6354
negative: count=8780.0, difficulty=0.1779, log_difficulty=0.1637, weight=1.8187

当前batch的pt分布：
positive: min=0.7844, max=0.9957, mean=0.9414
neutral: min=0.9405, max=0.9989, mean=0.9821
negative: min=0.9979, max=0.9997, mean=0.9990

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0377
焦点损失: 0.0006
边界损失: 0.1537
总损失: 0.1156
Epoch 5 [113/172] - loss: 0.1156
Epoch 5 [114/172] - loss: 0.1134
Epoch 5 [115/172] - loss: 0.1179
Epoch 5 [116/172] - loss: 0.1058
Epoch 5 [117/172] - loss: 0.1175
Epoch 5 [118/172] - loss: 0.1071
Epoch 5 [119/172] - loss: 0.1075
Epoch 5 [120/172] - loss: 0.1092, acc: 1.0000
Epoch 5 [121/172] - loss: 0.1139
Epoch 5 [122/172] - loss: 0.1105
Epoch 5 [123/172] - loss: 0.1114
Epoch 5 [124/172] - loss: 0.1097
Epoch 5 [125/172] - loss: 0.1067
Epoch 5 [126/172] - loss: 0.1075
Epoch 5 [127/172] - loss: 0.1196
Epoch 5 [128/172] - loss: 0.1195
Epoch 5 [129/172] - loss: 0.1265
Epoch 5 [130/172] - loss: 0.1069, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1132
Epoch 5 [132/172] - loss: 0.1273
Epoch 5 [133/172] - loss: 0.1275
Epoch 5 [134/172] - loss: 0.1513
Epoch 5 [135/172] - loss: 0.1068
Epoch 5 [136/172] - loss: 0.1064
Epoch 5 [137/172] - loss: 0.1206
Epoch 5 [138/172] - loss: 0.1239
Epoch 5 [139/172] - loss: 0.2260
Epoch 5 [140/172] - loss: 0.1162, acc: 0.9688
Epoch 5 [141/172] - loss: 0.1072
Epoch 5 [142/172] - loss: 0.1078
Epoch 5 [143/172] - loss: 0.1060
Epoch 5 [144/172] - loss: 0.1072
Epoch 5 [145/172] - loss: 0.1258
Epoch 5 [146/172] - loss: 0.1055
Epoch 5 [147/172] - loss: 0.1141
Epoch 5 [148/172] - loss: 0.1070
Epoch 5 [149/172] - loss: 0.1063
Epoch 5 [150/172] - loss: 0.1339, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1054
Epoch 5 [152/172] - loss: 0.1063
Epoch 5 [153/172] - loss: 0.1057
Epoch 5 [154/172] - loss: 0.1160
Epoch 5 [155/172] - loss: 0.1518
Epoch 5 [156/172] - loss: 0.1110
Epoch 5 [157/172] - loss: 0.1074
Epoch 5 [158/172] - loss: 0.1062
Epoch 5 [159/172] - loss: 0.1068
Epoch 5 [160/172] - loss: 0.1062, acc: 1.0000
Epoch 5 [161/172] - loss: 0.1087
Epoch 5 [162/172] - loss: 0.1148
Epoch 5 [163/172] - loss: 0.1527
Epoch 5 [164/172] - loss: 0.1055
Epoch 5 [165/172] - loss: 0.1286
Epoch 5 [166/172] - loss: 0.1190
Epoch 5 [167/172] - loss: 0.1204
Epoch 5 [168/172] - loss: 0.1074
Epoch 5 [169/172] - loss: 0.1084
Epoch 5 [170/172] - loss: 0.1061, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1205
Epoch 5 [172/172] - loss: 0.1120

类别准确率:
positive: 0.8351 (390/467)
neutral: 0.2892 (24/83)
negative: 0.6360 (159/250)

Epoch 5/10
Train Loss: 0.1144, Train Acc: 0.9939
Val Loss: 0.9157, Val Acc: 0.7163
Early stopping triggered!
Best validation accuracy: 0.7188

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_062629-c0ku8pds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.2_Multimodal_iterations_20250118_062628
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/c0ku8pds
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████
wandb:  train_acc ▂▃▁▅▅▅▆▆▅▇▇▇▇▇▇█▇▇██▇▇█▇▇▇██▇███████████
wandb: train_loss ███▆▅▅▃▃▄▃▂▃▃▂▃▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 858
wandb:  train_acc 1
wandb: train_loss 0.10605
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.2_Multimodal_iterations_20250118_062628 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/c0ku8pds
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_062629-c0ku8pds/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_063408-8li90bq2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.2_Multimodal_epochs_20250118_063408
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/8li90bq2
wandb: uploading history steps 0-0, summary; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▃▅▆█
wandb:  train_acc ▁▅▇▇█
wandb: train_loss █▄▂▂▁
wandb:    val_acc ▁███▇
wandb:   val_loss ▁▂▇█▇
wandb: 
wandb: Run summary:
wandb:      epoch 5
wandb:  train_acc 0.99394
wandb: train_loss 0.11441
wandb:    val_acc 0.71625
wandb:   val_loss 0.91565
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.2_Multimodal_epochs_20250118_063408 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/8li90bq2
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_063408-8li90bq2/logs

