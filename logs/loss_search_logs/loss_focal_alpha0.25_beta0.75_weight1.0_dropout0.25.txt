=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 1.0 --dropout 0.25 --name loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.25 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.25
text_dim: 128
image_dim: 256
dropout: 0.25
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6816, log_difficulty=0.5197, weight=3.5987
neutral: count=7.0, difficulty=0.6660, log_difficulty=0.5104, weight=3.5521
negative: count=13.0, difficulty=0.6175, log_difficulty=0.4809, weight=3.4043

当前batch的pt分布：
positive: min=0.1965, max=0.4070, mean=0.3184
neutral: min=0.2136, max=0.3739, mean=0.3340
negative: min=0.1981, max=0.8719, mean=0.3825

当前batch准确率：
整体准确率: 0.2812
positive 准确率: 0.2500
neutral 准确率: 0.1429
negative 准确率: 0.3846

损失分量：
基础交叉熵: 1.0951
焦点损失: 0.3524
边界损失: 0.8402
总损失: 0.9398
Epoch 1 [1/172] - loss: 0.9398, acc: 0.2812
Epoch 1 [2/172] - loss: 0.9429
Epoch 1 [3/172] - loss: 0.9173
Epoch 1 [4/172] - loss: 0.8377
Epoch 1 [5/172] - loss: 0.8373
Epoch 1 [6/172] - loss: 0.9805
Epoch 1 [7/172] - loss: 0.8991
Epoch 1 [8/172] - loss: 0.9618
Epoch 1 [9/172] - loss: 1.0112
Epoch 1 [10/172] - loss: 0.8957, acc: 0.3750
Epoch 1 [11/172] - loss: 0.8634
Epoch 1 [12/172] - loss: 0.8496
Epoch 1 [13/172] - loss: 0.9116
Epoch 1 [14/172] - loss: 0.9784
Epoch 1 [15/172] - loss: 0.9089
Epoch 1 [16/172] - loss: 0.8926
Epoch 1 [17/172] - loss: 0.9497
Epoch 1 [18/172] - loss: 0.9031
Epoch 1 [19/172] - loss: 0.8264
Epoch 1 [20/172] - loss: 0.9082, acc: 0.3750
Epoch 1 [21/172] - loss: 0.8367
Epoch 1 [22/172] - loss: 0.9110
Epoch 1 [23/172] - loss: 0.9733
Epoch 1 [24/172] - loss: 0.8998
Epoch 1 [25/172] - loss: 0.7874
Epoch 1 [26/172] - loss: 0.9371
Epoch 1 [27/172] - loss: 0.8542
Epoch 1 [28/172] - loss: 0.9489
Epoch 1 [29/172] - loss: 0.7869
Epoch 1 [30/172] - loss: 0.7810, acc: 0.5000
Epoch 1 [31/172] - loss: 0.9432
Epoch 1 [32/172] - loss: 0.7791
Epoch 1 [33/172] - loss: 0.7576
Epoch 1 [34/172] - loss: 0.7775
Epoch 1 [35/172] - loss: 0.8546
Epoch 1 [36/172] - loss: 0.6866
Epoch 1 [37/172] - loss: 0.6875
Epoch 1 [38/172] - loss: 0.8527
Epoch 1 [39/172] - loss: 0.7721
Epoch 1 [40/172] - loss: 0.7414, acc: 0.5625
Epoch 1 [41/172] - loss: 0.7620
Epoch 1 [42/172] - loss: 0.6935
Epoch 1 [43/172] - loss: 0.6804
Epoch 1 [44/172] - loss: 0.9111
Epoch 1 [45/172] - loss: 0.8761
Epoch 1 [46/172] - loss: 0.6403
Epoch 1 [47/172] - loss: 0.8377
Epoch 1 [48/172] - loss: 0.7373
Epoch 1 [49/172] - loss: 0.7720
Epoch 1 [50/172] - loss: 0.7622, acc: 0.5312
Epoch 1 [51/172] - loss: 0.7891
Epoch 1 [52/172] - loss: 0.8966
Epoch 1 [53/172] - loss: 0.8143
Epoch 1 [54/172] - loss: 0.7156
Epoch 1 [55/172] - loss: 0.7406
Epoch 1 [56/172] - loss: 0.6455
Epoch 1 [57/172] - loss: 0.7708
Epoch 1 [58/172] - loss: 0.6502
Epoch 1 [59/172] - loss: 0.8658
Epoch 1 [60/172] - loss: 0.7193, acc: 0.5312
Epoch 1 [61/172] - loss: 0.9098
Epoch 1 [62/172] - loss: 0.5919
Epoch 1 [63/172] - loss: 0.7890
Epoch 1 [64/172] - loss: 0.4709
Epoch 1 [65/172] - loss: 0.7191
Epoch 1 [66/172] - loss: 0.7306
Epoch 1 [67/172] - loss: 0.8701
Epoch 1 [68/172] - loss: 0.7910
Epoch 1 [69/172] - loss: 0.8546
Epoch 1 [70/172] - loss: 0.6330, acc: 0.5938
Epoch 1 [71/172] - loss: 0.5798
Epoch 1 [72/172] - loss: 0.6011
Epoch 1 [73/172] - loss: 0.6699
Epoch 1 [74/172] - loss: 0.7323
Epoch 1 [75/172] - loss: 0.5902
Epoch 1 [76/172] - loss: 0.5783
Epoch 1 [77/172] - loss: 0.6758
Epoch 1 [78/172] - loss: 0.6757
Epoch 1 [79/172] - loss: 0.5725
Epoch 1 [80/172] - loss: 0.4240, acc: 0.7812
Epoch 1 [81/172] - loss: 0.6181
Epoch 1 [82/172] - loss: 0.8430
Epoch 1 [83/172] - loss: 0.6140
Epoch 1 [84/172] - loss: 0.7026
Epoch 1 [85/172] - loss: 0.5730
Epoch 1 [86/172] - loss: 0.6103
Epoch 1 [87/172] - loss: 0.5081
Epoch 1 [88/172] - loss: 0.6219
Epoch 1 [89/172] - loss: 0.7030
Epoch 1 [90/172] - loss: 0.6769, acc: 0.4688
Epoch 1 [91/172] - loss: 0.6164
Epoch 1 [92/172] - loss: 0.5902
Epoch 1 [93/172] - loss: 0.7284
Epoch 1 [94/172] - loss: 0.5294
Epoch 1 [95/172] - loss: 0.5631
Epoch 1 [96/172] - loss: 0.6628
Epoch 1 [97/172] - loss: 0.6264
Epoch 1 [98/172] - loss: 0.5219
Epoch 1 [99/172] - loss: 0.6879
Epoch 1 [100/172] - loss: 0.5604, acc: 0.6875

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5626, log_difficulty=0.4464, weight=3.2319
neutral: count=983.0, difficulty=0.5553, log_difficulty=0.4417, weight=3.2083
negative: count=1119.0, difficulty=0.5823, log_difficulty=0.4589, weight=3.2943

当前batch的pt分布：
positive: min=0.0676, max=0.9481, mean=0.4966
neutral: min=0.4268, max=0.9874, mean=0.8160
negative: min=0.0828, max=0.9616, mean=0.4636

当前batch准确率：
整体准确率: 0.5625
positive 准确率: 0.5833
neutral 准确率: 0.7500
negative 准确率: 0.5000

损失分量：
基础交叉熵: 0.8999
焦点损失: 0.4328
边界损失: 0.3778
总损失: 0.6363
Epoch 1 [101/172] - loss: 0.6363
Epoch 1 [102/172] - loss: 0.4999
Epoch 1 [103/172] - loss: 0.5696
Epoch 1 [104/172] - loss: 0.4172
Epoch 1 [105/172] - loss: 0.7582
Epoch 1 [106/172] - loss: 0.6554
Epoch 1 [107/172] - loss: 0.5557
Epoch 1 [108/172] - loss: 0.7996
Epoch 1 [109/172] - loss: 0.5299
Epoch 1 [110/172] - loss: 0.5500, acc: 0.6562
Epoch 1 [111/172] - loss: 0.6206
Epoch 1 [112/172] - loss: 0.4276
Epoch 1 [113/172] - loss: 0.3996
Epoch 1 [114/172] - loss: 0.4926
Epoch 1 [115/172] - loss: 0.6091
Epoch 1 [116/172] - loss: 0.4860
Epoch 1 [117/172] - loss: 0.5120
Epoch 1 [118/172] - loss: 0.5208
Epoch 1 [119/172] - loss: 0.5636
Epoch 1 [120/172] - loss: 0.3938, acc: 0.8125
Epoch 1 [121/172] - loss: 0.4063
Epoch 1 [122/172] - loss: 0.7545
Epoch 1 [123/172] - loss: 0.3926
Epoch 1 [124/172] - loss: 0.5262
Epoch 1 [125/172] - loss: 0.3413
Epoch 1 [126/172] - loss: 0.5661
Epoch 1 [127/172] - loss: 0.4486
Epoch 1 [128/172] - loss: 0.3633
Epoch 1 [129/172] - loss: 0.6630
Epoch 1 [130/172] - loss: 0.3576, acc: 0.7500
Epoch 1 [131/172] - loss: 0.3839
Epoch 1 [132/172] - loss: 0.5817
Epoch 1 [133/172] - loss: 0.6622
Epoch 1 [134/172] - loss: 0.3136
Epoch 1 [135/172] - loss: 0.5360
Epoch 1 [136/172] - loss: 0.4268
Epoch 1 [137/172] - loss: 0.5108
Epoch 1 [138/172] - loss: 0.3555
Epoch 1 [139/172] - loss: 0.3714
Epoch 1 [140/172] - loss: 0.5132, acc: 0.7188
Epoch 1 [141/172] - loss: 0.4130
Epoch 1 [142/172] - loss: 0.3837
Epoch 1 [143/172] - loss: 0.4722
Epoch 1 [144/172] - loss: 0.4229
Epoch 1 [145/172] - loss: 0.4562
Epoch 1 [146/172] - loss: 0.4357
Epoch 1 [147/172] - loss: 0.5662
Epoch 1 [148/172] - loss: 0.5126
Epoch 1 [149/172] - loss: 0.3563
Epoch 1 [150/172] - loss: 0.4612, acc: 0.6562
Epoch 1 [151/172] - loss: 0.5409
Epoch 1 [152/172] - loss: 0.3677
Epoch 1 [153/172] - loss: 0.4273
Epoch 1 [154/172] - loss: 0.4131
Epoch 1 [155/172] - loss: 0.4417
Epoch 1 [156/172] - loss: 0.5613
Epoch 1 [157/172] - loss: 0.4901
Epoch 1 [158/172] - loss: 0.4723
Epoch 1 [159/172] - loss: 0.7323
Epoch 1 [160/172] - loss: 0.5507, acc: 0.6875
Epoch 1 [161/172] - loss: 0.3781
Epoch 1 [162/172] - loss: 0.3709
Epoch 1 [163/172] - loss: 0.3918
Epoch 1 [164/172] - loss: 0.4885
Epoch 1 [165/172] - loss: 0.4198
Epoch 1 [166/172] - loss: 0.3284
Epoch 1 [167/172] - loss: 0.4147
Epoch 1 [168/172] - loss: 0.4209
Epoch 1 [169/172] - loss: 0.4267
Epoch 1 [170/172] - loss: 0.4531, acc: 0.7188
Epoch 1 [171/172] - loss: 0.4030
Epoch 1 [172/172] - loss: 0.3442

类别准确率:
positive: 0.7901 (369/467)
neutral: 0.5904 (49/83)
negative: 0.4840 (121/250)

Epoch 1/10
Train Loss: 0.4429, Train Acc: 0.7495
Val Loss: 0.7625, Val Acc: 0.6737
Epoch 2 [1/172] - loss: 0.3686, acc: 0.7188
Epoch 2 [2/172] - loss: 0.3729
Epoch 2 [3/172] - loss: 0.2654
Epoch 2 [4/172] - loss: 0.3144
Epoch 2 [5/172] - loss: 0.5037
Epoch 2 [6/172] - loss: 0.3629
Epoch 2 [7/172] - loss: 0.4130
Epoch 2 [8/172] - loss: 0.4270
Epoch 2 [9/172] - loss: 0.2601
Epoch 2 [10/172] - loss: 0.3239, acc: 0.8750
Epoch 2 [11/172] - loss: 0.2878
Epoch 2 [12/172] - loss: 0.2971
Epoch 2 [13/172] - loss: 0.3314
Epoch 2 [14/172] - loss: 0.3718
Epoch 2 [15/172] - loss: 0.3123
Epoch 2 [16/172] - loss: 0.3026
Epoch 2 [17/172] - loss: 0.4859
Epoch 2 [18/172] - loss: 0.4755
Epoch 2 [19/172] - loss: 0.3545
Epoch 2 [20/172] - loss: 0.3352, acc: 0.7812
Epoch 2 [21/172] - loss: 0.3896
Epoch 2 [22/172] - loss: 0.3600
Epoch 2 [23/172] - loss: 0.2999
Epoch 2 [24/172] - loss: 0.5522
Epoch 2 [25/172] - loss: 0.3683
Epoch 2 [26/172] - loss: 0.2868
Epoch 2 [27/172] - loss: 0.2762
Epoch 2 [28/172] - loss: 0.3378

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4672, log_difficulty=0.3834, weight=2.9168
neutral: count=1952.0, difficulty=0.4296, log_difficulty=0.3574, weight=2.7869
negative: count=2216.0, difficulty=0.4879, log_difficulty=0.3973, weight=2.9867

当前batch的pt分布：
positive: min=0.3051, max=0.9905, mean=0.7436
neutral: min=0.4187, max=0.9846, mean=0.8073
negative: min=0.0979, max=0.9434, mean=0.6662

当前batch准确率：
整体准确率: 0.7812
positive 准确率: 0.7778
neutral 准确率: 0.9091
negative 准确率: 0.6667

损失分量：
基础交叉熵: 0.4032
焦点损失: 0.1292
边界损失: 0.2746
总损失: 0.3016
Epoch 2 [29/172] - loss: 0.3016
Epoch 2 [30/172] - loss: 0.3296, acc: 0.8438
Epoch 2 [31/172] - loss: 0.3195
Epoch 2 [32/172] - loss: 0.3190
Epoch 2 [33/172] - loss: 0.2563
Epoch 2 [34/172] - loss: 0.3498
Epoch 2 [35/172] - loss: 0.2702
Epoch 2 [36/172] - loss: 0.3755
Epoch 2 [37/172] - loss: 0.2489
Epoch 2 [38/172] - loss: 0.3232
Epoch 2 [39/172] - loss: 0.4862
Epoch 2 [40/172] - loss: 0.4145, acc: 0.6875
Epoch 2 [41/172] - loss: 0.3064
Epoch 2 [42/172] - loss: 0.2012
Epoch 2 [43/172] - loss: 0.1865
Epoch 2 [44/172] - loss: 0.4502
Epoch 2 [45/172] - loss: 0.3463
Epoch 2 [46/172] - loss: 0.2584
Epoch 2 [47/172] - loss: 0.4140
Epoch 2 [48/172] - loss: 0.4471
Epoch 2 [49/172] - loss: 0.3709
Epoch 2 [50/172] - loss: 0.3924, acc: 0.6875
Epoch 2 [51/172] - loss: 0.3666
Epoch 2 [52/172] - loss: 0.3313
Epoch 2 [53/172] - loss: 0.3305
Epoch 2 [54/172] - loss: 0.2582
Epoch 2 [55/172] - loss: 0.2565
Epoch 2 [56/172] - loss: 0.3413
Epoch 2 [57/172] - loss: 0.2546
Epoch 2 [58/172] - loss: 0.3589
Epoch 2 [59/172] - loss: 0.4585
Epoch 2 [60/172] - loss: 0.2646, acc: 0.8438
Epoch 2 [61/172] - loss: 0.1927
Epoch 2 [62/172] - loss: 0.2096
Epoch 2 [63/172] - loss: 0.3378
Epoch 2 [64/172] - loss: 0.2437
Epoch 2 [65/172] - loss: 0.3078
Epoch 2 [66/172] - loss: 0.2707
Epoch 2 [67/172] - loss: 0.2441
Epoch 2 [68/172] - loss: 0.3222
Epoch 2 [69/172] - loss: 0.2327
Epoch 2 [70/172] - loss: 0.4794, acc: 0.6875
Epoch 2 [71/172] - loss: 0.3721
Epoch 2 [72/172] - loss: 0.3122
Epoch 2 [73/172] - loss: 0.3652
Epoch 2 [74/172] - loss: 0.2964
Epoch 2 [75/172] - loss: 0.2723
Epoch 2 [76/172] - loss: 0.2511
Epoch 2 [77/172] - loss: 0.2520
Epoch 2 [78/172] - loss: 0.3384
Epoch 2 [79/172] - loss: 0.2260
Epoch 2 [80/172] - loss: 0.2963, acc: 0.7812
Epoch 2 [81/172] - loss: 0.2775
Epoch 2 [82/172] - loss: 0.2701
Epoch 2 [83/172] - loss: 0.2866
Epoch 2 [84/172] - loss: 0.3523
Epoch 2 [85/172] - loss: 0.2523
Epoch 2 [86/172] - loss: 0.2536
Epoch 2 [87/172] - loss: 0.4724
Epoch 2 [88/172] - loss: 0.2777
Epoch 2 [89/172] - loss: 0.1968
Epoch 2 [90/172] - loss: 0.2896, acc: 0.8125
Epoch 2 [91/172] - loss: 0.1534
Epoch 2 [92/172] - loss: 0.4066
Epoch 2 [93/172] - loss: 0.2760
Epoch 2 [94/172] - loss: 0.2941
Epoch 2 [95/172] - loss: 0.3328
Epoch 2 [96/172] - loss: 0.2324
Epoch 2 [97/172] - loss: 0.2562
Epoch 2 [98/172] - loss: 0.2787
Epoch 2 [99/172] - loss: 0.1767
Epoch 2 [100/172] - loss: 0.3119, acc: 0.8438
Epoch 2 [101/172] - loss: 0.2627
Epoch 2 [102/172] - loss: 0.1908
Epoch 2 [103/172] - loss: 0.2590
Epoch 2 [104/172] - loss: 0.3371
Epoch 2 [105/172] - loss: 0.2788
Epoch 2 [106/172] - loss: 0.2068
Epoch 2 [107/172] - loss: 0.2230
Epoch 2 [108/172] - loss: 0.3960
Epoch 2 [109/172] - loss: 0.2172
Epoch 2 [110/172] - loss: 0.3140, acc: 0.8125
Epoch 2 [111/172] - loss: 0.2619
Epoch 2 [112/172] - loss: 0.1983
Epoch 2 [113/172] - loss: 0.1852
Epoch 2 [114/172] - loss: 0.2847
Epoch 2 [115/172] - loss: 0.2204
Epoch 2 [116/172] - loss: 0.2178
Epoch 2 [117/172] - loss: 0.5127
Epoch 2 [118/172] - loss: 0.1810
Epoch 2 [119/172] - loss: 0.3095
Epoch 2 [120/172] - loss: 0.2200, acc: 0.9062
Epoch 2 [121/172] - loss: 0.2161
Epoch 2 [122/172] - loss: 0.3521
Epoch 2 [123/172] - loss: 0.1939
Epoch 2 [124/172] - loss: 0.2291
Epoch 2 [125/172] - loss: 0.1710
Epoch 2 [126/172] - loss: 0.2544
Epoch 2 [127/172] - loss: 0.1941
Epoch 2 [128/172] - loss: 0.2402

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.4052, log_difficulty=0.3402, weight=2.7009
neutral: count=2949.0, difficulty=0.3376, log_difficulty=0.2909, weight=2.4545
negative: count=3294.0, difficulty=0.4118, log_difficulty=0.3449, weight=2.7244

当前batch的pt分布：
positive: min=0.3416, max=0.9816, mean=0.7802
neutral: min=0.5875, max=0.9913, mean=0.8793
negative: min=0.2722, max=0.9865, mean=0.7183

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.9000
neutral 准确率: 1.0000
negative 准确率: 0.7273

损失分量：
基础交叉熵: 0.2927
焦点损失: 0.0690
边界损失: 0.2514
总损失: 0.2353
Epoch 2 [129/172] - loss: 0.2353
Epoch 2 [130/172] - loss: 0.3028, acc: 0.8750
Epoch 2 [131/172] - loss: 0.2714
Epoch 2 [132/172] - loss: 0.2667
Epoch 2 [133/172] - loss: 0.2431
Epoch 2 [134/172] - loss: 0.2330
Epoch 2 [135/172] - loss: 0.2865
Epoch 2 [136/172] - loss: 0.2737
Epoch 2 [137/172] - loss: 0.2053
Epoch 2 [138/172] - loss: 0.2001
Epoch 2 [139/172] - loss: 0.1964
Epoch 2 [140/172] - loss: 0.2846, acc: 0.8438
Epoch 2 [141/172] - loss: 0.1665
Epoch 2 [142/172] - loss: 0.2747
Epoch 2 [143/172] - loss: 0.2140
Epoch 2 [144/172] - loss: 0.2543
Epoch 2 [145/172] - loss: 0.3901
Epoch 2 [146/172] - loss: 0.1410
Epoch 2 [147/172] - loss: 0.2216
Epoch 2 [148/172] - loss: 0.2662
Epoch 2 [149/172] - loss: 0.1773
Epoch 2 [150/172] - loss: 0.1984, acc: 0.9375
Epoch 2 [151/172] - loss: 0.2024
Epoch 2 [152/172] - loss: 0.2748
Epoch 2 [153/172] - loss: 0.2725
Epoch 2 [154/172] - loss: 0.1515
Epoch 2 [155/172] - loss: 0.1979
Epoch 2 [156/172] - loss: 0.1958
Epoch 2 [157/172] - loss: 0.1650
Epoch 2 [158/172] - loss: 0.1853
Epoch 2 [159/172] - loss: 0.3019
Epoch 2 [160/172] - loss: 0.1895, acc: 0.9688
Epoch 2 [161/172] - loss: 0.2624
Epoch 2 [162/172] - loss: 0.1684
Epoch 2 [163/172] - loss: 0.3078
Epoch 2 [164/172] - loss: 0.2698
Epoch 2 [165/172] - loss: 0.2857
Epoch 2 [166/172] - loss: 0.4128
Epoch 2 [167/172] - loss: 0.4172
Epoch 2 [168/172] - loss: 0.2089
Epoch 2 [169/172] - loss: 0.1876
Epoch 2 [170/172] - loss: 0.1607, acc: 0.9688
Epoch 2 [171/172] - loss: 0.2429
Epoch 2 [172/172] - loss: 0.4714

类别准确率:
positive: 0.8394 (392/467)
neutral: 0.4578 (38/83)
negative: 0.6080 (152/250)

Epoch 2/10
Train Loss: 0.2648, Train Acc: 0.8869
Val Loss: 0.7502, Val Acc: 0.7275
Epoch 3 [1/172] - loss: 0.2082, acc: 0.9688
Epoch 3 [2/172] - loss: 0.2582
Epoch 3 [3/172] - loss: 0.1449
Epoch 3 [4/172] - loss: 0.1523
Epoch 3 [5/172] - loss: 0.1694
Epoch 3 [6/172] - loss: 0.1524
Epoch 3 [7/172] - loss: 0.2068
Epoch 3 [8/172] - loss: 0.2673
Epoch 3 [9/172] - loss: 0.1505
Epoch 3 [10/172] - loss: 0.1784, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1415
Epoch 3 [12/172] - loss: 0.1241
Epoch 3 [13/172] - loss: 0.1445
Epoch 3 [14/172] - loss: 0.1540
Epoch 3 [15/172] - loss: 0.1720
Epoch 3 [16/172] - loss: 0.2089
Epoch 3 [17/172] - loss: 0.1818
Epoch 3 [18/172] - loss: 0.3232
Epoch 3 [19/172] - loss: 0.1590
Epoch 3 [20/172] - loss: 0.1424, acc: 1.0000
Epoch 3 [21/172] - loss: 0.1356
Epoch 3 [22/172] - loss: 0.3207
Epoch 3 [23/172] - loss: 0.1543
Epoch 3 [24/172] - loss: 0.2123
Epoch 3 [25/172] - loss: 0.1556
Epoch 3 [26/172] - loss: 0.1325
Epoch 3 [27/172] - loss: 0.1730
Epoch 3 [28/172] - loss: 0.1317
Epoch 3 [29/172] - loss: 0.1626
Epoch 3 [30/172] - loss: 0.1673, acc: 0.9688
Epoch 3 [31/172] - loss: 0.1512
Epoch 3 [32/172] - loss: 0.1525
Epoch 3 [33/172] - loss: 0.1362
Epoch 3 [34/172] - loss: 0.1801
Epoch 3 [35/172] - loss: 0.2370
Epoch 3 [36/172] - loss: 0.1371
Epoch 3 [37/172] - loss: 0.2411
Epoch 3 [38/172] - loss: 0.1917
Epoch 3 [39/172] - loss: 0.1420
Epoch 3 [40/172] - loss: 0.1550, acc: 1.0000
Epoch 3 [41/172] - loss: 0.1910
Epoch 3 [42/172] - loss: 0.1507
Epoch 3 [43/172] - loss: 0.1520
Epoch 3 [44/172] - loss: 0.1223
Epoch 3 [45/172] - loss: 0.1734
Epoch 3 [46/172] - loss: 0.1710
Epoch 3 [47/172] - loss: 0.1491
Epoch 3 [48/172] - loss: 0.1814
Epoch 3 [49/172] - loss: 0.1292
Epoch 3 [50/172] - loss: 0.1312, acc: 1.0000
Epoch 3 [51/172] - loss: 0.2058
Epoch 3 [52/172] - loss: 0.1676
Epoch 3 [53/172] - loss: 0.1330
Epoch 3 [54/172] - loss: 0.1786
Epoch 3 [55/172] - loss: 0.1652
Epoch 3 [56/172] - loss: 0.1581

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3452, log_difficulty=0.2966, weight=2.4829
neutral: count=3923.0, difficulty=0.2762, log_difficulty=0.2439, weight=2.2195
negative: count=4382.0, difficulty=0.3480, log_difficulty=0.2986, weight=2.4931

当前batch的pt分布：
positive: min=0.6699, max=0.9856, mean=0.9079
neutral: min=0.0234, max=0.9759, mean=0.8117
negative: min=0.9645, max=0.9994, mean=0.9904

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 1.0000
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.2349
焦点损失: 0.1255
边界损失: 0.1934
总损失: 0.2148
Epoch 3 [57/172] - loss: 0.2148
Epoch 3 [58/172] - loss: 0.1488
Epoch 3 [59/172] - loss: 0.2012
Epoch 3 [60/172] - loss: 0.1883, acc: 0.9375
Epoch 3 [61/172] - loss: 0.1289
Epoch 3 [62/172] - loss: 0.1762
Epoch 3 [63/172] - loss: 0.1315
Epoch 3 [64/172] - loss: 0.1615
Epoch 3 [65/172] - loss: 0.1710
Epoch 3 [66/172] - loss: 0.1984
Epoch 3 [67/172] - loss: 0.1483
Epoch 3 [68/172] - loss: 0.1375
Epoch 3 [69/172] - loss: 0.2788
Epoch 3 [70/172] - loss: 0.1354, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1494
Epoch 3 [72/172] - loss: 0.2167
Epoch 3 [73/172] - loss: 0.1401
Epoch 3 [74/172] - loss: 0.1945
Epoch 3 [75/172] - loss: 0.1429
Epoch 3 [76/172] - loss: 0.1374
Epoch 3 [77/172] - loss: 0.1337
Epoch 3 [78/172] - loss: 0.2037
Epoch 3 [79/172] - loss: 0.1239
Epoch 3 [80/172] - loss: 0.2519, acc: 0.8750
Epoch 3 [81/172] - loss: 0.1366
Epoch 3 [82/172] - loss: 0.2086
Epoch 3 [83/172] - loss: 0.1303
Epoch 3 [84/172] - loss: 0.1283
Epoch 3 [85/172] - loss: 0.1406
Epoch 3 [86/172] - loss: 0.1252
Epoch 3 [87/172] - loss: 0.1727
Epoch 3 [88/172] - loss: 0.1722
Epoch 3 [89/172] - loss: 0.1403
Epoch 3 [90/172] - loss: 0.1251, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1932
Epoch 3 [92/172] - loss: 0.1977
Epoch 3 [93/172] - loss: 0.1945
Epoch 3 [94/172] - loss: 0.1690
Epoch 3 [95/172] - loss: 0.1378
Epoch 3 [96/172] - loss: 0.1962
Epoch 3 [97/172] - loss: 0.2215
Epoch 3 [98/172] - loss: 0.1346
Epoch 3 [99/172] - loss: 0.1366
Epoch 3 [100/172] - loss: 0.1743, acc: 0.9375
Epoch 3 [101/172] - loss: 0.2187
Epoch 3 [102/172] - loss: 0.1444
Epoch 3 [103/172] - loss: 0.2032
Epoch 3 [104/172] - loss: 0.1610
Epoch 3 [105/172] - loss: 0.1923
Epoch 3 [106/172] - loss: 0.1435
Epoch 3 [107/172] - loss: 0.1170
Epoch 3 [108/172] - loss: 0.1612
Epoch 3 [109/172] - loss: 0.1327
Epoch 3 [110/172] - loss: 0.1832, acc: 0.9375
Epoch 3 [111/172] - loss: 0.1855
Epoch 3 [112/172] - loss: 0.1440
Epoch 3 [113/172] - loss: 0.1500
Epoch 3 [114/172] - loss: 0.1430
Epoch 3 [115/172] - loss: 0.1429
Epoch 3 [116/172] - loss: 0.1499
Epoch 3 [117/172] - loss: 0.1967
Epoch 3 [118/172] - loss: 0.1859
Epoch 3 [119/172] - loss: 0.1380
Epoch 3 [120/172] - loss: 0.2574, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1474
Epoch 3 [122/172] - loss: 0.1269
Epoch 3 [123/172] - loss: 0.1545
Epoch 3 [124/172] - loss: 0.1561
Epoch 3 [125/172] - loss: 0.1893
Epoch 3 [126/172] - loss: 0.2915
Epoch 3 [127/172] - loss: 0.1819
Epoch 3 [128/172] - loss: 0.1250
Epoch 3 [129/172] - loss: 0.1291
Epoch 3 [130/172] - loss: 0.1381, acc: 1.0000
Epoch 3 [131/172] - loss: 0.1690
Epoch 3 [132/172] - loss: 0.1435
Epoch 3 [133/172] - loss: 0.1296
Epoch 3 [134/172] - loss: 0.1165
Epoch 3 [135/172] - loss: 0.1621
Epoch 3 [136/172] - loss: 0.1394
Epoch 3 [137/172] - loss: 0.1372
Epoch 3 [138/172] - loss: 0.1237
Epoch 3 [139/172] - loss: 0.1357
Epoch 3 [140/172] - loss: 0.1368, acc: 1.0000
Epoch 3 [141/172] - loss: 0.1458
Epoch 3 [142/172] - loss: 0.1553
Epoch 3 [143/172] - loss: 0.1348
Epoch 3 [144/172] - loss: 0.2235
Epoch 3 [145/172] - loss: 0.1335
Epoch 3 [146/172] - loss: 0.1222
Epoch 3 [147/172] - loss: 0.1669
Epoch 3 [148/172] - loss: 0.1624
Epoch 3 [149/172] - loss: 0.1416
Epoch 3 [150/172] - loss: 0.1384, acc: 1.0000
Epoch 3 [151/172] - loss: 0.1600
Epoch 3 [152/172] - loss: 0.3156
Epoch 3 [153/172] - loss: 0.1909
Epoch 3 [154/172] - loss: 0.1968
Epoch 3 [155/172] - loss: 0.1186
Epoch 3 [156/172] - loss: 0.1416

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2986, log_difficulty=0.2613, weight=2.3066
neutral: count=4903.0, difficulty=0.2334, log_difficulty=0.2098, weight=2.0490
negative: count=5500.0, difficulty=0.2999, log_difficulty=0.2623, weight=2.3113

当前batch的pt分布：
positive: min=0.6607, max=0.9991, mean=0.9340
neutral: min=0.8154, max=0.9955, mean=0.9496
negative: min=0.2543, max=0.9971, mean=0.9033

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.0938
焦点损失: 0.0233
边界损失: 0.1649
总损失: 0.1371
Epoch 3 [157/172] - loss: 0.1371
Epoch 3 [158/172] - loss: 0.1674
Epoch 3 [159/172] - loss: 0.1484
Epoch 3 [160/172] - loss: 0.1704, acc: 0.9375
Epoch 3 [161/172] - loss: 0.2109
Epoch 3 [162/172] - loss: 0.1532
Epoch 3 [163/172] - loss: 0.1707
Epoch 3 [164/172] - loss: 0.1259
Epoch 3 [165/172] - loss: 0.2142
Epoch 3 [166/172] - loss: 0.1400
Epoch 3 [167/172] - loss: 0.1449
Epoch 3 [168/172] - loss: 0.1272
Epoch 3 [169/172] - loss: 0.1148
Epoch 3 [170/172] - loss: 0.1610, acc: 0.9688
Epoch 3 [171/172] - loss: 0.1311
Epoch 3 [172/172] - loss: 0.1149

类别准确率:
positive: 0.8373 (391/467)
neutral: 0.3133 (26/83)
negative: 0.6560 (164/250)

Epoch 3/10
Train Loss: 0.1520, Train Acc: 0.9576
Val Loss: 0.8158, Val Acc: 0.7262
Epoch 4 [1/172] - loss: 0.1161, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1219
Epoch 4 [3/172] - loss: 0.1405
Epoch 4 [4/172] - loss: 0.1435
Epoch 4 [5/172] - loss: 0.1541
Epoch 4 [6/172] - loss: 0.1098
Epoch 4 [7/172] - loss: 0.1250
Epoch 4 [8/172] - loss: 0.1143
Epoch 4 [9/172] - loss: 0.1595
Epoch 4 [10/172] - loss: 0.1564, acc: 0.9688
Epoch 4 [11/172] - loss: 0.1141
Epoch 4 [12/172] - loss: 0.1173
Epoch 4 [13/172] - loss: 0.1491
Epoch 4 [14/172] - loss: 0.1233
Epoch 4 [15/172] - loss: 0.1160
Epoch 4 [16/172] - loss: 0.1144
Epoch 4 [17/172] - loss: 0.1250
Epoch 4 [18/172] - loss: 0.1292
Epoch 4 [19/172] - loss: 0.1247
Epoch 4 [20/172] - loss: 0.1366, acc: 0.9688
Epoch 4 [21/172] - loss: 0.2340
Epoch 4 [22/172] - loss: 0.1099
Epoch 4 [23/172] - loss: 0.1556
Epoch 4 [24/172] - loss: 0.1120
Epoch 4 [25/172] - loss: 0.1166
Epoch 4 [26/172] - loss: 0.2458
Epoch 4 [27/172] - loss: 0.1097
Epoch 4 [28/172] - loss: 0.1372
Epoch 4 [29/172] - loss: 0.1101
Epoch 4 [30/172] - loss: 0.1632, acc: 0.9375
Epoch 4 [31/172] - loss: 0.1689
Epoch 4 [32/172] - loss: 0.1290
Epoch 4 [33/172] - loss: 0.1399
Epoch 4 [34/172] - loss: 0.1186
Epoch 4 [35/172] - loss: 0.1882
Epoch 4 [36/172] - loss: 0.1217
Epoch 4 [37/172] - loss: 0.1153
Epoch 4 [38/172] - loss: 0.1168
Epoch 4 [39/172] - loss: 0.1303
Epoch 4 [40/172] - loss: 0.2094, acc: 0.8750
Epoch 4 [41/172] - loss: 0.1322
Epoch 4 [42/172] - loss: 0.1703
Epoch 4 [43/172] - loss: 0.1349
Epoch 4 [44/172] - loss: 0.1251
Epoch 4 [45/172] - loss: 0.1181
Epoch 4 [46/172] - loss: 0.1211
Epoch 4 [47/172] - loss: 0.1188
Epoch 4 [48/172] - loss: 0.1148
Epoch 4 [49/172] - loss: 0.1165
Epoch 4 [50/172] - loss: 0.1241, acc: 0.9688
Epoch 4 [51/172] - loss: 0.1125
Epoch 4 [52/172] - loss: 0.1996
Epoch 4 [53/172] - loss: 0.1206
Epoch 4 [54/172] - loss: 0.1583
Epoch 4 [55/172] - loss: 0.1855
Epoch 4 [56/172] - loss: 0.1168
Epoch 4 [57/172] - loss: 0.1155
Epoch 4 [58/172] - loss: 0.1101
Epoch 4 [59/172] - loss: 0.1118
Epoch 4 [60/172] - loss: 0.1169, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1632
Epoch 4 [62/172] - loss: 0.1395
Epoch 4 [63/172] - loss: 0.1279
Epoch 4 [64/172] - loss: 0.1145
Epoch 4 [65/172] - loss: 0.1299
Epoch 4 [66/172] - loss: 0.1110
Epoch 4 [67/172] - loss: 0.1251
Epoch 4 [68/172] - loss: 0.1129
Epoch 4 [69/172] - loss: 0.1162
Epoch 4 [70/172] - loss: 0.1157, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1123
Epoch 4 [72/172] - loss: 0.1171
Epoch 4 [73/172] - loss: 0.1117
Epoch 4 [74/172] - loss: 0.1946
Epoch 4 [75/172] - loss: 0.1252
Epoch 4 [76/172] - loss: 0.1086
Epoch 4 [77/172] - loss: 0.1556
Epoch 4 [78/172] - loss: 0.1193
Epoch 4 [79/172] - loss: 0.1211
Epoch 4 [80/172] - loss: 0.1139, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1566
Epoch 4 [82/172] - loss: 0.1133
Epoch 4 [83/172] - loss: 0.1126
Epoch 4 [84/172] - loss: 0.1105

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2606, log_difficulty=0.2316, weight=2.1581
neutral: count=5865.0, difficulty=0.2026, log_difficulty=0.1845, weight=1.9225
negative: count=6629.0, difficulty=0.2600, log_difficulty=0.2311, weight=2.1556

当前batch的pt分布：
positive: min=0.5179, max=0.9981, mean=0.8959
neutral: min=0.9823, max=0.9991, mean=0.9931
negative: min=0.9443, max=0.9990, mean=0.9861

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0665
焦点损失: 0.0052
边界损失: 0.1646
总损失: 0.1262
Epoch 4 [85/172] - loss: 0.1262
Epoch 4 [86/172] - loss: 0.1504
Epoch 4 [87/172] - loss: 0.1202
Epoch 4 [88/172] - loss: 0.1128
Epoch 4 [89/172] - loss: 0.1135
Epoch 4 [90/172] - loss: 0.1096, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1594
Epoch 4 [92/172] - loss: 0.2530
Epoch 4 [93/172] - loss: 0.1117
Epoch 4 [94/172] - loss: 0.1100
Epoch 4 [95/172] - loss: 0.1875
Epoch 4 [96/172] - loss: 0.1364
Epoch 4 [97/172] - loss: 0.1244
Epoch 4 [98/172] - loss: 0.1242
Epoch 4 [99/172] - loss: 0.1236
Epoch 4 [100/172] - loss: 0.1595, acc: 0.9375
Epoch 4 [101/172] - loss: 0.1329
Epoch 4 [102/172] - loss: 0.1284
Epoch 4 [103/172] - loss: 0.1246
Epoch 4 [104/172] - loss: 0.1137
Epoch 4 [105/172] - loss: 0.1286
Epoch 4 [106/172] - loss: 0.1117
Epoch 4 [107/172] - loss: 0.1426
Epoch 4 [108/172] - loss: 0.1533
Epoch 4 [109/172] - loss: 0.1494
Epoch 4 [110/172] - loss: 0.2403, acc: 0.9062
Epoch 4 [111/172] - loss: 0.1102
Epoch 4 [112/172] - loss: 0.1172
Epoch 4 [113/172] - loss: 0.1234
Epoch 4 [114/172] - loss: 0.1364
Epoch 4 [115/172] - loss: 0.1152
Epoch 4 [116/172] - loss: 0.1213
Epoch 4 [117/172] - loss: 0.1173
Epoch 4 [118/172] - loss: 0.1174
Epoch 4 [119/172] - loss: 0.1109
Epoch 4 [120/172] - loss: 0.1322, acc: 0.9688
Epoch 4 [121/172] - loss: 0.1439
Epoch 4 [122/172] - loss: 0.1539
Epoch 4 [123/172] - loss: 0.1210
Epoch 4 [124/172] - loss: 0.1129
Epoch 4 [125/172] - loss: 0.1423
Epoch 4 [126/172] - loss: 0.2139
Epoch 4 [127/172] - loss: 0.2213
Epoch 4 [128/172] - loss: 0.1119
Epoch 4 [129/172] - loss: 0.1131
Epoch 4 [130/172] - loss: 0.1137, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1132
Epoch 4 [132/172] - loss: 0.1138
Epoch 4 [133/172] - loss: 0.1137
Epoch 4 [134/172] - loss: 0.1100
Epoch 4 [135/172] - loss: 0.1185
Epoch 4 [136/172] - loss: 0.1455
Epoch 4 [137/172] - loss: 0.1390
Epoch 4 [138/172] - loss: 0.1168
Epoch 4 [139/172] - loss: 0.1096
Epoch 4 [140/172] - loss: 0.1175, acc: 1.0000
Epoch 4 [141/172] - loss: 0.1346
Epoch 4 [142/172] - loss: 0.1208
Epoch 4 [143/172] - loss: 0.1153
Epoch 4 [144/172] - loss: 0.1129
Epoch 4 [145/172] - loss: 0.2170
Epoch 4 [146/172] - loss: 0.1130
Epoch 4 [147/172] - loss: 0.1235
Epoch 4 [148/172] - loss: 0.1117
Epoch 4 [149/172] - loss: 0.1446
Epoch 4 [150/172] - loss: 0.1265, acc: 1.0000
Epoch 4 [151/172] - loss: 0.2075
Epoch 4 [152/172] - loss: 0.1099
Epoch 4 [153/172] - loss: 0.1112
Epoch 4 [154/172] - loss: 0.1937
Epoch 4 [155/172] - loss: 0.1109
Epoch 4 [156/172] - loss: 0.1297
Epoch 4 [157/172] - loss: 0.1564
Epoch 4 [158/172] - loss: 0.1096
Epoch 4 [159/172] - loss: 0.1254
Epoch 4 [160/172] - loss: 0.1297, acc: 0.9688
Epoch 4 [161/172] - loss: 0.1445
Epoch 4 [162/172] - loss: 0.1141
Epoch 4 [163/172] - loss: 0.1319
Epoch 4 [164/172] - loss: 0.1258
Epoch 4 [165/172] - loss: 0.1350
Epoch 4 [166/172] - loss: 0.1223
Epoch 4 [167/172] - loss: 0.1647
Epoch 4 [168/172] - loss: 0.1106
Epoch 4 [169/172] - loss: 0.1795
Epoch 4 [170/172] - loss: 0.1883, acc: 0.9375
Epoch 4 [171/172] - loss: 0.1299
Epoch 4 [172/172] - loss: 0.2376

类别准确率:
positive: 0.8544 (399/467)
neutral: 0.2048 (17/83)
negative: 0.6840 (171/250)

Epoch 4/10
Train Loss: 0.1441, Train Acc: 0.9717
Val Loss: 0.8854, Val Acc: 0.7338
Epoch 5 [1/172] - loss: 0.1129, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1226
Epoch 5 [3/172] - loss: 0.1121
Epoch 5 [4/172] - loss: 0.1146
Epoch 5 [5/172] - loss: 0.1104
Epoch 5 [6/172] - loss: 0.1313
Epoch 5 [7/172] - loss: 0.1427
Epoch 5 [8/172] - loss: 0.1347
Epoch 5 [9/172] - loss: 0.1548
Epoch 5 [10/172] - loss: 0.1255, acc: 0.9688
Epoch 5 [11/172] - loss: 0.1117
Epoch 5 [12/172] - loss: 0.1188

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2322, log_difficulty=0.2088, weight=2.0440
neutral: count=6845.0, difficulty=0.1795, log_difficulty=0.1651, weight=1.8254
negative: count=7694.0, difficulty=0.2320, log_difficulty=0.2087, weight=2.0433

当前batch的pt分布：
positive: min=0.1114, max=0.9948, mean=0.9018
neutral: min=0.1481, max=0.9997, mean=0.8769
negative: min=0.9131, max=0.9993, mean=0.9729

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9286
neutral 准确率: 0.8571
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1541
焦点损失: 0.0969
边界损失: 0.1598
总损失: 0.1670
Epoch 5 [13/172] - loss: 0.1670
Epoch 5 [14/172] - loss: 0.1539
Epoch 5 [15/172] - loss: 0.1111
Epoch 5 [16/172] - loss: 0.1077
Epoch 5 [17/172] - loss: 0.1388
Epoch 5 [18/172] - loss: 0.1123
Epoch 5 [19/172] - loss: 0.1398
Epoch 5 [20/172] - loss: 0.1984, acc: 0.9375
Epoch 5 [21/172] - loss: 0.1923
Epoch 5 [22/172] - loss: 0.2283
Epoch 5 [23/172] - loss: 0.1116
Epoch 5 [24/172] - loss: 0.1356
Epoch 5 [25/172] - loss: 0.1099
Epoch 5 [26/172] - loss: 0.1520
Epoch 5 [27/172] - loss: 0.1137
Epoch 5 [28/172] - loss: 0.1190
Epoch 5 [29/172] - loss: 0.1134
Epoch 5 [30/172] - loss: 0.1191, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1156
Epoch 5 [32/172] - loss: 0.1079
Epoch 5 [33/172] - loss: 0.1233
Epoch 5 [34/172] - loss: 0.1104
Epoch 5 [35/172] - loss: 0.1093
Epoch 5 [36/172] - loss: 0.1319
Epoch 5 [37/172] - loss: 0.1093
Epoch 5 [38/172] - loss: 0.1412
Epoch 5 [39/172] - loss: 0.1752
Epoch 5 [40/172] - loss: 0.1279, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1144
Epoch 5 [42/172] - loss: 0.1277
Epoch 5 [43/172] - loss: 0.1683
Epoch 5 [44/172] - loss: 0.1322
Epoch 5 [45/172] - loss: 0.1065
Epoch 5 [46/172] - loss: 0.1287
Epoch 5 [47/172] - loss: 0.1139
Epoch 5 [48/172] - loss: 0.1196
Epoch 5 [49/172] - loss: 0.1108
Epoch 5 [50/172] - loss: 0.1183, acc: 1.0000
Epoch 5 [51/172] - loss: 0.1215
Epoch 5 [52/172] - loss: 0.1103
Epoch 5 [53/172] - loss: 0.1425
Epoch 5 [54/172] - loss: 0.1165
Epoch 5 [55/172] - loss: 0.1474
Epoch 5 [56/172] - loss: 0.1125
Epoch 5 [57/172] - loss: 0.1229
Epoch 5 [58/172] - loss: 0.1088
Epoch 5 [59/172] - loss: 0.1342
Epoch 5 [60/172] - loss: 0.1096, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1204
Epoch 5 [62/172] - loss: 0.1108
Epoch 5 [63/172] - loss: 0.1513
Epoch 5 [64/172] - loss: 0.1173
Epoch 5 [65/172] - loss: 0.1172
Epoch 5 [66/172] - loss: 0.1073
Epoch 5 [67/172] - loss: 0.1065
Epoch 5 [68/172] - loss: 0.1238
Epoch 5 [69/172] - loss: 0.1226
Epoch 5 [70/172] - loss: 0.1077, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1130
Epoch 5 [72/172] - loss: 0.1804
Epoch 5 [73/172] - loss: 0.1142
Epoch 5 [74/172] - loss: 0.2474
Epoch 5 [75/172] - loss: 0.1110
Epoch 5 [76/172] - loss: 0.1148
Epoch 5 [77/172] - loss: 0.1520
Epoch 5 [78/172] - loss: 0.1179
Epoch 5 [79/172] - loss: 0.1080
Epoch 5 [80/172] - loss: 0.1141, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1670
Epoch 5 [82/172] - loss: 0.1301
Epoch 5 [83/172] - loss: 0.1199
Epoch 5 [84/172] - loss: 0.1134
Epoch 5 [85/172] - loss: 0.1719
Epoch 5 [86/172] - loss: 0.1119
Epoch 5 [87/172] - loss: 0.1275
Epoch 5 [88/172] - loss: 0.1333
Epoch 5 [89/172] - loss: 0.1198
Epoch 5 [90/172] - loss: 0.2023, acc: 0.9375
Epoch 5 [91/172] - loss: 0.1166
Epoch 5 [92/172] - loss: 0.1109
Epoch 5 [93/172] - loss: 0.1099
Epoch 5 [94/172] - loss: 0.1115
Epoch 5 [95/172] - loss: 0.1135
Epoch 5 [96/172] - loss: 0.1125
Epoch 5 [97/172] - loss: 0.1483
Epoch 5 [98/172] - loss: 0.1192
Epoch 5 [99/172] - loss: 0.1436
Epoch 5 [100/172] - loss: 0.1707, acc: 0.9375
Epoch 5 [101/172] - loss: 0.1132
Epoch 5 [102/172] - loss: 0.1328
Epoch 5 [103/172] - loss: 0.1140
Epoch 5 [104/172] - loss: 0.1604
Epoch 5 [105/172] - loss: 0.2088
Epoch 5 [106/172] - loss: 0.1100
Epoch 5 [107/172] - loss: 0.1119
Epoch 5 [108/172] - loss: 0.1374
Epoch 5 [109/172] - loss: 0.1079
Epoch 5 [110/172] - loss: 0.1091, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1250
Epoch 5 [112/172] - loss: 0.1065

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2087, log_difficulty=0.1895, weight=1.9477
neutral: count=7825.0, difficulty=0.1618, log_difficulty=0.1500, weight=1.7498
negative: count=8780.0, difficulty=0.2097, log_difficulty=0.1904, weight=1.9519

当前batch的pt分布：
positive: min=0.3878, max=0.9948, mean=0.8879
neutral: min=0.8450, max=0.9976, mean=0.9736
negative: min=0.9965, max=0.9995, mean=0.9987

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.8750
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0870
焦点损失: 0.0207
边界损失: 0.1653
总损失: 0.1340
Epoch 5 [113/172] - loss: 0.1340
Epoch 5 [114/172] - loss: 0.1491
Epoch 5 [115/172] - loss: 0.1344
Epoch 5 [116/172] - loss: 0.1082
Epoch 5 [117/172] - loss: 0.1113
Epoch 5 [118/172] - loss: 0.1085
Epoch 5 [119/172] - loss: 0.1104
Epoch 5 [120/172] - loss: 0.1146, acc: 1.0000
Epoch 5 [121/172] - loss: 0.1140
Epoch 5 [122/172] - loss: 0.1110
Epoch 5 [123/172] - loss: 0.1139
Epoch 5 [124/172] - loss: 0.1107
Epoch 5 [125/172] - loss: 0.1101
Epoch 5 [126/172] - loss: 0.1237
Epoch 5 [127/172] - loss: 0.1318
Epoch 5 [128/172] - loss: 0.1109
Epoch 5 [129/172] - loss: 0.1983
Epoch 5 [130/172] - loss: 0.1066, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1243
Epoch 5 [132/172] - loss: 0.1441
Epoch 5 [133/172] - loss: 0.1740
Epoch 5 [134/172] - loss: 0.1247
Epoch 5 [135/172] - loss: 0.1129
Epoch 5 [136/172] - loss: 0.1102
Epoch 5 [137/172] - loss: 0.1179
Epoch 5 [138/172] - loss: 0.1766
Epoch 5 [139/172] - loss: 0.1557
Epoch 5 [140/172] - loss: 0.1533, acc: 0.9688
Epoch 5 [141/172] - loss: 0.1186
Epoch 5 [142/172] - loss: 0.1191
Epoch 5 [143/172] - loss: 0.1070
Epoch 5 [144/172] - loss: 0.1065
Epoch 5 [145/172] - loss: 0.1200
Epoch 5 [146/172] - loss: 0.1086
Epoch 5 [147/172] - loss: 0.1148
Epoch 5 [148/172] - loss: 0.1068
Epoch 5 [149/172] - loss: 0.1068
Epoch 5 [150/172] - loss: 0.1512, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1075
Epoch 5 [152/172] - loss: 0.1083
Epoch 5 [153/172] - loss: 0.1068
Epoch 5 [154/172] - loss: 0.1146
Epoch 5 [155/172] - loss: 0.1121
Epoch 5 [156/172] - loss: 0.1238
Epoch 5 [157/172] - loss: 0.1166
Epoch 5 [158/172] - loss: 0.1121
Epoch 5 [159/172] - loss: 0.1106
Epoch 5 [160/172] - loss: 0.1206, acc: 1.0000
Epoch 5 [161/172] - loss: 0.1146
Epoch 5 [162/172] - loss: 0.1155
Epoch 5 [163/172] - loss: 0.1576
Epoch 5 [164/172] - loss: 0.1069
Epoch 5 [165/172] - loss: 0.1490
Epoch 5 [166/172] - loss: 0.1287
Epoch 5 [167/172] - loss: 0.1390
Epoch 5 [168/172] - loss: 0.1087
Epoch 5 [169/172] - loss: 0.1107
Epoch 5 [170/172] - loss: 0.1106, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1182
Epoch 5 [172/172] - loss: 0.1168

类别准确率:
positive: 0.8822 (412/467)
neutral: 0.3494 (29/83)
negative: 0.4560 (114/250)

Epoch 5/10
Train Loss: 0.1210, Train Acc: 0.9919
Val Loss: 0.9807, Val Acc: 0.6937
Epoch 6 [1/172] - loss: 0.1613, acc: 0.9688
Epoch 6 [2/172] - loss: 0.1177
Epoch 6 [3/172] - loss: 0.1089
Epoch 6 [4/172] - loss: 0.1108
Epoch 6 [5/172] - loss: 0.1221
Epoch 6 [6/172] - loss: 0.1084
Epoch 6 [7/172] - loss: 0.1409
Epoch 6 [8/172] - loss: 0.1149
Epoch 6 [9/172] - loss: 0.1130
Epoch 6 [10/172] - loss: 0.1088, acc: 1.0000
Epoch 6 [11/172] - loss: 0.1085
Epoch 6 [12/172] - loss: 0.1079
Epoch 6 [13/172] - loss: 0.1118
Epoch 6 [14/172] - loss: 0.1069
Epoch 6 [15/172] - loss: 0.1075
Epoch 6 [16/172] - loss: 0.1498
Epoch 6 [17/172] - loss: 0.1126
Epoch 6 [18/172] - loss: 0.1098
Epoch 6 [19/172] - loss: 0.1099
Epoch 6 [20/172] - loss: 0.1089, acc: 1.0000
Epoch 6 [21/172] - loss: 0.1230
Epoch 6 [22/172] - loss: 0.1329
Epoch 6 [23/172] - loss: 0.1100
Epoch 6 [24/172] - loss: 0.1079
Epoch 6 [25/172] - loss: 0.1178
Epoch 6 [26/172] - loss: 0.1139
Epoch 6 [27/172] - loss: 0.1390
Epoch 6 [28/172] - loss: 0.1131
Epoch 6 [29/172] - loss: 0.1106
Epoch 6 [30/172] - loss: 0.1118, acc: 1.0000
Epoch 6 [31/172] - loss: 0.1086
Epoch 6 [32/172] - loss: 0.1071
Epoch 6 [33/172] - loss: 0.1118
Epoch 6 [34/172] - loss: 0.1125
Epoch 6 [35/172] - loss: 0.1103
Epoch 6 [36/172] - loss: 0.1116
Epoch 6 [37/172] - loss: 0.1106
Epoch 6 [38/172] - loss: 0.1104
Epoch 6 [39/172] - loss: 0.1085
Epoch 6 [40/172] - loss: 0.1114, acc: 1.0000

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1897, log_difficulty=0.1737, weight=1.8687
neutral: count=8815.0, difficulty=0.1468, log_difficulty=0.1370, weight=1.6849
negative: count=9870.0, difficulty=0.1905, log_difficulty=0.1744, weight=1.8720

当前batch的pt分布：
positive: min=0.2680, max=0.9990, mean=0.9260
neutral: min=0.9539, max=0.9996, mean=0.9897
negative: min=0.9473, max=0.9986, mean=0.9832

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0529
焦点损失: 0.0219
边界损失: 0.1457
总损失: 0.1195
Epoch 6 [41/172] - loss: 0.1195
Epoch 6 [42/172] - loss: 0.1118
Epoch 6 [43/172] - loss: 0.1404
Epoch 6 [44/172] - loss: 0.1063
Epoch 6 [45/172] - loss: 0.1154
Epoch 6 [46/172] - loss: 0.1226
Epoch 6 [47/172] - loss: 0.1069
Epoch 6 [48/172] - loss: 0.1065
Epoch 6 [49/172] - loss: 0.1282
Epoch 6 [50/172] - loss: 0.1504, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1238
Epoch 6 [52/172] - loss: 0.1160
Epoch 6 [53/172] - loss: 0.1069
Epoch 6 [54/172] - loss: 0.1750
Epoch 6 [55/172] - loss: 0.1087
Epoch 6 [56/172] - loss: 0.1092
Epoch 6 [57/172] - loss: 0.1099
Epoch 6 [58/172] - loss: 0.1149
Epoch 6 [59/172] - loss: 0.1285
Epoch 6 [60/172] - loss: 0.1312, acc: 0.9688
Epoch 6 [61/172] - loss: 0.1116
Epoch 6 [62/172] - loss: 0.1140
Epoch 6 [63/172] - loss: 0.1091
Epoch 6 [64/172] - loss: 0.1716
Epoch 6 [65/172] - loss: 0.1190
Epoch 6 [66/172] - loss: 0.1102
Epoch 6 [67/172] - loss: 0.1289
Epoch 6 [68/172] - loss: 0.1520
Epoch 6 [69/172] - loss: 0.1192
Epoch 6 [70/172] - loss: 0.1095, acc: 1.0000
Epoch 6 [71/172] - loss: 0.1117
Epoch 6 [72/172] - loss: 0.1193
Epoch 6 [73/172] - loss: 0.1496
Epoch 6 [74/172] - loss: 0.1092
Epoch 6 [75/172] - loss: 0.1114
Epoch 6 [76/172] - loss: 0.1081
Epoch 6 [77/172] - loss: 0.1591
Epoch 6 [78/172] - loss: 0.1491
Epoch 6 [79/172] - loss: 0.1082
Epoch 6 [80/172] - loss: 0.1236, acc: 0.9688
Epoch 6 [81/172] - loss: 0.1185
Epoch 6 [82/172] - loss: 0.1174
Epoch 6 [83/172] - loss: 0.1057
Epoch 6 [84/172] - loss: 0.1081
Epoch 6 [85/172] - loss: 0.1317
Epoch 6 [86/172] - loss: 0.1188
Epoch 6 [87/172] - loss: 0.1127
Epoch 6 [88/172] - loss: 0.1342
Epoch 6 [89/172] - loss: 0.1222
Epoch 6 [90/172] - loss: 0.1058, acc: 1.0000
Epoch 6 [91/172] - loss: 0.1085
Epoch 6 [92/172] - loss: 0.1118
Epoch 6 [93/172] - loss: 0.1061
Epoch 6 [94/172] - loss: 0.1249
Epoch 6 [95/172] - loss: 0.1136
Epoch 6 [96/172] - loss: 0.1081
Epoch 6 [97/172] - loss: 0.1075
Epoch 6 [98/172] - loss: 0.1074
Epoch 6 [99/172] - loss: 0.1094
Epoch 6 [100/172] - loss: 0.1070, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1211
Epoch 6 [102/172] - loss: 0.1063
Epoch 6 [103/172] - loss: 0.1122
Epoch 6 [104/172] - loss: 0.1347
Epoch 6 [105/172] - loss: 0.1127
Epoch 6 [106/172] - loss: 0.1285
Epoch 6 [107/172] - loss: 0.1058
Epoch 6 [108/172] - loss: 0.1061
Epoch 6 [109/172] - loss: 0.1853
Epoch 6 [110/172] - loss: 0.1062, acc: 1.0000
Epoch 6 [111/172] - loss: 0.1092
Epoch 6 [112/172] - loss: 0.1100
Epoch 6 [113/172] - loss: 0.1488
Epoch 6 [114/172] - loss: 0.1053
Epoch 6 [115/172] - loss: 0.1154
Epoch 6 [116/172] - loss: 0.1643
Epoch 6 [117/172] - loss: 0.1078
Epoch 6 [118/172] - loss: 0.1094
Epoch 6 [119/172] - loss: 0.2304
Epoch 6 [120/172] - loss: 0.1121, acc: 1.0000
Epoch 6 [121/172] - loss: 0.1094
Epoch 6 [122/172] - loss: 0.1181
Epoch 6 [123/172] - loss: 0.1079
Epoch 6 [124/172] - loss: 0.1116
Epoch 6 [125/172] - loss: 0.1147
Epoch 6 [126/172] - loss: 0.1696
Epoch 6 [127/172] - loss: 0.1524
Epoch 6 [128/172] - loss: 0.1180
Epoch 6 [129/172] - loss: 0.1161
Epoch 6 [130/172] - loss: 0.1344, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1136
Epoch 6 [132/172] - loss: 0.1327
Epoch 6 [133/172] - loss: 0.1071
Epoch 6 [134/172] - loss: 0.1065
Epoch 6 [135/172] - loss: 0.1080
Epoch 6 [136/172] - loss: 0.1055
Epoch 6 [137/172] - loss: 0.1149
Epoch 6 [138/172] - loss: 0.1153
Epoch 6 [139/172] - loss: 0.1078
Epoch 6 [140/172] - loss: 0.1203, acc: 0.9688

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1740, log_difficulty=0.1604, weight=1.8022
neutral: count=9796.0, difficulty=0.1349, log_difficulty=0.1265, weight=1.6326
negative: count=10972.0, difficulty=0.1756, log_difficulty=0.1618, weight=1.8088

当前batch的pt分布：
positive: min=0.9863, max=0.9999, mean=0.9944
neutral: min=0.9881, max=0.9990, mean=0.9936
negative: min=0.9318, max=0.9976, mean=0.9756

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0137
焦点损失: 0.0000
边界损失: 0.1417
总损失: 0.1063
Epoch 6 [141/172] - loss: 0.1063
Epoch 6 [142/172] - loss: 0.1089
Epoch 6 [143/172] - loss: 0.1103
Epoch 6 [144/172] - loss: 0.1095
Epoch 6 [145/172] - loss: 0.1078
Epoch 6 [146/172] - loss: 0.1048
Epoch 6 [147/172] - loss: 0.1112
Epoch 6 [148/172] - loss: 0.1111
Epoch 6 [149/172] - loss: 0.1068
Epoch 6 [150/172] - loss: 0.1047, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1114
Epoch 6 [152/172] - loss: 0.1224
Epoch 6 [153/172] - loss: 0.1041
Epoch 6 [154/172] - loss: 0.1051
Epoch 6 [155/172] - loss: 0.1281
Epoch 6 [156/172] - loss: 0.1322
Epoch 6 [157/172] - loss: 0.1073
Epoch 6 [158/172] - loss: 0.1147
Epoch 6 [159/172] - loss: 0.1111
Epoch 6 [160/172] - loss: 0.1566, acc: 0.9688
Epoch 6 [161/172] - loss: 0.1141
Epoch 6 [162/172] - loss: 0.1285
Epoch 6 [163/172] - loss: 0.1490
Epoch 6 [164/172] - loss: 0.1303
Epoch 6 [165/172] - loss: 0.2384
Epoch 6 [166/172] - loss: 0.1137
Epoch 6 [167/172] - loss: 0.1073
Epoch 6 [168/172] - loss: 0.1058
Epoch 6 [169/172] - loss: 0.1197
Epoch 6 [170/172] - loss: 0.1074, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1534
Epoch 6 [172/172] - loss: 0.1124

类别准确率:
positive: 0.9015 (421/467)
neutral: 0.3253 (27/83)
negative: 0.3400 (85/250)

Epoch 6/10
Train Loss: 0.1294, Train Acc: 0.9798
Val Loss: 1.1699, Val Acc: 0.6663
Epoch 7 [1/172] - loss: 0.1167, acc: 1.0000
Epoch 7 [2/172] - loss: 0.1088
Epoch 7 [3/172] - loss: 0.1053
Epoch 7 [4/172] - loss: 0.1078
Epoch 7 [5/172] - loss: 0.1072
Epoch 7 [6/172] - loss: 0.1056
Epoch 7 [7/172] - loss: 0.1496
Epoch 7 [8/172] - loss: 0.1560
Epoch 7 [9/172] - loss: 0.1073
Epoch 7 [10/172] - loss: 0.1071, acc: 1.0000
Epoch 7 [11/172] - loss: 0.1092
Epoch 7 [12/172] - loss: 0.1311
Epoch 7 [13/172] - loss: 0.1156
Epoch 7 [14/172] - loss: 0.1181
Epoch 7 [15/172] - loss: 0.1502
Epoch 7 [16/172] - loss: 0.1220
Epoch 7 [17/172] - loss: 0.1402
Epoch 7 [18/172] - loss: 0.1078
Epoch 7 [19/172] - loss: 0.1077
Epoch 7 [20/172] - loss: 0.1065, acc: 1.0000
Epoch 7 [21/172] - loss: 0.1155
Epoch 7 [22/172] - loss: 0.1139
Epoch 7 [23/172] - loss: 0.1052
Epoch 7 [24/172] - loss: 0.1067
Epoch 7 [25/172] - loss: 0.1071
Epoch 7 [26/172] - loss: 0.1232
Epoch 7 [27/172] - loss: 0.1085
Epoch 7 [28/172] - loss: 0.1188
Epoch 7 [29/172] - loss: 0.1072
Epoch 7 [30/172] - loss: 0.1288, acc: 0.9688
Epoch 7 [31/172] - loss: 0.1100
Epoch 7 [32/172] - loss: 0.1048
Epoch 7 [33/172] - loss: 0.1085
Epoch 7 [34/172] - loss: 0.1075
Epoch 7 [35/172] - loss: 0.1070
Epoch 7 [36/172] - loss: 0.1533
Epoch 7 [37/172] - loss: 0.1065
Epoch 7 [38/172] - loss: 0.1057
Epoch 7 [39/172] - loss: 0.1107
Epoch 7 [40/172] - loss: 0.1055, acc: 1.0000
Epoch 7 [41/172] - loss: 0.1064
Epoch 7 [42/172] - loss: 0.1078
Epoch 7 [43/172] - loss: 0.1069
Epoch 7 [44/172] - loss: 0.1232
Epoch 7 [45/172] - loss: 0.1104
Epoch 7 [46/172] - loss: 0.1352
Epoch 7 [47/172] - loss: 0.1168
Epoch 7 [48/172] - loss: 0.1150
Epoch 7 [49/172] - loss: 0.1056
Epoch 7 [50/172] - loss: 0.1068, acc: 1.0000
Epoch 7 [51/172] - loss: 0.1426
Epoch 7 [52/172] - loss: 0.1062
Epoch 7 [53/172] - loss: 0.1054
Epoch 7 [54/172] - loss: 0.1106
Epoch 7 [55/172] - loss: 0.1068
Epoch 7 [56/172] - loss: 0.1074
Epoch 7 [57/172] - loss: 0.1112
Epoch 7 [58/172] - loss: 0.1134
Epoch 7 [59/172] - loss: 0.1071
Epoch 7 [60/172] - loss: 0.1106, acc: 1.0000
Epoch 7 [61/172] - loss: 0.1142
Epoch 7 [62/172] - loss: 0.1083
Epoch 7 [63/172] - loss: 0.1465
Epoch 7 [64/172] - loss: 0.1637
Epoch 7 [65/172] - loss: 0.1146
Epoch 7 [66/172] - loss: 0.1057
Epoch 7 [67/172] - loss: 0.1068
Epoch 7 [68/172] - loss: 0.1137

=== 第 1101 次迭代调试信息 ===
当前类别统计：
positive: count=12302.0, difficulty=0.1609, log_difficulty=0.1492, weight=1.7458
neutral: count=10756.0, difficulty=0.1247, log_difficulty=0.1175, weight=1.5875
negative: count=12072.0, difficulty=0.1631, log_difficulty=0.1511, weight=1.7553

当前batch的pt分布：
positive: min=0.9890, max=0.9993, mean=0.9958
neutral: min=0.9900, max=0.9995, mean=0.9968
negative: min=0.9303, max=0.9962, mean=0.9737

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0139
焦点损失: 0.0000
边界损失: 0.1416
总损失: 0.1062
Epoch 7 [69/172] - loss: 0.1062
Epoch 7 [70/172] - loss: 0.1072, acc: 1.0000
Epoch 7 [71/172] - loss: 0.1093
Epoch 7 [72/172] - loss: 0.1086
Epoch 7 [73/172] - loss: 0.1125
Epoch 7 [74/172] - loss: 0.1053
Epoch 7 [75/172] - loss: 0.1055
Epoch 7 [76/172] - loss: 0.1115
Epoch 7 [77/172] - loss: 0.1094
Epoch 7 [78/172] - loss: 0.1079
Epoch 7 [79/172] - loss: 0.1148
Epoch 7 [80/172] - loss: 0.1305, acc: 0.9688
Epoch 7 [81/172] - loss: 0.1062
Epoch 7 [82/172] - loss: 0.1078
Epoch 7 [83/172] - loss: 0.1251
Epoch 7 [84/172] - loss: 0.1082
Epoch 7 [85/172] - loss: 0.1128
Epoch 7 [86/172] - loss: 0.1071
Epoch 7 [87/172] - loss: 0.1089
Epoch 7 [88/172] - loss: 0.1063
Epoch 7 [89/172] - loss: 0.1051
Epoch 7 [90/172] - loss: 0.1073, acc: 1.0000
Epoch 7 [91/172] - loss: 0.1103
Epoch 7 [92/172] - loss: 0.1074
Epoch 7 [93/172] - loss: 0.1247
Epoch 7 [94/172] - loss: 0.1056
Epoch 7 [95/172] - loss: 0.1080
Epoch 7 [96/172] - loss: 0.1185
Epoch 7 [97/172] - loss: 0.1172
Epoch 7 [98/172] - loss: 0.1209
Epoch 7 [99/172] - loss: 0.1062
Epoch 7 [100/172] - loss: 0.1070, acc: 1.0000
Epoch 7 [101/172] - loss: 0.1056
Epoch 7 [102/172] - loss: 0.1061
Epoch 7 [103/172] - loss: 0.1056
Epoch 7 [104/172] - loss: 0.1362
Epoch 7 [105/172] - loss: 0.1127
Epoch 7 [106/172] - loss: 0.1227
Epoch 7 [107/172] - loss: 0.1063
Epoch 7 [108/172] - loss: 0.1047
Epoch 7 [109/172] - loss: 0.1166
Epoch 7 [110/172] - loss: 0.1149, acc: 1.0000
Epoch 7 [111/172] - loss: 0.1074
Epoch 7 [112/172] - loss: 0.1121
Epoch 7 [113/172] - loss: 0.1055
Epoch 7 [114/172] - loss: 0.1056
Epoch 7 [115/172] - loss: 0.1048
Epoch 7 [116/172] - loss: 0.1175
Epoch 7 [117/172] - loss: 0.1083
Epoch 7 [118/172] - loss: 0.1277
Epoch 7 [119/172] - loss: 0.1100
Epoch 7 [120/172] - loss: 0.1127, acc: 1.0000
Epoch 7 [121/172] - loss: 0.1096
Epoch 7 [122/172] - loss: 0.1080
Epoch 7 [123/172] - loss: 0.1049
Epoch 7 [124/172] - loss: 0.1152
Epoch 7 [125/172] - loss: 0.1075
Epoch 7 [126/172] - loss: 0.1050
Epoch 7 [127/172] - loss: 0.1103
Epoch 7 [128/172] - loss: 0.1066
Epoch 7 [129/172] - loss: 0.1067
Epoch 7 [130/172] - loss: 0.1090, acc: 1.0000
Epoch 7 [131/172] - loss: 0.1506
Epoch 7 [132/172] - loss: 0.1578
Epoch 7 [133/172] - loss: 0.1048
Epoch 7 [134/172] - loss: 0.1083
Epoch 7 [135/172] - loss: 0.1160
Epoch 7 [136/172] - loss: 0.1093
Epoch 7 [137/172] - loss: 0.1158
Epoch 7 [138/172] - loss: 0.1050
Epoch 7 [139/172] - loss: 0.1235
Epoch 7 [140/172] - loss: 0.1142, acc: 1.0000
Epoch 7 [141/172] - loss: 0.1536
Epoch 7 [142/172] - loss: 0.1119
Epoch 7 [143/172] - loss: 0.1174
Epoch 7 [144/172] - loss: 0.1076
Epoch 7 [145/172] - loss: 0.1112
Epoch 7 [146/172] - loss: 0.1309
Epoch 7 [147/172] - loss: 0.1123
Epoch 7 [148/172] - loss: 0.1183
Epoch 7 [149/172] - loss: 0.1063
Epoch 7 [150/172] - loss: 0.1113, acc: 1.0000
Epoch 7 [151/172] - loss: 0.1300
Epoch 7 [152/172] - loss: 0.1042
Epoch 7 [153/172] - loss: 0.1051
Epoch 7 [154/172] - loss: 0.1271
Epoch 7 [155/172] - loss: 0.1052
Epoch 7 [156/172] - loss: 0.1306
Epoch 7 [157/172] - loss: 0.1143
Epoch 7 [158/172] - loss: 0.1073
Epoch 7 [159/172] - loss: 0.1046
Epoch 7 [160/172] - loss: 0.1058, acc: 1.0000
Epoch 7 [161/172] - loss: 0.1053
Epoch 7 [162/172] - loss: 0.1207
Epoch 7 [163/172] - loss: 0.1093
Epoch 7 [164/172] - loss: 0.1379
Epoch 7 [165/172] - loss: 0.1236
Epoch 7 [166/172] - loss: 0.1063
Epoch 7 [167/172] - loss: 0.1156
Epoch 7 [168/172] - loss: 0.1057

=== 第 1201 次迭代调试信息 ===
当前类别统计：
positive: count=13426.0, difficulty=0.1494, log_difficulty=0.1393, weight=1.6963
neutral: count=11731.0, difficulty=0.1162, log_difficulty=0.1100, weight=1.5498
negative: count=13173.0, difficulty=0.1518, log_difficulty=0.1413, weight=1.7066

当前batch的pt分布：
positive: min=0.9628, max=0.9990, mean=0.9896
neutral: min=0.9897, max=0.9993, mean=0.9960
negative: min=0.3243, max=0.9994, mean=0.9163

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9167

损失分量：
基础交叉熵: 0.0510
焦点损失: 0.0168
边界损失: 0.1492
总损失: 0.1191
Epoch 7 [169/172] - loss: 0.1191
Epoch 7 [170/172] - loss: 0.1119, acc: 1.0000
Epoch 7 [171/172] - loss: 0.1074
Epoch 7 [172/172] - loss: 0.1037

类别准确率:
positive: 0.8137 (380/467)
neutral: 0.2651 (22/83)
negative: 0.6360 (159/250)

Epoch 7/10
Train Loss: 0.1124, Train Acc: 0.9919
Val Loss: 1.0261, Val Acc: 0.7013
Early stopping triggered!
Best validation accuracy: 0.7338

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_054445-lz46p0zf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.25_Multimodal_iterations_20250118_054444
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/lz46p0zf
wandb: uploading wandb-summary.json
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇████
wandb:  train_acc ▁▄▆▃▆▆▅▆▆▆▇████████████▇████████████████
wandb: train_loss █▇▆▄▇▄▆▄▅▃▂▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1202
wandb:  train_acc 1
wandb: train_loss 0.11189
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.25_Multimodal_iterations_20250118_054444 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/lz46p0zf
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_054445-lz46p0zf/logs
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_055516-c4cd563p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.25_Multimodal_epochs_20250118_055516
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/c4cd563p
wandb: uploading summary; uploading wandb-summary.json; uploading wandb-metadata.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▃▅▆▇█
wandb:  train_acc ▁▅▇▇███
wandb: train_loss █▄▂▂▁▁▁
wandb:    val_acc ▂▇▇█▄▁▅
wandb:   val_loss ▁▁▂▃▅█▆
wandb: 
wandb: Run summary:
wandb:      epoch 7
wandb:  train_acc 0.99192
wandb: train_loss 0.1124
wandb:    val_acc 0.70125
wandb:   val_loss 1.02608
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.25_Multimodal_epochs_20250118_055516 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/c4cd563p
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_055516-c4cd563p/logs

