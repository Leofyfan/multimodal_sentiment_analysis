=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 1.5 --dropout 0.15 --name loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.15 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.15
text_dim: 128
image_dim: 256
dropout: 0.15
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 1.5

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6902, log_difficulty=0.5249, weight=3.6243
neutral: count=7.0, difficulty=0.6763, log_difficulty=0.5166, weight=3.5828
negative: count=13.0, difficulty=0.6546, log_difficulty=0.5035, weight=3.5177

当前batch的pt分布：
positive: min=0.2019, max=0.4326, mean=0.3098
neutral: min=0.1940, max=0.4234, mean=0.3237
negative: min=0.1748, max=0.6354, mean=0.3454

当前batch准确率：
整体准确率: 0.3125
positive 准确率: 0.2500
neutral 准确率: 0.4286
negative 准确率: 0.3077

损失分量：
基础交叉熵: 1.1553
焦点损失: 0.3972
边界损失: 0.8107
总损失: 0.9629
Epoch 1 [1/172] - loss: 0.9629, acc: 0.3125
Epoch 1 [2/172] - loss: 0.9531
Epoch 1 [3/172] - loss: 0.9496
Epoch 1 [4/172] - loss: 0.9680
Epoch 1 [5/172] - loss: 0.8962
Epoch 1 [6/172] - loss: 0.9703
Epoch 1 [7/172] - loss: 0.9539
Epoch 1 [8/172] - loss: 0.8319
Epoch 1 [9/172] - loss: 0.7936
Epoch 1 [10/172] - loss: 0.8342, acc: 0.5625
Epoch 1 [11/172] - loss: 0.8275
Epoch 1 [12/172] - loss: 0.8149
Epoch 1 [13/172] - loss: 0.8053
Epoch 1 [14/172] - loss: 0.8215
Epoch 1 [15/172] - loss: 0.7207
Epoch 1 [16/172] - loss: 0.7203
Epoch 1 [17/172] - loss: 0.7043
Epoch 1 [18/172] - loss: 0.8494
Epoch 1 [19/172] - loss: 0.9110
Epoch 1 [20/172] - loss: 0.7815, acc: 0.4688
Epoch 1 [21/172] - loss: 0.7299
Epoch 1 [22/172] - loss: 0.6303
Epoch 1 [23/172] - loss: 0.7681
Epoch 1 [24/172] - loss: 0.7502
Epoch 1 [25/172] - loss: 0.9649
Epoch 1 [26/172] - loss: 0.7538
Epoch 1 [27/172] - loss: 0.8693
Epoch 1 [28/172] - loss: 0.6943
Epoch 1 [29/172] - loss: 0.7953
Epoch 1 [30/172] - loss: 0.5619, acc: 0.7188
Epoch 1 [31/172] - loss: 0.7620
Epoch 1 [32/172] - loss: 0.7600
Epoch 1 [33/172] - loss: 0.8300
Epoch 1 [34/172] - loss: 0.6820
Epoch 1 [35/172] - loss: 0.7891
Epoch 1 [36/172] - loss: 0.5859
Epoch 1 [37/172] - loss: 0.7099
Epoch 1 [38/172] - loss: 0.6912
Epoch 1 [39/172] - loss: 0.6137
Epoch 1 [40/172] - loss: 0.6915, acc: 0.5625
Epoch 1 [41/172] - loss: 0.6588
Epoch 1 [42/172] - loss: 0.5173
Epoch 1 [43/172] - loss: 0.5918
Epoch 1 [44/172] - loss: 0.8315
Epoch 1 [45/172] - loss: 0.9407
Epoch 1 [46/172] - loss: 0.5124
Epoch 1 [47/172] - loss: 0.5187
Epoch 1 [48/172] - loss: 0.5331
Epoch 1 [49/172] - loss: 0.5961
Epoch 1 [50/172] - loss: 0.5959, acc: 0.6875
Epoch 1 [51/172] - loss: 0.6110
Epoch 1 [52/172] - loss: 0.5892
Epoch 1 [53/172] - loss: 0.6810
Epoch 1 [54/172] - loss: 0.7683
Epoch 1 [55/172] - loss: 0.4106
Epoch 1 [56/172] - loss: 0.3864
Epoch 1 [57/172] - loss: 0.7246
Epoch 1 [58/172] - loss: 0.4200
Epoch 1 [59/172] - loss: 0.5136
Epoch 1 [60/172] - loss: 0.5184, acc: 0.8125
Epoch 1 [61/172] - loss: 0.6227
Epoch 1 [62/172] - loss: 0.5915
Epoch 1 [63/172] - loss: 0.4424
Epoch 1 [64/172] - loss: 0.4723
Epoch 1 [65/172] - loss: 0.6515
Epoch 1 [66/172] - loss: 0.6535
Epoch 1 [67/172] - loss: 0.6358
Epoch 1 [68/172] - loss: 0.6335
Epoch 1 [69/172] - loss: 0.6673
Epoch 1 [70/172] - loss: 0.5513, acc: 0.6875
Epoch 1 [71/172] - loss: 0.3511
Epoch 1 [72/172] - loss: 0.4627
Epoch 1 [73/172] - loss: 0.4814
Epoch 1 [74/172] - loss: 0.5311
Epoch 1 [75/172] - loss: 0.2954
Epoch 1 [76/172] - loss: 0.5239
Epoch 1 [77/172] - loss: 0.4549
Epoch 1 [78/172] - loss: 0.4896
Epoch 1 [79/172] - loss: 0.4373
Epoch 1 [80/172] - loss: 0.4440, acc: 0.7500
Epoch 1 [81/172] - loss: 0.4471
Epoch 1 [82/172] - loss: 0.6026
Epoch 1 [83/172] - loss: 0.5943
Epoch 1 [84/172] - loss: 0.5118
Epoch 1 [85/172] - loss: 0.5713
Epoch 1 [86/172] - loss: 0.7399
Epoch 1 [87/172] - loss: 0.5276
Epoch 1 [88/172] - loss: 0.8204
Epoch 1 [89/172] - loss: 0.6456
Epoch 1 [90/172] - loss: 0.6162, acc: 0.5938
Epoch 1 [91/172] - loss: 0.5145
Epoch 1 [92/172] - loss: 0.4610
Epoch 1 [93/172] - loss: 0.5054
Epoch 1 [94/172] - loss: 0.3807
Epoch 1 [95/172] - loss: 0.4731
Epoch 1 [96/172] - loss: 0.4494
Epoch 1 [97/172] - loss: 0.4611
Epoch 1 [98/172] - loss: 0.3616
Epoch 1 [99/172] - loss: 0.6344
Epoch 1 [100/172] - loss: 0.4941, acc: 0.6875

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5279, log_difficulty=0.4239, weight=3.1194
neutral: count=983.0, difficulty=0.4825, log_difficulty=0.3937, weight=2.9685
negative: count=1119.0, difficulty=0.4653, log_difficulty=0.3821, weight=2.9104

当前batch的pt分布：
positive: min=0.0187, max=0.9909, mean=0.5202
neutral: min=0.4713, max=0.9940, mean=0.7945
negative: min=0.1944, max=0.9639, mean=0.5288

当前batch准确率：
整体准确率: 0.6875
positive 准确率: 0.5833
neutral 准确率: 1.0000
negative 准确率: 0.6875

损失分量：
基础交叉熵: 0.7925
焦点损失: 0.3524
边界损失: 0.4023
总损失: 0.5707
Epoch 1 [101/172] - loss: 0.5707
Epoch 1 [102/172] - loss: 0.5130
Epoch 1 [103/172] - loss: 0.4885
Epoch 1 [104/172] - loss: 0.4271
Epoch 1 [105/172] - loss: 0.5633
Epoch 1 [106/172] - loss: 0.7060
Epoch 1 [107/172] - loss: 0.4059
Epoch 1 [108/172] - loss: 0.6090
Epoch 1 [109/172] - loss: 0.5500
Epoch 1 [110/172] - loss: 0.5023, acc: 0.6250
Epoch 1 [111/172] - loss: 0.5705
Epoch 1 [112/172] - loss: 0.4448
Epoch 1 [113/172] - loss: 0.3482
Epoch 1 [114/172] - loss: 0.4770
Epoch 1 [115/172] - loss: 0.4890
Epoch 1 [116/172] - loss: 0.3785
Epoch 1 [117/172] - loss: 0.5542
Epoch 1 [118/172] - loss: 0.3940
Epoch 1 [119/172] - loss: 0.4639
Epoch 1 [120/172] - loss: 0.3326, acc: 0.8438
Epoch 1 [121/172] - loss: 0.4041
Epoch 1 [122/172] - loss: 0.4443
Epoch 1 [123/172] - loss: 0.3829
Epoch 1 [124/172] - loss: 0.4273
Epoch 1 [125/172] - loss: 0.3706
Epoch 1 [126/172] - loss: 0.6358
Epoch 1 [127/172] - loss: 0.4153
Epoch 1 [128/172] - loss: 0.3166
Epoch 1 [129/172] - loss: 0.5052
Epoch 1 [130/172] - loss: 0.3063, acc: 0.8125
Epoch 1 [131/172] - loss: 0.2173
Epoch 1 [132/172] - loss: 0.3679
Epoch 1 [133/172] - loss: 0.4049
Epoch 1 [134/172] - loss: 0.3941
Epoch 1 [135/172] - loss: 0.4020
Epoch 1 [136/172] - loss: 0.3580
Epoch 1 [137/172] - loss: 0.4437
Epoch 1 [138/172] - loss: 0.3948
Epoch 1 [139/172] - loss: 0.3287
Epoch 1 [140/172] - loss: 0.2646, acc: 0.8750
Epoch 1 [141/172] - loss: 0.3449
Epoch 1 [142/172] - loss: 0.3913
Epoch 1 [143/172] - loss: 0.4855
Epoch 1 [144/172] - loss: 0.3021
Epoch 1 [145/172] - loss: 0.4381
Epoch 1 [146/172] - loss: 0.4447
Epoch 1 [147/172] - loss: 0.6530
Epoch 1 [148/172] - loss: 0.4005
Epoch 1 [149/172] - loss: 0.2656
Epoch 1 [150/172] - loss: 0.3994, acc: 0.7500
Epoch 1 [151/172] - loss: 0.4535
Epoch 1 [152/172] - loss: 0.3775
Epoch 1 [153/172] - loss: 0.3416
Epoch 1 [154/172] - loss: 0.3529
Epoch 1 [155/172] - loss: 0.4762
Epoch 1 [156/172] - loss: 0.4812
Epoch 1 [157/172] - loss: 0.3863
Epoch 1 [158/172] - loss: 0.3131
Epoch 1 [159/172] - loss: 0.5396
Epoch 1 [160/172] - loss: 0.3503, acc: 0.8125
Epoch 1 [161/172] - loss: 0.3784
Epoch 1 [162/172] - loss: 0.3438
Epoch 1 [163/172] - loss: 0.3311
Epoch 1 [164/172] - loss: 0.4728
Epoch 1 [165/172] - loss: 0.2917
Epoch 1 [166/172] - loss: 0.3870
Epoch 1 [167/172] - loss: 0.2709
Epoch 1 [168/172] - loss: 0.4013
Epoch 1 [169/172] - loss: 0.3662
Epoch 1 [170/172] - loss: 0.2683, acc: 0.8438
Epoch 1 [171/172] - loss: 0.2708
Epoch 1 [172/172] - loss: 0.3597

类别准确率:
positive: 0.6660 (311/467)
neutral: 0.5904 (49/83)
negative: 0.6640 (166/250)

Epoch 1/10
Train Loss: 0.3582, Train Acc: 0.8162
Val Loss: 0.8100, Val Acc: 0.6575
Epoch 2 [1/172] - loss: 0.2986, acc: 0.8438
Epoch 2 [2/172] - loss: 0.2985
Epoch 2 [3/172] - loss: 0.2380
Epoch 2 [4/172] - loss: 0.2711
Epoch 2 [5/172] - loss: 0.4003
Epoch 2 [6/172] - loss: 0.3956
Epoch 2 [7/172] - loss: 0.2906
Epoch 2 [8/172] - loss: 0.3455
Epoch 2 [9/172] - loss: 0.2573
Epoch 2 [10/172] - loss: 0.3388, acc: 0.8750
Epoch 2 [11/172] - loss: 0.2250
Epoch 2 [12/172] - loss: 0.1783
Epoch 2 [13/172] - loss: 0.4090
Epoch 2 [14/172] - loss: 0.3110
Epoch 2 [15/172] - loss: 0.3052
Epoch 2 [16/172] - loss: 0.3379
Epoch 2 [17/172] - loss: 0.4164
Epoch 2 [18/172] - loss: 0.3776
Epoch 2 [19/172] - loss: 0.2780
Epoch 2 [20/172] - loss: 0.2501, acc: 0.8438
Epoch 2 [21/172] - loss: 0.2894
Epoch 2 [22/172] - loss: 0.3041
Epoch 2 [23/172] - loss: 0.2323
Epoch 2 [24/172] - loss: 0.4076
Epoch 2 [25/172] - loss: 0.3035
Epoch 2 [26/172] - loss: 0.1821
Epoch 2 [27/172] - loss: 0.2234
Epoch 2 [28/172] - loss: 0.2848

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4490, log_difficulty=0.3709, weight=2.8544
neutral: count=1952.0, difficulty=0.3573, log_difficulty=0.3055, weight=2.5276
negative: count=2216.0, difficulty=0.3928, log_difficulty=0.3313, weight=2.6566

当前batch的pt分布：
positive: min=0.2201, max=0.9968, mean=0.7987
neutral: min=0.7843, max=0.9881, mean=0.9216
negative: min=0.0157, max=0.9948, mean=0.7142

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8889
neutral 准确率: 1.0000
negative 准确率: 0.8333

损失分量：
基础交叉熵: 0.3526
焦点损失: 0.1795
边界损失: 0.2159
总损失: 0.2825
Epoch 2 [29/172] - loss: 0.2825
Epoch 2 [30/172] - loss: 0.2741, acc: 0.8750
Epoch 2 [31/172] - loss: 0.2577
Epoch 2 [32/172] - loss: 0.2380
Epoch 2 [33/172] - loss: 0.2159
Epoch 2 [34/172] - loss: 0.2579
Epoch 2 [35/172] - loss: 0.1776
Epoch 2 [36/172] - loss: 0.3774
Epoch 2 [37/172] - loss: 0.2086
Epoch 2 [38/172] - loss: 0.2889
Epoch 2 [39/172] - loss: 0.3216
Epoch 2 [40/172] - loss: 0.2833, acc: 0.8125
Epoch 2 [41/172] - loss: 0.2466
Epoch 2 [42/172] - loss: 0.1910
Epoch 2 [43/172] - loss: 0.1708
Epoch 2 [44/172] - loss: 0.3655
Epoch 2 [45/172] - loss: 0.2067
Epoch 2 [46/172] - loss: 0.2427
Epoch 2 [47/172] - loss: 0.4015
Epoch 2 [48/172] - loss: 0.3159
Epoch 2 [49/172] - loss: 0.2259
Epoch 2 [50/172] - loss: 0.3853, acc: 0.8125
Epoch 2 [51/172] - loss: 0.3072
Epoch 2 [52/172] - loss: 0.1729
Epoch 2 [53/172] - loss: 0.2087
Epoch 2 [54/172] - loss: 0.2163
Epoch 2 [55/172] - loss: 0.2370
Epoch 2 [56/172] - loss: 0.1827
Epoch 2 [57/172] - loss: 0.2151
Epoch 2 [58/172] - loss: 0.2509
Epoch 2 [59/172] - loss: 0.2872
Epoch 2 [60/172] - loss: 0.2314, acc: 0.9375
Epoch 2 [61/172] - loss: 0.1975
Epoch 2 [62/172] - loss: 0.1749
Epoch 2 [63/172] - loss: 0.2292
Epoch 2 [64/172] - loss: 0.1796
Epoch 2 [65/172] - loss: 0.2333
Epoch 2 [66/172] - loss: 0.2155
Epoch 2 [67/172] - loss: 0.1617
Epoch 2 [68/172] - loss: 0.2506
Epoch 2 [69/172] - loss: 0.2065
Epoch 2 [70/172] - loss: 0.2382, acc: 0.9062
Epoch 2 [71/172] - loss: 0.2574
Epoch 2 [72/172] - loss: 0.2229
Epoch 2 [73/172] - loss: 0.3084
Epoch 2 [74/172] - loss: 0.2464
Epoch 2 [75/172] - loss: 0.2206
Epoch 2 [76/172] - loss: 0.2721
Epoch 2 [77/172] - loss: 0.2963
Epoch 2 [78/172] - loss: 0.2296
Epoch 2 [79/172] - loss: 0.2603
Epoch 2 [80/172] - loss: 0.1760, acc: 0.9688
Epoch 2 [81/172] - loss: 0.3465
Epoch 2 [82/172] - loss: 0.1883
Epoch 2 [83/172] - loss: 0.2686
Epoch 2 [84/172] - loss: 0.2348
Epoch 2 [85/172] - loss: 0.2424
Epoch 2 [86/172] - loss: 0.1945
Epoch 2 [87/172] - loss: 0.3927
Epoch 2 [88/172] - loss: 0.2157
Epoch 2 [89/172] - loss: 0.1699
Epoch 2 [90/172] - loss: 0.2297, acc: 0.8750
Epoch 2 [91/172] - loss: 0.1643
Epoch 2 [92/172] - loss: 0.2866
Epoch 2 [93/172] - loss: 0.2112
Epoch 2 [94/172] - loss: 0.1933
Epoch 2 [95/172] - loss: 0.3512
Epoch 2 [96/172] - loss: 0.1558
Epoch 2 [97/172] - loss: 0.2117
Epoch 2 [98/172] - loss: 0.1814
Epoch 2 [99/172] - loss: 0.1634
Epoch 2 [100/172] - loss: 0.2216, acc: 0.8438
Epoch 2 [101/172] - loss: 0.2095
Epoch 2 [102/172] - loss: 0.1716
Epoch 2 [103/172] - loss: 0.3058
Epoch 2 [104/172] - loss: 0.2381
Epoch 2 [105/172] - loss: 0.2345
Epoch 2 [106/172] - loss: 0.1678
Epoch 2 [107/172] - loss: 0.1911
Epoch 2 [108/172] - loss: 0.2802
Epoch 2 [109/172] - loss: 0.1953
Epoch 2 [110/172] - loss: 0.2198, acc: 0.9375
Epoch 2 [111/172] - loss: 0.1786
Epoch 2 [112/172] - loss: 0.1498
Epoch 2 [113/172] - loss: 0.1549
Epoch 2 [114/172] - loss: 0.2063
Epoch 2 [115/172] - loss: 0.3175
Epoch 2 [116/172] - loss: 0.2715
Epoch 2 [117/172] - loss: 0.3816
Epoch 2 [118/172] - loss: 0.1771
Epoch 2 [119/172] - loss: 0.2297
Epoch 2 [120/172] - loss: 0.2554, acc: 0.9062
Epoch 2 [121/172] - loss: 0.1718
Epoch 2 [122/172] - loss: 0.4074
Epoch 2 [123/172] - loss: 0.2365
Epoch 2 [124/172] - loss: 0.2276
Epoch 2 [125/172] - loss: 0.1664
Epoch 2 [126/172] - loss: 0.1837
Epoch 2 [127/172] - loss: 0.1709
Epoch 2 [128/172] - loss: 0.1729

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3733, log_difficulty=0.3172, weight=2.5862
neutral: count=2949.0, difficulty=0.2731, log_difficulty=0.2414, weight=2.2071
negative: count=3294.0, difficulty=0.3302, log_difficulty=0.2854, weight=2.4268

当前batch的pt分布：
positive: min=0.1959, max=0.9978, mean=0.7821
neutral: min=0.8059, max=0.9982, mean=0.9355
negative: min=0.0354, max=0.9901, mean=0.7768

当前batch准确率：
整体准确率: 0.8750
positive 准确率: 0.8000
neutral 准确率: 1.0000
negative 准确率: 0.8182

损失分量：
基础交叉熵: 0.3149
焦点损失: 0.1740
边界损失: 0.1871
总损失: 0.2481
Epoch 2 [129/172] - loss: 0.2481
Epoch 2 [130/172] - loss: 0.2484, acc: 0.9062
Epoch 2 [131/172] - loss: 0.2627
Epoch 2 [132/172] - loss: 0.2383
Epoch 2 [133/172] - loss: 0.1886
Epoch 2 [134/172] - loss: 0.2749
Epoch 2 [135/172] - loss: 0.3106
Epoch 2 [136/172] - loss: 0.1828
Epoch 2 [137/172] - loss: 0.1655
Epoch 2 [138/172] - loss: 0.1579
Epoch 2 [139/172] - loss: 0.1596
Epoch 2 [140/172] - loss: 0.2022, acc: 0.8750
Epoch 2 [141/172] - loss: 0.1859
Epoch 2 [142/172] - loss: 0.2039
Epoch 2 [143/172] - loss: 0.2064
Epoch 2 [144/172] - loss: 0.1553
Epoch 2 [145/172] - loss: 0.3977
Epoch 2 [146/172] - loss: 0.1633
Epoch 2 [147/172] - loss: 0.2077
Epoch 2 [148/172] - loss: 0.2518
Epoch 2 [149/172] - loss: 0.2285
Epoch 2 [150/172] - loss: 0.1503, acc: 1.0000
Epoch 2 [151/172] - loss: 0.2075
Epoch 2 [152/172] - loss: 0.1778
Epoch 2 [153/172] - loss: 0.1603
Epoch 2 [154/172] - loss: 0.1718
Epoch 2 [155/172] - loss: 0.2085
Epoch 2 [156/172] - loss: 0.1781
Epoch 2 [157/172] - loss: 0.1869
Epoch 2 [158/172] - loss: 0.1840
Epoch 2 [159/172] - loss: 0.1544
Epoch 2 [160/172] - loss: 0.1607, acc: 0.9375
Epoch 2 [161/172] - loss: 0.1643
Epoch 2 [162/172] - loss: 0.1330
Epoch 2 [163/172] - loss: 0.3641
Epoch 2 [164/172] - loss: 0.1762
Epoch 2 [165/172] - loss: 0.2725
Epoch 2 [166/172] - loss: 0.2685
Epoch 2 [167/172] - loss: 0.2422
Epoch 2 [168/172] - loss: 0.1714
Epoch 2 [169/172] - loss: 0.1421
Epoch 2 [170/172] - loss: 0.2121, acc: 0.8750
Epoch 2 [171/172] - loss: 0.2436
Epoch 2 [172/172] - loss: 0.4443

类别准确率:
positive: 0.8351 (390/467)
neutral: 0.3976 (33/83)
negative: 0.6120 (153/250)

Epoch 2/10
Train Loss: 0.2200, Train Acc: 0.9253
Val Loss: 0.7464, Val Acc: 0.7200
Epoch 3 [1/172] - loss: 0.1498, acc: 1.0000
Epoch 3 [2/172] - loss: 0.1461
Epoch 3 [3/172] - loss: 0.1344
Epoch 3 [4/172] - loss: 0.1551
Epoch 3 [5/172] - loss: 0.1434
Epoch 3 [6/172] - loss: 0.1278
Epoch 3 [7/172] - loss: 0.1688
Epoch 3 [8/172] - loss: 0.1561
Epoch 3 [9/172] - loss: 0.1738
Epoch 3 [10/172] - loss: 0.1338, acc: 1.0000
Epoch 3 [11/172] - loss: 0.1343
Epoch 3 [12/172] - loss: 0.1264
Epoch 3 [13/172] - loss: 0.1579
Epoch 3 [14/172] - loss: 0.1293
Epoch 3 [15/172] - loss: 0.1424
Epoch 3 [16/172] - loss: 0.2330
Epoch 3 [17/172] - loss: 0.1780
Epoch 3 [18/172] - loss: 0.1822
Epoch 3 [19/172] - loss: 0.1398
Epoch 3 [20/172] - loss: 0.1595, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1446
Epoch 3 [22/172] - loss: 0.2619
Epoch 3 [23/172] - loss: 0.1817
Epoch 3 [24/172] - loss: 0.1804
Epoch 3 [25/172] - loss: 0.1804
Epoch 3 [26/172] - loss: 0.1566
Epoch 3 [27/172] - loss: 0.1481
Epoch 3 [28/172] - loss: 0.1291
Epoch 3 [29/172] - loss: 0.1854
Epoch 3 [30/172] - loss: 0.1381, acc: 1.0000
Epoch 3 [31/172] - loss: 0.1632
Epoch 3 [32/172] - loss: 0.1326
Epoch 3 [33/172] - loss: 0.1258
Epoch 3 [34/172] - loss: 0.1775
Epoch 3 [35/172] - loss: 0.1513
Epoch 3 [36/172] - loss: 0.1421
Epoch 3 [37/172] - loss: 0.1731
Epoch 3 [38/172] - loss: 0.1197
Epoch 3 [39/172] - loss: 0.1288
Epoch 3 [40/172] - loss: 0.1566, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1361
Epoch 3 [42/172] - loss: 0.1326
Epoch 3 [43/172] - loss: 0.1406
Epoch 3 [44/172] - loss: 0.1742
Epoch 3 [45/172] - loss: 0.1716
Epoch 3 [46/172] - loss: 0.1516
Epoch 3 [47/172] - loss: 0.1234
Epoch 3 [48/172] - loss: 0.1906
Epoch 3 [49/172] - loss: 0.1152
Epoch 3 [50/172] - loss: 0.1538, acc: 0.9375
Epoch 3 [51/172] - loss: 0.1818
Epoch 3 [52/172] - loss: 0.1910
Epoch 3 [53/172] - loss: 0.1311
Epoch 3 [54/172] - loss: 0.1634
Epoch 3 [55/172] - loss: 0.1328
Epoch 3 [56/172] - loss: 0.1392

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3119, log_difficulty=0.2715, weight=2.3573
neutral: count=3923.0, difficulty=0.2237, log_difficulty=0.2019, weight=2.0094
negative: count=4382.0, difficulty=0.2790, log_difficulty=0.2461, weight=2.2305

当前batch的pt分布：
positive: min=0.2959, max=0.9985, mean=0.8396
neutral: min=0.0061, max=0.9889, mean=0.8404
negative: min=0.9898, max=0.9993, mean=0.9954

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8182
neutral 准确率: 0.9375
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.3038
焦点损失: 0.1950
边界损失: 0.1805
总损失: 0.2362
Epoch 3 [57/172] - loss: 0.2362
Epoch 3 [58/172] - loss: 0.1272
Epoch 3 [59/172] - loss: 0.1514
Epoch 3 [60/172] - loss: 0.1348, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1223
Epoch 3 [62/172] - loss: 0.1352
Epoch 3 [63/172] - loss: 0.1592
Epoch 3 [64/172] - loss: 0.1633
Epoch 3 [65/172] - loss: 0.1254
Epoch 3 [66/172] - loss: 0.1527
Epoch 3 [67/172] - loss: 0.1345
Epoch 3 [68/172] - loss: 0.1202
Epoch 3 [69/172] - loss: 0.1607
Epoch 3 [70/172] - loss: 0.1164, acc: 1.0000
Epoch 3 [71/172] - loss: 0.1550
Epoch 3 [72/172] - loss: 0.1779
Epoch 3 [73/172] - loss: 0.1403
Epoch 3 [74/172] - loss: 0.1810
Epoch 3 [75/172] - loss: 0.1547
Epoch 3 [76/172] - loss: 0.1256
Epoch 3 [77/172] - loss: 0.1563
Epoch 3 [78/172] - loss: 0.2162
Epoch 3 [79/172] - loss: 0.1354
Epoch 3 [80/172] - loss: 0.1961, acc: 0.8750
Epoch 3 [81/172] - loss: 0.1242
Epoch 3 [82/172] - loss: 0.1809
Epoch 3 [83/172] - loss: 0.1178
Epoch 3 [84/172] - loss: 0.1185
Epoch 3 [85/172] - loss: 0.1282
Epoch 3 [86/172] - loss: 0.1165
Epoch 3 [87/172] - loss: 0.1724
Epoch 3 [88/172] - loss: 0.1484
Epoch 3 [89/172] - loss: 0.1221
Epoch 3 [90/172] - loss: 0.1207, acc: 1.0000
Epoch 3 [91/172] - loss: 0.1375
Epoch 3 [92/172] - loss: 0.1192
Epoch 3 [93/172] - loss: 0.1801
Epoch 3 [94/172] - loss: 0.1646
Epoch 3 [95/172] - loss: 0.1152
Epoch 3 [96/172] - loss: 0.1412
Epoch 3 [97/172] - loss: 0.1591
Epoch 3 [98/172] - loss: 0.1369
Epoch 3 [99/172] - loss: 0.1247
Epoch 3 [100/172] - loss: 0.1574, acc: 0.9688
Epoch 3 [101/172] - loss: 0.2138
Epoch 3 [102/172] - loss: 0.1117
Epoch 3 [103/172] - loss: 0.1568
Epoch 3 [104/172] - loss: 0.1290
Epoch 3 [105/172] - loss: 0.1225
Epoch 3 [106/172] - loss: 0.1361
Epoch 3 [107/172] - loss: 0.1197
Epoch 3 [108/172] - loss: 0.1218
Epoch 3 [109/172] - loss: 0.1122
Epoch 3 [110/172] - loss: 0.1408, acc: 0.9688
Epoch 3 [111/172] - loss: 0.1484
Epoch 3 [112/172] - loss: 0.1194
Epoch 3 [113/172] - loss: 0.1149
Epoch 3 [114/172] - loss: 0.1425
Epoch 3 [115/172] - loss: 0.1281
Epoch 3 [116/172] - loss: 0.1198
Epoch 3 [117/172] - loss: 0.1317
Epoch 3 [118/172] - loss: 0.1313
Epoch 3 [119/172] - loss: 0.1222
Epoch 3 [120/172] - loss: 0.2156, acc: 0.9688
Epoch 3 [121/172] - loss: 0.1857
Epoch 3 [122/172] - loss: 0.1216
Epoch 3 [123/172] - loss: 0.1152
Epoch 3 [124/172] - loss: 0.1649
Epoch 3 [125/172] - loss: 0.1309
Epoch 3 [126/172] - loss: 0.2780
Epoch 3 [127/172] - loss: 0.1552
Epoch 3 [128/172] - loss: 0.1336
Epoch 3 [129/172] - loss: 0.1188
Epoch 3 [130/172] - loss: 0.1320, acc: 0.9688
Epoch 3 [131/172] - loss: 0.1255
Epoch 3 [132/172] - loss: 0.1468
Epoch 3 [133/172] - loss: 0.1311
Epoch 3 [134/172] - loss: 0.1251
Epoch 3 [135/172] - loss: 0.1754
Epoch 3 [136/172] - loss: 0.1307
Epoch 3 [137/172] - loss: 0.1242
Epoch 3 [138/172] - loss: 0.1296
Epoch 3 [139/172] - loss: 0.1250
Epoch 3 [140/172] - loss: 0.1493, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1570
Epoch 3 [142/172] - loss: 0.1364
Epoch 3 [143/172] - loss: 0.1249
Epoch 3 [144/172] - loss: 0.2234
Epoch 3 [145/172] - loss: 0.1423
Epoch 3 [146/172] - loss: 0.1314
Epoch 3 [147/172] - loss: 0.1311
Epoch 3 [148/172] - loss: 0.2062
Epoch 3 [149/172] - loss: 0.1680
Epoch 3 [150/172] - loss: 0.1569, acc: 0.9688
Epoch 3 [151/172] - loss: 0.2455
Epoch 3 [152/172] - loss: 0.2169
Epoch 3 [153/172] - loss: 0.1276
Epoch 3 [154/172] - loss: 0.1778
Epoch 3 [155/172] - loss: 0.1221
Epoch 3 [156/172] - loss: 0.1575

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2668, log_difficulty=0.2365, weight=2.1825
neutral: count=4903.0, difficulty=0.1883, log_difficulty=0.1725, weight=1.8625
negative: count=5500.0, difficulty=0.2395, log_difficulty=0.2147, weight=2.0737

当前batch的pt分布：
positive: min=0.6810, max=0.9947, mean=0.9446
neutral: min=0.8796, max=0.9976, mean=0.9673
negative: min=0.0362, max=0.9987, mean=0.8664

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1492
焦点损失: 0.0971
边界损失: 0.1573
总损失: 0.1683
Epoch 3 [157/172] - loss: 0.1683
Epoch 3 [158/172] - loss: 0.1456
Epoch 3 [159/172] - loss: 0.1350
Epoch 3 [160/172] - loss: 0.1938, acc: 0.9375
Epoch 3 [161/172] - loss: 0.1957
Epoch 3 [162/172] - loss: 0.1327
Epoch 3 [163/172] - loss: 0.1338
Epoch 3 [164/172] - loss: 0.1117
Epoch 3 [165/172] - loss: 0.1503
Epoch 3 [166/172] - loss: 0.1194
Epoch 3 [167/172] - loss: 0.1453
Epoch 3 [168/172] - loss: 0.1181
Epoch 3 [169/172] - loss: 0.1128
Epoch 3 [170/172] - loss: 0.1320, acc: 1.0000
Epoch 3 [171/172] - loss: 0.1539
Epoch 3 [172/172] - loss: 0.1114

类别准确率:
positive: 0.8437 (394/467)
neutral: 0.3012 (25/83)
negative: 0.6480 (162/250)

Epoch 3/10
Train Loss: 0.1412, Train Acc: 0.9758
Val Loss: 0.8424, Val Acc: 0.7262
Epoch 4 [1/172] - loss: 0.1156, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1136
Epoch 4 [3/172] - loss: 0.1300
Epoch 4 [4/172] - loss: 0.1204
Epoch 4 [5/172] - loss: 0.1384
Epoch 4 [6/172] - loss: 0.1208
Epoch 4 [7/172] - loss: 0.1278
Epoch 4 [8/172] - loss: 0.1106
Epoch 4 [9/172] - loss: 0.1430
Epoch 4 [10/172] - loss: 0.1355, acc: 0.9688
Epoch 4 [11/172] - loss: 0.1191
Epoch 4 [12/172] - loss: 0.1212
Epoch 4 [13/172] - loss: 0.1607
Epoch 4 [14/172] - loss: 0.1249
Epoch 4 [15/172] - loss: 0.1101
Epoch 4 [16/172] - loss: 0.1261
Epoch 4 [17/172] - loss: 0.1182
Epoch 4 [18/172] - loss: 0.1188
Epoch 4 [19/172] - loss: 0.1134
Epoch 4 [20/172] - loss: 0.1180, acc: 1.0000
Epoch 4 [21/172] - loss: 0.2097
Epoch 4 [22/172] - loss: 0.1141
Epoch 4 [23/172] - loss: 0.1325
Epoch 4 [24/172] - loss: 0.1076
Epoch 4 [25/172] - loss: 0.1120
Epoch 4 [26/172] - loss: 0.1801
Epoch 4 [27/172] - loss: 0.1109
Epoch 4 [28/172] - loss: 0.1272
Epoch 4 [29/172] - loss: 0.1178
Epoch 4 [30/172] - loss: 0.1636, acc: 0.9375
Epoch 4 [31/172] - loss: 0.1508
Epoch 4 [32/172] - loss: 0.1137
Epoch 4 [33/172] - loss: 0.1185
Epoch 4 [34/172] - loss: 0.1075
Epoch 4 [35/172] - loss: 0.1972
Epoch 4 [36/172] - loss: 0.1220
Epoch 4 [37/172] - loss: 0.1136
Epoch 4 [38/172] - loss: 0.1107
Epoch 4 [39/172] - loss: 0.1418
Epoch 4 [40/172] - loss: 0.1686, acc: 0.9375
Epoch 4 [41/172] - loss: 0.1142
Epoch 4 [42/172] - loss: 0.1464
Epoch 4 [43/172] - loss: 0.1456
Epoch 4 [44/172] - loss: 0.1180
Epoch 4 [45/172] - loss: 0.1204
Epoch 4 [46/172] - loss: 0.1122
Epoch 4 [47/172] - loss: 0.1269
Epoch 4 [48/172] - loss: 0.1212
Epoch 4 [49/172] - loss: 0.1069
Epoch 4 [50/172] - loss: 0.1290, acc: 0.9688
Epoch 4 [51/172] - loss: 0.1081
Epoch 4 [52/172] - loss: 0.1537
Epoch 4 [53/172] - loss: 0.1128
Epoch 4 [54/172] - loss: 0.1219
Epoch 4 [55/172] - loss: 0.2136
Epoch 4 [56/172] - loss: 0.1178
Epoch 4 [57/172] - loss: 0.1104
Epoch 4 [58/172] - loss: 0.1129
Epoch 4 [59/172] - loss: 0.1092
Epoch 4 [60/172] - loss: 0.1119, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1124
Epoch 4 [62/172] - loss: 0.1559
Epoch 4 [63/172] - loss: 0.1166
Epoch 4 [64/172] - loss: 0.1116
Epoch 4 [65/172] - loss: 0.1235
Epoch 4 [66/172] - loss: 0.1093
Epoch 4 [67/172] - loss: 0.1456
Epoch 4 [68/172] - loss: 0.1157
Epoch 4 [69/172] - loss: 0.1158
Epoch 4 [70/172] - loss: 0.1143, acc: 1.0000
Epoch 4 [71/172] - loss: 0.1159
Epoch 4 [72/172] - loss: 0.1118
Epoch 4 [73/172] - loss: 0.1293
Epoch 4 [74/172] - loss: 0.1652
Epoch 4 [75/172] - loss: 0.1746
Epoch 4 [76/172] - loss: 0.1064
Epoch 4 [77/172] - loss: 0.1372
Epoch 4 [78/172] - loss: 0.1208
Epoch 4 [79/172] - loss: 0.1080
Epoch 4 [80/172] - loss: 0.1070, acc: 1.0000
Epoch 4 [81/172] - loss: 0.1559
Epoch 4 [82/172] - loss: 0.1153
Epoch 4 [83/172] - loss: 0.1365
Epoch 4 [84/172] - loss: 0.1074

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2319, log_difficulty=0.2085, weight=2.0427
neutral: count=5865.0, difficulty=0.1638, log_difficulty=0.1517, weight=1.7586
negative: count=6629.0, difficulty=0.2082, log_difficulty=0.1891, weight=1.9457

当前batch的pt分布：
positive: min=0.3445, max=0.9949, mean=0.8623
neutral: min=0.9103, max=0.9999, mean=0.9851
negative: min=0.2294, max=0.9999, mean=0.9030

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 0.8889

损失分量：
基础交叉熵: 0.1428
焦点损失: 0.0452
边界损失: 0.1760
总损失: 0.1544
Epoch 4 [85/172] - loss: 0.1544
Epoch 4 [86/172] - loss: 0.1873
Epoch 4 [87/172] - loss: 0.1131
Epoch 4 [88/172] - loss: 0.1103
Epoch 4 [89/172] - loss: 0.1097
Epoch 4 [90/172] - loss: 0.1148, acc: 1.0000
Epoch 4 [91/172] - loss: 0.2046
Epoch 4 [92/172] - loss: 0.2222
Epoch 4 [93/172] - loss: 0.1115
Epoch 4 [94/172] - loss: 0.1070
Epoch 4 [95/172] - loss: 0.1413
Epoch 4 [96/172] - loss: 0.1623
Epoch 4 [97/172] - loss: 0.1089
Epoch 4 [98/172] - loss: 0.1099
Epoch 4 [99/172] - loss: 0.1134
Epoch 4 [100/172] - loss: 0.1145, acc: 1.0000
Epoch 4 [101/172] - loss: 0.1212
Epoch 4 [102/172] - loss: 0.1319
Epoch 4 [103/172] - loss: 0.1094
Epoch 4 [104/172] - loss: 0.1078
Epoch 4 [105/172] - loss: 0.1203
Epoch 4 [106/172] - loss: 0.1185
Epoch 4 [107/172] - loss: 0.1122
Epoch 4 [108/172] - loss: 0.1257
Epoch 4 [109/172] - loss: 0.1468
Epoch 4 [110/172] - loss: 0.2664, acc: 0.9062
Epoch 4 [111/172] - loss: 0.1081
Epoch 4 [112/172] - loss: 0.1170
Epoch 4 [113/172] - loss: 0.1189
Epoch 4 [114/172] - loss: 0.1113
Epoch 4 [115/172] - loss: 0.1162
Epoch 4 [116/172] - loss: 0.1531
Epoch 4 [117/172] - loss: 0.1106
Epoch 4 [118/172] - loss: 0.1395
Epoch 4 [119/172] - loss: 0.1393
Epoch 4 [120/172] - loss: 0.1212, acc: 1.0000
Epoch 4 [121/172] - loss: 0.1450
Epoch 4 [122/172] - loss: 0.2035
Epoch 4 [123/172] - loss: 0.1208
Epoch 4 [124/172] - loss: 0.1249
Epoch 4 [125/172] - loss: 0.1258
Epoch 4 [126/172] - loss: 0.1628
Epoch 4 [127/172] - loss: 0.1394
Epoch 4 [128/172] - loss: 0.1159
Epoch 4 [129/172] - loss: 0.1124
Epoch 4 [130/172] - loss: 0.1093, acc: 1.0000
Epoch 4 [131/172] - loss: 0.1233
Epoch 4 [132/172] - loss: 0.1082
Epoch 4 [133/172] - loss: 0.1219
Epoch 4 [134/172] - loss: 0.1150
Epoch 4 [135/172] - loss: 0.1151
Epoch 4 [136/172] - loss: 0.1413
Epoch 4 [137/172] - loss: 0.1118
Epoch 4 [138/172] - loss: 0.1085
Epoch 4 [139/172] - loss: 0.1299
Epoch 4 [140/172] - loss: 0.1168, acc: 1.0000
Epoch 4 [141/172] - loss: 0.1717
Epoch 4 [142/172] - loss: 0.1189
Epoch 4 [143/172] - loss: 0.1358
Epoch 4 [144/172] - loss: 0.1280
Epoch 4 [145/172] - loss: 0.2415
Epoch 4 [146/172] - loss: 0.1104
Epoch 4 [147/172] - loss: 0.1380
Epoch 4 [148/172] - loss: 0.1177
Epoch 4 [149/172] - loss: 0.1139
Epoch 4 [150/172] - loss: 0.1283, acc: 1.0000
Epoch 4 [151/172] - loss: 0.2013
Epoch 4 [152/172] - loss: 0.1094
Epoch 4 [153/172] - loss: 0.1114
Epoch 4 [154/172] - loss: 0.1346
Epoch 4 [155/172] - loss: 0.1118
Epoch 4 [156/172] - loss: 0.1171
Epoch 4 [157/172] - loss: 0.2615
Epoch 4 [158/172] - loss: 0.1091
Epoch 4 [159/172] - loss: 0.1084
Epoch 4 [160/172] - loss: 0.1120, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1609
Epoch 4 [162/172] - loss: 0.1092
Epoch 4 [163/172] - loss: 0.1176
Epoch 4 [164/172] - loss: 0.1066
Epoch 4 [165/172] - loss: 0.1395
Epoch 4 [166/172] - loss: 0.1174
Epoch 4 [167/172] - loss: 0.1277
Epoch 4 [168/172] - loss: 0.1306
Epoch 4 [169/172] - loss: 0.1280
Epoch 4 [170/172] - loss: 0.1613, acc: 0.9688
Epoch 4 [171/172] - loss: 0.1157
Epoch 4 [172/172] - loss: 0.1141

类别准确率:
positive: 0.9572 (447/467)
neutral: 0.1325 (11/83)
negative: 0.4480 (112/250)

Epoch 4/10
Train Loss: 0.1325, Train Acc: 0.9838
Val Loss: 1.1366, Val Acc: 0.7125
Epoch 5 [1/172] - loss: 0.1239, acc: 0.9688
Epoch 5 [2/172] - loss: 0.1451
Epoch 5 [3/172] - loss: 0.1083
Epoch 5 [4/172] - loss: 0.1233
Epoch 5 [5/172] - loss: 0.1101
Epoch 5 [6/172] - loss: 0.1335
Epoch 5 [7/172] - loss: 0.1117
Epoch 5 [8/172] - loss: 0.1325
Epoch 5 [9/172] - loss: 0.1341
Epoch 5 [10/172] - loss: 0.1125, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1246
Epoch 5 [12/172] - loss: 0.1102

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2061, log_difficulty=0.1874, weight=1.9369
neutral: count=6845.0, difficulty=0.1449, log_difficulty=0.1353, weight=1.6767
negative: count=7694.0, difficulty=0.1868, log_difficulty=0.1712, weight=1.8561

当前batch的pt分布：
positive: min=0.0908, max=0.9994, mean=0.8862
neutral: min=0.9317, max=0.9997, mean=0.9883
negative: min=0.8706, max=0.9998, mean=0.9693

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1115
焦点损失: 0.0621
边界损失: 0.1599
总损失: 0.1500
Epoch 5 [13/172] - loss: 0.1500
Epoch 5 [14/172] - loss: 0.1513
Epoch 5 [15/172] - loss: 0.1077
Epoch 5 [16/172] - loss: 0.1076
Epoch 5 [17/172] - loss: 0.1302
Epoch 5 [18/172] - loss: 0.1064
Epoch 5 [19/172] - loss: 0.1514
Epoch 5 [20/172] - loss: 0.1507, acc: 0.9688
Epoch 5 [21/172] - loss: 0.1447
Epoch 5 [22/172] - loss: 0.2123
Epoch 5 [23/172] - loss: 0.1103
Epoch 5 [24/172] - loss: 0.1373
Epoch 5 [25/172] - loss: 0.1196
Epoch 5 [26/172] - loss: 0.1448
Epoch 5 [27/172] - loss: 0.1214
Epoch 5 [28/172] - loss: 0.1102
Epoch 5 [29/172] - loss: 0.1116
Epoch 5 [30/172] - loss: 0.1146, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1199
Epoch 5 [32/172] - loss: 0.1145
Epoch 5 [33/172] - loss: 0.1166
Epoch 5 [34/172] - loss: 0.1363
Epoch 5 [35/172] - loss: 0.1080
Epoch 5 [36/172] - loss: 0.1114
Epoch 5 [37/172] - loss: 0.1092
Epoch 5 [38/172] - loss: 0.1119
Epoch 5 [39/172] - loss: 0.1991
Epoch 5 [40/172] - loss: 0.1177, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1098
Epoch 5 [42/172] - loss: 0.1085
Epoch 5 [43/172] - loss: 0.1395
Epoch 5 [44/172] - loss: 0.1266
Epoch 5 [45/172] - loss: 0.1179
Epoch 5 [46/172] - loss: 0.1340
Epoch 5 [47/172] - loss: 0.1077
Epoch 5 [48/172] - loss: 0.1162
Epoch 5 [49/172] - loss: 0.1109
Epoch 5 [50/172] - loss: 0.1166, acc: 1.0000
Epoch 5 [51/172] - loss: 0.1119
Epoch 5 [52/172] - loss: 0.1290
Epoch 5 [53/172] - loss: 0.1282
Epoch 5 [54/172] - loss: 0.1220
Epoch 5 [55/172] - loss: 0.1420
Epoch 5 [56/172] - loss: 0.1182
Epoch 5 [57/172] - loss: 0.1128
Epoch 5 [58/172] - loss: 0.1131
Epoch 5 [59/172] - loss: 0.1345
Epoch 5 [60/172] - loss: 0.1063, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1207
Epoch 5 [62/172] - loss: 0.1123
Epoch 5 [63/172] - loss: 0.1173
Epoch 5 [64/172] - loss: 0.1460
Epoch 5 [65/172] - loss: 0.1077
Epoch 5 [66/172] - loss: 0.1068
Epoch 5 [67/172] - loss: 0.1059
Epoch 5 [68/172] - loss: 0.1116
Epoch 5 [69/172] - loss: 0.1097
Epoch 5 [70/172] - loss: 0.1097, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1090
Epoch 5 [72/172] - loss: 0.1148
Epoch 5 [73/172] - loss: 0.1120
Epoch 5 [74/172] - loss: 0.1215
Epoch 5 [75/172] - loss: 0.1094
Epoch 5 [76/172] - loss: 0.1136
Epoch 5 [77/172] - loss: 0.1146
Epoch 5 [78/172] - loss: 0.1138
Epoch 5 [79/172] - loss: 0.1180
Epoch 5 [80/172] - loss: 0.1061, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1785
Epoch 5 [82/172] - loss: 0.1248
Epoch 5 [83/172] - loss: 0.1096
Epoch 5 [84/172] - loss: 0.1067
Epoch 5 [85/172] - loss: 0.1737
Epoch 5 [86/172] - loss: 0.1080
Epoch 5 [87/172] - loss: 0.1208
Epoch 5 [88/172] - loss: 0.1281
Epoch 5 [89/172] - loss: 0.1218
Epoch 5 [90/172] - loss: 0.2151, acc: 0.9688
Epoch 5 [91/172] - loss: 0.1067
Epoch 5 [92/172] - loss: 0.1067
Epoch 5 [93/172] - loss: 0.1064
Epoch 5 [94/172] - loss: 0.1454
Epoch 5 [95/172] - loss: 0.1156
Epoch 5 [96/172] - loss: 0.1157
Epoch 5 [97/172] - loss: 0.1342
Epoch 5 [98/172] - loss: 0.1050
Epoch 5 [99/172] - loss: 0.1268
Epoch 5 [100/172] - loss: 0.1096, acc: 1.0000
Epoch 5 [101/172] - loss: 0.1112
Epoch 5 [102/172] - loss: 0.1173
Epoch 5 [103/172] - loss: 0.1108
Epoch 5 [104/172] - loss: 0.1316
Epoch 5 [105/172] - loss: 0.1994
Epoch 5 [106/172] - loss: 0.1172
Epoch 5 [107/172] - loss: 0.1138
Epoch 5 [108/172] - loss: 0.1446
Epoch 5 [109/172] - loss: 0.1104
Epoch 5 [110/172] - loss: 0.1232, acc: 0.9688
Epoch 5 [111/172] - loss: 0.1111
Epoch 5 [112/172] - loss: 0.1045

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.1850, log_difficulty=0.1697, weight=1.8487
neutral: count=7825.0, difficulty=0.1303, log_difficulty=0.1225, weight=1.6125
negative: count=8780.0, difficulty=0.1689, log_difficulty=0.1561, weight=1.7803

当前batch的pt分布：
positive: min=0.3259, max=0.9875, mean=0.9196
neutral: min=0.8099, max=0.9992, mean=0.9619
negative: min=0.9009, max=1.0000, mean=0.9797

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0722
焦点损失: 0.0164
边界损失: 0.1597
总损失: 0.1273
Epoch 5 [113/172] - loss: 0.1273
Epoch 5 [114/172] - loss: 0.1504
Epoch 5 [115/172] - loss: 0.1081
Epoch 5 [116/172] - loss: 0.1061
Epoch 5 [117/172] - loss: 0.1098
Epoch 5 [118/172] - loss: 0.1133
Epoch 5 [119/172] - loss: 0.1120
Epoch 5 [120/172] - loss: 0.1075, acc: 1.0000
Epoch 5 [121/172] - loss: 0.1128
Epoch 5 [122/172] - loss: 0.1117
Epoch 5 [123/172] - loss: 0.1131
Epoch 5 [124/172] - loss: 0.1166
Epoch 5 [125/172] - loss: 0.1064
Epoch 5 [126/172] - loss: 0.1095
Epoch 5 [127/172] - loss: 0.1078
Epoch 5 [128/172] - loss: 0.1283
Epoch 5 [129/172] - loss: 0.1217
Epoch 5 [130/172] - loss: 0.1055, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1073
Epoch 5 [132/172] - loss: 0.1205
Epoch 5 [133/172] - loss: 0.1466
Epoch 5 [134/172] - loss: 0.1249
Epoch 5 [135/172] - loss: 0.1069
Epoch 5 [136/172] - loss: 0.1144
Epoch 5 [137/172] - loss: 0.1195
Epoch 5 [138/172] - loss: 0.1486
Epoch 5 [139/172] - loss: 0.2178
Epoch 5 [140/172] - loss: 0.1124, acc: 1.0000
Epoch 5 [141/172] - loss: 0.1088
Epoch 5 [142/172] - loss: 0.1106
Epoch 5 [143/172] - loss: 0.1114
Epoch 5 [144/172] - loss: 0.1053
Epoch 5 [145/172] - loss: 0.1230
Epoch 5 [146/172] - loss: 0.1300
Epoch 5 [147/172] - loss: 0.1557
Epoch 5 [148/172] - loss: 0.1049
Epoch 5 [149/172] - loss: 0.1061
Epoch 5 [150/172] - loss: 0.1751, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1373
Epoch 5 [152/172] - loss: 0.1065
Epoch 5 [153/172] - loss: 0.1090
Epoch 5 [154/172] - loss: 0.1222
Epoch 5 [155/172] - loss: 0.1298
Epoch 5 [156/172] - loss: 0.1143
Epoch 5 [157/172] - loss: 0.1195
Epoch 5 [158/172] - loss: 0.1368
Epoch 5 [159/172] - loss: 0.1057
Epoch 5 [160/172] - loss: 0.1092, acc: 1.0000
Epoch 5 [161/172] - loss: 0.1085
Epoch 5 [162/172] - loss: 0.1297
Epoch 5 [163/172] - loss: 0.1451
Epoch 5 [164/172] - loss: 0.1119
Epoch 5 [165/172] - loss: 0.1693
Epoch 5 [166/172] - loss: 0.1222
Epoch 5 [167/172] - loss: 0.1114
Epoch 5 [168/172] - loss: 0.1083
Epoch 5 [169/172] - loss: 0.1175
Epoch 5 [170/172] - loss: 0.1100, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1197
Epoch 5 [172/172] - loss: 0.1283

类别准确率:
positive: 0.7537 (352/467)
neutral: 0.2289 (19/83)
negative: 0.7840 (196/250)

Epoch 5/10
Train Loss: 0.1221, Train Acc: 0.9919
Val Loss: 1.0354, Val Acc: 0.7087
Epoch 6 [1/172] - loss: 0.1184, acc: 1.0000
Epoch 6 [2/172] - loss: 0.1509
Epoch 6 [3/172] - loss: 0.1063
Epoch 6 [4/172] - loss: 0.1054
Epoch 6 [5/172] - loss: 0.1363
Epoch 6 [6/172] - loss: 0.1082
Epoch 6 [7/172] - loss: 0.1232
Epoch 6 [8/172] - loss: 0.1087
Epoch 6 [9/172] - loss: 0.1095
Epoch 6 [10/172] - loss: 0.1080, acc: 1.0000
Epoch 6 [11/172] - loss: 0.1173
Epoch 6 [12/172] - loss: 0.1088
Epoch 6 [13/172] - loss: 0.1128
Epoch 6 [14/172] - loss: 0.1054
Epoch 6 [15/172] - loss: 0.1127
Epoch 6 [16/172] - loss: 0.1696
Epoch 6 [17/172] - loss: 0.1076
Epoch 6 [18/172] - loss: 0.1121
Epoch 6 [19/172] - loss: 0.1120
Epoch 6 [20/172] - loss: 0.1116, acc: 1.0000
Epoch 6 [21/172] - loss: 0.1106
Epoch 6 [22/172] - loss: 0.1455
Epoch 6 [23/172] - loss: 0.1226
Epoch 6 [24/172] - loss: 0.1097
Epoch 6 [25/172] - loss: 0.1107
Epoch 6 [26/172] - loss: 0.1122
Epoch 6 [27/172] - loss: 0.1321
Epoch 6 [28/172] - loss: 0.1169
Epoch 6 [29/172] - loss: 0.1091
Epoch 6 [30/172] - loss: 0.1086, acc: 1.0000
Epoch 6 [31/172] - loss: 0.1057
Epoch 6 [32/172] - loss: 0.1121
Epoch 6 [33/172] - loss: 0.1068
Epoch 6 [34/172] - loss: 0.1067
Epoch 6 [35/172] - loss: 0.1098
Epoch 6 [36/172] - loss: 0.1061
Epoch 6 [37/172] - loss: 0.1068
Epoch 6 [38/172] - loss: 0.1166
Epoch 6 [39/172] - loss: 0.1073
Epoch 6 [40/172] - loss: 0.1265, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1688, log_difficulty=0.1560, weight=1.7800
neutral: count=8815.0, difficulty=0.1186, log_difficulty=0.1120, weight=1.5602
negative: count=9870.0, difficulty=0.1537, log_difficulty=0.1430, weight=1.7150

当前batch的pt分布：
positive: min=0.0342, max=0.9996, mean=0.9068
neutral: min=0.9768, max=0.9990, mean=0.9924
negative: min=0.9499, max=0.9996, mean=0.9839

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1154
焦点损失: 0.0985
边界损失: 0.1406
总损失: 0.1493
Epoch 6 [41/172] - loss: 0.1493
Epoch 6 [42/172] - loss: 0.1157
Epoch 6 [43/172] - loss: 0.1854
Epoch 6 [44/172] - loss: 0.1083
Epoch 6 [45/172] - loss: 0.1463
Epoch 6 [46/172] - loss: 0.1167
Epoch 6 [47/172] - loss: 0.1351
Epoch 6 [48/172] - loss: 0.1202
Epoch 6 [49/172] - loss: 0.1198
Epoch 6 [50/172] - loss: 0.1554, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1404
Epoch 6 [52/172] - loss: 0.1346
Epoch 6 [53/172] - loss: 0.1053
Epoch 6 [54/172] - loss: 0.1581
Epoch 6 [55/172] - loss: 0.1081
Epoch 6 [56/172] - loss: 0.1121
Epoch 6 [57/172] - loss: 0.1126
Epoch 6 [58/172] - loss: 0.1125
Epoch 6 [59/172] - loss: 0.1095
Epoch 6 [60/172] - loss: 0.1150, acc: 1.0000
Epoch 6 [61/172] - loss: 0.1054
Epoch 6 [62/172] - loss: 0.1144
Epoch 6 [63/172] - loss: 0.1093
Epoch 6 [64/172] - loss: 0.1480
Epoch 6 [65/172] - loss: 0.1143
Epoch 6 [66/172] - loss: 0.1076
Epoch 6 [67/172] - loss: 0.1058
Epoch 6 [68/172] - loss: 0.1140
Epoch 6 [69/172] - loss: 0.1219
Epoch 6 [70/172] - loss: 0.1090, acc: 1.0000
Epoch 6 [71/172] - loss: 0.1259
Epoch 6 [72/172] - loss: 0.1068
Epoch 6 [73/172] - loss: 0.1110
Epoch 6 [74/172] - loss: 0.1052
Epoch 6 [75/172] - loss: 0.1167
Epoch 6 [76/172] - loss: 0.1067
Epoch 6 [77/172] - loss: 0.1220
Epoch 6 [78/172] - loss: 0.1259
Epoch 6 [79/172] - loss: 0.1052
Epoch 6 [80/172] - loss: 0.1220, acc: 0.9688
Epoch 6 [81/172] - loss: 0.1246
Epoch 6 [82/172] - loss: 0.1147
Epoch 6 [83/172] - loss: 0.1050
Epoch 6 [84/172] - loss: 0.1054
Epoch 6 [85/172] - loss: 0.1255
Epoch 6 [86/172] - loss: 0.1103
Epoch 6 [87/172] - loss: 0.1100
Epoch 6 [88/172] - loss: 0.1454
Epoch 6 [89/172] - loss: 0.1081
Epoch 6 [90/172] - loss: 0.1297, acc: 0.9688
Epoch 6 [91/172] - loss: 0.1046
Epoch 6 [92/172] - loss: 0.1062
Epoch 6 [93/172] - loss: 0.1065
Epoch 6 [94/172] - loss: 0.1134
Epoch 6 [95/172] - loss: 0.1138
Epoch 6 [96/172] - loss: 0.1053
Epoch 6 [97/172] - loss: 0.1110
Epoch 6 [98/172] - loss: 0.1077
Epoch 6 [99/172] - loss: 0.1046
Epoch 6 [100/172] - loss: 0.1044, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1383
Epoch 6 [102/172] - loss: 0.1083
Epoch 6 [103/172] - loss: 0.1138
Epoch 6 [104/172] - loss: 0.1311
Epoch 6 [105/172] - loss: 0.1088
Epoch 6 [106/172] - loss: 0.1141
Epoch 6 [107/172] - loss: 0.1050
Epoch 6 [108/172] - loss: 0.1085
Epoch 6 [109/172] - loss: 0.1274
Epoch 6 [110/172] - loss: 0.1720, acc: 0.9375
Epoch 6 [111/172] - loss: 0.1070
Epoch 6 [112/172] - loss: 0.1059
Epoch 6 [113/172] - loss: 0.1182
Epoch 6 [114/172] - loss: 0.1060
Epoch 6 [115/172] - loss: 0.1396
Epoch 6 [116/172] - loss: 0.1513
Epoch 6 [117/172] - loss: 0.1063
Epoch 6 [118/172] - loss: 0.1061
Epoch 6 [119/172] - loss: 0.1555
Epoch 6 [120/172] - loss: 0.1053, acc: 1.0000
Epoch 6 [121/172] - loss: 0.1234
Epoch 6 [122/172] - loss: 0.1343
Epoch 6 [123/172] - loss: 0.1062
Epoch 6 [124/172] - loss: 0.1050
Epoch 6 [125/172] - loss: 0.1144
Epoch 6 [126/172] - loss: 0.1161
Epoch 6 [127/172] - loss: 0.1321
Epoch 6 [128/172] - loss: 0.1118
Epoch 6 [129/172] - loss: 0.1130
Epoch 6 [130/172] - loss: 0.1166, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1192
Epoch 6 [132/172] - loss: 0.1244
Epoch 6 [133/172] - loss: 0.1042
Epoch 6 [134/172] - loss: 0.1048
Epoch 6 [135/172] - loss: 0.1078
Epoch 6 [136/172] - loss: 0.1060
Epoch 6 [137/172] - loss: 0.1077
Epoch 6 [138/172] - loss: 0.1073
Epoch 6 [139/172] - loss: 0.1107
Epoch 6 [140/172] - loss: 0.1075, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1551, log_difficulty=0.1441, weight=1.7207
neutral: count=9796.0, difficulty=0.1090, log_difficulty=0.1035, weight=1.5173
negative: count=10972.0, difficulty=0.1417, log_difficulty=0.1325, weight=1.6624

当前batch的pt分布：
positive: min=0.9827, max=0.9994, mean=0.9950
neutral: min=0.9400, max=0.9995, mean=0.9870
negative: min=0.8971, max=0.9963, mean=0.9775

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0149
焦点损失: 0.0001
边界损失: 0.1420
总损失: 0.1065
Epoch 6 [141/172] - loss: 0.1065
Epoch 6 [142/172] - loss: 0.1056
Epoch 6 [143/172] - loss: 0.1111
Epoch 6 [144/172] - loss: 0.1093
Epoch 6 [145/172] - loss: 0.1072
Epoch 6 [146/172] - loss: 0.1052
Epoch 6 [147/172] - loss: 0.1082
Epoch 6 [148/172] - loss: 0.1216
Epoch 6 [149/172] - loss: 0.1334
Epoch 6 [150/172] - loss: 0.1048, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1079
Epoch 6 [152/172] - loss: 0.1153
Epoch 6 [153/172] - loss: 0.1057
Epoch 6 [154/172] - loss: 0.1246
Epoch 6 [155/172] - loss: 0.1580
Epoch 6 [156/172] - loss: 0.1205
Epoch 6 [157/172] - loss: 0.1057
Epoch 6 [158/172] - loss: 0.1113
Epoch 6 [159/172] - loss: 0.1064
Epoch 6 [160/172] - loss: 0.1297, acc: 0.9688
Epoch 6 [161/172] - loss: 0.1127
Epoch 6 [162/172] - loss: 0.1044
Epoch 6 [163/172] - loss: 0.1067
Epoch 6 [164/172] - loss: 0.1444
Epoch 6 [165/172] - loss: 0.1640
Epoch 6 [166/172] - loss: 0.1114
Epoch 6 [167/172] - loss: 0.1049
Epoch 6 [168/172] - loss: 0.1057
Epoch 6 [169/172] - loss: 0.1096
Epoch 6 [170/172] - loss: 0.1060, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1077
Epoch 6 [172/172] - loss: 0.1092

类别准确率:
positive: 0.9122 (426/467)
neutral: 0.2169 (18/83)
negative: 0.5440 (136/250)

Epoch 6/10
Train Loss: 0.1150, Train Acc: 0.9899
Val Loss: 1.0432, Val Acc: 0.7250
Early stopping triggered!
Best validation accuracy: 0.7262

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_061716-hwjqvv1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.15_Multimodal_iterations_20250118_061715
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/hwjqvv1r
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▂▂▂▂▂▂▂▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███
wandb:  train_acc ▁▃▅▃▄▂▅▅▅▆▇▆▅▇▆▇██▇██▇▇█▇▇▇██▇███████▇█▇
wandb: train_loss █▇▅▆▅▄▃▃▂▃▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1030
wandb:  train_acc 1
wandb: train_loss 0.10596
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.15_Multimodal_iterations_20250118_061715 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/hwjqvv1r
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_061716-hwjqvv1r/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_062615-11l1li0i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.15_Multimodal_epochs_20250118_062615
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/11l1li0i
wandb: uploading history steps 0-0, summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▄▅▇█
wandb:  train_acc ▁▅▇███
wandb: train_loss █▄▂▂▁▁
wandb:    val_acc ▁▇█▇▆█
wandb:   val_loss ▂▁▃█▆▆
wandb: 
wandb: Run summary:
wandb:      epoch 6
wandb:  train_acc 0.9899
wandb: train_loss 0.11498
wandb:    val_acc 0.725
wandb:   val_loss 1.04319
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.5_dropout0.15_Multimodal_epochs_20250118_062615 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/11l1li0i
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_062615-11l1li0i/logs

