=== 命令 ===
python main.py --loss_type focal --alpha 0.25 --beta 0.75 --neural_init_weight 1.0 --dropout 0.15 --name loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.15 --wandb True

=== 标准输出 ===
Config Info:
device: cuda
batch_size: 32
learning_rate: 0.0001
num_epochs: 10
val_ratio: 0.2
wandb: True
early_stop_patience: 3
text_model_name: ./pretrained_models/bert-base-uncased
image_model_name: ./pretrained_models/swinv2-base
data_dir: data
train_file: train.txt
test_file: test_without_label.txt
result_file: result.txt
use_kfold: False
k_folds: 5
project_name: multimodal_sentiment_analysis_loss
use_text: True
use_image: True
feature_fusion: concat
num_classes: 3
log_iteration: 10
name: loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.15
text_dim: 128
image_dim: 256
dropout: 0.15
loss_type: focal
alpha: 0.25
beta: 0.75
neural_init_weight: 1.0

数据集统计信息:
总样本数: 6869
原始样本数: 4000
增强样本数: 2869

标签分布:
negative: 2386 (34.74%)
neutral: 2095 (30.50%)
positive: 2388 (34.76%)

缺失文本数: 0
缺失图像数: 0
Training on cuda

=== 第 1 次迭代调试信息 ===
当前类别统计：
positive: count=12.0, difficulty=0.6908, log_difficulty=0.5252, weight=3.6261
neutral: count=7.0, difficulty=0.6803, log_difficulty=0.5190, weight=3.5948
negative: count=13.0, difficulty=0.6529, log_difficulty=0.5025, weight=3.5126

当前batch的pt分布：
positive: min=0.1979, max=0.4312, mean=0.3092
neutral: min=0.1711, max=0.4225, mean=0.3197
negative: min=0.1774, max=0.6381, mean=0.3471

当前batch准确率：
整体准确率: 0.2812
positive 准确率: 0.2500
neutral 准确率: 0.4286
negative 准确率: 0.2308

损失分量：
基础交叉熵: 1.1592
焦点损失: 0.4023
边界损失: 0.8042
总损失: 0.9628
Epoch 1 [1/172] - loss: 0.9628, acc: 0.2812
Epoch 1 [2/172] - loss: 0.9470
Epoch 1 [3/172] - loss: 0.9817
Epoch 1 [4/172] - loss: 0.9024
Epoch 1 [5/172] - loss: 0.9560
Epoch 1 [6/172] - loss: 1.0120
Epoch 1 [7/172] - loss: 0.9096
Epoch 1 [8/172] - loss: 0.8773
Epoch 1 [9/172] - loss: 0.8129
Epoch 1 [10/172] - loss: 0.8266, acc: 0.5312
Epoch 1 [11/172] - loss: 0.8063
Epoch 1 [12/172] - loss: 0.7658
Epoch 1 [13/172] - loss: 0.7325
Epoch 1 [14/172] - loss: 0.8170
Epoch 1 [15/172] - loss: 0.8094
Epoch 1 [16/172] - loss: 0.9120
Epoch 1 [17/172] - loss: 0.9322
Epoch 1 [18/172] - loss: 0.8258
Epoch 1 [19/172] - loss: 0.7295
Epoch 1 [20/172] - loss: 0.8266, acc: 0.3438
Epoch 1 [21/172] - loss: 0.7762
Epoch 1 [22/172] - loss: 0.7608
Epoch 1 [23/172] - loss: 0.8323
Epoch 1 [24/172] - loss: 0.8423
Epoch 1 [25/172] - loss: 0.7648
Epoch 1 [26/172] - loss: 0.8002
Epoch 1 [27/172] - loss: 0.8472
Epoch 1 [28/172] - loss: 0.7050
Epoch 1 [29/172] - loss: 0.8054
Epoch 1 [30/172] - loss: 0.5750, acc: 0.6875
Epoch 1 [31/172] - loss: 0.7203
Epoch 1 [32/172] - loss: 0.7186
Epoch 1 [33/172] - loss: 0.7131
Epoch 1 [34/172] - loss: 0.7811
Epoch 1 [35/172] - loss: 0.9340
Epoch 1 [36/172] - loss: 0.5769
Epoch 1 [37/172] - loss: 0.5193
Epoch 1 [38/172] - loss: 0.7152
Epoch 1 [39/172] - loss: 0.6605
Epoch 1 [40/172] - loss: 0.6382, acc: 0.5625
Epoch 1 [41/172] - loss: 0.6554
Epoch 1 [42/172] - loss: 0.4542
Epoch 1 [43/172] - loss: 0.7311
Epoch 1 [44/172] - loss: 0.8560
Epoch 1 [45/172] - loss: 0.8979
Epoch 1 [46/172] - loss: 0.5625
Epoch 1 [47/172] - loss: 0.6524
Epoch 1 [48/172] - loss: 0.5822
Epoch 1 [49/172] - loss: 0.7589
Epoch 1 [50/172] - loss: 0.6766, acc: 0.6875
Epoch 1 [51/172] - loss: 0.6864
Epoch 1 [52/172] - loss: 0.6938
Epoch 1 [53/172] - loss: 0.6414
Epoch 1 [54/172] - loss: 0.6808
Epoch 1 [55/172] - loss: 0.5164
Epoch 1 [56/172] - loss: 0.5220
Epoch 1 [57/172] - loss: 0.6694
Epoch 1 [58/172] - loss: 0.4486
Epoch 1 [59/172] - loss: 0.7767
Epoch 1 [60/172] - loss: 0.5486, acc: 0.7188
Epoch 1 [61/172] - loss: 0.5864
Epoch 1 [62/172] - loss: 0.6027
Epoch 1 [63/172] - loss: 0.6879
Epoch 1 [64/172] - loss: 0.5314
Epoch 1 [65/172] - loss: 0.7047
Epoch 1 [66/172] - loss: 0.5957
Epoch 1 [67/172] - loss: 0.7318
Epoch 1 [68/172] - loss: 0.7485
Epoch 1 [69/172] - loss: 0.6892
Epoch 1 [70/172] - loss: 0.5616, acc: 0.6875
Epoch 1 [71/172] - loss: 0.5585
Epoch 1 [72/172] - loss: 0.7356
Epoch 1 [73/172] - loss: 0.5585
Epoch 1 [74/172] - loss: 0.6356
Epoch 1 [75/172] - loss: 0.3803
Epoch 1 [76/172] - loss: 0.6131
Epoch 1 [77/172] - loss: 0.6863
Epoch 1 [78/172] - loss: 0.5329
Epoch 1 [79/172] - loss: 0.5974
Epoch 1 [80/172] - loss: 0.4647, acc: 0.6875
Epoch 1 [81/172] - loss: 0.6321
Epoch 1 [82/172] - loss: 0.8565
Epoch 1 [83/172] - loss: 0.5924
Epoch 1 [84/172] - loss: 0.5593
Epoch 1 [85/172] - loss: 0.5305
Epoch 1 [86/172] - loss: 0.6331
Epoch 1 [87/172] - loss: 0.6111
Epoch 1 [88/172] - loss: 0.6715
Epoch 1 [89/172] - loss: 0.5468
Epoch 1 [90/172] - loss: 0.6051, acc: 0.6562
Epoch 1 [91/172] - loss: 0.4810
Epoch 1 [92/172] - loss: 0.5454
Epoch 1 [93/172] - loss: 0.5423
Epoch 1 [94/172] - loss: 0.4386
Epoch 1 [95/172] - loss: 0.4487
Epoch 1 [96/172] - loss: 0.5632
Epoch 1 [97/172] - loss: 0.4415
Epoch 1 [98/172] - loss: 0.4405
Epoch 1 [99/172] - loss: 0.6331
Epoch 1 [100/172] - loss: 0.5592, acc: 0.6875

=== 第 101 次迭代调试信息 ===
当前类别统计：
positive: count=1130.0, difficulty=0.5535, log_difficulty=0.4405, weight=3.2025
neutral: count=983.0, difficulty=0.5148, log_difficulty=0.4153, weight=3.0764
negative: count=1119.0, difficulty=0.4910, log_difficulty=0.3995, weight=2.9973

当前batch的pt分布：
positive: min=0.0061, max=0.9887, mean=0.5180
neutral: min=0.2457, max=0.9952, mean=0.6333
negative: min=0.0377, max=0.9038, mean=0.4838

当前batch准确率：
整体准确率: 0.5938
positive 准确率: 0.5833
neutral 准确率: 0.7500
negative 准确率: 0.5625

损失分量：
基础交叉熵: 1.0046
焦点损失: 0.5700
边界损失: 0.3479
总损失: 0.7046
Epoch 1 [101/172] - loss: 0.7046
Epoch 1 [102/172] - loss: 0.5595
Epoch 1 [103/172] - loss: 0.5049
Epoch 1 [104/172] - loss: 0.4035
Epoch 1 [105/172] - loss: 0.6490
Epoch 1 [106/172] - loss: 0.7407
Epoch 1 [107/172] - loss: 0.4960
Epoch 1 [108/172] - loss: 0.5955
Epoch 1 [109/172] - loss: 0.4826
Epoch 1 [110/172] - loss: 0.8880, acc: 0.5000
Epoch 1 [111/172] - loss: 0.4360
Epoch 1 [112/172] - loss: 0.4181
Epoch 1 [113/172] - loss: 0.4211
Epoch 1 [114/172] - loss: 0.3506
Epoch 1 [115/172] - loss: 0.4972
Epoch 1 [116/172] - loss: 0.4859
Epoch 1 [117/172] - loss: 0.3889
Epoch 1 [118/172] - loss: 0.4105
Epoch 1 [119/172] - loss: 0.3569
Epoch 1 [120/172] - loss: 0.4134, acc: 0.8125
Epoch 1 [121/172] - loss: 0.3820
Epoch 1 [122/172] - loss: 0.6006
Epoch 1 [123/172] - loss: 0.3818
Epoch 1 [124/172] - loss: 0.3521
Epoch 1 [125/172] - loss: 0.3444
Epoch 1 [126/172] - loss: 0.6836
Epoch 1 [127/172] - loss: 0.3653
Epoch 1 [128/172] - loss: 0.3621
Epoch 1 [129/172] - loss: 0.4854
Epoch 1 [130/172] - loss: 0.3793, acc: 0.7500
Epoch 1 [131/172] - loss: 0.2683
Epoch 1 [132/172] - loss: 0.4784
Epoch 1 [133/172] - loss: 0.4826
Epoch 1 [134/172] - loss: 0.4254
Epoch 1 [135/172] - loss: 0.4286
Epoch 1 [136/172] - loss: 0.3205
Epoch 1 [137/172] - loss: 0.4089
Epoch 1 [138/172] - loss: 0.3327
Epoch 1 [139/172] - loss: 0.2980
Epoch 1 [140/172] - loss: 0.3373, acc: 0.8438
Epoch 1 [141/172] - loss: 0.4687
Epoch 1 [142/172] - loss: 0.3974
Epoch 1 [143/172] - loss: 0.3694
Epoch 1 [144/172] - loss: 0.2942
Epoch 1 [145/172] - loss: 0.3678
Epoch 1 [146/172] - loss: 0.4284
Epoch 1 [147/172] - loss: 0.7281
Epoch 1 [148/172] - loss: 0.4892
Epoch 1 [149/172] - loss: 0.2434
Epoch 1 [150/172] - loss: 0.6281, acc: 0.5625
Epoch 1 [151/172] - loss: 0.4484
Epoch 1 [152/172] - loss: 0.4643
Epoch 1 [153/172] - loss: 0.3479
Epoch 1 [154/172] - loss: 0.3557
Epoch 1 [155/172] - loss: 0.3994
Epoch 1 [156/172] - loss: 0.5145
Epoch 1 [157/172] - loss: 0.4726
Epoch 1 [158/172] - loss: 0.4386
Epoch 1 [159/172] - loss: 0.5177
Epoch 1 [160/172] - loss: 0.3500, acc: 0.8438
Epoch 1 [161/172] - loss: 0.3714
Epoch 1 [162/172] - loss: 0.3762
Epoch 1 [163/172] - loss: 0.3518
Epoch 1 [164/172] - loss: 0.4837
Epoch 1 [165/172] - loss: 0.3328
Epoch 1 [166/172] - loss: 0.4890
Epoch 1 [167/172] - loss: 0.3310
Epoch 1 [168/172] - loss: 0.5211
Epoch 1 [169/172] - loss: 0.3515
Epoch 1 [170/172] - loss: 0.3710, acc: 0.7500
Epoch 1 [171/172] - loss: 0.3009
Epoch 1 [172/172] - loss: 0.4525

类别准确率:
positive: 0.7452 (348/467)
neutral: 0.5663 (47/83)
negative: 0.6400 (160/250)

Epoch 1/10
Train Loss: 0.4070, Train Acc: 0.7919
Val Loss: 0.7028, Val Acc: 0.6937
Epoch 2 [1/172] - loss: 0.3265, acc: 0.8438
Epoch 2 [2/172] - loss: 0.2269
Epoch 2 [3/172] - loss: 0.2684
Epoch 2 [4/172] - loss: 0.4435
Epoch 2 [5/172] - loss: 0.4347
Epoch 2 [6/172] - loss: 0.4143
Epoch 2 [7/172] - loss: 0.3390
Epoch 2 [8/172] - loss: 0.3516
Epoch 2 [9/172] - loss: 0.3420
Epoch 2 [10/172] - loss: 0.2816, acc: 0.9375
Epoch 2 [11/172] - loss: 0.2638
Epoch 2 [12/172] - loss: 0.2276
Epoch 2 [13/172] - loss: 0.4464
Epoch 2 [14/172] - loss: 0.4003
Epoch 2 [15/172] - loss: 0.2904
Epoch 2 [16/172] - loss: 0.3271
Epoch 2 [17/172] - loss: 0.3590
Epoch 2 [18/172] - loss: 0.4223
Epoch 2 [19/172] - loss: 0.2931
Epoch 2 [20/172] - loss: 0.2469, acc: 0.8438
Epoch 2 [21/172] - loss: 0.2871
Epoch 2 [22/172] - loss: 0.2683
Epoch 2 [23/172] - loss: 0.2320
Epoch 2 [24/172] - loss: 0.4260
Epoch 2 [25/172] - loss: 0.3240
Epoch 2 [26/172] - loss: 0.2285
Epoch 2 [27/172] - loss: 0.1963
Epoch 2 [28/172] - loss: 0.2183

=== 第 201 次迭代调试信息 ===
当前类别统计：
positive: count=2247.0, difficulty=0.4582, log_difficulty=0.3772, weight=2.8861
neutral: count=1952.0, difficulty=0.3874, log_difficulty=0.3275, weight=2.6373
negative: count=2216.0, difficulty=0.4193, log_difficulty=0.3502, weight=2.7508

当前batch的pt分布：
positive: min=0.0963, max=0.9957, mean=0.7129
neutral: min=0.3555, max=0.9934, mean=0.8755
negative: min=0.0296, max=0.9881, mean=0.7173

当前batch准确率：
整体准确率: 0.7812
positive 准确率: 0.6667
neutral 准确率: 0.9091
negative 准确率: 0.7500

损失分量：
基础交叉熵: 0.4471
焦点损失: 0.2480
边界损失: 0.2150
总损失: 0.3344
Epoch 2 [29/172] - loss: 0.3344
Epoch 2 [30/172] - loss: 0.2590, acc: 0.9375
Epoch 2 [31/172] - loss: 0.3154
Epoch 2 [32/172] - loss: 0.3807
Epoch 2 [33/172] - loss: 0.2907
Epoch 2 [34/172] - loss: 0.3524
Epoch 2 [35/172] - loss: 0.2444
Epoch 2 [36/172] - loss: 0.3631
Epoch 2 [37/172] - loss: 0.2015
Epoch 2 [38/172] - loss: 0.2580
Epoch 2 [39/172] - loss: 0.3612
Epoch 2 [40/172] - loss: 0.4289, acc: 0.7500
Epoch 2 [41/172] - loss: 0.2699
Epoch 2 [42/172] - loss: 0.1702
Epoch 2 [43/172] - loss: 0.1958
Epoch 2 [44/172] - loss: 0.3395
Epoch 2 [45/172] - loss: 0.2014
Epoch 2 [46/172] - loss: 0.1962
Epoch 2 [47/172] - loss: 0.3162
Epoch 2 [48/172] - loss: 0.3432
Epoch 2 [49/172] - loss: 0.2292
Epoch 2 [50/172] - loss: 0.3083, acc: 0.7812
Epoch 2 [51/172] - loss: 0.3253
Epoch 2 [52/172] - loss: 0.2171
Epoch 2 [53/172] - loss: 0.3153
Epoch 2 [54/172] - loss: 0.3005
Epoch 2 [55/172] - loss: 0.2515
Epoch 2 [56/172] - loss: 0.2732
Epoch 2 [57/172] - loss: 0.2165
Epoch 2 [58/172] - loss: 0.2316
Epoch 2 [59/172] - loss: 0.3713
Epoch 2 [60/172] - loss: 0.1783, acc: 0.9688
Epoch 2 [61/172] - loss: 0.1719
Epoch 2 [62/172] - loss: 0.1950
Epoch 2 [63/172] - loss: 0.3568
Epoch 2 [64/172] - loss: 0.3868
Epoch 2 [65/172] - loss: 0.2553
Epoch 2 [66/172] - loss: 0.2871
Epoch 2 [67/172] - loss: 0.1953
Epoch 2 [68/172] - loss: 0.2689
Epoch 2 [69/172] - loss: 0.2188
Epoch 2 [70/172] - loss: 0.3241, acc: 0.8750
Epoch 2 [71/172] - loss: 0.3556
Epoch 2 [72/172] - loss: 0.2385
Epoch 2 [73/172] - loss: 0.3025
Epoch 2 [74/172] - loss: 0.2775
Epoch 2 [75/172] - loss: 0.2359
Epoch 2 [76/172] - loss: 0.2645
Epoch 2 [77/172] - loss: 0.2797
Epoch 2 [78/172] - loss: 0.2878
Epoch 2 [79/172] - loss: 0.2368
Epoch 2 [80/172] - loss: 0.2427, acc: 0.8750
Epoch 2 [81/172] - loss: 0.2657
Epoch 2 [82/172] - loss: 0.2088
Epoch 2 [83/172] - loss: 0.2212
Epoch 2 [84/172] - loss: 0.2270
Epoch 2 [85/172] - loss: 0.2462
Epoch 2 [86/172] - loss: 0.2516
Epoch 2 [87/172] - loss: 0.4565
Epoch 2 [88/172] - loss: 0.2245
Epoch 2 [89/172] - loss: 0.1753
Epoch 2 [90/172] - loss: 0.3270, acc: 0.8125
Epoch 2 [91/172] - loss: 0.1799
Epoch 2 [92/172] - loss: 0.2932
Epoch 2 [93/172] - loss: 0.2806
Epoch 2 [94/172] - loss: 0.2091
Epoch 2 [95/172] - loss: 0.2135
Epoch 2 [96/172] - loss: 0.1696
Epoch 2 [97/172] - loss: 0.2589
Epoch 2 [98/172] - loss: 0.2138
Epoch 2 [99/172] - loss: 0.2225
Epoch 2 [100/172] - loss: 0.2515, acc: 0.9375
Epoch 2 [101/172] - loss: 0.1804
Epoch 2 [102/172] - loss: 0.1965
Epoch 2 [103/172] - loss: 0.2479
Epoch 2 [104/172] - loss: 0.2536
Epoch 2 [105/172] - loss: 0.2797
Epoch 2 [106/172] - loss: 0.1805
Epoch 2 [107/172] - loss: 0.1873
Epoch 2 [108/172] - loss: 0.3442
Epoch 2 [109/172] - loss: 0.1947
Epoch 2 [110/172] - loss: 0.2507, acc: 0.9062
Epoch 2 [111/172] - loss: 0.2124
Epoch 2 [112/172] - loss: 0.1572
Epoch 2 [113/172] - loss: 0.1719
Epoch 2 [114/172] - loss: 0.3342
Epoch 2 [115/172] - loss: 0.2746
Epoch 2 [116/172] - loss: 0.2641
Epoch 2 [117/172] - loss: 0.3826
Epoch 2 [118/172] - loss: 0.2068
Epoch 2 [119/172] - loss: 0.2311
Epoch 2 [120/172] - loss: 0.2097, acc: 0.9062
Epoch 2 [121/172] - loss: 0.1635
Epoch 2 [122/172] - loss: 0.3505
Epoch 2 [123/172] - loss: 0.1758
Epoch 2 [124/172] - loss: 0.1974
Epoch 2 [125/172] - loss: 0.1466
Epoch 2 [126/172] - loss: 0.1949
Epoch 2 [127/172] - loss: 0.2308
Epoch 2 [128/172] - loss: 0.2735

=== 第 301 次迭代调试信息 ===
当前类别统计：
positive: count=3372.0, difficulty=0.3837, log_difficulty=0.3248, weight=2.6239
neutral: count=2949.0, difficulty=0.2970, log_difficulty=0.2601, weight=2.3003
negative: count=3294.0, difficulty=0.3507, log_difficulty=0.3006, weight=2.5032

当前batch的pt分布：
positive: min=0.0639, max=0.9837, mean=0.7880
neutral: min=0.5499, max=0.9983, mean=0.8813
negative: min=0.0379, max=0.9815, mean=0.7911

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.8000
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.3398
焦点损失: 0.1860
边界损失: 0.2097
总损失: 0.2758
Epoch 2 [129/172] - loss: 0.2758
Epoch 2 [130/172] - loss: 0.2307, acc: 0.8750
Epoch 2 [131/172] - loss: 0.1525
Epoch 2 [132/172] - loss: 0.2580
Epoch 2 [133/172] - loss: 0.1889
Epoch 2 [134/172] - loss: 0.2459
Epoch 2 [135/172] - loss: 0.3196
Epoch 2 [136/172] - loss: 0.1854
Epoch 2 [137/172] - loss: 0.2063
Epoch 2 [138/172] - loss: 0.1943
Epoch 2 [139/172] - loss: 0.2351
Epoch 2 [140/172] - loss: 0.2599, acc: 0.9062
Epoch 2 [141/172] - loss: 0.1774
Epoch 2 [142/172] - loss: 0.2068
Epoch 2 [143/172] - loss: 0.2092
Epoch 2 [144/172] - loss: 0.2262
Epoch 2 [145/172] - loss: 0.4572
Epoch 2 [146/172] - loss: 0.1587
Epoch 2 [147/172] - loss: 0.2568
Epoch 2 [148/172] - loss: 0.1831
Epoch 2 [149/172] - loss: 0.3541
Epoch 2 [150/172] - loss: 0.2126, acc: 0.9375
Epoch 2 [151/172] - loss: 0.2077
Epoch 2 [152/172] - loss: 0.1925
Epoch 2 [153/172] - loss: 0.2196
Epoch 2 [154/172] - loss: 0.2277
Epoch 2 [155/172] - loss: 0.2188
Epoch 2 [156/172] - loss: 0.1746
Epoch 2 [157/172] - loss: 0.1429
Epoch 2 [158/172] - loss: 0.2242
Epoch 2 [159/172] - loss: 0.2248
Epoch 2 [160/172] - loss: 0.1700, acc: 0.9688
Epoch 2 [161/172] - loss: 0.1855
Epoch 2 [162/172] - loss: 0.1860
Epoch 2 [163/172] - loss: 0.2761
Epoch 2 [164/172] - loss: 0.2566
Epoch 2 [165/172] - loss: 0.3435
Epoch 2 [166/172] - loss: 0.2602
Epoch 2 [167/172] - loss: 0.3190
Epoch 2 [168/172] - loss: 0.2109
Epoch 2 [169/172] - loss: 0.1794
Epoch 2 [170/172] - loss: 0.2410, acc: 0.9375
Epoch 2 [171/172] - loss: 0.2411
Epoch 2 [172/172] - loss: 0.4713

类别准确率:
positive: 0.8737 (408/467)
neutral: 0.3855 (32/83)
negative: 0.5200 (130/250)

Epoch 2/10
Train Loss: 0.2458, Train Acc: 0.8970
Val Loss: 0.8078, Val Acc: 0.7125
Epoch 3 [1/172] - loss: 0.1868, acc: 0.9688
Epoch 3 [2/172] - loss: 0.1746
Epoch 3 [3/172] - loss: 0.1480
Epoch 3 [4/172] - loss: 0.1705
Epoch 3 [5/172] - loss: 0.1535
Epoch 3 [6/172] - loss: 0.1503
Epoch 3 [7/172] - loss: 0.1622
Epoch 3 [8/172] - loss: 0.1976
Epoch 3 [9/172] - loss: 0.1933
Epoch 3 [10/172] - loss: 0.1627, acc: 0.9688
Epoch 3 [11/172] - loss: 0.1552
Epoch 3 [12/172] - loss: 0.1426
Epoch 3 [13/172] - loss: 0.1623
Epoch 3 [14/172] - loss: 0.1352
Epoch 3 [15/172] - loss: 0.1878
Epoch 3 [16/172] - loss: 0.2570
Epoch 3 [17/172] - loss: 0.1945
Epoch 3 [18/172] - loss: 0.3816
Epoch 3 [19/172] - loss: 0.2197
Epoch 3 [20/172] - loss: 0.1354, acc: 0.9688
Epoch 3 [21/172] - loss: 0.1355
Epoch 3 [22/172] - loss: 0.2493
Epoch 3 [23/172] - loss: 0.1624
Epoch 3 [24/172] - loss: 0.1706
Epoch 3 [25/172] - loss: 0.1374
Epoch 3 [26/172] - loss: 0.1620
Epoch 3 [27/172] - loss: 0.1350
Epoch 3 [28/172] - loss: 0.1296
Epoch 3 [29/172] - loss: 0.2061
Epoch 3 [30/172] - loss: 0.1809, acc: 0.9375
Epoch 3 [31/172] - loss: 0.1390
Epoch 3 [32/172] - loss: 0.1785
Epoch 3 [33/172] - loss: 0.1289
Epoch 3 [34/172] - loss: 0.2565
Epoch 3 [35/172] - loss: 0.2426
Epoch 3 [36/172] - loss: 0.1343
Epoch 3 [37/172] - loss: 0.1413
Epoch 3 [38/172] - loss: 0.1863
Epoch 3 [39/172] - loss: 0.1402
Epoch 3 [40/172] - loss: 0.1414, acc: 0.9688
Epoch 3 [41/172] - loss: 0.1485
Epoch 3 [42/172] - loss: 0.1515
Epoch 3 [43/172] - loss: 0.1510
Epoch 3 [44/172] - loss: 0.1289
Epoch 3 [45/172] - loss: 0.1874
Epoch 3 [46/172] - loss: 0.2029
Epoch 3 [47/172] - loss: 0.1179
Epoch 3 [48/172] - loss: 0.1770
Epoch 3 [49/172] - loss: 0.1275
Epoch 3 [50/172] - loss: 0.1260, acc: 1.0000
Epoch 3 [51/172] - loss: 0.2083
Epoch 3 [52/172] - loss: 0.1763
Epoch 3 [53/172] - loss: 0.1255
Epoch 3 [54/172] - loss: 0.1748
Epoch 3 [55/172] - loss: 0.1781
Epoch 3 [56/172] - loss: 0.1572

=== 第 401 次迭代调试信息 ===
当前类别统计：
positive: count=4493.0, difficulty=0.3270, log_difficulty=0.2829, weight=2.4146
neutral: count=3923.0, difficulty=0.2468, log_difficulty=0.2206, weight=2.1029
negative: count=4382.0, difficulty=0.2982, log_difficulty=0.2609, weight=2.3047

当前batch的pt分布：
positive: min=0.0464, max=0.9906, mean=0.8726
neutral: min=0.0031, max=0.9867, mean=0.8052
negative: min=0.9881, max=0.9986, mean=0.9932

当前batch准确率：
整体准确率: 0.9062
positive 准确率: 0.9091
neutral 准确率: 0.8750
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.4267
焦点损失: 0.3508
边界损失: 0.1681
总损失: 0.3172
Epoch 3 [57/172] - loss: 0.3172
Epoch 3 [58/172] - loss: 0.1359
Epoch 3 [59/172] - loss: 0.1387
Epoch 3 [60/172] - loss: 0.1428, acc: 0.9688
Epoch 3 [61/172] - loss: 0.1659
Epoch 3 [62/172] - loss: 0.1461
Epoch 3 [63/172] - loss: 0.1267
Epoch 3 [64/172] - loss: 0.1610
Epoch 3 [65/172] - loss: 0.1534
Epoch 3 [66/172] - loss: 0.2051
Epoch 3 [67/172] - loss: 0.1421
Epoch 3 [68/172] - loss: 0.1204
Epoch 3 [69/172] - loss: 0.1856
Epoch 3 [70/172] - loss: 0.1376, acc: 0.9375
Epoch 3 [71/172] - loss: 0.1582
Epoch 3 [72/172] - loss: 0.2034
Epoch 3 [73/172] - loss: 0.1309
Epoch 3 [74/172] - loss: 0.1490
Epoch 3 [75/172] - loss: 0.1455
Epoch 3 [76/172] - loss: 0.1903
Epoch 3 [77/172] - loss: 0.1364
Epoch 3 [78/172] - loss: 0.2560
Epoch 3 [79/172] - loss: 0.1451
Epoch 3 [80/172] - loss: 0.2650, acc: 0.8750
Epoch 3 [81/172] - loss: 0.1384
Epoch 3 [82/172] - loss: 0.1913
Epoch 3 [83/172] - loss: 0.1425
Epoch 3 [84/172] - loss: 0.1252
Epoch 3 [85/172] - loss: 0.1366
Epoch 3 [86/172] - loss: 0.1536
Epoch 3 [87/172] - loss: 0.2166
Epoch 3 [88/172] - loss: 0.2223
Epoch 3 [89/172] - loss: 0.1292
Epoch 3 [90/172] - loss: 0.1307, acc: 0.9688
Epoch 3 [91/172] - loss: 0.1705
Epoch 3 [92/172] - loss: 0.1346
Epoch 3 [93/172] - loss: 0.1541
Epoch 3 [94/172] - loss: 0.2031
Epoch 3 [95/172] - loss: 0.1291
Epoch 3 [96/172] - loss: 0.1557
Epoch 3 [97/172] - loss: 0.1379
Epoch 3 [98/172] - loss: 0.1607
Epoch 3 [99/172] - loss: 0.1333
Epoch 3 [100/172] - loss: 0.1882, acc: 0.9062
Epoch 3 [101/172] - loss: 0.1873
Epoch 3 [102/172] - loss: 0.1272
Epoch 3 [103/172] - loss: 0.1968
Epoch 3 [104/172] - loss: 0.2243
Epoch 3 [105/172] - loss: 0.1238
Epoch 3 [106/172] - loss: 0.1751
Epoch 3 [107/172] - loss: 0.1283
Epoch 3 [108/172] - loss: 0.1388
Epoch 3 [109/172] - loss: 0.1159
Epoch 3 [110/172] - loss: 0.1578, acc: 0.9375
Epoch 3 [111/172] - loss: 0.1976
Epoch 3 [112/172] - loss: 0.1387
Epoch 3 [113/172] - loss: 0.1227
Epoch 3 [114/172] - loss: 0.1966
Epoch 3 [115/172] - loss: 0.2538
Epoch 3 [116/172] - loss: 0.1278
Epoch 3 [117/172] - loss: 0.1392
Epoch 3 [118/172] - loss: 0.1542
Epoch 3 [119/172] - loss: 0.1844
Epoch 3 [120/172] - loss: 0.1813, acc: 0.9688
Epoch 3 [121/172] - loss: 0.2159
Epoch 3 [122/172] - loss: 0.1575
Epoch 3 [123/172] - loss: 0.1301
Epoch 3 [124/172] - loss: 0.1524
Epoch 3 [125/172] - loss: 0.1389
Epoch 3 [126/172] - loss: 0.2789
Epoch 3 [127/172] - loss: 0.2315
Epoch 3 [128/172] - loss: 0.1129
Epoch 3 [129/172] - loss: 0.1287
Epoch 3 [130/172] - loss: 0.1221, acc: 1.0000
Epoch 3 [131/172] - loss: 0.2317
Epoch 3 [132/172] - loss: 0.1337
Epoch 3 [133/172] - loss: 0.1367
Epoch 3 [134/172] - loss: 0.1157
Epoch 3 [135/172] - loss: 0.1388
Epoch 3 [136/172] - loss: 0.1220
Epoch 3 [137/172] - loss: 0.1229
Epoch 3 [138/172] - loss: 0.1701
Epoch 3 [139/172] - loss: 0.1181
Epoch 3 [140/172] - loss: 0.1600, acc: 0.9688
Epoch 3 [141/172] - loss: 0.1645
Epoch 3 [142/172] - loss: 0.1514
Epoch 3 [143/172] - loss: 0.1405
Epoch 3 [144/172] - loss: 0.3275
Epoch 3 [145/172] - loss: 0.1555
Epoch 3 [146/172] - loss: 0.1280
Epoch 3 [147/172] - loss: 0.1395
Epoch 3 [148/172] - loss: 0.1861
Epoch 3 [149/172] - loss: 0.1762
Epoch 3 [150/172] - loss: 0.1360, acc: 0.9688
Epoch 3 [151/172] - loss: 0.1915
Epoch 3 [152/172] - loss: 0.3406
Epoch 3 [153/172] - loss: 0.1338
Epoch 3 [154/172] - loss: 0.1784
Epoch 3 [155/172] - loss: 0.1253
Epoch 3 [156/172] - loss: 0.1372

=== 第 501 次迭代调试信息 ===
当前类别统计：
positive: count=5595.0, difficulty=0.2833, log_difficulty=0.2495, weight=2.2473
neutral: count=4903.0, difficulty=0.2097, log_difficulty=0.1903, weight=1.9517
negative: count=5500.0, difficulty=0.2573, log_difficulty=0.2290, weight=2.1448

当前batch的pt分布：
positive: min=0.7112, max=0.9976, mean=0.9399
neutral: min=0.9563, max=0.9966, mean=0.9809
negative: min=0.1210, max=0.9975, mean=0.8651

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 0.9000

损失分量：
基础交叉熵: 0.1113
焦点损失: 0.0508
边界损失: 0.1603
总损失: 0.1475
Epoch 3 [157/172] - loss: 0.1475
Epoch 3 [158/172] - loss: 0.2086
Epoch 3 [159/172] - loss: 0.1296
Epoch 3 [160/172] - loss: 0.2962, acc: 0.8750
Epoch 3 [161/172] - loss: 0.1546
Epoch 3 [162/172] - loss: 0.1943
Epoch 3 [163/172] - loss: 0.2576
Epoch 3 [164/172] - loss: 0.1270
Epoch 3 [165/172] - loss: 0.1539
Epoch 3 [166/172] - loss: 0.1676
Epoch 3 [167/172] - loss: 0.1352
Epoch 3 [168/172] - loss: 0.1656
Epoch 3 [169/172] - loss: 0.1315
Epoch 3 [170/172] - loss: 0.1638, acc: 0.9375
Epoch 3 [171/172] - loss: 0.1652
Epoch 3 [172/172] - loss: 0.1290

类别准确率:
positive: 0.8073 (377/467)
neutral: 0.2892 (24/83)
negative: 0.7360 (184/250)

Epoch 3/10
Train Loss: 0.1704, Train Acc: 0.9576
Val Loss: 0.7813, Val Acc: 0.7312
Epoch 4 [1/172] - loss: 0.1112, acc: 1.0000
Epoch 4 [2/172] - loss: 0.1631
Epoch 4 [3/172] - loss: 0.1341
Epoch 4 [4/172] - loss: 0.1396
Epoch 4 [5/172] - loss: 0.1688
Epoch 4 [6/172] - loss: 0.1160
Epoch 4 [7/172] - loss: 0.1187
Epoch 4 [8/172] - loss: 0.1335
Epoch 4 [9/172] - loss: 0.1610
Epoch 4 [10/172] - loss: 0.1435, acc: 0.9375
Epoch 4 [11/172] - loss: 0.1203
Epoch 4 [12/172] - loss: 0.1417
Epoch 4 [13/172] - loss: 0.1592
Epoch 4 [14/172] - loss: 0.1798
Epoch 4 [15/172] - loss: 0.1738
Epoch 4 [16/172] - loss: 0.1190
Epoch 4 [17/172] - loss: 0.1159
Epoch 4 [18/172] - loss: 0.1406
Epoch 4 [19/172] - loss: 0.1336
Epoch 4 [20/172] - loss: 0.1237, acc: 1.0000
Epoch 4 [21/172] - loss: 0.1759
Epoch 4 [22/172] - loss: 0.1194
Epoch 4 [23/172] - loss: 0.1584
Epoch 4 [24/172] - loss: 0.1113
Epoch 4 [25/172] - loss: 0.1311
Epoch 4 [26/172] - loss: 0.2563
Epoch 4 [27/172] - loss: 0.1477
Epoch 4 [28/172] - loss: 0.1320
Epoch 4 [29/172] - loss: 0.1272
Epoch 4 [30/172] - loss: 0.1294, acc: 0.9688
Epoch 4 [31/172] - loss: 0.1661
Epoch 4 [32/172] - loss: 0.1462
Epoch 4 [33/172] - loss: 0.1227
Epoch 4 [34/172] - loss: 0.1175
Epoch 4 [35/172] - loss: 0.1775
Epoch 4 [36/172] - loss: 0.1279
Epoch 4 [37/172] - loss: 0.1131
Epoch 4 [38/172] - loss: 0.1149
Epoch 4 [39/172] - loss: 0.1400
Epoch 4 [40/172] - loss: 0.2039, acc: 0.8750
Epoch 4 [41/172] - loss: 0.1344
Epoch 4 [42/172] - loss: 0.1366
Epoch 4 [43/172] - loss: 0.1237
Epoch 4 [44/172] - loss: 0.1339
Epoch 4 [45/172] - loss: 0.1142
Epoch 4 [46/172] - loss: 0.1204
Epoch 4 [47/172] - loss: 0.1214
Epoch 4 [48/172] - loss: 0.1224
Epoch 4 [49/172] - loss: 0.1225
Epoch 4 [50/172] - loss: 0.1593, acc: 0.9688
Epoch 4 [51/172] - loss: 0.1174
Epoch 4 [52/172] - loss: 0.1518
Epoch 4 [53/172] - loss: 0.1109
Epoch 4 [54/172] - loss: 0.1315
Epoch 4 [55/172] - loss: 0.2327
Epoch 4 [56/172] - loss: 0.1259
Epoch 4 [57/172] - loss: 0.1115
Epoch 4 [58/172] - loss: 0.1106
Epoch 4 [59/172] - loss: 0.1145
Epoch 4 [60/172] - loss: 0.1114, acc: 1.0000
Epoch 4 [61/172] - loss: 0.1261
Epoch 4 [62/172] - loss: 0.1384
Epoch 4 [63/172] - loss: 0.1158
Epoch 4 [64/172] - loss: 0.1200
Epoch 4 [65/172] - loss: 0.1325
Epoch 4 [66/172] - loss: 0.1138
Epoch 4 [67/172] - loss: 0.1146
Epoch 4 [68/172] - loss: 0.1392
Epoch 4 [69/172] - loss: 0.1318
Epoch 4 [70/172] - loss: 0.1273, acc: 0.9688
Epoch 4 [71/172] - loss: 0.1099
Epoch 4 [72/172] - loss: 0.1135
Epoch 4 [73/172] - loss: 0.1187
Epoch 4 [74/172] - loss: 0.1666
Epoch 4 [75/172] - loss: 0.1524
Epoch 4 [76/172] - loss: 0.1095
Epoch 4 [77/172] - loss: 0.1499
Epoch 4 [78/172] - loss: 0.1148
Epoch 4 [79/172] - loss: 0.1155
Epoch 4 [80/172] - loss: 0.1339, acc: 0.9688
Epoch 4 [81/172] - loss: 0.2118
Epoch 4 [82/172] - loss: 0.1116
Epoch 4 [83/172] - loss: 0.1152
Epoch 4 [84/172] - loss: 0.1200

=== 第 601 次迭代调试信息 ===
当前类别统计：
positive: count=6687.0, difficulty=0.2485, log_difficulty=0.2220, weight=2.1098
neutral: count=5865.0, difficulty=0.1826, log_difficulty=0.1677, weight=1.8385
negative: count=6629.0, difficulty=0.2268, log_difficulty=0.2044, weight=2.0221

当前batch的pt分布：
positive: min=0.5339, max=0.9959, mean=0.8755
neutral: min=0.9139, max=0.9997, mean=0.9852
negative: min=0.9270, max=0.9988, mean=0.9790

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0845
焦点损失: 0.0082
边界损失: 0.1741
总损失: 0.1349
Epoch 4 [85/172] - loss: 0.1349
Epoch 4 [86/172] - loss: 0.1400
Epoch 4 [87/172] - loss: 0.1612
Epoch 4 [88/172] - loss: 0.1076
Epoch 4 [89/172] - loss: 0.1519
Epoch 4 [90/172] - loss: 0.1109, acc: 1.0000
Epoch 4 [91/172] - loss: 0.1383
Epoch 4 [92/172] - loss: 0.2321
Epoch 4 [93/172] - loss: 0.1136
Epoch 4 [94/172] - loss: 0.1305
Epoch 4 [95/172] - loss: 0.1217
Epoch 4 [96/172] - loss: 0.1635
Epoch 4 [97/172] - loss: 0.1182
Epoch 4 [98/172] - loss: 0.1348
Epoch 4 [99/172] - loss: 0.1192
Epoch 4 [100/172] - loss: 0.1371, acc: 0.9375
Epoch 4 [101/172] - loss: 0.1265
Epoch 4 [102/172] - loss: 0.1529
Epoch 4 [103/172] - loss: 0.1142
Epoch 4 [104/172] - loss: 0.1231
Epoch 4 [105/172] - loss: 0.1494
Epoch 4 [106/172] - loss: 0.1426
Epoch 4 [107/172] - loss: 0.1168
Epoch 4 [108/172] - loss: 0.1879
Epoch 4 [109/172] - loss: 0.1203
Epoch 4 [110/172] - loss: 0.3049, acc: 0.8750
Epoch 4 [111/172] - loss: 0.1127
Epoch 4 [112/172] - loss: 0.1159
Epoch 4 [113/172] - loss: 0.1185
Epoch 4 [114/172] - loss: 0.2042
Epoch 4 [115/172] - loss: 0.1193
Epoch 4 [116/172] - loss: 0.1139
Epoch 4 [117/172] - loss: 0.1177
Epoch 4 [118/172] - loss: 0.1389
Epoch 4 [119/172] - loss: 0.1147
Epoch 4 [120/172] - loss: 0.1548, acc: 0.9375
Epoch 4 [121/172] - loss: 0.1706
Epoch 4 [122/172] - loss: 0.2210
Epoch 4 [123/172] - loss: 0.1137
Epoch 4 [124/172] - loss: 0.1201
Epoch 4 [125/172] - loss: 0.1405
Epoch 4 [126/172] - loss: 0.1615
Epoch 4 [127/172] - loss: 0.1312
Epoch 4 [128/172] - loss: 0.1197
Epoch 4 [129/172] - loss: 0.1086
Epoch 4 [130/172] - loss: 0.1442, acc: 0.9688
Epoch 4 [131/172] - loss: 0.1225
Epoch 4 [132/172] - loss: 0.1099
Epoch 4 [133/172] - loss: 0.1957
Epoch 4 [134/172] - loss: 0.1523
Epoch 4 [135/172] - loss: 0.1559
Epoch 4 [136/172] - loss: 0.1421
Epoch 4 [137/172] - loss: 0.1159
Epoch 4 [138/172] - loss: 0.1327
Epoch 4 [139/172] - loss: 0.1294
Epoch 4 [140/172] - loss: 0.1133, acc: 1.0000
Epoch 4 [141/172] - loss: 0.1341
Epoch 4 [142/172] - loss: 0.1336
Epoch 4 [143/172] - loss: 0.1189
Epoch 4 [144/172] - loss: 0.1565
Epoch 4 [145/172] - loss: 0.1889
Epoch 4 [146/172] - loss: 0.1194
Epoch 4 [147/172] - loss: 0.1546
Epoch 4 [148/172] - loss: 0.1249
Epoch 4 [149/172] - loss: 0.1553
Epoch 4 [150/172] - loss: 0.2325, acc: 0.9062
Epoch 4 [151/172] - loss: 0.1786
Epoch 4 [152/172] - loss: 0.1140
Epoch 4 [153/172] - loss: 0.1134
Epoch 4 [154/172] - loss: 0.1817
Epoch 4 [155/172] - loss: 0.1511
Epoch 4 [156/172] - loss: 0.1267
Epoch 4 [157/172] - loss: 0.1834
Epoch 4 [158/172] - loss: 0.1153
Epoch 4 [159/172] - loss: 0.1146
Epoch 4 [160/172] - loss: 0.1236, acc: 1.0000
Epoch 4 [161/172] - loss: 0.1196
Epoch 4 [162/172] - loss: 0.1162
Epoch 4 [163/172] - loss: 0.1304
Epoch 4 [164/172] - loss: 0.1158
Epoch 4 [165/172] - loss: 0.1247
Epoch 4 [166/172] - loss: 0.1234
Epoch 4 [167/172] - loss: 0.1451
Epoch 4 [168/172] - loss: 0.1575
Epoch 4 [169/172] - loss: 0.1497
Epoch 4 [170/172] - loss: 0.1930, acc: 0.9375
Epoch 4 [171/172] - loss: 0.1194
Epoch 4 [172/172] - loss: 0.1517

类别准确率:
positive: 0.8116 (379/467)
neutral: 0.2289 (19/83)
negative: 0.7240 (181/250)

Epoch 4/10
Train Loss: 0.1365, Train Acc: 0.9798
Val Loss: 0.8718, Val Acc: 0.7238
Epoch 5 [1/172] - loss: 0.1112, acc: 1.0000
Epoch 5 [2/172] - loss: 0.1197
Epoch 5 [3/172] - loss: 0.1252
Epoch 5 [4/172] - loss: 0.1282
Epoch 5 [5/172] - loss: 0.1137
Epoch 5 [6/172] - loss: 0.1309
Epoch 5 [7/172] - loss: 0.1822
Epoch 5 [8/172] - loss: 0.1487
Epoch 5 [9/172] - loss: 0.1225
Epoch 5 [10/172] - loss: 0.1146, acc: 1.0000
Epoch 5 [11/172] - loss: 0.1447
Epoch 5 [12/172] - loss: 0.1069

=== 第 701 次迭代调试信息 ===
当前类别统计：
positive: count=7825.0, difficulty=0.2226, log_difficulty=0.2010, weight=2.0051
neutral: count=6845.0, difficulty=0.1618, log_difficulty=0.1500, weight=1.7499
negative: count=7694.0, difficulty=0.2052, log_difficulty=0.1866, weight=1.9332

当前batch的pt分布：
positive: min=0.0677, max=0.9946, mean=0.8888
neutral: min=0.9802, max=0.9996, mean=0.9941
negative: min=0.2061, max=0.9955, mean=0.8858

当前batch准确率：
整体准确率: 0.9375
positive 准确率: 0.9286
neutral 准确率: 1.0000
negative 准确率: 0.9091

损失分量：
基础交叉熵: 0.1720
焦点损失: 0.1048
边界损失: 0.1588
总损失: 0.1710
Epoch 5 [13/172] - loss: 0.1710
Epoch 5 [14/172] - loss: 0.1545
Epoch 5 [15/172] - loss: 0.1109
Epoch 5 [16/172] - loss: 0.1083
Epoch 5 [17/172] - loss: 0.1217
Epoch 5 [18/172] - loss: 0.1091
Epoch 5 [19/172] - loss: 0.1253
Epoch 5 [20/172] - loss: 0.1218, acc: 1.0000
Epoch 5 [21/172] - loss: 0.1717
Epoch 5 [22/172] - loss: 0.2070
Epoch 5 [23/172] - loss: 0.1416
Epoch 5 [24/172] - loss: 0.1485
Epoch 5 [25/172] - loss: 0.1396
Epoch 5 [26/172] - loss: 0.1618
Epoch 5 [27/172] - loss: 0.1165
Epoch 5 [28/172] - loss: 0.1104
Epoch 5 [29/172] - loss: 0.1103
Epoch 5 [30/172] - loss: 0.1210, acc: 1.0000
Epoch 5 [31/172] - loss: 0.1128
Epoch 5 [32/172] - loss: 0.1119
Epoch 5 [33/172] - loss: 0.1235
Epoch 5 [34/172] - loss: 0.1316
Epoch 5 [35/172] - loss: 0.1094
Epoch 5 [36/172] - loss: 0.1124
Epoch 5 [37/172] - loss: 0.1180
Epoch 5 [38/172] - loss: 0.1088
Epoch 5 [39/172] - loss: 0.1926
Epoch 5 [40/172] - loss: 0.1155, acc: 1.0000
Epoch 5 [41/172] - loss: 0.1094
Epoch 5 [42/172] - loss: 0.1416
Epoch 5 [43/172] - loss: 0.1426
Epoch 5 [44/172] - loss: 0.1625
Epoch 5 [45/172] - loss: 0.1094
Epoch 5 [46/172] - loss: 0.1681
Epoch 5 [47/172] - loss: 0.1073
Epoch 5 [48/172] - loss: 0.1177
Epoch 5 [49/172] - loss: 0.1250
Epoch 5 [50/172] - loss: 0.1273, acc: 0.9688
Epoch 5 [51/172] - loss: 0.1261
Epoch 5 [52/172] - loss: 0.1460
Epoch 5 [53/172] - loss: 0.1288
Epoch 5 [54/172] - loss: 0.1434
Epoch 5 [55/172] - loss: 0.1299
Epoch 5 [56/172] - loss: 0.1197
Epoch 5 [57/172] - loss: 0.1115
Epoch 5 [58/172] - loss: 0.1132
Epoch 5 [59/172] - loss: 0.1299
Epoch 5 [60/172] - loss: 0.1081, acc: 1.0000
Epoch 5 [61/172] - loss: 0.1270
Epoch 5 [62/172] - loss: 0.1082
Epoch 5 [63/172] - loss: 0.1612
Epoch 5 [64/172] - loss: 0.1249
Epoch 5 [65/172] - loss: 0.1344
Epoch 5 [66/172] - loss: 0.1114
Epoch 5 [67/172] - loss: 0.1087
Epoch 5 [68/172] - loss: 0.1224
Epoch 5 [69/172] - loss: 0.1140
Epoch 5 [70/172] - loss: 0.1095, acc: 1.0000
Epoch 5 [71/172] - loss: 0.1123
Epoch 5 [72/172] - loss: 0.1522
Epoch 5 [73/172] - loss: 0.1385
Epoch 5 [74/172] - loss: 0.1195
Epoch 5 [75/172] - loss: 0.1078
Epoch 5 [76/172] - loss: 0.1153
Epoch 5 [77/172] - loss: 0.1298
Epoch 5 [78/172] - loss: 0.1429
Epoch 5 [79/172] - loss: 0.1208
Epoch 5 [80/172] - loss: 0.1079, acc: 1.0000
Epoch 5 [81/172] - loss: 0.1774
Epoch 5 [82/172] - loss: 0.1190
Epoch 5 [83/172] - loss: 0.1151
Epoch 5 [84/172] - loss: 0.1124
Epoch 5 [85/172] - loss: 0.1705
Epoch 5 [86/172] - loss: 0.1299
Epoch 5 [87/172] - loss: 0.1158
Epoch 5 [88/172] - loss: 0.1395
Epoch 5 [89/172] - loss: 0.1170
Epoch 5 [90/172] - loss: 0.1680, acc: 0.9375
Epoch 5 [91/172] - loss: 0.1522
Epoch 5 [92/172] - loss: 0.1092
Epoch 5 [93/172] - loss: 0.1155
Epoch 5 [94/172] - loss: 0.1080
Epoch 5 [95/172] - loss: 0.1499
Epoch 5 [96/172] - loss: 0.1178
Epoch 5 [97/172] - loss: 0.1428
Epoch 5 [98/172] - loss: 0.1160
Epoch 5 [99/172] - loss: 0.1841
Epoch 5 [100/172] - loss: 0.1267, acc: 0.9688
Epoch 5 [101/172] - loss: 0.1158
Epoch 5 [102/172] - loss: 0.1351
Epoch 5 [103/172] - loss: 0.1165
Epoch 5 [104/172] - loss: 0.2636
Epoch 5 [105/172] - loss: 0.2019
Epoch 5 [106/172] - loss: 0.1127
Epoch 5 [107/172] - loss: 0.1167
Epoch 5 [108/172] - loss: 0.1487
Epoch 5 [109/172] - loss: 0.1118
Epoch 5 [110/172] - loss: 0.1072, acc: 1.0000
Epoch 5 [111/172] - loss: 0.1201
Epoch 5 [112/172] - loss: 0.1085

=== 第 801 次迭代调试信息 ===
当前类别统计：
positive: count=8959.0, difficulty=0.2005, log_difficulty=0.1827, weight=1.9135
neutral: count=7825.0, difficulty=0.1466, log_difficulty=0.1368, weight=1.6839
negative: count=8780.0, difficulty=0.1865, log_difficulty=0.1710, weight=1.8548

当前batch的pt分布：
positive: min=0.0748, max=0.9898, mean=0.8986
neutral: min=0.9354, max=0.9989, mean=0.9831
negative: min=0.9978, max=0.9995, mean=0.9990

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9375
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.1101
焦点损失: 0.0694
边界损失: 0.1507
总损失: 0.1462
Epoch 5 [113/172] - loss: 0.1462
Epoch 5 [114/172] - loss: 0.1291
Epoch 5 [115/172] - loss: 0.1188
Epoch 5 [116/172] - loss: 0.1153
Epoch 5 [117/172] - loss: 0.1117
Epoch 5 [118/172] - loss: 0.1071
Epoch 5 [119/172] - loss: 0.1182
Epoch 5 [120/172] - loss: 0.1236, acc: 1.0000
Epoch 5 [121/172] - loss: 0.1213
Epoch 5 [122/172] - loss: 0.1093
Epoch 5 [123/172] - loss: 0.1381
Epoch 5 [124/172] - loss: 0.1099
Epoch 5 [125/172] - loss: 0.1089
Epoch 5 [126/172] - loss: 0.1176
Epoch 5 [127/172] - loss: 0.1114
Epoch 5 [128/172] - loss: 0.1113
Epoch 5 [129/172] - loss: 0.1524
Epoch 5 [130/172] - loss: 0.1088, acc: 1.0000
Epoch 5 [131/172] - loss: 0.1196
Epoch 5 [132/172] - loss: 0.1461
Epoch 5 [133/172] - loss: 0.1567
Epoch 5 [134/172] - loss: 0.1585
Epoch 5 [135/172] - loss: 0.1120
Epoch 5 [136/172] - loss: 0.1085
Epoch 5 [137/172] - loss: 0.1151
Epoch 5 [138/172] - loss: 0.1290
Epoch 5 [139/172] - loss: 0.1779
Epoch 5 [140/172] - loss: 0.1494, acc: 0.9375
Epoch 5 [141/172] - loss: 0.1147
Epoch 5 [142/172] - loss: 0.1156
Epoch 5 [143/172] - loss: 0.1074
Epoch 5 [144/172] - loss: 0.1074
Epoch 5 [145/172] - loss: 0.1237
Epoch 5 [146/172] - loss: 0.1082
Epoch 5 [147/172] - loss: 0.1168
Epoch 5 [148/172] - loss: 0.1056
Epoch 5 [149/172] - loss: 0.1108
Epoch 5 [150/172] - loss: 0.1554, acc: 0.9688
Epoch 5 [151/172] - loss: 0.1093
Epoch 5 [152/172] - loss: 0.1087
Epoch 5 [153/172] - loss: 0.1067
Epoch 5 [154/172] - loss: 0.1080
Epoch 5 [155/172] - loss: 0.1072
Epoch 5 [156/172] - loss: 0.1089
Epoch 5 [157/172] - loss: 0.1257
Epoch 5 [158/172] - loss: 0.1059
Epoch 5 [159/172] - loss: 0.1088
Epoch 5 [160/172] - loss: 0.1650, acc: 0.9688
Epoch 5 [161/172] - loss: 0.1071
Epoch 5 [162/172] - loss: 0.1726
Epoch 5 [163/172] - loss: 0.1490
Epoch 5 [164/172] - loss: 0.1059
Epoch 5 [165/172] - loss: 0.1380
Epoch 5 [166/172] - loss: 0.1156
Epoch 5 [167/172] - loss: 0.1497
Epoch 5 [168/172] - loss: 0.1063
Epoch 5 [169/172] - loss: 0.1108
Epoch 5 [170/172] - loss: 0.1137, acc: 1.0000
Epoch 5 [171/172] - loss: 0.1088
Epoch 5 [172/172] - loss: 0.1152

类别准确率:
positive: 0.8929 (417/467)
neutral: 0.2651 (22/83)
negative: 0.5320 (133/250)

Epoch 5/10
Train Loss: 0.1249, Train Acc: 0.9859
Val Loss: 0.9399, Val Acc: 0.7150
Epoch 6 [1/172] - loss: 0.1400, acc: 1.0000
Epoch 6 [2/172] - loss: 0.1201
Epoch 6 [3/172] - loss: 0.1068
Epoch 6 [4/172] - loss: 0.1068
Epoch 6 [5/172] - loss: 0.1339
Epoch 6 [6/172] - loss: 0.1051
Epoch 6 [7/172] - loss: 0.1099
Epoch 6 [8/172] - loss: 0.1188
Epoch 6 [9/172] - loss: 0.1081
Epoch 6 [10/172] - loss: 0.1060, acc: 1.0000
Epoch 6 [11/172] - loss: 0.1143
Epoch 6 [12/172] - loss: 0.1078
Epoch 6 [13/172] - loss: 0.1232
Epoch 6 [14/172] - loss: 0.1086
Epoch 6 [15/172] - loss: 0.1176
Epoch 6 [16/172] - loss: 0.1478
Epoch 6 [17/172] - loss: 0.1069
Epoch 6 [18/172] - loss: 0.1108
Epoch 6 [19/172] - loss: 0.1095
Epoch 6 [20/172] - loss: 0.1156, acc: 1.0000
Epoch 6 [21/172] - loss: 0.1531
Epoch 6 [22/172] - loss: 0.1118
Epoch 6 [23/172] - loss: 0.1078
Epoch 6 [24/172] - loss: 0.1120
Epoch 6 [25/172] - loss: 0.1455
Epoch 6 [26/172] - loss: 0.1158
Epoch 6 [27/172] - loss: 0.1384
Epoch 6 [28/172] - loss: 0.1141
Epoch 6 [29/172] - loss: 0.1091
Epoch 6 [30/172] - loss: 0.1052, acc: 1.0000
Epoch 6 [31/172] - loss: 0.1211
Epoch 6 [32/172] - loss: 0.1064
Epoch 6 [33/172] - loss: 0.1058
Epoch 6 [34/172] - loss: 0.1233
Epoch 6 [35/172] - loss: 0.1071
Epoch 6 [36/172] - loss: 0.1062
Epoch 6 [37/172] - loss: 0.1064
Epoch 6 [38/172] - loss: 0.1058
Epoch 6 [39/172] - loss: 0.1154
Epoch 6 [40/172] - loss: 0.1248, acc: 0.9688

=== 第 901 次迭代调试信息 ===
当前类别统计：
positive: count=10062.0, difficulty=0.1821, log_difficulty=0.1673, weight=1.8366
neutral: count=8815.0, difficulty=0.1335, log_difficulty=0.1253, weight=1.6265
negative: count=9870.0, difficulty=0.1700, log_difficulty=0.1570, weight=1.7851

当前batch的pt分布：
positive: min=0.2061, max=0.9990, mean=0.9195
neutral: min=0.9795, max=0.9995, mean=0.9922
negative: min=0.9311, max=0.9969, mean=0.9847

当前batch准确率：
整体准确率: 0.9688
positive 准确率: 0.9091
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0601
焦点损失: 0.0311
边界损失: 0.1442
总损失: 0.1225
Epoch 6 [41/172] - loss: 0.1225
Epoch 6 [42/172] - loss: 0.1083
Epoch 6 [43/172] - loss: 0.1344
Epoch 6 [44/172] - loss: 0.1068
Epoch 6 [45/172] - loss: 0.1477
Epoch 6 [46/172] - loss: 0.1108
Epoch 6 [47/172] - loss: 0.1073
Epoch 6 [48/172] - loss: 0.1060
Epoch 6 [49/172] - loss: 0.1105
Epoch 6 [50/172] - loss: 0.1654, acc: 0.9688
Epoch 6 [51/172] - loss: 0.1112
Epoch 6 [52/172] - loss: 0.1227
Epoch 6 [53/172] - loss: 0.1137
Epoch 6 [54/172] - loss: 0.1681
Epoch 6 [55/172] - loss: 0.1108
Epoch 6 [56/172] - loss: 0.1083
Epoch 6 [57/172] - loss: 0.1073
Epoch 6 [58/172] - loss: 0.1109
Epoch 6 [59/172] - loss: 0.1169
Epoch 6 [60/172] - loss: 0.1414, acc: 0.9375
Epoch 6 [61/172] - loss: 0.1067
Epoch 6 [62/172] - loss: 0.1226
Epoch 6 [63/172] - loss: 0.1096
Epoch 6 [64/172] - loss: 0.1249
Epoch 6 [65/172] - loss: 0.1180
Epoch 6 [66/172] - loss: 0.1080
Epoch 6 [67/172] - loss: 0.1051
Epoch 6 [68/172] - loss: 0.1243
Epoch 6 [69/172] - loss: 0.1132
Epoch 6 [70/172] - loss: 0.1060, acc: 1.0000
Epoch 6 [71/172] - loss: 0.1068
Epoch 6 [72/172] - loss: 0.1117
Epoch 6 [73/172] - loss: 0.1103
Epoch 6 [74/172] - loss: 0.1075
Epoch 6 [75/172] - loss: 0.1226
Epoch 6 [76/172] - loss: 0.1124
Epoch 6 [77/172] - loss: 0.1181
Epoch 6 [78/172] - loss: 0.1160
Epoch 6 [79/172] - loss: 0.1230
Epoch 6 [80/172] - loss: 0.1095, acc: 1.0000
Epoch 6 [81/172] - loss: 0.1151
Epoch 6 [82/172] - loss: 0.1225
Epoch 6 [83/172] - loss: 0.1069
Epoch 6 [84/172] - loss: 0.1162
Epoch 6 [85/172] - loss: 0.1212
Epoch 6 [86/172] - loss: 0.1110
Epoch 6 [87/172] - loss: 0.1096
Epoch 6 [88/172] - loss: 0.1242
Epoch 6 [89/172] - loss: 0.1073
Epoch 6 [90/172] - loss: 0.1052, acc: 1.0000
Epoch 6 [91/172] - loss: 0.1086
Epoch 6 [92/172] - loss: 0.1078
Epoch 6 [93/172] - loss: 0.1065
Epoch 6 [94/172] - loss: 0.1170
Epoch 6 [95/172] - loss: 0.1110
Epoch 6 [96/172] - loss: 0.1062
Epoch 6 [97/172] - loss: 0.1118
Epoch 6 [98/172] - loss: 0.1140
Epoch 6 [99/172] - loss: 0.1077
Epoch 6 [100/172] - loss: 0.1059, acc: 1.0000
Epoch 6 [101/172] - loss: 0.1224
Epoch 6 [102/172] - loss: 0.1104
Epoch 6 [103/172] - loss: 0.1124
Epoch 6 [104/172] - loss: 0.1376
Epoch 6 [105/172] - loss: 0.1075
Epoch 6 [106/172] - loss: 0.1329
Epoch 6 [107/172] - loss: 0.1146
Epoch 6 [108/172] - loss: 0.1064
Epoch 6 [109/172] - loss: 0.1684
Epoch 6 [110/172] - loss: 0.1129, acc: 1.0000
Epoch 6 [111/172] - loss: 0.1065
Epoch 6 [112/172] - loss: 0.1059
Epoch 6 [113/172] - loss: 0.1156
Epoch 6 [114/172] - loss: 0.1051
Epoch 6 [115/172] - loss: 0.1342
Epoch 6 [116/172] - loss: 0.1900
Epoch 6 [117/172] - loss: 0.1065
Epoch 6 [118/172] - loss: 0.1062
Epoch 6 [119/172] - loss: 0.1432
Epoch 6 [120/172] - loss: 0.1091, acc: 1.0000
Epoch 6 [121/172] - loss: 0.1189
Epoch 6 [122/172] - loss: 0.1085
Epoch 6 [123/172] - loss: 0.1063
Epoch 6 [124/172] - loss: 0.1040
Epoch 6 [125/172] - loss: 0.1098
Epoch 6 [126/172] - loss: 0.1181
Epoch 6 [127/172] - loss: 0.1371
Epoch 6 [128/172] - loss: 0.1077
Epoch 6 [129/172] - loss: 0.1062
Epoch 6 [130/172] - loss: 0.1727, acc: 0.9688
Epoch 6 [131/172] - loss: 0.1251
Epoch 6 [132/172] - loss: 0.1195
Epoch 6 [133/172] - loss: 0.1051
Epoch 6 [134/172] - loss: 0.1163
Epoch 6 [135/172] - loss: 0.1062
Epoch 6 [136/172] - loss: 0.1041
Epoch 6 [137/172] - loss: 0.1069
Epoch 6 [138/172] - loss: 0.1303
Epoch 6 [139/172] - loss: 0.1064
Epoch 6 [140/172] - loss: 0.1101, acc: 1.0000

=== 第 1001 次迭代调试信息 ===
当前类别统计：
positive: count=11179.0, difficulty=0.1671, log_difficulty=0.1545, weight=1.7724
neutral: count=9796.0, difficulty=0.1225, log_difficulty=0.1155, weight=1.5777
negative: count=10972.0, difficulty=0.1561, log_difficulty=0.1450, weight=1.7251

当前batch的pt分布：
positive: min=0.9895, max=0.9992, mean=0.9954
neutral: min=0.9878, max=0.9979, mean=0.9947
negative: min=0.8515, max=0.9961, mean=0.9723

当前batch准确率：
整体准确率: 1.0000
positive 准确率: 1.0000
neutral 准确率: 1.0000
negative 准确率: 1.0000

损失分量：
基础交叉熵: 0.0147
焦点损失: 0.0001
边界损失: 0.1423
总损失: 0.1068
Epoch 6 [141/172] - loss: 0.1068
Epoch 6 [142/172] - loss: 0.1065
Epoch 6 [143/172] - loss: 0.1093
Epoch 6 [144/172] - loss: 0.1091
Epoch 6 [145/172] - loss: 0.1052
Epoch 6 [146/172] - loss: 0.1094
Epoch 6 [147/172] - loss: 0.1061
Epoch 6 [148/172] - loss: 0.1091
Epoch 6 [149/172] - loss: 0.1067
Epoch 6 [150/172] - loss: 0.1091, acc: 1.0000
Epoch 6 [151/172] - loss: 0.1066
Epoch 6 [152/172] - loss: 0.1121
Epoch 6 [153/172] - loss: 0.1060
Epoch 6 [154/172] - loss: 0.1055
Epoch 6 [155/172] - loss: 0.1333
Epoch 6 [156/172] - loss: 0.1729
Epoch 6 [157/172] - loss: 0.1052
Epoch 6 [158/172] - loss: 0.1155
Epoch 6 [159/172] - loss: 0.1085
Epoch 6 [160/172] - loss: 0.1229, acc: 0.9688
Epoch 6 [161/172] - loss: 0.1059
Epoch 6 [162/172] - loss: 0.1081
Epoch 6 [163/172] - loss: 0.1149
Epoch 6 [164/172] - loss: 0.1205
Epoch 6 [165/172] - loss: 0.1974
Epoch 6 [166/172] - loss: 0.1097
Epoch 6 [167/172] - loss: 0.1048
Epoch 6 [168/172] - loss: 0.1281
Epoch 6 [169/172] - loss: 0.1219
Epoch 6 [170/172] - loss: 0.1067, acc: 1.0000
Epoch 6 [171/172] - loss: 0.1063
Epoch 6 [172/172] - loss: 0.1071

类别准确率:
positive: 0.8544 (399/467)
neutral: 0.2771 (23/83)
negative: 0.6200 (155/250)

Epoch 6/10
Train Loss: 0.1177, Train Acc: 0.9899
Val Loss: 0.9842, Val Acc: 0.7212
Early stopping triggered!
Best validation accuracy: 0.7312

=== 标准错误 ===
/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/root/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: leofyfan (leofyfan-east-china-normal-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_052344-iy0783w5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.15_Multimodal_iterations_20250118_052342
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/iy0783w5
wandb: uploading wandb-summary.json; uploading config.yaml; uploading output.log
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:  train_acc ▄▄▄▄▁▅▂▅▅▆▇▇▆▇▇▇███▇█▇█▆█▇██████████▇███
wandb: train_loss █▇▅▅▅▄▄▃▃▂▃▃▂▂▂▁▂▁▁▂▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 1030
wandb:  train_acc 1
wandb: train_loss 0.10673
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.15_Multimodal_iterations_20250118_052342 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/iy0783w5
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_052344-iy0783w5/logs
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /root/project5/wandb/run-20250118_053241-s21hr9y4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.15_Multimodal_epochs_20250118_053241
wandb: ⭐️ View project at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: 🚀 View run at https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/s21hr9y4
wandb: uploading history steps 0-0, summary; uploading wandb-metadata.json; uploading wandb-summary.json
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:      epoch ▁▂▄▅▇█
wandb:  train_acc ▁▅▇███
wandb: train_loss █▄▂▁▁▁
wandb:    val_acc ▁▄█▇▅▆
wandb:   val_loss ▁▄▃▅▇█
wandb: 
wandb: Run summary:
wandb:      epoch 6
wandb:  train_acc 0.9899
wandb: train_loss 0.11772
wandb:    val_acc 0.72125
wandb:   val_loss 0.98415
wandb: 
wandb: 🚀 View run loss_focal_alpha0.25_beta0.75_weight1.0_dropout0.15_Multimodal_epochs_20250118_053241 at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss/runs/s21hr9y4
wandb: ⭐️ View project at: https://wandb.ai/leofyfan-east-china-normal-university/multimodal_sentiment_analysis_loss
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250118_053241-s21hr9y4/logs

